<?xml version="1.0" encoding="utf-8" standalone="yes"?><rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom"><channel><title>Question Answering on Akitenkrad's Blog</title><link>https://akitenkrad.github.io/blog-akitenkrad/tags/question-answering/</link><description>Recent content in Question Answering on Akitenkrad's Blog</description><generator>Hugo -- gohugo.io</generator><language>ja-jp</language><lastBuildDate>Sat, 14 May 2022 00:00:00 +0000</lastBuildDate><atom:link href="https://akitenkrad.github.io/blog-akitenkrad/tags/question-answering/index.xml" rel="self" type="application/rss+xml"/><item><title>UnitedQA: A Hybrid Approach for Open Domain Question Answering</title><link>https://akitenkrad.github.io/blog-akitenkrad/posts/papers/202205/20220514151839/</link><pubDate>Sat, 14 May 2022 00:00:00 +0000</pubDate><guid>https://akitenkrad.github.io/blog-akitenkrad/posts/papers/202205/20220514151839/</guid><description>Round-1: Overview Round-2: Model Implementation Details Round-3: Experiments Citation Cheng, H., Shen, Y., Liu, X., He, P., Chen, W., &amp;amp; Gao, J. (2021).
UnitedQA: A Hybrid Approach for Open Domain Question Answering.
https://doi.org/10.48550/arxiv.2101.00178 Abstract To date, most of recent work under the retrieval-reader framework for open-domain QA focuses on either extractive or generative reader exclusively. In this paper, we study a hybrid approach for leveraging the strengths of both models.</description></item><item><title>Multi-Style Generative Reading Comprehension</title><link>https://akitenkrad.github.io/blog-akitenkrad/posts/papers/202205/20220511010217/</link><pubDate>Wed, 11 May 2022 00:00:00 +0000</pubDate><guid>https://akitenkrad.github.io/blog-akitenkrad/posts/papers/202205/20220511010217/</guid><description>Round-1: Overview Round-2: Model Implementation Details Round-3: Experiments Citation Nishida, K., Saito, I., Nishida, K., Shinoda, K., Otsuka, A., Asano, H., &amp;amp; Tomita, J. (2020).
Multi-style Generative Reading Comprehension.
ACL 2019 - 57th Annual Meeting of the Association for Computational Linguistics, Proceedings of the Conference, 2273–2284.
https://doi.org/10.18653/v1/p19-1220 Abstract This study tackles generative reading comprehension (RC), which consists of answering questions based on textual evidence and natural language generation (NLG). We proposea multi-style abstractive summarization model for question answering, called Masque.</description></item><item><title>A Deep Cascade Model for Multi-Document Reading Comprehension</title><link>https://akitenkrad.github.io/blog-akitenkrad/posts/papers/202205/20220508162318/</link><pubDate>Sun, 08 May 2022 00:00:00 +0000</pubDate><guid>https://akitenkrad.github.io/blog-akitenkrad/posts/papers/202205/20220508162318/</guid><description>Round-1: Overview Round-2: Model Implementation Details Round-3: Experiments Citation Yan, M., Xia, J., Wu, C., Bi, B., Zhao, Z., Zhang, J., Si, L., Wang, R., Wang, W., &amp;amp; Chen, H. (2019).
A Deep Cascade Model for Multi-Document Reading Comprehension.
Proceedings of the AAAI Conference on Artificial Intelligence, 33, 7354–7361.
https://doi.org/10.1609/aaai.v33i01.33017354 Abstract A fundamental trade-off between effectiveness and efficiency needs to be balanced when designing an online question answering system. Effectiveness comes from sophisticated functions such as extractive machine reading comprehension (MRC), while efficiency is obtained from improvements in preliminary retrieval components such as candidate document selection and paragraph ranking.</description></item><item><title>Dense Passage Retrieval for Open-Domain Question Answering</title><link>https://akitenkrad.github.io/blog-akitenkrad/posts/papers/202205/20220505222900/</link><pubDate>Thu, 05 May 2022 00:00:00 +0000</pubDate><guid>https://akitenkrad.github.io/blog-akitenkrad/posts/papers/202205/20220505222900/</guid><description>Round-1: Overview Round-2: Model Implementation Details Round-3: Experiments Citation Karpukhin, V., Oğuz, B., Min, S., Lewis, P., Wu, L., Edunov, S., Chen, D., &amp;amp; Yih, W. (2020).
Dense Passage Retrieval for Open-Domain Question Answering.
Paper Link Abstract Open-domain question answering relies on efficient passage retrieval to select candidate contexts, where traditional sparse vector space models, such as TF-IDF or BM25, are the de facto method. In this work, we show that retrieval can be practically implemented using dense representations alone, where embeddings are learned from a small number of questions and passages by a simple dual-encoder framework.</description></item></channel></rss>