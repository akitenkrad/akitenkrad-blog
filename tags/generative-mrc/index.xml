<?xml version="1.0" encoding="utf-8" standalone="yes"?><rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom"><channel><title>Generative MRC on Akitenkrad's Blog</title><link>https://akitenkrad.github.io/blog-akitenkrad/tags/generative-mrc/</link><description>Recent content in Generative MRC on Akitenkrad's Blog</description><generator>Hugo -- gohugo.io</generator><language>ja-jp</language><lastBuildDate>Sat, 14 May 2022 00:00:00 +0000</lastBuildDate><atom:link href="https://akitenkrad.github.io/blog-akitenkrad/tags/generative-mrc/index.xml" rel="self" type="application/rss+xml"/><item><title>UnitedQA: A Hybrid Approach for Open Domain Question Answering</title><link>https://akitenkrad.github.io/blog-akitenkrad/posts/papers/202205/20220514151839/</link><pubDate>Sat, 14 May 2022 00:00:00 +0000</pubDate><guid>https://akitenkrad.github.io/blog-akitenkrad/posts/papers/202205/20220514151839/</guid><description>Round-1: Overview Round-2: Model Implementation Details Round-3: Experiments Citation Cheng, H., Shen, Y., Liu, X., He, P., Chen, W., &amp;amp; Gao, J. (2021).
UnitedQA: A Hybrid Approach for Open Domain Question Answering.
https://doi.org/10.48550/arxiv.2101.00178 Abstract To date, most of recent work under the retrieval-reader framework for open-domain QA focuses on either extractive or generative reader exclusively. In this paper, we study a hybrid approach for leveraging the strengths of both models.</description></item><item><title>Multi-Style Generative Reading Comprehension</title><link>https://akitenkrad.github.io/blog-akitenkrad/posts/papers/202205/20220511010217/</link><pubDate>Wed, 11 May 2022 00:00:00 +0000</pubDate><guid>https://akitenkrad.github.io/blog-akitenkrad/posts/papers/202205/20220511010217/</guid><description>Round-1: Overview Round-2: Model Implementation Details Round-3: Experiments Citation Nishida, K., Saito, I., Nishida, K., Shinoda, K., Otsuka, A., Asano, H., &amp;amp; Tomita, J. (2020).
Multi-style Generative Reading Comprehension.
ACL 2019 - 57th Annual Meeting of the Association for Computational Linguistics, Proceedings of the Conference, 2273â€“2284.
https://doi.org/10.18653/v1/p19-1220 Abstract This study tackles generative reading comprehension (RC), which consists of answering questions based on textual evidence and natural language generation (NLG). We proposea multi-style abstractive summarization model for question answering, called Masque.</description></item></channel></rss>