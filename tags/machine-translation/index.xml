<?xml version="1.0" encoding="utf-8" standalone="yes"?><rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom"><channel><title>Machine Translation on Akitenkrad's Blog</title><link>https://akitenkrad.github.io/blog-akitenkrad/tags/machine-translation/</link><description>Recent content in Machine Translation on Akitenkrad's Blog</description><generator>Hugo -- gohugo.io</generator><language>ja-jp</language><lastBuildDate>Mon, 30 May 2022 00:00:00 +0000</lastBuildDate><atom:link href="https://akitenkrad.github.io/blog-akitenkrad/tags/machine-translation/index.xml" rel="self" type="application/rss+xml"/><item><title>Neural Machine Translation of Rare Words with Subword Units</title><link>https://akitenkrad.github.io/blog-akitenkrad/posts/papers/202205/20220530102936/</link><pubDate>Mon, 30 May 2022 00:00:00 +0000</pubDate><guid>https://akitenkrad.github.io/blog-akitenkrad/posts/papers/202205/20220530102936/</guid><description>Round-1: Overview Round-2: Model Implementation Details Round-3: Experiments Citation Sennrich, R., Haddow, B., &amp;amp; Birch, A. (2015).
Neural Machine Translation of Rare Words with Subword Units.
https://doi.org/10.48550/arxiv.1508.07909 Abstract Neural machine translation (NMT) models typically operate with a fixed vocabulary, but translation is an open-vocabulary problem. Previous work addresses the translation of out-of-vocabulary words by backing off to a dictionary. In this paper, we introduce a simpler and more effective approach, making the NMT model capable of open-vocabulary translation by encoding rare and unknown words as sequences of subword units.</description></item></channel></rss>