---
draft: false
title: "arXiv @ 2024.04.08"
date: 2024-04-08
author: "akitenkrad"
description: ""
tags: ["arXiv", "Published:2024"]
menu:
  sidebar:
    name: "arXiv @ 2024.04.08"
    identifier: arxiv_20240408
    parent: 202404_arxiv
    weight: 10
math: true
---

<figure style="border:none; width:100%; display:flex; justify-content: center">
    <iframe src="pie.html" width=900 height=620 style="border:none"></iframe>
</figure>


## Primary Categories

- [astro-ph.IM (1)](#astro-phim-1)
- [cs.AI (6)](#csai-6)
- [cs.AR (1)](#csar-1)
- [cs.CE (1)](#csce-1)
- [cs.CG (1)](#cscg-1)
- [cs.CL (18)](#cscl-18)
- [cs.CR (5)](#cscr-5)
- [cs.CV (42)](#cscv-42)
- [cs.CY (1)](#cscy-1)
- [cs.DB (1)](#csdb-1)
- [cs.DS (1)](#csds-1)
- [cs.HC (3)](#cshc-3)
- [cs.IR (1)](#csir-1)
- [cs.IT (1)](#csit-1)
- [cs.LG (16)](#cslg-16)
- [cs.MM (1)](#csmm-1)
- [cs.NE (2)](#csne-2)
- [cs.NI (3)](#csni-3)
- [cs.PL (3)](#cspl-3)
- [cs.RO (1)](#csro-1)
- [cs.SE (2)](#csse-2)
- [eess.IV (2)](#eessiv-2)
- [eess.SY (7)](#eesssy-7)
- [math.OC (1)](#mathoc-1)
- [physics.flu-dyn (1)](#physicsflu-dyn-1)
- [physics.soc-ph (1)](#physicssoc-ph-1)
- [stat.ML (3)](#statml-3)

## Keywords

<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th>keyword</th>
      <th>cs.CL</th>
      <th>cs.CV</th>
      <th>cs.LG</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td>Active Learning</td>
      <td></td>
      <td>2</td>
      <td></td>
    </tr>
    <tr>
      <td>Adversarial Learning</td>
      <td></td>
      <td>1</td>
      <td></td>
    </tr>
    <tr>
      <td>Anomaly Detection</td>
      <td></td>
      <td>1</td>
      <td></td>
    </tr>
    <tr>
      <td>Autoencoder</td>
      <td>1</td>
      <td>1</td>
      <td></td>
    </tr>
    <tr>
      <td>Automatic Evaluation</td>
      <td></td>
      <td>1</td>
      <td></td>
    </tr>
    <tr>
      <td>BERT</td>
      <td>2</td>
      <td></td>
      <td></td>
    </tr>
    <tr>
      <td>BLOOM</td>
      <td>1</td>
      <td></td>
      <td></td>
    </tr>
    <tr>
      <td>Bandit Algorithm</td>
      <td></td>
      <td></td>
      <td>1</td>
    </tr>
    <tr>
      <td>Benchmarking</td>
      <td>4</td>
      <td>17</td>
      <td>3</td>
    </tr>
    <tr>
      <td>Black Box</td>
      <td>1</td>
      <td></td>
      <td></td>
    </tr>
    <tr>
      <td>Chatbot</td>
      <td></td>
      <td></td>
      <td>1</td>
    </tr>
    <tr>
      <td>Clustering</td>
      <td>1</td>
      <td>2</td>
      <td>1</td>
    </tr>
    <tr>
      <td>Continual Learning</td>
      <td></td>
      <td></td>
      <td>1</td>
    </tr>
    <tr>
      <td>Contrastive Learning</td>
      <td>1</td>
      <td>3</td>
      <td>1</td>
    </tr>
    <tr>
      <td>ControlNet</td>
      <td></td>
      <td>1</td>
      <td></td>
    </tr>
    <tr>
      <td>Convolution</td>
      <td></td>
      <td>3</td>
      <td>1</td>
    </tr>
    <tr>
      <td>Convolutional Neural Network</td>
      <td></td>
      <td>4</td>
      <td></td>
    </tr>
    <tr>
      <td>Counter-factual</td>
      <td></td>
      <td></td>
      <td>1</td>
    </tr>
    <tr>
      <td>Data Augmentation</td>
      <td></td>
      <td>2</td>
      <td></td>
    </tr>
    <tr>
      <td>Dependency Parsing</td>
      <td>1</td>
      <td></td>
      <td></td>
    </tr>
    <tr>
      <td>Diffusion Model</td>
      <td></td>
      <td>8</td>
      <td></td>
    </tr>
    <tr>
      <td>Direct Preference Optimization</td>
      <td>1</td>
      <td></td>
      <td>1</td>
    </tr>
    <tr>
      <td>Distribution Shift</td>
      <td></td>
      <td>2</td>
      <td></td>
    </tr>
    <tr>
      <td>Domain Adaptation</td>
      <td>1</td>
      <td>1</td>
      <td></td>
    </tr>
    <tr>
      <td>Emotion Recognition</td>
      <td>1</td>
      <td>1</td>
      <td></td>
    </tr>
    <tr>
      <td>Explainable AI</td>
      <td></td>
      <td>1</td>
      <td>1</td>
    </tr>
    <tr>
      <td>Face Recognition</td>
      <td></td>
      <td>1</td>
      <td></td>
    </tr>
    <tr>
      <td>Fairness</td>
      <td></td>
      <td></td>
      <td>1</td>
    </tr>
    <tr>
      <td>Federated Learning</td>
      <td></td>
      <td></td>
      <td>2</td>
    </tr>
    <tr>
      <td>Few-shot</td>
      <td></td>
      <td>1</td>
      <td></td>
    </tr>
    <tr>
      <td>Fine-tuning</td>
      <td>4</td>
      <td>1</td>
      <td></td>
    </tr>
    <tr>
      <td>Foundation Model</td>
      <td></td>
      <td></td>
      <td>1</td>
    </tr>
    <tr>
      <td>GPT</td>
      <td>2</td>
      <td></td>
      <td></td>
    </tr>
    <tr>
      <td>GPT-3</td>
      <td>1</td>
      <td></td>
      <td></td>
    </tr>
    <tr>
      <td>GPT-3.5</td>
      <td>1</td>
      <td></td>
      <td></td>
    </tr>
    <tr>
      <td>Gemini</td>
      <td>2</td>
      <td></td>
      <td></td>
    </tr>
    <tr>
      <td>Generative AI</td>
      <td></td>
      <td>1</td>
      <td></td>
    </tr>
    <tr>
      <td>Generative Adversarial Network</td>
      <td></td>
      <td>1</td>
      <td></td>
    </tr>
    <tr>
      <td>Geometry</td>
      <td></td>
      <td>2</td>
      <td></td>
    </tr>
    <tr>
      <td>Graph</td>
      <td></td>
      <td>2</td>
      <td>3</td>
    </tr>
    <tr>
      <td>Graph Attention Networks</td>
      <td></td>
      <td>2</td>
      <td></td>
    </tr>
    <tr>
      <td>Graph Neural Network</td>
      <td></td>
      <td></td>
      <td>3</td>
    </tr>
    <tr>
      <td>Image2text</td>
      <td></td>
      <td>2</td>
      <td></td>
    </tr>
    <tr>
      <td>In-context Learning</td>
      <td>1</td>
      <td></td>
      <td></td>
    </tr>
    <tr>
      <td>Information Retrieval</td>
      <td>1</td>
      <td></td>
      <td></td>
    </tr>
    <tr>
      <td>Instruction Tuning</td>
      <td>1</td>
      <td></td>
      <td></td>
    </tr>
    <tr>
      <td>Knowledge Distillation</td>
      <td>2</td>
      <td>2</td>
      <td></td>
    </tr>
    <tr>
      <td>LLaMA</td>
      <td>1</td>
      <td></td>
      <td></td>
    </tr>
    <tr>
      <td>Large Language Model</td>
      <td>19</td>
      <td>3</td>
      <td>5</td>
    </tr>
    <tr>
      <td>Logistic Regression</td>
      <td></td>
      <td></td>
      <td>1</td>
    </tr>
    <tr>
      <td>Low-Resource</td>
      <td>3</td>
      <td></td>
      <td></td>
    </tr>
    <tr>
      <td>MNIST</td>
      <td></td>
      <td>2</td>
      <td></td>
    </tr>
    <tr>
      <td>Massive Multitask Language Understanding (MMLU)</td>
      <td>1</td>
      <td></td>
      <td></td>
    </tr>
    <tr>
      <td>Message-Passing</td>
      <td></td>
      <td></td>
      <td>1</td>
    </tr>
    <tr>
      <td>Model Compression</td>
      <td>1</td>
      <td></td>
      <td></td>
    </tr>
    <tr>
      <td>Multi-modal</td>
      <td>2</td>
      <td>5</td>
      <td></td>
    </tr>
    <tr>
      <td>Mutual Information</td>
      <td>1</td>
      <td></td>
      <td></td>
    </tr>
    <tr>
      <td>Named Entity Recognition</td>
      <td>1</td>
      <td></td>
      <td></td>
    </tr>
    <tr>
      <td>Natural Language Inference</td>
      <td>3</td>
      <td></td>
      <td></td>
    </tr>
    <tr>
      <td>Neural Machine Translation</td>
      <td>1</td>
      <td></td>
      <td></td>
    </tr>
    <tr>
      <td>Object Detection</td>
      <td></td>
      <td>3</td>
      <td></td>
    </tr>
    <tr>
      <td>Offline Reinforcement Learning</td>
      <td></td>
      <td></td>
      <td>1</td>
    </tr>
    <tr>
      <td>Open-Domain Question Answering</td>
      <td>2</td>
      <td></td>
      <td></td>
    </tr>
    <tr>
      <td>Out-of-distribution</td>
      <td></td>
      <td>1</td>
      <td>1</td>
    </tr>
    <tr>
      <td>Out-of-domain</td>
      <td>1</td>
      <td>1</td>
      <td></td>
    </tr>
    <tr>
      <td>Pre-trained Language Model</td>
      <td>5</td>
      <td></td>
      <td></td>
    </tr>
    <tr>
      <td>Probabilistic Model</td>
      <td>1</td>
      <td></td>
      <td></td>
    </tr>
    <tr>
      <td>Prompt</td>
      <td>2</td>
      <td>4</td>
      <td>1</td>
    </tr>
    <tr>
      <td>Pruning</td>
      <td>1</td>
      <td>1</td>
      <td>1</td>
    </tr>
    <tr>
      <td>Quantization</td>
      <td>1</td>
      <td></td>
      <td></td>
    </tr>
    <tr>
      <td>Question Answering</td>
      <td>3</td>
      <td>1</td>
      <td></td>
    </tr>
    <tr>
      <td>Reasoning</td>
      <td>2</td>
      <td>3</td>
      <td></td>
    </tr>
    <tr>
      <td>Recommendation</td>
      <td></td>
      <td>1</td>
      <td></td>
    </tr>
    <tr>
      <td>Reinforcement Learning</td>
      <td></td>
      <td></td>
      <td>2</td>
    </tr>
    <tr>
      <td>Relation Extraction</td>
      <td></td>
      <td>1</td>
      <td></td>
    </tr>
    <tr>
      <td>Representation Learning</td>
      <td></td>
      <td>1</td>
      <td></td>
    </tr>
    <tr>
      <td>Rerank</td>
      <td>1</td>
      <td></td>
      <td></td>
    </tr>
    <tr>
      <td>Retrieval-Augmented Generation</td>
      <td>3</td>
      <td></td>
      <td></td>
    </tr>
    <tr>
      <td>Security</td>
      <td></td>
      <td>1</td>
      <td></td>
    </tr>
    <tr>
      <td>Self-Attention</td>
      <td></td>
      <td>4</td>
      <td></td>
    </tr>
    <tr>
      <td>Self-supervised Learning</td>
      <td></td>
      <td>3</td>
      <td></td>
    </tr>
    <tr>
      <td>Semi-Supervised Learning</td>
      <td></td>
      <td>1</td>
      <td></td>
    </tr>
    <tr>
      <td>Simulation</td>
      <td></td>
      <td>1</td>
      <td>4</td>
    </tr>
    <tr>
      <td>Simulator</td>
      <td></td>
      <td>1</td>
      <td>4</td>
    </tr>
    <tr>
      <td>Stemming</td>
      <td></td>
      <td>1</td>
      <td></td>
    </tr>
    <tr>
      <td>Summarization</td>
      <td></td>
      <td>2</td>
      <td></td>
    </tr>
    <tr>
      <td>Supervised Learning</td>
      <td>1</td>
      <td>5</td>
      <td>2</td>
    </tr>
    <tr>
      <td>Text Understanding</td>
      <td>1</td>
      <td></td>
      <td></td>
    </tr>
    <tr>
      <td>Text-to-speech</td>
      <td>2</td>
      <td></td>
      <td></td>
    </tr>
    <tr>
      <td>Text2image</td>
      <td></td>
      <td>4</td>
      <td></td>
    </tr>
    <tr>
      <td>Tokenization</td>
      <td></td>
      <td>1</td>
      <td></td>
    </tr>
    <tr>
      <td>Transfer Learning</td>
      <td></td>
      <td>1</td>
      <td></td>
    </tr>
    <tr>
      <td>Transformer</td>
      <td>2</td>
      <td>8</td>
      <td></td>
    </tr>
    <tr>
      <td>Unsupervised Learning</td>
      <td>1</td>
      <td>5</td>
      <td></td>
    </tr>
    <tr>
      <td>Vision Transformer</td>
      <td></td>
      <td>2</td>
      <td></td>
    </tr>
    <tr>
      <td>Vision-and-Language</td>
      <td></td>
      <td>1</td>
      <td></td>
    </tr>
    <tr>
      <td>Visual Question Answering</td>
      <td>2</td>
      <td>1</td>
      <td></td>
    </tr>
    <tr>
      <td>Word Embedding</td>
      <td>1</td>
      <td></td>
      <td></td>
    </tr>
    <tr>
      <td>Zero-shot</td>
      <td>2</td>
      <td></td>
      <td></td>
    </tr>
  </tbody>
</table>

<script>
$(function() {
  $("table").addClass("keyword-table table-bordered border-success");
  $("table thead").addClass("sticky-top");
  $("table tbody td").css("text-align", "");
});
</script>


## cs.CL (18)



### (1/18 | 1/126) IITK at SemEval-2024 Task 2: Exploring the Capabilities of LLMs for Safe Biomedical Natural Language Inference for Clinical Trials (Shreyasi Mandal et al., 2024)

{{<citation>}}

Shreyasi Mandal, Ashutosh Modi. (2024)  
**IITK at SemEval-2024 Task 2: Exploring the Capabilities of LLMs for Safe Biomedical Natural Language Inference for Clinical Trials**
<br/>
<button class="copy-to-clipboard" title="IITK at SemEval-2024 Task 2: Exploring the Capabilities of LLMs for Safe Biomedical Natural Language Inference for Clinical Trials" index=1>
  <span class="copy-to-clipboard-item">Copy Title<span>
</button>
<div class="toast toast-copied toast-index-1 align-items-center text-bg-secondary border-0 position-absolute top-0 end-0" role="alert" aria-live="assertive" aria-atomic="true">
  <div class="d-flex">
    <div class="toast-body">
      Copied!
    </div>
  </div>
</div>

---
Primary Category: cs.CL  
Categories: cs-AI, cs-CL, cs-LG, cs.CL  
Keyword Score: 150  
Keywords: Retrieval-Augmented Generation, Retrieval-Augmented Generation, Retrieval-Augmented Generation, Zero-shot, GPT, GPT-3, GPT-3.5, Gemini, Natural Language Inference, Natural Language Inference, Reasoning, Large Language Model, Large Language Model, Pre-trained Language Model, Pre-trained Language Model  
<a type="button" class="btn btn-outline-primary" href="http://arxiv.org/abs/2404.04510v1" target="_blank" >Paper Link</a>
<button type="button" class="btn btn-outline-primary download-pdf" url="https://arxiv.org/pdf/2404.04510v1.pdf" filename="2404.04510v1.pdf">Download PDF</button>

---


**ABSTRACT**  
<b>Large</b> <b>Language</b> <b>models</b> <b>(LLMs)</b> have demonstrated state-of-the-art performance in various <b>natural</b> <b>language</b> <b>processing</b> (NLP) tasks across multiple domains, yet they are prone to shortcut learning and factual inconsistencies. This research investigates <b>LLMs'</b> robustness, consistency, and faithful <b>reasoning</b> when performing <b>Natural</b> <b>Language</b> <b>Inference</b> <b>(NLI)</b> on breast cancer Clinical Trial Reports (CTRs) in the context of SemEval 2024 Task 2: Safe Biomedical <b>Natural</b> <b>Language</b> <b>Inference</b> for Clinical Trials. We examine the <b>reasoning</b> capabilities of <b>LLMs</b> and their adeptness at logical problem-solving. A comparative analysis is conducted on <b>pre-trained</b> <b>language</b> <b>models</b> <b>(PLMs),</b> <b>GPT-3.5,</b> and <b>Gemini</b> Pro under <b>zero-shot</b> settings using <b>Retrieval-Augmented</b> <b>Generation</b> <b>(RAG)</b> framework, integrating various <b>reasoning</b> chains. The evaluation yields an F1 score of 0.69, consistency of 0.71, and a faithfulness score of 0.90 on the test dataset.

{{</citation>}}


### (2/18 | 2/126) Joint Visual and Text Prompting for Improved Object-Centric Perception with Multimodal Large Language Models (Songtao Jiang et al., 2024)

{{<citation>}}

Songtao Jiang, Yan Zhang, Chenyi Zhou, Yeying Jin, Yang Feng, Jian Wu, Zuozhu Liu. (2024)  
**Joint Visual and Text Prompting for Improved Object-Centric Perception with Multimodal Large Language Models**
<br/>
<button class="copy-to-clipboard" title="Joint Visual and Text Prompting for Improved Object-Centric Perception with Multimodal Large Language Models" index=2>
  <span class="copy-to-clipboard-item">Copy Title<span>
</button>
<div class="toast toast-copied toast-index-2 align-items-center text-bg-secondary border-0 position-absolute top-0 end-0" role="alert" aria-live="assertive" aria-atomic="true">
  <div class="d-flex">
    <div class="toast-body">
      Copied!
    </div>
  </div>
</div>

---
Primary Category: cs.CL  
Categories: cs-CL, cs.CL  
Keyword Score: 79  
Keywords: Benchmarking, Multi-modal, Multi-modal, GPT, Gemini, Question Answering, Visual Question Answering, Visual Question Answering, Large Language Model, Prompt  
<a type="button" class="btn btn-outline-primary" href="http://arxiv.org/abs/2404.04514v1" target="_blank" >Paper Link</a>
<button type="button" class="btn btn-outline-primary download-pdf" url="https://arxiv.org/pdf/2404.04514v1.pdf" filename="2404.04514v1.pdf">Download PDF</button>

---


**ABSTRACT**  
<b>Multimodal</b> <b>Large</b> <b>Language</b> <b>Models</b> (MLLMs) such as <b>GPT-4V</b> and <b>Gemini</b> Pro face challenges in achieving human-level perception in <b>Visual</b> <b>Question</b> <b>Answering</b> <b>(VQA),</b> particularly in object-oriented perception tasks which demand fine-grained understanding of object identities, locations or attributes, as indicated by empirical findings. This is mainly due to their limited capability to effectively integrate complex <b>visual</b> <b>cues</b> <b>with</b> textual information and potential object hallucinations. In this paper, we present a novel approach, Joint <b>Visual</b> <b>and</b> <b>Text</b> <b>Prompting</b> (VTPrompt), that employs fine-grained <b>visual</b> <b>information</b> <b>to</b> enhance the capability of MLLMs in <b>VQA,</b> especially for object-oriented perception. VTPrompt merges <b>visual</b> <b>and</b> <b>text</b> <b>prompts</b> to extract key concepts from textual <b>questions</b> <b>and</b> employs a detection model to highlight relevant objects as <b>visual</b> <b>prompts</b> <b>in</b> images. The processed images alongside text <b>prompts</b> are subsequently fed into MLLMs to produce more accurate answers. Our experiments with <b>GPT-4V</b> and <b>Gemini</b> Pro, on three <b>benchmarks,</b> i.e., MME , MMB and POPE, demonstrate significant improvements. Particularly, our method led to a score improvement of up to 183.5 for <b>GPT-4V</b> on MME and enhanced MMB performance by 8.17\% for <b>GPT-4V</b> and 15.69\% for <b>Gemini</b> Pro.

{{</citation>}}


### (3/18 | 3/126) A Morphology-Based Investigation of Positional Encodings (Poulami Ghosh et al., 2024)

{{<citation>}}

Poulami Ghosh, Shikhar Vashishth, Raj Dabre, Pushpak Bhattacharyya. (2024)  
**A Morphology-Based Investigation of Positional Encodings**
<br/>
<button class="copy-to-clipboard" title="A Morphology-Based Investigation of Positional Encodings" index=3>
  <span class="copy-to-clipboard-item">Copy Title<span>
</button>
<div class="toast toast-copied toast-index-3 align-items-center text-bg-secondary border-0 position-absolute top-0 end-0" role="alert" aria-live="assertive" aria-atomic="true">
  <div class="d-flex">
    <div class="toast-body">
      Copied!
    </div>
  </div>
</div>

---
Primary Category: cs.CL  
Categories: cs-CL, cs.CL  
Keyword Score: 73  
Keywords: Clustering, Fine-tuning, BERT, Dependency Parsing, Named Entity Recognition, Natural Language Inference, Pre-trained Language Model, Pre-trained Language Model  
<a type="button" class="btn btn-outline-primary" href="http://arxiv.org/abs/2404.04530v1" target="_blank" >Paper Link</a>
<button type="button" class="btn btn-outline-primary download-pdf" url="https://arxiv.org/pdf/2404.04530v1.pdf" filename="2404.04530v1.pdf">Download PDF</button>

---


**ABSTRACT**  
How does the importance of positional encoding in <b>pre-trained</b> <b>language</b> <b>models</b> <b>(PLMs)</b> vary across languages with different morphological complexity? In this paper, we offer the first study addressing this question, encompassing 23 morphologically diverse languages and 5 different downstream tasks. We choose two categories of tasks: syntactic tasks (part-of-speech tagging, <b>named</b> <b>entity</b> <b>recognition,</b> <b>dependency</b> <b>parsing)</b> and semantic tasks <b>(natural</b> <b>language</b> <b>inference,</b> paraphrasing). We consider language-specific <b>BERT</b> models trained on monolingual corpus for our investigation. The main experiment consists of nullifying the effect of positional encoding during <b>fine-tuning</b> and investigating its impact across various tasks and languages. Our findings demonstrate that the significance of positional encoding diminishes as the morphological complexity of a language increases. Across all experiments, we observe <b>clustering</b> of languages according to their morphological typology - with analytic languages at one end and synthetic languages at the opposite end.

{{</citation>}}


### (4/18 | 4/126) IITK at SemEval-2024 Task 1: Contrastive Learning and Autoencoders for Semantic Textual Relatedness in Multilingual Texts (Udvas Basak et al., 2024)

{{<citation>}}

Udvas Basak, Rajarshi Dutta, Shivam Pandey, Ashutosh Modi. (2024)  
**IITK at SemEval-2024 Task 1: Contrastive Learning and Autoencoders for Semantic Textual Relatedness in Multilingual Texts**
<br/>
<button class="copy-to-clipboard" title="IITK at SemEval-2024 Task 1: Contrastive Learning and Autoencoders for Semantic Textual Relatedness in Multilingual Texts" index=4>
  <span class="copy-to-clipboard-item">Copy Title<span>
</button>
<div class="toast toast-copied toast-index-4 align-items-center text-bg-secondary border-0 position-absolute top-0 end-0" role="alert" aria-live="assertive" aria-atomic="true">
  <div class="d-flex">
    <div class="toast-body">
      Copied!
    </div>
  </div>
</div>

---
Primary Category: cs.CL  
Categories: cs-AI, cs-CL, cs-LG, cs.CL  
Keyword Score: 70  
Keywords: Autoencoder, Contrastive Learning, Low-Resource, Supervised Learning, Unsupervised Learning, BERT, Word Embedding  
<a type="button" class="btn btn-outline-primary" href="http://arxiv.org/abs/2404.04513v1" target="_blank" >Paper Link</a>
<button type="button" class="btn btn-outline-primary download-pdf" url="https://arxiv.org/pdf/2404.04513v1.pdf" filename="2404.04513v1.pdf">Download PDF</button>

---


**ABSTRACT**  
This paper describes our system developed for the SemEval-2024 Task 1: Semantic Textual Relatedness. The challenge is focused on automatically detecting the degree of relatedness between pairs of sentences for 14 languages including both high and <b>low-resource</b> Asian and African languages. Our team participated in two subtasks consisting of Track A: <b>supervised</b> and Track B: <b>unsupervised.</b> This paper focuses on a <b>BERT-based</b> <b>contrastive</b> <b>learning</b> and similarity metric based approach primarily for the <b>supervised</b> track while exploring <b>autoencoders</b> for the <b>unsupervised</b> track. It also aims on the creation of a bigram relatedness corpus using negative sampling strategy, thereby producing refined <b>word</b> <b>embeddings.</b>

{{</citation>}}


### (5/18 | 5/126) What Happens When Small Is Made Smaller? Exploring the Impact of Compression on Small Data Pretrained Language Models (Busayo Awobade et al., 2024)

{{<citation>}}

Busayo Awobade, Mardiyyah Oduwole, Steven Kolawole. (2024)  
**What Happens When Small Is Made Smaller? Exploring the Impact of Compression on Small Data Pretrained Language Models**
<br/>
<button class="copy-to-clipboard" title="What Happens When Small Is Made Smaller? Exploring the Impact of Compression on Small Data Pretrained Language Models" index=5>
  <span class="copy-to-clipboard-item">Copy Title<span>
</button>
<div class="toast toast-copied toast-index-5 align-items-center text-bg-secondary border-0 position-absolute top-0 end-0" role="alert" aria-live="assertive" aria-atomic="true">
  <div class="d-flex">
    <div class="toast-body">
      Copied!
    </div>
  </div>
</div>

---
Primary Category: cs.CL  
Categories: cs-CL, cs-LG, cs.CL  
Keyword Score: 60  
Keywords: Knowledge Distillation, Knowledge Distillation, Low-Resource, Pruning, Quantization, Pre-trained Language Model  
<a type="button" class="btn btn-outline-primary" href="http://arxiv.org/abs/2404.04759v1" target="_blank" >Paper Link</a>
<button type="button" class="btn btn-outline-primary download-pdf" url="https://arxiv.org/pdf/2404.04759v1.pdf" filename="2404.04759v1.pdf">Download PDF</button>

---


**ABSTRACT**  
Compression techniques have been crucial in advancing machine learning by enabling efficient training and deployment of large-scale language models. However, these techniques have received limited attention in the context of <b>low-resource</b> language models, which are trained on even smaller amounts of data and under computational constraints, a scenario known as the <b>"low-resource</b> double-bind." This paper investigates the effectiveness of <b>pruning,</b> <b>knowledge</b> <b>distillation,</b> and <b>quantization</b> on an exclusively <b>low-resourced,</b> small-data language model, AfriBERTa. Through a battery of experiments, we assess the effects of compression on performance across several metrics beyond accuracy. Our study provides evidence that compression techniques significantly improve the efficiency and effectiveness of small-data language models, confirming that the prevailing beliefs regarding the effects of compression on large, heavily parameterized models hold true for less-parameterized, small-data models.

{{</citation>}}


### (6/18 | 6/126) KazQAD: Kazakh Open-Domain Question Answering Dataset (Rustem Yeshpanov et al., 2024)

{{<citation>}}

Rustem Yeshpanov, Pavel Efimov, Leonid Boytsov, Ardak Shalkarbayuli, Pavel Braslavski. (2024)  
**KazQAD: Kazakh Open-Domain Question Answering Dataset**
<br/>
<button class="copy-to-clipboard" title="KazQAD: Kazakh Open-Domain Question Answering Dataset" index=6>
  <span class="copy-to-clipboard-item">Copy Title<span>
</button>
<div class="toast toast-copied toast-index-6 align-items-center text-bg-secondary border-0 position-absolute top-0 end-0" role="alert" aria-live="assertive" aria-atomic="true">
  <div class="d-flex">
    <div class="toast-body">
      Copied!
    </div>
  </div>
</div>

---
Primary Category: cs.CL  
Categories: cs-CL, cs.CL  
Keyword Score: 60  
Keywords: Information Retrieval, Neural Machine Translation, Open-Domain Question Answering, Open-Domain Question Answering, Question Answering, Question Answering  
<a type="button" class="btn btn-outline-primary" href="http://arxiv.org/abs/2404.04487v1" target="_blank" >Paper Link</a>
<button type="button" class="btn btn-outline-primary download-pdf" url="https://arxiv.org/pdf/2404.04487v1.pdf" filename="2404.04487v1.pdf">Download PDF</button>

---


**ABSTRACT**  
We introduce KazQAD -- a Kazakh <b>open-domain</b> <b>question</b> <b>answering</b> <b>(ODQA)</b> dataset -- that can be used in both reading comprehension and full <b>ODQA</b> settings, as well as for <b>information</b> <b>retrieval</b> experiments. KazQAD contains just under 6,000 unique <b>questions</b> <b>with</b> extracted short answers and nearly 12,000 passage-level relevance judgements. We use a combination of <b>machine</b> <b>translation,</b> Wikipedia search, and in-house manual annotation to ensure annotation efficiency and data quality. The <b>questions</b> <b>come</b> from two sources: translated items from the Natural <b>Questions</b> <b>(NQ)</b> dataset (only for training) and the original Kazakh Unified National Testing (UNT) exam (for development and testing). The accompanying text corpus contains more than 800,000 passages from the Kazakh Wikipedia. As a supplementary dataset, we release around 61,000 <b>question-passage-answer</b> <b>triples</b> from the NQ dataset that have been <b>machine-translated</b> <b>into</b> Kazakh. We develop baseline retrievers and readers that achieve reasonable scores in retrieval (NDCG@10 = 0.389 MRR = 0.382), reading comprehension (EM = 38.5 F1 = 54.2), and full <b>ODQA</b> (EM = 17.8 F1 = 28.7) settings. Nevertheless, these results are substantially lower than state-of-the-art results for English <b>QA</b> collections, and we think that there should still be ample room for improvement. We also show that the current OpenAI's ChatGPTv3.5 is not able to answer KazQAD test <b>questions</b> <b>in</b> the closed-book setting with acceptable quality. The dataset is freely available under the Creative Commons licence (CC BY-SA) at https://github.com/IS2AI/KazQAD.

{{</citation>}}


### (7/18 | 7/126) Multilingual Brain Surgeon: Large Language Models Can be Compressed Leaving No Language Behind (Hongchuan Zeng et al., 2024)

{{<citation>}}

Hongchuan Zeng, Hongshen Xu, Lu Chen, Kai Yu. (2024)  
**Multilingual Brain Surgeon: Large Language Models Can be Compressed Leaving No Language Behind**
<br/>
<button class="copy-to-clipboard" title="Multilingual Brain Surgeon: Large Language Models Can be Compressed Leaving No Language Behind" index=7>
  <span class="copy-to-clipboard-item">Copy Title<span>
</button>
<div class="toast toast-copied toast-index-7 align-items-center text-bg-secondary border-0 position-absolute top-0 end-0" role="alert" aria-live="assertive" aria-atomic="true">
  <div class="d-flex">
    <div class="toast-body">
      Copied!
    </div>
  </div>
</div>

---
Primary Category: cs.CL  
Categories: cs-CL, cs.CL  
Keyword Score: 50  
Keywords: Low-Resource, Model Compression, BLOOM, Large Language Model, Large Language Model  
<a type="button" class="btn btn-outline-primary" href="http://arxiv.org/abs/2404.04748v1" target="_blank" >Paper Link</a>
<button type="button" class="btn btn-outline-primary download-pdf" url="https://arxiv.org/pdf/2404.04748v1.pdf" filename="2404.04748v1.pdf">Download PDF</button>

---


**ABSTRACT**  
<b>Large</b> <b>Language</b> <b>Models</b> <b>(LLMs)</b> have ushered in a new era in Natural Language Processing, but their massive size demands effective compression techniques for practicality. Although numerous <b>model</b> <b>compression</b> techniques have been investigated, they typically rely on a calibration set that overlooks the multilingual context and results in significant accuracy degradation for <b>low-resource</b> languages. This paper introduces Multilingual Brain Surgeon (MBS), a novel calibration data sampling method for multilingual <b>LLMs</b> compression. MBS overcomes the English-centric limitations of existing methods by sampling calibration data from various languages proportionally to the language distribution of the <b>model</b> <b>training</b> datasets. Our experiments, conducted on the <b>BLOOM</b> multilingual <b>LLM,</b> demonstrate that MBS improves the performance of existing English-centric compression methods, especially for <b>low-resource</b> languages. We also uncover the dynamics of language interaction during compression, revealing that the larger the proportion of a language in the training set and the more similar the language is to the calibration language, the better performance the language retains after compression. In conclusion, MBS presents an innovative approach to compressing multilingual <b>LLMs,</b> addressing the performance disparities and improving the language inclusivity of existing compression techniques.

{{</citation>}}


### (8/18 | 8/126) HyperTTS: Parameter Efficient Adaptation in Text to Speech using Hypernetworks (Yingting Li et al., 2024)

{{<citation>}}

Yingting Li, Rishabh Bhardwaj, Ambuj Mehrish, Bo Cheng, Soujanya Poria. (2024)  
**HyperTTS: Parameter Efficient Adaptation in Text to Speech using Hypernetworks**
<br/>
<button class="copy-to-clipboard" title="HyperTTS: Parameter Efficient Adaptation in Text to Speech using Hypernetworks" index=8>
  <span class="copy-to-clipboard-item">Copy Title<span>
</button>
<div class="toast toast-copied toast-index-8 align-items-center text-bg-secondary border-0 position-absolute top-0 end-0" role="alert" aria-live="assertive" aria-atomic="true">
  <div class="d-flex">
    <div class="toast-body">
      Copied!
    </div>
  </div>
</div>

---
Primary Category: cs.CL  
Categories: cs-CL, cs-LG, cs-SD, cs.CL, eess-AS  
Keyword Score: 50  
Keywords: Fine-tuning, Out-of-domain, Text-to-speech, Text-to-speech, Domain Adaptation  
<a type="button" class="btn btn-outline-primary" href="http://arxiv.org/abs/2404.04645v1" target="_blank" >Paper Link</a>
<button type="button" class="btn btn-outline-primary download-pdf" url="https://arxiv.org/pdf/2404.04645v1.pdf" filename="2404.04645v1.pdf">Download PDF</button>

---


**ABSTRACT**  
Neural speech synthesis, or <b>text-to-speech</b> <b>(TTS),</b> aims to transform a signal from the text <b>domain</b> <b>to</b> the speech <b>domain.</b> <b>While</b> developing <b>TTS</b> architectures that train and test on the same set of speakers has seen significant improvements, <b>out-of-domain</b> speaker performance still faces enormous limitations. <b>Domain</b> <b>adaptation</b> on a new set of speakers can be achieved by <b>fine-tuning</b> the whole model for each new <b>domain,</b> <b>thus</b> making it parameter-inefficient. This problem can be solved by Adapters that provide a parameter-efficient alternative to <b>domain</b> <b>adaptation.</b> Although famous in NLP, speech synthesis has not seen much improvement from Adapters. In this work, we present HyperTTS, which comprises a small learnable network, "hypernetwork", that generates parameters of the Adapter blocks, allowing us to condition Adapters on speaker representations and making them dynamic. Extensive evaluations of two <b>domain</b> <b>adaptation</b> settings demonstrate its effectiveness in achieving state-of-the-art performance in the parameter-efficient regime. We also compare different variants of HyperTTS, comparing them with baselines in different studies. Promising results on the dynamic adaptation of adapter parameters using hypernetworks open up new avenues for <b>domain-generic</b> <b>multi-speaker</b> <b>TTS</b> systems. The audio samples and code are available at https://github.com/declare-lab/HyperTTS.

{{</citation>}}


### (9/18 | 9/126) Q-PEFT: Query-dependent Parameter Efficient Fine-tuning for Text Reranking with Large Language Models (Zhiyuan Peng et al., 2024)

{{<citation>}}

Zhiyuan Peng, Xuyang Wu, Qifan Wang, Sravanthi Rajanala, Yi Fang. (2024)  
**Q-PEFT: Query-dependent Parameter Efficient Fine-tuning for Text Reranking with Large Language Models**
<br/>
<button class="copy-to-clipboard" title="Q-PEFT: Query-dependent Parameter Efficient Fine-tuning for Text Reranking with Large Language Models" index=9>
  <span class="copy-to-clipboard-item">Copy Title<span>
</button>
<div class="toast toast-copied toast-index-9 align-items-center text-bg-secondary border-0 position-absolute top-0 end-0" role="alert" aria-live="assertive" aria-atomic="true">
  <div class="d-flex">
    <div class="toast-body">
      Copied!
    </div>
  </div>
</div>

---
Primary Category: cs.CL  
Categories: cs-AI, cs-CL, cs-IR, cs-LG, cs.CL  
Keyword Score: 50  
Keywords: Fine-tuning, Rerank, Large Language Model, Large Language Model, Prompt  
<a type="button" class="btn btn-outline-primary" href="http://arxiv.org/abs/2404.04522v1" target="_blank" >Paper Link</a>
<button type="button" class="btn btn-outline-primary download-pdf" url="https://arxiv.org/pdf/2404.04522v1.pdf" filename="2404.04522v1.pdf">Download PDF</button>

---


**ABSTRACT**  
Parameter Efficient <b>Fine-Tuning</b> (PEFT) methods have been extensively utilized in <b>Large</b> <b>Language</b> <b>Models</b> <b>(LLMs)</b> to improve the down-streaming tasks without the cost of fine-tuing the whole <b>LLMs.</b> Recent studies have shown how to effectively use PEFT for <b>fine-tuning</b> <b>LLMs</b> in ranking tasks with convincing performance; there are some limitations, including the learned <b>prompt</b> being fixed for different documents, overfitting to specific tasks, and low adaptation ability. In this paper, we introduce a query-dependent parameter efficient <b>fine-tuning</b> (Q-PEFT) approach for text <b>reranking</b> to leak the information of the true queries to <b>LLMs</b> and then make the generation of true queries from input documents much easier. Specifically, we utilize the query to extract the top-$k$ tokens from concatenated documents, serving as contextual clues. We further augment Q-PEFT by substituting the retrieval mechanism with a multi-head attention layer to achieve end-to-end training and cover all the tokens in the documents, guiding the <b>LLMs</b> to generate more document-specific synthetic queries, thereby further improving the <b>reranking</b> performance. Extensive experiments are conducted on four public datasets, demonstrating the effectiveness of our proposed approach.

{{</citation>}}


### (10/18 | 10/126) Inferring the Phylogeny of Large Language Models and Predicting their Performances in Benchmarks (Nicolas Yax et al., 2024)

{{<citation>}}

Nicolas Yax, Pierre-Yves Oudeyer, Stefano Palminteri. (2024)  
**Inferring the Phylogeny of Large Language Models and Predicting their Performances in Benchmarks**
<br/>
<button class="copy-to-clipboard" title="Inferring the Phylogeny of Large Language Models and Predicting their Performances in Benchmarks" index=10>
  <span class="copy-to-clipboard-item">Copy Title<span>
</button>
<div class="toast toast-copied toast-index-10 align-items-center text-bg-secondary border-0 position-absolute top-0 end-0" role="alert" aria-live="assertive" aria-atomic="true">
  <div class="d-flex">
    <div class="toast-body">
      Copied!
    </div>
  </div>
</div>

---
Primary Category: cs.CL  
Categories: cs-CL, cs-LG, cs.CL, q-bio-PE  
Keyword Score: 43  
Keywords: Benchmarking, Fine-tuning, Massive Multitask Language Understanding (MMLU), Large Language Model, Large Language Model  
<a type="button" class="btn btn-outline-primary" href="http://arxiv.org/abs/2404.04671v1" target="_blank" >Paper Link</a>
<button type="button" class="btn btn-outline-primary download-pdf" url="https://arxiv.org/pdf/2404.04671v1.pdf" filename="2404.04671v1.pdf">Download PDF</button>

---


**ABSTRACT**  
This paper introduces PhyloLM, a method applying phylogenetic algorithms to <b>Large</b> <b>Language</b> <b>Models</b> to explore their <b>finetuning</b> relationships, and predict their performance characteristics. By leveraging the phylogenetic distance metric, we construct dendrograms, which satisfactorily capture distinct <b>LLM</b> families (across a set of 77 open-source and 22 closed models). Furthermore, phylogenetic distance predicts performances in <b>benchmarks</b> (we test <b>MMLU</b> and ARC), thus enabling a time and cost-effective estimation of <b>LLM</b> capabilities. The approach translates genetic concepts to machine learning, offering tools to infer <b>LLM</b> development, relationships, and capabilities, even in the absence of transparent training information.

{{</citation>}}


### (11/18 | 11/126) PoLLMgraph: Unraveling Hallucinations in Large Language Models via State Transition Dynamics (Derui Zhu et al., 2024)

{{<citation>}}

Derui Zhu, Dingfan Chen, Qing Li, Zongxiong Chen, Lei Ma, Jens Grossklags, Mario Fritz. (2024)  
**PoLLMgraph: Unraveling Hallucinations in Large Language Models via State Transition Dynamics**
<br/>
<button class="copy-to-clipboard" title="PoLLMgraph: Unraveling Hallucinations in Large Language Models via State Transition Dynamics" index=11>
  <span class="copy-to-clipboard-item">Copy Title<span>
</button>
<div class="toast toast-copied toast-index-11 align-items-center text-bg-secondary border-0 position-absolute top-0 end-0" role="alert" aria-live="assertive" aria-atomic="true">
  <div class="d-flex">
    <div class="toast-body">
      Copied!
    </div>
  </div>
</div>

---
Primary Category: cs.CL  
Categories: cs-CL, cs-CR, cs-SE, cs.CL  
Keyword Score: 41  
Keywords: Benchmarking, Benchmarking, Black Box, Probabilistic Model, Large Language Model, Large Language Model  
<a type="button" class="btn btn-outline-primary" href="http://arxiv.org/abs/2404.04722v1" target="_blank" >Paper Link</a>
<button type="button" class="btn btn-outline-primary download-pdf" url="https://arxiv.org/pdf/2404.04722v1.pdf" filename="2404.04722v1.pdf">Download PDF</button>

---


**ABSTRACT**  
Despite tremendous advancements in <b>large</b> <b>language</b> <b>models</b> <b>(LLMs)</b> over recent years, a notably urgent challenge for their practical deployment is the phenomenon of hallucination, where the model fabricates facts and produces non-factual statements. In response, we propose PoLLMgraph, a Polygraph for <b>LLMs,</b> as an effective model-based white-box detection and forecasting approach. PoLLMgraph distinctly differs from the <b>large</b> <b>body</b> <b>of</b> existing research that concentrates on addressing such challenges through <b>black-box</b> <b>evaluations.</b> In particular, we demonstrate that hallucination can be effectively detected by analyzing the <b>LLM's</b> internal state transition dynamics during generation via tractable <b>probabilistic</b> <b>models.</b> Experimental results on various open-source <b>LLMs</b> confirm the efficacy of PoLLMgraph, outperforming state-of-the-art methods by a considerable margin, evidenced by over 20% improvement in AUC-ROC on common <b>benchmarking</b> datasets like TruthfulQA. Our work paves a new way for model-based white-box analysis of <b>LLMs,</b> motivating the research community to further explore, understand, and refine the intricate dynamics of <b>LLM</b> behaviors.

{{</citation>}}


### (12/18 | 12/126) On the Limitations of Large Language Models (LLMs): False Attribution (Tosin Adewumi et al., 2024)

{{<citation>}}

Tosin Adewumi, Nudrat Habib, Lama Alkhaled, Elisa Barney. (2024)  
**On the Limitations of Large Language Models (LLMs): False Attribution**
<br/>
<button class="copy-to-clipboard" title="On the Limitations of Large Language Models (LLMs): False Attribution" index=12>
  <span class="copy-to-clipboard-item">Copy Title<span>
</button>
<div class="toast toast-copied toast-index-12 align-items-center text-bg-secondary border-0 position-absolute top-0 end-0" role="alert" aria-live="assertive" aria-atomic="true">
  <div class="d-flex">
    <div class="toast-body">
      Copied!
    </div>
  </div>
</div>

---
Primary Category: cs.CL  
Categories: cs-CL, cs.CL  
Keyword Score: 40  
Keywords: Zero-shot, LLaMA, Large Language Model, Large Language Model  
<a type="button" class="btn btn-outline-primary" href="http://arxiv.org/abs/2404.04631v1" target="_blank" >Paper Link</a>
<button type="button" class="btn btn-outline-primary download-pdf" url="https://arxiv.org/pdf/2404.04631v1.pdf" filename="2404.04631v1.pdf">Download PDF</button>

---


**ABSTRACT**  
In this work, we provide insight into one important limitation of <b>large</b> <b>language</b> <b>models</b> <b>(LLMs),</b> i.e. false attribution, and introduce a new hallucination metric - Simple Hallucination Index (SHI). The task of automatic author attribution for relatively small chunks of text is an important NLP task but can be challenging. We empirically evaluate the power of 3 open SotA <b>LLMs</b> in <b>zero-shot</b> setting <b>(LLaMA-2-13B,</b> Mixtral 8x7B, and Gemma-7B), especially as human annotation can be costly. We collected the top 10 most popular books, according to Project Gutenberg, divided each one into equal chunks of 400 words, and asked each <b>LLM</b> to predict the author. We then randomly sampled 162 chunks for human evaluation from each of the annotated books, based on the error margin of 7% and a confidence level of 95% for the book with the most chunks (Great Expectations by Charles Dickens, having 922 chunks). The average results show that Mixtral 8x7B has the highest prediction accuracy, the lowest SHI, and a Pearson's correlation (r) of 0.737, 0.249, and -0.9996, respectively, followed by <b>LLaMA-2-13B</b> and Gemma-7B. However, Mixtral 8x7B suffers from high hallucinations for 3 books, rising as high as an SHI of 0.87 (in the range 0-1, where 1 is the worst). The strong negative correlation of accuracy and SHI, given by r, demonstrates the fidelity of the new hallucination metric, which is generalizable to other tasks. We publicly release the annotated chunks of data and our codes to aid the reproducibility and evaluation of other models.

{{</citation>}}


### (13/18 | 13/126) Order-Based Pre-training Strategies for Procedural Text Understanding (Abhilash Nandy et al., 2024)

{{<citation>}}

Abhilash Nandy, Yash Kulkarni, Pawan Goyal, Niloy Ganguly. (2024)  
**Order-Based Pre-training Strategies for Procedural Text Understanding**
<br/>
<button class="copy-to-clipboard" title="Order-Based Pre-training Strategies for Procedural Text Understanding" index=13>
  <span class="copy-to-clipboard-item">Copy Title<span>
</button>
<div class="toast toast-copied toast-index-13 align-items-center text-bg-secondary border-0 position-absolute top-0 end-0" role="alert" aria-live="assertive" aria-atomic="true">
  <div class="d-flex">
    <div class="toast-body">
      Copied!
    </div>
  </div>
</div>

---
Primary Category: cs.CL  
Categories: cs-CL, cs.CL  
Keyword Score: 30  
Keywords: Transformer, Large Language Model, Text Understanding  
<a type="button" class="btn btn-outline-primary" href="http://arxiv.org/abs/2404.04676v1" target="_blank" >Paper Link</a>
<button type="button" class="btn btn-outline-primary download-pdf" url="https://arxiv.org/pdf/2404.04676v1.pdf" filename="2404.04676v1.pdf">Download PDF</button>

---


**ABSTRACT**  
In this paper, we propose sequence-based pretraining methods to enhance procedural understanding in natural language processing. Procedural <b>text,</b> <b>containing</b> sequential instructions to accomplish a task, is difficult to understand due to the changing attributes of entities in the context. We focus on recipes, which are commonly represented as ordered instructions, and use this order as a supervision signal. Our work is one of the first to compare several 'order as-supervision' <b>transformer</b> pre-training methods, including Permutation Classification, Embedding Regression, and Skip-Clip, and shows that these methods give improved results compared to the baselines and SoTA <b>LLMs</b> on two downstream Entity-Tracking datasets: NPN-Cooking dataset in recipe domain and ProPara dataset in open domain. Our proposed methods address the non-trivial Entity Tracking Task that requires prediction of entity states across procedure steps, which requires understanding the order of steps. These methods show an improvement over the best baseline by 1.6% and 7-9% on NPN-Cooking and ProPara Datasets respectively across metrics.

{{</citation>}}


### (14/18 | 14/126) Multilingual Pretraining and Instruction Tuning Improve Cross-Lingual Knowledge Alignment, But Only Shallowly (Changjiang Gao et al., 2024)

{{<citation>}}

Changjiang Gao, Hongda Hu, Peng Hu, Jiajun Chen, Jixing Li, Shujian Huang. (2024)  
**Multilingual Pretraining and Instruction Tuning Improve Cross-Lingual Knowledge Alignment, But Only Shallowly**
<br/>
<button class="copy-to-clipboard" title="Multilingual Pretraining and Instruction Tuning Improve Cross-Lingual Knowledge Alignment, But Only Shallowly" index=14>
  <span class="copy-to-clipboard-item">Copy Title<span>
</button>
<div class="toast toast-copied toast-index-14 align-items-center text-bg-secondary border-0 position-absolute top-0 end-0" role="alert" aria-live="assertive" aria-atomic="true">
  <div class="d-flex">
    <div class="toast-body">
      Copied!
    </div>
  </div>
</div>

---
Primary Category: cs.CL  
Categories: cs-CL, cs.CL  
Keyword Score: 30  
Keywords: Instruction Tuning, Large Language Model, Large Language Model  
<a type="button" class="btn btn-outline-primary" href="http://arxiv.org/abs/2404.04659v1" target="_blank" >Paper Link</a>
<button type="button" class="btn btn-outline-primary download-pdf" url="https://arxiv.org/pdf/2404.04659v1.pdf" filename="2404.04659v1.pdf">Download PDF</button>

---


**ABSTRACT**  
Despite their strong ability to retrieve knowledge in English, current <b>large</b> <b>language</b> <b>models</b> show imbalance abilities in different languages. Two approaches are proposed to address this, i.e., multilingual pretraining and multilingual <b>instruction</b> <b>tuning.</b> However, whether and how do such methods contribute to the cross-lingual knowledge alignment inside the models is unknown. In this paper, we propose CLiKA, a systematic framework to assess the cross-lingual knowledge alignment of <b>LLMs</b> in the Performance, Consistency and Conductivity levels, and explored the effect of multilingual pretraining and <b>instruction</b> <b>tuning</b> on the degree of alignment. Results show that: while both multilingual pretraining and <b>instruction</b> <b>tuning</b> are beneficial for cross-lingual knowledge alignment, the training strategy needs to be carefully designed. Namely, continued pretraining improves the alignment of the target language at the cost of other languages, while mixed pretraining affect other languages less. Also, the overall cross-lingual knowledge alignment, especially in the conductivity level, is unsatisfactory for all tested <b>LLMs,</b> and neither multilingual pretraining nor <b>instruction</b> <b>tuning</b> can substantially improve the cross-lingual knowledge conductivity.

{{</citation>}}


### (15/18 | 15/126) Towards Analyzing and Understanding the Limitations of DPO: A Theoretical Perspective (Duanyu Feng et al., 2024)

{{<citation>}}

Duanyu Feng, Bowen Qin, Chen Huang, Zheng Zhang, Wenqiang Lei. (2024)  
**Towards Analyzing and Understanding the Limitations of DPO: A Theoretical Perspective**
<br/>
<button class="copy-to-clipboard" title="Towards Analyzing and Understanding the Limitations of DPO: A Theoretical Perspective" index=15>
  <span class="copy-to-clipboard-item">Copy Title<span>
</button>
<div class="toast toast-copied toast-index-15 align-items-center text-bg-secondary border-0 position-absolute top-0 end-0" role="alert" aria-live="assertive" aria-atomic="true">
  <div class="d-flex">
    <div class="toast-body">
      Copied!
    </div>
  </div>
</div>

---
Primary Category: cs.CL  
Categories: cs-AI, cs-CL, cs.CL  
Keyword Score: 30  
Keywords: Direct Preference Optimization, Large Language Model, Large Language Model  
<a type="button" class="btn btn-outline-primary" href="http://arxiv.org/abs/2404.04626v1" target="_blank" >Paper Link</a>
<button type="button" class="btn btn-outline-primary download-pdf" url="https://arxiv.org/pdf/2404.04626v1.pdf" filename="2404.04626v1.pdf">Download PDF</button>

---


**ABSTRACT**  
<b>Direct</b> <b>Preference</b> <b>Optimization</b> (DPO), which derives reward signals directly from pairwise preference data, has shown its effectiveness on aligning <b>Large</b> <b>Language</b> <b>Models</b> <b>(LLMs)</b> with human preferences. Despite its widespread use across various tasks, DPO has been criticized for its sensitivity to the SFT's effectiveness and its hindrance to the learning capacity towards human-preferred responses, leading to less satisfactory performance. To overcome those limitations, the theoretical understanding of DPO are indispensable but still lacking. To this end, we take a step towards theoretically analyzing and understanding the limitations of DPO. Specifically, we provide an analytical framework using the field theory to analyze the optimization process of DPO. By analyzing the gradient vector field of the DPO loss function, we find that the DPO loss function decreases the probability of producing human dispreferred data at a faster rate than it increases the probability of producing preferred data. This provides theoretical insights for understanding the limitations of DPO discovered in the related research experiments, thereby setting the foundation for its improvement.

{{</citation>}}


### (16/18 | 16/126) IITK at SemEval-2024 Task 10: Who is the speaker? Improving Emotion Recognition and Flip Reasoning in Conversations via Speaker Embeddings (Shubham Patel et al., 2024)

{{<citation>}}

Shubham Patel, Divyaksh Shukla, Ashutosh Modi. (2024)  
**IITK at SemEval-2024 Task 10: Who is the speaker? Improving Emotion Recognition and Flip Reasoning in Conversations via Speaker Embeddings**
<br/>
<button class="copy-to-clipboard" title="IITK at SemEval-2024 Task 10: Who is the speaker? Improving Emotion Recognition and Flip Reasoning in Conversations via Speaker Embeddings" index=16>
  <span class="copy-to-clipboard-item">Copy Title<span>
</button>
<div class="toast toast-copied toast-index-16 align-items-center text-bg-secondary border-0 position-absolute top-0 end-0" role="alert" aria-live="assertive" aria-atomic="true">
  <div class="d-flex">
    <div class="toast-body">
      Copied!
    </div>
  </div>
</div>

---
Primary Category: cs.CL  
Categories: cs-AI, cs-CL, cs-LG, cs.CL  
Keyword Score: 30  
Keywords: Transformer, Emotion Recognition, Reasoning  
<a type="button" class="btn btn-outline-primary" href="http://arxiv.org/abs/2404.04525v1" target="_blank" >Paper Link</a>
<button type="button" class="btn btn-outline-primary download-pdf" url="https://arxiv.org/pdf/2404.04525v1.pdf" filename="2404.04525v1.pdf">Download PDF</button>

---


**ABSTRACT**  
This paper presents our approach for the SemEval-2024 Task 10: <b>Emotion</b> <b>Discovery</b> and <b>Reasoning</b> its Flip in Conversations. For the <b>Emotion</b> <b>Recognition</b> in Conversations (ERC) task, we utilize a masked-memory network along with speaker participation. We propose a <b>transformer-based</b> speaker-centric model for the <b>Emotion</b> <b>Flip</b> <b>Reasoning</b> (EFR) task. We also introduce Probable Trigger Zone, a region of the conversation that is more likely to contain the utterances causing the <b>emotion</b> <b>to</b> flip. For sub-task 3, the proposed approach achieves a 5.9 (F1 score) improvement over the task baseline. The ablation study results highlight the significance of various design choices in the proposed method.

{{</citation>}}


### (17/18 | 17/126) Context versus Prior Knowledge in Language Models (Kevin Du et al., 2024)

{{<citation>}}

Kevin Du, Vsteinn Snbjarnarson, Niklas Stoehr, Jennifer C. White, Aaron Schein, Ryan Cotterell. (2024)  
**Context versus Prior Knowledge in Language Models**
<br/>
<button class="copy-to-clipboard" title="Context versus Prior Knowledge in Language Models" index=17>
  <span class="copy-to-clipboard-item">Copy Title<span>
</button>
<div class="toast toast-copied toast-index-17 align-items-center text-bg-secondary border-0 position-absolute top-0 end-0" role="alert" aria-live="assertive" aria-atomic="true">
  <div class="d-flex">
    <div class="toast-body">
      Copied!
    </div>
  </div>
</div>

---
Primary Category: cs.CL  
Categories: cs-CL, cs.CL  
Keyword Score: 20  
Keywords: Mutual Information, In-context Learning  
<a type="button" class="btn btn-outline-primary" href="http://arxiv.org/abs/2404.04633v1" target="_blank" >Paper Link</a>
<button type="button" class="btn btn-outline-primary download-pdf" url="https://arxiv.org/pdf/2404.04633v1.pdf" filename="2404.04633v1.pdf">Download PDF</button>

---


**ABSTRACT**  
To answer a question, language models often need to integrate prior knowledge learned during pretraining and new information presented in context. We hypothesize that models perform this integration in a predictable way across different questions and contexts: models will rely more on prior knowledge for questions about entities (e.g., persons, places, etc.) that they are more familiar with due to higher exposure in the training corpus, and be more easily persuaded by some contexts than others. To formalize this problem, we propose two <b>mutual</b> <b>information-based</b> metrics to measure a model's dependency on a context and on its prior about an entity: first, the persuasion score of a given context represents how much a model depends on the context in its decision, and second, the susceptibility score of a given entity represents how much the model can be swayed away from its original answer distribution about an entity. Following well-established measurement modeling methods, we empirically test for the validity and reliability of these metrics. Finally, we explore and find a relationship between the scores and the model's expected familiarity with an entity, and provide two use cases to illustrate their benefits.

{{</citation>}}


### (18/18 | 18/126) Navigating the Landscape of Hint Generation Research: From the Past to the Future (Anubhav Jangra et al., 2024)

{{<citation>}}

Anubhav Jangra, Jamshid Mozafari, Adam Jatowt, Smaranda Muresan. (2024)  
**Navigating the Landscape of Hint Generation Research: From the Past to the Future**
<br/>
<button class="copy-to-clipboard" title="Navigating the Landscape of Hint Generation Research: From the Past to the Future" index=18>
  <span class="copy-to-clipboard-item">Copy Title<span>
</button>
<div class="toast toast-copied toast-index-18 align-items-center text-bg-secondary border-0 position-absolute top-0 end-0" role="alert" aria-live="assertive" aria-atomic="true">
  <div class="d-flex">
    <div class="toast-body">
      Copied!
    </div>
  </div>
</div>

---
Primary Category: cs.CL  
Categories: cs-CL, cs-HC, cs.CL  
Keyword Score: 10  
Keywords: Large Language Model  
<a type="button" class="btn btn-outline-primary" href="http://arxiv.org/abs/2404.04728v1" target="_blank" >Paper Link</a>
<button type="button" class="btn btn-outline-primary download-pdf" url="https://arxiv.org/pdf/2404.04728v1.pdf" filename="2404.04728v1.pdf">Download PDF</button>

---


**ABSTRACT**  
Digital education has gained popularity in the last decade, especially after the COVID-19 pandemic. With the improving capabilities of <b>large</b> <b>language</b> <b>models</b> to reason and communicate with users, envisioning intelligent tutoring systems (ITSs) that can facilitate self-learning is not very far-fetched. One integral component to fulfill this vision is the ability to give accurate and effective feedback via hints to scaffold the learning process. In this survey article, we present a comprehensive review of prior research on hint generation, aiming to bridge the gap between research in education and cognitive science, and research in AI and Natural Language Processing. Informed by our findings, we propose a formal definition of the hint generation task, and discuss the roadmap of building an effective hint generation system aligned with the formal definition, including open challenges, future directions and ethical considerations.

{{</citation>}}


## cs.CV (42)



### (1/42 | 19/126) Self-Training Large Language Models for Improved Visual Program Synthesis With Visual Reinforcement (Zaid Khan et al., 2024)

{{<citation>}}

Zaid Khan, Vijay Kumar BG, Samuel Schulter, Yun Fu, Manmohan Chandraker. (2024)  
**Self-Training Large Language Models for Improved Visual Program Synthesis With Visual Reinforcement**
<br/>
<button class="copy-to-clipboard" title="Self-Training Large Language Models for Improved Visual Program Synthesis With Visual Reinforcement" index=19>
  <span class="copy-to-clipboard-item">Copy Title<span>
</button>
<div class="toast toast-copied toast-index-19 align-items-center text-bg-secondary border-0 position-absolute top-0 end-0" role="alert" aria-live="assertive" aria-atomic="true">
  <div class="d-flex">
    <div class="toast-body">
      Copied!
    </div>
  </div>
</div>

---
Primary Category: cs.CV  
Categories: cs-CV, cs.CV  
Keyword Score: 100  
Keywords: Object Detection, Few-shot, Image2text, Question Answering, Reasoning, Visual Question Answering, Large Language Model, Large Language Model, Prompt, Vision-and-Language  
<a type="button" class="btn btn-outline-primary" href="http://arxiv.org/abs/2404.04627v1" target="_blank" >Paper Link</a>
<button type="button" class="btn btn-outline-primary download-pdf" url="https://arxiv.org/pdf/2404.04627v1.pdf" filename="2404.04627v1.pdf">Download PDF</button>

---


**ABSTRACT**  
<b>Visual</b> <b>program</b> <b>synthesis</b> is a promising approach to exploit the <b>reasoning</b> abilities of <b>large</b> <b>language</b> <b>models</b> for compositional computer vision tasks. Previous work has used <b>few-shot</b> <b>prompting</b> with frozen <b>LLMs</b> to synthesize <b>visual</b> <b>programs.</b> <b>Training</b> an <b>LLM</b> to write better <b>visual</b> <b>programs</b> <b>is</b> an attractive prospect, but it is unclear how to accomplish this. No dataset of <b>visual</b> <b>programs</b> <b>for</b> training exists, and acquisition of a <b>visual</b> <b>program</b> <b>dataset</b> cannot be easily crowdsourced due to the need for expert annotators. To get around the lack of direct supervision, we explore improving the program synthesis abilities of an <b>LLM</b> using feedback from interactive experience. We propose a method where we exploit existing annotations for a <b>vision-language</b> task to improvise a coarse reward signal for that task, treat the <b>LLM</b> as a policy, and apply reinforced self-training to improve the <b>visual</b> <b>program</b> <b>synthesis</b> ability of the <b>LLM</b> for that task. We describe a series of experiments on <b>object</b> <b>detection,</b> compositional <b>visual</b> <b>question</b> <b>answering,</b> and <b>image-text</b> retrieval, and show that in each case, the self-trained <b>LLM</b> outperforms or performs on par with <b>few-shot</b> frozen <b>LLMs</b> that are an order of magnitude larger. Website: https://zaidkhan.me/ViReP

{{</citation>}}


### (2/42 | 20/126) VTR: An Optimized Vision Transformer for SAR ATR Acceleration on FPGA (Sachini Wickramasinghe et al., 2024)

{{<citation>}}

Sachini Wickramasinghe, Dhruv Parikh, Bingyi Zhang, Rajgopal Kannan, Viktor Prasanna, Carl Busart. (2024)  
**VTR: An Optimized Vision Transformer for SAR ATR Acceleration on FPGA**
<br/>
<button class="copy-to-clipboard" title="VTR: An Optimized Vision Transformer for SAR ATR Acceleration on FPGA" index=20>
  <span class="copy-to-clipboard-item">Copy Title<span>
</button>
<div class="toast toast-copied toast-index-20 align-items-center text-bg-secondary border-0 position-absolute top-0 end-0" role="alert" aria-live="assertive" aria-atomic="true">
  <div class="d-flex">
    <div class="toast-body">
      Copied!
    </div>
  </div>
</div>

---
Primary Category: cs.CV  
Categories: cs-AI, cs-AR, cs-CV, cs-DC, cs.CV  
Keyword Score: 60  
Keywords: Vision Transformer, Convolutional Neural Network, Transformer, Tokenization, Self-Attention, Vision Transformer  
<a type="button" class="btn btn-outline-primary" href="http://arxiv.org/abs/2404.04527v1" target="_blank" >Paper Link</a>
<button type="button" class="btn btn-outline-primary download-pdf" url="https://arxiv.org/pdf/2404.04527v1.pdf" filename="2404.04527v1.pdf">Download PDF</button>

---


**ABSTRACT**  
Synthetic Aperture Radar (SAR) Automatic Target Recognition (ATR) is a key technique used in military applications like remote-sensing image recognition. <b>Vision</b> <b>Transformers</b> (ViTs) are the current state-of-the-art in various computer <b>vision</b> <b>applications,</b> outperforming their <b>CNN</b> counterparts. However, using ViTs for SAR ATR applications is challenging due to (1) standard ViTs require extensive training data to generalize well due to their low locality; the standard SAR datasets, however, have a limited number of labeled training data which reduces the learning capability of ViTs; (2) ViTs have a high parameter count and are computation intensive which makes their deployment on resource-constrained SAR platforms difficult. In this work, we develop a lightweight ViT model that can be trained directly on small datasets without any pre-training by utilizing the Shifted Patch <b>Tokenization</b> (SPT) and Locality <b>Self-Attention</b> (LSA) modules. We directly train this model on SAR datasets which have limited training samples to evaluate its effectiveness for SAR ATR applications. We evaluate our proposed model, that we call VTR (ViT for SAR ATR), on three widely used SAR datasets: MSTAR, SynthWakeSAR, and GBSAR. Further, we propose a novel FPGA accelerator for VTR, in order to enable deployment for real-time SAR ATR applications.

{{</citation>}}


### (3/42 | 21/126) Towards Generalized Entropic Sparsification for Convolutional Neural Networks (Tin Barisin et al., 2024)

{{<citation>}}

Tin Barisin, Illia Horenko. (2024)  
**Towards Generalized Entropic Sparsification for Convolutional Neural Networks**
<br/>
<button class="copy-to-clipboard" title="Towards Generalized Entropic Sparsification for Convolutional Neural Networks" index=21>
  <span class="copy-to-clipboard-item">Copy Title<span>
</button>
<div class="toast toast-copied toast-index-21 align-items-center text-bg-secondary border-0 position-absolute top-0 end-0" role="alert" aria-live="assertive" aria-atomic="true">
  <div class="d-flex">
    <div class="toast-body">
      Copied!
    </div>
  </div>
</div>

---
Primary Category: cs.CV  
Categories: cs-CV, cs.CV  
Keyword Score: 53  
Keywords: MNIST, Benchmarking, Convolution, Convolutional Neural Network, Convolutional Neural Network, Pruning  
<a type="button" class="btn btn-outline-primary" href="http://arxiv.org/abs/2404.04734v1" target="_blank" >Paper Link</a>
<button type="button" class="btn btn-outline-primary download-pdf" url="https://arxiv.org/pdf/2404.04734v1.pdf" filename="2404.04734v1.pdf">Download PDF</button>

---


**ABSTRACT**  
<b>Convolutional</b> <b>neural</b> <b>networks</b> <b>(CNNs)</b> are reported to be overparametrized. The search for optimal (minimal) and sufficient architecture is an NP-hard problem as the hyperparameter space for possible network configurations is vast. Here, we introduce a layer-by-layer data-driven <b>pruning</b> method based on the mathematical idea aiming at a computationally-scalable entropic relaxation of the <b>pruning</b> problem. The sparse subnetwork is found from the pre-trained (full) <b>CNN</b> using the network entropy minimization as a sparsity constraint. This allows deploying a numerically scalable algorithm with a sublinear scaling cost. The method is validated on several <b>benchmarks</b> (architectures): (i) <b>MNIST</b> (LeNet) with sparsity 55%-84% and loss in accuracy 0.1%-0.5%, and (ii) CIFAR-10 (VGG-16, ResNet18) with sparsity 73-89% and loss in accuracy 0.1%-0.5%.

{{</citation>}}


### (4/42 | 22/126) Music Recommendation Based on Facial Emotion Recognition (Rajesh B et al., 2024)

{{<citation>}}

Rajesh B, Keerthana V, Narayana Darapaneni, Anwesh Reddy P. (2024)  
**Music Recommendation Based on Facial Emotion Recognition**
<br/>
<button class="copy-to-clipboard" title="Music Recommendation Based on Facial Emotion Recognition" index=22>
  <span class="copy-to-clipboard-item">Copy Title<span>
</button>
<div class="toast toast-copied toast-index-22 align-items-center text-bg-secondary border-0 position-absolute top-0 end-0" role="alert" aria-live="assertive" aria-atomic="true">
  <div class="d-flex">
    <div class="toast-body">
      Copied!
    </div>
  </div>
</div>

---
Primary Category: cs.CV  
Categories: cs-CV, cs-IR, cs.CV  
Keyword Score: 50  
Keywords: Convolution, Explainable AI, Recommendation, Emotion Recognition, Reasoning  
<a type="button" class="btn btn-outline-primary" href="http://arxiv.org/abs/2404.04654v1" target="_blank" >Paper Link</a>
<button type="button" class="btn btn-outline-primary download-pdf" url="https://arxiv.org/pdf/2404.04654v1.pdf" filename="2404.04654v1.pdf">Download PDF</button>

---


**ABSTRACT**  
Introduction: Music provides an incredible avenue for individuals to express their thoughts and <b>emotions,</b> <b>while</b> also serving as a delightful mode of entertainment for enthusiasts and music lovers. Objectives: This paper presents a comprehensive approach to enhancing the user experience through the integration of <b>emotion</b> <b>recognition,</b> music <b>recommendation,</b> and <b>explainable</b> <b>AI</b> using GRAD-CAM. Methods: The proposed methodology utilizes a ResNet50 model trained on the Facial Expression Recognition (FER) dataset, consisting of real images of individuals expressing various <b>emotions.</b> <b>Results:</b> The system achieves an accuracy of 82% in <b>emotion</b> <b>classification.</b> By leveraging GRAD-CAM, the model provides explanations for its predictions, allowing users to understand the <b>reasoning</b> behind the system's <b>recommendations.</b> The model is trained on both FER and real user datasets, which include labelled facial expressions, and real images of individuals expressing various <b>emotions.</b> <b>The</b> training process involves pre-processing the input images, extracting features through <b>convolutional</b> layers, <b>reasoning</b> with dense layers, and generating <b>emotion</b> <b>predictions</b> through the output layer. Conclusion: The proposed methodology, leveraging the Resnet50 model with ROI-based analysis and <b>explainable</b> <b>AI</b> techniques, offers a robust and interpretable solution for facial <b>emotion</b> <b>detection</b> paper.

{{</citation>}}


### (5/42 | 23/126) Aligning Diffusion Models by Optimizing Human Utility (Shufan Li et al., 2024)

{{<citation>}}

Shufan Li, Konstantinos Kallidromitis, Akash Gokul, Yusuke Kato, Kazuki Kozuka. (2024)  
**Aligning Diffusion Models by Optimizing Human Utility**
<br/>
<button class="copy-to-clipboard" title="Aligning Diffusion Models by Optimizing Human Utility" index=23>
  <span class="copy-to-clipboard-item">Copy Title<span>
</button>
<div class="toast toast-copied toast-index-23 align-items-center text-bg-secondary border-0 position-absolute top-0 end-0" role="alert" aria-live="assertive" aria-atomic="true">
  <div class="d-flex">
    <div class="toast-body">
      Copied!
    </div>
  </div>
</div>

---
Primary Category: cs.CV  
Categories: cs-CV, cs.CV  
Keyword Score: 50  
Keywords: Diffusion Model, Automatic Evaluation, Fine-tuning, Supervised Learning, Text2image  
<a type="button" class="btn btn-outline-primary" href="http://arxiv.org/abs/2404.04465v1" target="_blank" >Paper Link</a>
<button type="button" class="btn btn-outline-primary download-pdf" url="https://arxiv.org/pdf/2404.04465v1.pdf" filename="2404.04465v1.pdf">Download PDF</button>

---


**ABSTRACT**  
We present <b>Diffusion-KTO,</b> <b>a</b> novel approach for aligning <b>text-to-image</b> <b>diffusion</b> <b>models</b> by formulating the alignment objective as the maximization of expected human utility. Since this objective applies to each generation independently, <b>Diffusion-KTO</b> <b>does</b> not require collecting costly pairwise preference data nor training a complex reward model. Instead, our objective requires simple per-image binary feedback signals, e.g. likes or dislikes, which are abundantly available. After <b>fine-tuning</b> using <b>Diffusion-KTO,</b> <b>text-to-image</b> <b>diffusion</b> <b>models</b> exhibit superior performance compared to existing techniques, including <b>supervised</b> <b>fine-tuning</b> and <b>Diffusion-DPO,</b> <b>both</b> in terms of human judgment and <b>automatic</b> <b>evaluation</b> metrics such as PickScore and ImageReward. Overall, <b>Diffusion-KTO</b> <b>unlocks</b> the potential of leveraging readily available per-image binary signals and broadens the applicability of aligning <b>text-to-image</b> <b>diffusion</b> <b>models</b> with human preferences.

{{</citation>}}


### (6/42 | 24/126) DifFUSER: Diffusion Model for Robust Multi-Sensor Fusion in 3D Object Detection and BEV Segmentation (Duy-Tho Le et al., 2024)

{{<citation>}}

Duy-Tho Le, Hengcan Shi, Jianfei Cai, Hamid Rezatofighi. (2024)  
**DifFUSER: Diffusion Model for Robust Multi-Sensor Fusion in 3D Object Detection and BEV Segmentation**
<br/>
<button class="copy-to-clipboard" title="DifFUSER: Diffusion Model for Robust Multi-Sensor Fusion in 3D Object Detection and BEV Segmentation" index=24>
  <span class="copy-to-clipboard-item">Copy Title<span>
</button>
<div class="toast toast-copied toast-index-24 align-items-center text-bg-secondary border-0 position-absolute top-0 end-0" role="alert" aria-live="assertive" aria-atomic="true">
  <div class="d-flex">
    <div class="toast-body">
      Copied!
    </div>
  </div>
</div>

---
Primary Category: cs.CV  
Categories: cs-CV, cs.CV  
Keyword Score: 43  
Keywords: Diffusion Model, Object Detection, Graph Attention Networks, Multi-modal, Transformer  
<a type="button" class="btn btn-outline-primary" href="http://arxiv.org/abs/2404.04629v1" target="_blank" >Paper Link</a>
<button type="button" class="btn btn-outline-primary download-pdf" url="https://arxiv.org/pdf/2404.04629v1.pdf" filename="2404.04629v1.pdf">Download PDF</button>

---


**ABSTRACT**  
<b>Diffusion</b> <b>models</b> have recently gained prominence as powerful deep generative models, demonstrating unmatched performance across various domains. However, their potential in multi-sensor fusion remains largely unexplored. In this work, we introduce DifFUSER, a novel approach that leverages <b>diffusion</b> <b>models</b> for <b>multi-modal</b> fusion in 3D <b>object</b> <b>detection</b> and BEV map segmentation. Benefiting from the inherent denoising property of <b>diffusion,</b> <b>DifFUSER</b> is able to refine or even synthesize sensor features in case of sensor malfunction, thereby improving the quality of the fused output. In terms of architecture, our DifFUSER blocks are chained together in a hierarchical BiFPN fashion, termed cMini-BiFPN, offering an alternative architecture for latent <b>diffusion.</b> <b>We</b> further introduce a <b>Gated</b> Self-conditioned Modulated (GSM) latent <b>diffusion</b> <b>module</b> together with a Progressive Sensor Dropout Training (PSDT) paradigm, designed to add stronger conditioning to the <b>diffusion</b> <b>process</b> and robustness to sensor failures. Our extensive evaluations on the Nuscenes dataset reveal that DifFUSER not only achieves state-of-the-art performance with a 69.1% mIOU in BEV map segmentation tasks but also competes effectively with leading <b>transformer-based</b> fusion techniques in 3D <b>object</b> <b>detection.</b>

{{</citation>}}


### (7/42 | 25/126) Frequency Decomposition-Driven Unsupervised Domain Adaptation for Remote Sensing Image Semantic Segmentation (Xianping Ma et al., 2024)

{{<citation>}}

Xianping Ma, Xiaokang Zhang, Xingchen Ding, Man-On Pun, Siwei Ma. (2024)  
**Frequency Decomposition-Driven Unsupervised Domain Adaptation for Remote Sensing Image Semantic Segmentation**
<br/>
<button class="copy-to-clipboard" title="Frequency Decomposition-Driven Unsupervised Domain Adaptation for Remote Sensing Image Semantic Segmentation" index=25>
  <span class="copy-to-clipboard-item">Copy Title<span>
</button>
<div class="toast toast-copied toast-index-25 align-items-center text-bg-secondary border-0 position-absolute top-0 end-0" role="alert" aria-live="assertive" aria-atomic="true">
  <div class="d-flex">
    <div class="toast-body">
      Copied!
    </div>
  </div>
</div>

---
Primary Category: cs.CV  
Categories: cs-CV, cs.CV  
Keyword Score: 43  
Keywords: Benchmarking, Generative Adversarial Network, Unsupervised Learning, Transformer, Domain Adaptation  
<a type="button" class="btn btn-outline-primary" href="http://arxiv.org/abs/2404.04531v1" target="_blank" >Paper Link</a>
<button type="button" class="btn btn-outline-primary download-pdf" url="https://arxiv.org/pdf/2404.04531v1.pdf" filename="2404.04531v1.pdf">Download PDF</button>

---


**ABSTRACT**  
Cross-domain semantic segmentation of remote sensing (RS) imagery based on <b>unsupervised</b> <b>domain</b> <b>adaptation</b> (UDA) techniques has significantly advanced deep-learning applications in the geosciences. Recently, with its ingenious and versatile architecture, the <b>Transformer</b> model has been successfully applied in RS-UDA tasks. However, existing UDA methods mainly focus on <b>domain</b> <b>alignment</b> in the high-level feature space. It is still challenging to retain cross-domain local spatial details and global contextual semantics simultaneously, which is crucial for the RS image semantic segmentation task. To address these problems, we propose novel high/low-frequency decomposition (HLFD) techniques to guide representation alignment in cross-domain semantic segmentation. Specifically, HLFD attempts to decompose the feature maps into high- and low-frequency components before performing the <b>domain</b> <b>alignment</b> in the corresponding subspaces. Secondly, to further facilitate the alignment of decomposed features, we propose a fully global-local <b>generative</b> <b>adversarial</b> <b>network,</b> namely GLGAN, to learn <b>domain-invariant</b> <b>detailed</b> and semantic features across <b>domains</b> <b>by</b> leveraging global-local <b>transformer</b> blocks (GLTBs). By integrating HLFD techniques and the GLGAN, a novel UDA framework called FD-GLGAN is developed to improve the cross-domain transferability and generalization capability of semantic segmentation models. Extensive experiments on two fine-resolution <b>benchmark</b> datasets, namely ISPRS Potsdam and ISPRS Vaihingen, highlight the effectiveness and superiority of the proposed approach as compared to the state-of-the-art UDA methods. The source code for this work will be accessible at https://github.com/sstary/SSRS.

{{</citation>}}


### (8/42 | 26/126) InitNO: Boosting Text-to-Image Diffusion Models via Initial Noise Optimization (Xiefan Guo et al., 2024)

{{<citation>}}

Xiefan Guo, Jinlin Liu, Miaomiao Cui, Jiankai Li, Hongyu Yang, Di Huang. (2024)  
**InitNO: Boosting Text-to-Image Diffusion Models via Initial Noise Optimization**
<br/>
<button class="copy-to-clipboard" title="InitNO: Boosting Text-to-Image Diffusion Models via Initial Noise Optimization" index=26>
  <span class="copy-to-clipboard-item">Copy Title<span>
</button>
<div class="toast toast-copied toast-index-26 align-items-center text-bg-secondary border-0 position-absolute top-0 end-0" role="alert" aria-live="assertive" aria-atomic="true">
  <div class="d-flex">
    <div class="toast-body">
      Copied!
    </div>
  </div>
</div>

---
Primary Category: cs.CV  
Categories: cs-CV, cs.CV  
Keyword Score: 40  
Keywords: Diffusion Model, Text2image, Prompt, Self-Attention  
<a type="button" class="btn btn-outline-primary" href="http://arxiv.org/abs/2404.04650v1" target="_blank" >Paper Link</a>
<button type="button" class="btn btn-outline-primary download-pdf" url="https://arxiv.org/pdf/2404.04650v1.pdf" filename="2404.04650v1.pdf">Download PDF</button>

---


**ABSTRACT**  
Recent strides in the development of <b>diffusion</b> <b>models,</b> exemplified by advancements such as Stable <b>Diffusion,</b> <b>have</b> underscored their remarkable prowess in generating visually compelling images. However, the imperative of achieving a seamless alignment between the generated image and the provided <b>prompt</b> persists as a formidable challenge. This paper traces the root of these difficulties to invalid initial noise, and proposes a solution in the form of Initial Noise Optimization (InitNO), a paradigm that refines this noise. Considering text <b>prompts,</b> not all random noises are effective in synthesizing semantically-faithful images. We design the cross-attention response score and the <b>self-attention</b> conflict score to evaluate the initial noise, bifurcating the initial latent space into valid and invalid sectors. A strategically crafted noise optimization pipeline is developed to guide the initial noise towards valid regions. Our method, validated through rigorous experimentation, shows a commendable proficiency in generating images in strict accordance with text <b>prompts.</b> Our code is available at https://github.com/xiefan-guo/initno.

{{</citation>}}


### (9/42 | 27/126) Enhancing Video Summarization with Context Awareness (Hai-Dang Huynh-Lam et al., 2024)

{{<citation>}}

Hai-Dang Huynh-Lam, Ngoc-Phuong Ho-Thi, Minh-Triet Tran, Trung-Nghia Le. (2024)  
**Enhancing Video Summarization with Context Awareness**
<br/>
<button class="copy-to-clipboard" title="Enhancing Video Summarization with Context Awareness" index=27>
  <span class="copy-to-clipboard-item">Copy Title<span>
</button>
<div class="toast toast-copied toast-index-27 align-items-center text-bg-secondary border-0 position-absolute top-0 end-0" role="alert" aria-live="assertive" aria-atomic="true">
  <div class="d-flex">
    <div class="toast-body">
      Copied!
    </div>
  </div>
</div>

---
Primary Category: cs.CV  
Categories: cs-AI, cs-CV, cs.CV  
Keyword Score: 36  
Keywords: Benchmarking, Benchmarking, Supervised Learning, Unsupervised Learning, Summarization  
<a type="button" class="btn btn-outline-primary" href="http://arxiv.org/abs/2404.04564v1" target="_blank" >Paper Link</a>
<button type="button" class="btn btn-outline-primary download-pdf" url="https://arxiv.org/pdf/2404.04564v1.pdf" filename="2404.04564v1.pdf">Download PDF</button>

---


**ABSTRACT**  
Video <b>summarization</b> is a crucial research area that aims to efficiently browse and retrieve relevant information from the vast amount of video content available today. With the exponential growth of multimedia data, the ability to extract meaningful representations from videos has become essential. Video <b>summarization</b> techniques automatically generate concise summaries by selecting keyframes, shots, or segments that capture the video's essence. This process improves the efficiency and accuracy of various applications, including video surveillance, education, entertainment, and social media. Despite the importance of video <b>summarization,</b> there is a lack of diverse and representative datasets, hindering comprehensive evaluation and <b>benchmarking</b> of algorithms. Existing evaluation metrics also fail to fully capture the complexities of video <b>summarization,</b> limiting accurate algorithm assessment and hindering the field's progress. To overcome data scarcity challenges and improve evaluation, we propose an <b>unsupervised</b> approach that leverages video data structure and information for generating informative summaries. By moving away from fixed annotations, our framework can produce representative summaries effectively. Moreover, we introduce an innovative evaluation pipeline tailored specifically for video <b>summarization.</b> Human participants are involved in the evaluation, comparing our generated summaries to ground truth summaries and assessing their informativeness. This human-centric approach provides valuable insights into the effectiveness of our proposed techniques. Experimental results demonstrate that our training-free framework outperforms existing <b>unsupervised</b> approaches and achieves competitive results compared to state-of-the-art <b>supervised</b> methods.

{{</citation>}}


### (10/42 | 28/126) DATENeRF: Depth-Aware Text-based Editing of NeRFs (Sara Rojas et al., 2024)

{{<citation>}}

Sara Rojas, Julien Philip, Kai Zhang, Sai Bi, Fujun Luan, Bernard Ghanem, Kalyan Sunkavall. (2024)  
**DATENeRF: Depth-Aware Text-based Editing of NeRFs**
<br/>
<button class="copy-to-clipboard" title="DATENeRF: Depth-Aware Text-based Editing of NeRFs" index=28>
  <span class="copy-to-clipboard-item">Copy Title<span>
</button>
<div class="toast toast-copied toast-index-28 align-items-center text-bg-secondary border-0 position-absolute top-0 end-0" role="alert" aria-live="assertive" aria-atomic="true">
  <div class="d-flex">
    <div class="toast-body">
      Copied!
    </div>
  </div>
</div>

---
Primary Category: cs.CV  
Categories: cs-CV, cs.CV  
Keyword Score: 35  
Keywords: ControlNet, Diffusion Model, Geometry, Prompt  
<a type="button" class="btn btn-outline-primary" href="http://arxiv.org/abs/2404.04526v1" target="_blank" >Paper Link</a>
<button type="button" class="btn btn-outline-primary download-pdf" url="https://arxiv.org/pdf/2404.04526v1.pdf" filename="2404.04526v1.pdf">Download PDF</button>

---


**ABSTRACT**  
Recent advancements in <b>diffusion</b> <b>models</b> have shown remarkable proficiency in editing 2D images based on text <b>prompts.</b> However, extending these techniques to edit scenes in Neural Radiance Fields (NeRF) is complex, as editing individual 2D frames can result in inconsistencies across multiple views. Our crucial insight is that a NeRF scene's <b>geometry</b> can serve as a bridge to integrate these 2D edits. Utilizing this <b>geometry,</b> we employ a depth-conditioned <b>ControlNet</b> to enhance the coherence of each 2D image modification. Moreover, we introduce an inpainting approach that leverages the depth information of NeRF scenes to distribute 2D edits across different images, ensuring robustness against errors and resampling challenges. Our results reveal that this methodology achieves more consistent, lifelike, and detailed edits than existing leading methods for text-driven NeRF scene editing.

{{</citation>}}


### (11/42 | 29/126) Diffusion Time-step Curriculum for One Image to 3D Generation (Xuanyu Yi et al., 2024)

{{<citation>}}

Xuanyu Yi, Zike Wu, Qingshan Xu, Pan Zhou, Joo-Hwee Lim, Hanwang Zhang. (2024)  
**Diffusion Time-step Curriculum for One Image to 3D Generation**
<br/>
<button class="copy-to-clipboard" title="Diffusion Time-step Curriculum for One Image to 3D Generation" index=29>
  <span class="copy-to-clipboard-item">Copy Title<span>
</button>
<div class="toast toast-copied toast-index-29 align-items-center text-bg-secondary border-0 position-absolute top-0 end-0" role="alert" aria-live="assertive" aria-atomic="true">
  <div class="d-flex">
    <div class="toast-body">
      Copied!
    </div>
  </div>
</div>

---
Primary Category: cs.CV  
Categories: cs-CV, cs.CV  
Keyword Score: 33  
Keywords: Diffusion Model, Benchmarking, Knowledge Distillation, Knowledge Distillation  
<a type="button" class="btn btn-outline-primary" href="http://arxiv.org/abs/2404.04562v1" target="_blank" >Paper Link</a>
<button type="button" class="btn btn-outline-primary download-pdf" url="https://arxiv.org/pdf/2404.04562v1.pdf" filename="2404.04562v1.pdf">Download PDF</button>

---


**ABSTRACT**  
Score <b>distillation</b> sampling~(SDS) has been widely adopted to overcome the absence of unseen views in reconstructing 3D objects from a \textbf{single} image. It leverages pre-trained 2D <b>diffusion</b> <b>models</b> as teacher to guide the reconstruction of student 3D models. Despite their remarkable success, SDS-based methods often encounter geometric artifacts and texture saturation. We find out the crux is the overlooked indiscriminate treatment of <b>diffusion</b> <b>time-steps</b> during optimization: it unreasonably treats the student-teacher <b>knowledge</b> <b>distillation</b> to be equal at all time-steps and thus entangles coarse-grained and fine-grained modeling. Therefore, we propose the <b>Diffusion</b> <b>Time-step</b> Curriculum one-image-to-3D pipeline (DTC123), which involves both the teacher and student models collaborating with the time-step curriculum in a coarse-to-fine manner. Extensive experiments on NeRF4, RealFusion15, GSO and Level50 <b>benchmark</b> demonstrate that DTC123 can produce multi-view consistent, high-quality, and diverse 3D assets. Codes and more generation demos will be released in https://github.com/yxymessi/DTC123.

{{</citation>}}


### (12/42 | 30/126) MedIAnomaly: A comparative study of anomaly detection in medical images (Yu Cai et al., 2024)

{{<citation>}}

Yu Cai, Weiwen Zhang, Hao Chen, Kwang-Ting Cheng. (2024)  
**MedIAnomaly: A comparative study of anomaly detection in medical images**
<br/>
<button class="copy-to-clipboard" title="MedIAnomaly: A comparative study of anomaly detection in medical images" index=30>
  <span class="copy-to-clipboard-item">Copy Title<span>
</button>
<div class="toast toast-copied toast-index-30 align-items-center text-bg-secondary border-0 position-absolute top-0 end-0" role="alert" aria-live="assertive" aria-atomic="true">
  <div class="d-flex">
    <div class="toast-body">
      Copied!
    </div>
  </div>
</div>

---
Primary Category: cs.CV  
Categories: cs-CV, cs.CV  
Keyword Score: 33  
Keywords: Anomaly Detection, Benchmarking, Self-supervised Learning, Self-supervised Learning  
<a type="button" class="btn btn-outline-primary" href="http://arxiv.org/abs/2404.04518v1" target="_blank" >Paper Link</a>
<button type="button" class="btn btn-outline-primary download-pdf" url="https://arxiv.org/pdf/2404.04518v1.pdf" filename="2404.04518v1.pdf">Download PDF</button>

---


**ABSTRACT**  
<b>Anomaly</b> <b>detection</b> (AD) aims at detecting abnormal samples that deviate from the expected normal patterns. Generally, it can be trained on merely normal data without the requirement for abnormal samples, and thereby plays an important role in the recognition of rare diseases and health screening in the medical domain. Despite numerous related studies, we observe a lack of a fair and comprehensive evaluation, which causes some ambiguous conclusions and hinders the development of this field. This paper focuses on building a <b>benchmark</b> with unified implementation and comparison to address this problem. In particular, seven medical datasets with five image modalities, including chest X-rays, brain MRIs, retinal fundus images, dermatoscopic images, and histopathology whole slide images are organized for extensive evaluation. Twenty-seven typical AD methods, including reconstruction and <b>self-supervised</b> <b>learning-based</b> methods, are involved in comparison of image-level <b>anomaly</b> <b>classification</b> and pixel-level <b>anomaly</b> <b>segmentation.</b> Furthermore, we for the first time formally explore the effect of key components in existing methods, clearly revealing unresolved challenges and potential future directions. The datasets and code are available at \url{https://github.com/caiyu6666/MedIAnomaly}.

{{</citation>}}


### (13/42 | 31/126) Cluster-based Video Summarization with Temporal Context Awareness (Hai-Dang Huynh-Lam et al., 2024)

{{<citation>}}

Hai-Dang Huynh-Lam, Ngoc-Phuong Ho-Thi, Minh-Triet Tran, Trung-Nghia Le. (2024)  
**Cluster-based Video Summarization with Temporal Context Awareness**
<br/>
<button class="copy-to-clipboard" title="Cluster-based Video Summarization with Temporal Context Awareness" index=31>
  <span class="copy-to-clipboard-item">Copy Title<span>
</button>
<div class="toast toast-copied toast-index-31 align-items-center text-bg-secondary border-0 position-absolute top-0 end-0" role="alert" aria-live="assertive" aria-atomic="true">
  <div class="d-flex">
    <div class="toast-body">
      Copied!
    </div>
  </div>
</div>

---
Primary Category: cs.CV  
Categories: cs-AI, cs-CV, cs.CV  
Keyword Score: 33  
Keywords: Clustering, Supervised Learning, Unsupervised Learning, Summarization  
<a type="button" class="btn btn-outline-primary" href="http://arxiv.org/abs/2404.04511v1" target="_blank" >Paper Link</a>
<button type="button" class="btn btn-outline-primary download-pdf" url="https://arxiv.org/pdf/2404.04511v1.pdf" filename="2404.04511v1.pdf">Download PDF</button>

---


**ABSTRACT**  
In this paper, we present TAC-SUM, a novel and efficient training-free approach for video <b>summarization</b> that addresses the limitations of existing cluster-based models by incorporating temporal context. Our method partitions the input video into temporally consecutive segments with <b>clustering</b> information, enabling the injection of temporal awareness into the <b>clustering</b> process, setting it apart from prior cluster-based <b>summarization</b> methods. The resulting temporal-aware clusters are then utilized to compute the final summary, using simple rules for keyframe selection and frame importance scoring. Experimental results on the SumMe dataset demonstrate the effectiveness of our proposed approach, outperforming existing <b>unsupervised</b> methods and achieving comparable performance to state-of-the-art <b>supervised</b> <b>summarization</b> techniques. Our source code is available for reference at \url{https://github.com/hcmus-thesis-gulu/TAC-SUM}.

{{</citation>}}


### (14/42 | 32/126) Focused Active Learning for Histopathological Image Classification (Arne Schmidt et al., 2024)

{{<citation>}}

Arne Schmidt, Pablo Morales-lvarez, Lee A. D. Cooper, Lee A. Newberg, Andinet Enquobahrie, Aggelos K. Katsaggelos, Rafael Molina. (2024)  
**Focused Active Learning for Histopathological Image Classification**
<br/>
<button class="copy-to-clipboard" title="Focused Active Learning for Histopathological Image Classification" index=32>
  <span class="copy-to-clipboard-item">Copy Title<span>
</button>
<div class="toast toast-copied toast-index-32 align-items-center text-bg-secondary border-0 position-absolute top-0 end-0" role="alert" aria-live="assertive" aria-atomic="true">
  <div class="d-flex">
    <div class="toast-body">
      Copied!
    </div>
  </div>
</div>

---
Primary Category: cs.CV  
Categories: cs-AI, cs-CV, cs.CV  
Keyword Score: 30  
Keywords: MNIST, Active Learning, Out-of-distribution  
<a type="button" class="btn btn-outline-primary" href="http://arxiv.org/abs/2404.04663v1" target="_blank" >Paper Link</a>
<button type="button" class="btn btn-outline-primary download-pdf" url="https://arxiv.org/pdf/2404.04663v1.pdf" filename="2404.04663v1.pdf">Download PDF</button>

---


**ABSTRACT**  
<b>Active</b> <b>Learning</b> (AL) has the potential to solve a major problem of digital pathology: the efficient acquisition of labeled data for machine learning algorithms. However, existing AL methods often struggle in realistic settings with artifacts, ambiguities, and class imbalances, as commonly seen in the medical field. The lack of precise uncertainty estimations leads to the acquisition of images with a low informative value. To address these challenges, we propose Focused <b>Active</b> <b>Learning</b> (FocAL), which combines a Bayesian Neural Network with <b>Out-of-Distribution</b> detection to estimate different uncertainties for the acquisition function. Specifically, the weighted epistemic uncertainty accounts for the class imbalance, aleatoric uncertainty for ambiguous images, and an OoD score for artifacts. We perform extensive experiments to validate our method on <b>MNIST</b> and the real-world Panda dataset for the classification of prostate cancer. The results confirm that other AL methods are 'distracted' by ambiguities and artifacts which harm the performance. FocAL effectively focuses on the most informative images, avoiding ambiguities and artifacts during acquisition. For both experiments, FocAL outperforms existing AL approaches, reaching a Cohen's kappa of 0.764 with only 0.69% of the labeled Panda data.

{{</citation>}}


### (15/42 | 33/126) BeyondScene: Higher-Resolution Human-Centric Scene Generation With Pretrained Diffusion (Gwanghyun Kim et al., 2024)

{{<citation>}}

Gwanghyun Kim, Hayeon Kim, Hoigi Seo, Dong Un Kang, Se Young Chun. (2024)  
**BeyondScene: Higher-Resolution Human-Centric Scene Generation With Pretrained Diffusion**
<br/>
<button class="copy-to-clipboard" title="BeyondScene: Higher-Resolution Human-Centric Scene Generation With Pretrained Diffusion" index=33>
  <span class="copy-to-clipboard-item">Copy Title<span>
</button>
<div class="toast toast-copied toast-index-33 align-items-center text-bg-secondary border-0 position-absolute top-0 end-0" role="alert" aria-live="assertive" aria-atomic="true">
  <div class="d-flex">
    <div class="toast-body">
      Copied!
    </div>
  </div>
</div>

---
Primary Category: cs.CV  
Categories: cs-AI, cs-CV, cs.CV  
Keyword Score: 30  
Keywords: Diffusion Model, Text2image, Text2image  
<a type="button" class="btn btn-outline-primary" href="http://arxiv.org/abs/2404.04544v1" target="_blank" >Paper Link</a>
<button type="button" class="btn btn-outline-primary download-pdf" url="https://arxiv.org/pdf/2404.04544v1.pdf" filename="2404.04544v1.pdf">Download PDF</button>

---


**ABSTRACT**  
Generating higher-resolution human-centric scenes with details and controls remains a challenge for existing <b>text-to-image</b> <b>diffusion</b> <b>models.</b> This challenge stems from limited training image size, text encoder capacity (limited tokens), and the inherent difficulty of generating complex scenes involving multiple humans. While current methods attempted to address training size limit only, they often yielded human-centric scenes with severe artifacts. We propose BeyondScene, a novel framework that overcomes prior limitations, generating exquisite higher-resolution (over 8K) human-centric scenes with exceptional <b>text-image</b> correspondence and naturalness using existing pretrained <b>diffusion</b> <b>models.</b> BeyondScene employs a staged and hierarchical approach to initially generate a detailed base image focusing on crucial elements in instance creation for multiple humans and detailed descriptions beyond token limit of <b>diffusion</b> <b>model,</b> and then to seamlessly convert the base image to a higher-resolution output, exceeding training image size and incorporating details aware of text and instances via our novel instance-aware hierarchical enlargement process that consists of our proposed high-frequency injected forward <b>diffusion</b> <b>and</b> adaptive joint <b>diffusion.</b> <b>BeyondScene</b> surpasses existing methods in terms of correspondence with detailed text descriptions and naturalness, paving the way for advanced applications in higher-resolution human-centric scene creation beyond the capacity of pretrained <b>diffusion</b> <b>models</b> without costly retraining. Project page: https://janeyeon.github.io/beyond-scene.

{{</citation>}}


### (16/42 | 34/126) Diffusion-RWKV: Scaling RWKV-Like Architectures for Diffusion Models (Zhengcong Fei et al., 2024)

{{<citation>}}

Zhengcong Fei, Mingyuan Fan, Changqian Yu, Debang Li, Junshi Huang. (2024)  
**Diffusion-RWKV: Scaling RWKV-Like Architectures for Diffusion Models**
<br/>
<button class="copy-to-clipboard" title="Diffusion-RWKV: Scaling RWKV-Like Architectures for Diffusion Models" index=34>
  <span class="copy-to-clipboard-item">Copy Title<span>
</button>
<div class="toast toast-copied toast-index-34 align-items-center text-bg-secondary border-0 position-absolute top-0 end-0" role="alert" aria-live="assertive" aria-atomic="true">
  <div class="d-flex">
    <div class="toast-body">
      Copied!
    </div>
  </div>
</div>

---
Primary Category: cs.CV  
Categories: cs-CV, cs.CV  
Keyword Score: 30  
Keywords: Diffusion Model, Convolutional Neural Network, Transformer  
<a type="button" class="btn btn-outline-primary" href="http://arxiv.org/abs/2404.04478v1" target="_blank" >Paper Link</a>
<button type="button" class="btn btn-outline-primary download-pdf" url="https://arxiv.org/pdf/2404.04478v1.pdf" filename="2404.04478v1.pdf">Download PDF</button>

---


**ABSTRACT**  
<b>Transformers</b> have catalyzed advancements in computer vision and natural language processing (NLP) fields. However, substantial computational complexity poses limitations for their application in long-context tasks, such as high-resolution image generation. This paper introduces a series of architectures adapted from the RWKV model used in the NLP, with requisite modifications tailored for <b>diffusion</b> <b>model</b> applied to image generation tasks, referred to as <b>Diffusion-RWKV.</b> <b>Similar</b> to the <b>diffusion</b> <b>with</b> <b>Transformers,</b> our model is designed to efficiently handle patchnified inputs in a sequence with extra conditions, while also scaling up effectively, accommodating both large-scale parameters and extensive datasets. Its distinctive advantage manifests in its reduced spatial aggregation complexity, rendering it exceptionally adept at processing high-resolution images, thereby eliminating the necessity for windowing or group cached operations. Experimental results on both condition and unconditional image generation tasks demonstrate that Diffison-RWKV achieves performance on par with or surpasses existing <b>CNN</b> or <b>Transformer-based</b> <b>diffusion</b> <b>models</b> in FID and IS metrics while significantly reducing total computation FLOP usage.

{{</citation>}}


### (17/42 | 35/126) SportsHHI: A Dataset for Human-Human Interaction Detection in Sports Videos (Tao Wu et al., 2024)

{{<citation>}}

Tao Wu, Runyu He, Gangshan Wu, Limin Wang. (2024)  
**SportsHHI: A Dataset for Human-Human Interaction Detection in Sports Videos**
<br/>
<button class="copy-to-clipboard" title="SportsHHI: A Dataset for Human-Human Interaction Detection in Sports Videos" index=35>
  <span class="copy-to-clipboard-item">Copy Title<span>
</button>
<div class="toast toast-copied toast-index-35 align-items-center text-bg-secondary border-0 position-absolute top-0 end-0" role="alert" aria-live="assertive" aria-atomic="true">
  <div class="d-flex">
    <div class="toast-body">
      Copied!
    </div>
  </div>
</div>

---
Primary Category: cs.CV  
Categories: cs-CV, cs.CV  
Keyword Score: 26  
Keywords: Graph, Benchmarking, Reasoning, Relation Extraction  
<a type="button" class="btn btn-outline-primary" href="http://arxiv.org/abs/2404.04565v1" target="_blank" >Paper Link</a>
<button type="button" class="btn btn-outline-primary download-pdf" url="https://arxiv.org/pdf/2404.04565v1.pdf" filename="2404.04565v1.pdf">Download PDF</button>

---


**ABSTRACT**  
Video-based visual <b>relation</b> <b>detection</b> tasks, such as video scene <b>graph</b> generation, play important roles in fine-grained video understanding. However, current video visual <b>relation</b> <b>detection</b> datasets have two main limitations that hinder the progress of research in this area. First, they do not explore complex human-human interactions in multi-person scenarios. Second, the <b>relation</b> <b>types</b> of existing datasets have relatively low-level semantics and can be often recognized by appearance or simple prior information, without the need for detailed spatio-temporal context <b>reasoning.</b> Nevertheless, comprehending high-level interactions between humans is crucial for understanding complex multi-person videos, such as sports and surveillance videos. To address this issue, we propose a new video visual <b>relation</b> <b>detection</b> task: video human-human interaction detection, and build a dataset named SportsHHI for it. SportsHHI contains 34 high-level interaction classes from basketball and volleyball sports. 118,075 human bounding boxes and 50,649 interaction instances are annotated on 11,398 keyframes. To <b>benchmark</b> this, we propose a two-stage baseline method and conduct extensive experiments to reveal the key factors for a successful human-human interaction detector. We hope that SportsHHI can stimulate research on human interaction understanding in videos and promote the development of spatio-temporal context modeling techniques in video visual <b>relation</b> <b>detection.</b>

{{</citation>}}


### (18/42 | 36/126) Z-Splat: Z-Axis Gaussian Splatting for Camera-Sonar Fusion (Ziyuan Qu et al., 2024)

{{<citation>}}

Ziyuan Qu, Omkar Vengurlekar, Mohamad Qadri, Kevin Zhang, Michael Kaess, Christopher Metzler, Suren Jayasuriya, Adithya Pediredla. (2024)  
**Z-Splat: Z-Axis Gaussian Splatting for Camera-Sonar Fusion**
<br/>
<button class="copy-to-clipboard" title="Z-Splat: Z-Axis Gaussian Splatting for Camera-Sonar Fusion" index=36>
  <span class="copy-to-clipboard-item">Copy Title<span>
</button>
<div class="toast toast-copied toast-index-36 align-items-center text-bg-secondary border-0 position-absolute top-0 end-0" role="alert" aria-live="assertive" aria-atomic="true">
  <div class="d-flex">
    <div class="toast-body">
      Copied!
    </div>
  </div>
</div>

---
Primary Category: cs.CV  
Categories: cs-CV, cs-GR, cs-LG, cs.CV  
Keyword Score: 25  
Keywords: Geometry, Simulation, Simulator  
<a type="button" class="btn btn-outline-primary" href="http://arxiv.org/abs/2404.04687v1" target="_blank" >Paper Link</a>
<button type="button" class="btn btn-outline-primary download-pdf" url="https://arxiv.org/pdf/2404.04687v1.pdf" filename="2404.04687v1.pdf">Download PDF</button>

---


**ABSTRACT**  
Differentiable 3D-Gaussian splatting (GS) is emerging as a prominent technique in computer vision and graphics for reconstructing 3D scenes. GS represents a scene as a set of 3D Gaussians with varying opacities and employs a computationally efficient splatting operation along with analytical derivatives to compute the 3D Gaussian parameters given scene images captured from various viewpoints. Unfortunately, capturing surround view ($360^{\circ}$ viewpoint) images is impossible or impractical in many real-world imaging scenarios, including underwater imaging, rooms inside a building, and autonomous navigation. In these restricted baseline imaging scenarios, the GS algorithm suffers from a well-known 'missing cone' problem, which results in poor reconstruction along the depth axis. In this manuscript, we demonstrate that using transient data (from sonars) allows us to address the missing cone problem by sampling high-frequency data along the depth axis. We extend the Gaussian splatting algorithms for two commonly used sonars and propose fusion algorithms that simultaneously utilize RGB camera data and sonar data. Through <b>simulations,</b> emulations, and hardware experiments across various imaging scenarios, we show that the proposed fusion algorithms lead to significantly better novel view synthesis (5 dB improvement in PSNR) and 3D <b>geometry</b> reconstruction (60% lower Chamfer distance).

{{</citation>}}


### (19/42 | 37/126) Adaptive Intra-Class Variation Contrastive Learning for Unsupervised Person Re-Identification (Lingzhi Liu et al., 2024)

{{<citation>}}

Lingzhi Liu, Haiyang Zhang, Chengwei Tang, Tiantian Zhang. (2024)  
**Adaptive Intra-Class Variation Contrastive Learning for Unsupervised Person Re-Identification**
<br/>
<button class="copy-to-clipboard" title="Adaptive Intra-Class Variation Contrastive Learning for Unsupervised Person Re-Identification" index=37>
  <span class="copy-to-clipboard-item">Copy Title<span>
</button>
<div class="toast toast-copied toast-index-37 align-items-center text-bg-secondary border-0 position-absolute top-0 end-0" role="alert" aria-live="assertive" aria-atomic="true">
  <div class="d-flex">
    <div class="toast-body">
      Copied!
    </div>
  </div>
</div>

---
Primary Category: cs.CV  
Categories: cs-AI, cs-CV, cs.CV  
Keyword Score: 23  
Keywords: Clustering, Contrastive Learning, Unsupervised Learning  
<a type="button" class="btn btn-outline-primary" href="http://arxiv.org/abs/2404.04665v1" target="_blank" >Paper Link</a>
<button type="button" class="btn btn-outline-primary download-pdf" url="https://arxiv.org/pdf/2404.04665v1.pdf" filename="2404.04665v1.pdf">Download PDF</button>

---


**ABSTRACT**  
The memory dictionary-based <b>contrastive</b> <b>learning</b> method has achieved remarkable results in the field of <b>unsupervised</b> person Re-ID. However, The method of updating memory based on all samples does not fully utilize the hardest sample to improve the generalization ability of the model, and the method based on hardest sample mining will inevitably introduce false-positive samples that are incorrectly clustered in the early stages of the model. <b>Clustering-based</b> methods usually discard a significant number of outliers, leading to the loss of valuable information. In order to address the issues mentioned before, we propose an adaptive intra-class variation <b>contrastive</b> <b>learning</b> algorithm for <b>unsupervised</b> Re-ID, called AdaInCV. And the algorithm quantitatively evaluates the learning ability of the model for each class by considering the intra-class variations after <b>clustering,</b> which helps in selecting appropriate samples during the training process of the model. To be more specific, two new strategies are proposed: Adaptive Sample Mining (AdaSaM) and Adaptive Outlier Filter (AdaOF). The first one gradually creates more reliable clusters to dynamically refine the memory, while the second can identify and filter out valuable outliers as negative samples.

{{</citation>}}


### (20/42 | 38/126) Mixed-Query Transformer: A Unified Image Segmentation Architecture (Pei Wang et al., 2024)

{{<citation>}}

Pei Wang, Zhaowei Cai, Hao Yang, Ashwin Swaminathan, R. Manmatha, Stefano Soatto. (2024)  
**Mixed-Query Transformer: A Unified Image Segmentation Architecture**
<br/>
<button class="copy-to-clipboard" title="Mixed-Query Transformer: A Unified Image Segmentation Architecture" index=38>
  <span class="copy-to-clipboard-item">Copy Title<span>
</button>
<div class="toast toast-copied toast-index-38 align-items-center text-bg-secondary border-0 position-absolute top-0 end-0" role="alert" aria-live="assertive" aria-atomic="true">
  <div class="d-flex">
    <div class="toast-body">
      Copied!
    </div>
  </div>
</div>

---
Primary Category: cs.CV  
Categories: cs-CV, cs.CV  
Keyword Score: 23  
Keywords: Benchmarking, Data Augmentation, Transformer  
<a type="button" class="btn btn-outline-primary" href="http://arxiv.org/abs/2404.04469v1" target="_blank" >Paper Link</a>
<button type="button" class="btn btn-outline-primary download-pdf" url="https://arxiv.org/pdf/2404.04469v1.pdf" filename="2404.04469v1.pdf">Download PDF</button>

---


**ABSTRACT**  
Existing unified image segmentation models either employ a unified architecture across multiple tasks but use separate weights tailored to each dataset, or apply a single set of weights to multiple datasets but are limited to a single task. In this paper, we introduce the Mixed-Query <b>Transformer</b> (MQ-Former), a unified architecture for multi-task and multi-dataset image segmentation using a single set of weights. To enable this, we propose a mixed query strategy, which can effectively and dynamically accommodate different types of objects without heuristic designs. In addition, the unified architecture allows us to use <b>data</b> <b>augmentation</b> with synthetic masks and captions to further improve model generalization. Experiments demonstrate that MQ-Former can not only effectively handle multiple segmentation datasets and tasks compared to specialized state-of-the-art models with competitive performance, but also generalize better to open-set segmentation tasks, evidenced by over 7 points higher performance than the prior art on the open-vocabulary SeginW <b>benchmark.</b>

{{</citation>}}


### (21/42 | 39/126) ProtoAL: Interpretable Deep Active Learning with prototypes for medical imaging (Iury B. de A. Santos et al., 2024)

{{<citation>}}

Iury B. de A. Santos, Andr C. P. L. F. de Carvalho. (2024)  
**ProtoAL: Interpretable Deep Active Learning with prototypes for medical imaging**
<br/>
<button class="copy-to-clipboard" title="ProtoAL: Interpretable Deep Active Learning with prototypes for medical imaging" index=39>
  <span class="copy-to-clipboard-item">Copy Title<span>
</button>
<div class="toast toast-copied toast-index-39 align-items-center text-bg-secondary border-0 position-absolute top-0 end-0" role="alert" aria-live="assertive" aria-atomic="true">
  <div class="d-flex">
    <div class="toast-body">
      Copied!
    </div>
  </div>
</div>

---
Primary Category: cs.CV  
Categories: cs-AI, cs-CV, cs-LG, cs.CV  
Keyword Score: 20  
Keywords: Active Learning, Prompt  
<a type="button" class="btn btn-outline-primary" href="http://arxiv.org/abs/2404.04736v1" target="_blank" >Paper Link</a>
<button type="button" class="btn btn-outline-primary download-pdf" url="https://arxiv.org/pdf/2404.04736v1.pdf" filename="2404.04736v1.pdf">Download PDF</button>

---


**ABSTRACT**  
The adoption of Deep Learning algorithms in the medical imaging field is a prominent area of research, with high potential for advancing AI-based Computer-aided diagnosis (AI-CAD) solutions. However, current solutions face challenges due to a lack of interpretability features and high data demands, <b>prompting</b> recent efforts to address these issues. In this study, we propose the ProtoAL method, where we integrate an interpretable DL model into the Deep <b>Active</b> <b>Learning</b> (DAL) framework. This approach aims to address both challenges by focusing on the medical imaging context and utilizing an inherently interpretable model based on prototypes. We evaluated ProtoAL on the Messidor dataset, achieving an area under the precision-recall curve of 0.79 while utilizing only 76.54\% of the available labeled data. These capabilities can enhances the practical usability of a DL model in the medical field, providing a means of trust calibration in domain experts and a suitable solution for learning in the data scarcity context often found.

{{</citation>}}


### (22/42 | 40/126) Salient Sparse Visual Odometry With Pose-Only Supervision (Siyu Chen et al., 2024)

{{<citation>}}

Siyu Chen, Kangcheng Liu, Chen Wang, Shenghai Yuan, Jianfei Yang, Lihua Xie. (2024)  
**Salient Sparse Visual Odometry With Pose-Only Supervision**
<br/>
<button class="copy-to-clipboard" title="Salient Sparse Visual Odometry With Pose-Only Supervision" index=40>
  <span class="copy-to-clipboard-item">Copy Title<span>
</button>
<div class="toast toast-copied toast-index-40 align-items-center text-bg-secondary border-0 position-absolute top-0 end-0" role="alert" aria-live="assertive" aria-atomic="true">
  <div class="d-flex">
    <div class="toast-body">
      Copied!
    </div>
  </div>
</div>

---
Primary Category: cs.CV  
Categories: cs-CV, cs-RO, cs.CV  
Keyword Score: 20  
Keywords: Self-supervised Learning, Supervised Learning  
<a type="button" class="btn btn-outline-primary" href="http://arxiv.org/abs/2404.04677v1" target="_blank" >Paper Link</a>
<button type="button" class="btn btn-outline-primary download-pdf" url="https://arxiv.org/pdf/2404.04677v1.pdf" filename="2404.04677v1.pdf">Download PDF</button>

---


**ABSTRACT**  
Visual Odometry (VO) is vital for the navigation of autonomous systems, providing accurate position and orientation estimates at reasonable costs. While traditional VO methods excel in some conditions, they struggle with challenges like variable lighting and motion blur. Deep learning-based VO, though more adaptable, can face generalization problems in new environments. Addressing these drawbacks, this paper presents a novel hybrid visual odometry (VO) framework that leverages pose-only supervision, offering a balanced solution between robustness and the need for extensive labeling. We propose two cost-effective and innovative designs: a <b>self-supervised</b> homographic pre-training for enhancing optical flow learning from pose-only labels and a random patch-based salient point detection strategy for more accurate optical flow patch extraction. These designs eliminate the need for dense optical flow labels for training and significantly improve the generalization capability of the system in diverse and challenging environments. Our pose-only <b>supervised</b> method achieves competitive performance on standard datasets and greater robustness and generalization ability in extreme and unseen scenarios, even compared to dense optical flow-supervised state-of-the-art methods.

{{</citation>}}


### (23/42 | 41/126) Empowering Image Recovery_ A Multi-Attention Approach (Juan Wen et al., 2024)

{{<citation>}}

Juan Wen, Yawei Li, Chao Zhang, Weiyan Hou, Radu Timofte, Luc Van Gool. (2024)  
**Empowering Image Recovery_ A Multi-Attention Approach**
<br/>
<button class="copy-to-clipboard" title="Empowering Image Recovery_ A Multi-Attention Approach" index=41>
  <span class="copy-to-clipboard-item">Copy Title<span>
</button>
<div class="toast toast-copied toast-index-41 align-items-center text-bg-secondary border-0 position-absolute top-0 end-0" role="alert" aria-live="assertive" aria-atomic="true">
  <div class="d-flex">
    <div class="toast-body">
      Copied!
    </div>
  </div>
</div>

---
Primary Category: cs.CV  
Categories: 68T07 (Primary) 168T45 (Secondary), I-4-4, cs-CV, cs.CV  
Keyword Score: 20  
Keywords: Transformer, Self-Attention  
<a type="button" class="btn btn-outline-primary" href="http://arxiv.org/abs/2404.04617v1" target="_blank" >Paper Link</a>
<button type="button" class="btn btn-outline-primary download-pdf" url="https://arxiv.org/pdf/2404.04617v1.pdf" filename="2404.04617v1.pdf">Download PDF</button>

---


**ABSTRACT**  
We propose Diverse Restormer (DART), a novel image restoration method that effectively integrates information from various sources (long sequences, local and global regions, feature dimensions, and positional dimensions) to address restoration challenges. While <b>Transformer</b> models have demonstrated excellent performance in image restoration due to their <b>self-attention</b> mechanism, they face limitations in complex scenarios. Leveraging recent advancements in <b>Transformers</b> and various attention mechanisms, our method utilizes customized attention mechanisms to enhance overall performance. DART, our novel network architecture, employs windowed attention to mimic the selective focusing mechanism of human eyes. By dynamically adjusting receptive fields, it optimally captures the fundamental features crucial for image resolution reconstruction. Efficiency and performance balance are achieved through the LongIR attention mechanism for long sequence image restoration. Integration of attention mechanisms across feature and positional dimensions further enhances the recovery of fine details. Evaluation across five restoration tasks consistently positions DART at the forefront. Upon acceptance, we commit to providing publicly accessible code and models to ensure reproducibility and facilitate further research.

{{</citation>}}


### (24/42 | 42/126) PIE: Physics-inspired Low-light Enhancement (Dong Liang et al., 2024)

{{<citation>}}

Dong Liang, Zhengyan Xu, Ling Li, Mingqiang Wei, Songcan Chen. (2024)  
**PIE: Physics-inspired Low-light Enhancement**
<br/>
<button class="copy-to-clipboard" title="PIE: Physics-inspired Low-light Enhancement" index=42>
  <span class="copy-to-clipboard-item">Copy Title<span>
</button>
<div class="toast toast-copied toast-index-42 align-items-center text-bg-secondary border-0 position-absolute top-0 end-0" role="alert" aria-live="assertive" aria-atomic="true">
  <div class="d-flex">
    <div class="toast-body">
      Copied!
    </div>
  </div>
</div>

---
Primary Category: cs.CV  
Categories: cs-CV, cs.CV  
Keyword Score: 20  
Keywords: Contrastive Learning, Unsupervised Learning  
<a type="button" class="btn btn-outline-primary" href="http://arxiv.org/abs/2404.04586v1" target="_blank" >Paper Link</a>
<button type="button" class="btn btn-outline-primary download-pdf" url="https://arxiv.org/pdf/2404.04586v1.pdf" filename="2404.04586v1.pdf">Download PDF</button>

---


**ABSTRACT**  
In this paper, we propose a physics-inspired <b>contrastive</b> <b>learning</b> paradigm for low-light enhancement, called PIE. PIE primarily addresses three issues: (i) To resolve the problem of existing learning-based methods often training a LLE model with strict pixel-correspondence image pairs, we eliminate the need for pixel-correspondence paired training data and instead train with unpaired images. (ii) To address the disregard for negative samples and the inadequacy of their generation in existing methods, we incorporate physics-inspired <b>contrastive</b> <b>learning</b> for LLE and design the Bag of Curves (BoC) method to generate more reasonable negative samples that closely adhere to the underlying physical imaging principle. (iii) To overcome the reliance on semantic ground truths in existing methods, we propose an <b>unsupervised</b> regional segmentation module, ensuring regional brightness consistency while eliminating the dependency on semantic ground truths. Overall, the proposed PIE can effectively learn from unpaired positive/negative samples and smoothly realize non-semantic regional enhancement, which is clearly different from existing LLE efforts. Besides the novel architecture of PIE, we explore the gain of PIE on downstream tasks such as semantic segmentation and face detection. Training on readily available open data and extensive experiments demonstrate that our method surpasses the state-of-the-art LLE models over six independent cross-scenes datasets. PIE runs fast with reasonable GFLOPs in test time, making it easy to use on mobile devices.

{{</citation>}}


### (25/42 | 43/126) D$^3$: Scaling Up Deepfake Detection by Learning from Discrepancy (Yongqi Yang et al., 2024)

{{<citation>}}

Yongqi Yang, Zhihao Qian, Ye Zhu, Yu Wu. (2024)  
**D$^3$: Scaling Up Deepfake Detection by Learning from Discrepancy**
<br/>
<button class="copy-to-clipboard" title="D$^3$: Scaling Up Deepfake Detection by Learning from Discrepancy" index=43>
  <span class="copy-to-clipboard-item">Copy Title<span>
</button>
<div class="toast toast-copied toast-index-43 align-items-center text-bg-secondary border-0 position-absolute top-0 end-0" role="alert" aria-live="assertive" aria-atomic="true">
  <div class="d-flex">
    <div class="toast-body">
      Copied!
    </div>
  </div>
</div>

---
Primary Category: cs.CV  
Categories: cs-CV, cs.CV  
Keyword Score: 20  
Keywords: Generative AI, Out-of-domain  
<a type="button" class="btn btn-outline-primary" href="http://arxiv.org/abs/2404.04584v1" target="_blank" >Paper Link</a>
<button type="button" class="btn btn-outline-primary download-pdf" url="https://arxiv.org/pdf/2404.04584v1.pdf" filename="2404.04584v1.pdf">Download PDF</button>

---


**ABSTRACT**  
The boom of <b>Generative</b> <b>AI</b> brings opportunities entangled with risks and concerns. In this work, we seek a step toward a universal deepfake detection system with better generalization and robustness, to accommodate the responsible deployment of diverse image <b>generative</b> <b>models.</b> We do so by first scaling up the existing detection task setup from the one-generator to multiple-generators in training, during which we disclose two challenges presented in prior methodological designs. Specifically, we reveal that the current methods tailored for training on one specific generator either struggle to learn comprehensive artifacts from multiple generators or tend to sacrifice their ability to identify fake images from seen generators (i.e., In-Domain performance) to exchange the generalization for unseen generators (i.e., <b>Out-Of-Domain</b> performance). To tackle the above challenges, we propose our Discrepancy Deepfake Detector (D$^3$) framework, whose core idea is to learn the universal artifacts from multiple generators by introducing a parallel network branch that takes a distorted image as extra discrepancy signal to supplement its original counterpart. Extensive scaled-up experiments on the merged UFD and GenImage datasets with six detection models demonstrate the effectiveness of our framework, achieving a 5.3% accuracy improvement in the OOD testing compared to the current SOTA methods while maintaining the ID performance.

{{</citation>}}


### (26/42 | 44/126) GLCM-Based Feature Combination for Extraction Model Optimization in Object Detection Using Machine Learning (Florentina Tatrin Kurniati et al., 2024)

{{<citation>}}

Florentina Tatrin Kurniati, Daniel HF Manongga, Eko Sediyono, Sri Yulianto Joko Prasetyo, Roy Rudolf Huizen. (2024)  
**GLCM-Based Feature Combination for Extraction Model Optimization in Object Detection Using Machine Learning**
<br/>
<button class="copy-to-clipboard" title="GLCM-Based Feature Combination for Extraction Model Optimization in Object Detection Using Machine Learning" index=44>
  <span class="copy-to-clipboard-item">Copy Title<span>
</button>
<div class="toast toast-copied toast-index-44 align-items-center text-bg-secondary border-0 position-absolute top-0 end-0" role="alert" aria-live="assertive" aria-atomic="true">
  <div class="d-flex">
    <div class="toast-body">
      Copied!
    </div>
  </div>
</div>

---
Primary Category: cs.CV  
Categories: cs-CV, cs.CV  
Keyword Score: 20  
Keywords: Object Detection, Security  
<a type="button" class="btn btn-outline-primary" href="http://arxiv.org/abs/2404.04578v1" target="_blank" >Paper Link</a>
<button type="button" class="btn btn-outline-primary download-pdf" url="https://arxiv.org/pdf/2404.04578v1.pdf" filename="2404.04578v1.pdf">Download PDF</button>

---


**ABSTRACT**  
In the era of modern technology, <b>object</b> <b>detection</b> using the Gray Level Co-occurrence Matrix (GLCM) extraction method plays a crucial role in <b>object</b> <b>recognition</b> processes. It finds applications in real-time scenarios such as <b>security</b> surveillance and autonomous vehicle navigation, among others. Computational efficiency becomes a critical factor in achieving real-time <b>object</b> <b>detection.</b> Hence, there is a need for a detection model with low complexity and satisfactory accuracy. This research aims to enhance computational efficiency by selecting appropriate features within the GLCM framework. Two classification models, namely K-Nearest Neighbours (K-NN) and Support Vector Machine (SVM), were employed, with the results indicating that K-Nearest Neighbours (K-NN) outperforms SVM in terms of computational complexity. Specifically, K-NN, when utilizing a combination of Correlation, Energy, and Homogeneity features, achieves a 100% accuracy rate with low complexity. Moreover, when using a combination of Energy and Homogeneity features, K-NN attains an almost perfect accuracy level of 99.9889%, while maintaining low complexity. On the other hand, despite SVM achieving 100% accuracy in certain feature combinations, its high or very high complexity can pose challenges, particularly in real-time applications. Therefore, based on the trade-off between accuracy and complexity, the K-NN model with a combination of Correlation, Energy, and Homogeneity features emerges as a more suitable choice for real-time applications that demand high accuracy and low complexity. This research provides valuable insights for optimizing <b>object</b> <b>detection</b> in various applications requiring both high accuracy and rapid responsiveness.

{{</citation>}}


### (27/42 | 45/126) A self-attention model for robust rigid slice-to-volume registration of functional MRI (Samah Khawaled et al., 2024)

{{<citation>}}

Samah Khawaled, Simon K. Warfield, Moti Freiman. (2024)  
**A self-attention model for robust rigid slice-to-volume registration of functional MRI**
<br/>
<button class="copy-to-clipboard" title="A self-attention model for robust rigid slice-to-volume registration of functional MRI" index=45>
  <span class="copy-to-clipboard-item">Copy Title<span>
</button>
<div class="toast toast-copied toast-index-45 align-items-center text-bg-secondary border-0 position-absolute top-0 end-0" role="alert" aria-live="assertive" aria-atomic="true">
  <div class="d-flex">
    <div class="toast-body">
      Copied!
    </div>
  </div>
</div>

---
Primary Category: cs.CV  
Categories: cs-CV, cs.CV  
Keyword Score: 20  
Keywords: Stemming, Self-Attention  
<a type="button" class="btn btn-outline-primary" href="http://arxiv.org/abs/2404.04546v1" target="_blank" >Paper Link</a>
<button type="button" class="btn btn-outline-primary download-pdf" url="https://arxiv.org/pdf/2404.04546v1.pdf" filename="2404.04546v1.pdf">Download PDF</button>

---


**ABSTRACT**  
Functional Magnetic Resonance Imaging (fMRI) is vital in neuroscience, enabling investigations into brain disorders, treatment monitoring, and brain function mapping. However, head motion during fMRI scans, occurring between shots of slice acquisition, can result in distortion, biased analyses, and increased costs due to the need for scan repetitions. Therefore, retrospective slice-level motion correction through slice-to-volume registration (SVR) is crucial. Previous studies have utilized deep learning (DL) based models to address the SVR task; however, they overlooked the uncertainty <b>stemming</b> from the input stack of slices and did not assign weighting or scoring to each slice. In this work, we introduce an end-to-end SVR model for aligning 2D fMRI slices with a 3D reference volume, incorporating a <b>self-attention</b> mechanism to enhance robustness against input data variations and uncertainties. It utilizes independent slice and volume encoders and a <b>self-attention</b> module to assign pixel-wise scores for each slice. We conducted evaluation experiments on 200 images involving synthetic rigid motion generated from 27 subjects belonging to the test set, from the publicly available Healthy Brain Network (HBN) dataset. Our experimental results demonstrate that our model achieves competitive performance in terms of alignment accuracy compared to state-of-the-art deep learning-based methods (Euclidean distance of $0.93$ [mm] vs. $1.86$ [mm]). Furthermore, our approach exhibits significantly faster registration speed compared to conventional iterative methods ($0.096$ sec. vs. $1.17$ sec.). Our end-to-end SVR model facilitates real-time head motion tracking during fMRI acquisition, ensuring reliability and robustness against uncertainties in inputs. source code, which includes the training and evaluations, will be available soon.

{{</citation>}}


### (28/42 | 46/126) Latent-based Diffusion Model for Long-tailed Recognition (Pengxiao Han et al., 2024)

{{<citation>}}

Pengxiao Han, Changkun Ye, Jieming Zhou, Jing Zhang, Jie Hong, Xuesong Li. (2024)  
**Latent-based Diffusion Model for Long-tailed Recognition**
<br/>
<button class="copy-to-clipboard" title="Latent-based Diffusion Model for Long-tailed Recognition" index=46>
  <span class="copy-to-clipboard-item">Copy Title<span>
</button>
<div class="toast toast-copied toast-index-46 align-items-center text-bg-secondary border-0 position-absolute top-0 end-0" role="alert" aria-live="assertive" aria-atomic="true">
  <div class="d-flex">
    <div class="toast-body">
      Copied!
    </div>
  </div>
</div>

---
Primary Category: cs.CV  
Categories: cs-AI, cs-CV, cs.CV  
Keyword Score: 20  
Keywords: Diffusion Model, Transfer Learning  
<a type="button" class="btn btn-outline-primary" href="http://arxiv.org/abs/2404.04517v1" target="_blank" >Paper Link</a>
<button type="button" class="btn btn-outline-primary download-pdf" url="https://arxiv.org/pdf/2404.04517v1.pdf" filename="2404.04517v1.pdf">Download PDF</button>

---


**ABSTRACT**  
Long-tailed imbalance distribution is a common issue in practical computer vision applications. Previous works proposed methods to address this problem, which can be categorized into several classes: re-sampling, re-weighting, <b>transfer</b> <b>learning,</b> and feature augmentation. In recent years, <b>diffusion</b> <b>models</b> have shown an impressive generation ability in many sub-problems of deep computer vision. However, its powerful generation has not been explored in long-tailed problems. We propose a new approach, the Latent-based <b>Diffusion</b> <b>Model</b> for Long-tailed Recognition (LDMLR), as a feature augmentation method to tackle the issue. First, we encode the imbalanced dataset into features using the baseline model. Then, we train a Denoising <b>Diffusion</b> <b>Implicit</b> Model (DDIM) using these encoded features to generate pseudo-features. Finally, we train the classifier using the encoded and pseudo-features from the previous two steps. The model's accuracy shows an improvement on the CIFAR-LT and ImageNet-LT datasets by using the proposed method.

{{</citation>}}


### (29/42 | 47/126) Automated Polyp Segmentation in Colonoscopy Images (Swagat Ranjit et al., 2024)

{{<citation>}}

Swagat Ranjit, Jian Zhang, Bijaya B. Karki. (2024)  
**Automated Polyp Segmentation in Colonoscopy Images**
<br/>
<button class="copy-to-clipboard" title="Automated Polyp Segmentation in Colonoscopy Images" index=47>
  <span class="copy-to-clipboard-item">Copy Title<span>
</button>
<div class="toast toast-copied toast-index-47 align-items-center text-bg-secondary border-0 position-absolute top-0 end-0" role="alert" aria-live="assertive" aria-atomic="true">
  <div class="d-flex">
    <div class="toast-body">
      Copied!
    </div>
  </div>
</div>

---
Primary Category: cs.CV  
Categories: cs-CV, cs.CV  
Keyword Score: 20  
Keywords: Convolution, Data Augmentation  
<a type="button" class="btn btn-outline-primary" href="http://arxiv.org/abs/2404.04461v1" target="_blank" >Paper Link</a>
<button type="button" class="btn btn-outline-primary download-pdf" url="https://arxiv.org/pdf/2404.04461v1.pdf" filename="2404.04461v1.pdf">Download PDF</button>

---


**ABSTRACT**  
It is important to find the polyps in a human system that helps to prevent cancer during medical diagnosis. This research discusses using a dilated <b>convolution</b> module along with a criss cross attention-based network to segment polyps from the endoscopic images of the colon. To gather the context information of all pixels in an image more efficiently, criss-cross attention module has played a vital role. In order to extract maximum information from dataset, <b>data</b> <b>augmentation</b> techniques are employed in the dataset. Rotations, flips, scaling, and contrast along with varying learning rates were implemented to make a better model. Global average pooling was applied over ResNet50 that helped to store the important details of encoder. In our experiment, the proposed architecture's performance was compared with existing models like U-Net, DeepLabV3, PraNet. This architecture outperformed other models on the subset of dataset which has irregular polyp shapes. The combination of dilated <b>convolution</b> module, RCCA, and global average pooling was found to be effective for irregular shapes. Our architecture demonstrates an enhancement, with an average improvement of 3.75% across all metrics when compared to existing models.

{{</citation>}}


### (30/42 | 48/126) SDFR: Synthetic Data for Face Recognition Competition (Hatef Otroshi Shahreza et al., 2024)

{{<citation>}}

Hatef Otroshi Shahreza, Christophe Ecabert, Anjith George, Alexander Unnervik, Sbastien Marcel, Nicol Di Domenico, Guido Borghi, Davide Maltoni, Fadi Boutros, Julia Vogel, Naser Damer, ngela Snchez-Prez, EnriqueMas-Candela, Jorge Calvo-Zaragoza, Bernardo Biesseck, Pedro Vidal, Roger Granada, David Menotti, Ivan DeAndres-Tame, Simone Maurizio La Cava, Sara Concas, Pietro Melzi, Ruben Tolosana, Ruben Vera-Rodriguez, Gianpaolo Perelli, Giulia Orr, Gian Luca Marcialis, Julian Fierrez. (2024)  
**SDFR: Synthetic Data for Face Recognition Competition**
<br/>
<button class="copy-to-clipboard" title="SDFR: Synthetic Data for Face Recognition Competition" index=48>
  <span class="copy-to-clipboard-item">Copy Title<span>
</button>
<div class="toast toast-copied toast-index-48 align-items-center text-bg-secondary border-0 position-absolute top-0 end-0" role="alert" aria-live="assertive" aria-atomic="true">
  <div class="d-flex">
    <div class="toast-body">
      Copied!
    </div>
  </div>
</div>

---
Primary Category: cs.CV  
Categories: cs-CV, cs.CV  
Keyword Score: 16  
Keywords: Face Recognition, Benchmarking, Benchmarking  
<a type="button" class="btn btn-outline-primary" href="http://arxiv.org/abs/2404.04580v1" target="_blank" >Paper Link</a>
<button type="button" class="btn btn-outline-primary download-pdf" url="https://arxiv.org/pdf/2404.04580v1.pdf" filename="2404.04580v1.pdf">Download PDF</button>

---


**ABSTRACT**  
Large-scale <b>face</b> <b>recognition</b> datasets are collected by crawling the Internet and without individuals' consent, raising legal, ethical, and privacy concerns. With the recent advances in generative models, recently several works proposed generating synthetic <b>face</b> <b>recognition</b> datasets to mitigate concerns in web-crawled <b>face</b> <b>recognition</b> datasets. This paper presents the summary of the Synthetic Data for <b>Face</b> <b>Recognition</b> (SDFR) Competition held in conjunction with the 18th IEEE International Conference on Automatic <b>Face</b> <b>and</b> Gesture Recognition (FG 2024) and established to investigate the use of synthetic data for training <b>face</b> <b>recognition</b> models. The SDFR competition was split into two tasks, allowing participants to train <b>face</b> <b>recognition</b> systems using new synthetic datasets and/or existing ones. In the first task, the <b>face</b> <b>recognition</b> backbone was fixed and the dataset size was limited, while the second task provided almost complete freedom on the model backbone, the dataset, and the training pipeline. The submitted models were trained on existing and also new synthetic datasets and used clever methods to improve training with synthetic data. The submissions were evaluated and ranked on a diverse set of seven <b>benchmarking</b> datasets. The paper gives an overview of the submitted <b>face</b> <b>recognition</b> models and reports achieved performance compared to baseline models trained on real and synthetic datasets. Furthermore, the evaluation of submissions is extended to bias assessment across different demography groups. Lastly, an outlook on the current state of the research in training <b>face</b> <b>recognition</b> models using synthetic data is presented, and existing problems as well as potential future directions are also discussed.

{{</citation>}}


### (31/42 | 49/126) Co-Occ: Coupling Explicit Feature Fusion with Volume Rendering Regularization for Multi-Modal 3D Semantic Occupancy Prediction (Jingyi Pan et al., 2024)

{{<citation>}}

Jingyi Pan, Zipeng Wang, Lin Wang. (2024)  
**Co-Occ: Coupling Explicit Feature Fusion with Volume Rendering Regularization for Multi-Modal 3D Semantic Occupancy Prediction**
<br/>
<button class="copy-to-clipboard" title="Co-Occ: Coupling Explicit Feature Fusion with Volume Rendering Regularization for Multi-Modal 3D Semantic Occupancy Prediction" index=49>
  <span class="copy-to-clipboard-item">Copy Title<span>
</button>
<div class="toast toast-copied toast-index-49 align-items-center text-bg-secondary border-0 position-absolute top-0 end-0" role="alert" aria-live="assertive" aria-atomic="true">
  <div class="d-flex">
    <div class="toast-body">
      Copied!
    </div>
  </div>
</div>

---
Primary Category: cs.CV  
Categories: cs-CV, cs.CV  
Keyword Score: 16  
Keywords: Benchmarking, Multi-modal, Supervised Learning  
<a type="button" class="btn btn-outline-primary" href="http://arxiv.org/abs/2404.04561v1" target="_blank" >Paper Link</a>
<button type="button" class="btn btn-outline-primary download-pdf" url="https://arxiv.org/pdf/2404.04561v1.pdf" filename="2404.04561v1.pdf">Download PDF</button>

---


**ABSTRACT**  
3D semantic occupancy prediction is a pivotal task in the field of autonomous driving. Recent approaches have made great advances in 3D semantic occupancy predictions on a single modality. However, <b>multi-modal</b> semantic occupancy prediction approaches have encountered difficulties in dealing with the modality heterogeneity, modality misalignment, and insufficient modality interactions that arise during the fusion of different modalities data, which may result in the loss of important geometric and semantic information. This letter presents a novel <b>multi-modal,</b> i.e., LiDAR-camera 3D semantic occupancy prediction framework, dubbed Co-Occ, which couples explicit LiDAR-camera feature fusion with implicit volume rendering regularization. The key insight is that volume rendering in the feature space can proficiently bridge the gap between 3D LiDAR sweeps and 2D images while serving as a physical regularization to enhance LiDAR-camera fused volumetric representation. Specifically, we first propose a Geometric- and Semantic-aware Fusion (GSFusion) module to explicitly enhance LiDAR features by incorporating neighboring camera features through a K-nearest neighbors (KNN) search. Then, we employ volume rendering to project the fused feature back to the image planes for reconstructing color and depth maps. These maps are then <b>supervised</b> by input images from the camera and depth estimations derived from LiDAR, respectively. Extensive experiments on the popular nuScenes and SemanticKITTI <b>benchmarks</b> verify the effectiveness of our Co-Occ for 3D semantic occupancy prediction. The project page is available at https://rorisis.github.io/Co-Occ_project-page/.

{{</citation>}}


### (32/42 | 50/126) JRDB-Social: A Multifaceted Robotic Dataset for Understanding of Context and Dynamics of Human Interactions Within Social Groups (Simindokht Jahangard et al., 2024)

{{<citation>}}

Simindokht Jahangard, Zhixi Cai, Shiki Wen, Hamid Rezatofighi. (2024)  
**JRDB-Social: A Multifaceted Robotic Dataset for Understanding of Context and Dynamics of Human Interactions Within Social Groups**
<br/>
<button class="copy-to-clipboard" title="JRDB-Social: A Multifaceted Robotic Dataset for Understanding of Context and Dynamics of Human Interactions Within Social Groups" index=50>
  <span class="copy-to-clipboard-item">Copy Title<span>
</button>
<div class="toast toast-copied toast-index-50 align-items-center text-bg-secondary border-0 position-absolute top-0 end-0" role="alert" aria-live="assertive" aria-atomic="true">
  <div class="d-flex">
    <div class="toast-body">
      Copied!
    </div>
  </div>
</div>

---
Primary Category: cs.CV  
Categories: cs-CV, cs.CV  
Keyword Score: 16  
Keywords: Benchmarking, Multi-modal, Large Language Model  
<a type="button" class="btn btn-outline-primary" href="http://arxiv.org/abs/2404.04458v1" target="_blank" >Paper Link</a>
<button type="button" class="btn btn-outline-primary download-pdf" url="https://arxiv.org/pdf/2404.04458v1.pdf" filename="2404.04458v1.pdf">Download PDF</button>

---


**ABSTRACT**  
Understanding human social behaviour is crucial in computer vision and robotics. Micro-level observations like individual actions fall short, necessitating a comprehensive approach that considers individual behaviour, intra-group dynamics, and social group levels for a thorough understanding. To address dataset limitations, this paper introduces JRDB-Social, an extension of JRDB. Designed to fill gaps in human understanding across diverse indoor and outdoor social contexts, JRDB-Social provides annotations at three levels: individual attributes, intra-group interactions, and social group context. This dataset aims to enhance our grasp of human social dynamics for robotic applications. Utilizing the recent cutting-edge <b>multi-modal</b> <b>large</b> <b>language</b> <b>models,</b> we evaluated our <b>benchmark</b> to explore their capacity to decipher social human behaviour.

{{</citation>}}


### (33/42 | 51/126) On Exploring PDE Modeling for Point Cloud Video Representation Learning (Zhuoxu Huang et al., 2024)

{{<citation>}}

Zhuoxu Huang, Zhenkun Fan, Tao Xu, Jungong Han. (2024)  
**On Exploring PDE Modeling for Point Cloud Video Representation Learning**
<br/>
<button class="copy-to-clipboard" title="On Exploring PDE Modeling for Point Cloud Video Representation Learning" index=51>
  <span class="copy-to-clipboard-item">Copy Title<span>
</button>
<div class="toast toast-copied toast-index-51 align-items-center text-bg-secondary border-0 position-absolute top-0 end-0" role="alert" aria-live="assertive" aria-atomic="true">
  <div class="d-flex">
    <div class="toast-body">
      Copied!
    </div>
  </div>
</div>

---
Primary Category: cs.CV  
Categories: cs-CV, cs.CV  
Keyword Score: 15  
Keywords: Contrastive Learning, Representation Learning  
<a type="button" class="btn btn-outline-primary" href="http://arxiv.org/abs/2404.04720v1" target="_blank" >Paper Link</a>
<button type="button" class="btn btn-outline-primary download-pdf" url="https://arxiv.org/pdf/2404.04720v1.pdf" filename="2404.04720v1.pdf">Download PDF</button>

---


**ABSTRACT**  
Point cloud video <b>representation</b> <b>learning</b> is challenging due to complex structures and unordered spatial arrangement. Traditional methods struggle with frame-to-frame correlations and point-wise correspondence tracking. Recently, partial differential equations (PDE) have provided a new perspective in uniformly solving spatial-temporal data information within certain constraints. While tracking tangible point correspondence remains challenging, we propose to formalize point cloud video <b>representation</b> <b>learning</b> as a PDE-solving problem. Inspired by fluid analysis, where PDEs are used to solve the deformation of spatial shape over time, we employ PDE to solve the variations of spatial points affected by temporal information. By modeling spatial-temporal correlations, we aim to regularize spatial variations with temporal features, thereby enhancing <b>representation</b> <b>learning</b> in point cloud videos. We introduce Motion PointNet composed of a PointNet-like encoder and a PDE-solving module. Initially, we construct a lightweight yet effective encoder to model an initial state of the spatial variations. Subsequently, we develop our PDE-solving module in a parameterized latent space, tailored to address the spatio-temporal correlations inherent in point cloud video. The process of solving PDE is guided and refined by a <b>contrastive</b> <b>learning</b> structure, which is pivotal in reshaping the feature distribution, thereby optimizing the feature <b>representation</b> <b>within</b> point cloud video data. Remarkably, our Motion PointNet achieves an impressive accuracy of 97.52% on the MSRAction-3D dataset, surpassing the current state-of-the-art in all aspects while consuming minimal resources (only 0.72M parameters and 0.82G FLOPs).

{{</citation>}}


### (34/42 | 52/126) Collaborative Feedback Discriminative Propagation for Video Super-Resolution (Hao Li et al., 2024)

{{<citation>}}

Hao Li, Xiang Chen, Jiangxin Dong, Jinhui Tang, Jinshan Pan. (2024)  
**Collaborative Feedback Discriminative Propagation for Video Super-Resolution**
<br/>
<button class="copy-to-clipboard" title="Collaborative Feedback Discriminative Propagation for Video Super-Resolution" index=52>
  <span class="copy-to-clipboard-item">Copy Title<span>
</button>
<div class="toast toast-copied toast-index-52 align-items-center text-bg-secondary border-0 position-absolute top-0 end-0" role="alert" aria-live="assertive" aria-atomic="true">
  <div class="d-flex">
    <div class="toast-body">
      Copied!
    </div>
  </div>
</div>

---
Primary Category: cs.CV  
Categories: cs-CV, cs.CV  
Keyword Score: 13  
Keywords: Graph Attention Networks, Benchmarking  
<a type="button" class="btn btn-outline-primary" href="http://arxiv.org/abs/2404.04745v1" target="_blank" >Paper Link</a>
<button type="button" class="btn btn-outline-primary download-pdf" url="https://arxiv.org/pdf/2404.04745v1.pdf" filename="2404.04745v1.pdf">Download PDF</button>

---


**ABSTRACT**  
The key success of existing video super-resolution (VSR) methods stems mainly from exploring spatial and temporal information, which is usually achieved by a recurrent propagation module with an alignment module. However, inaccurate alignment usually leads to aligned features with significant artifacts, which will be accumulated during propagation and thus affect video restoration. Moreover, propagation modules only propagate the same timestep features forward or backward that may fail in case of complex motion or occlusion, limiting their performance for high-quality frame restoration. To address these issues, we propose a collaborative feedback discriminative (CFD) method to correct inaccurate aligned features and model long -range spatial and temporal information for better video reconstruction. In detail, we develop a discriminative alignment correction (DAC) method to adaptively explore information and reduce the influences of the artifacts caused by inaccurate alignment. Then, we propose a collaborative feedback propagation (CFP) module that employs feedback and <b>gating</b> mechanisms to better explore spatial and temporal information of different timestep features from forward and backward propagation simultaneously. Finally, we embed the proposed DAC and CFP into commonly used VSR networks to verify the effectiveness of our method. Quantitative and qualitative experiments on several <b>benchmarks</b> demonstrate that our method can improve the performance of existing VSR models while maintaining a lower model complexity. The source code and pre-trained models will be available at \url{https://github.com/House-Leo/CFDVSR}.

{{</citation>}}


### (35/42 | 53/126) Structured Gradient-based Interpretations via Norm-Regularized Adversarial Training (Shizhan Gong et al., 2024)

{{<citation>}}

Shizhan Gong, Qi Dou, Farzan Farnia. (2024)  
**Structured Gradient-based Interpretations via Norm-Regularized Adversarial Training**
<br/>
<button class="copy-to-clipboard" title="Structured Gradient-based Interpretations via Norm-Regularized Adversarial Training" index=53>
  <span class="copy-to-clipboard-item">Copy Title<span>
</button>
<div class="toast toast-copied toast-index-53 align-items-center text-bg-secondary border-0 position-absolute top-0 end-0" role="alert" aria-live="assertive" aria-atomic="true">
  <div class="d-flex">
    <div class="toast-body">
      Copied!
    </div>
  </div>
</div>

---
Primary Category: cs.CV  
Categories: cs-CV, cs.CV  
Keyword Score: 13  
Keywords: Adversarial Learning, Benchmarking  
<a type="button" class="btn btn-outline-primary" href="http://arxiv.org/abs/2404.04647v1" target="_blank" >Paper Link</a>
<button type="button" class="btn btn-outline-primary download-pdf" url="https://arxiv.org/pdf/2404.04647v1.pdf" filename="2404.04647v1.pdf">Download PDF</button>

---


**ABSTRACT**  
Gradient-based saliency maps have been widely used to explain the decisions of deep neural network classifiers. However, standard gradient-based interpretation maps, including the simple gradient and integrated gradient algorithms, often lack desired structures such as sparsity and connectedness in their application to real-world computer vision models. A frequently used approach to inducing sparsity structures into gradient-based saliency maps is to alter the simple gradient scheme using sparsification or norm-based regularization. A drawback with such post-processing methods is their frequently-observed significant loss in fidelity to the original simple gradient map. In this work, we propose to apply <b>adversarial</b> <b>training</b> as an in-processing scheme to train neural networks with structured simple gradient maps. We show a duality relation between the regularized norms of the <b>adversarial</b> <b>perturbations</b> and gradient-based maps, based on which we design <b>adversarial</b> <b>training</b> loss functions promoting sparsity and group-sparsity properties in simple gradient maps. We present several numerical results to show the influence of our proposed norm-based <b>adversarial</b> <b>training</b> methods on the standard gradient-based maps of standard neural network architectures on <b>benchmark</b> image datasets.

{{</citation>}}


### (36/42 | 54/126) Learning Instance-Aware Correspondences for Robust Multi-Instance Point Cloud Registration in Cluttered Scenes (Zhiyuan Yu et al., 2024)

{{<citation>}}

Zhiyuan Yu, Zheng Qin, Lintao Zheng, Kai Xu. (2024)  
**Learning Instance-Aware Correspondences for Robust Multi-Instance Point Cloud Registration in Cluttered Scenes**
<br/>
<button class="copy-to-clipboard" title="Learning Instance-Aware Correspondences for Robust Multi-Instance Point Cloud Registration in Cluttered Scenes" index=54>
  <span class="copy-to-clipboard-item">Copy Title<span>
</button>
<div class="toast toast-copied toast-index-54 align-items-center text-bg-secondary border-0 position-absolute top-0 end-0" role="alert" aria-live="assertive" aria-atomic="true">
  <div class="d-flex">
    <div class="toast-body">
      Copied!
    </div>
  </div>
</div>

---
Primary Category: cs.CV  
Categories: cs-CV, cs.CV  
Keyword Score: 13  
Keywords: Benchmarking, Transformer  
<a type="button" class="btn btn-outline-primary" href="http://arxiv.org/abs/2404.04557v1" target="_blank" >Paper Link</a>
<button type="button" class="btn btn-outline-primary download-pdf" url="https://arxiv.org/pdf/2404.04557v1.pdf" filename="2404.04557v1.pdf">Download PDF</button>

---


**ABSTRACT**  
Multi-instance point cloud registration estimates the poses of multiple instances of a model point cloud in a scene point cloud. Extracting accurate point correspondence is to the center of the problem. Existing approaches usually treat the scene point cloud as a whole, overlooking the separation of instances. Therefore, point features could be easily polluted by other points from the background or different instances, leading to inaccurate correspondences oblivious to separate instances, especially in cluttered scenes. In this work, we propose MIRETR, Multi-Instance REgistration <b>TRansformer,</b> a coarse-to-fine approach to the extraction of instance-aware correspondences. At the coarse level, it jointly learns instance-aware superpoint features and predicts per-instance masks. With instance masks, the influence from outside of the instance being concerned is minimized, such that highly reliable superpoint correspondences can be extracted. The superpoint correspondences are then extended to instance candidates at the fine level according to the instance masks. At last, an efficient candidate selection and refinement algorithm is devised to obtain the final registrations. Extensive experiments on three public <b>benchmarks</b> demonstrate the efficacy of our approach. In particular, MIRETR outperforms the state of the arts by 16.6 points on F1 score on the challenging ROBI <b>benchmark.</b> Code and models are available at https://github.com/zhiyuanYU134/MIRETR.

{{</citation>}}


### (37/42 | 55/126) Rethinking Self-training for Semi-supervised Landmark Detection: A Selection-free Approach (Haibo Jin et al., 2024)

{{<citation>}}

Haibo Jin, Haoxuan Che, Hao Chen. (2024)  
**Rethinking Self-training for Semi-supervised Landmark Detection: A Selection-free Approach**
<br/>
<button class="copy-to-clipboard" title="Rethinking Self-training for Semi-supervised Landmark Detection: A Selection-free Approach" index=55>
  <span class="copy-to-clipboard-item">Copy Title<span>
</button>
<div class="toast toast-copied toast-index-55 align-items-center text-bg-secondary border-0 position-absolute top-0 end-0" role="alert" aria-live="assertive" aria-atomic="true">
  <div class="d-flex">
    <div class="toast-body">
      Copied!
    </div>
  </div>
</div>

---
Primary Category: cs.CV  
Categories: cs-CV, cs.CV  
Keyword Score: 13  
Keywords: Benchmarking, Semi-Supervised Learning  
<a type="button" class="btn btn-outline-primary" href="http://arxiv.org/abs/2404.04556v1" target="_blank" >Paper Link</a>
<button type="button" class="btn btn-outline-primary download-pdf" url="https://arxiv.org/pdf/2404.04556v1.pdf" filename="2404.04556v1.pdf">Download PDF</button>

---


**ABSTRACT**  
Self-training is a simple yet effective method for <b>semi-supervised</b> <b>learning,</b> during which pseudo-label selection plays an important role for handling confirmation bias. Despite its popularity, applying self-training to landmark detection faces three problems: 1) The selected confident pseudo-labels often contain data bias, which may hurt model performance; 2) It is not easy to decide a proper threshold for sample selection as the localization task can be sensitive to noisy pseudo-labels; 3) coordinate regression does not output confidence, making selection-based self-training infeasible. To address the above issues, we propose Self-Training for Landmark Detection (STLD), a method that does not require explicit pseudo-label selection. Instead, STLD constructs a task curriculum to deal with confirmation bias, which progressively transitions from more confident to less confident tasks over the rounds of self-training. Pseudo pretraining and shrink regression are two essential components for such a curriculum, where the former is the first task of the curriculum for providing a better model initialization and the latter is further added in the later rounds to directly leverage the pseudo-labels in a coarse-to-fine manner. Experiments on three facial and one medical landmark detection <b>benchmark</b> show that STLD outperforms the existing methods consistently in both semi- and omni-supervised settings.

{{</citation>}}


### (38/42 | 56/126) Beyond the Known: Adversarial Autoencoders in Novelty Detection (Muhammad Asad et al., 2024)

{{<citation>}}

Muhammad Asad, Ihsan Ullah, Ganesh Sistu, Michael G. Madden. (2024)  
**Beyond the Known: Adversarial Autoencoders in Novelty Detection**
<br/>
<button class="copy-to-clipboard" title="Beyond the Known: Adversarial Autoencoders in Novelty Detection" index=56>
  <span class="copy-to-clipboard-item">Copy Title<span>
</button>
<div class="toast toast-copied toast-index-56 align-items-center text-bg-secondary border-0 position-absolute top-0 end-0" role="alert" aria-live="assertive" aria-atomic="true">
  <div class="d-flex">
    <div class="toast-body">
      Copied!
    </div>
  </div>
</div>

---
Primary Category: cs.CV  
Categories: cs-AI, cs-CV, cs-LG, cs.CV  
Keyword Score: 13  
Keywords: Autoencoder, Benchmarking  
<a type="button" class="btn btn-outline-primary" href="http://arxiv.org/abs/2404.04456v1" target="_blank" >Paper Link</a>
<button type="button" class="btn btn-outline-primary download-pdf" url="https://arxiv.org/pdf/2404.04456v1.pdf" filename="2404.04456v1.pdf">Download PDF</button>

---


**ABSTRACT**  
In novelty detection, the goal is to decide if a new data point should be categorized as an inlier or an outlier, given a training dataset that primarily captures the inlier distribution. Recent approaches typically use deep encoder and decoder network frameworks to derive a reconstruction error, and employ this error either to determine a novelty score, or as the basis for a one-class classifier. In this research, we use a similar framework but with a lightweight deep network, and we adopt a probabilistic score with reconstruction error. Our methodology calculates the probability of whether the sample comes from the inlier distribution or not. This work makes two key contributions. The first is that we compute the novelty probability by linearizing the manifold that holds the structure of the inlier distribution. This allows us to interpret how the probability is distributed and can be determined in relation to the local coordinates of the manifold tangent space. The second contribution is that we improve the training protocol for the network. Our results indicate that our approach is effective at learning the target class, and it outperforms recent state-of-the-art methods on several <b>benchmark</b> datasets.

{{</citation>}}


### (39/42 | 57/126) HawkDrive: A Transformer-driven Visual Perception System for Autonomous Driving in Night Scene (Ziang Guo et al., 2024)

{{<citation>}}

Ziang Guo, Stepan Perminov, Mikhail Konenkov, Dzmitry Tsetserukou. (2024)  
**HawkDrive: A Transformer-driven Visual Perception System for Autonomous Driving in Night Scene**
<br/>
<button class="copy-to-clipboard" title="HawkDrive: A Transformer-driven Visual Perception System for Autonomous Driving in Night Scene" index=57>
  <span class="copy-to-clipboard-item">Copy Title<span>
</button>
<div class="toast toast-copied toast-index-57 align-items-center text-bg-secondary border-0 position-absolute top-0 end-0" role="alert" aria-live="assertive" aria-atomic="true">
  <div class="d-flex">
    <div class="toast-body">
      Copied!
    </div>
  </div>
</div>

---
Primary Category: cs.CV  
Categories: cs-CV, cs-RO, cs.CV  
Keyword Score: 10  
Keywords: Transformer  
<a type="button" class="btn btn-outline-primary" href="http://arxiv.org/abs/2404.04653v1" target="_blank" >Paper Link</a>
<button type="button" class="btn btn-outline-primary download-pdf" url="https://arxiv.org/pdf/2404.04653v1.pdf" filename="2404.04653v1.pdf">Download PDF</button>

---


**ABSTRACT**  
Many established vision perception systems for autonomous driving scenarios ignore the influence of light conditions, one of the key elements for driving safety. To address this problem, we present HawkDrive, a novel perception system with hardware and software solutions. Hardware that utilizes stereo vision perception, which has been demonstrated to be a more reliable way of estimating depth information than monocular vision, is partnered with the edge computing device Nvidia Jetson Xavier AGX. Our software for low light enhancement, depth estimation, and semantic segmentation tasks, is a <b>transformer-based</b> neural network. Our software stack, which enables fast inference and noise reduction, is packaged into system modules in Robot Operating System 2 (ROS2). Our experimental results have shown that the proposed end-to-end system is effective in improving the depth estimation and semantic segmentation performance. Our dataset and codes will be released at https://github.com/ZionGo6/HawkDrive.

{{</citation>}}


### (40/42 | 58/126) NPB-REC: A Non-parametric Bayesian Deep-learning Approach for Undersampled MRI Reconstruction with Uncertainty Estimation (Samah Khawaled et al., 2024)

{{<citation>}}

Samah Khawaled, Moti Freiman. (2024)  
**NPB-REC: A Non-parametric Bayesian Deep-learning Approach for Undersampled MRI Reconstruction with Uncertainty Estimation**
<br/>
<button class="copy-to-clipboard" title="NPB-REC: A Non-parametric Bayesian Deep-learning Approach for Undersampled MRI Reconstruction with Uncertainty Estimation" index=58>
  <span class="copy-to-clipboard-item">Copy Title<span>
</button>
<div class="toast toast-copied toast-index-58 align-items-center text-bg-secondary border-0 position-absolute top-0 end-0" role="alert" aria-live="assertive" aria-atomic="true">
  <div class="d-flex">
    <div class="toast-body">
      Copied!
    </div>
  </div>
</div>

---
Primary Category: cs.CV  
Categories: cs-CV, cs.CV  
Keyword Score: 10  
Keywords: Distribution Shift, Distribution Shift  
<a type="button" class="btn btn-outline-primary" href="http://arxiv.org/abs/2404.04550v1" target="_blank" >Paper Link</a>
<button type="button" class="btn btn-outline-primary download-pdf" url="https://arxiv.org/pdf/2404.04550v1.pdf" filename="2404.04550v1.pdf">Download PDF</button>

---


**ABSTRACT**  
The ability to reconstruct high-quality images from undersampled MRI data is vital in improving MRI temporal resolution and reducing acquisition times. Deep learning methods have been proposed for this task, but the lack of verified methods to quantify the uncertainty in the reconstructed images hampered clinical applicability. We introduce "NPB-REC", a non-parametric fully Bayesian framework, for MRI reconstruction from undersampled data with uncertainty estimation. We use Stochastic Gradient Langevin Dynamics during training to characterize the posterior <b>distribution</b> <b>of</b> the network parameters. This enables us to both improve the quality of the reconstructed images and quantify the uncertainty in the reconstructed images. We demonstrate the efficacy of our approach on a multi-coil MRI dataset from the fastMRI challenge and compare it to the baseline End-to-End Variational Network (E2E-VarNet). Our approach outperforms the baseline in terms of reconstruction accuracy by means of PSNR and SSIM ($34.55$, $0.908$ vs. $33.08$, $0.897$, $p<0.01$, acceleration rate $R=8$) and provides uncertainty measures that correlate better with the reconstruction error (Pearson correlation, $R=0.94$ vs. $R=0.91$). Additionally, our approach exhibits better generalization capabilities against anatomical <b>distribution</b> <b>shifts</b> (PSNR and SSIM of $32.38$, $0.849$ vs. $31.63$, $0.836$, $p<0.01$, training on brain data, inference on knee data, acceleration rate $R=8$). NPB-REC has the potential to facilitate the safe utilization of deep learning-based methods for MRI reconstruction from undersampled data. Code and trained models are available at \url{https://github.com/samahkh/NPB-REC}.

{{</citation>}}


### (41/42 | 59/126) RoNet: Rotation-oriented Continuous Image Translation (Yi Li et al., 2024)

{{<citation>}}

Yi Li, Xin Xie, Lina Lei, Haiyan Fu, Yanqing Guo. (2024)  
**RoNet: Rotation-oriented Continuous Image Translation**
<br/>
<button class="copy-to-clipboard" title="RoNet: Rotation-oriented Continuous Image Translation" index=59>
  <span class="copy-to-clipboard-item">Copy Title<span>
</button>
<div class="toast toast-copied toast-index-59 align-items-center text-bg-secondary border-0 position-absolute top-0 end-0" role="alert" aria-live="assertive" aria-atomic="true">
  <div class="d-flex">
    <div class="toast-body">
      Copied!
    </div>
  </div>
</div>

---
Primary Category: cs.CV  
Categories: cs-CV, cs.CV  
Keyword Score: 10  
Keywords: Image2text  
<a type="button" class="btn btn-outline-primary" href="http://arxiv.org/abs/2404.04474v1" target="_blank" >Paper Link</a>
<button type="button" class="btn btn-outline-primary download-pdf" url="https://arxiv.org/pdf/2404.04474v1.pdf" filename="2404.04474v1.pdf">Download PDF</button>

---


**ABSTRACT**  
The generation of smooth and continuous <b>images</b> <b>between</b> domains has recently drawn much attention in <b>image-to-image</b> <b>(I2I)</b> translation. Linear relationship acts as the basic assumption in most existing approaches, while applied to different aspects including features, models or labels. However, the linear assumption is hard to conform with the element dimension increases and suffers from the limit that having to obtain both ends of the line. In this paper, we propose a novel rotation-oriented solution and model the continuous generation with an in-plane rotation over the style representation of an <b>image,</b> <b>achieving</b> a network named RoNet. A rotation module is implanted in the generation network to automatically learn the proper plane while disentangling the content and the style of an <b>image.</b> <b>To</b> encourage realistic texture, we also design a patch-based semantic style loss that learns the different styles of the similar object in different domains. We conduct experiments on forest scenes (where the complex texture makes the generation very challenging), faces, streetscapes and the iphone2dslr task. The results validate the superiority of our method in terms of visual quality and continuity.

{{</citation>}}


### (42/42 | 60/126) Interpretable Multimodal Learning for Cardiovascular Hemodynamics Assessment (Prasun C Tripathi et al., 2024)

{{<citation>}}

Prasun C Tripathi, Sina Tabakhi, Mohammod N I Suvon, Lawrence Schb, Samer Alabed, Andrew J Swift, Shuo Zhou, Haiping Lu. (2024)  
**Interpretable Multimodal Learning for Cardiovascular Hemodynamics Assessment**
<br/>
<button class="copy-to-clipboard" title="Interpretable Multimodal Learning for Cardiovascular Hemodynamics Assessment" index=60>
  <span class="copy-to-clipboard-item">Copy Title<span>
</button>
<div class="toast toast-copied toast-index-60 align-items-center text-bg-secondary border-0 position-absolute top-0 end-0" role="alert" aria-live="assertive" aria-atomic="true">
  <div class="d-flex">
    <div class="toast-body">
      Copied!
    </div>
  </div>
</div>

---
Primary Category: cs.CV  
Categories: cs-AI, cs-CV, cs.CV  
Keyword Score: 9  
Keywords: Graph, Multi-modal, Multi-modal  
<a type="button" class="btn btn-outline-primary" href="http://arxiv.org/abs/2404.04718v1" target="_blank" >Paper Link</a>
<button type="button" class="btn btn-outline-primary download-pdf" url="https://arxiv.org/pdf/2404.04718v1.pdf" filename="2404.04718v1.pdf">Download PDF</button>

---


**ABSTRACT**  
Pulmonary Arterial Wedge Pressure (PAWP) is an essential cardiovascular hemodynamics marker to detect heart failure. In clinical practice, Right Heart Catheterization is considered a gold standard for assessing cardiac hemodynamics while non-invasive methods are often needed to screen high-risk patients from a large population. In this paper, we propose a <b>multimodal</b> learning pipeline to predict PAWP marker. We utilize complementary information from Cardiac Magnetic Resonance Imaging (CMR) scans (short-axis and four-chamber) and Electronic Health Records (EHRs). We extract spatio-temporal features from CMR scans using tensor-based learning. We propose a <b>graph</b> attention network to select important EHR features for prediction, where we model subjects as <b>graph</b> nodes and feature relationships as <b>graph</b> edges using the attention mechanism. We design four feature fusion strategies: early, intermediate, late, and hybrid fusion. With a linear classifier and linear fusion strategies, our pipeline is interpretable. We validate our pipeline on a large dataset of $2,641$ subjects from our ASPIRE registry. The comparative study against state-of-the-art methods confirms the superiority of our pipeline. The decision curve analysis further validates that our pipeline can be applied to screen a large population. The code is available at https://github.com/prasunc/hemodynamics.

{{</citation>}}


## cs.AI (6)



### (1/6 | 61/126) Do We Really Need a Complex Agent System? Distill Embodied Agent into a Single Model (Zhonghan Zhao et al., 2024)

{{<citation>}}

Zhonghan Zhao, Ke Ma, Wenhao Chai, Xuan Wang, Kewei Chen, Dongxu Guo, Yanting Zhang, Hongwei Wang, Gaoang Wang. (2024)  
**Do We Really Need a Complex Agent System? Distill Embodied Agent into a Single Model**
<br/>
<button class="copy-to-clipboard" title="Do We Really Need a Complex Agent System? Distill Embodied Agent into a Single Model" index=61>
  <span class="copy-to-clipboard-item">Copy Title<span>
</button>
<div class="toast toast-copied toast-index-61 align-items-center text-bg-secondary border-0 position-absolute top-0 end-0" role="alert" aria-live="assertive" aria-atomic="true">
  <div class="d-flex">
    <div class="toast-body">
      Copied!
    </div>
  </div>
</div>

---
Primary Category: cs.AI  
Categories: cs-AI, cs-CV, cs.AI  
Keyword Score: 93  
Keywords: Knowledge Distillation, Knowledge Distillation, Knowledge Distillation, Multi-modal, Simulation, Simulator, Large Language Model, Large Language Model, Masked Language Model, Prompt  
<a type="button" class="btn btn-outline-primary" href="http://arxiv.org/abs/2404.04619v1" target="_blank" >Paper Link</a>
<button type="button" class="btn btn-outline-primary download-pdf" url="https://arxiv.org/pdf/2404.04619v1.pdf" filename="2404.04619v1.pdf">Download PDF</button>

---


**ABSTRACT**  
With the power of <b>large</b> <b>language</b> <b>models</b> <b>(LLMs),</b> open-ended embodied agents can flexibly understand human instructions, generate interpretable guidance strategies, and output executable actions. Nowadays, <b>Multi-modal</b> Language Models~(MLMs) integrate <b>multi-modal</b> signals into <b>LLMs,</b> further bringing richer perception to entity agents and allowing embodied agents to perceive world-understanding tasks more delicately. However, existing works: 1) operate independently by agents, each containing multiple <b>LLMs,</b> from perception to action, resulting in gaps between complex tasks and execution; 2) train <b>MLMs</b> on static data, struggling with dynamics in open-ended scenarios; 3) input prior <b>knowledge</b> <b>directly</b> as <b>prompts,</b> suppressing application flexibility. We propose STEVE-2, a hierarchical <b>knowledge</b> <b>distillation</b> framework for open-ended embodied tasks, characterized by 1) a hierarchical system for multi-granular task division, 2) a mirrored <b>distillation</b> method for parallel <b>simulation</b> data, and 3) an extra expert model for bringing additional <b>knowledge</b> <b>into</b> parallel <b>simulation.</b> After <b>distillation,</b> embodied agents can complete complex, open-ended tasks without additional expert guidance, utilizing the performance and <b>knowledge</b> <b>of</b> a versatile <b>MLM.</b> Extensive evaluations on navigation and creation tasks highlight the superior performance of STEVE-2 in open-ended tasks, with $1.4 \times$ - $7.3 \times$ in performance.

{{</citation>}}


### (2/6 | 62/126) Soft-Prompting with Graph-of-Thought for Multi-modal Representation Learning (Juncheng Yang et al., 2024)

{{<citation>}}

Juncheng Yang, Zuchao Li, Shuai Xie, Wei Yu, Shijun Li, Bo Du. (2024)  
**Soft-Prompting with Graph-of-Thought for Multi-modal Representation Learning**
<br/>
<button class="copy-to-clipboard" title="Soft-Prompting with Graph-of-Thought for Multi-modal Representation Learning" index=62>
  <span class="copy-to-clipboard-item">Copy Title<span>
</button>
<div class="toast toast-copied toast-index-62 align-items-center text-bg-secondary border-0 position-absolute top-0 end-0" role="alert" aria-live="assertive" aria-atomic="true">
  <div class="d-flex">
    <div class="toast-body">
      Copied!
    </div>
  </div>
</div>

---
Primary Category: cs.AI  
Categories: cs-AI, cs-CL, cs.AI  
Keyword Score: 61  
Keywords: Graph, Multi-modal, Representation Learning, Question Answering, Reasoning, Text2image, Visual Question Answering, Prompt  
<a type="button" class="btn btn-outline-primary" href="http://arxiv.org/abs/2404.04538v1" target="_blank" >Paper Link</a>
<button type="button" class="btn btn-outline-primary download-pdf" url="https://arxiv.org/pdf/2404.04538v1.pdf" filename="2404.04538v1.pdf">Download PDF</button>

---


**ABSTRACT**  
The chain-of-thought technique has been received well in <b>multi-modal</b> tasks. It is a step-by-step linear <b>reasoning</b> process that adjusts the length of the chain to improve the performance of generated <b>prompts.</b> However, human thought processes are predominantly non-linear, as they encompass multiple aspects simultaneously and employ dynamic adjustment and updating mechanisms. Therefore, we propose a novel Aggregation-Graph-of-Thought (AGoT) mechanism for soft-prompt tuning in <b>multi-modal</b> <b>representation</b> <b>learning.</b> The proposed AGoT models the human thought process not only as a chain but also models each step as a <b>reasoning</b> aggregation <b>graph</b> to cope with the overlooked multiple aspects of thinking in single-step <b>reasoning.</b> This turns the entire <b>reasoning</b> process into <b>prompt</b> aggregation and <b>prompt</b> flow operations. Experiments show that our <b>multi-modal</b> model enhanced with AGoT soft-prompting achieves good results in several tasks such as <b>text-image</b> retrieval, <b>visual</b> <b>question</b> <b>answering,</b> and image recognition. In addition, we demonstrate that it has good domain generalization performance due to better <b>reasoning.</b>

{{</citation>}}


### (3/6 | 63/126) MACM: Utilizing a Multi-Agent System for Condition Mining in Solving Complex Mathematical Problems (Bin Lei, 2024)

{{<citation>}}

Bin Lei. (2024)  
**MACM: Utilizing a Multi-Agent System for Condition Mining in Solving Complex Mathematical Problems**
<br/>
<button class="copy-to-clipboard" title="MACM: Utilizing a Multi-Agent System for Condition Mining in Solving Complex Mathematical Problems" index=63>
  <span class="copy-to-clipboard-item">Copy Title<span>
</button>
<div class="toast toast-copied toast-index-63 align-items-center text-bg-secondary border-0 position-absolute top-0 end-0" role="alert" aria-live="assertive" aria-atomic="true">
  <div class="d-flex">
    <div class="toast-body">
      Copied!
    </div>
  </div>
</div>

---
Primary Category: cs.AI  
Categories: cs-AI, cs-CL, cs-MA, cs.AI  
Keyword Score: 53  
Keywords: Graph, GPT, GPT-4, GPT-4 turbo, Large Language Model, Prompt  
<a type="button" class="btn btn-outline-primary" href="http://arxiv.org/abs/2404.04735v1" target="_blank" >Paper Link</a>
<button type="button" class="btn btn-outline-primary download-pdf" url="https://arxiv.org/pdf/2404.04735v1.pdf" filename="2404.04735v1.pdf">Download PDF</button>

---


**ABSTRACT**  
Recent advancements in <b>large</b> <b>language</b> <b>models,</b> such as <b>GPT-4,</b> <b>have</b> demonstrated remarkable capabilities in processing standard queries. Despite these advancements, their performance substantially declines in \textbf{advanced mathematical problems requiring complex, multi-step logical reasoning}. To enhance their inferential capabilities, current research has delved into \textit{prompting engineering}, exemplified by methodologies such as the Tree of Thought and <b>Graph</b> of Thought. Nonetheless, these existing approaches encounter two significant limitations. Firstly, their effectiveness in tackling complex mathematical problems is somewhat constrained. Secondly, the necessity to design distinct <b>prompts</b> for individual problems hampers their generalizability. In response to these limitations, this paper introduces the \textit{Multi-Agent System for conditional Mining} (\textbf{MACM}) <b>prompting</b> method. It not only resolves intricate mathematical problems but also demonstrates strong generalization capabilities across various mathematical contexts. With the assistance of MACM, the accuracy of <b>GPT-4</b> <b>Turbo</b> on the most challenging level five mathematical problems in the MATH dataset increase from $\mathbf{54.68\%} \text{ to } \mathbf{76.73\%}$. The code is available in \url{https://github.com/bin123apple/MACM}.

{{</citation>}}


### (4/6 | 64/126) Autonomous Artificial Intelligence Agents for Clinical Decision Making in Oncology (Dyke Ferber et al., 2024)

{{<citation>}}

Dyke Ferber, Omar S. M. El Nahhas, Georg Wlflein, Isabella C. Wiest, Jan Clusmann, Marie-Elisabeth Leman, Sebastian Foersch, Jacqueline Lammert, Maximilian Tschochohei, Dirk Jger, Manuel Salto-Tellez, Nikolaus Schultz, Daniel Truhn, Jakob Nikolas Kather. (2024)  
**Autonomous Artificial Intelligence Agents for Clinical Decision Making in Oncology**
<br/>
<button class="copy-to-clipboard" title="Autonomous Artificial Intelligence Agents for Clinical Decision Making in Oncology" index=64>
  <span class="copy-to-clipboard-item">Copy Title<span>
</button>
<div class="toast toast-copied toast-index-64 align-items-center text-bg-secondary border-0 position-absolute top-0 end-0" role="alert" aria-live="assertive" aria-atomic="true">
  <div class="d-flex">
    <div class="toast-body">
      Copied!
    </div>
  </div>
</div>

---
Primary Category: cs.AI  
Categories: cs-AI, cs.AI, q-bio-TO  
Keyword Score: 46  
Keywords: Multi-modal, Multi-modal, Recommendation, Reasoning, Large Language Model, Large Language Model  
<a type="button" class="btn btn-outline-primary" href="http://arxiv.org/abs/2404.04667v1" target="_blank" >Paper Link</a>
<button type="button" class="btn btn-outline-primary download-pdf" url="https://arxiv.org/pdf/2404.04667v1.pdf" filename="2404.04667v1.pdf">Download PDF</button>

---


**ABSTRACT**  
<b>Multimodal</b> artificial intelligence (AI) systems have the potential to enhance clinical decision-making by interpreting various types of medical data. However, the effectiveness of these models across all medical fields is uncertain. Each discipline presents unique challenges that need to be addressed for optimal performance. This complexity is further increased when attempting to integrate different fields into a single model. Here, we introduce an alternative approach to <b>multimodal</b> medical AI that utilizes the generalist capabilities of a <b>large</b> <b>language</b> <b>model</b> <b>(LLM)</b> as a central <b>reasoning</b> engine. This engine autonomously coordinates and deploys a set of specialized medical AI tools. These tools include text, radiology and histopathology image interpretation, genomic data processing, web searches, and document retrieval from medical guidelines. We validate our system across a series of clinical oncology scenarios that closely resemble typical patient care workflows. We show that the system has a high capability in employing appropriate tools (97%), drawing correct conclusions (93.6%), and providing complete (94%), and helpful (89.2%) <b>recommendations</b> for individual patient cases while consistently referencing relevant literature (82.5%) upon instruction. This work provides evidence that <b>LLMs</b> can effectively plan and execute domain-specific models to retrieve or synthesize new information when used as autonomous agents. This enables them to function as specialist, patient-tailored clinical assistants. It also simplifies regulatory compliance by allowing each component tool to be individually validated and approved. We believe, that our work can serve as a proof-of-concept for more advanced <b>LLM-agents</b> in the medical domain.

{{</citation>}}


### (5/6 | 65/126) Challenges Faced by Large Language Models in Solving Multi-Agent Flocking (Peihan Li et al., 2024)

{{<citation>}}

Peihan Li, Vishnu Menon, Bhavanaraj Gudiguntla, Daniel Ting, Lifeng Zhou. (2024)  
**Challenges Faced by Large Language Models in Solving Multi-Agent Flocking**
<br/>
<button class="copy-to-clipboard" title="Challenges Faced by Large Language Models in Solving Multi-Agent Flocking" index=65>
  <span class="copy-to-clipboard-item">Copy Title<span>
</button>
<div class="toast toast-copied toast-index-65 align-items-center text-bg-secondary border-0 position-absolute top-0 end-0" role="alert" aria-live="assertive" aria-atomic="true">
  <div class="d-flex">
    <div class="toast-body">
      Copied!
    </div>
  </div>
</div>

---
Primary Category: cs.AI  
Categories: cs-AI, cs-MA, cs.AI  
Keyword Score: 30  
Keywords: Reasoning, Large Language Model, Large Language Model  
<a type="button" class="btn btn-outline-primary" href="http://arxiv.org/abs/2404.04752v1" target="_blank" >Paper Link</a>
<button type="button" class="btn btn-outline-primary download-pdf" url="https://arxiv.org/pdf/2404.04752v1.pdf" filename="2404.04752v1.pdf">Download PDF</button>

---


**ABSTRACT**  
Flocking is a behavior where multiple agents in a system attempt to stay close to each other while avoiding collision and maintaining a desired formation. This is observed in the natural world and has applications in robotics, including natural disaster search and rescue, wild animal tracking, and perimeter surveillance and patrol. Recently, <b>large</b> <b>language</b> <b>models</b> <b>(LLMs)</b> have displayed an impressive ability to solve various collaboration tasks as individual decision-makers. Solving multi-agent flocking with <b>LLMs</b> would demonstrate their usefulness in situations requiring spatial and decentralized decision-making. Yet, when <b>LLM-powered</b> agents are tasked with implementing multi-agent flocking, they fall short of the desired behavior. After extensive testing, we find that agents with <b>LLMs</b> as individual decision-makers typically opt to converge on the average of their initial positions or diverge from each other. After breaking the problem down, we discover that <b>LLMs</b> cannot understand maintaining a shape or keeping a distance in a meaningful way. Solving multi-agent flocking with <b>LLMs</b> would enhance their ability to understand collaborative spatial <b>reasoning</b> and lay a foundation for addressing more complex multi-agent tasks. This paper discusses the challenges <b>LLMs</b> face in multi-agent flocking and suggests areas for future improvement and research.

{{</citation>}}


### (6/6 | 66/126) The Case for Developing a Foundation Model for Planning-like Tasks from Scratch (Biplav Srivastava et al., 2024)

{{<citation>}}

Biplav Srivastava, Vishal Pallagani. (2024)  
**The Case for Developing a Foundation Model for Planning-like Tasks from Scratch**
<br/>
<button class="copy-to-clipboard" title="The Case for Developing a Foundation Model for Planning-like Tasks from Scratch" index=66>
  <span class="copy-to-clipboard-item">Copy Title<span>
</button>
<div class="toast toast-copied toast-index-66 align-items-center text-bg-secondary border-0 position-absolute top-0 end-0" role="alert" aria-live="assertive" aria-atomic="true">
  <div class="d-flex">
    <div class="toast-body">
      Copied!
    </div>
  </div>
</div>

---
Primary Category: cs.AI  
Categories: cs-AI, cs.AI  
Keyword Score: 30  
Keywords: Fine-tuning, Foundation Model, Large Language Model  
<a type="button" class="btn btn-outline-primary" href="http://arxiv.org/abs/2404.04540v1" target="_blank" >Paper Link</a>
<button type="button" class="btn btn-outline-primary download-pdf" url="https://arxiv.org/pdf/2404.04540v1.pdf" filename="2404.04540v1.pdf">Download PDF</button>

---


**ABSTRACT**  
<b>Foundation</b> <b>Models</b> (FMs) have revolutionized many areas of computing, including Automated Planning and Scheduling (APS). For example, a recent study found them useful for planning problems: plan generation, language translation, model construction, multi-agent planning, interactive planning, heuristics optimization, tool integration, and brain-inspired planning. Besides APS, there are many seemingly related tasks involving the generation of a series of actions with varying guarantees of their executability to achieve intended goals, which we collectively call planning-like (PL) tasks like business processes, programs, workflows, and guidelines, where researchers have considered using FMs. However, previous works have primarily focused on pre-trained, off-the-shelf FMs and optionally <b>fine-tuned</b> them. This paper discusses the need for a comprehensive FM for PL tasks from scratch and explores its design considerations. We argue that such an FM will open new and efficient avenues for PL problem-solving, just like <b>LLMs</b> are creating for APS.

{{</citation>}}


## stat.ML (3)



### (1/3 | 67/126) Multicalibration for Confidence Scoring in LLMs (Gianluca Detommaso et al., 2024)

{{<citation>}}

Gianluca Detommaso, Martin Bertran, Riccardo Fogliato, Aaron Roth. (2024)  
**Multicalibration for Confidence Scoring in LLMs**
<br/>
<button class="copy-to-clipboard" title="Multicalibration for Confidence Scoring in LLMs" index=67>
  <span class="copy-to-clipboard-item">Copy Title<span>
</button>
<div class="toast toast-copied toast-index-67 align-items-center text-bg-secondary border-0 position-absolute top-0 end-0" role="alert" aria-live="assertive" aria-atomic="true">
  <div class="d-flex">
    <div class="toast-body">
      Copied!
    </div>
  </div>
</div>

---
Primary Category: stat.ML  
Categories: cs-CL, cs-LG, stat-ML, stat.ML  
Keyword Score: 49  
Keywords: Benchmarking, Benchmarking, Clustering, Question Answering, Large Language Model, Large Language Model, Prompt  
<a type="button" class="btn btn-outline-primary" href="http://arxiv.org/abs/2404.04689v1" target="_blank" >Paper Link</a>
<button type="button" class="btn btn-outline-primary download-pdf" url="https://arxiv.org/pdf/2404.04689v1.pdf" filename="2404.04689v1.pdf">Download PDF</button>

---


**ABSTRACT**  
This paper proposes the use of "multicalibration" to yield interpretable and reliable confidence scores for outputs generated by <b>large</b> <b>language</b> <b>models</b> <b>(LLMs).</b> Multicalibration asks for calibration not just marginally, but simultaneously across various intersecting groupings of the data. We show how to form groupings for prompt/completion pairs that are correlated with the probability of correctness via two techniques: <b>clustering</b> within an embedding space, and "self-annotation" - querying the <b>LLM</b> by asking it various yes-or-no <b>questions</b> <b>about</b> the <b>prompt.</b> We also develop novel variants of multicalibration algorithms that offer performance improvements by reducing their tendency to overfit. Through systematic <b>benchmarking</b> across various <b>question</b> <b>answering</b> datasets and <b>LLMs,</b> we show how our techniques can yield confidence scores that provide substantial improvements in fine-grained measures of both calibration and accuracy compared to existing methods.

{{</citation>}}


### (2/3 | 68/126) Bayesian Inference for Consistent Predictions in Overparameterized Nonlinear Regression (Tomoya Wakayama, 2024)

{{<citation>}}

Tomoya Wakayama. (2024)  
**Bayesian Inference for Consistent Predictions in Overparameterized Nonlinear Regression**
<br/>
<button class="copy-to-clipboard" title="Bayesian Inference for Consistent Predictions in Overparameterized Nonlinear Regression" index=68>
  <span class="copy-to-clipboard-item">Copy Title<span>
</button>
<div class="toast toast-copied toast-index-68 align-items-center text-bg-secondary border-0 position-absolute top-0 end-0" role="alert" aria-live="assertive" aria-atomic="true">
  <div class="d-flex">
    <div class="toast-body">
      Copied!
    </div>
  </div>
</div>

---
Primary Category: stat.ML  
Categories: cs-LG, stat-ME, stat-ML, stat.ML  
Keyword Score: 20  
Keywords: Simulation, Simulator  
<a type="button" class="btn btn-outline-primary" href="http://arxiv.org/abs/2404.04498v1" target="_blank" >Paper Link</a>
<button type="button" class="btn btn-outline-primary download-pdf" url="https://arxiv.org/pdf/2404.04498v1.pdf" filename="2404.04498v1.pdf">Download PDF</button>

---


**ABSTRACT**  
The remarkable generalization performance of overparameterized models has challenged the conventional wisdom of statistical learning theory. While recent theoretical studies have shed light on this behavior in linear models or nonlinear classifiers, a comprehensive understanding of overparameterization in nonlinear regression remains lacking. This paper explores the predictive properties of overparameterized nonlinear regression within the Bayesian framework, extending the methodology of adaptive prior based on the intrinsic spectral structure of the data. We establish posterior contraction for single-neuron models with Lipschitz continuous activation functions and for generalized linear models, demonstrating that our approach achieves consistent predictions in the overparameterized regime. Moreover, our Bayesian framework allows for uncertainty estimation of the predictions. The proposed method is validated through numerical <b>simulations</b> and a real data application, showcasing its ability to achieve accurate predictions and reliable uncertainty estimates. Our work advances the theoretical understanding of the blessing of overparameterization and offers a principled Bayesian approach for prediction in large nonlinear models.

{{</citation>}}


### (3/3 | 69/126) Demand Balancing in Primal-Dual Optimization for Blind Network Revenue Management (Sentao Miao et al., 2024)

{{<citation>}}

Sentao Miao, Yining Wang. (2024)  
**Demand Balancing in Primal-Dual Optimization for Blind Network Revenue Management**
<br/>
<button class="copy-to-clipboard" title="Demand Balancing in Primal-Dual Optimization for Blind Network Revenue Management" index=69>
  <span class="copy-to-clipboard-item">Copy Title<span>
</button>
<div class="toast toast-copied toast-index-69 align-items-center text-bg-secondary border-0 position-absolute top-0 end-0" role="alert" aria-live="assertive" aria-atomic="true">
  <div class="d-flex">
    <div class="toast-body">
      Copied!
    </div>
  </div>
</div>

---
Primary Category: stat.ML  
Categories: cs-LG, stat-ML, stat.ML  
Keyword Score: 3  
Keywords: Benchmarking  
<a type="button" class="btn btn-outline-primary" href="http://arxiv.org/abs/2404.04467v1" target="_blank" >Paper Link</a>
<button type="button" class="btn btn-outline-primary download-pdf" url="https://arxiv.org/pdf/2404.04467v1.pdf" filename="2404.04467v1.pdf">Download PDF</button>

---


**ABSTRACT**  
This paper proposes a practically efficient algorithm with optimal theoretical regret which solves the classical network revenue management (NRM) problem with unknown, nonparametric demand. Over a time horizon of length $T$, in each time period the retailer needs to decide prices of $N$ types of products which are produced based on $M$ types of resources with unreplenishable initial inventory. When demand is nonparametric with some mild assumptions, Miao and Wang (2021) is the first paper which proposes an algorithm with $O(\text{poly}(N,M,\ln(T))\sqrt{T})$ type of regret (in particular, $\tilde O(N^{3.5}\sqrt{T})$ plus additional high-order terms that are $o(\sqrt{T})$ with sufficiently large $T\gg N$). In this paper, we improve the previous result by proposing a primal-dual optimization algorithm which is not only more practical, but also with an improved regret of $\tilde O(N^{3.25}\sqrt{T})$ free from additional high-order terms. A key technical contribution of the proposed algorithm is the so-called demand balancing, which pairs the primal solution (i.e., the price) in each time period with another price to offset the violation of complementary slackness on resource inventory constraints. Numerical experiments compared with several <b>benchmark</b> algorithms further illustrate the effectiveness of our algorithm.

{{</citation>}}


## cs.MM (1)



### (1/1 | 70/126) TCAN: Text-oriented Cross Attention Network for Multimodal Sentiment Analysis (Ming Zhou et al., 2024)

{{<citation>}}

Ming Zhou, Weize Quan, Ziqi Zhou, Kai Wang, Tong Wang, Dong-Ming Yan. (2024)  
**TCAN: Text-oriented Cross Attention Network for Multimodal Sentiment Analysis**
<br/>
<button class="copy-to-clipboard" title="TCAN: Text-oriented Cross Attention Network for Multimodal Sentiment Analysis" index=70>
  <span class="copy-to-clipboard-item">Copy Title<span>
</button>
<div class="toast toast-copied toast-index-70 align-items-center text-bg-secondary border-0 position-absolute top-0 end-0" role="alert" aria-live="assertive" aria-atomic="true">
  <div class="d-flex">
    <div class="toast-body">
      Copied!
    </div>
  </div>
</div>

---
Primary Category: cs.MM  
Categories: cs-CL, cs-MM, cs.MM  
Keyword Score: 41  
Keywords: Graph Attention Networks, Multi-modal, Multi-modal, Representation Learning, Sentiment Analysis, Self-Attention  
<a type="button" class="btn btn-outline-primary" href="http://arxiv.org/abs/2404.04545v1" target="_blank" >Paper Link</a>
<button type="button" class="btn btn-outline-primary download-pdf" url="https://arxiv.org/pdf/2404.04545v1.pdf" filename="2404.04545v1.pdf">Download PDF</button>

---


**ABSTRACT**  
<b>Multimodal</b> <b>Sentiment</b> <b>Analysis</b> (MSA) endeavors to understand human <b>sentiment</b> <b>by</b> leveraging language, visual, and acoustic modalities. Despite the remarkable performance exhibited by previous MSA approaches, the presence of inherent <b>multimodal</b> heterogeneities poses a challenge, with the contribution of different modalities varying considerably. Past research predominantly focused on improving <b>representation</b> <b>learning</b> techniques and feature fusion strategies. However, many of these efforts overlooked the variation in semantic richness among different modalities, treating each modality uniformly. This approach may lead to underestimating the significance of strong modalities while overemphasizing the importance of weak ones. Motivated by these insights, we introduce a Text-oriented Cross-Attention Network (TCAN), emphasizing the predominant role of the text modality in MSA. Specifically, for each <b>multimodal</b> sample, by taking unaligned sequences of the three modalities as inputs, we initially allocate the extracted unimodal features into a visual-text and an acoustic-text pair. Subsequently, we implement <b>self-attention</b> on the text modality and apply text-queried cross-attention to the visual and acoustic modalities. To mitigate the influence of noise signals and redundant features, we incorporate a <b>gated</b> control mechanism into the framework. Additionally, we introduce unimodal joint learning to gain a deeper understanding of homogeneous emotional tendencies across diverse modalities through backpropagation. Experimental results demonstrate that TCAN consistently outperforms state-of-the-art MSA methods on two datasets (CMU-MOSI and CMU-MOSEI).

{{</citation>}}


## cs.LG (16)



### (1/16 | 71/126) Binary Classifier Optimization for Large Language Model Alignment (Seungjae Jung et al., 2024)

{{<citation>}}

Seungjae Jung, Gunsoo Han, Daniel Wontae Nam, Kyoung-Woon On. (2024)  
**Binary Classifier Optimization for Large Language Model Alignment**
<br/>
<button class="copy-to-clipboard" title="Binary Classifier Optimization for Large Language Model Alignment" index=71>
  <span class="copy-to-clipboard-item">Copy Title<span>
</button>
<div class="toast toast-copied toast-index-71 align-items-center text-bg-secondary border-0 position-absolute top-0 end-0" role="alert" aria-live="assertive" aria-atomic="true">
  <div class="d-flex">
    <div class="toast-body">
      Copied!
    </div>
  </div>
</div>

---
Primary Category: cs.LG  
Categories: cs-AI, cs-CL, cs-LG, cs.LG  
Keyword Score: 40  
Keywords: Direct Preference Optimization, Large Language Model, Large Language Model, Prompt  
<a type="button" class="btn btn-outline-primary" href="http://arxiv.org/abs/2404.04656v1" target="_blank" >Paper Link</a>
<button type="button" class="btn btn-outline-primary download-pdf" url="https://arxiv.org/pdf/2404.04656v1.pdf" filename="2404.04656v1.pdf">Download PDF</button>

---


**ABSTRACT**  
Aligning <b>Large</b> <b>Language</b> <b>Models</b> <b>(LLMs)</b> to human preferences through preference optimization has been crucial but labor-intensive, necessitating for each <b>prompt</b> a comparison of both a chosen and a rejected text completion by evaluators. Recently, Kahneman-Tversky Optimization (KTO) has demonstrated that <b>LLMs</b> can be aligned using merely binary "thumbs-up" or "thumbs-down" signals on each <b>prompt-completion</b> pair. In this paper, we present theoretical foundations to explain the successful alignment achieved through these binary signals. Our analysis uncovers a new perspective: optimizing a binary classifier, whose logit is a reward, implicitly induces minimizing the <b>Direct</b> <b>Preference</b> <b>Optimization</b> (DPO) loss. In the process of this discovery, we identified two techniques for effective alignment: reward shift and underlying distribution matching. Consequently, we propose a new algorithm, \textit{Binary Classifier Optimization}, that integrates the techniques. We validate our methodology in two settings: first, on a paired preference dataset, where our method performs on par with DPO and KTO; and second, on binary signal datasets simulating real-world conditions with divergent underlying distributions between thumbs-up and thumbs-down data. Our model consistently demonstrates effective and robust alignment across two base <b>LLMs</b> and three different binary signal datasets, showcasing the strength of our approach to learning from binary feedback.

{{</citation>}}


### (2/16 | 72/126) Spectral GNN via Two-dimensional (2-D) Graph Convolution (Guoming Li et al., 2024)

{{<citation>}}

Guoming Li, Jian Yang, Shangsong Liang, Dongsheng Luo. (2024)  
**Spectral GNN via Two-dimensional (2-D) Graph Convolution**
<br/>
<button class="copy-to-clipboard" title="Spectral GNN via Two-dimensional (2-D) Graph Convolution" index=72>
  <span class="copy-to-clipboard-item">Copy Title<span>
</button>
<div class="toast toast-copied toast-index-72 align-items-center text-bg-secondary border-0 position-absolute top-0 end-0" role="alert" aria-live="assertive" aria-atomic="true">
  <div class="d-flex">
    <div class="toast-body">
      Copied!
    </div>
  </div>
</div>

---
Primary Category: cs.LG  
Categories: cs-LG, cs-NA, cs.LG, eess-SP, math-NA  
Keyword Score: 36  
Keywords: Graph, Graph Neural Network, Graph Neural Network, Benchmarking, Convolution  
<a type="button" class="btn btn-outline-primary" href="http://arxiv.org/abs/2404.04559v1" target="_blank" >Paper Link</a>
<button type="button" class="btn btn-outline-primary download-pdf" url="https://arxiv.org/pdf/2404.04559v1.pdf" filename="2404.04559v1.pdf">Download PDF</button>

---


**ABSTRACT**  
Spectral <b>Graph</b> <b>Neural</b> <b>Networks</b> <b>(GNNs)</b> have achieved tremendous success in <b>graph</b> <b>learning.</b> <b>As</b> an essential part of spectral <b>GNNs,</b> spectral <b>graph</b> <b>convolution</b> <b>extracts</b> crucial frequency information in <b>graph</b> <b>data,</b> <b>leading</b> to superior performance of spectral <b>GNNs</b> in downstream tasks. However, in this paper, we show that existing spectral <b>GNNs</b> remain critical drawbacks in performing the spectral <b>graph</b> <b>convolution.</b> <b>Specifically,</b> considering the spectral <b>graph</b> <b>convolution</b> <b>as</b> a construction operation towards target output, we prove that existing popular <b>convolution</b> paradigms cannot construct the target output with mild conditions on input <b>graph</b> <b>signals,</b> <b>causing</b> spectral <b>GNNs</b> to fall into suboptimal solutions. To address the issues, we rethink the spectral <b>graph</b> <b>convolution</b> <b>from</b> a more general two-dimensional (2-D) signal <b>convolution</b> perspective and propose a new <b>convolution</b> paradigm, named 2-D <b>graph</b> <b>convolution.</b> <b>We</b> prove that 2-D <b>graph</b> <b>convolution</b> <b>unifies</b> existing <b>graph</b> <b>convolution</b> <b>paradigms,</b> and is capable to construct arbitrary target output. Based on the proposed 2-D <b>graph</b> <b>convolution,</b> <b>we</b> further propose ChebNet2D, an efficient and effective <b>GNN</b> implementation of 2-D <b>graph</b> <b>convolution</b> <b>through</b> applying Chebyshev interpolation. Extensive experiments on <b>benchmark</b> datasets demonstrate both effectiveness and efficiency of the ChebNet2D.

{{</citation>}}


### (3/16 | 73/126) Spectral Graph Pruning Against Over-Squashing and Over-Smoothing (Adarsh Jamadandi et al., 2024)

{{<citation>}}

Adarsh Jamadandi, Celia Rubio-Madrigal, Rebekka Burkholz. (2024)  
**Spectral Graph Pruning Against Over-Squashing and Over-Smoothing**
<br/>
<button class="copy-to-clipboard" title="Spectral Graph Pruning Against Over-Squashing and Over-Smoothing" index=73>
  <span class="copy-to-clipboard-item">Copy Title<span>
</button>
<div class="toast toast-copied toast-index-73 align-items-center text-bg-secondary border-0 position-absolute top-0 end-0" role="alert" aria-live="assertive" aria-atomic="true">
  <div class="d-flex">
    <div class="toast-body">
      Copied!
    </div>
  </div>
</div>

---
Primary Category: cs.LG  
Categories: cs-LG, cs.LG, eess-SP, stat-ML  
Keyword Score: 33  
Keywords: Message-Passing, Graph, Graph Neural Network, Pruning  
<a type="button" class="btn btn-outline-primary" href="http://arxiv.org/abs/2404.04612v1" target="_blank" >Paper Link</a>
<button type="button" class="btn btn-outline-primary download-pdf" url="https://arxiv.org/pdf/2404.04612v1.pdf" filename="2404.04612v1.pdf">Download PDF</button>

---


**ABSTRACT**  
Message Passing <b>Graph</b> <b>Neural</b> <b>Networks</b> are known to suffer from two problems that are sometimes believed to be diametrically opposed: over-squashing and over-smoothing. The former results from topological bottlenecks that hamper the information flow from distant nodes and are mitigated by spectral gap maximization, primarily, by means of edge additions. However, such additions often promote over-smoothing that renders nodes of different classes less distinguishable. Inspired by the Braess phenomenon, we argue that deleting edges can address over-squashing and over-smoothing simultaneously. This insight explains how edge deletions can improve generalization, thus connecting spectral gap optimization to a seemingly disconnected objective of reducing computational resources by <b>pruning</b> <b>graphs</b> <b>for</b> <b>lottery</b> tickets. To this end, we propose a more effective spectral gap optimization framework to add or delete edges and demonstrate its effectiveness on large heterophilic datasets.

{{</citation>}}


### (4/16 | 74/126) Length-Controlled AlpacaEval: A Simple Way to Debias Automatic Evaluators (Yann Dubois et al., 2024)

{{<citation>}}

Yann Dubois, Balzs Galambosi, Percy Liang, Tatsunori B. Hashimoto. (2024)  
**Length-Controlled AlpacaEval: A Simple Way to Debias Automatic Evaluators**
<br/>
<button class="copy-to-clipboard" title="Length-Controlled AlpacaEval: A Simple Way to Debias Automatic Evaluators" index=74>
  <span class="copy-to-clipboard-item">Copy Title<span>
</button>
<div class="toast toast-copied toast-index-74 align-items-center text-bg-secondary border-0 position-absolute top-0 end-0" role="alert" aria-live="assertive" aria-atomic="true">
  <div class="d-flex">
    <div class="toast-body">
      Copied!
    </div>
  </div>
</div>

---
Primary Category: cs.LG  
Categories: cs-AI, cs-CL, cs-LG, cs.LG, stat-ML  
Keyword Score: 33  
Keywords: Benchmarking, Counter-factual, Chatbot, Large Language Model  
<a type="button" class="btn btn-outline-primary" href="http://arxiv.org/abs/2404.04475v1" target="_blank" >Paper Link</a>
<button type="button" class="btn btn-outline-primary download-pdf" url="https://arxiv.org/pdf/2404.04475v1.pdf" filename="2404.04475v1.pdf">Download PDF</button>

---


**ABSTRACT**  
<b>LLM-based</b> auto-annotators have become a key component of the <b>LLM</b> development process due to their cost-effectiveness and scalability compared to human-based evaluation. However, these auto-annotators can introduce complex biases that are hard to remove. Even simple, known confounders such as preference for longer outputs remain in existing automated evaluation metrics. We propose a simple regression analysis approach for controlling biases in auto-evaluations. As a real case study, we focus on reducing the length bias of AlpacaEval, a fast and affordable <b>benchmark</b> for chat <b>LLMs</b> that uses <b>LLMs</b> to estimate response quality. Despite being highly correlated with human preferences, AlpacaEval is known to favor models that generate longer outputs. We introduce a length-controlled AlpacaEval that aims to answer the <b>counterfactual</b> question: "What would the preference be if the model's and baseline's output had the same length?". To achieve this, we first fit a generalized linear model to predict the biased output of interest (auto-annotator preferences) based on the mediators we want to control for (length difference) and other relevant features. We then obtain length-controlled preferences by predicting preferences while conditioning the GLM with a zero difference in lengths. Length-controlling not only improves the robustness of the metric to manipulations in model verbosity, we also find that it increases the Spearman correlation with LMSYS' <b>Chatbot</b> Arena from 0.94 to 0.98. We release the code and leaderboard at https://tatsu-lab.github.io/alpaca_eval/ .

{{</citation>}}


### (5/16 | 75/126) Predictive Modeling for Breast Cancer Classification in the Context of Bangladeshi Patients: A Supervised Machine Learning Approach with Explainable AI (Taminul Islam et al., 2024)

{{<citation>}}

Taminul Islam, Md. Alif Sheakh, Mst. Sazia Tahosin, Most. Hasna Hena, Shopnil Akash, Yousef A. Bin Jardan, Gezahign Fentahun Wondmie, Hiba-Allah Nafidi, Mohammed Bourhia. (2024)  
**Predictive Modeling for Breast Cancer Classification in the Context of Bangladeshi Patients: A Supervised Machine Learning Approach with Explainable AI**
<br/>
<button class="copy-to-clipboard" title="Predictive Modeling for Breast Cancer Classification in the Context of Bangladeshi Patients: A Supervised Machine Learning Approach with Explainable AI" index=75>
  <span class="copy-to-clipboard-item">Copy Title<span>
</button>
<div class="toast toast-copied toast-index-75 align-items-center text-bg-secondary border-0 position-absolute top-0 end-0" role="alert" aria-live="assertive" aria-atomic="true">
  <div class="d-flex">
    <div class="toast-body">
      Copied!
    </div>
  </div>
</div>

---
Primary Category: cs.LG  
Categories: cs-AI, cs-CV, cs-LG, cs.LG  
Keyword Score: 30  
Keywords: Explainable AI, Logistic Regression, Supervised Learning  
<a type="button" class="btn btn-outline-primary" href="http://arxiv.org/abs/2404.04686v1" target="_blank" >Paper Link</a>
<button type="button" class="btn btn-outline-primary download-pdf" url="https://arxiv.org/pdf/2404.04686v1.pdf" filename="2404.04686v1.pdf">Download PDF</button>

---


**ABSTRACT**  
Breast cancer has rapidly increased in prevalence in recent years, making it one of the leading causes of mortality worldwide. Among all cancers, it is by far the most common. Diagnosing this illness manually requires significant time and expertise. Since detecting breast cancer is a time-consuming process, preventing its further spread can be aided by creating machine-based forecasts. Machine learning and <b>Explainable</b> <b>AI</b> are crucial in classification as they not only provide accurate predictions but also offer insights into how the model arrives at its decisions, aiding in the understanding and trustworthiness of the classification results. In this study, we evaluate and compare the classification accuracy, precision, recall, and F-1 scores of five different machine learning methods using a primary dataset (500 patients from Dhaka Medical College Hospital). Five different <b>supervised</b> machine learning techniques, including decision tree, random forest, <b>logistic</b> <b>regression,</b> naive bayes, and XGBoost, have been used to achieve optimal results on our dataset. Additionally, this study applied SHAP analysis to the XGBoost model to interpret the model's predictions and understand the impact of each feature on the model's output. We compared the accuracy with which several algorithms classified the data, as well as contrasted with other literature in this field. After final evaluation, this study found that XGBoost achieved the best model accuracy, which is 97%.

{{</citation>}}


### (6/16 | 76/126) Vanishing Variance Problem in Fully Decentralized Neural-Network Systems (Yongding Tian et al., 2024)

{{<citation>}}

Yongding Tian, Zaid Al-Ars, Maksim Kitsak, Peter Hofstee. (2024)  
**Vanishing Variance Problem in Fully Decentralized Neural-Network Systems**
<br/>
<button class="copy-to-clipboard" title="Vanishing Variance Problem in Fully Decentralized Neural-Network Systems" index=76>
  <span class="copy-to-clipboard-item">Copy Title<span>
</button>
<div class="toast toast-copied toast-index-76 align-items-center text-bg-secondary border-0 position-absolute top-0 end-0" role="alert" aria-live="assertive" aria-atomic="true">
  <div class="d-flex">
    <div class="toast-body">
      Copied!
    </div>
  </div>
</div>

---
Primary Category: cs.LG  
Categories: cs-DC, cs-LG, cs.LG  
Keyword Score: 30  
Keywords: Federated Learning, Simulation, Simulator  
<a type="button" class="btn btn-outline-primary" href="http://arxiv.org/abs/2404.04616v1" target="_blank" >Paper Link</a>
<button type="button" class="btn btn-outline-primary download-pdf" url="https://arxiv.org/pdf/2404.04616v1.pdf" filename="2404.04616v1.pdf">Download PDF</button>

---


**ABSTRACT**  
<b>Federated</b> <b>learning</b> and gossip learning are emerging methodologies designed to mitigate data privacy concerns by retaining training data on client devices and exclusively sharing locally-trained machine learning (ML) models with others. The primary distinction between the two lies in their approach to model aggregation: <b>federated</b> <b>learning</b> employs a centralized parameter server, whereas gossip learning adopts a fully decentralized mechanism, enabling direct model exchanges among nodes. This decentralized nature often positions gossip learning as less efficient compared to <b>federated</b> <b>learning.</b> Both methodologies involve a critical step: computing a representation of received ML models and integrating this representation into the existing model. Conventionally, this representation is derived by averaging the received models, exemplified by the FedAVG algorithm. Our findings suggest that this averaging approach inherently introduces a potential delay in model convergence. We identify the underlying cause and refer to it as the "vanishing variance" problem, where averaging across uncorrelated ML models undermines the optimal variance established by the Xavier weight initialization. Unlike <b>federated</b> <b>learning</b> where the central server ensures model correlation, and unlike traditional gossip learning which circumvents this problem through model partitioning and sampling, our research introduces a variance-corrected model averaging algorithm. This novel algorithm preserves the optimal variance needed during model averaging, irrespective of network topology or non-IID data distributions. Our extensive <b>simulation</b> results demonstrate that our approach enables gossip learning to achieve convergence efficiency comparable to that of <b>federated</b> <b>learning.</b>

{{</citation>}}


### (7/16 | 77/126) To Cool or not to Cool? Temperature Network Meets Large Foundation Models via DRO (Zi-Hao Qiu et al., 2024)

{{<citation>}}

Zi-Hao Qiu, Siqi Guo, Mao Xu, Tuo Zhao, Lijun Zhang, Tianbao Yang. (2024)  
**To Cool or not to Cool? Temperature Network Meets Large Foundation Models via DRO**
<br/>
<button class="copy-to-clipboard" title="To Cool or not to Cool? Temperature Network Meets Large Foundation Models via DRO" index=77>
  <span class="copy-to-clipboard-item">Copy Title<span>
</button>
<div class="toast toast-copied toast-index-77 align-items-center text-bg-secondary border-0 position-absolute top-0 end-0" role="alert" aria-live="assertive" aria-atomic="true">
  <div class="d-flex">
    <div class="toast-body">
      Copied!
    </div>
  </div>
</div>

---
Primary Category: cs.LG  
Categories: cs-AI, cs-LG, cs.LG, math-OC  
Keyword Score: 30  
Keywords: Foundation Model, Large Language Model, Large Language Model  
<a type="button" class="btn btn-outline-primary" href="http://arxiv.org/abs/2404.04575v1" target="_blank" >Paper Link</a>
<button type="button" class="btn btn-outline-primary download-pdf" url="https://arxiv.org/pdf/2404.04575v1.pdf" filename="2404.04575v1.pdf">Download PDF</button>

---


**ABSTRACT**  
The temperature parameter plays a profound role during training and/or inference with <b>large</b> <b>foundation</b> <b>models</b> (LFMs) such as <b>large</b> <b>language</b> <b>models</b> <b>(LLMs)</b> and CLIP models. Particularly, it adjusts the logits in the softmax function in <b>LLMs,</b> which is crucial for next token generation, and it scales the similarities in the contrastive loss for training CLIP models. A significant question remains: Is it viable to learn a neural network to predict a personalized temperature of any input data for enhancing LFMs"? In this paper, we present a principled framework for learning a small yet generalizable temperature prediction network (TempNet) to improve LFMs. Our solution is composed of a novel learning framework with a robust loss underpinned by constrained distributionally robust optimization (DRO), and a properly designed TempNet with theoretical inspiration. TempNet can be trained together with a <b>large</b> <b>foundation</b> <b>model</b> from scratch or learned separately given a pretrained <b>foundation</b> <b>model.</b> It is not only useful for predicting personalized temperature to promote the training of LFMs but also generalizable and transferable to new tasks. Our experiments on <b>LLMs</b> and CLIP models demonstrate that TempNet greatly improves the performance of existing solutions or models, e.g. Table 1. The code to reproduce the experimental results in this paper can be found at https://github.com/zhqiu/TempNet.

{{</citation>}}


### (8/16 | 78/126) Distributed No-Regret Learning for Multi-Stage Systems with End-to-End Bandit Feedback (I-Hong Hou, 2024)

{{<citation>}}

I-Hong Hou. (2024)  
**Distributed No-Regret Learning for Multi-Stage Systems with End-to-End Bandit Feedback**
<br/>
<button class="copy-to-clipboard" title="Distributed No-Regret Learning for Multi-Stage Systems with End-to-End Bandit Feedback" index=78>
  <span class="copy-to-clipboard-item">Copy Title<span>
</button>
<div class="toast toast-copied toast-index-78 align-items-center text-bg-secondary border-0 position-absolute top-0 end-0" role="alert" aria-live="assertive" aria-atomic="true">
  <div class="d-flex">
    <div class="toast-body">
      Copied!
    </div>
  </div>
</div>

---
Primary Category: cs.LG  
Categories: cs-LG, cs-NI, cs.LG  
Keyword Score: 30  
Keywords: Bandit Algorithm, Simulation, Simulator  
<a type="button" class="btn btn-outline-primary" href="http://arxiv.org/abs/2404.04509v1" target="_blank" >Paper Link</a>
<button type="button" class="btn btn-outline-primary download-pdf" url="https://arxiv.org/pdf/2404.04509v1.pdf" filename="2404.04509v1.pdf">Download PDF</button>

---


**ABSTRACT**  
This paper studies multi-stage systems with end-to-end <b>bandit</b> feedback. In such systems, each job needs to go through multiple stages, each managed by a different agent, before generating an outcome. Each agent can only control its own action and learn the final outcome of the job. It has neither knowledge nor control on actions taken by agents in the next stage. The goal of this paper is to develop distributed online learning algorithms that achieve sublinear regret in adversarial environments. The setting of this paper significantly expands the traditional multi-armed <b>bandit</b> problem, which considers only one agent and one stage. In addition to the exploration-exploitation dilemma in the traditional multi-armed <b>bandit</b> problem, we show that the consideration of multiple stages introduces a third component, education, where an agent needs to choose its actions to facilitate the learning of agents in the next stage. To solve this newly introduced exploration-exploitation-education trilemma, we propose a simple distributed online learning algorithm, $\epsilon-$EXP3. We theoretically prove that the $\epsilon-$EXP3 algorithm is a no-regret policy that achieves sublinear regret. <b>Simulation</b> results show that the $\epsilon-$EXP3 algorithm significantly outperforms existing no-regret online learning algorithms for the traditional multi-armed <b>bandit</b> problem.

{{</citation>}}


### (9/16 | 79/126) DELTA: Decoupling Long-Tailed Online Continual Learning (Siddeshwar Raghavan et al., 2024)

{{<citation>}}

Siddeshwar Raghavan, Jiangpeng He, Fengqing Zhu. (2024)  
**DELTA: Decoupling Long-Tailed Online Continual Learning**
<br/>
<button class="copy-to-clipboard" title="DELTA: Decoupling Long-Tailed Online Continual Learning" index=79>
  <span class="copy-to-clipboard-item">Copy Title<span>
</button>
<div class="toast toast-copied toast-index-79 align-items-center text-bg-secondary border-0 position-absolute top-0 end-0" role="alert" aria-live="assertive" aria-atomic="true">
  <div class="d-flex">
    <div class="toast-body">
      Copied!
    </div>
  </div>
</div>

---
Primary Category: cs.LG  
Categories: cs-CV, cs-LG, cs.LG  
Keyword Score: 30  
Keywords: Continual Learning, Contrastive Learning, Supervised Learning  
<a type="button" class="btn btn-outline-primary" href="http://arxiv.org/abs/2404.04476v1" target="_blank" >Paper Link</a>
<button type="button" class="btn btn-outline-primary download-pdf" url="https://arxiv.org/pdf/2404.04476v1.pdf" filename="2404.04476v1.pdf">Download PDF</button>

---


**ABSTRACT**  
A significant challenge in achieving ubiquitous Artificial Intelligence is the limited ability of models to rapidly learn new information in real-world scenarios where data follows long-tailed distributions, all while avoiding forgetting previously acquired knowledge. In this work, we study the under-explored problem of Long-Tailed Online <b>Continual</b> <b>Learning</b> (LTOCL), which aims to learn new tasks from sequentially arriving class-imbalanced data streams. Each data is observed only once for training without knowing the task data distribution. We present DELTA, a decoupled learning approach designed to enhance learning representations and address the substantial imbalance in LTOCL. We enhance the learning process by adapting <b>supervised</b> <b>contrastive</b> <b>learning</b> to attract similar samples and repel dissimilar (out-of-class) samples. Further, by balancing gradients during training using an equalization loss, DELTA significantly enhances learning outcomes and successfully mitigates catastrophic forgetting. Through extensive evaluation, we demonstrate that DELTA improves the capacity for incremental learning, surpassing existing OCL methods. Our results suggest considerable promise for applying OCL in real-world applications.

{{</citation>}}


### (10/16 | 80/126) Compositional Conservatism: A Transductive Approach in Offline Reinforcement Learning (Yeda Song et al., 2024)

{{<citation>}}

Yeda Song, Dongwook Lee, Gunhee Kim. (2024)  
**Compositional Conservatism: A Transductive Approach in Offline Reinforcement Learning**
<br/>
<button class="copy-to-clipboard" title="Compositional Conservatism: A Transductive Approach in Offline Reinforcement Learning" index=80>
  <span class="copy-to-clipboard-item">Copy Title<span>
</button>
<div class="toast toast-copied toast-index-80 align-items-center text-bg-secondary border-0 position-absolute top-0 end-0" role="alert" aria-live="assertive" aria-atomic="true">
  <div class="d-flex">
    <div class="toast-body">
      Copied!
    </div>
  </div>
</div>

---
Primary Category: cs.LG  
Categories: cs-AI, cs-LG, cs-RO, cs.LG  
Keyword Score: 23  
Keywords: Benchmarking, Offline Reinforcement Learning, Reinforcement Learning  
<a type="button" class="btn btn-outline-primary" href="http://arxiv.org/abs/2404.04682v1" target="_blank" >Paper Link</a>
<button type="button" class="btn btn-outline-primary download-pdf" url="https://arxiv.org/pdf/2404.04682v1.pdf" filename="2404.04682v1.pdf">Download PDF</button>

---


**ABSTRACT**  
<b>Offline</b> <b>reinforcement</b> <b>learning</b> (RL) is a compelling framework for learning optimal policies from past experiences without additional interaction with the environment. Nevertheless, <b>offline</b> <b>RL</b> <b>inevitably</b> faces the problem of distributional shifts, where the states and actions encountered during policy execution may not be in the training dataset distribution. A common solution involves incorporating conservatism into the policy or the value function to safeguard against uncertainties and unknowns. In this work, we focus on achieving the same objectives of conservatism but from a different perspective. We propose COmpositional COnservatism with Anchor-seeking (COCOA) for <b>offline</b> <b>RL,</b> <b>an</b> approach that pursues conservatism in a compositional manner on top of the transductive reparameterization (Netanyahu et al., 2023), which decomposes the input variable (the state in our case) into an anchor and its difference from the original input. Our COCOA seeks both in-distribution anchors and differences by utilizing the learned reverse dynamics model, encouraging conservatism in the compositional input space for the policy or value function. Such compositional conservatism is independent of and agnostic to the prevalent behavioral conservatism in <b>offline</b> <b>RL.</b> <b>We</b> apply COCOA to four state-of-the-art <b>offline</b> <b>RL</b> <b>algorithms</b> and evaluate them on the D4RL <b>benchmark,</b> where COCOA generally improves the performance of each algorithm. The code is available at https://github.com/runamu/compositional-conservatism.

{{</citation>}}


### (11/16 | 81/126) The Identification and Categorization of Anemia Through Artificial Neural Networks: A Comparative Analysis of Three Models (Mohammed A. A. Elmaleeh, 2024)

{{<citation>}}

Mohammed A. A. Elmaleeh. (2024)  
**The Identification and Categorization of Anemia Through Artificial Neural Networks: A Comparative Analysis of Three Models**
<br/>
<button class="copy-to-clipboard" title="The Identification and Categorization of Anemia Through Artificial Neural Networks: A Comparative Analysis of Three Models" index=81>
  <span class="copy-to-clipboard-item">Copy Title<span>
</button>
<div class="toast toast-copied toast-index-81 align-items-center text-bg-secondary border-0 position-absolute top-0 end-0" role="alert" aria-live="assertive" aria-atomic="true">
  <div class="d-flex">
    <div class="toast-body">
      Copied!
    </div>
  </div>
</div>

---
Primary Category: cs.LG  
Categories: cs-LG, cs-SY, cs.LG, eess-SY  
Keyword Score: 20  
Keywords: Simulation, Simulator  
<a type="button" class="btn btn-outline-primary" href="http://arxiv.org/abs/2404.04690v1" target="_blank" >Paper Link</a>
<button type="button" class="btn btn-outline-primary download-pdf" url="https://arxiv.org/pdf/2404.04690v1.pdf" filename="2404.04690v1.pdf">Download PDF</button>

---


**ABSTRACT**  
This paper presents different neural network-based classifier algorithms for diagnosing and classifying Anemia. The study compares these classifiers with established models such as Feed Forward Neural Network (FFNN), Elman network, and Non-linear Auto-Regressive Exogenous model (NARX). Experimental evaluations were conducted using data from clinical laboratory test results for 230 patients. The proposed neural network features nine inputs (age, gender, RBC, HGB, HCT, MCV, MCH, MCHC, WBCs) and one output. The <b>simulation</b> outcomes for diverse patients demonstrate that the suggested artificial neural network rapidly and accurately detects the presence of the disease. Consequently, the network could be seamlessly integrated into clinical laboratories for automatic generation of Anemia patients' reports Additionally, the suggested method is affordable and can be deployed on hardware at low costs.

{{</citation>}}


### (12/16 | 82/126) Automatic Gradient Estimation for Calibrating Crowd Models with Discrete Decision Making (Philipp Andelfinger et al., 2024)

{{<citation>}}

Philipp Andelfinger, Justin N. Kreikemeyer. (2024)  
**Automatic Gradient Estimation for Calibrating Crowd Models with Discrete Decision Making**
<br/>
<button class="copy-to-clipboard" title="Automatic Gradient Estimation for Calibrating Crowd Models with Discrete Decision Making" index=82>
  <span class="copy-to-clipboard-item">Copy Title<span>
</button>
<div class="toast toast-copied toast-index-82 align-items-center text-bg-secondary border-0 position-absolute top-0 end-0" role="alert" aria-live="assertive" aria-atomic="true">
  <div class="d-flex">
    <div class="toast-body">
      Copied!
    </div>
  </div>
</div>

---
Primary Category: cs.LG  
Categories: cs-LG, cs-MA, cs.LG  
Keyword Score: 20  
Keywords: Simulation, Simulator  
<a type="button" class="btn btn-outline-primary" href="http://arxiv.org/abs/2404.04678v1" target="_blank" >Paper Link</a>
<button type="button" class="btn btn-outline-primary download-pdf" url="https://arxiv.org/pdf/2404.04678v1.pdf" filename="2404.04678v1.pdf">Download PDF</button>

---


**ABSTRACT**  
Recently proposed gradient estimators enable gradient descent over stochastic programs with discrete jumps in the response surface, which are not covered by automatic differentiation (AD) alone. Although these estimators' capability to guide a swift local search has been shown for certain problems, their applicability to models relevant to real-world applications remains largely unexplored. As the gradients governing the choice in candidate solutions are calculated from sampled <b>simulation</b> trajectories, the optimization procedure bears similarities to metaheuristics such as particle swarm optimization, which puts the focus on the different methods' calibration progress per function evaluation. Here, we consider the calibration of force-based crowd evacuation models based on the popular Social Force model augmented by discrete decision making. After studying the ability of an AD-based estimator for branching programs to capture the <b>simulation's</b> rugged response surface, calibration problems are tackled using gradient descent and two metaheuristics. As our main insights, we find 1) that the estimation's fidelity benefits from disregarding jumps of large magnitude inherent to the Social Force model, and 2) that the common problem of calibration by adjusting a <b>simulation</b> input distribution obviates the need for AD across the Social Force calculations, allowing gradient descent to excel.

{{</citation>}}


### (13/16 | 83/126) Transform then Explore: a Simple and Effective Technique for Exploratory Combinatorial Optimization with Reinforcement Learning (Tianle Pu et al., 2024)

{{<citation>}}

Tianle Pu, Changjun Fan, Mutian Shen, Yizhou Lu, Li Zeng, Zohar Nussinov, Chao Chen, Zhong Liu. (2024)  
**Transform then Explore: a Simple and Effective Technique for Exploratory Combinatorial Optimization with Reinforcement Learning**
<br/>
<button class="copy-to-clipboard" title="Transform then Explore: a Simple and Effective Technique for Exploratory Combinatorial Optimization with Reinforcement Learning" index=83>
  <span class="copy-to-clipboard-item">Copy Title<span>
</button>
<div class="toast toast-copied toast-index-83 align-items-center text-bg-secondary border-0 position-absolute top-0 end-0" role="alert" aria-live="assertive" aria-atomic="true">
  <div class="d-flex">
    <div class="toast-body">
      Copied!
    </div>
  </div>
</div>

---
Primary Category: cs.LG  
Categories: cs-AI, cs-LG, cs.LG  
Keyword Score: 13  
Keywords: Graph, Reinforcement Learning  
<a type="button" class="btn btn-outline-primary" href="http://arxiv.org/abs/2404.04661v1" target="_blank" >Paper Link</a>
<button type="button" class="btn btn-outline-primary download-pdf" url="https://arxiv.org/pdf/2404.04661v1.pdf" filename="2404.04661v1.pdf">Download PDF</button>

---


**ABSTRACT**  
Many complex problems encountered in both production and daily life can be conceptualized as combinatorial optimization problems (COPs) over <b>graphs.</b> Recent years, <b>reinforcement</b> <b>learning</b> (RL) based models have emerged as a promising direction, which treat the COPs solving as a heuristic learning problem. However, current finite-horizon-MDP based RL models have inherent limitations. They are not allowed to explore adquately for improving solutions at test time, which may be necessary given the complexity of NP-hard optimization tasks. Some recent attempts solve this issue by focusing on reward design and state feature engineering, which are tedious and ad-hoc. In this work, we instead propose a much simpler but more effective technique, named gauge transformation (GT). The technique is originated from physics, but is very effective in enabling RL agents to explore to continuously improve the solutions during test. Morever, GT is very simple, which can be implemented with less than 10 lines of Python codes, and can be applied to a vast majority of RL models. Experimentally, we show that traditional RL models with GT technique produce the state-of-the-art performances on the MaxCut problem. Furthermore, since GT is independent of any RL models, it can be seamlessly integrated into various RL frameworks, paving the way of these models for more effective explorations in the solving of general COPs.

{{</citation>}}


### (14/16 | 84/126) Hyperparameter Optimization for SecureBoost via Constrained Multi-Objective Federated Learning (Yan Kang et al., 2024)

{{<citation>}}

Yan Kang, Ziyao Ren, Lixin Fan, Linghua Yang, Yongxin Tong, Qiang Yang. (2024)  
**Hyperparameter Optimization for SecureBoost via Constrained Multi-Objective Federated Learning**
<br/>
<button class="copy-to-clipboard" title="Hyperparameter Optimization for SecureBoost via Constrained Multi-Objective Federated Learning" index=84>
  <span class="copy-to-clipboard-item">Copy Title<span>
</button>
<div class="toast toast-copied toast-index-84 align-items-center text-bg-secondary border-0 position-absolute top-0 end-0" role="alert" aria-live="assertive" aria-atomic="true">
  <div class="d-flex">
    <div class="toast-body">
      Copied!
    </div>
  </div>
</div>

---
Primary Category: cs.LG  
Categories: cs-CR, cs-LG, cs.LG  
Keyword Score: 13  
Keywords: Clustering, Federated Learning  
<a type="button" class="btn btn-outline-primary" href="http://arxiv.org/abs/2404.04490v1" target="_blank" >Paper Link</a>
<button type="button" class="btn btn-outline-primary download-pdf" url="https://arxiv.org/pdf/2404.04490v1.pdf" filename="2404.04490v1.pdf">Download PDF</button>

---


**ABSTRACT**  
SecureBoost is a tree-boosting algorithm that leverages homomorphic encryption (HE) to protect data privacy in vertical <b>federated</b> <b>learning.</b> SecureBoost and its variants have been widely adopted in fields such as finance and healthcare. However, the hyperparameters of SecureBoost are typically configured heuristically for optimizing model performance (i.e., utility) solely, assuming that privacy is secured. Our study found that SecureBoost and some of its variants are still vulnerable to label leakage. This vulnerability may lead the current heuristic hyperparameter configuration of SecureBoost to a suboptimal trade-off between utility, privacy, and efficiency, which are pivotal elements toward a trustworthy <b>federated</b> <b>learning</b> system. To address this issue, we propose the Constrained Multi-Objective SecureBoost (CMOSB) algorithm, which aims to approximate Pareto optimal solutions that each solution is a set of hyperparameters achieving an optimal trade-off between utility loss, training cost, and privacy leakage. We design measurements of the three objectives, including a novel label inference attack named instance <b>clustering</b> attack (ICA) to measure the privacy leakage of SecureBoost. Additionally, we provide two countermeasures against ICA. The experimental results demonstrate that the CMOSB yields superior hyperparameters over those optimized by grid search and Bayesian optimization regarding the trade-off between utility loss, training cost, and privacy leakage.

{{</citation>}}


### (15/16 | 85/126) Domain Generalisation via Imprecise Learning (Anurag Singh et al., 2024)

{{<citation>}}

Anurag Singh, Siu Lun Chau, Shahine Bouabid, Krikamol Muandet. (2024)  
**Domain Generalisation via Imprecise Learning**
<br/>
<button class="copy-to-clipboard" title="Domain Generalisation via Imprecise Learning" index=85>
  <span class="copy-to-clipboard-item">Copy Title<span>
</button>
<div class="toast toast-copied toast-index-85 align-items-center text-bg-secondary border-0 position-absolute top-0 end-0" role="alert" aria-live="assertive" aria-atomic="true">
  <div class="d-flex">
    <div class="toast-body">
      Copied!
    </div>
  </div>
</div>

---
Primary Category: cs.LG  
Categories: cs-LG, cs.LG  
Keyword Score: 10  
Keywords: Out-of-distribution  
<a type="button" class="btn btn-outline-primary" href="http://arxiv.org/abs/2404.04669v1" target="_blank" >Paper Link</a>
<button type="button" class="btn btn-outline-primary download-pdf" url="https://arxiv.org/pdf/2404.04669v1.pdf" filename="2404.04669v1.pdf">Download PDF</button>

---


**ABSTRACT**  
<b>Out-of-distribution</b> (OOD) generalisation is challenging because it involves not only learning from empirical data, but also deciding among various notions of generalisation, e.g., optimising the average-case risk, worst-case risk, or interpolations thereof. While this choice should in principle be made by the model operator like medical doctors, this information might not always be available at training time. The institutional separation between machine learners and model operators leads to arbitrary commitments to specific generalisation strategies by machine learners due to these deployment uncertainties. We introduce the Imprecise Domain Generalisation framework to mitigate this, featuring an imprecise risk optimisation that allows learners to stay imprecise by optimising against a continuous spectrum of generalisation strategies during training, and a model framework that allows operators to specify their generalisation preference at deployment. Supported by both theoretical and empirical evidence, our work showcases the benefits of integrating imprecision into domain generalisation.

{{</citation>}}


### (16/16 | 86/126) Impact of Fairness Regulations on Institutions' Policies and Population Qualifications (Hamidreza Montaseri et al., 2024)

{{<citation>}}

Hamidreza Montaseri, Amin Gohari. (2024)  
**Impact of Fairness Regulations on Institutions' Policies and Population Qualifications**
<br/>
<button class="copy-to-clipboard" title="Impact of Fairness Regulations on Institutions' Policies and Population Qualifications" index=86>
  <span class="copy-to-clipboard-item">Copy Title<span>
</button>
<div class="toast toast-copied toast-index-86 align-items-center text-bg-secondary border-0 position-absolute top-0 end-0" role="alert" aria-live="assertive" aria-atomic="true">
  <div class="d-flex">
    <div class="toast-body">
      Copied!
    </div>
  </div>
</div>

---
Primary Category: cs.LG  
Categories: cs-AI, cs-CY, cs-LG, cs.LG  
Keyword Score: 10  
Keywords: Fairness  
<a type="button" class="btn btn-outline-primary" href="http://arxiv.org/abs/2404.04534v1" target="_blank" >Paper Link</a>
<button type="button" class="btn btn-outline-primary download-pdf" url="https://arxiv.org/pdf/2404.04534v1.pdf" filename="2404.04534v1.pdf">Download PDF</button>

---


**ABSTRACT**  
The proliferation of algorithmic systems has fueled discussions surrounding the regulation and control of their social impact. Herein, we consider a system whose primary objective is to maximize utility by selecting the most qualified individuals. To promote demographic parity in the selection algorithm, we consider penalizing discrimination across social groups. We examine conditions under which a discrimination penalty can effectively reduce disparity in the selection. Additionally, we explore the implications of such a penalty when individual qualifications may evolve over time in response to the imposed penalizing policy. We identify scenarios where the penalty could hinder the natural attainment of equity within the population. Moreover, we propose certain conditions that can counteract this undesirable outcome, thus ensuring <b>fairness.</b>

{{</citation>}}


## cs.NE (2)



### (1/2 | 87/126) Neuroevolving Electronic Dynamical Networks (Derek Whitley, 2024)

{{<citation>}}

Derek Whitley. (2024)  
**Neuroevolving Electronic Dynamical Networks**
<br/>
<button class="copy-to-clipboard" title="Neuroevolving Electronic Dynamical Networks" index=87>
  <span class="copy-to-clipboard-item">Copy Title<span>
</button>
<div class="toast toast-copied toast-index-87 align-items-center text-bg-secondary border-0 position-absolute top-0 end-0" role="alert" aria-live="assertive" aria-atomic="true">
  <div class="d-flex">
    <div class="toast-body">
      Copied!
    </div>
  </div>
</div>

---
Primary Category: cs.NE  
Categories: cs-AI, cs-AR, cs-NE, cs.NE  
Keyword Score: 40  
Keywords: Continuous Time, Continuous Time, Simulation, Simulator, Recurrent Neural Network  
<a type="button" class="btn btn-outline-primary" href="http://arxiv.org/abs/2404.04587v1" target="_blank" >Paper Link</a>
<button type="button" class="btn btn-outline-primary download-pdf" url="https://arxiv.org/pdf/2404.04587v1.pdf" filename="2404.04587v1.pdf">Download PDF</button>

---


**ABSTRACT**  
Neuroevolution is a powerful method of applying an evolutionary algorithm to refine the performance of artificial neural networks through natural selection; however, the fitness evaluation of these networks can be time-consuming and computationally expensive, particularly for <b>continuous</b> <b>time</b> <b>recurrent</b> <b>neural</b> <b>networks</b> (CTRNNs) that necessitate the <b>simulation</b> of differential equations. To overcome this challenge, field programmable gate arrays (FPGAs) have emerged as an increasingly popular solution, due to their high performance and low power consumption. Further, their ability to undergo dynamic and partial reconfiguration enables the extremely rapid evaluation of the fitness of CTRNNs, effectively addressing the bottleneck associated with conventional methods. By incorporating fitness evaluation directly upon the programmable logic of the FPGA, hyper-parallel evaluation becomes feasible, dramatically reducing the time required for assessment. This inherent parallelism of FPGAs accelerates the entire neuroevolutionary process by several orders of magnitude, facilitating faster convergence to an optimal solution. The work presented in this study demonstrates the potential of utilizing dynamic and partial reconfiguration on capable FPGAs as a powerful platform for neuroevolving dynamic neural networks.

{{</citation>}}


### (2/2 | 88/126) Exhaustive Exploitation of Nature-inspired Computation for Cancer Screening in an Ensemble Manner (Xubin Wang et al., 2024)

{{<citation>}}

Xubin Wang, Yunhe Wang, Zhiqing Ma, Ka-Chun Wong, Xiangtao Li. (2024)  
**Exhaustive Exploitation of Nature-inspired Computation for Cancer Screening in an Ensemble Manner**
<br/>
<button class="copy-to-clipboard" title="Exhaustive Exploitation of Nature-inspired Computation for Cancer Screening in an Ensemble Manner" index=88>
  <span class="copy-to-clipboard-item">Copy Title<span>
</button>
<div class="toast toast-copied toast-index-88 align-items-center text-bg-secondary border-0 position-absolute top-0 end-0" role="alert" aria-live="assertive" aria-atomic="true">
  <div class="d-flex">
    <div class="toast-body">
      Copied!
    </div>
  </div>
</div>

---
Primary Category: cs.NE  
Categories: cs-AI, cs-LG, cs-NE, cs.NE  
Keyword Score: 3  
Keywords: Benchmarking  
<a type="button" class="btn btn-outline-primary" href="http://arxiv.org/abs/2404.04547v1" target="_blank" >Paper Link</a>
<button type="button" class="btn btn-outline-primary download-pdf" url="https://arxiv.org/pdf/2404.04547v1.pdf" filename="2404.04547v1.pdf">Download PDF</button>

---


**ABSTRACT**  
Accurate screening of cancer types is crucial for effective cancer detection and precise treatment selection. However, the association between gene expression profiles and tumors is often limited to a small number of biomarker genes. While computational methods using nature-inspired algorithms have shown promise in selecting predictive genes, existing techniques are limited by inefficient search and poor generalization across diverse datasets. This study presents a framework termed Evolutionary Optimized Diverse Ensemble Learning (EODE) to improve ensemble learning for cancer classification from gene expression data. The EODE methodology combines an intelligent grey wolf optimization algorithm for selective feature space reduction, guided random injection modeling for ensemble diversity enhancement, and subset model optimization for synergistic classifier combinations. Extensive experiments were conducted across 35 gene expression <b>benchmark</b> datasets encompassing varied cancer types. Results demonstrated that EODE obtained significantly improved screening accuracy over individual and conventionally aggregated models. The integrated optimization of advanced feature selection, directed specialized modeling, and cooperative classifier ensembles helps address key challenges in current nature-inspired approaches. This provides an effective framework for robust and generalized ensemble learning with gene expression biomarkers. Specifically, we have opened EODE source code on Github at https://github.com/wangxb96/EODE.

{{</citation>}}


## astro-ph.IM (1)



### (1/1 | 89/126) Galaxy 3D Shape Recovery using Mixture Density Network (Suk Yee Yong et al., 2024)

{{<citation>}}

Suk Yee Yong, K. E. Harborne, Caroline Foster, Robert Bassett, Gregory B. Poole, Mitchell Cavanagh. (2024)  
**Galaxy 3D Shape Recovery using Mixture Density Network**
<br/>
<button class="copy-to-clipboard" title="Galaxy 3D Shape Recovery using Mixture Density Network" index=89>
  <span class="copy-to-clipboard-item">Copy Title<span>
</button>
<div class="toast toast-copied toast-index-89 align-items-center text-bg-secondary border-0 position-absolute top-0 end-0" role="alert" aria-live="assertive" aria-atomic="true">
  <div class="d-flex">
    <div class="toast-body">
      Copied!
    </div>
  </div>
</div>

---
Primary Category: astro-ph.IM  
Categories: astro-ph-GA, astro-ph-IM, astro-ph.IM, cs-LG  
Keyword Score: 40  
Keywords: Recommendation, Simulation, Simulator, Supervised Learning  
<a type="button" class="btn btn-outline-primary" href="http://arxiv.org/abs/2404.04491v1" target="_blank" >Paper Link</a>
<button type="button" class="btn btn-outline-primary download-pdf" url="https://arxiv.org/pdf/2404.04491v1.pdf" filename="2404.04491v1.pdf">Download PDF</button>

---


**ABSTRACT**  
Since the turn of the century, astronomers have been exploiting the rich information afforded by combining stellar kinematic maps and imaging in an attempt to recover the intrinsic, three-dimensional (3D) shape of a galaxy. A common intrinsic shape recovery method relies on an expected monotonic relationship between the intrinsic misalignment of the kinematic and morphological axes and the triaxiality parameter. Recent studies have, however, cast doubt about underlying assumptions relating shape and intrinsic kinematic misalignment. In this work, we aim to recover the 3D shape of individual galaxies using their projected stellar kinematic and flux distributions using a <b>supervised</b> machine learning approach with mixture density network (MDN). Using a mock dataset of the EAGLE hydrodynamical cosmological <b>simulation,</b> we train the MDN model for a carefully selected set of common kinematic and photometric parameters. Compared to previous methods, we demonstrate potential improvements achieved with the MDN model to retrieve the 3D galaxy shape along with the uncertainties, especially for prolate and triaxial systems. We make specific <b>recommendations</b> for recovering galaxy intrinsic shapes relevant for current and future integral field spectroscopic galaxy surveys.

{{</citation>}}


## cs.AR (1)



### (1/1 | 90/126) Efficient Sparse Processing-in-Memory Architecture (ESPIM) for Machine Learning Inference (Mingxuan He et al., 2024)

{{<citation>}}

Mingxuan He, Mithuna Thottethodi, T. N. Vijaykumar. (2024)  
**Efficient Sparse Processing-in-Memory Architecture (ESPIM) for Machine Learning Inference**
<br/>
<button class="copy-to-clipboard" title="Efficient Sparse Processing-in-Memory Architecture (ESPIM) for Machine Learning Inference" index=90>
  <span class="copy-to-clipboard-item">Copy Title<span>
</button>
<div class="toast toast-copied toast-index-90 align-items-center text-bg-secondary border-0 position-absolute top-0 end-0" role="alert" aria-live="assertive" aria-atomic="true">
  <div class="d-flex">
    <div class="toast-body">
      Copied!
    </div>
  </div>
</div>

---
Primary Category: cs.AR  
Categories: cs-AR, cs.AR  
Keyword Score: 30  
Keywords: Simulation, Simulator, Transformer  
<a type="button" class="btn btn-outline-primary" href="http://arxiv.org/abs/2404.04708v1" target="_blank" >Paper Link</a>
<button type="button" class="btn btn-outline-primary download-pdf" url="https://arxiv.org/pdf/2404.04708v1.pdf" filename="2404.04708v1.pdf">Download PDF</button>

---


**ABSTRACT**  
Emerging machine learning (ML) models (e.g., <b>transformers)</b> involve memory pin bandwidth-bound matrix-vector (MV) computation in inference. By avoiding pin crossings, processing in memory (PIM) can improve performance and energy for pin-bound workloads, as evidenced by recent commercial efforts in (digital) PIM. Sparse models can improve performance and energy of inference without losing much accuracy. However, unstructured sparse inference injects the key challenges of uncertainty, irregularity, and load imbalance into a dense PIM's operation across all the banks. The dense PIM reads the matrix cells from each bank and broadcasts the vector elements to all the banks exploiting DRAM organization. To address these challenges efficiently, we propose ESPIM which makes four contributions: (1) Because matrix sparsity increases the vector broadcast bandwidth demand per matrix column-read, ESPIM employs a fine-grained interleaving of the matrix cells so that each vector broadcast is shared among multiple rows in each bank, cutting the bandwidth demand. (2) ESPIM mostly avoids on-chip control's area and energy despite sparsity's uncertainties by exploiting the observation that the sparsity is data-dependent but static and known before inference. Accordingly, ESPIM employs static data-dependent scheduling (SDDS) (3) ESPIM decouples the matrix cell values and their indices, placing the indices ahead of the values to enable prefetching of the vector elements. We extend SDDS for performance and correctness with the decoupled prefetching. (4) Finally, we simplify the switch required to select the vector elements that match the matrix cells. We extend SDDS to improve performance by reducing conflicts in the simplified switch. In our <b>simulations,</b> ESPIM achieves 2x average (up to 4.2x) speedup over and 34% average (up to 63%) lower energy than Newton while incurring under 5% area.

{{</citation>}}


## eess.SY (7)



### (1/7 | 91/126) Deep Reinforcement Learning Control for Disturbance Rejection in a Nonlinear Dynamic System with Parametric Uncertainty (Vincent W. Hill, 2024)

{{<citation>}}

Vincent W. Hill. (2024)  
**Deep Reinforcement Learning Control for Disturbance Rejection in a Nonlinear Dynamic System with Parametric Uncertainty**
<br/>
<button class="copy-to-clipboard" title="Deep Reinforcement Learning Control for Disturbance Rejection in a Nonlinear Dynamic System with Parametric Uncertainty" index=91>
  <span class="copy-to-clipboard-item">Copy Title<span>
</button>
<div class="toast toast-copied toast-index-91 align-items-center text-bg-secondary border-0 position-absolute top-0 end-0" role="alert" aria-live="assertive" aria-atomic="true">
  <div class="d-flex">
    <div class="toast-body">
      Copied!
    </div>
  </div>
</div>

---
Primary Category: eess.SY  
Categories: cs-SY, eess-SY, eess.SY  
Keyword Score: 30  
Keywords: Reinforcement Learning, Simulation, Simulator  
<a type="button" class="btn btn-outline-primary" href="http://arxiv.org/abs/2404.04699v1" target="_blank" >Paper Link</a>
<button type="button" class="btn btn-outline-primary download-pdf" url="https://arxiv.org/pdf/2404.04699v1.pdf" filename="2404.04699v1.pdf">Download PDF</button>

---


**ABSTRACT**  
This work describes a technique for active rejection of multiple independent and time-correlated stochastic disturbances for a nonlinear flexible inverted pendulum with cart system with uncertain model parameters. The control law is determined through deep <b>reinforcement</b> <b>learning,</b> specifically with a continuous actor-critic variant of deep Q-learning known as Deep Deterministic Policy Gradient, while the disturbance magnitudes evolve via independent stochastic processes. <b>Simulation</b> results are then compared with those from a classical control system.

{{</citation>}}


### (2/7 | 92/126) Securing the Skies: An IRS-Assisted AoI-Aware Secure Multi-UAV System with Efficient Task Offloading (Poorvi Joshi et al., 2024)

{{<citation>}}

Poorvi Joshi, Alakesh Kalita, Mohan Gurusamy. (2024)  
**Securing the Skies: An IRS-Assisted AoI-Aware Secure Multi-UAV System with Efficient Task Offloading**
<br/>
<button class="copy-to-clipboard" title="Securing the Skies: An IRS-Assisted AoI-Aware Secure Multi-UAV System with Efficient Task Offloading" index=92>
  <span class="copy-to-clipboard-item">Copy Title<span>
</button>
<div class="toast toast-copied toast-index-92 align-items-center text-bg-secondary border-0 position-absolute top-0 end-0" role="alert" aria-live="assertive" aria-atomic="true">
  <div class="d-flex">
    <div class="toast-body">
      Copied!
    </div>
  </div>
</div>

---
Primary Category: eess.SY  
Categories: cs-CR, cs-LG, cs-NI, cs-SY, eess-SY, eess.SY  
Keyword Score: 30  
Keywords: Reinforcement Learning, Transformer, Security  
<a type="button" class="btn btn-outline-primary" href="http://arxiv.org/abs/2404.04692v1" target="_blank" >Paper Link</a>
<button type="button" class="btn btn-outline-primary download-pdf" url="https://arxiv.org/pdf/2404.04692v1.pdf" filename="2404.04692v1.pdf">Download PDF</button>

---


**ABSTRACT**  
Unmanned Aerial Vehicles (UAVs) are integral in various sectors like agriculture, surveillance, and logistics, driven by advancements in 5G. However, existing research lacks a comprehensive approach addressing both data freshness and <b>security</b> concerns. In this paper, we address the intricate challenges of data freshness, and <b>security,</b> especially in the context of eavesdropping and jamming in modern UAV networks. Our framework incorporates exponential AoI metrics and emphasizes secrecy rate to tackle eavesdropping and jamming threats. We introduce a <b>transformer-enhanced</b> Deep <b>Reinforcement</b> <b>Learning</b> (DRL) approach to optimize task offloading processes. Comparative analysis with existing algorithms showcases the superiority of our scheme, indicating its promising advancements in UAV network management.

{{</citation>}}


### (3/7 | 93/126) Self-organizing Multiagent Target Enclosing under Limited Information and Safety Guarantees (Praveen Kumar Ranjan et al., 2024)

{{<citation>}}

Praveen Kumar Ranjan, Abhinav Sinha, Yongcan Cao. (2024)  
**Self-organizing Multiagent Target Enclosing under Limited Information and Safety Guarantees**
<br/>
<button class="copy-to-clipboard" title="Self-organizing Multiagent Target Enclosing under Limited Information and Safety Guarantees" index=93>
  <span class="copy-to-clipboard-item">Copy Title<span>
</button>
<div class="toast toast-copied toast-index-93 align-items-center text-bg-secondary border-0 position-absolute top-0 end-0" role="alert" aria-live="assertive" aria-atomic="true">
  <div class="d-flex">
    <div class="toast-body">
      Copied!
    </div>
  </div>
</div>

---
Primary Category: eess.SY  
Categories: cs-MA, cs-RO, cs-SY, eess-SY, eess.SY, math-OC  
Keyword Score: 25  
Keywords: Geometry, Simulation, Simulator  
<a type="button" class="btn btn-outline-primary" href="http://arxiv.org/abs/2404.04497v1" target="_blank" >Paper Link</a>
<button type="button" class="btn btn-outline-primary download-pdf" url="https://arxiv.org/pdf/2404.04497v1.pdf" filename="2404.04497v1.pdf">Download PDF</button>

---


**ABSTRACT**  
This paper introduces an approach to address the target enclosing problem using non-holonomic multiagent systems, where agents autonomously self-organize themselves in the desired formation around a fixed target. Our approach combines global enclosing behavior and local collision avoidance mechanisms by devising a novel potential function and sliding manifold. In our approach, agents independently move toward the desired enclosing <b>geometry</b> when apart and activate the collision avoidance mechanism when a collision is imminent, thereby guaranteeing inter-agent safety. We rigorously show that an agent does not need to ensure safety with every other agent and put forth a concept of the nearest colliding agent (for any arbitrary agent) with whom ensuring safety is sufficient to avoid collisions in the entire swarm. The proposed control eliminates the need for a fixed or pre-established agent arrangement around the target and requires only relative information between an agent and the target. This makes our design particularly appealing for scenarios with limited global information, hence significantly reducing communication requirements. We finally present <b>simulation</b> results to vindicate the efficacy of the proposed method.

{{</citation>}}


### (4/7 | 94/126) A Two Time-Scale Joint Optimization Approach for UAV-assisted MEC (Zemin Sun et al., 2024)

{{<citation>}}

Zemin Sun, Geng Sun, Long He, Fang Mei, Shuang Liang, Yanheng Liu. (2024)  
**A Two Time-Scale Joint Optimization Approach for UAV-assisted MEC**
<br/>
<button class="copy-to-clipboard" title="A Two Time-Scale Joint Optimization Approach for UAV-assisted MEC" index=94>
  <span class="copy-to-clipboard-item">Copy Title<span>
</button>
<div class="toast toast-copied toast-index-94 align-items-center text-bg-secondary border-0 position-absolute top-0 end-0" role="alert" aria-live="assertive" aria-atomic="true">
  <div class="d-flex">
    <div class="toast-body">
      Copied!
    </div>
  </div>
</div>

---
Primary Category: eess.SY  
Categories: cs-SY, eess-SY, eess.SY  
Keyword Score: 20  
Keywords: Simulation, Simulator  
<a type="button" class="btn btn-outline-primary" href="http://arxiv.org/abs/2404.04597v1" target="_blank" >Paper Link</a>
<button type="button" class="btn btn-outline-primary download-pdf" url="https://arxiv.org/pdf/2404.04597v1.pdf" filename="2404.04597v1.pdf">Download PDF</button>

---


**ABSTRACT**  
Unmanned aerial vehicles (UAV)-assisted mobile edge computing (MEC) is emerging as a promising paradigm to provide aerial-terrestrial computing services close to mobile devices (MDs). However, meeting the demands of computation-intensive and delay-sensitive tasks for MDs poses several challenges, including the demand-supply contradiction between MDs and MEC servers, the demand-supply heterogeneity between MDs and MEC servers, the trajectory control requirements on energy efficiency and timeliness, and the different time-scale dynamics of the network. To address these issues, we first present a hierarchical architecture by incorporating terrestrial-aerial computing capabilities and leveraging UAV flexibility. Furthermore, we formulate a joint computing resource allocation, computation offloading, and trajectory control problem to maximize the system utility. Since the problem is a non-convex mixed integer nonlinear programming (MINLP), we propose a two time-scale joint computing resource allocation, computation offloading, and trajectory control (TJCCT) approach. In the short time scale, we propose a price-incentive method for on-demand computing resource allocation and a matching mechanism-based method for computation offloading. In the long time scale, we propose a convex optimization-based method for UAV trajectory control. Besides, we prove the stability, optimality, and polynomial complexity of TJCCT. <b>Simulation</b> results demonstrate that TJCCT outperforms the comparative algorithms in terms of the utility of the system, the QoE of MDs, and the revenue of MEC servers.

{{</citation>}}


### (5/7 | 95/126) A code-driven tutorial on encrypted control: From pioneering realizations to modern implementations (Nils Schlter et al., 2024)

{{<citation>}}

Nils Schlter, Junsoo Kim, Moritz Schulze Darup. (2024)  
**A code-driven tutorial on encrypted control: From pioneering realizations to modern implementations**
<br/>
<button class="copy-to-clipboard" title="A code-driven tutorial on encrypted control: From pioneering realizations to modern implementations" index=95>
  <span class="copy-to-clipboard-item">Copy Title<span>
</button>
<div class="toast toast-copied toast-index-95 align-items-center text-bg-secondary border-0 position-absolute top-0 end-0" role="alert" aria-live="assertive" aria-atomic="true">
  <div class="d-flex">
    <div class="toast-body">
      Copied!
    </div>
  </div>
</div>

---
Primary Category: eess.SY  
Categories: cs-SY, eess-SY, eess.SY  
Keyword Score: 10  
Keywords: Security  
<a type="button" class="btn btn-outline-primary" href="http://arxiv.org/abs/2404.04727v1" target="_blank" >Paper Link</a>
<button type="button" class="btn btn-outline-primary download-pdf" url="https://arxiv.org/pdf/2404.04727v1.pdf" filename="2404.04727v1.pdf">Download PDF</button>

---


**ABSTRACT**  
The growing interconnectivity in control systems due to robust wireless communication and cloud usage paves the way for exciting new opportunities such as data-driven control and service-based decision-making. At the same time, connected systems are susceptible to cyberattacks and data leakages. Against this background, encrypted control aims to increase the <b>security</b> and safety of cyber-physical systems. A central goal is to ensure confidentiality of process data during networked controller evaluations, which is enabled by, e.g., homomorphic encryption. However, the integration of advanced cryptographic systems renders the design of encrypted controllers an interdisciplinary challenge. This code-driven tutorial paper aims to facilitate the access to encrypted control by providing exemplary realizations based on popular homomorphic cryptosystems. In particular, we discuss the encrypted implementation of state feedback and PI controllers using the Paillier, GSW, and CKKS cryptosystem.

{{</citation>}}


### (6/7 | 96/126) Stability Assessment of Low-Inertia Power Systems: A System Operator Perspective (Manuel Hurtado et al., 2024)

{{<citation>}}

Manuel Hurtado, Mohammad Jafarian, Taulant Kerci, Simon Tweed, Marta Val Escudero, Eoin Kennedy, Federico Milano. (2024)  
**Stability Assessment of Low-Inertia Power Systems: A System Operator Perspective**
<br/>
<button class="copy-to-clipboard" title="Stability Assessment of Low-Inertia Power Systems: A System Operator Perspective" index=96>
  <span class="copy-to-clipboard-item">Copy Title<span>
</button>
<div class="toast toast-copied toast-index-96 align-items-center text-bg-secondary border-0 position-absolute top-0 end-0" role="alert" aria-live="assertive" aria-atomic="true">
  <div class="d-flex">
    <div class="toast-body">
      Copied!
    </div>
  </div>
</div>

---
Primary Category: eess.SY  
Categories: cs-SY, eess-SY, eess.SY  
Keyword Score: 10  
Keywords: Security  
<a type="button" class="btn btn-outline-primary" href="http://arxiv.org/abs/2404.04618v1" target="_blank" >Paper Link</a>
<button type="button" class="btn btn-outline-primary download-pdf" url="https://arxiv.org/pdf/2404.04618v1.pdf" filename="2404.04618v1.pdf">Download PDF</button>

---


**ABSTRACT**  
This paper discusses the stability assessment of low-inertia power systems through a real-world large-scale low-inertia system, namely, the All-Island power system (AIPS) of Ireland and Northern Ireland. This system currently accommodates world-record levels of system non-synchronous penetration namely 75% (planning to increase to 80% next year). The paper discusses one-month results obtained with the state-of-the-art stability tool called look-ahead <b>security</b> assessment (LSAT). This tool carries out rotor-angle, frequency and voltage stability analyses and is implemented in the control centres of the transmission system operators (TSOs). The paper shows that, at the time of writing, the main binding stability constraint of the AIPS is related to the limits on the rate of change of frequency (RoCoF).

{{</citation>}}


### (7/7 | 97/126) Recovery from Adversarial Attacks in Cyber-physical Systems: Shallow, Deep and Exploratory Works (Pengyuan Lu et al., 2024)

{{<citation>}}

Pengyuan Lu, Lin Zhang, Mengyu Liu, Kaustubh Sridhar, Fanxin Kong, Oleg Sokolsky, Insup Lee. (2024)  
**Recovery from Adversarial Attacks in Cyber-physical Systems: Shallow, Deep and Exploratory Works**
<br/>
<button class="copy-to-clipboard" title="Recovery from Adversarial Attacks in Cyber-physical Systems: Shallow, Deep and Exploratory Works" index=97>
  <span class="copy-to-clipboard-item">Copy Title<span>
</button>
<div class="toast toast-copied toast-index-97 align-items-center text-bg-secondary border-0 position-absolute top-0 end-0" role="alert" aria-live="assertive" aria-atomic="true">
  <div class="d-flex">
    <div class="toast-body">
      Copied!
    </div>
  </div>
</div>

---
Primary Category: eess.SY  
Categories: cs-SY, eess-SY, eess.SY  
Keyword Score: 10  
Keywords: Adversarial Attack  
<a type="button" class="btn btn-outline-primary" href="http://arxiv.org/abs/2404.04472v1" target="_blank" >Paper Link</a>
<button type="button" class="btn btn-outline-primary download-pdf" url="https://arxiv.org/pdf/2404.04472v1.pdf" filename="2404.04472v1.pdf">Download PDF</button>

---


**ABSTRACT**  
Cyber-physical systems (CPS) have experienced rapid growth in recent decades. However, like any other computer-based systems, malicious attacks evolve mutually, driving CPS to undesirable physical states and potentially causing catastrophes. Although the current state-of-the-art is well aware of this issue, the majority of researchers have not focused on CPS recovery, the procedure we defined as restoring a CPS's physical state back to a target condition under <b>adversarial</b> <b>attacks.</b> To call for attention on CPS recovery and identify existing efforts, we have surveyed a total of 30 relevant papers. We identify a major partition of the proposed recovery strategies: shallow recovery vs. deep recovery, where the former does not use a dedicated recovery controller while the latter does. Additionally, we surveyed exploratory research on topics that facilitate recovery. From these publications, we discuss the current state-of-the-art of CPS recovery, with respect to applications, attack type, attack surfaces and system dynamics. Then, we identify untouched sub-domains in this field and suggest possible future directions for researchers.

{{</citation>}}


## cs.CR (5)



### (1/5 | 98/126) CANEDERLI: On The Impact of Adversarial Training and Transferability on CAN Intrusion Detection Systems (Francesco Marchiori et al., 2024)

{{<citation>}}

Francesco Marchiori, Mauro Conti. (2024)  
**CANEDERLI: On The Impact of Adversarial Training and Transferability on CAN Intrusion Detection Systems**
<br/>
<button class="copy-to-clipboard" title="CANEDERLI: On The Impact of Adversarial Training and Transferability on CAN Intrusion Detection Systems" index=98>
  <span class="copy-to-clipboard-item">Copy Title<span>
</button>
<div class="toast toast-copied toast-index-98 align-items-center text-bg-secondary border-0 position-absolute top-0 end-0" role="alert" aria-live="assertive" aria-atomic="true">
  <div class="d-flex">
    <div class="toast-body">
      Copied!
    </div>
  </div>
</div>

---
Primary Category: cs.CR  
Categories: cs-CR, cs.CR  
Keyword Score: 30  
Keywords: Adversarial Learning, Fine-tuning, Adversarial Attack  
<a type="button" class="btn btn-outline-primary" href="http://arxiv.org/abs/2404.04648v1" target="_blank" >Paper Link</a>
<button type="button" class="btn btn-outline-primary download-pdf" url="https://arxiv.org/pdf/2404.04648v1.pdf" filename="2404.04648v1.pdf">Download PDF</button>

---


**ABSTRACT**  
The growing integration of vehicles with external networks has led to a surge in attacks targeting their Controller Area Network (CAN) internal bus. As a countermeasure, various Intrusion Detection Systems (IDSs) have been suggested in the literature to prevent and mitigate these threats. With the increasing volume of data facilitated by the integration of Vehicle-to-Vehicle (V2V) and Vehicle-to-Infrastructure (V2I) communication networks, most of these systems rely on data-driven approaches such as Machine Learning (ML) and Deep Learning (DL) models. However, these systems are susceptible to <b>adversarial</b> <b>evasion</b> attacks. While many researchers have explored this vulnerability, their studies often involve unrealistic assumptions, lack consideration for a realistic threat model, and fail to provide effective solutions. In this paper, we present CANEDERLI (CAN Evasion Detection ResiLIence), a novel framework for securing CAN-based IDSs. Our system considers a realistic threat model and addresses the impact of <b>adversarial</b> <b>attacks</b> on DL-based detection systems. Our findings highlight strong transferability properties among diverse attack methodologies by considering multiple state-of-the-art attacks and model architectures. We analyze the impact of <b>adversarial</b> <b>training</b> in addressing this threat and propose an adaptive online <b>adversarial</b> <b>training</b> technique outclassing traditional <b>fine-tuning</b> methodologies with F1 scores up to 0.941. By making our framework publicly available, we aid practitioners and researchers in assessing the resilience of IDSs to a varied <b>adversarial</b> <b>landscape.</b>

{{</citation>}}


### (2/5 | 99/126) Trustless Audits without Revealing Data or Models (Suppakit Waiwitlikhit et al., 2024)

{{<citation>}}

Suppakit Waiwitlikhit, Ion Stoica, Yi Sun, Tatsunori Hashimoto, Daniel Kang. (2024)  
**Trustless Audits without Revealing Data or Models**
<br/>
<button class="copy-to-clipboard" title="Trustless Audits without Revealing Data or Models" index=99>
  <span class="copy-to-clipboard-item">Copy Title<span>
</button>
<div class="toast toast-copied toast-index-99 align-items-center text-bg-secondary border-0 position-absolute top-0 end-0" role="alert" aria-live="assertive" aria-atomic="true">
  <div class="d-flex">
    <div class="toast-body">
      Copied!
    </div>
  </div>
</div>

---
Primary Category: cs.CR  
Categories: cs-AI, cs-CR, cs-CY, cs-LG, cs.CR  
Keyword Score: 30  
Keywords: Counter-factual, Recommender System, Stochastic Gradient Descent  
<a type="button" class="btn btn-outline-primary" href="http://arxiv.org/abs/2404.04500v1" target="_blank" >Paper Link</a>
<button type="button" class="btn btn-outline-primary download-pdf" url="https://arxiv.org/pdf/2404.04500v1.pdf" filename="2404.04500v1.pdf">Download PDF</button>

---


**ABSTRACT**  
There is an increasing conflict between business incentives to hide models and data as trade secrets, and the societal need for algorithmic transparency. For example, a rightsholder wishing to know whether their copyrighted works have been used during training must convince the model provider to allow a third party to audit the model and data. Finding a mutually agreeable third party is difficult, and the associated costs often make this approach impractical. In this work, we show that it is possible to simultaneously allow model providers to keep their model weights (but not architecture) and data secret while allowing other parties to trustlessly audit model and data properties. We do this by designing a protocol called ZkAudit in which model providers publish cryptographic commitments of datasets and model weights, alongside a zero-knowledge proof (ZKP) certifying that published commitments are derived from training the model. Model providers can then respond to audit requests by privately computing any function F of the dataset (or model) and releasing the output of F alongside another ZKP certifying the correct execution of F. To enable ZkAudit, we develop new methods of computing ZKPs for <b>SGD</b> on modern neural nets for simple <b>recommender</b> <b>systems</b> and image classification models capable of high accuracies on ImageNet. Empirically, we show it is possible to provide trustless audits of DNNs, including copyright, censorship, and <b>counterfactual</b> audits with little to no loss in accuracy.

{{</citation>}}


### (3/5 | 100/126) We need to aim at the top: Factors associated with cybersecurity awareness of cyber and information security decision-makers (Simon Vrhovec et al., 2024)

{{<citation>}}

Simon Vrhovec, Bla Markelj. (2024)  
**We need to aim at the top: Factors associated with cybersecurity awareness of cyber and information security decision-makers**
<br/>
<button class="copy-to-clipboard" title="We need to aim at the top: Factors associated with cybersecurity awareness of cyber and information security decision-makers" index=100>
  <span class="copy-to-clipboard-item">Copy Title<span>
</button>
<div class="toast toast-copied toast-index-100 align-items-center text-bg-secondary border-0 position-absolute top-0 end-0" role="alert" aria-live="assertive" aria-atomic="true">
  <div class="d-flex">
    <div class="toast-body">
      Copied!
    </div>
  </div>
</div>

---
Primary Category: cs.CR  
Categories: cs-CR, cs.CR  
Keyword Score: 10  
Keywords: Security  
<a type="button" class="btn btn-outline-primary" href="http://arxiv.org/abs/2404.04725v1" target="_blank" >Paper Link</a>
<button type="button" class="btn btn-outline-primary download-pdf" url="https://arxiv.org/pdf/2404.04725v1.pdf" filename="2404.04725v1.pdf">Download PDF</button>

---


**ABSTRACT**  
Cyberattacks pose a significant business risk to organizations. Although there is ample literature focusing on why people pose a major risk to organizational cybersecurity and how to deal with it, there is surprisingly little we know about cyber and information <b>security</b> decision-makers who are essentially the people in charge of setting up and maintaining organizational cybersecurity. In this paper, we study cybersecurity awareness of cyber and information <b>security</b> decision-makers, and investigate factors associated with it. We conducted an online survey among Slovenian cyber and information <b>security</b> decision-makers (N=283) to (1) determine whether their cybersecurity awareness is associated with adoption of antimalware solutions in their organizations, and (2) explore which organizational factors and personal characteristics are associated with their cybersecurity awareness. Our findings indicate that awareness of well-known threats and solutions seems to be quite low for individuals in decision-making roles. They also provide insights into which threats and solutions are cyber and information <b>security</b> decision-makers the least aware of. We uncovered that awareness of certain threats and solutions is positively associated with either adoption of advanced antimalware solutions with EDR/XDR capabilities or adoption of SOC. Additionally, we identified significant organizational factors (organizational role type) and personal characteristics (gender, age, experience with information <b>security</b> and experience with IT) related to cybersecurity awareness of cyber and information <b>security</b> decision-makers. Organization size and formal education were not significant. These results offer insights that can be leveraged in targeted cybersecurity training tailored to the needs of groups of cyber and information <b>security</b> decision-makers based on these key factors.

{{</citation>}}


### (4/5 | 101/126) Advances in Differential Privacy and Differentially Private Machine Learning (Saswat Das et al., 2024)

{{<citation>}}

Saswat Das, Subhankar Mishra. (2024)  
**Advances in Differential Privacy and Differentially Private Machine Learning**
<br/>
<button class="copy-to-clipboard" title="Advances in Differential Privacy and Differentially Private Machine Learning" index=101>
  <span class="copy-to-clipboard-item">Copy Title<span>
</button>
<div class="toast toast-copied toast-index-101 align-items-center text-bg-secondary border-0 position-absolute top-0 end-0" role="alert" aria-live="assertive" aria-atomic="true">
  <div class="d-flex">
    <div class="toast-body">
      Copied!
    </div>
  </div>
</div>

---
Primary Category: cs.CR  
Categories: cs-CR, cs.CR  
Keyword Score: 10  
Keywords: Differential Privacy  
<a type="button" class="btn btn-outline-primary" href="http://arxiv.org/abs/2404.04706v1" target="_blank" >Paper Link</a>
<button type="button" class="btn btn-outline-primary download-pdf" url="https://arxiv.org/pdf/2404.04706v1.pdf" filename="2404.04706v1.pdf">Download PDF</button>

---


**ABSTRACT**  
There has been an explosion of research on <b>differential</b> <b>privacy</b> (DP) and its various applications in recent years, ranging from novel variants and accounting techniques in <b>differential</b> <b>privacy</b> to the thriving field of differentially private machine learning (DPML) to newer implementations in practice, like those by various companies and organisations such as census bureaus. Most recent surveys focus on the applications of <b>differential</b> <b>privacy</b> in particular contexts like data publishing, specific machine learning tasks, analysis of unstructured data, location privacy, etc. This work thus seeks to fill the gap for a survey that primarily discusses recent developments in the theory of <b>differential</b> <b>privacy</b> along with newer DP variants, viz. Renyi DP and Concentrated DP, novel mechanisms and techniques, and the theoretical developments in differentially private machine learning in proper detail. In addition, this survey discusses its applications to privacy-preserving machine learning in practice and a few practical implementations of DP.

{{</citation>}}


### (5/5 | 102/126) Optimization of Lightweight Malware Detection Models For AIoT Devices (Felicia Lo et al., 2024)

{{<citation>}}

Felicia Lo, Shin-Ming Cheng, Rafael Kaliski. (2024)  
**Optimization of Lightweight Malware Detection Models For AIoT Devices**
<br/>
<button class="copy-to-clipboard" title="Optimization of Lightweight Malware Detection Models For AIoT Devices" index=102>
  <span class="copy-to-clipboard-item">Copy Title<span>
</button>
<div class="toast toast-copied toast-index-102 align-items-center text-bg-secondary border-0 position-absolute top-0 end-0" role="alert" aria-live="assertive" aria-atomic="true">
  <div class="d-flex">
    <div class="toast-body">
      Copied!
    </div>
  </div>
</div>

---
Primary Category: cs.CR  
Categories: cs-CR, cs-LG, cs.CR  
Keyword Score: 10  
Keywords: Meta Learning  
<a type="button" class="btn btn-outline-primary" href="http://arxiv.org/abs/2404.04567v1" target="_blank" >Paper Link</a>
<button type="button" class="btn btn-outline-primary download-pdf" url="https://arxiv.org/pdf/2404.04567v1.pdf" filename="2404.04567v1.pdf">Download PDF</button>

---


**ABSTRACT**  
Malware intrusion is problematic for Internet of Things (IoT) and Artificial Intelligence of Things (AIoT) devices as they often reside in an ecosystem of connected devices, such as a smart home. If any devices are infected, the whole ecosystem can be compromised. Although various Machine Learning (ML) models are deployed to detect malware and network intrusion, generally speaking, robust high-accuracy models tend to require resources not found in all IoT devices, compared to less robust models defined by weak learners. In order to combat this issue, Fadhilla proposed a <b>meta-learner</b> <b>ensemble</b> model comprised of less robust prediction results inherent with weak learner ML models to produce a highly robust <b>meta-learning</b> <b>ensemble</b> model. The main problem with the prior research is that it cannot be deployed in low-end AIoT devices due to the limited resources comprising processing power, storage, and memory (the required libraries quickly exhaust low-end AIoT devices' resources.) Hence, this research aims to optimize the proposed super learner <b>meta-learning</b> <b>ensemble</b> model to make it viable for low-end AIoT devices. We show the library and ML model memory requirements associated with each optimization stage and emphasize that optimization of current ML models is necessitated for low-end AIoT devices. Our results demonstrate that we can obtain similar accuracy and False Positive Rate (FPR) metrics from high-end AIoT devices running the derived ML model, with a lower inference duration and smaller memory footprint.

{{</citation>}}


## cs.HC (3)



### (1/3 | 103/126) Analyzing LLM Usage in an Advanced Computing Class in India (Chaitanya Arora et al., 2024)

{{<citation>}}

Chaitanya Arora, Utkarsh Venaik, Pavit Singh, Sahil Goyal, Jatin Tyagi, Shyama Goel, Ujjwal Singhal, Dhruv Kumar. (2024)  
**Analyzing LLM Usage in an Advanced Computing Class in India**
<br/>
<button class="copy-to-clipboard" title="Analyzing LLM Usage in an Advanced Computing Class in India" index=103>
  <span class="copy-to-clipboard-item">Copy Title<span>
</button>
<div class="toast toast-copied toast-index-103 align-items-center text-bg-secondary border-0 position-absolute top-0 end-0" role="alert" aria-live="assertive" aria-atomic="true">
  <div class="d-flex">
    <div class="toast-body">
      Copied!
    </div>
  </div>
</div>

---
Primary Category: cs.HC  
Categories: cs-CY, cs-HC, cs.HC  
Keyword Score: 30  
Keywords: Large Language Model, Large Language Model, Prompt  
<a type="button" class="btn btn-outline-primary" href="http://arxiv.org/abs/2404.04603v1" target="_blank" >Paper Link</a>
<button type="button" class="btn btn-outline-primary download-pdf" url="https://arxiv.org/pdf/2404.04603v1.pdf" filename="2404.04603v1.pdf">Download PDF</button>

---


**ABSTRACT**  
This paper investigates the usage patterns of undergraduate and graduate students when engaging with <b>large</b> <b>language</b> <b>models</b> <b>(LLMs)</b> to tackle programming assignments in the context of advanced computing courses. Existing work predominantly focuses on the influence of <b>LLMs</b> in introductory programming contexts. Additionally, there is a scarcity of studies analyzing actual conversations between students and <b>LLMs.</b> Our study provides a comprehensive quantitative and qualitative analysis of raw interactions between students and <b>LLMs</b> within an advanced computing course (Distributed Systems) at an Indian University. We further complement this by conducting student interviews to gain deeper insights into their usage patterns. Our study shows that students make use of <b>large</b> <b>language</b> <b>models</b> <b>(LLMs)</b> in various ways: generating code or debugging code by identifying and fixing errors. They also copy and paste assignment descriptions into <b>LLM</b> interfaces for specific solutions, ask conceptual questions about complex programming ideas or theoretical concepts, and generate test cases to check code functionality and robustness. Our analysis includes over 4,000 <b>prompts</b> from 411 students and conducting interviews with 10 students. Our analysis shows that <b>LLMs</b> excel at generating boilerplate code and assisting in debugging, while students handle the integration of components and system troubleshooting. This aligns with the learning objectives of advanced computing courses, which are oriented towards teaching students how to build systems and troubleshoot, with less emphasis on generating code from scratch. Therefore, <b>LLM</b> tools can be leveraged to increase student productivity, as shown by the data we collected. This study contributes to the ongoing discussion on <b>LLM</b> use in education, advocating for their usefulness in advanced computing courses to complement higher-level learning and productivity.

{{</citation>}}


### (2/3 | 104/126) A Map of Exploring Human Interaction patterns with LLM: Insights into Collaboration and Creativity (Jiayang Li et al., 2024)

{{<citation>}}

Jiayang Li, Jiale Li. (2024)  
**A Map of Exploring Human Interaction patterns with LLM: Insights into Collaboration and Creativity**
<br/>
<button class="copy-to-clipboard" title="A Map of Exploring Human Interaction patterns with LLM: Insights into Collaboration and Creativity" index=104>
  <span class="copy-to-clipboard-item">Copy Title<span>
</button>
<div class="toast toast-copied toast-index-104 align-items-center text-bg-secondary border-0 position-absolute top-0 end-0" role="alert" aria-live="assertive" aria-atomic="true">
  <div class="d-flex">
    <div class="toast-body">
      Copied!
    </div>
  </div>
</div>

---
Primary Category: cs.HC  
Categories: cs-HC, cs.HC  
Keyword Score: 23  
Keywords: Clustering, Large Language Model, Large Language Model  
<a type="button" class="btn btn-outline-primary" href="http://arxiv.org/abs/2404.04570v1" target="_blank" >Paper Link</a>
<button type="button" class="btn btn-outline-primary download-pdf" url="https://arxiv.org/pdf/2404.04570v1.pdf" filename="2404.04570v1.pdf">Download PDF</button>

---


**ABSTRACT**  
The outstanding performance capabilities of <b>large</b> <b>language</b> <b>model</b> have driven the evolution of current AI system interaction patterns. This has led to considerable discussion within the Human-AI Interaction (HAII) community. Numerous studies explore this interaction from technical, design, and empirical perspectives. However, the majority of current literature reviews concentrate on interactions across the wider spectrum of AI, with limited attention given to the specific realm of interaction with <b>LLM.</b> We searched for articles on human interaction with <b>LLM,</b> selecting 110 relevant publications meeting consensus definition of Human-AI interaction. Subsequently, we developed a comprehensive Mapping Procedure, structured in five distinct stages, to systematically analyze and categorize the collected publications. Applying this methodical approach, we meticulously mapped the chosen studies, culminating in a detailed and insightful representation of the research landscape. Overall, our review presents an novel approach, introducing a distinctive mapping method, specifically tailored to evaluate human-LLM interaction patterns. We conducted a comprehensive analysis of the current research in related fields, employing <b>clustering</b> techniques for categorization, which enabled us to clearly delineate the status and challenges prevalent in each identified area.

{{</citation>}}


### (3/3 | 105/126) Designing for Complementarity: A Conceptual Framework to Go Beyond the Current Paradigm of Using XAI in Healthcare (Elisa Rubegni et al., 2024)

{{<citation>}}

Elisa Rubegni, Omran Ayoub, Stefania Maria Rita Rizzo, Marco Barbero, Guenda Bernegger, Francesca Faraci, Francesca Mangili, Emiliano Soldini, Pierpaolo Trimboli, Alessandro Facchini. (2024)  
**Designing for Complementarity: A Conceptual Framework to Go Beyond the Current Paradigm of Using XAI in Healthcare**
<br/>
<button class="copy-to-clipboard" title="Designing for Complementarity: A Conceptual Framework to Go Beyond the Current Paradigm of Using XAI in Healthcare" index=105>
  <span class="copy-to-clipboard-item">Copy Title<span>
</button>
<div class="toast toast-copied toast-index-105 align-items-center text-bg-secondary border-0 position-absolute top-0 end-0" role="alert" aria-live="assertive" aria-atomic="true">
  <div class="d-flex">
    <div class="toast-body">
      Copied!
    </div>
  </div>
</div>

---
Primary Category: cs.HC  
Categories: cs-HC, cs.HC  
Keyword Score: 5  
Keywords: Black Box  
<a type="button" class="btn btn-outline-primary" href="http://arxiv.org/abs/2404.04638v1" target="_blank" >Paper Link</a>
<button type="button" class="btn btn-outline-primary download-pdf" url="https://arxiv.org/pdf/2404.04638v1.pdf" filename="2404.04638v1.pdf">Download PDF</button>

---


**ABSTRACT**  
The widespread use of Artificial Intelligence-based tools in the healthcare sector raises many ethical and legal problems, one of the main reasons being their <b>black-box</b> <b>nature</b> and therefore the seemingly opacity and inscrutability of their characteristics and decision-making process. Literature extensively discusses how this can lead to phenomena of over-reliance and under-reliance, ultimately limiting the adoption of AI. We addressed these issues by building a theoretical framework based on three concepts: Feature Importance, Counterexample Explanations, and Similar-Case Explanations. Grounded in the literature, the model was deployed within a case study in which, using a participatory design approach, we designed and developed a high-fidelity prototype. Through the co-design and development of the prototype and the underlying model, we advanced the knowledge on how to design AI-based systems for enabling complementarity in the decision-making process in the healthcare domain. Our work aims at contributing to the current discourse on designing AI systems to support clinicians' decision-making processes.

{{</citation>}}


## cs.RO (1)



### (1/1 | 106/126) Constrained 6-DoF Grasp Generation on Complex Shapes for Improved Dual-Arm Manipulation (Gaurav Singh et al., 2024)

{{<citation>}}

Gaurav Singh, Sanket Kalwar, Md Faizal Karim, Bipasha Sen, Nagamanikandan Govindan, Srinath Sridhar, K Madhava Krishna. (2024)  
**Constrained 6-DoF Grasp Generation on Complex Shapes for Improved Dual-Arm Manipulation**
<br/>
<button class="copy-to-clipboard" title="Constrained 6-DoF Grasp Generation on Complex Shapes for Improved Dual-Arm Manipulation" index=106>
  <span class="copy-to-clipboard-item">Copy Title<span>
</button>
<div class="toast toast-copied toast-index-106 align-items-center text-bg-secondary border-0 position-absolute top-0 end-0" role="alert" aria-live="assertive" aria-atomic="true">
  <div class="d-flex">
    <div class="toast-body">
      Copied!
    </div>
  </div>
</div>

---
Primary Category: cs.RO  
Categories: cs-CV, cs-RO, cs.RO  
Keyword Score: 25  
Keywords: Geometry, Simulation, Simulator  
<a type="button" class="btn btn-outline-primary" href="http://arxiv.org/abs/2404.04643v1" target="_blank" >Paper Link</a>
<button type="button" class="btn btn-outline-primary download-pdf" url="https://arxiv.org/pdf/2404.04643v1.pdf" filename="2404.04643v1.pdf">Download PDF</button>

---


**ABSTRACT**  
Efficiently generating grasp poses tailored to specific regions of an object is vital for various robotic manipulation tasks, especially in a dual-arm setup. This scenario presents a significant challenge due to the complex geometries involved, requiring a deep understanding of the local <b>geometry</b> to generate grasps efficiently on the specified constrained regions. Existing methods only explore settings involving table-top/small objects and require augmented datasets to train, limiting their performance on complex objects. We propose CGDF: Constrained Grasp Diffusion Fields, a diffusion-based grasp generative model that generalizes to objects with arbitrary geometries, as well as generates dense grasps on the target regions. CGDF uses a part-guided diffusion approach that enables it to get high sample efficiency in constrained grasping without explicitly training on massive constraint-augmented datasets. We provide qualitative and quantitative comparisons using analytical metrics and in <b>simulation,</b> in both unconstrained and constrained settings to show that our method can generalize to generate stable grasps on complex objects, especially useful for dual-arm manipulation settings, while existing methods struggle to do so.

{{</citation>}}


## physics.flu-dyn (1)



### (1/1 | 107/126) PointSAGE: Mesh-independent superresolution approach to fluid flow predictions (Rajat Sarkar et al., 2024)

{{<citation>}}

Rajat Sarkar, Krishna Sai Sudhir Aripirala, Vishal Sudam Jadhav, Sagar Srinivas Sakhinana, Venkataramana Runkana. (2024)  
**PointSAGE: Mesh-independent superresolution approach to fluid flow predictions**
<br/>
<button class="copy-to-clipboard" title="PointSAGE: Mesh-independent superresolution approach to fluid flow predictions" index=107>
  <span class="copy-to-clipboard-item">Copy Title<span>
</button>
<div class="toast toast-copied toast-index-107 align-items-center text-bg-secondary border-0 position-absolute top-0 end-0" role="alert" aria-live="assertive" aria-atomic="true">
  <div class="d-flex">
    <div class="toast-body">
      Copied!
    </div>
  </div>
</div>

---
Primary Category: physics.flu-dyn  
Categories: cs-AI, cs-LG, physics-flu-dyn, physics.flu-dyn  
Keyword Score: 25  
Keywords: Geometry, Simulation, Simulator  
<a type="button" class="btn btn-outline-primary" href="http://arxiv.org/abs/2404.04615v1" target="_blank" >Paper Link</a>
<button type="button" class="btn btn-outline-primary download-pdf" url="https://arxiv.org/pdf/2404.04615v1.pdf" filename="2404.04615v1.pdf">Download PDF</button>

---


**ABSTRACT**  
Computational Fluid Dynamics (CFD) serves as a powerful tool for simulating fluid flow across diverse industries. High-resolution CFD <b>simulations</b> offer valuable insights into fluid behavior and flow patterns, aiding in optimizing design features or enhancing system performance. However, as resolution increases, computational data requirements and time increase proportionately. This presents a persistent challenge in CFD. Recently, efforts have been directed towards accurately predicting fine-mesh <b>simulations</b> using coarse-mesh <b>simulations,</b> with <b>geometry</b> and boundary conditions as input. Drawing inspiration from models designed for super-resolution, deep learning techniques like UNets have been applied to address this challenge. However, these existing methods are limited to structured data and fail if the mesh is unstructured due to its inability to convolute. Additionally, incorporating geometry/mesh information in the training process introduces drawbacks such as increased data requirements, challenges in generalizing to unseen geometries for the same physical phenomena, and issues with robustness to mesh distortions. To address these concerns, we propose a novel framework, PointSAGE a mesh-independent network that leverages the unordered, mesh-less nature of Pointcloud to learn the complex fluid flow and directly predict fine <b>simulations,</b> completely neglecting mesh information. Utilizing an adaptable framework, the model accurately predicts the fine data across diverse point cloud sizes, regardless of the training dataset's dimension. We have evaluated the effectiveness of PointSAGE on diverse datasets in different scenarios, demonstrating notable results and a significant acceleration in computational time in generating fine <b>simulations</b> compared to standard CFD techniques.

{{</citation>}}


## cs.SE (2)



### (1/2 | 108/126) Towards Better Graph Neural Neural Network-based Fault Localization Through Enhanced Code Representation (Md Nakhla Rafi et al., 2024)

{{<citation>}}

Md Nakhla Rafi, Dong Jae Kim, An Ran Chen, Tse-Hsun Chen, Shaowei Wang. (2024)  
**Towards Better Graph Neural Neural Network-based Fault Localization Through Enhanced Code Representation**
<br/>
<button class="copy-to-clipboard" title="Towards Better Graph Neural Neural Network-based Fault Localization Through Enhanced Code Representation" index=108>
  <span class="copy-to-clipboard-item">Copy Title<span>
</button>
<div class="toast toast-copied toast-index-108 align-items-center text-bg-secondary border-0 position-absolute top-0 end-0" role="alert" aria-live="assertive" aria-atomic="true">
  <div class="d-flex">
    <div class="toast-body">
      Copied!
    </div>
  </div>
</div>

---
Primary Category: cs.SE  
Categories: cs-SE, cs.SE  
Keyword Score: 23  
Keywords: Graph, Graph Neural Network, Graph Neural Network  
<a type="button" class="btn btn-outline-primary" href="http://arxiv.org/abs/2404.04496v1" target="_blank" >Paper Link</a>
<button type="button" class="btn btn-outline-primary download-pdf" url="https://arxiv.org/pdf/2404.04496v1.pdf" filename="2404.04496v1.pdf">Download PDF</button>

---


**ABSTRACT**  
Automatic software fault localization plays an important role in software quality assurance by pinpointing faulty locations for easier debugging. Coverage-based fault localization, a widely used technique, employs statistics on coverage spectra to rank code based on suspiciousness scores. However, the rigidity of statistical approaches calls for learning-based techniques. Amongst all, Grace, a <b>graph-neural</b> <b>network</b> <b>(GNN)</b> based technique has achieved state-of-the-art due to its capacity to preserve coverage spectra, i.e., test-to-source coverage relationships, as precise abstract syntax-enhanced <b>graph</b> <b>representation,</b> <b>mitigating</b> the limitation of other learning-based technique which compresses the feature representation. However, such representation struggles with scalability due to the increasing complexity of software and associated coverage spectra and AST <b>graphs.</b> <b>In</b> <b>this</b> work, we proposed a new <b>graph</b> <b>representation,</b> <b>DepGraph,</b> that reduces the complexity of the <b>graph</b> <b>representation</b> <b>by</b> 70% in nodes and edges by integrating interprocedural call <b>graph</b> <b>in</b> <b>the</b> <b>graph</b> <b>representation</b> <b>of</b> the code. Moreover, we integrate additional features such as code change information in the <b>graph</b> <b>as</b> <b>attributes</b> so the model can leverage rich historical project data. We evaluate DepGraph using Defects4j 2.0.0, and it outperforms Grace by locating 20% more faults in Top-1 and improving the Mean First Rank (MFR) and the Mean Average Rank (MAR) by over 50% while decreasing GPU memory usage by 44% and training/inference time by 85%. Additionally, in cross-project settings, DepGraph surpasses the state-of-the-art baseline with a 42% higher Top-1 accuracy, and 68% and 65% improvement in MFR and MAR, respectively. Our study demonstrates DepGraph's robustness, achieving state-of-the-art accuracy and scalability for future extension and adoption.

{{</citation>}}


### (2/2 | 109/126) Efficient and Green Large Language Models for Software Engineering: Vision and the Road Ahead (Jieke Shi et al., 2024)

{{<citation>}}

Jieke Shi, Zhou Yang, David Lo. (2024)  
**Efficient and Green Large Language Models for Software Engineering: Vision and the Road Ahead**
<br/>
<button class="copy-to-clipboard" title="Efficient and Green Large Language Models for Software Engineering: Vision and the Road Ahead" index=109>
  <span class="copy-to-clipboard-item">Copy Title<span>
</button>
<div class="toast toast-copied toast-index-109 align-items-center text-bg-secondary border-0 position-absolute top-0 end-0" role="alert" aria-live="assertive" aria-atomic="true">
  <div class="d-flex">
    <div class="toast-body">
      Copied!
    </div>
  </div>
</div>

---
Primary Category: cs.SE  
Categories: cs-SE, cs.SE  
Keyword Score: 20  
Keywords: Large Language Model, Large Language Model  
<a type="button" class="btn btn-outline-primary" href="http://arxiv.org/abs/2404.04566v1" target="_blank" >Paper Link</a>
<button type="button" class="btn btn-outline-primary download-pdf" url="https://arxiv.org/pdf/2404.04566v1.pdf" filename="2404.04566v1.pdf">Download PDF</button>

---


**ABSTRACT**  
<b>Large</b> <b>Language</b> <b>Models</b> <b>(LLMs)</b> have recently shown remarkable capabilities in various software engineering tasks, spurring the rapid development of the <b>Large</b> <b>Language</b> <b>Models</b> for Software Engineering (LLM4SE) area. However, limited attention has been paid to crafting efficient LLM4SE solutions that demand minimal time and memory resources, as well as green LLM4SE solutions that reduce energy consumption and carbon emissions. This 2030 Software Engineering position paper aims to redirect the focus of the research community towards the efficiency and greenness of LLM4SE, while also sharing potential research directions to achieve this goal. It commences with a brief overview of the significance of LLM4SE and highlights the need for efficient and green LLM4SE solutions. Subsequently, the paper presents a vision for a future where efficient and green LLM4SE revolutionizes the software engineering tool landscape, benefiting various stakeholders, including industry, individual practitioners, and society. The paper then delineates a roadmap for future research, outlining specific research paths and potential solutions for the research community to pursue. While not intended to be a definitive guide, the paper aims to inspire further progress, with the ultimate goal of establishing efficient and green LLM4SE as a central element in the future of software engineering.

{{</citation>}}


## cs.IR (1)



### (1/1 | 110/126) Joint Identifiability of Cross-Domain Recommendation via Hierarchical Subspace Disentanglement (Jing Du et al., 2024)

{{<citation>}}

Jing Du, Zesheng Ye, Bin Guo, Zhiwen Yu, Lina Yao. (2024)  
**Joint Identifiability of Cross-Domain Recommendation via Hierarchical Subspace Disentanglement**
<br/>
<button class="copy-to-clipboard" title="Joint Identifiability of Cross-Domain Recommendation via Hierarchical Subspace Disentanglement" index=110>
  <span class="copy-to-clipboard-item">Copy Title<span>
</button>
<div class="toast toast-copied toast-index-110 align-items-center text-bg-secondary border-0 position-absolute top-0 end-0" role="alert" aria-live="assertive" aria-atomic="true">
  <div class="d-flex">
    <div class="toast-body">
      Copied!
    </div>
  </div>
</div>

---
Primary Category: cs.IR  
Categories: cs-AI, cs-IR, cs-LG, cs.IR  
Keyword Score: 23  
Keywords: Graph, Knowledge Transfer, Recommendation  
<a type="button" class="btn btn-outline-primary" href="http://arxiv.org/abs/2404.04481v1" target="_blank" >Paper Link</a>
<button type="button" class="btn btn-outline-primary download-pdf" url="https://arxiv.org/pdf/2404.04481v1.pdf" filename="2404.04481v1.pdf">Download PDF</button>

---


**ABSTRACT**  
Cross-Domain <b>Recommendation</b> (CDR) seeks to enable effective <b>knowledge</b> <b>transfer</b> across domains. Existing works rely on either representation alignment or transformation bridges, but they struggle on identifying domain-shared from domain-specific latent factors. Specifically, while CDR describes user representations as a joint distribution over two domains, these methods fail to account for its joint identifiability as they primarily fixate on the marginal distribution within a particular domain. Such a failure may overlook the conditionality between two domains and how it contributes to latent factor disentanglement, leading to negative transfer when domains are weakly correlated. In this study, we explore what should and should not be transferred in cross-domain user representations from a causality perspective. We propose a Hierarchical subspace disentanglement approach to explore the Joint IDentifiability of cross-domain joint distribution, termed HJID, to preserve domain-specific behaviors from domain-shared factors. HJID organizes user representations into layers: generic shallow subspaces and domain-oriented deep subspaces. We first encode the generic pattern in the shallow subspace by minimizing the Maximum Mean Discrepancy of initial layer activation. Then, to dissect how domain-oriented latent factors are encoded in deeper layers activation, we construct a cross-domain causality-based data generation <b>graph,</b> which identifies cross-domain consistent and domain-specific components, adhering to the Minimal Change principle. This allows HJID to maintain stability whilst discovering unique factors for different domains, all within a generative framework of invertible transformations that guarantee the joint identifiability. With experiments on real-world datasets, we show that HJID outperforms SOTA methods on a range of strongly and weakly correlated CDR tasks.

{{</citation>}}


## cs.NI (3)



### (1/3 | 111/126) RIS in Cellular Networks -- Challenges and Issues (Magnus strm et al., 2024)

{{<citation>}}

Magnus strm, Philipp Gentner, Omer Haliloglu, Behrooz Makki, Ola Tageman. (2024)  
**RIS in Cellular Networks -- Challenges and Issues**
<br/>
<button class="copy-to-clipboard" title="RIS in Cellular Networks -- Challenges and Issues" index=111>
  <span class="copy-to-clipboard-item">Copy Title<span>
</button>
<div class="toast toast-copied toast-index-111 align-items-center text-bg-secondary border-0 position-absolute top-0 end-0" role="alert" aria-live="assertive" aria-atomic="true">
  <div class="d-flex">
    <div class="toast-body">
      Copied!
    </div>
  </div>
</div>

---
Primary Category: cs.NI  
Categories: cs-IT, cs-NI, cs.NI, math-IT  
Keyword Score: 20  
Keywords: Simulation, Simulator  
<a type="button" class="btn btn-outline-primary" href="http://arxiv.org/abs/2404.04753v1" target="_blank" >Paper Link</a>
<button type="button" class="btn btn-outline-primary download-pdf" url="https://arxiv.org/pdf/2404.04753v1.pdf" filename="2404.04753v1.pdf">Download PDF</button>

---


**ABSTRACT**  
Reconfigurable intelligent surface (RIS) has been suggested to be a key 6G feature and was suggested to be considered as a study-item in both 3GPP Releases 18 and 19. However, in both releases, it has been decided not to continue with it as a study-item, and to leave it for possible future specification. In this paper, we present the rationale for such a decision. Particularly, we demonstrate the practical issues which may affect the feasibility or usefulness of RIS in cellular networks, and present open problems to be addressed before RIS can be used in practice. Moreover, we compare the performance of RIS with network-controlled repeater, the node with the most similar characteristics to RIS and which has been standardized in 3GPP Release 18. Finally, different <b>simulations</b> are presented to evaluate the performance of RIS-assisted networks.

{{</citation>}}


### (2/3 | 112/126) Exploring UAV Networking from the Terrain Information Completeness Perspective: A Tutorial (Zhengying Lou et al., 2024)

{{<citation>}}

Zhengying Lou, Ruibo Wang, Baha Eddine Youcef Belmekki, Mustafa A. Kishk, Mohamed-Slim Alouini. (2024)  
**Exploring UAV Networking from the Terrain Information Completeness Perspective: A Tutorial**
<br/>
<button class="copy-to-clipboard" title="Exploring UAV Networking from the Terrain Information Completeness Perspective: A Tutorial" index=112>
  <span class="copy-to-clipboard-item">Copy Title<span>
</button>
<div class="toast toast-copied toast-index-112 align-items-center text-bg-secondary border-0 position-absolute top-0 end-0" role="alert" aria-live="assertive" aria-atomic="true">
  <div class="d-flex">
    <div class="toast-body">
      Copied!
    </div>
  </div>
</div>

---
Primary Category: cs.NI  
Categories: cs-NI, cs.NI  
Keyword Score: 15  
Keywords: Geometry, Summarization  
<a type="button" class="btn btn-outline-primary" href="http://arxiv.org/abs/2404.04505v1" target="_blank" >Paper Link</a>
<button type="button" class="btn btn-outline-primary download-pdf" url="https://arxiv.org/pdf/2404.04505v1.pdf" filename="2404.04505v1.pdf">Download PDF</button>

---


**ABSTRACT**  
Terrain information is a crucial factor affecting the performance of unmanned aerial vehicle (UAV) networks. As a tutorial, this article provides a unique perspective on the completeness of terrain information, summarizing and enhancing the research on terrain-based UAV deployment. In the presence of complete terrain information, two highly discussed topics are UAV-aided map construction and dynamic trajectory design based on maps. We propose a case study illustrating the mutually reinforcing relationship between them. When terrain information is incomplete, and only terrain-related feature parameters are available, we discuss how existing models map terrain features to blockage probabilities. By introducing the application of this model with stochastic <b>geometry,</b> a case study is proposed to analyze the accuracy of the model. When no terrain information is available, UAVs gather terrain information during the real-time networking process and determine the next position by collected information. This real-time search method is currently limited to relay communication. In the case study, we extend it to a multi-user scenario and <b>summarize</b> three trade-offs of the method. Finally, we conduct a qualitative analysis to assess the impact of three factors that have been overlooked in terrain-based UAV deployment.

{{</citation>}}


### (3/3 | 113/126) EVT-enriched Radio Maps for URLLC (Dian Echevarra Prez et al., 2024)

{{<citation>}}

Dian Echevarra Prez, Onel L. Alcaraz Lpez, Hirley Alves. (2024)  
**EVT-enriched Radio Maps for URLLC**
<br/>
<button class="copy-to-clipboard" title="EVT-enriched Radio Maps for URLLC" index=113>
  <span class="copy-to-clipboard-item">Copy Title<span>
</button>
<div class="toast toast-copied toast-index-113 align-items-center text-bg-secondary border-0 position-absolute top-0 end-0" role="alert" aria-live="assertive" aria-atomic="true">
  <div class="d-flex">
    <div class="toast-body">
      Copied!
    </div>
  </div>
</div>

---
Primary Category: cs.NI  
Categories: cs-NI, cs.NI  
Keyword Score: 3  
Keywords: Benchmarking  
<a type="button" class="btn btn-outline-primary" href="http://arxiv.org/abs/2404.04558v1" target="_blank" >Paper Link</a>
<button type="button" class="btn btn-outline-primary download-pdf" url="https://arxiv.org/pdf/2404.04558v1.pdf" filename="2404.04558v1.pdf">Download PDF</button>

---


**ABSTRACT**  
This paper introduces a sophisticated and adaptable framework combining extreme value theory with radio maps to spatially model extreme channel conditions accurately. Utilising existing signal-to-noise ratio (SNR) measurements and leveraging Gaussian processes, our approach predicts the tail of the SNR distribution, which entails estimating the parameters of a generalised Pareto distribution, at unobserved locations. This innovative method offers a versatile solution adaptable to various resource allocation challenges in ultra-reliable low-latency communications. We evaluate the performance of this method in a rate maximisation problem with defined outage constraints and compare it with a <b>benchmark</b> in the literature. Notably, the proposed approach meets the outage demands in a larger percentage of the coverage area and reaches higher transmission rates.

{{</citation>}}


## cs.CE (1)



### (1/1 | 114/126) Fast and Accurate Bayesian Optimization with Pre-trained Transformers for Constrained Engineering Problems (Rosen et al., 2024)

{{<citation>}}

Rosen, Yu, Cyril Picard, Faez Ahmed. (2024)  
**Fast and Accurate Bayesian Optimization with Pre-trained Transformers for Constrained Engineering Problems**
<br/>
<button class="copy-to-clipboard" title="Fast and Accurate Bayesian Optimization with Pre-trained Transformers for Constrained Engineering Problems" index=114>
  <span class="copy-to-clipboard-item">Copy Title<span>
</button>
<div class="toast toast-copied toast-index-114 align-items-center text-bg-secondary border-0 position-absolute top-0 end-0" role="alert" aria-live="assertive" aria-atomic="true">
  <div class="d-flex">
    <div class="toast-body">
      Copied!
    </div>
  </div>
</div>

---
Primary Category: cs.CE  
Categories: cs-CE, cs.CE  
Keyword Score: 18  
Keywords: Benchmarking, Black Box, Transformer  
<a type="button" class="btn btn-outline-primary" href="http://arxiv.org/abs/2404.04495v1" target="_blank" >Paper Link</a>
<button type="button" class="btn btn-outline-primary download-pdf" url="https://arxiv.org/pdf/2404.04495v1.pdf" filename="2404.04495v1.pdf">Download PDF</button>

---


**ABSTRACT**  
Bayesian Optimization (BO) is a foundational strategy in the field of engineering design optimization for efficiently handling <b>black-box</b> <b>functions</b> with many constraints and expensive evaluations. This paper introduces a fast and accurate BO framework that leverages Pre-trained <b>Transformers</b> for Bayesian Optimization (PFN4sBO) to address constrained optimization problems in engineering. Unlike traditional BO methods that rely heavily on Gaussian Processes (GPs), our approach utilizes Prior-data Fitted Networks (PFNs), a type of pre-trained <b>transformer,</b> to infer constraints and optimal solutions without requiring any iterative retraining. We demonstrate the effectiveness of PFN-based BO through a comprehensive <b>benchmark</b> consisting of fifteen test problems, encompassing synthetic, structural, and engineering design challenges. Our findings reveal that PFN-based BO significantly outperforms Constrained Expected Improvement and Penalty-based GP methods by an order of magnitude in speed while also outperforming them in accuracy in identifying feasible, optimal solutions. This work showcases the potential of integrating machine learning with optimization techniques in solving complex engineering challenges, heralding a significant leap forward for optimization methodologies, opening up the path to using PFN-based BO to solve other challenging problems, such as enabling user-guided interactive BO, adaptive experiment design, or multi-objective design optimization. Additionally, we establish a <b>benchmark</b> for evaluating BO algorithms in engineering design, offering a robust platform for future research and development in the field. This <b>benchmark</b> framework for evaluating new BO algorithms in engineering design will be published at https://github.com/rosenyu304/BOEngineeringBenchmark.

{{</citation>}}


## cs.CY (1)



### (1/1 | 115/126) Now, Later, and Lasting: Ten Priorities for AI Research, Policy, and Practice (Eric Horvitz et al., 2024)

{{<citation>}}

Eric Horvitz, Vincent Conitzer, Sheila McIlraith, Peter Stone. (2024)  
**Now, Later, and Lasting: Ten Priorities for AI Research, Policy, and Practice**
<br/>
<button class="copy-to-clipboard" title="Now, Later, and Lasting: Ten Priorities for AI Research, Policy, and Practice" index=115>
  <span class="copy-to-clipboard-item">Copy Title<span>
</button>
<div class="toast toast-copied toast-index-115 align-items-center text-bg-secondary border-0 position-absolute top-0 end-0" role="alert" aria-live="assertive" aria-atomic="true">
  <div class="d-flex">
    <div class="toast-body">
      Copied!
    </div>
  </div>
</div>

---
Primary Category: cs.CY  
Categories: cs-CY, cs.CY  
Keyword Score: 10  
Keywords: Recommendation  
<a type="button" class="btn btn-outline-primary" href="http://arxiv.org/abs/2404.04750v1" target="_blank" >Paper Link</a>
<button type="button" class="btn btn-outline-primary download-pdf" url="https://arxiv.org/pdf/2404.04750v1.pdf" filename="2404.04750v1.pdf">Download PDF</button>

---


**ABSTRACT**  
Advances in artificial intelligence (AI) will transform many aspects of our lives and society, bringing immense opportunities but also posing significant risks and challenges. The next several decades may well be a turning point for humanity, comparable to the industrial revolution. We write to share a set of <b>recommendations</b> for moving forward from the perspective of the founder and leaders of the One Hundred Year Study on AI. Launched a decade ago, the project is committed to a perpetual series of studies by multidisciplinary experts to evaluate the immediate, longer-term, and far-reaching effects of AI on people and society, and to make <b>recommendations</b> about AI research, policy, and practice. As we witness new capabilities emerging from neural models, it is crucial that we engage in efforts to advance our scientific understanding of these models and their behaviors. We must address the impact of AI on people and society through technical, social, and sociotechnical lenses, incorporating insights from a diverse range of experts including voices from engineering, social, behavioral, and economic disciplines. By fostering dialogue, collaboration, and action among various stakeholders, we can strategically guide the development and deployment of AI in ways that maximize its potential for contributing to human flourishing. Despite the growing divide in the field between focusing on short-term versus long-term implications, we think both are of critical importance. As Alan Turing, one of the pioneers of AI, wrote in 1950, "We can only see a short distance ahead, but we can see plenty there that needs to be done." We offer ten <b>recommendations</b> for action that collectively address both the short- and long-term potential impacts of AI technologies.

{{</citation>}}


## cs.PL (3)



### (1/3 | 116/126) From Batch to Stream: Automatic Generation of Online Algorithms (Ziteng Wang et al., 2024)

{{<citation>}}

Ziteng Wang, Shankara Pailoor, Aaryan Prakash, Yuepeng Wang, Isil Dillig. (2024)  
**From Batch to Stream: Automatic Generation of Online Algorithms**
<br/>
<button class="copy-to-clipboard" title="From Batch to Stream: Automatic Generation of Online Algorithms" index=116>
  <span class="copy-to-clipboard-item">Copy Title<span>
</button>
<div class="toast toast-copied toast-index-116 align-items-center text-bg-secondary border-0 position-absolute top-0 end-0" role="alert" aria-live="assertive" aria-atomic="true">
  <div class="d-flex">
    <div class="toast-body">
      Copied!
    </div>
  </div>
</div>

---
Primary Category: cs.PL  
Categories: D-3-0, cs-PL, cs.PL  
Keyword Score: 10  
Keywords: Reasoning  
<a type="button" class="btn btn-outline-primary" href="http://arxiv.org/abs/2404.04743v1" target="_blank" >Paper Link</a>
<button type="button" class="btn btn-outline-primary download-pdf" url="https://arxiv.org/pdf/2404.04743v1.pdf" filename="2404.04743v1.pdf">Download PDF</button>

---


**ABSTRACT**  
Online streaming algorithms, tailored for continuous data processing, offer substantial benefits but are often more intricate to design than their offline counterparts. This paper introduces a novel approach for automatically synthesizing online streaming algorithms from their offline versions. In particular, we propose a novel methodology, based on the notion of relational function signature (RFS), for deriving an online algorithm given its offline version. Then, we propose a concrete synthesis algorithm that is an instantiation of the proposed methodology. Our algorithm uses the RFS to decompose the synthesis problem into a set of independent subtasks and uses a combination of symbolic <b>reasoning</b> and search to solve each subproblem. We implement the proposed technique in a new tool called Opera and evaluate it on over 50 tasks spanning two domains: statistical computations and online auctions. Our results show that Opera can automatically derive the online version of the original algorithm for 98% of the tasks. Our experiments also demonstrate that Opera significantly outperforms alternative approaches, including adaptations of SyGuS solvers to this problem as well as two of Opera's own ablations.

{{</citation>}}


### (2/3 | 117/126) Compilation of Modular and General Sparse Workspaces (Genghan Zhang et al., 2024)

{{<citation>}}

Genghan Zhang, Olivia Hsu, Fredrik Kjolstad. (2024)  
**Compilation of Modular and General Sparse Workspaces**
<br/>
<button class="copy-to-clipboard" title="Compilation of Modular and General Sparse Workspaces" index=117>
  <span class="copy-to-clipboard-item">Copy Title<span>
</button>
<div class="toast toast-copied toast-index-117 align-items-center text-bg-secondary border-0 position-absolute top-0 end-0" role="alert" aria-live="assertive" aria-atomic="true">
  <div class="d-flex">
    <div class="toast-body">
      Copied!
    </div>
  </div>
</div>

---
Primary Category: cs.PL  
Categories: cs-PL, cs.PL  
Keyword Score: 10  
Keywords: Code Generation  
<a type="button" class="btn btn-outline-primary" href="http://arxiv.org/abs/2404.04541v1" target="_blank" >Paper Link</a>
<button type="button" class="btn btn-outline-primary download-pdf" url="https://arxiv.org/pdf/2404.04541v1.pdf" filename="2404.04541v1.pdf">Download PDF</button>

---


**ABSTRACT**  
Recent years have seen considerable work on compiling sparse tensor algebra expressions. This paper addresses a shortcoming in that work, namely how to generate efficient <b>code</b> <b>(in</b> time and space) that scatters values into a sparse result tensor. We address this shortcoming through a compiler design that generates <b>code</b> <b>that</b> uses sparse intermediate tensors (sparse workspaces) as efficient adapters between compute <b>code</b> <b>that</b> scatters and result tensors that do not support random insertion. Our compiler automatically detects sparse scattering behavior in tensor expressions and inserts necessary intermediate workspace tensors. We present an algorithm template for workspace insertion that is the backbone of our <b>code</b> <b>generation</b> algorithm. Our algorithm template is modular by design, supporting sparse workspaces that span multiple user-defined implementations. Our evaluation shows that sparse workspaces can be up to 27.12$\times$ faster than the dense workspaces of prior work. On the other hand, dense workspaces can be up to 7.58$\times$ faster than the sparse workspaces generated by our compiler in other situations, which motivates our compiler design that supports both. Our compiler produces sequential <b>code</b> <b>that</b> is competitive with hand-optimized linear and tensor algebra libraries on the expressions they support, but that generalizes to any other expression. Sparse workspaces are also more memory efficient than dense workspaces as they compress away zeros. This compression can asymptotically decrease memory usage, enabling tensor computations on data that would otherwise run out of memory.

{{</citation>}}


### (3/3 | 118/126) IsoPredict: Dynamic Predictive Analysis for Detecting Unserializable Behaviors in Weakly Isolated Data Store Applications (Chujun Geng et al., 2024)

{{<citation>}}

Chujun Geng, Spyros Blanas, Michael D. Bond, Yang Wang. (2024)  
**IsoPredict: Dynamic Predictive Analysis for Detecting Unserializable Behaviors in Weakly Isolated Data Store Applications**
<br/>
<button class="copy-to-clipboard" title="IsoPredict: Dynamic Predictive Analysis for Detecting Unserializable Behaviors in Weakly Isolated Data Store Applications" index=118>
  <span class="copy-to-clipboard-item">Copy Title<span>
</button>
<div class="toast toast-copied toast-index-118 align-items-center text-bg-secondary border-0 position-absolute top-0 end-0" role="alert" aria-live="assertive" aria-atomic="true">
  <div class="d-flex">
    <div class="toast-body">
      Copied!
    </div>
  </div>
</div>

---
Primary Category: cs.PL  
Categories: cs-DB, cs-PL, cs.PL  
Keyword Score: 3  
Keywords: Benchmarking  
<a type="button" class="btn btn-outline-primary" href="http://arxiv.org/abs/2404.04621v1" target="_blank" >Paper Link</a>
<button type="button" class="btn btn-outline-primary download-pdf" url="https://arxiv.org/pdf/2404.04621v1.pdf" filename="2404.04621v1.pdf">Download PDF</button>

---


**ABSTRACT**  
This paper presents the first dynamic predictive analysis for data store applications under weak isolation levels, called Isopredict. Given an observed serializable execution of a data store application, Isopredict generates and solves SMT constraints to find an unserializable execution that is a feasible execution of the application. Isopredict introduces novel techniques that handle divergent application behavior; solve mutually recursive sets of constraints; and balance coverage, precision, and performance. An evaluation on four transactional data store <b>benchmarks</b> shows that Isopredict often predicts unserializable behaviors, 99% of which are feasible.

{{</citation>}}


## cs.DB (1)



### (1/1 | 119/126) Faster Algorithms for Fair Max-Min Diversification in $\mathbb{R}^d$ (Yash Kurkure et al., 2024)

{{<citation>}}

Yash Kurkure, Miles Shamo, Joseph Wiseman, Sainyam Galhotra, Stavros Sintos. (2024)  
**Faster Algorithms for Fair Max-Min Diversification in $\mathbb{R}^d$**
<br/>
<button class="copy-to-clipboard" title="Faster Algorithms for Fair Max-Min Diversification in $\mathbb{R}^d$" index=119>
  <span class="copy-to-clipboard-item">Copy Title<span>
</button>
<div class="toast toast-copied toast-index-119 align-items-center text-bg-secondary border-0 position-absolute top-0 end-0" role="alert" aria-live="assertive" aria-atomic="true">
  <div class="d-flex">
    <div class="toast-body">
      Copied!
    </div>
  </div>
</div>

---
Primary Category: cs.DB  
Categories: cs-DB, cs-DS, cs.DB  
Keyword Score: 10  
Keywords: Fairness  
<a type="button" class="btn btn-outline-primary" href="http://arxiv.org/abs/2404.04713v1" target="_blank" >Paper Link</a>
<button type="button" class="btn btn-outline-primary download-pdf" url="https://arxiv.org/pdf/2404.04713v1.pdf" filename="2404.04713v1.pdf">Download PDF</button>

---


**ABSTRACT**  
The task of extracting a diverse subset from a dataset, often referred to as maximum diversification, plays a pivotal role in various real-world applications that have far-reaching consequences. In this work, we delve into the realm of <b>fairness-aware</b> data subset selection, specifically focusing on the problem of selecting a diverse set of size $k$ from a large collection of $n$ data points (FairDiv). The FairDiv problem is well-studied in the data management and theory community. In this work, we develop the first constant approximation algorithm for FairDiv that runs in near-linear time using only linear space. In contrast, all previously known constant approximation algorithms run in super-linear time (with respect to $n$ or $k$) and use super-linear space. Our approach achieves this efficiency by employing a novel combination of the Multiplicative Weight Update method and advanced geometric data structures to implicitly and approximately solve a linear program. Furthermore, we improve the efficiency of our techniques by constructing a coreset. Using our coreset, we also propose the first efficient streaming algorithm for the FairDiv problem whose efficiency does not depend on the distribution of data points. Empirical evaluation on million-sized datasets demonstrates that our algorithm achieves the best diversity within a minute. All prior techniques are either highly inefficient or do not generate a good solution.

{{</citation>}}


## cs.IT (1)



### (1/1 | 120/126) Study of Adaptive Reweighted Sparse Belief Propagation Decoders for Polar Codes (R. M. Oliveira et al., 2024)

{{<citation>}}

R. M. Oliveira, R. C. de Lamare. (2024)  
**Study of Adaptive Reweighted Sparse Belief Propagation Decoders for Polar Codes**
<br/>
<button class="copy-to-clipboard" title="Study of Adaptive Reweighted Sparse Belief Propagation Decoders for Polar Codes" index=120>
  <span class="copy-to-clipboard-item">Copy Title<span>
</button>
<div class="toast toast-copied toast-index-120 align-items-center text-bg-secondary border-0 position-absolute top-0 end-0" role="alert" aria-live="assertive" aria-atomic="true">
  <div class="d-flex">
    <div class="toast-body">
      Copied!
    </div>
  </div>
</div>

---
Primary Category: cs.IT  
Categories: cs-IT, cs.IT, math-IT  
Keyword Score: 10  
Keywords: Message-Passing  
<a type="button" class="btn btn-outline-primary" href="http://arxiv.org/abs/2404.04674v1" target="_blank" >Paper Link</a>
<button type="button" class="btn btn-outline-primary download-pdf" url="https://arxiv.org/pdf/2404.04674v1.pdf" filename="2404.04674v1.pdf">Download PDF</button>

---


**ABSTRACT**  
In this paper, we present an adaptive reweighted sparse belief propagation (AR-SBP) decoder for polar codes. The AR-SBP technique is inspired by decoders that employ the sum-product algorithm for low-density parity-check codes. In particular, the AR-SBP decoding strategy introduces reweighting of the exchanged log-likelihood-ratio in order to refine the message passing, improving the performance of the decoder and reducing the number of required iterations. An analysis of the convergence of AR-SBP is carried out along with a study of the complexity of the analyzed decoders. Numerical examples show that the AR-SBP decoder outperforms existing decoding algorithms for a reduced number of iterations, enabling low-latency applications.

{{</citation>}}


## eess.IV (2)



### (1/2 | 121/126) Power-Efficient Image Storage: Leveraging Super Resolution Generative Adversarial Network for Sustainable Compression and Reduced Carbon Footprint (Ashok Mondal et al., 2024)

{{<citation>}}

Ashok Mondal, Satyam Singh. (2024)  
**Power-Efficient Image Storage: Leveraging Super Resolution Generative Adversarial Network for Sustainable Compression and Reduced Carbon Footprint**
<br/>
<button class="copy-to-clipboard" title="Power-Efficient Image Storage: Leveraging Super Resolution Generative Adversarial Network for Sustainable Compression and Reduced Carbon Footprint" index=121>
  <span class="copy-to-clipboard-item">Copy Title<span>
</button>
<div class="toast toast-copied toast-index-121 align-items-center text-bg-secondary border-0 position-absolute top-0 end-0" role="alert" aria-live="assertive" aria-atomic="true">
  <div class="d-flex">
    <div class="toast-body">
      Copied!
    </div>
  </div>
</div>

---
Primary Category: eess.IV  
Categories: 68T07, I-2-m; H-3-2, cs-AI, cs-LG, eess-IV, eess.IV  
Keyword Score: 10  
Keywords: Generative Adversarial Network  
<a type="button" class="btn btn-outline-primary" href="http://arxiv.org/abs/2404.04642v1" target="_blank" >Paper Link</a>
<button type="button" class="btn btn-outline-primary download-pdf" url="https://arxiv.org/pdf/2404.04642v1.pdf" filename="2404.04642v1.pdf">Download PDF</button>

---


**ABSTRACT**  
In recent years, large-scale adoption of cloud storage solutions has revolutionized the way we think about digital data storage. However, the exponential increase in data volume, especially images, has raised environmental concerns regarding power and resource consumption, as well as the rising digital carbon footprint emissions. The aim of this research is to propose a methodology for cloud-based image storage by integrating image compression technology with SuperResolution <b>Generative</b> <b>Adversarial</b> <b>Networks</b> (SRGAN). Rather than storing images in their original format directly on the cloud, our approach involves initially reducing the image size through compression and downsizing techniques before storage. Upon request, these compressed images will be retrieved and processed by SRGAN to generate images. The efficacy of the proposed method is evaluated in terms of PSNR and SSIM metrics. Additionally, a mathematical analysis is given to calculate power consumption and carbon footprint assesment. The proposed data compression technique provides a significant solution to achieve a reasonable trade off between environmental sustainability and industrial efficiency.

{{</citation>}}


### (2/2 | 122/126) A Deep Look Into -- Automated Lung X-Ray Abnormality Detection System (Nagullas KS et al., 2024)

{{<citation>}}

Nagullas KS, Vivekanand. V, Narayana Darapaneni, Anwesh R P. (2024)  
**A Deep Look Into -- Automated Lung X-Ray Abnormality Detection System**
<br/>
<button class="copy-to-clipboard" title="A Deep Look Into -- Automated Lung X-Ray Abnormality Detection System" index=122>
  <span class="copy-to-clipboard-item">Copy Title<span>
</button>
<div class="toast toast-copied toast-index-122 align-items-center text-bg-secondary border-0 position-absolute top-0 end-0" role="alert" aria-live="assertive" aria-atomic="true">
  <div class="d-flex">
    <div class="toast-body">
      Copied!
    </div>
  </div>
</div>

---
Primary Category: eess.IV  
Categories: cs-CV, eess-IV, eess.IV  
Keyword Score: 10  
Keywords: Convolutional Neural Network  
<a type="button" class="btn btn-outline-primary" href="http://arxiv.org/abs/2404.04635v1" target="_blank" >Paper Link</a>
<button type="button" class="btn btn-outline-primary download-pdf" url="https://arxiv.org/pdf/2404.04635v1.pdf" filename="2404.04635v1.pdf">Download PDF</button>

---


**ABSTRACT**  
Introduction: Automated Lung X-Ray Abnormality Detection System is the application which distinguish the normal x-ray images from infected x-ray images and highlight area considered for prediction, with the recent pandemic a need to have a non-conventional method and faster detecting diseases, for which X ray serves the purpose. Obectives: As of current situation any viral disease that is infectious is potential pandemic, so there is need for cheap and early detection system. Methods: This research will help to eases the work of expert to do further analysis. Accuracy of three different preexisting models such as DenseNet, MobileNet and VGG16 were high but models over-fitted primarily due to black and white images. Results: This led to building up new method such as as V-BreathNet which gave more than 96% percent accuracy. Conclusion: Thus, it can be stated that not all state-of art <b>CNN</b> models can be used on B/W images. In conclusion not all state-of-art <b>CNN</b> models can be used on B/W images.

{{</citation>}}


## math.OC (1)



### (1/1 | 123/126) Convex Reformulation of LMI-Based Distributed Controller Design with a Class of Non-Block-Diagonal Lyapunov Functions (Yuto Watanabe et al., 2024)

{{<citation>}}

Yuto Watanabe, Sotaro Fushimi, Kazunori Sakurama. (2024)  
**Convex Reformulation of LMI-Based Distributed Controller Design with a Class of Non-Block-Diagonal Lyapunov Functions**
<br/>
<button class="copy-to-clipboard" title="Convex Reformulation of LMI-Based Distributed Controller Design with a Class of Non-Block-Diagonal Lyapunov Functions" index=123>
  <span class="copy-to-clipboard-item">Copy Title<span>
</button>
<div class="toast toast-copied toast-index-123 align-items-center text-bg-secondary border-0 position-absolute top-0 end-0" role="alert" aria-live="assertive" aria-atomic="true">
  <div class="d-flex">
    <div class="toast-body">
      Copied!
    </div>
  </div>
</div>

---
Primary Category: math.OC  
Categories: cs-SY, eess-SY, math-OC, math.OC  
Keyword Score: 10  
Keywords: Continuous Time, Continuous Time  
<a type="button" class="btn btn-outline-primary" href="http://arxiv.org/abs/2404.04576v1" target="_blank" >Paper Link</a>
<button type="button" class="btn btn-outline-primary download-pdf" url="https://arxiv.org/pdf/2404.04576v1.pdf" filename="2404.04576v1.pdf">Download PDF</button>

---


**ABSTRACT**  
This study addresses a distributed state feedback controller design problem for <b>continuous-time</b> <b>linear</b> time-invariant systems by means of linear matrix inequalities (LMI). As the exact convexification is still open, the block-diagonal relaxation of Lyapunov functions has been prevalent despite its conservatism. In this work, we target a class of non-block-diagonal Lyapunov functions that has the same sparsity as distributed controllers. By leveraging a block-diagonal factorization of sparse matrices and Finsler's lemma, we first present a (nonlinear) matrix inequality for stabilizing distributed controllers with such Lyapunov functions, which boils down to a necessary and sufficient condition for such controllers if the sparsity pattern is chordal. As a relaxation of the inequality, we derive an LMI that completely covers the conventional relaxation and then provide analogous results for $H_\infty$ control. Lastly, numerical examples underscore the efficacy of our results.

{{</citation>}}


## physics.soc-ph (1)



### (1/1 | 124/126) Explaining Indian Stock Market through Geometry of Scale free Networks (Pawanesh Yadav et al., 2024)

{{<citation>}}

Pawanesh Yadav, Charu Sharma, Niteesh Sahni. (2024)  
**Explaining Indian Stock Market through Geometry of Scale free Networks**
<br/>
<button class="copy-to-clipboard" title="Explaining Indian Stock Market through Geometry of Scale free Networks" index=124>
  <span class="copy-to-clipboard-item">Copy Title<span>
</button>
<div class="toast toast-copied toast-index-124 align-items-center text-bg-secondary border-0 position-absolute top-0 end-0" role="alert" aria-live="assertive" aria-atomic="true">
  <div class="d-flex">
    <div class="toast-body">
      Copied!
    </div>
  </div>
</div>

---
Primary Category: physics.soc-ph  
Categories: cs-LG, physics-soc-ph, physics.soc-ph, q-fin-ST  
Keyword Score: 8  
Keywords: Clustering, Geometry  
<a type="button" class="btn btn-outline-primary" href="http://arxiv.org/abs/2404.04710v1" target="_blank" >Paper Link</a>
<button type="button" class="btn btn-outline-primary download-pdf" url="https://arxiv.org/pdf/2404.04710v1.pdf" filename="2404.04710v1.pdf">Download PDF</button>

---


**ABSTRACT**  
This paper presents an analysis of the Indian stock market using a method based on embedding the network in a hyperbolic space using Machine learning techniques. We claim novelty on four counts. First, it is demonstrated that the hyperbolic clusters resemble the topological network communities more closely than the Euclidean clusters. Second, we are able to clearly distinguish between periods of market stability and volatility through a statistical analysis of hyperbolic distance and hyperbolic shortest path distance corresponding to the embedded network. Third, we demonstrate that using the modularity of the embedded network significant market changes can be spotted early. Lastly, the coalescent embedding is able to segregate the certain market sectors thereby underscoring its natural <b>clustering</b> ability.

{{</citation>}}


## cs.CG (1)



### (1/1 | 125/126) Quantum Speedup for Some Geometric 3SUM-Hard Problems and Beyond (J. Mark Keil et al., 2024)

{{<citation>}}

J. Mark Keil, Fraser McLeod, Debajyoti Mondal. (2024)  
**Quantum Speedup for Some Geometric 3SUM-Hard Problems and Beyond**
<br/>
<button class="copy-to-clipboard" title="Quantum Speedup for Some Geometric 3SUM-Hard Problems and Beyond" index=125>
  <span class="copy-to-clipboard-item">Copy Title<span>
</button>
<div class="toast toast-copied toast-index-125 align-items-center text-bg-secondary border-0 position-absolute top-0 end-0" role="alert" aria-live="assertive" aria-atomic="true">
  <div class="d-flex">
    <div class="toast-body">
      Copied!
    </div>
  </div>
</div>

---
Primary Category: cs.CG  
Categories: 68Q12, F-2, cs-CG, cs-DS, cs.CG  
Keyword Score: 5  
Keywords: Geometry  
<a type="button" class="btn btn-outline-primary" href="http://arxiv.org/abs/2404.04535v1" target="_blank" >Paper Link</a>
<button type="button" class="btn btn-outline-primary download-pdf" url="https://arxiv.org/pdf/2404.04535v1.pdf" filename="2404.04535v1.pdf">Download PDF</button>

---


**ABSTRACT**  
The classical 3SUM conjecture states that the class of 3SUM-hard problems does not admit a truly subquadratic $O(n^{2-\delta})$-time algorithm, where $\delta >0$, in classical computing. The geometric 3SUM-hard problems have widely been studied in computational <b>geometry</b> and recently, these problems have been examined under the quantum computing model. For example, Ambainis and Larka [TQC'20] designed a quantum algorithm that can solve many geometric 3SUM-hard problems in $O(n^{1+o(1)})$-time, whereas Buhrman [ITCS'22] investigated lower bounds under quantum 3SUM conjecture that claims there does not exist any sublinear $O(n^{1-\delta})$-time quantum algorithm for the 3SUM problem. The main idea of Ambainis and Larka is to formulate a 3SUM-hard problem as a search problem, where one needs to find a point with a certain property over a set of regions determined by a line arrangement in the plane. The quantum speed-up then comes from the application of the well-known quantum search technique called Grover search over all regions. This paper further generalizes the technique of Ambainis and Larka for some 3SUM-hard problems when a solution may not necessarily correspond to a single point or the search regions do not immediately correspond to the subdivision determined by a line arrangement. Given a set of $n$ points and a positive number $q$, we design $O(n^{1+o(1)})$-time quantum algorithms to determine whether there exists a triangle among these points with an area at most $q$ or a unit disk that contains at least $q$ points. We also give an $O(n^{1+o(1)})$-time quantum algorithm to determine whether a given set of intervals can be translated so that it becomes contained in another set of given intervals and discuss further generalizations.

{{</citation>}}


## cs.DS (1)



### (1/1 | 126/126) Spectral Independence Beyond Total Influence on Trees and Related Graphs (Xiaoyu Chen et al., 2024)

{{<citation>}}

Xiaoyu Chen, Xiongxin Yang, Yitong Yin, Xinyuan Zhang. (2024)  
**Spectral Independence Beyond Total Influence on Trees and Related Graphs**
<br/>
<button class="copy-to-clipboard" title="Spectral Independence Beyond Total Influence on Trees and Related Graphs" index=126>
  <span class="copy-to-clipboard-item">Copy Title<span>
</button>
<div class="toast toast-copied toast-index-126 align-items-center text-bg-secondary border-0 position-absolute top-0 end-0" role="alert" aria-live="assertive" aria-atomic="true">
  <div class="d-flex">
    <div class="toast-body">
      Copied!
    </div>
  </div>
</div>

---
Primary Category: cs.DS  
Categories: cs-DS, cs.DS, math-PR  
Keyword Score: 3  
Keywords: Graph  
<a type="button" class="btn btn-outline-primary" href="http://arxiv.org/abs/2404.04668v1" target="_blank" >Paper Link</a>
<button type="button" class="btn btn-outline-primary download-pdf" url="https://arxiv.org/pdf/2404.04668v1.pdf" filename="2404.04668v1.pdf">Download PDF</button>

---


**ABSTRACT**  
We study how to establish $\textit{spectral independence}$, a key concept in sampling, without relying on total influence bounds, by applying an $\textit{approximate inverse}$ of the influence matrix. Our method gives constant upper bounds on spectral independence for two foundational Gibbs distributions known to have unbounded total influences: $\bullet$ The monomer-dimer model on <b>graphs</b> with large girth (including trees). Prior to our work, such results were only known for <b>graphs</b> with constant maximum degrees or infinite regular trees, as shown by Chen, Liu, and Vigoda (STOC '21). $\bullet$ The hardcore model on trees with fugacity $\lambda < \mathrm{e}^2$. This remarkably surpasses the well-known $\lambda_r>\mathrm{e}-1$ lower bound for the reconstruction threshold on trees, significantly improving upon the current threshold $\lambda < 1.3$, established in a prior work by Efthymiou, Hayes, \v{S}tefankovi\v{c}, and Vigoda (RANDOM '23). Consequently, we establish optimal $\Omega(n^{-1})$ spectral gaps of the Glauber dynamics for these models on arbitrary trees, regardless of the maximum degree $\Delta$.

{{</citation>}}
