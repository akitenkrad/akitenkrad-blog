---
draft: false
title: "arXiv @ 2024.04.10"
date: 2024-04-10
author: "akitenkrad"
description: ""
tags: ["arXiv", "Published:2024"]
menu:
  sidebar:
    name: "arXiv @ 2024.04.10"
    identifier: arxiv_20240410
    parent: 202404_arxiv
    weight: 10
math: true
---

<figure style="border:none; width:100%; display:flex; justify-content: center">
    <iframe src="pie.html" width=900 height=620 style="border:none"></iframe>
</figure>


## Primary Categories

- [cs.AI (6)](#csai-6)
- [cs.AR (4)](#csar-4)
- [cs.CE (1)](#csce-1)
- [cs.CG (2)](#cscg-2)
- [cs.CL (43)](#cscl-43)
- [cs.CR (10)](#cscr-10)
- [cs.CV (76)](#cscv-76)
- [cs.CY (3)](#cscy-3)
- [cs.DB (1)](#csdb-1)
- [cs.DC (1)](#csdc-1)
- [cs.DM (1)](#csdm-1)
- [cs.DS (2)](#csds-2)
- [cs.ET (2)](#cset-2)
- [cs.GR (1)](#csgr-1)
- [cs.GT (1)](#csgt-1)
- [cs.HC (6)](#cshc-6)
- [cs.IR (3)](#csir-3)
- [cs.IT (8)](#csit-8)
- [cs.LG (34)](#cslg-34)
- [cs.MA (1)](#csma-1)
- [cs.MS (1)](#csms-1)
- [cs.NE (1)](#csne-1)
- [cs.NI (3)](#csni-3)
- [cs.PL (1)](#cspl-1)
- [cs.RO (17)](#csro-17)
- [cs.SE (5)](#csse-5)
- [cs.SI (3)](#cssi-3)
- [cs.SY (1)](#cssy-1)
- [eess.IV (3)](#eessiv-3)
- [eess.SP (3)](#eesssp-3)
- [eess.SY (6)](#eesssy-6)
- [math.CO (1)](#mathco-1)
- [math.NA (1)](#mathna-1)
- [math.OC (3)](#mathoc-3)
- [math.ST (2)](#mathst-2)
- [physics.comp-ph (1)](#physicscomp-ph-1)
- [physics.flu-dyn (1)](#physicsflu-dyn-1)
- [physics.geo-ph (1)](#physicsgeo-ph-1)
- [quant-ph (3)](#quant-ph-3)
- [stat.ME (1)](#statme-1)
- [stat.ML (2)](#statml-2)

## Keywords

<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th>keyword</th>
      <th>cs.CL</th>
      <th>cs.CR</th>
      <th>cs.CV</th>
      <th>cs.LG</th>
      <th>cs.RO</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td>Active Learning</td>
      <td></td>
      <td></td>
      <td></td>
      <td>1</td>
      <td></td>
    </tr>
    <tr>
      <td>Adversarial Attack</td>
      <td>1</td>
      <td></td>
      <td></td>
      <td>3</td>
      <td></td>
    </tr>
    <tr>
      <td>Adversarial Learning</td>
      <td></td>
      <td></td>
      <td>1</td>
      <td>1</td>
      <td></td>
    </tr>
    <tr>
      <td>Anomaly Detection</td>
      <td></td>
      <td></td>
      <td>1</td>
      <td>1</td>
      <td></td>
    </tr>
    <tr>
      <td>Augmented Reality (AR)</td>
      <td></td>
      <td></td>
      <td>1</td>
      <td></td>
      <td></td>
    </tr>
    <tr>
      <td>Autoencoder</td>
      <td></td>
      <td></td>
      <td>2</td>
      <td></td>
      <td>1</td>
    </tr>
    <tr>
      <td>Automatic Evaluation</td>
      <td></td>
      <td></td>
      <td>1</td>
      <td></td>
      <td></td>
    </tr>
    <tr>
      <td>Automatic Speech Recognition</td>
      <td>3</td>
      <td></td>
      <td></td>
      <td></td>
      <td></td>
    </tr>
    <tr>
      <td>BERT</td>
      <td>4</td>
      <td></td>
      <td></td>
      <td></td>
      <td>1</td>
    </tr>
    <tr>
      <td>BLOOM</td>
      <td>1</td>
      <td></td>
      <td></td>
      <td></td>
      <td></td>
    </tr>
    <tr>
      <td>Bandit Algorithm</td>
      <td></td>
      <td></td>
      <td></td>
      <td>2</td>
      <td></td>
    </tr>
    <tr>
      <td>Benchmarking</td>
      <td>17</td>
      <td></td>
      <td>16</td>
      <td>10</td>
      <td></td>
    </tr>
    <tr>
      <td>Black Box</td>
      <td>2</td>
      <td></td>
      <td>1</td>
      <td>4</td>
      <td></td>
    </tr>
    <tr>
      <td>ChatGPT</td>
      <td>1</td>
      <td></td>
      <td></td>
      <td></td>
      <td>1</td>
    </tr>
    <tr>
      <td>Clustering</td>
      <td></td>
      <td></td>
      <td>1</td>
      <td>1</td>
      <td></td>
    </tr>
    <tr>
      <td>Continual Learning</td>
      <td></td>
      <td></td>
      <td></td>
      <td>1</td>
      <td></td>
    </tr>
    <tr>
      <td>Contrastive Learning</td>
      <td></td>
      <td></td>
      <td>2</td>
      <td></td>
      <td></td>
    </tr>
    <tr>
      <td>ControlNet</td>
      <td></td>
      <td></td>
      <td>1</td>
      <td></td>
      <td></td>
    </tr>
    <tr>
      <td>Convolution</td>
      <td></td>
      <td></td>
      <td>8</td>
      <td></td>
      <td>1</td>
    </tr>
    <tr>
      <td>Convolutional Neural Network</td>
      <td></td>
      <td></td>
      <td>10</td>
      <td>1</td>
      <td></td>
    </tr>
    <tr>
      <td>Data Augmentation</td>
      <td></td>
      <td></td>
      <td>2</td>
      <td></td>
      <td></td>
    </tr>
    <tr>
      <td>Dependency Parsing</td>
      <td>1</td>
      <td></td>
      <td></td>
      <td></td>
      <td></td>
    </tr>
    <tr>
      <td>Diffusion Model</td>
      <td></td>
      <td></td>
      <td>11</td>
      <td></td>
      <td></td>
    </tr>
    <tr>
      <td>Direct Preference Optimization</td>
      <td>1</td>
      <td></td>
      <td></td>
      <td></td>
      <td></td>
    </tr>
    <tr>
      <td>Disambiguation</td>
      <td>2</td>
      <td></td>
      <td></td>
      <td></td>
      <td></td>
    </tr>
    <tr>
      <td>Distribution Shift</td>
      <td></td>
      <td></td>
      <td></td>
      <td>2</td>
      <td></td>
    </tr>
    <tr>
      <td>Domain Adaptation</td>
      <td>1</td>
      <td></td>
      <td></td>
      <td>1</td>
      <td></td>
    </tr>
    <tr>
      <td>Explainable AI</td>
      <td></td>
      <td></td>
      <td>1</td>
      <td></td>
      <td></td>
    </tr>
    <tr>
      <td>Fairness</td>
      <td></td>
      <td></td>
      <td></td>
      <td>2</td>
      <td></td>
    </tr>
    <tr>
      <td>Federated Learning</td>
      <td></td>
      <td>2</td>
      <td></td>
      <td></td>
      <td></td>
    </tr>
    <tr>
      <td>Few-shot</td>
      <td></td>
      <td></td>
      <td>5</td>
      <td></td>
      <td></td>
    </tr>
    <tr>
      <td>Fine-tuning</td>
      <td>14</td>
      <td></td>
      <td>8</td>
      <td>4</td>
      <td></td>
    </tr>
    <tr>
      <td>Foundation Model</td>
      <td></td>
      <td></td>
      <td>2</td>
      <td></td>
      <td></td>
    </tr>
    <tr>
      <td>GPT</td>
      <td>5</td>
      <td></td>
      <td>1</td>
      <td></td>
      <td></td>
    </tr>
    <tr>
      <td>GPT-2</td>
      <td>1</td>
      <td></td>
      <td></td>
      <td></td>
      <td></td>
    </tr>
    <tr>
      <td>GPT-3</td>
      <td>3</td>
      <td></td>
      <td></td>
      <td></td>
      <td></td>
    </tr>
    <tr>
      <td>GPT-3.5</td>
      <td>3</td>
      <td></td>
      <td></td>
      <td></td>
      <td></td>
    </tr>
    <tr>
      <td>GPT-4</td>
      <td>2</td>
      <td></td>
      <td></td>
      <td>1</td>
      <td></td>
    </tr>
    <tr>
      <td>Generative Adversarial Network</td>
      <td></td>
      <td></td>
      <td>6</td>
      <td></td>
      <td></td>
    </tr>
    <tr>
      <td>Geometry</td>
      <td></td>
      <td></td>
      <td>2</td>
      <td>1</td>
      <td>3</td>
    </tr>
    <tr>
      <td>Graph</td>
      <td>1</td>
      <td></td>
      <td>2</td>
      <td>10</td>
      <td></td>
    </tr>
    <tr>
      <td>Graph Embedding</td>
      <td></td>
      <td></td>
      <td>1</td>
      <td></td>
      <td></td>
    </tr>
    <tr>
      <td>Graph Neural Network</td>
      <td></td>
      <td></td>
      <td></td>
      <td>8</td>
      <td></td>
    </tr>
    <tr>
      <td>Grounding</td>
      <td>1</td>
      <td></td>
      <td>2</td>
      <td></td>
      <td></td>
    </tr>
    <tr>
      <td>Human Intervention</td>
      <td></td>
      <td></td>
      <td>1</td>
      <td></td>
      <td>1</td>
    </tr>
    <tr>
      <td>Image2text</td>
      <td></td>
      <td></td>
      <td>1</td>
      <td></td>
      <td></td>
    </tr>
    <tr>
      <td>In-context Learning</td>
      <td>4</td>
      <td></td>
      <td>2</td>
      <td></td>
      <td></td>
    </tr>
    <tr>
      <td>Information Retrieval</td>
      <td>1</td>
      <td></td>
      <td></td>
      <td></td>
      <td></td>
    </tr>
    <tr>
      <td>Instruction Following</td>
      <td>1</td>
      <td></td>
      <td>1</td>
      <td></td>
      <td></td>
    </tr>
    <tr>
      <td>Instruction Tuning</td>
      <td>1</td>
      <td></td>
      <td>1</td>
      <td></td>
      <td></td>
    </tr>
    <tr>
      <td>Keyword Extraction</td>
      <td>1</td>
      <td></td>
      <td></td>
      <td></td>
      <td></td>
    </tr>
    <tr>
      <td>Knowledge Distillation</td>
      <td>1</td>
      <td></td>
      <td></td>
      <td></td>
      <td></td>
    </tr>
    <tr>
      <td>Knowledge Transfer</td>
      <td>1</td>
      <td></td>
      <td></td>
      <td></td>
      <td></td>
    </tr>
    <tr>
      <td>LLaMA</td>
      <td>1</td>
      <td></td>
      <td></td>
      <td></td>
      <td></td>
    </tr>
    <tr>
      <td>LSTM</td>
      <td>3</td>
      <td></td>
      <td></td>
      <td></td>
      <td></td>
    </tr>
    <tr>
      <td>Language Generation</td>
      <td>2</td>
      <td></td>
      <td></td>
      <td></td>
      <td></td>
    </tr>
    <tr>
      <td>Large Language Model</td>
      <td>40</td>
      <td>3</td>
      <td>17</td>
      <td>7</td>
      <td>4</td>
    </tr>
    <tr>
      <td>Logistic Regression</td>
      <td></td>
      <td></td>
      <td></td>
      <td>1</td>
      <td></td>
    </tr>
    <tr>
      <td>Low-Resource</td>
      <td>2</td>
      <td></td>
      <td></td>
      <td></td>
      <td></td>
    </tr>
    <tr>
      <td>MNIST</td>
      <td></td>
      <td></td>
      <td>2</td>
      <td>2</td>
      <td></td>
    </tr>
    <tr>
      <td>Malware</td>
      <td></td>
      <td>4</td>
      <td></td>
      <td></td>
      <td></td>
    </tr>
    <tr>
      <td>Masked Language Model</td>
      <td>1</td>
      <td></td>
      <td></td>
      <td></td>
      <td></td>
    </tr>
    <tr>
      <td>Mathematical Reasoning</td>
      <td>1</td>
      <td></td>
      <td></td>
      <td></td>
      <td></td>
    </tr>
    <tr>
      <td>Message-Passing</td>
      <td></td>
      <td></td>
      <td></td>
      <td>1</td>
      <td></td>
    </tr>
    <tr>
      <td>Mistral</td>
      <td>1</td>
      <td></td>
      <td></td>
      <td>1</td>
      <td></td>
    </tr>
    <tr>
      <td>Mixed Reality (MR)</td>
      <td></td>
      <td></td>
      <td></td>
      <td></td>
      <td>1</td>
    </tr>
    <tr>
      <td>Model Pruning</td>
      <td></td>
      <td></td>
      <td>1</td>
      <td></td>
      <td></td>
    </tr>
    <tr>
      <td>Morphological Analysis</td>
      <td>1</td>
      <td></td>
      <td></td>
      <td></td>
      <td></td>
    </tr>
    <tr>
      <td>Multi-modal</td>
      <td>3</td>
      <td>2</td>
      <td>18</td>
      <td></td>
      <td></td>
    </tr>
    <tr>
      <td>Multiple Instance Learning</td>
      <td></td>
      <td></td>
      <td>1</td>
      <td></td>
      <td></td>
    </tr>
    <tr>
      <td>Named Entity Recognition</td>
      <td>6</td>
      <td></td>
      <td></td>
      <td></td>
      <td></td>
    </tr>
    <tr>
      <td>Natural Language Understanding</td>
      <td>1</td>
      <td></td>
      <td></td>
      <td></td>
      <td></td>
    </tr>
    <tr>
      <td>Neural Machine Translation</td>
      <td>1</td>
      <td></td>
      <td></td>
      <td></td>
      <td></td>
    </tr>
    <tr>
      <td>Node Embedding</td>
      <td></td>
      <td></td>
      <td></td>
      <td>1</td>
      <td></td>
    </tr>
    <tr>
      <td>Object Detection</td>
      <td></td>
      <td></td>
      <td>4</td>
      <td></td>
      <td>1</td>
    </tr>
    <tr>
      <td>Opinion Summarization</td>
      <td>1</td>
      <td></td>
      <td></td>
      <td></td>
      <td></td>
    </tr>
    <tr>
      <td>Optical Character Recognition</td>
      <td></td>
      <td></td>
      <td>3</td>
      <td></td>
      <td></td>
    </tr>
    <tr>
      <td>Out-of-distribution</td>
      <td></td>
      <td></td>
      <td>1</td>
      <td>1</td>
      <td></td>
    </tr>
    <tr>
      <td>Pre-trained Language Model</td>
      <td>3</td>
      <td></td>
      <td></td>
      <td></td>
      <td></td>
    </tr>
    <tr>
      <td>Probabilistic Model</td>
      <td></td>
      <td></td>
      <td>2</td>
      <td>1</td>
      <td></td>
    </tr>
    <tr>
      <td>Prompt</td>
      <td>4</td>
      <td></td>
      <td>11</td>
      <td>2</td>
      <td></td>
    </tr>
    <tr>
      <td>Prompt Learning</td>
      <td></td>
      <td></td>
      <td>1</td>
      <td></td>
      <td></td>
    </tr>
    <tr>
      <td>Pruning</td>
      <td></td>
      <td></td>
      <td>2</td>
      <td>1</td>
      <td></td>
    </tr>
    <tr>
      <td>Quantization</td>
      <td>2</td>
      <td>1</td>
      <td>2</td>
      <td>3</td>
      <td></td>
    </tr>
    <tr>
      <td>Question Answering</td>
      <td>9</td>
      <td></td>
      <td>2</td>
      <td></td>
      <td></td>
    </tr>
    <tr>
      <td>Reasoning</td>
      <td>4</td>
      <td></td>
      <td>3</td>
      <td>1</td>
      <td>1</td>
    </tr>
    <tr>
      <td>Recurrent Neural Network</td>
      <td>1</td>
      <td></td>
      <td>1</td>
      <td></td>
      <td></td>
    </tr>
    <tr>
      <td>Reinforcement Learning</td>
      <td>1</td>
      <td></td>
      <td>2</td>
      <td>3</td>
      <td>3</td>
    </tr>
    <tr>
      <td>Reinforcement Learning from Human Feedback</td>
      <td>2</td>
      <td></td>
      <td>2</td>
      <td></td>
      <td></td>
    </tr>
    <tr>
      <td>Relation Extraction</td>
      <td>4</td>
      <td></td>
      <td></td>
      <td></td>
      <td></td>
    </tr>
    <tr>
      <td>Representation Learning</td>
      <td></td>
      <td></td>
      <td>1</td>
      <td>1</td>
      <td></td>
    </tr>
    <tr>
      <td>Rerank</td>
      <td>1</td>
      <td></td>
      <td></td>
      <td></td>
      <td></td>
    </tr>
    <tr>
      <td>Retrieval-Augmented Generation</td>
      <td>6</td>
      <td></td>
      <td></td>
      <td></td>
      <td></td>
    </tr>
    <tr>
      <td>RoBERTa</td>
      <td>2</td>
      <td></td>
      <td></td>
      <td></td>
      <td></td>
    </tr>
    <tr>
      <td>Rouge</td>
      <td>1</td>
      <td></td>
      <td></td>
      <td></td>
      <td></td>
    </tr>
    <tr>
      <td>Scaling Law</td>
      <td>1</td>
      <td></td>
      <td></td>
      <td>1</td>
      <td></td>
    </tr>
    <tr>
      <td>Security</td>
      <td></td>
      <td>6</td>
      <td>2</td>
      <td>1</td>
      <td></td>
    </tr>
    <tr>
      <td>Self-Attention</td>
      <td></td>
      <td></td>
      <td>4</td>
      <td></td>
      <td></td>
    </tr>
    <tr>
      <td>Self-supervised Learning</td>
      <td>1</td>
      <td></td>
      <td>6</td>
      <td></td>
      <td></td>
    </tr>
    <tr>
      <td>Semi-Supervised Learning</td>
      <td></td>
      <td></td>
      <td></td>
      <td>1</td>
      <td></td>
    </tr>
    <tr>
      <td>Semi-Supervised Training</td>
      <td></td>
      <td></td>
      <td>1</td>
      <td></td>
      <td></td>
    </tr>
    <tr>
      <td>Sentiment Analysis</td>
      <td>3</td>
      <td></td>
      <td></td>
      <td></td>
      <td></td>
    </tr>
    <tr>
      <td>Simulation</td>
      <td>2</td>
      <td></td>
      <td>2</td>
      <td>3</td>
      <td>9</td>
    </tr>
    <tr>
      <td>Simulator</td>
      <td>2</td>
      <td></td>
      <td>2</td>
      <td>3</td>
      <td>9</td>
    </tr>
    <tr>
      <td>Stance Detection</td>
      <td>1</td>
      <td></td>
      <td></td>
      <td></td>
      <td></td>
    </tr>
    <tr>
      <td>Stemming</td>
      <td></td>
      <td></td>
      <td></td>
      <td>1</td>
      <td></td>
    </tr>
    <tr>
      <td>Stochastic Gradient Descent</td>
      <td></td>
      <td></td>
      <td></td>
      <td>2</td>
      <td></td>
    </tr>
    <tr>
      <td>Style Transfer</td>
      <td></td>
      <td></td>
      <td>2</td>
      <td></td>
      <td></td>
    </tr>
    <tr>
      <td>Summarization</td>
      <td>3</td>
      <td>1</td>
      <td></td>
      <td></td>
      <td></td>
    </tr>
    <tr>
      <td>Supervised Learning</td>
      <td>6</td>
      <td></td>
      <td>5</td>
      <td>2</td>
      <td></td>
    </tr>
    <tr>
      <td>Text Classification</td>
      <td>2</td>
      <td></td>
      <td></td>
      <td></td>
      <td></td>
    </tr>
    <tr>
      <td>Text Generation</td>
      <td>2</td>
      <td></td>
      <td></td>
      <td></td>
      <td></td>
    </tr>
    <tr>
      <td>Text Mining</td>
      <td>1</td>
      <td></td>
      <td></td>
      <td></td>
      <td></td>
    </tr>
    <tr>
      <td>Text Understanding</td>
      <td>1</td>
      <td></td>
      <td></td>
      <td></td>
      <td></td>
    </tr>
    <tr>
      <td>Text2image</td>
      <td></td>
      <td></td>
      <td>8</td>
      <td></td>
      <td></td>
    </tr>
    <tr>
      <td>Transfer Learning</td>
      <td></td>
      <td></td>
      <td>1</td>
      <td></td>
      <td></td>
    </tr>
    <tr>
      <td>Transformer</td>
      <td>3</td>
      <td></td>
      <td>12</td>
      <td>3</td>
      <td>1</td>
    </tr>
    <tr>
      <td>Unsupervised Learning</td>
      <td>4</td>
      <td></td>
      <td>3</td>
      <td>2</td>
      <td>1</td>
    </tr>
    <tr>
      <td>Virtual Reality (VR)</td>
      <td></td>
      <td></td>
      <td></td>
      <td></td>
      <td>2</td>
    </tr>
    <tr>
      <td>Vision Transformer</td>
      <td></td>
      <td></td>
      <td>8</td>
      <td></td>
      <td></td>
    </tr>
    <tr>
      <td>Vision-and-Language</td>
      <td></td>
      <td></td>
      <td>8</td>
      <td></td>
      <td></td>
    </tr>
    <tr>
      <td>Visual Question Answering</td>
      <td></td>
      <td></td>
      <td>2</td>
      <td></td>
      <td></td>
    </tr>
    <tr>
      <td>Weakly-supervised Learning</td>
      <td></td>
      <td></td>
      <td>1</td>
      <td></td>
      <td></td>
    </tr>
    <tr>
      <td>Yolo</td>
      <td></td>
      <td></td>
      <td>1</td>
      <td></td>
      <td></td>
    </tr>
    <tr>
      <td>Zero-shot</td>
      <td>2</td>
      <td></td>
      <td>8</td>
      <td>1</td>
      <td>2</td>
    </tr>
  </tbody>
</table>

<script>
$(function() {
  $("table").addClass("keyword-table table-bordered border-success");
  $("table thead").addClass("sticky-top");
  $("table tbody td").css("text-align", "");
});
</script>


## cs.CL (43)



### (1/43 | 1/266) Relation Extraction Using Large Language Models: A Case Study on Acupuncture Point Locations (Yiming Li et al., 2024)

{{<citation>}}

Yiming Li, Xueqing Peng, Jianfu Li, Xu Zuo, Suyuan Peng, Donghong Pei, Cui Tao, Hua Xu, Na Hong. (2024)  
**Relation Extraction Using Large Language Models: A Case Study on Acupuncture Point Locations**
<br/>
<button class="copy-to-clipboard" title="Relation Extraction Using Large Language Models: A Case Study on Acupuncture Point Locations" index=1>
  <span class="copy-to-clipboard-item">Copy Title<span>
</button>
<div class="toast toast-copied toast-index-1 align-items-center text-bg-secondary border-0 position-absolute top-0 end-0" role="alert" aria-live="assertive" aria-atomic="true">
  <div class="d-flex">
    <div class="toast-body">
      Copied!
    </div>
  </div>
</div>

---
Primary Category: cs.CL  
Categories: cs-AI, cs-CL, cs.CL  
Keyword Score: 140  
Keywords: Fine-tuning, Fine-tuning, GPT, GPT-3, GPT-3.5, GPT-4, LSTM, LSTM, LSTM, Transformer, Relation Extraction, Text Mining, Large Language Model, Large Language Model  
<a type="button" class="btn btn-outline-primary" href="http://arxiv.org/abs/2404.05415v1" target="_blank" >Paper Link</a>
<button type="button" class="btn btn-outline-primary download-pdf" url="https://arxiv.org/pdf/2404.05415v1.pdf" filename="2404.05415v1.pdf">Download PDF</button>

---


**ABSTRACT**  
In acupuncture therapy, the accurate location of acupoints is essential for its effectiveness. The advanced language understanding capabilities of <b>large</b> <b>language</b> <b>models</b> <b>(LLMs)</b> like Generative Pre-trained <b>Transformers</b> <b>(GPT)</b> present a significant opportunity for extracting <b>relations</b> <b>related</b> to acupoint locations from textual knowledge sources. This study aims to compare the performance of <b>GPT</b> with traditional deep learning models <b>(Long</b> <b>Short-Term</b> <b>Memory</b> <b>(LSTM)</b> and Bidirectional Encoder Representations from <b>Transformers</b> for Biomedical <b>Text</b> <b>Mining</b> (BioBERT)) in extracting acupoint-related location <b>relations</b> <b>and</b> assess the impact of pretraining and <b>fine-tuning</b> on <b>GPT's</b> performance. We utilized the World Health Organization Standard Acupuncture Point Locations in the Western Pacific Region (WHO Standard) as our corpus, which consists of descriptions of 361 acupoints. Five types of <b>relations</b> <b>('direction_of,'</b> 'distance_of,' 'part_of,' 'near_acupoint,' and 'located_near') (n= 3,174) between acupoints were annotated. Five models were compared: BioBERT, <b>LSTM,</b> pre-trained <b>GPT-3.5,</b> and <b>fine-tuned</b> <b>GPT-3.5,</b> as well as pre-trained <b>GPT-4.</b> Performance metrics included micro-average exact match precision, recall, and F1 scores. Our results demonstrate that <b>fine-tuned</b> <b>GPT-3.5</b> consistently outperformed other models in F1 scores across all <b>relation</b> <b>types.</b> Overall, it achieved the highest micro-average F1 score of 0.92. This study underscores the effectiveness of <b>LLMs</b> like <b>GPT</b> in extracting <b>relations</b> <b>related</b> to acupoint locations, with implications for accurately modeling acupuncture knowledge and promoting standard implementation in acupuncture training and practice. The findings also contribute to advancing informatics applications in traditional and complementary medicine, showcasing the potential of <b>LLMs</b> in natural language processing.

{{</citation>}}


### (2/43 | 2/266) Enhancing Software Related Information Extraction with Generative Language Models through Single-Choice Question Answering (Wolfgang Otto et al., 2024)

{{<citation>}}

Wolfgang Otto, Sharmila Upadhyaya, Stefan Dietze. (2024)  
**Enhancing Software Related Information Extraction with Generative Language Models through Single-Choice Question Answering**
<br/>
<button class="copy-to-clipboard" title="Enhancing Software Related Information Extraction with Generative Language Models through Single-Choice Question Answering" index=2>
  <span class="copy-to-clipboard-item">Copy Title<span>
</button>
<div class="toast toast-copied toast-index-2 align-items-center text-bg-secondary border-0 position-absolute top-0 end-0" role="alert" aria-live="assertive" aria-atomic="true">
  <div class="d-flex">
    <div class="toast-body">
      Copied!
    </div>
  </div>
</div>

---
Primary Category: cs.CL  
Categories: I-2-7, cs-CL, cs.CL  
Keyword Score: 120  
Keywords: Retrieval-Augmented Generation, Retrieval-Augmented Generation, Retrieval-Augmented Generation, Disambiguation, Information Retrieval, Named Entity Recognition, Named Entity Recognition, Question Answering, Question Answering, Relation Extraction, In-context Learning, In-context Learning  
<a type="button" class="btn btn-outline-primary" href="http://arxiv.org/abs/2404.05587v1" target="_blank" >Paper Link</a>
<button type="button" class="btn btn-outline-primary download-pdf" url="https://arxiv.org/pdf/2404.05587v1.pdf" filename="2404.05587v1.pdf">Download PDF</button>

---


**ABSTRACT**  
This paper describes our participation in the Shared Task on Software Mentions <b>Disambiguation</b> (SOMD), with a focus on improving <b>relation</b> <b>extraction</b> in scholarly texts through Generative Language Models (GLMs) using single-choice <b>question-answering.</b> <b>The</b> methodology prioritises the use of <b>in-context</b> <b>learning</b> capabilities of GLMs to extract software-related entities and their descriptive attributes, such as distributive <b>information.</b> <b>Our</b> approach uses <b>Retrieval-Augmented</b> <b>Generation</b> <b>(RAG)</b> techniques and GLMs for <b>Named</b> <b>Entity</b> <b>Recognition</b> <b>(NER)</b> and Attributive <b>NER</b> to identify relationships between extracted software entities, providing a structured solution for analysing software citations in academic literature. The paper provides a detailed description of our approach, demonstrating how using GLMs in a single-choice <b>QA</b> paradigm can greatly enhance IE methodologies. Our participation in the SOMD shared task highlights the importance of precise software citation practices and showcases our system's ability to overcome the challenges of disambiguating and extracting relationships between software mentions. This sets the groundwork for future research and development in this field.

{{</citation>}}


### (3/43 | 3/266) LTNER: Large Language Model Tagging for Named Entity Recognition with Contextualized Entity Marking (Faren Yan et al., 2024)

{{<citation>}}

Faren Yan, Peng Yu, Xin Chen. (2024)  
**LTNER: Large Language Model Tagging for Named Entity Recognition with Contextualized Entity Marking**
<br/>
<button class="copy-to-clipboard" title="LTNER: Large Language Model Tagging for Named Entity Recognition with Contextualized Entity Marking" index=3>
  <span class="copy-to-clipboard-item">Copy Title<span>
</button>
<div class="toast toast-copied toast-index-3 align-items-center text-bg-secondary border-0 position-absolute top-0 end-0" role="alert" aria-live="assertive" aria-atomic="true">
  <div class="d-flex">
    <div class="toast-body">
      Copied!
    </div>
  </div>
</div>

---
Primary Category: cs.CL  
Categories: cs-AI, cs-CL, cs.CL  
Keyword Score: 100  
Keywords: Fine-tuning, Supervised Learning, Supervised Learning, GPT, GPT-3, GPT-3.5, Named Entity Recognition, Named Entity Recognition, Large Language Model, Large Language Model  
<a type="button" class="btn btn-outline-primary" href="http://arxiv.org/abs/2404.05624v1" target="_blank" >Paper Link</a>
<button type="button" class="btn btn-outline-primary download-pdf" url="https://arxiv.org/pdf/2404.05624v1.pdf" filename="2404.05624v1.pdf">Download PDF</button>

---


**ABSTRACT**  
The use of <b>LLMs</b> for natural language processing has become a popular trend in the past two years, driven by their formidable capacity for context comprehension and learning, which has inspired a wave of research from academics and industry professionals. However, for certain NLP tasks, such as <b>NER,</b> the performance of <b>LLMs</b> still falls short when compared to <b>supervised</b> <b>learning</b> methods. In our research, we developed a <b>NER</b> processing framework called LTNER that incorporates a revolutionary Contextualized Entity Marking Gen Method. By leveraging the cost-effective <b>GPT-3.5</b> coupled with context learning that does not require additional training, we significantly improved the accuracy of <b>LLMs</b> in handling <b>NER</b> tasks. The F1 score on the CoNLL03 dataset increased from the initial 85.9% to 91.9%, approaching the performance of <b>supervised</b> <b>fine-tuning.</b> This outcome has led to a deeper understanding of the potential of <b>LLMs.</b>

{{</citation>}}


### (4/43 | 4/266) MedExpQA: Multilingual Benchmarking of Large Language Models for Medical Question Answering (Iñigo Alonso et al., 2024)

{{<citation>}}

Iñigo Alonso, Maite Oronoz, Rodrigo Agerri. (2024)  
**MedExpQA: Multilingual Benchmarking of Large Language Models for Medical Question Answering**
<br/>
<button class="copy-to-clipboard" title="MedExpQA: Multilingual Benchmarking of Large Language Models for Medical Question Answering" index=4>
  <span class="copy-to-clipboard-item">Copy Title<span>
</button>
<div class="toast toast-copied toast-index-4 align-items-center text-bg-secondary border-0 position-absolute top-0 end-0" role="alert" aria-live="assertive" aria-atomic="true">
  <div class="d-flex">
    <div class="toast-body">
      Copied!
    </div>
  </div>
</div>

---
Primary Category: cs.CL  
Categories: cs-CL, cs.CL  
Keyword Score: 86  
Keywords: Benchmarking, Benchmarking, Retrieval-Augmented Generation, Retrieval-Augmented Generation, Retrieval-Augmented Generation, Question Answering, Question Answering, Reasoning, Large Language Model, Large Language Model  
<a type="button" class="btn btn-outline-primary" href="http://arxiv.org/abs/2404.05590v1" target="_blank" >Paper Link</a>
<button type="button" class="btn btn-outline-primary download-pdf" url="https://arxiv.org/pdf/2404.05590v1.pdf" filename="2404.05590v1.pdf">Download PDF</button>

---


**ABSTRACT**  
<b>Large</b> <b>Language</b> <b>Models</b> <b>(LLMs)</b> have the potential of facilitating the development of Artificial Intelligence technology to assist medical experts for interactive decision support, which has been demonstrated by their competitive performances in Medical <b>QA.</b> However, while impressive, the required quality bar for medical applications remains far from being achieved. Currently, <b>LLMs</b> remain challenged by outdated knowledge and by their tendency to generate hallucinated content. Furthermore, most <b>benchmarks</b> to assess medical knowledge lack reference gold explanations which means that it is not possible to evaluate the <b>reasoning</b> of <b>LLMs</b> predictions. Finally, the situation is particularly grim if we consider <b>benchmarking</b> <b>LLMs</b> for languages other than English which remains, as far as we know, a totally neglected topic. In order to address these shortcomings, in this paper we present MedExpQA, the first multilingual <b>benchmark</b> based on medical exams to evaluate <b>LLMs</b> in Medical <b>Question</b> <b>Answering.</b> To the best of our knowledge, MedExpQA includes for the first time reference gold explanations written by medical doctors which can be leveraged to establish various gold-based upper-bounds for comparison with <b>LLMs</b> performance. Comprehensive multilingual experimentation using both the gold reference explanations and <b>Retrieval</b> <b>Augmented</b> <b>Generation</b> <b>(RAG)</b> approaches show that performance of <b>LLMs</b> still has <b>large</b> <b>room</b> <b>for</b> improvement, especially for languages other than English. Furthermore, and despite using state-of-the-art <b>RAG</b> methods, our results also demonstrate the difficulty of obtaining and integrating readily available medical knowledge that may positively impact results on downstream evaluations for Medical <b>Question</b> <b>Answering.</b> So far the <b>benchmark</b> is available in four languages, but we hope that this work may encourage further development to other languages.

{{</citation>}}


### (5/43 | 5/266) Comprehensive Study on German Language Models for Clinical and Biomedical Text Understanding (Ahmad Idrissi-Yaghir et al., 2024)

{{<citation>}}

Ahmad Idrissi-Yaghir, Amin Dada, Henning Schäfer, Kamyar Arzideh, Giulia Baldini, Jan Trienes, Max Hasin, Jeanette Bewersdorff, Cynthia S. Schmidt, Marie Bauer, Kaleb E. Smith, Jiang Bian, Yonghui Wu, Jörg Schlötterer, Torsten Zesch, Peter A. Horn, Christin Seifert, Felix Nensa, Jens Kleesiek, Christoph M. Friedrich. (2024)  
**Comprehensive Study on German Language Models for Clinical and Biomedical Text Understanding**
<br/>
<button class="copy-to-clipboard" title="Comprehensive Study on German Language Models for Clinical and Biomedical Text Understanding" index=5>
  <span class="copy-to-clipboard-item">Copy Title<span>
</button>
<div class="toast toast-copied toast-index-5 align-items-center text-bg-secondary border-0 position-absolute top-0 end-0" role="alert" aria-live="assertive" aria-atomic="true">
  <div class="d-flex">
    <div class="toast-body">
      Copied!
    </div>
  </div>
</div>

---
Primary Category: cs.CL  
Categories: cs-AI, cs-CL, cs-LG, cs.CL  
Keyword Score: 80  
Keywords: BERT, RoBERTa, Named Entity Recognition, Named Entity Recognition, Question Answering, Domain Adaptation, Pre-trained Language Model, Text Understanding  
<a type="button" class="btn btn-outline-primary" href="http://arxiv.org/abs/2404.05694v1" target="_blank" >Paper Link</a>
<button type="button" class="btn btn-outline-primary download-pdf" url="https://arxiv.org/pdf/2404.05694v1.pdf" filename="2404.05694v1.pdf">Download PDF</button>

---


**ABSTRACT**  
Recent advances in natural language processing (NLP) can be largely attributed to the advent of <b>pre-trained</b> <b>language</b> <b>models</b> such as <b>BERT</b> and <b>RoBERTa.</b> While these models demonstrate remarkable performance on general datasets, they can struggle in specialized <b>domains</b> <b>such</b> as medicine, where unique <b>domain-specific</b> <b>terminologies,</b> <b>domain-specific</b> <b>abbreviations,</b> and varying document structures are common. This paper explores strategies for adapting these models to <b>domain-specific</b> <b>requirements,</b> primarily through continuous pre-training on <b>domain-specific</b> <b>data.</b> We <b>pre-trained</b> <b>several</b> <b>German</b> medical language models on 2.4B tokens derived from translated public English medical data and 3B tokens of German clinical data. The resulting models were evaluated on various German downstream tasks, including <b>named</b> <b>entity</b> <b>recognition</b> <b>(NER),</b> multi-label classification, and extractive <b>question</b> <b>answering.</b> Our results suggest that models augmented by clinical and translation-based pre-training typically outperform general <b>domain</b> <b>models</b> in medical contexts. We conclude that continuous pre-training has demonstrated the ability to match or even exceed the performance of clinical models trained from scratch. Furthermore, pre-training on clinical data or leveraging translated <b>texts</b> <b>have</b> proven to be reliable methods for <b>domain</b> <b>adaptation</b> in medical NLP tasks.

{{</citation>}}


### (6/43 | 6/266) WILBUR: Adaptive In-Context Learning for Robust and Accurate Web Agents (Michael Lutz et al., 2024)

{{<citation>}}

Michael Lutz, Arth Bohra, Manvel Saroyan, Artem Harutyunyan, Giovanni Campagna. (2024)  
**WILBUR: Adaptive In-Context Learning for Robust and Accurate Web Agents**
<br/>
<button class="copy-to-clipboard" title="WILBUR: Adaptive In-Context Learning for Robust and Accurate Web Agents" index=6>
  <span class="copy-to-clipboard-item">Copy Title<span>
</button>
<div class="toast toast-copied toast-index-6 align-items-center text-bg-secondary border-0 position-absolute top-0 end-0" role="alert" aria-live="assertive" aria-atomic="true">
  <div class="d-flex">
    <div class="toast-body">
      Copied!
    </div>
  </div>
</div>

---
Primary Category: cs.CL  
Categories: cs-AI, cs-CL, cs.CL  
Keyword Score: 71  
Keywords: Benchmarking, Black Box, Fine-tuning, Multi-modal, In-context Learning, In-context Learning, Large Language Model, Large Language Model, Prompt  
<a type="button" class="btn btn-outline-primary" href="http://arxiv.org/abs/2404.05902v1" target="_blank" >Paper Link</a>
<button type="button" class="btn btn-outline-primary download-pdf" url="https://arxiv.org/pdf/2404.05902v1.pdf" filename="2404.05902v1.pdf">Download PDF</button>

---


**ABSTRACT**  
In the realm of web agent research, achieving both generalization and accuracy remains a challenging problem. Due to high variance in website structure, existing approaches often fail. Moreover, existing <b>fine-tuning</b> and <b>in-context</b> <b>learning</b> techniques fail to generalize across multiple websites. We introduce Wilbur, an approach that uses a differentiable ranking model and a novel instruction synthesis technique to optimally populate a <b>black-box</b> <b>large</b> <b>language</b> <b>model's</b> <b>prompt</b> with task demonstrations from previous runs. To maximize end-to-end success rates, we also propose an intelligent backtracking mechanism that learns and recovers from its mistakes. Finally, we show that our ranking model can be trained on data from a generative auto-curriculum which samples representative goals from an <b>LLM,</b> runs the agent, and automatically evaluates it, with no manual annotation. Wilbur achieves state-of-the-art results on the WebVoyager <b>benchmark,</b> beating text-only models by 8% overall, and up to 36% on certain websites. On the same <b>benchmark,</b> Wilbur is within 5% of a strong <b>multi-modal</b> model despite only receiving textual inputs, and further analysis reveals a substantial number of failures are due to engineering challenges of operating the web.

{{</citation>}}


### (7/43 | 7/266) Chinese Sequence Labeling with Semi-Supervised Boundary-Aware Language Model Pre-training (Longhui Zhang et al., 2024)

{{<citation>}}

Longhui Zhang, Dingkun Long, Meishan Zhang, Yanzhao Zhang, Pengjun Xie, Min Zhang. (2024)  
**Chinese Sequence Labeling with Semi-Supervised Boundary-Aware Language Model Pre-training**
<br/>
<button class="copy-to-clipboard" title="Chinese Sequence Labeling with Semi-Supervised Boundary-Aware Language Model Pre-training" index=7>
  <span class="copy-to-clipboard-item">Copy Title<span>
</button>
<div class="toast toast-copied toast-index-7 align-items-center text-bg-secondary border-0 position-absolute top-0 end-0" role="alert" aria-live="assertive" aria-atomic="true">
  <div class="d-flex">
    <div class="toast-body">
      Copied!
    </div>
  </div>
</div>

---
Primary Category: cs.CL  
Categories: cs-CL, cs.CL  
Keyword Score: 70  
Keywords: Fine-tuning, Supervised Learning, Unsupervised Learning, BERT, Natural Language Understanding, Pre-trained Language Model, Pre-trained Language Model  
<a type="button" class="btn btn-outline-primary" href="http://arxiv.org/abs/2404.05560v1" target="_blank" >Paper Link</a>
<button type="button" class="btn btn-outline-primary download-pdf" url="https://arxiv.org/pdf/2404.05560v1.pdf" filename="2404.05560v1.pdf">Download PDF</button>

---


**ABSTRACT**  
Chinese sequence labeling tasks are heavily reliant on accurate word boundary demarcation. Although current <b>pre-trained</b> <b>language</b> <b>models</b> <b>(PLMs)</b> have achieved substantial gains on these tasks, they rarely explicitly incorporate boundary information into the modeling process. An exception to this is BABERT, which incorporates <b>unsupervised</b> statistical boundary information into Chinese <b>BERT's</b> pre-training objectives. Building upon this approach, we input <b>supervised</b> high-quality boundary information to enhance BABERT's learning, developing a semi-supervised boundary-aware <b>PLM.</b> To assess <b>PLMs'</b> ability to encode boundaries, we introduce a novel ``Boundary Information Metric'' that is both simple and effective. This metric allows comparison of different <b>PLMs</b> without task-specific <b>fine-tuning.</b> Experimental results on Chinese sequence labeling datasets demonstrate that the improved BABERT variant outperforms the vanilla version, not only on these tasks but also more broadly across a range of Chinese <b>natural</b> <b>language</b> <b>understanding</b> tasks. Additionally, our proposed metric offers a convenient and accurate means of evaluating <b>PLMs'</b> boundary awareness.

{{</citation>}}


### (8/43 | 8/266) Product Description and QA Assisted Self-Supervised Opinion Summarization (Tejpalsingh Siledar et al., 2024)

{{<citation>}}

Tejpalsingh Siledar, Rupasai Rangaraju, Sankara Sri Raghava Ravindra Muddu, Suman Banerjee, Amey Patil, Sudhanshu Shekhar Singh, Muthusamy Chelliah, Nikesh Garera, Swaprava Nath, Pushpak Bhattacharyya. (2024)  
**Product Description and QA Assisted Self-Supervised Opinion Summarization**
<br/>
<button class="copy-to-clipboard" title="Product Description and QA Assisted Self-Supervised Opinion Summarization" index=8>
  <span class="copy-to-clipboard-item">Copy Title<span>
</button>
<div class="toast toast-copied toast-index-8 align-items-center text-bg-secondary border-0 position-absolute top-0 end-0" role="alert" aria-live="assertive" aria-atomic="true">
  <div class="d-flex">
    <div class="toast-body">
      Copied!
    </div>
  </div>
</div>

---
Primary Category: cs.CL  
Categories: cs-AI, cs-CL, cs.CL  
Keyword Score: 70  
Keywords: Self-supervised Learning, Supervised Learning, ChatGPT, Opinion Summarization, Question Answering, Rouge, Summarization  
<a type="button" class="btn btn-outline-primary" href="http://arxiv.org/abs/2404.05243v1" target="_blank" >Paper Link</a>
<button type="button" class="btn btn-outline-primary download-pdf" url="https://arxiv.org/pdf/2404.05243v1.pdf" filename="2404.05243v1.pdf">Download PDF</button>

---


**ABSTRACT**  
In e-commerce, <b>opinion</b> <b>summarization</b> is the process of summarizing the consensus <b>opinions</b> <b>found</b> in product reviews. However, the potential of additional sources such as product description and question-answers <b>(QA)</b> has been considered less often. Moreover, the absence of any <b>supervised</b> training data makes this task challenging. To address this, we propose a novel synthetic dataset creation (SDC) strategy that leverages information from reviews as well as additional sources for selecting one of the reviews as a pseudo-summary to enable <b>supervised</b> training. Our Multi-Encoder Decoder framework for <b>Opinion</b> <b>Summarization</b> (MEDOS) employs a separate encoder for each source, enabling effective selection of information while generating the summary. For evaluation, due to the unavailability of test sets with additional sources, we extend the Amazon, Oposum+, and Flipkart test sets and leverage <b>ChatGPT</b> to annotate summaries. Experiments across nine test sets demonstrate that the combination of our SDC approach and MEDOS model achieves on average a 14.5% improvement in <b>ROUGE-1</b> F1 over the SOTA. Moreover, comparative analysis underlines the significance of incorporating additional sources for generating more informative summaries. Human evaluations further indicate that MEDOS scores relatively higher in coherence and fluency with 0.41 and 0.5 (-1 to 1) respectively, compared to existing models. To the best of our knowledge, we are the first to generate <b>opinion</b> <b>summaries</b> leveraging additional sources in a <b>self-supervised</b> setting.

{{</citation>}}


### (9/43 | 9/266) Plug and Play with Prompts: A Prompt Tuning Approach for Controlling Text Generation (Rohan Deepak Ajwani et al., 2024)

{{<citation>}}

Rohan Deepak Ajwani, Zining Zhu, Jonathan Rose, Frank Rudzicz. (2024)  
**Plug and Play with Prompts: A Prompt Tuning Approach for Controlling Text Generation**
<br/>
<button class="copy-to-clipboard" title="Plug and Play with Prompts: A Prompt Tuning Approach for Controlling Text Generation" index=9>
  <span class="copy-to-clipboard-item">Copy Title<span>
</button>
<div class="toast toast-copied toast-index-9 align-items-center text-bg-secondary border-0 position-absolute top-0 end-0" role="alert" aria-live="assertive" aria-atomic="true">
  <div class="d-flex">
    <div class="toast-body">
      Copied!
    </div>
  </div>
</div>

---
Primary Category: cs.CL  
Categories: cs-AI, cs-CL, cs-LG, cs.CL  
Keyword Score: 70  
Keywords: Transformer, Language Generation, Sentiment Analysis, Text Generation, Large Language Model, Large Language Model, Prompt  
<a type="button" class="btn btn-outline-primary" href="http://arxiv.org/abs/2404.05143v1" target="_blank" >Paper Link</a>
<button type="button" class="btn btn-outline-primary download-pdf" url="https://arxiv.org/pdf/2404.05143v1.pdf" filename="2404.05143v1.pdf">Download PDF</button>

---


**ABSTRACT**  
<b>Transformer-based</b> <b>Large</b> <b>Language</b> <b>Models</b> <b>(LLMs)</b> have shown exceptional <b>language</b> <b>generation</b> capabilities in response to <b>text-based</b> <b>prompts.</b> However, controlling the direction of generation via textual <b>prompts</b> has been challenging, especially with smaller models. In this work, we explore the use of <b>Prompt</b> Tuning to achieve controlled <b>language</b> <b>generation.</b> Generated <b>text</b> <b>is</b> steered using <b>prompt</b> embeddings, which are trained using a small <b>language</b> <b>model,</b> used as a discriminator. Moreover, we demonstrate that these <b>prompt</b> embeddings can be trained with a very small dataset, with as low as a few hundred training examples. Our method thus offers a data and parameter efficient solution towards controlling <b>language</b> <b>model</b> outputs. We carry out extensive evaluation on four datasets: SST-5 and Yelp <b>(sentiment</b> <b>analysis),</b> GYAFC (formality) and JIGSAW (toxic <b>language).</b> <b>Finally,</b> we demonstrate the efficacy of our method towards mitigating harmful, toxic, and biased <b>text</b> <b>generated</b> by <b>language</b> <b>models.</b>

{{</citation>}}


### (10/43 | 10/266) SambaLingo: Teaching Large Language Models New Languages (Zoltan Csaki et al., 2024)

{{<citation>}}

Zoltan Csaki, Bo Li, Jonathan Li, Qiantong Xu, Pian Pawakapan, Leon Zhang, Yun Du, Hengyu Zhao, Changran Hu, Urmish Thakker. (2024)  
**SambaLingo: Teaching Large Language Models New Languages**
<br/>
<button class="copy-to-clipboard" title="SambaLingo: Teaching Large Language Models New Languages" index=10>
  <span class="copy-to-clipboard-item">Copy Title<span>
</button>
<div class="toast toast-copied toast-index-10 align-items-center text-bg-secondary border-0 position-absolute top-0 end-0" role="alert" aria-live="assertive" aria-atomic="true">
  <div class="d-flex">
    <div class="toast-body">
      Copied!
    </div>
  </div>
</div>

---
Primary Category: cs.CL  
Categories: cs-AI, cs-CL, cs-LG, cs.CL  
Keyword Score: 60  
Keywords: Direct Preference Optimization, Low-Resource, BLOOM, LLaMA, Large Language Model, Large Language Model  
<a type="button" class="btn btn-outline-primary" href="http://arxiv.org/abs/2404.05829v1" target="_blank" >Paper Link</a>
<button type="button" class="btn btn-outline-primary download-pdf" url="https://arxiv.org/pdf/2404.05829v1.pdf" filename="2404.05829v1.pdf">Download PDF</button>

---


**ABSTRACT**  
Despite the widespread availability of <b>LLMs,</b> there remains a substantial gap in their capabilities and availability across diverse languages. One approach to address these issues has been to take an existing pre-trained <b>LLM</b> and continue to train it on new languages. While prior works have experimented with language adaptation, many questions around best practices and methodology have not been covered. In this paper, we present a comprehensive investigation into the adaptation of <b>LLMs</b> to new languages. Our study covers the key components in this process, including vocabulary extension, <b>direct</b> <b>preference</b> <b>optimization</b> and the data scarcity problem for human alignment in <b>low-resource</b> languages. We scale these experiments across 9 languages and 2 parameter scales (7B and 70B). We compare our models against <b>Llama</b> 2, Aya-101, XGLM, <b>BLOOM</b> and existing language experts, outperforming all prior published baselines. Additionally, all evaluation code and checkpoints are made public to facilitate future research.

{{</citation>}}


### (11/43 | 11/266) LLM Reasoners: New Evaluation, Library, and Analysis of Step-by-Step Reasoning with Large Language Models (Shibo Hao et al., 2024)

{{<citation>}}

Shibo Hao, Yi Gu, Haotian Luo, Tianyang Liu, Xiyan Shao, Xinyuan Wang, Shuhua Xie, Haodi Ma, Adithya Samavedhi, Qiyue Gao, Zhen Wang, Zhiting Hu. (2024)  
**LLM Reasoners: New Evaluation, Library, and Analysis of Step-by-Step Reasoning with Large Language Models**
<br/>
<button class="copy-to-clipboard" title="LLM Reasoners: New Evaluation, Library, and Analysis of Step-by-Step Reasoning with Large Language Models" index=11>
  <span class="copy-to-clipboard-item">Copy Title<span>
</button>
<div class="toast toast-copied toast-index-11 align-items-center text-bg-secondary border-0 position-absolute top-0 end-0" role="alert" aria-live="assertive" aria-atomic="true">
  <div class="d-flex">
    <div class="toast-body">
      Copied!
    </div>
  </div>
</div>

---
Primary Category: cs.CL  
Categories: cs-AI, cs-CL, cs.CL  
Keyword Score: 60  
Keywords: GPT, GPT-4, Reasoning, Large Language Model, Large Language Model, Prompt  
<a type="button" class="btn btn-outline-primary" href="http://arxiv.org/abs/2404.05221v1" target="_blank" >Paper Link</a>
<button type="button" class="btn btn-outline-primary download-pdf" url="https://arxiv.org/pdf/2404.05221v1.pdf" filename="2404.05221v1.pdf">Download PDF</button>

---


**ABSTRACT**  
Generating accurate step-by-step <b>reasoning</b> is essential for <b>Large</b> <b>Language</b> <b>Models</b> <b>(LLMs)</b> to address complex problems and enhance robustness and interpretability. Despite the flux of research on developing advanced <b>reasoning</b> approaches, systematically analyzing the diverse <b>LLMs</b> and <b>reasoning</b> strategies in generating <b>reasoning</b> chains remains a significant challenge. The difficulties stem from the lack of two key elements: (1) an automatic method for evaluating the generated <b>reasoning</b> chains on different tasks, and (2) a unified formalism and implementation of the diverse <b>reasoning</b> approaches for systematic comparison. This paper aims to close the gap: (1) We introduce AutoRace for fully automated <b>reasoning</b> chain evaluation. Existing metrics rely on expensive human annotations or pre-defined <b>LLM</b> <b>prompts</b> not adaptable to different tasks. In contrast, AutoRace automatically creates detailed evaluation criteria tailored for each task, and uses <b>GPT-4</b> for accurate evaluation following the criteria. (2) We develop <b>LLM</b> Reasoners, a library for standardized modular implementation of existing and new <b>reasoning</b> algorithms, under a unified formulation of the search, reward, and world model components. With the new evaluation and library, (3) we conduct extensive study of different <b>reasoning</b> approaches (e.g., CoT, ToT, RAP). The analysis reveals interesting findings about different factors contributing to <b>reasoning,</b> including the reward-guidance, breadth-vs-depth in search, world model, and <b>prompt</b> formats, etc.

{{</citation>}}


### (12/43 | 12/266) Semantic Stealth: Adversarial Text Attacks on NLP Using Several Methods (Roopkatha Dey et al., 2024)

{{<citation>}}

Roopkatha Dey, Aivy Debnath, Sayak Kumar Dutta, Kaustav Ghosh, Arijit Mitra, Arghya Roy Chowdhury, Jaydip Sen. (2024)  
**Semantic Stealth: Adversarial Text Attacks on NLP Using Several Methods**
<br/>
<button class="copy-to-clipboard" title="Semantic Stealth: Adversarial Text Attacks on NLP Using Several Methods" index=12>
  <span class="copy-to-clipboard-item">Copy Title<span>
</button>
<div class="toast toast-copied toast-index-12 align-items-center text-bg-secondary border-0 position-absolute top-0 end-0" role="alert" aria-live="assertive" aria-atomic="true">
  <div class="d-flex">
    <div class="toast-body">
      Copied!
    </div>
  </div>
</div>

---
Primary Category: cs.CL  
Categories: cs-CL, cs-CR, cs-LG, cs.CL  
Keyword Score: 60  
Keywords: BERT, Neural Machine Translation, Question Answering, Sentiment Analysis, Text Classification, Adversarial Attack  
<a type="button" class="btn btn-outline-primary" href="http://arxiv.org/abs/2404.05159v1" target="_blank" >Paper Link</a>
<button type="button" class="btn btn-outline-primary download-pdf" url="https://arxiv.org/pdf/2404.05159v1.pdf" filename="2404.05159v1.pdf">Download PDF</button>

---


**ABSTRACT**  
In various real-world applications such as <b>machine</b> <b>translation,</b> <b>sentiment</b> <b>analysis,</b> and <b>question</b> <b>answering,</b> a pivotal role is played by NLP models, facilitating efficient communication and decision-making processes in domains ranging from healthcare to finance. However, a significant challenge is posed to the robustness of these natural language processing models by <b>text</b> <b>adversarial</b> <b>attacks.</b> These attacks involve the deliberate manipulation of input <b>text</b> <b>to</b> mislead the predictions of the model while maintaining human interpretability. Despite the remarkable performance achieved by state-of-the-art models like <b>BERT</b> in various natural language processing tasks, they are found to remain vulnerable to <b>adversarial</b> <b>perturbations</b> in the input <b>text.</b> <b>In</b> addressing the vulnerability of <b>text</b> <b>classifiers</b> to <b>adversarial</b> <b>attacks,</b> three distinct attack mechanisms are explored in this paper using the victim model <b>BERT:</b> <b>BERT-on-BERT</b> attack, PWWS attack, and Fraud Bargain's Attack (FBA). Leveraging the IMDB, AG News, and SST2 datasets, a thorough comparative analysis is conducted to assess the effectiveness of these attacks on the <b>BERT</b> classifier model. It is revealed by the analysis that PWWS emerges as the most potent adversary, consistently outperforming other methods across multiple evaluation scenarios, thereby emphasizing its efficacy in generating <b>adversarial</b> <b>examples</b> for <b>text</b> <b>classification.</b> Through comprehensive experimentation, the performance of these attacks is assessed and the findings indicate that the PWWS attack outperforms others, demonstrating lower runtime, higher accuracy, and favorable semantic similarity scores. The key insight of this paper lies in the assessment of the relative performances of three prevalent state-of-the-art attack mechanisms.

{{</citation>}}


### (13/43 | 13/266) PetKaz at SemEval-2024 Task 3: Advancing Emotion Classification with an LLM for Emotion-Cause Pair Extraction in Conversations (Roman Kazakov et al., 2024)

{{<citation>}}

Roman Kazakov, Kseniia Petukhova, Ekaterina Kochmar. (2024)  
**PetKaz at SemEval-2024 Task 3: Advancing Emotion Classification with an LLM for Emotion-Cause Pair Extraction in Conversations**
<br/>
<button class="copy-to-clipboard" title="PetKaz at SemEval-2024 Task 3: Advancing Emotion Classification with an LLM for Emotion-Cause Pair Extraction in Conversations" index=13>
  <span class="copy-to-clipboard-item">Copy Title<span>
</button>
<div class="toast toast-copied toast-index-13 align-items-center text-bg-secondary border-0 position-absolute top-0 end-0" role="alert" aria-live="assertive" aria-atomic="true">
  <div class="d-flex">
    <div class="toast-body">
      Copied!
    </div>
  </div>
</div>

---
Primary Category: cs.CL  
Categories: I-2-7, cs-AI, cs-CL, cs.CL  
Keyword Score: 56  
Keywords: Fine-tuning, Multi-modal, Multi-modal, GPT, GPT-3, GPT-3.5, Large Language Model  
<a type="button" class="btn btn-outline-primary" href="http://arxiv.org/abs/2404.05502v1" target="_blank" >Paper Link</a>
<button type="button" class="btn btn-outline-primary download-pdf" url="https://arxiv.org/pdf/2404.05502v1.pdf" filename="2404.05502v1.pdf">Download PDF</button>

---


**ABSTRACT**  
In this paper, we present our submission to the SemEval-2023 Task~3 "The Competition of <b>Multimodal</b> Emotion Cause Analysis in Conversations", focusing on extracting emotion-cause pairs from dialogs. Specifically, our approach relies on combining <b>fine-tuned</b> <b>GPT-3.5</b> for emotion classification and a BiLSTM-based neural network to detect causes. We score 2nd in the ranking for Subtask 1, demonstrating the effectiveness of our approach through one of the highest weighted-average proportional F1 scores recorded at 0.264.

{{</citation>}}


### (14/43 | 14/266) VietMed: A Dataset and Benchmark for Automatic Speech Recognition of Vietnamese in the Medical Domain (Khai Le-Duc, 2024)

{{<citation>}}

Khai Le-Duc. (2024)  
**VietMed: A Dataset and Benchmark for Automatic Speech Recognition of Vietnamese in the Medical Domain**
<br/>
<button class="copy-to-clipboard" title="VietMed: A Dataset and Benchmark for Automatic Speech Recognition of Vietnamese in the Medical Domain" index=14>
  <span class="copy-to-clipboard-item">Copy Title<span>
</button>
<div class="toast toast-copied toast-index-14 align-items-center text-bg-secondary border-0 position-absolute top-0 end-0" role="alert" aria-live="assertive" aria-atomic="true">
  <div class="d-flex">
    <div class="toast-body">
      Copied!
    </div>
  </div>
</div>

---
Primary Category: cs.CL  
Categories: cs-AI, cs-CL, cs.CL, eess-AS  
Keyword Score: 53  
Keywords: Benchmarking, Fine-tuning, Unsupervised Learning, Automatic Speech Recognition, Automatic Speech Recognition, Automatic Speech Recognition  
<a type="button" class="btn btn-outline-primary" href="http://arxiv.org/abs/2404.05659v1" target="_blank" >Paper Link</a>
<button type="button" class="btn btn-outline-primary download-pdf" url="https://arxiv.org/pdf/2404.05659v1.pdf" filename="2404.05659v1.pdf">Download PDF</button>

---


**ABSTRACT**  
Due to privacy restrictions, there's a shortage of publicly available <b>speech</b> <b>recognition</b> datasets in the medical domain. In this work, we present VietMed - a Vietnamese <b>speech</b> <b>recognition</b> dataset in the medical domain comprising 16h of labeled medical <b>speech,</b> <b>1000h</b> of unlabeled medical <b>speech</b> <b>and</b> 1200h of unlabeled general-domain <b>speech.</b> <b>To</b> our best knowledge, VietMed is by far the world's largest public medical <b>speech</b> <b>recognition</b> dataset in 7 aspects: total duration, number of speakers, diseases, recording conditions, speaker roles, unique medical terms and accents. VietMed is also by far the largest public Vietnamese <b>speech</b> <b>dataset</b> in terms of total duration. Additionally, we are the first to present a medical <b>ASR</b> dataset covering all ICD-10 disease groups and all accents within a country. Moreover, we release the first public large-scale pre-trained models for Vietnamese <b>ASR,</b> w2v2-Viet and XLSR-53-Viet, along with the first public large-scale <b>fine-tuned</b> models for medical <b>ASR.</b> Even without any medical data in <b>unsupervised</b> pre-training, our best pre-trained model XLSR-53-Viet generalizes very well to the medical domain by outperforming state-of-the-art XLSR-53, from 51.8% to 29.6% WER on test set (a relative reduction of more than 40%). All code, data and models are made publicly available here: https://github.com/leduckhai/MultiMed.

{{</citation>}}


### (15/43 | 15/266) Physics of Language Models: Part 3.3, Knowledge Capacity Scaling Laws (Zeyuan Allen-Zhu et al., 2024)

{{<citation>}}

Zeyuan Allen-Zhu, Yuanzhi Li. (2024)  
**Physics of Language Models: Part 3.3, Knowledge Capacity Scaling Laws**
<br/>
<button class="copy-to-clipboard" title="Physics of Language Models: Part 3.3, Knowledge Capacity Scaling Laws" index=15>
  <span class="copy-to-clipboard-item">Copy Title<span>
</button>
<div class="toast toast-copied toast-index-15 align-items-center text-bg-secondary border-0 position-absolute top-0 end-0" role="alert" aria-live="assertive" aria-atomic="true">
  <div class="d-flex">
    <div class="toast-body">
      Copied!
    </div>
  </div>
</div>

---
Primary Category: cs.CL  
Categories: cs-AI, cs-CL, cs-LG, cs.CL  
Keyword Score: 53  
Keywords: Benchmarking, Quantization, Quantization, GPT, GPT-2, Scaling Law  
<a type="button" class="btn btn-outline-primary" href="http://arxiv.org/abs/2404.05405v1" target="_blank" >Paper Link</a>
<button type="button" class="btn btn-outline-primary download-pdf" url="https://arxiv.org/pdf/2404.05405v1.pdf" filename="2404.05405v1.pdf">Download PDF</button>

---


**ABSTRACT**  
<b>Scaling</b> <b>laws</b> describe the relationship between the size of language models and their capabilities. Unlike prior studies that evaluate a model's capability via loss or <b>benchmarks,</b> we estimate the number of knowledge bits a model stores. We focus on factual knowledge represented as tuples, such as (USA, capital, Washington D.C.) from a Wikipedia page. Through multiple controlled datasets, we establish that language models can and only can store 2 bits of knowledge per parameter, even when <b>quantized</b> to int8, and such knowledge can be flexibly extracted for downstream applications. Consequently, a 7B model can store 14B bits of knowledge, surpassing the English Wikipedia and textbooks combined based on our estimation. More broadly, we present 12 results on how (1) training duration, (2) model architecture, (3) <b>quantization,</b> (4) sparsity constraints such as MoE, and (5) data signal-to-noise ratio affect a model's knowledge storage capacity. Notable insights include: * The <b>GPT-2</b> architecture, with rotary embedding, matches or even surpasses LLaMA/Mistral architectures in knowledge storage, particularly over shorter training durations. This arises because LLaMA/Mistral uses GatedMLP, which is less stable and harder to train. * Prepending training data with domain names (e.g., wikipedia.org) significantly increases a model's knowledge capacity. Language models can autonomously identify and prioritize domains rich in knowledge, optimizing their storage capacity.

{{</citation>}}


### (16/43 | 16/266) Language-Independent Representations Improve Zero-Shot Summarization (Vladimir Solovyev et al., 2024)

{{<citation>}}

Vladimir Solovyev, Danni Liu, Jan Niehues. (2024)  
**Language-Independent Representations Improve Zero-Shot Summarization**
<br/>
<button class="copy-to-clipboard" title="Language-Independent Representations Improve Zero-Shot Summarization" index=16>
  <span class="copy-to-clipboard-item">Copy Title<span>
</button>
<div class="toast toast-copied toast-index-16 align-items-center text-bg-secondary border-0 position-absolute top-0 end-0" role="alert" aria-live="assertive" aria-atomic="true">
  <div class="d-flex">
    <div class="toast-body">
      Copied!
    </div>
  </div>
</div>

---
Primary Category: cs.CL  
Categories: cs-AI, cs-CL, cs.CL  
Keyword Score: 50  
Keywords: Fine-tuning, Fine-tuning, Zero-shot, Language Generation, Summarization  
<a type="button" class="btn btn-outline-primary" href="http://arxiv.org/abs/2404.05720v1" target="_blank" >Paper Link</a>
<button type="button" class="btn btn-outline-primary download-pdf" url="https://arxiv.org/pdf/2404.05720v1.pdf" filename="2404.05720v1.pdf">Download PDF</button>

---


**ABSTRACT**  
<b>Finetuning</b> pretrained models on downstream generation tasks often leads to catastrophic forgetting in <b>zero-shot</b> conditions. In this work, we focus on <b>summarization</b> and tackle the problem through the lens of <b>language-independent</b> <b>representations.</b> After training on monolingual <b>summarization,</b> we perform <b>zero-shot</b> transfer to new <b>languages</b> <b>or</b> <b>language</b> <b>pairs.</b> We first show naively <b>finetuned</b> models are highly <b>language-specific</b> <b>in</b> both output behavior and internal representations, resulting in poor <b>zero-shot</b> performance. Next, we propose query-key (QK) <b>finetuning</b> to decouple task-specific knowledge from the pretrained <b>language</b> <b>generation</b> abilities. Then, after showing downsides of the standard adversarial <b>language</b> <b>classifier,</b> we propose a balanced variant that more directly enforces <b>language-agnostic</b> <b>representations.</b> Moreover, our qualitative analyses show removing source <b>language</b> <b>identity</b> correlates to <b>zero-shot</b> <b>summarization</b> performance. Our code is openly available.

{{</citation>}}


### (17/43 | 17/266) Fighting crime with Transformers: Empirical analysis of address parsing methods in payment data (Haitham Hammami et al., 2024)

{{<citation>}}

Haitham Hammami, Louis Baligand, Bojan Petrovski. (2024)  
**Fighting crime with Transformers: Empirical analysis of address parsing methods in payment data**
<br/>
<button class="copy-to-clipboard" title="Fighting crime with Transformers: Empirical analysis of address parsing methods in payment data" index=17>
  <span class="copy-to-clipboard-item">Copy Title<span>
</button>
<div class="toast toast-copied toast-index-17 align-items-center text-bg-secondary border-0 position-absolute top-0 end-0" role="alert" aria-live="assertive" aria-atomic="true">
  <div class="d-flex">
    <div class="toast-body">
      Copied!
    </div>
  </div>
</div>

---
Primary Category: cs.CL  
Categories: cs-CL, cs.CL  
Keyword Score: 50  
Keywords: Fine-tuning, Zero-shot, Transformer, Large Language Model, Large Language Model  
<a type="button" class="btn btn-outline-primary" href="http://arxiv.org/abs/2404.05632v2" target="_blank" >Paper Link</a>
<button type="button" class="btn btn-outline-primary download-pdf" url="https://arxiv.org/pdf/2404.05632v2.pdf" filename="2404.05632v2.pdf">Download PDF</button>

---


**ABSTRACT**  
In the financial industry, identifying the location of parties involved in payments is a major challenge in the context of various regulatory requirements. For this purpose address parsing entails extracting fields such as street, postal code, or country from free text message attributes. While payment processing platforms are updating their standards with more structured formats such as SWIFT with ISO 20022, address parsing remains essential for a considerable volume of messages. With the emergence of <b>Transformers</b> and Generative <b>Large</b> <b>Language</b> <b>Models</b> <b>(LLM),</b> we explore the performance of state-of-the-art solutions given the constraint of processing a vast amount of daily data. This paper also aims to show the need for training robust models capable of dealing with real-world noisy transactional data. Our results suggest that a well <b>fine-tuned</b> <b>Transformer</b> model using early-stopping significantly outperforms other approaches. Nevertheless, generative <b>LLMs</b> demonstrate strong <b>zero-shot</b> performance and warrant further investigations.

{{</citation>}}


### (18/43 | 18/266) Best-of-Venom: Attacking RLHF by Injecting Poisoned Preference Data (Tim Baumgärtner et al., 2024)

{{<citation>}}

Tim Baumgärtner, Yang Gao, Dana Alon, Donald Metzler. (2024)  
**Best-of-Venom: Attacking RLHF by Injecting Poisoned Preference Data**
<br/>
<button class="copy-to-clipboard" title="Best-of-Venom: Attacking RLHF by Injecting Poisoned Preference Data" index=18>
  <span class="copy-to-clipboard-item">Copy Title<span>
</button>
<div class="toast toast-copied toast-index-18 align-items-center text-bg-secondary border-0 position-absolute top-0 end-0" role="alert" aria-live="assertive" aria-atomic="true">
  <div class="d-flex">
    <div class="toast-body">
      Copied!
    </div>
  </div>
</div>

---
Primary Category: cs.CL  
Categories: cs-AI, cs-CL, cs-CR, cs-LG, cs.CL  
Keyword Score: 50  
Keywords: Fine-tuning, Reinforcement Learning, Reinforcement Learning from Human Feedback, Reinforcement Learning from Human Feedback, Supervised Learning  
<a type="button" class="btn btn-outline-primary" href="http://arxiv.org/abs/2404.05530v1" target="_blank" >Paper Link</a>
<button type="button" class="btn btn-outline-primary download-pdf" url="https://arxiv.org/pdf/2404.05530v1.pdf" filename="2404.05530v1.pdf">Download PDF</button>

---


**ABSTRACT**  
<b>Reinforcement</b> <b>Learning</b> <b>from</b> <b>Human</b> <b>Feedback</b> <b>(RLHF)</b> is a popular method for aligning Language Models (LM) with human values and preferences. <b>RLHF</b> requires a large number of preference pairs as training data, which are often used in both the <b>Supervised</b> <b>Fine-Tuning</b> and Reward Model training, and therefore publicly available datasets are commonly used. In this work, we study to what extent a malicious actor can manipulate the LMs generations by poisoning the preferences, i.e., injecting poisonous preference pairs into these datasets and the <b>RLHF</b> training process. We propose strategies to build poisonous preference pairs and test their performance by poisoning two widely used preference datasets. Our results show that preference poisoning is highly effective: by injecting a small amount of poisonous data (1-5% of the original dataset), we can effectively manipulate the LM to generate a target entity in a target sentiment (positive or negative). The findings from our experiments also shed light on strategies to defend against the preference poisoning attack.

{{</citation>}}


### (19/43 | 19/266) RoT: Enhancing Large Language Models with Reflection on Search Trees (Wenyang Hui et al., 2024)

{{<citation>}}

Wenyang Hui, Chengyue Jiang, Yan Wang, Kewei Tu. (2024)  
**RoT: Enhancing Large Language Models with Reflection on Search Trees**
<br/>
<button class="copy-to-clipboard" title="RoT: Enhancing Large Language Models with Reflection on Search Trees" index=19>
  <span class="copy-to-clipboard-item">Copy Title<span>
</button>
<div class="toast toast-copied toast-index-19 align-items-center text-bg-secondary border-0 position-absolute top-0 end-0" role="alert" aria-live="assertive" aria-atomic="true">
  <div class="d-flex">
    <div class="toast-body">
      Copied!
    </div>
  </div>
</div>

---
Primary Category: cs.CL  
Categories: cs-CL, cs.CL  
Keyword Score: 50  
Keywords: Reasoning, Large Language Model, Large Language Model, Prompt, Summarization  
<a type="button" class="btn btn-outline-primary" href="http://arxiv.org/abs/2404.05449v2" target="_blank" >Paper Link</a>
<button type="button" class="btn btn-outline-primary download-pdf" url="https://arxiv.org/pdf/2404.05449v2.pdf" filename="2404.05449v2.pdf">Download PDF</button>

---


**ABSTRACT**  
<b>Large</b> <b>language</b> <b>models</b> <b>(LLMs)</b> have demonstrated impressive capability in <b>reasoning</b> and planning when integrated with tree-search-based <b>prompting</b> methods. However, since these methods ignore the previous search experiences, they often make the same mistakes in the search process. To address this issue, we introduce Reflection on search Trees (RoT), an <b>LLM</b> reflection framework designed to improve the performance of tree-search-based <b>prompting</b> methods. It uses a strong <b>LLM</b> to <b>summarize</b> guidelines from previous tree search experiences to enhance the ability of a weak <b>LLM.</b> The guidelines are instructions about solving this task through tree search which can prevent the weak <b>LLMs</b> from making similar mistakes in the past search process. In addition, we proposed a novel state selection method, which identifies the critical information from historical search processes to help RoT generate more specific and meaningful guidelines. In our extensive experiments, we find that RoT significantly improves the performance of <b>LLMs</b> in <b>reasoning</b> or planning tasks with various tree-search-based <b>prompting</b> methods (e.g., BFS and MCTS). Non-tree-search-based <b>prompting</b> methods such as Chain-of-Thought (CoT) can also benefit from RoT guidelines since RoT can provide task-specific knowledge collected from the search experience.

{{</citation>}}


### (20/43 | 20/266) Towards Objectively Benchmarking Social Intelligence for Language Agents at Action Level (Chenxu Wang et al., 2024)

{{<citation>}}

Chenxu Wang, Bin Dai, Huaping Liu, Baoyuan Wang. (2024)  
**Towards Objectively Benchmarking Social Intelligence for Language Agents at Action Level**
<br/>
<button class="copy-to-clipboard" title="Towards Objectively Benchmarking Social Intelligence for Language Agents at Action Level" index=20>
  <span class="copy-to-clipboard-item">Copy Title<span>
</button>
<div class="toast toast-copied toast-index-20 align-items-center text-bg-secondary border-0 position-absolute top-0 end-0" role="alert" aria-live="assertive" aria-atomic="true">
  <div class="d-flex">
    <div class="toast-body">
      Copied!
    </div>
  </div>
</div>

---
Primary Category: cs.CL  
Categories: cs-AI, cs-CL, cs.CL  
Keyword Score: 46  
Keywords: Benchmarking, Benchmarking, Simulation, Simulator, Grounding, Large Language Model  
<a type="button" class="btn btn-outline-primary" href="http://arxiv.org/abs/2404.05337v1" target="_blank" >Paper Link</a>
<button type="button" class="btn btn-outline-primary download-pdf" url="https://arxiv.org/pdf/2404.05337v1.pdf" filename="2404.05337v1.pdf">Download PDF</button>

---


**ABSTRACT**  
Prominent <b>large</b> <b>language</b> <b>models</b> have exhibited human-level performance in many domains, even enabling the derived agents to simulate human and social interactions. While practical works have substantiated the practicability of <b>grounding</b> language agents in sandbox <b>simulation</b> or embodied simulators, current social intelligence <b>benchmarks</b> either stay at the language level or use subjective metrics. In pursuit of a more realistic and objective evaluation, we introduce the Social Tasks in Sandbox <b>Simulation</b> (STSS) <b>benchmark,</b> which assesses language agents \textbf{objectively} at the \textbf{action level} by scrutinizing the goal achievements within the multi-agent <b>simulation.</b> Additionally, we sample conversation scenarios to build a language-level <b>benchmark</b> to provide an economically prudent preliminary evaluation and align with prevailing <b>benchmarks.</b> To gauge the significance of agent architecture, we implement a target-driven planning (TDP) module as an adjunct to the existing agent. Our evaluative findings highlight that the STSS <b>benchmark</b> is challenging for state-of-the-art language agents. Furthermore, it effectively discriminates between distinct language agents, suggesting its usefulness as a <b>benchmark</b> for evaluating both language models and agent architectures.

{{</citation>}}


### (21/43 | 21/266) CodecLM: Aligning Language Models with Tailored Synthetic Data (Zifeng Wang et al., 2024)

{{<citation>}}

Zifeng Wang, Chun-Liang Li, Vincent Perot, Long T. Le, Jin Miao, Zizhao Zhang, Chen-Yu Lee, Tomas Pfister. (2024)  
**CodecLM: Aligning Language Models with Tailored Synthetic Data**
<br/>
<button class="copy-to-clipboard" title="CodecLM: Aligning Language Models with Tailored Synthetic Data" index=21>
  <span class="copy-to-clipboard-item">Copy Title<span>
</button>
<div class="toast toast-copied toast-index-21 align-items-center text-bg-secondary border-0 position-absolute top-0 end-0" role="alert" aria-live="assertive" aria-atomic="true">
  <div class="d-flex">
    <div class="toast-body">
      Copied!
    </div>
  </div>
</div>

---
Primary Category: cs.CL  
Categories: cs-AI, cs-CL, cs-LG, cs.CL  
Keyword Score: 43  
Keywords: Benchmarking, Instruction Following, Instruction Tuning, Large Language Model, Large Language Model  
<a type="button" class="btn btn-outline-primary" href="http://arxiv.org/abs/2404.05875v1" target="_blank" >Paper Link</a>
<button type="button" class="btn btn-outline-primary download-pdf" url="https://arxiv.org/pdf/2404.05875v1.pdf" filename="2404.05875v1.pdf">Download PDF</button>

---


**ABSTRACT**  
<b>Instruction</b> <b>tuning</b> has emerged as the key in aligning <b>large</b> <b>language</b> <b>models</b> <b>(LLMs)</b> with specific task <b>instructions,</b> <b>thereby</b> mitigating the discrepancy between the next-token prediction objective and users' actual goals. To reduce the labor and time cost to collect or annotate data by humans, researchers start to explore the use of <b>LLMs</b> to generate <b>instruction-aligned</b> <b>synthetic</b> data. Recent works focus on generating diverse <b>instructions</b> <b>and</b> applying <b>LLM</b> to increase <b>instruction</b> <b>complexity,</b> often neglecting downstream use cases. It remains unclear how to tailor high-quality data to elicit better <b>instruction-following</b> <b>abilities</b> in different target <b>instruction</b> <b>distributions</b> and <b>LLMs.</b> To this end, we introduce CodecLM, a general framework for adaptively generating high-quality synthetic data for <b>LLM</b> alignment with different downstream <b>instruction</b> <b>distributions</b> and <b>LLMs.</b> Drawing on the Encode-Decode principles, we use <b>LLMs</b> as codecs to guide the data generation process. We first encode seed <b>instructions</b> <b>into</b> metadata, which are concise keywords generated on-the-fly to capture the target <b>instruction</b> <b>distribution,</b> and then decode metadata to create tailored <b>instructions.</b> <b>We</b> also introduce Self-Rubrics and Contrastive Filtering during decoding to tailor data-efficient samples. Extensive experiments on four open-domain <b>instruction</b> <b>following</b> <b>benchmarks</b> validate the effectiveness of CodecLM over the current state-of-the-arts.

{{</citation>}}


### (22/43 | 22/266) PerkwE_COQA: enhance Persian Conversational Question Answering by combining contextual keyword extraction with Large Language Models (Pardis Moradbeiki et al., 2024)

{{<citation>}}

Pardis Moradbeiki, Nasser Ghadiri. (2024)  
**PerkwE_COQA: enhance Persian Conversational Question Answering by combining contextual keyword extraction with Large Language Models**
<br/>
<button class="copy-to-clipboard" title="PerkwE_COQA: enhance Persian Conversational Question Answering by combining contextual keyword extraction with Large Language Models" index=22>
  <span class="copy-to-clipboard-item">Copy Title<span>
</button>
<div class="toast toast-copied toast-index-22 align-items-center text-bg-secondary border-0 position-absolute top-0 end-0" role="alert" aria-live="assertive" aria-atomic="true">
  <div class="d-flex">
    <div class="toast-body">
      Copied!
    </div>
  </div>
</div>

---
Primary Category: cs.CL  
Categories: 68T50, 68T07, J-3; I-2-7; I-2-1, cs-AI, cs-CL, cs.CL  
Keyword Score: 43  
Keywords: Benchmarking, Keyword Extraction, Question Answering, Large Language Model, Large Language Model  
<a type="button" class="btn btn-outline-primary" href="http://arxiv.org/abs/2404.05406v1" target="_blank" >Paper Link</a>
<button type="button" class="btn btn-outline-primary download-pdf" url="https://arxiv.org/pdf/2404.05406v1.pdf" filename="2404.05406v1.pdf">Download PDF</button>

---


**ABSTRACT**  
Smart cities need the involvement of their residents to enhance quality of life. Conversational query-answering is an emerging approach for user engagement. There is an increasing demand of an advanced conversational <b>question-answering</b> <b>that</b> goes beyond classic systems. Existing approaches have shown that <b>LLMs</b> offer promising capabilities for CQA, but may struggle to capture the nuances of conversational contexts. The new approach involves understanding the content and engaging in a multi-step conversation with the user to fulfill their needs. This paper presents a novel method to elevate the performance of Persian Conversational <b>question-answering</b> <b>(CQA)</b> systems. It combines the strengths of <b>Large</b> <b>Language</b> <b>Models</b> <b>(LLMs)</b> with contextual <b>keyword</b> <b>extraction.</b> Our method extracts <b>keywords</b> <b>specific</b> to the conversational flow, providing the <b>LLM</b> with additional context to understand the user's intent and generate more relevant and coherent responses. We evaluated the effectiveness of this combined approach through various metrics, demonstrating significant improvements in CQA performance compared to an <b>LLM-only</b> baseline. The proposed method effectively handles implicit <b>questions,</b> <b>delivers</b> contextually relevant answers, and tackles complex <b>questions</b> <b>that</b> rely heavily on conversational context. The findings indicate that our method outperformed the evaluation <b>benchmarks</b> up to 8% higher than existing methods and the <b>LLM-only</b> baseline.

{{</citation>}}


### (23/43 | 23/266) ÚFAL LatinPipe at EvaLatin 2024: Morphosyntactic Analysis of Latin (Milan Straka et al., 2024)

{{<citation>}}

Milan Straka, Jana Straková, Federica Gamba. (2024)  
**ÚFAL LatinPipe at EvaLatin 2024: Morphosyntactic Analysis of Latin**
<br/>
<button class="copy-to-clipboard" title="ÚFAL LatinPipe at EvaLatin 2024: Morphosyntactic Analysis of Latin" index=23>
  <span class="copy-to-clipboard-item">Copy Title<span>
</button>
<div class="toast toast-copied toast-index-23 align-items-center text-bg-secondary border-0 position-absolute top-0 end-0" role="alert" aria-live="assertive" aria-atomic="true">
  <div class="d-flex">
    <div class="toast-body">
      Copied!
    </div>
  </div>
</div>

---
Primary Category: cs.CL  
Categories: cs-CL, cs.CL  
Keyword Score: 40  
Keywords: Fine-tuning, Fine-tuning, Dependency Parsing, Morphological Analysis  
<a type="button" class="btn btn-outline-primary" href="http://arxiv.org/abs/2404.05839v1" target="_blank" >Paper Link</a>
<button type="button" class="btn btn-outline-primary download-pdf" url="https://arxiv.org/pdf/2404.05839v1.pdf" filename="2404.05839v1.pdf">Download PDF</button>

---


**ABSTRACT**  
We present LatinPipe, the winning submission to the EvaLatin 2024 <b>Dependency</b> <b>Parsing</b> shared task. Our system consists of a <b>fine-tuned</b> concatenation of base and large pre-trained LMs, with a dot-product attention head for parsing and softmax classification heads for morphology to jointly learn both <b>dependency</b> <b>parsing</b> and <b>morphological</b> <b>analysis.</b> It is trained by sampling from seven publicly available Latin corpora, utilizing additional harmonization of annotations to achieve a more unified annotation style. Before <b>fine-tuning,</b> we train the system for a few initial epochs with frozen weights. We also add additional local relative contextualization by stacking the BiLSTM layers on top of the Transformer(s). Finally, we ensemble output probability distributions from seven randomly instantiated networks for the final submission. The code is available at https://github.com/ufal/evalatin2024-latinpipe.

{{</citation>}}


### (24/43 | 24/266) Evaluating Mathematical Reasoning Beyond Accuracy (Shijie Xia et al., 2024)

{{<citation>}}

Shijie Xia, Xuefeng Li, Yixin Liu, Tongshuang Wu, Pengfei Liu. (2024)  
**Evaluating Mathematical Reasoning Beyond Accuracy**
<br/>
<button class="copy-to-clipboard" title="Evaluating Mathematical Reasoning Beyond Accuracy" index=24>
  <span class="copy-to-clipboard-item">Copy Title<span>
</button>
<div class="toast toast-copied toast-index-24 align-items-center text-bg-secondary border-0 position-absolute top-0 end-0" role="alert" aria-live="assertive" aria-atomic="true">
  <div class="d-flex">
    <div class="toast-body">
      Copied!
    </div>
  </div>
</div>

---
Primary Category: cs.CL  
Categories: cs-CL, cs.CL  
Keyword Score: 40  
Keywords: Mathematical Reasoning, Reasoning, Large Language Model, Large Language Model  
<a type="button" class="btn btn-outline-primary" href="http://arxiv.org/abs/2404.05692v1" target="_blank" >Paper Link</a>
<button type="button" class="btn btn-outline-primary download-pdf" url="https://arxiv.org/pdf/2404.05692v1.pdf" filename="2404.05692v1.pdf">Download PDF</button>

---


**ABSTRACT**  
The leaderboard of <b>Large</b> <b>Language</b> <b>Models</b> <b>(LLMs)</b> in <b>mathematical</b> <b>tasks</b> has been continuously updated. However, the majority of evaluations focus solely on the final results, neglecting the quality of the intermediate steps. This oversight can mask underlying problems, such as logical errors or unnecessary steps in the <b>reasoning</b> process. To measure <b>reasoning</b> beyond final-answer accuracy, we introduce ReasonEval, a new methodology for evaluating the quality of <b>reasoning</b> steps. ReasonEval employs $\textit{validity}$ and $\textit{redundancy}$ to characterize the <b>reasoning</b> quality, as well as accompanying <b>LLMs</b> to assess them automatically. Instantiated by base models that possess strong <b>mathematical</b> <b>knowledge</b> and trained with high-quality labeled data, ReasonEval achieves state-of-the-art performance on human-labeled datasets and can accurately detect different types of errors generated by perturbation. When applied to evaluate <b>LLMs</b> specialized in math, we find that an increase in final-answer accuracy does not necessarily guarantee an improvement in the overall quality of the <b>reasoning</b> steps for challenging <b>mathematical</b> <b>problems.</b> Additionally, we observe that ReasonEval can play a significant role in data selection. We release the best-performing model, meta-evaluation script, and all evaluation results at https://github.com/GAIR-NLP/ReasonEval.

{{</citation>}}


### (25/43 | 25/266) Enhancing Clinical Efficiency through LLM: Discharge Note Generation for Cardiac Patients (HyoJe Jung et al., 2024)

{{<citation>}}

HyoJe Jung, Yunha Kim, Heejung Choi, Hyeram Seo, Minkyoung Kim, JiYe Han, Gaeun Kee, Seohyun Park, Soyoung Ko, Byeolhee Kim, Suyeon Kim, Tae Joon Jun, Young-Hak Kim. (2024)  
**Enhancing Clinical Efficiency through LLM: Discharge Note Generation for Cardiac Patients**
<br/>
<button class="copy-to-clipboard" title="Enhancing Clinical Efficiency through LLM: Discharge Note Generation for Cardiac Patients" index=25>
  <span class="copy-to-clipboard-item">Copy Title<span>
</button>
<div class="toast toast-copied toast-index-25 align-items-center text-bg-secondary border-0 position-absolute top-0 end-0" role="alert" aria-live="assertive" aria-atomic="true">
  <div class="d-flex">
    <div class="toast-body">
      Copied!
    </div>
  </div>
</div>

---
Primary Category: cs.CL  
Categories: cs-CL, cs-CV, cs-LG, cs.CL  
Keyword Score: 40  
Keywords: Knowledge Distillation, Mistral, Large Language Model, Large Language Model  
<a type="button" class="btn btn-outline-primary" href="http://arxiv.org/abs/2404.05144v1" target="_blank" >Paper Link</a>
<button type="button" class="btn btn-outline-primary download-pdf" url="https://arxiv.org/pdf/2404.05144v1.pdf" filename="2404.05144v1.pdf">Download PDF</button>

---


**ABSTRACT**  
Medical documentation, including discharge notes, is crucial for ensuring patient care quality, continuity, and effective medical communication. However, the manual creation of these documents is not only time-consuming but also prone to inconsistencies and potential errors. The automation of this documentation process using artificial intelligence (AI) represents a promising area of innovation in healthcare. This study directly addresses the inefficiencies and inaccuracies in creating discharge notes manually, particularly for cardiac patients, by employing AI techniques, specifically <b>large</b> <b>language</b> <b>model</b> <b>(LLM).</b> Utilizing a substantial dataset from a cardiology center, encompassing wide-ranging medical records and physician assessments, our research evaluates the capability of <b>LLM</b> to enhance the documentation process. Among the various models assessed, <b>Mistral-7B</b> distinguished itself by accurately generating discharge notes that significantly improve both documentation efficiency and the continuity of care for patients. These notes underwent rigorous qualitative evaluation by medical expert, receiving high marks for their clinical relevance, completeness, readability, and contribution to informed decision-making and care planning. Coupled with quantitative analyses, these results confirm <b>Mistral-7B's</b> efficacy in <b>distilling</b> complex medical information into concise, coherent summaries. Overall, our findings illuminate the considerable promise of specialized <b>LLM,</b> such as <b>Mistral-7B,</b> in refining healthcare documentation workflows and advancing patient care. This study lays the groundwork for further integrating advanced AI technologies in healthcare, demonstrating their potential to revolutionize patient documentation and support better care outcomes.

{{</citation>}}


### (26/43 | 26/266) The Hallucinations Leaderboard -- An Open Effort to Measure Hallucinations in Large Language Models (Giwon Hong et al., 2024)

{{<citation>}}

Giwon Hong, Aryo Pradipta Gema, Rohit Saxena, Xiaotang Du, Ping Nie, Yu Zhao, Laura Perez-Beltrachini, Max Ryabinin, Xuanli He, Pasquale Minervini. (2024)  
**The Hallucinations Leaderboard -- An Open Effort to Measure Hallucinations in Large Language Models**
<br/>
<button class="copy-to-clipboard" title="The Hallucinations Leaderboard -- An Open Effort to Measure Hallucinations in Large Language Models" index=26>
  <span class="copy-to-clipboard-item">Copy Title<span>
</button>
<div class="toast toast-copied toast-index-26 align-items-center text-bg-secondary border-0 position-absolute top-0 end-0" role="alert" aria-live="assertive" aria-atomic="true">
  <div class="d-flex">
    <div class="toast-body">
      Copied!
    </div>
  </div>
</div>

---
Primary Category: cs.CL  
Categories: cs-CL, cs.CL  
Keyword Score: 33  
Keywords: Benchmarking, Question Answering, Large Language Model, Large Language Model  
<a type="button" class="btn btn-outline-primary" href="http://arxiv.org/abs/2404.05904v1" target="_blank" >Paper Link</a>
<button type="button" class="btn btn-outline-primary download-pdf" url="https://arxiv.org/pdf/2404.05904v1.pdf" filename="2404.05904v1.pdf">Download PDF</button>

---


**ABSTRACT**  
<b>Large</b> <b>Language</b> <b>Models</b> <b>(LLMs)</b> have transformed the Natural Language Processing (NLP) landscape with their remarkable ability to understand and generate human-like text. However, these models are prone to ``hallucinations'' -- outputs that do not align with factual reality or the input context. This paper introduces the Hallucinations Leaderboard, an open initiative to quantitatively measure and compare the tendency of each model to produce hallucinations. The leaderboard uses a comprehensive set of <b>benchmarks</b> focusing on different aspects of hallucinations, such as factuality and faithfulness, across various tasks, including <b>question-answering,</b> <b>summarisation,</b> and reading comprehension. Our analysis provides insights into the performance of different models, guiding researchers and practitioners in choosing the most reliable models for their applications.

{{</citation>}}


### (27/43 | 27/266) How to Evaluate Entity Resolution Systems: An Entity-Centric Framework with Application to Inventor Name Disambiguation (Olivier Binette et al., 2024)

{{<citation>}}

Olivier Binette, Youngsoo Baek, Siddharth Engineer, Christina Jones, Abel Dasylva, Jerome P. Reiter. (2024)  
**How to Evaluate Entity Resolution Systems: An Entity-Centric Framework with Application to Inventor Name Disambiguation**
<br/>
<button class="copy-to-clipboard" title="How to Evaluate Entity Resolution Systems: An Entity-Centric Framework with Application to Inventor Name Disambiguation" index=27>
  <span class="copy-to-clipboard-item">Copy Title<span>
</button>
<div class="toast toast-copied toast-index-27 align-items-center text-bg-secondary border-0 position-absolute top-0 end-0" role="alert" aria-live="assertive" aria-atomic="true">
  <div class="d-flex">
    <div class="toast-body">
      Copied!
    </div>
  </div>
</div>

---
Primary Category: cs.CL  
Categories: cs-CL, cs-LG, cs.CL, stat-ME  
Keyword Score: 33  
Keywords: Benchmarking, Simulation, Simulator, Disambiguation  
<a type="button" class="btn btn-outline-primary" href="http://arxiv.org/abs/2404.05622v1" target="_blank" >Paper Link</a>
<button type="button" class="btn btn-outline-primary download-pdf" url="https://arxiv.org/pdf/2404.05622v1.pdf" filename="2404.05622v1.pdf">Download PDF</button>

---


**ABSTRACT**  
Entity resolution (record linkage, microclustering) systems are notoriously difficult to evaluate. Looking for a needle in a haystack, traditional evaluation methods use sophisticated, application-specific sampling schemes to find matching pairs of records among an immense number of non-matches. We propose an alternative that facilitates the creation of representative, reusable <b>benchmark</b> data sets without necessitating complex sampling schemes. These <b>benchmark</b> data sets can then be used for model training and a variety of evaluation tasks. Specifically, we propose an entity-centric data labeling methodology that integrates with a unified framework for monitoring summary statistics, estimating key performance metrics such as cluster and pairwise precision and recall, and analyzing root causes for errors. We validate the framework in an application to inventor name <b>disambiguation</b> and through <b>simulation</b> studies. Software: https://github.com/OlivierBinette/er-evaluation/

{{</citation>}}


### (28/43 | 28/266) OPSD: an Offensive Persian Social media Dataset and its baseline evaluations (Mehran Safayani et al., 2024)

{{<citation>}}

Mehran Safayani, Amir Sartipi, Amir Hossein Ahmadi, Parniyan Jalali, Amir Hossein Mansouri, Mohammad Bisheh-Niasar, Zahra Pourbahman. (2024)  
**OPSD: an Offensive Persian Social media Dataset and its baseline evaluations**
<br/>
<button class="copy-to-clipboard" title="OPSD: an Offensive Persian Social media Dataset and its baseline evaluations" index=28>
  <span class="copy-to-clipboard-item">Copy Title<span>
</button>
<div class="toast toast-copied toast-index-28 align-items-center text-bg-secondary border-0 position-absolute top-0 end-0" role="alert" aria-live="assertive" aria-atomic="true">
  <div class="d-flex">
    <div class="toast-body">
      Copied!
    </div>
  </div>
</div>

---
Primary Category: cs.CL  
Categories: cs-AI, cs-CL, cs-LG, cs.CL  
Keyword Score: 30  
Keywords: Unsupervised Learning, Unsupervised Learning, Masked Language Model  
<a type="button" class="btn btn-outline-primary" href="http://arxiv.org/abs/2404.05540v1" target="_blank" >Paper Link</a>
<button type="button" class="btn btn-outline-primary download-pdf" url="https://arxiv.org/pdf/2404.05540v1.pdf" filename="2404.05540v1.pdf">Download PDF</button>

---


**ABSTRACT**  
The proliferation of hate speech and offensive comments on social media has become increasingly prevalent due to user activities. Such comments can have detrimental effects on individuals' psychological well-being and social behavior. While numerous datasets in the English language exist in this domain, few equivalent resources are available for Persian language. To address this gap, this paper introduces two offensive datasets. The first dataset comprises annotations provided by domain experts, while the second consists of a large collection of unlabeled data obtained through web crawling for <b>unsupervised</b> <b>learning</b> purposes. To ensure the quality of the former dataset, a meticulous three-stage labeling process was conducted, and kappa measures were computed to assess inter-annotator agreement. Furthermore, experiments were performed on the dataset using state-of-the-art language models, both with and without employing <b>masked</b> <b>language</b> <b>modeling</b> techniques, as well as machine learning algorithms, in order to establish the baselines for the dataset using contemporary cutting-edge approaches. The obtained F1-scores for the three-class and two-class versions of the dataset were 76.9% and 89.9% for XLM-RoBERTa, respectively.

{{</citation>}}


### (29/43 | 29/266) Know When To Stop: A Study of Semantic Drift in Text Generation (Ava Spataru et al., 2024)

{{<citation>}}

Ava Spataru, Eric Hambro, Elena Voita, Nicola Cancedda. (2024)  
**Know When To Stop: A Study of Semantic Drift in Text Generation**
<br/>
<button class="copy-to-clipboard" title="Know When To Stop: A Study of Semantic Drift in Text Generation" index=29>
  <span class="copy-to-clipboard-item">Copy Title<span>
</button>
<div class="toast toast-copied toast-index-29 align-items-center text-bg-secondary border-0 position-absolute top-0 end-0" role="alert" aria-live="assertive" aria-atomic="true">
  <div class="d-flex">
    <div class="toast-body">
      Copied!
    </div>
  </div>
</div>

---
Primary Category: cs.CL  
Categories: cs-CL, cs.CL  
Keyword Score: 30  
Keywords: Rerank, Text Generation, Large Language Model  
<a type="button" class="btn btn-outline-primary" href="http://arxiv.org/abs/2404.05411v1" target="_blank" >Paper Link</a>
<button type="button" class="btn btn-outline-primary download-pdf" url="https://arxiv.org/pdf/2404.05411v1.pdf" filename="2404.05411v1.pdf">Download PDF</button>

---


**ABSTRACT**  
In this work, we explicitly show that modern <b>LLMs</b> tend to generate correct facts first, then "drift away" and generate incorrect facts later: this was occasionally observed but never properly measured. We develop a semantic drift score that measures the degree of separation between correct and incorrect facts in generated <b>texts</b> <b>and</b> confirm our hypothesis when generating Wikipedia-style biographies. This correct-then-incorrect generation pattern suggests that factual accuracy can be improved by knowing when to stop generation. Therefore, we explore the trade-off between information quantity and factual accuracy for several early stopping methods and manage to improve factuality by a large margin. We further show that <b>reranking</b> with semantic similarity can further improve these results, both compared to the baseline and when combined with early stopping. Finally, we try calling external API to bring the model back to the right generation path, but do not get positive results. Overall, our methods generalize and can be applied to any long-form <b>text</b> <b>generation</b> to produce more reliable information, by balancing trade-offs between factual accuracy, information quantity and computational cost.

{{</citation>}}


### (30/43 | 30/266) EcoVerse: An Annotated Twitter Dataset for Eco-Relevance Classification, Environmental Impact Analysis, and Stance Detection (Francesca Grasso et al., 2024)

{{<citation>}}

Francesca Grasso, Stefano Locci, Giovanni Siragusa, Luigi Di Caro. (2024)  
**EcoVerse: An Annotated Twitter Dataset for Eco-Relevance Classification, Environmental Impact Analysis, and Stance Detection**
<br/>
<button class="copy-to-clipboard" title="EcoVerse: An Annotated Twitter Dataset for Eco-Relevance Classification, Environmental Impact Analysis, and Stance Detection" index=30>
  <span class="copy-to-clipboard-item">Copy Title<span>
</button>
<div class="toast toast-copied toast-index-30 align-items-center text-bg-secondary border-0 position-absolute top-0 end-0" role="alert" aria-live="assertive" aria-atomic="true">
  <div class="d-flex">
    <div class="toast-body">
      Copied!
    </div>
  </div>
</div>

---
Primary Category: cs.CL  
Categories: cs-CL, cs.CL  
Keyword Score: 30  
Keywords: BERT, Sentiment Analysis, Stance Detection  
<a type="button" class="btn btn-outline-primary" href="http://arxiv.org/abs/2404.05133v1" target="_blank" >Paper Link</a>
<button type="button" class="btn btn-outline-primary download-pdf" url="https://arxiv.org/pdf/2404.05133v1.pdf" filename="2404.05133v1.pdf">Download PDF</button>

---


**ABSTRACT**  
Anthropogenic ecological crisis constitutes a significant challenge that all within the academy must urgently face, including the Natural Language Processing (NLP) community. While recent years have seen increasing work revolving around climate-centric discourse, crucial environmental and ecological topics outside of climate change remain largely unaddressed, despite their prominent importance. Mainstream NLP tasks, such as <b>sentiment</b> <b>analysis,</b> dominate the scene, but there remains an untouched space in the literature involving the analysis of environmental impacts of certain events and practices. To address this gap, this paper presents EcoVerse, an annotated English Twitter dataset of 3,023 tweets spanning a wide spectrum of environmental topics. We propose a three-level annotation scheme designed for Eco-Relevance Classification, <b>Stance</b> <b>Detection,</b> and introducing an original approach for Environmental Impact Analysis. We detail the data collection, filtering, and labeling process that led to the creation of the dataset. Remarkable Inter-Annotator Agreement indicates that the annotation scheme produces consistent annotations of high quality. Subsequent classification experiments using <b>BERT-based</b> models, including ClimateBERT, are presented. These yield encouraging results, while also indicating room for a model specifically tailored for environmental texts. The dataset is made freely available to stimulate further research.

{{</citation>}}


### (31/43 | 31/266) Supervised Gradual Machine Learning for Aspect Category Detection (Murtadha Ahmed et al., 2024)

{{<citation>}}

Murtadha Ahmed, Qun Chen. (2024)  
**Supervised Gradual Machine Learning for Aspect Category Detection**
<br/>
<button class="copy-to-clipboard" title="Supervised Gradual Machine Learning for Aspect Category Detection" index=31>
  <span class="copy-to-clipboard-item">Copy Title<span>
</button>
<div class="toast toast-copied toast-index-31 align-items-center text-bg-secondary border-0 position-absolute top-0 end-0" role="alert" aria-live="assertive" aria-atomic="true">
  <div class="d-flex">
    <div class="toast-body">
      Copied!
    </div>
  </div>
</div>

---
Primary Category: cs.CL  
Categories: cs-CL, cs.CL  
Keyword Score: 26  
Keywords: Graph, Benchmarking, Knowledge Transfer, Supervised Learning  
<a type="button" class="btn btn-outline-primary" href="http://arxiv.org/abs/2404.05245v1" target="_blank" >Paper Link</a>
<button type="button" class="btn btn-outline-primary download-pdf" url="https://arxiv.org/pdf/2404.05245v1.pdf" filename="2404.05245v1.pdf">Download PDF</button>

---


**ABSTRACT**  
Aspect Category Detection (ACD) aims to identify implicit and explicit aspects in a given review sentence. The state-of-the-art approaches for ACD use Deep Neural Networks (DNNs) to address the problem as a multi-label classification task. However, learning category-specific representations heavily rely on the amount of labeled examples, which may not readily available in real-world scenarios. In this paper, we propose a novel approach to tackle the ACD task by combining DNNs with Gradual Machine Learning (GML) in a <b>supervised</b> setting. we aim to leverage the strength of DNN in semantic relation modeling, which can facilitate effective <b>knowledge</b> <b>transfer</b> between labeled and unlabeled instances during the gradual inference of GML. To achieve this, we first analyze the learned latent space of the DNN to model the relations, i.e., similar or opposite, between instances. We then represent these relations as binary features in a factor <b>graph</b> to efficiently convey <b>knowledge.</b> <b>Finally,</b> we conduct a comparative study of our proposed solution on real <b>benchmark</b> datasets and demonstrate that the GML approach, in collaboration with DNNs for feature extraction, consistently outperforms pure DNN solutions.

{{</citation>}}


### (32/43 | 32/266) PetKaz at SemEval-2024 Task 8: Can Linguistics Capture the Specifics of LLM-generated Text? (Kseniia Petukhova et al., 2024)

{{<citation>}}

Kseniia Petukhova, Roman Kazakov, Ekaterina Kochmar. (2024)  
**PetKaz at SemEval-2024 Task 8: Can Linguistics Capture the Specifics of LLM-generated Text?**
<br/>
<button class="copy-to-clipboard" title="PetKaz at SemEval-2024 Task 8: Can Linguistics Capture the Specifics of LLM-generated Text?" index=32>
  <span class="copy-to-clipboard-item">Copy Title<span>
</button>
<div class="toast toast-copied toast-index-32 align-items-center text-bg-secondary border-0 position-absolute top-0 end-0" role="alert" aria-live="assertive" aria-atomic="true">
  <div class="d-flex">
    <div class="toast-body">
      Copied!
    </div>
  </div>
</div>

---
Primary Category: cs.CL  
Categories: I-2-7, cs-AI, cs-CL, cs.CL  
Keyword Score: 25  
Keywords: Black Box, RoBERTa, Large Language Model  
<a type="button" class="btn btn-outline-primary" href="http://arxiv.org/abs/2404.05483v1" target="_blank" >Paper Link</a>
<button type="button" class="btn btn-outline-primary download-pdf" url="https://arxiv.org/pdf/2404.05483v1.pdf" filename="2404.05483v1.pdf">Download PDF</button>

---


**ABSTRACT**  
In this paper, we present our submission to the SemEval-2024 Task 8 "Multigenerator, Multidomain, and Multilingual <b>Black-Box</b> <b>Machine-Generated</b> Text Detection", focusing on the detection of machine-generated texts (MGTs) in English. Specifically, our approach relies on combining embeddings from the <b>RoBERTa-base</b> with diversity features and uses a resampled training set. We score 12th from 124 in the ranking for Subtask A (monolingual track), and our results show that our approach is generalizable across unseen models and domains, achieving an accuracy of 0.91.

{{</citation>}}


### (33/43 | 33/266) XL$^2$Bench: A Benchmark for Extremely Long Context Understanding with Long-range Dependencies (Xuanfan Ni et al., 2024)

{{<citation>}}

Xuanfan Ni, Hengyi Cai, Xiaochi Wei, Shuaiqiang Wang, Dawei Yin, Piji Li. (2024)  
**XL$^2$Bench: A Benchmark for Extremely Long Context Understanding with Long-range Dependencies**
<br/>
<button class="copy-to-clipboard" title="XL$^2$Bench: A Benchmark for Extremely Long Context Understanding with Long-range Dependencies" index=33>
  <span class="copy-to-clipboard-item">Copy Title<span>
</button>
<div class="toast toast-copied toast-index-33 align-items-center text-bg-secondary border-0 position-absolute top-0 end-0" role="alert" aria-live="assertive" aria-atomic="true">
  <div class="d-flex">
    <div class="toast-body">
      Copied!
    </div>
  </div>
</div>

---
Primary Category: cs.CL  
Categories: cs-CL, cs.CL  
Keyword Score: 23  
Keywords: Benchmarking, Large Language Model, Large Language Model  
<a type="button" class="btn btn-outline-primary" href="http://arxiv.org/abs/2404.05446v1" target="_blank" >Paper Link</a>
<button type="button" class="btn btn-outline-primary download-pdf" url="https://arxiv.org/pdf/2404.05446v1.pdf" filename="2404.05446v1.pdf">Download PDF</button>

---


**ABSTRACT**  
<b>Large</b> <b>Language</b> <b>Models</b> <b>(LLMs)</b> have demonstrated remarkable performance across diverse tasks but are constrained by their small context window sizes. Various efforts have been proposed to expand the context window to accommodate even up to 200K input tokens. Meanwhile, building high-quality <b>benchmarks</b> with much longer text lengths and more demanding tasks to provide comprehensive evaluations is of immense practical interest to facilitate long context understanding research of <b>LLMs.</b> However, prior <b>benchmarks</b> create datasets that ostensibly cater to long-text comprehension by expanding the input of traditional tasks, which falls short to exhibit the unique characteristics of long-text understanding, including long dependency tasks and longer text length compatible with modern <b>LLMs'</b> context window size. In this paper, we introduce a <b>benchmark</b> for extremely long context understanding with long-range dependencies, XL$^2$Bench, which includes three scenarios: Fiction Reading, Paper Reading, and Law Reading, and four tasks of increasing complexity: Memory Retrieval, Detailed Understanding, Overall Understanding, and Open-ended Generation, covering 27 subtasks in English and Chinese. It has an average length of 100K+ words (English) and 200K+ characters (Chinese). Evaluating six leading <b>LLMs</b> on XL$^2$Bench, we find that their performance significantly lags behind human levels. Moreover, the observed decline in performance across both the original and enhanced datasets underscores the efficacy of our approach to mitigating data contamination.

{{</citation>}}


### (34/43 | 34/266) SafetyPrompts: a Systematic Review of Open Datasets for Evaluating and Improving Large Language Model Safety (Paul Röttger et al., 2024)

{{<citation>}}

Paul Röttger, Fabio Pernisi, Bertie Vidgen, Dirk Hovy. (2024)  
**SafetyPrompts: a Systematic Review of Open Datasets for Evaluating and Improving Large Language Model Safety**
<br/>
<button class="copy-to-clipboard" title="SafetyPrompts: a Systematic Review of Open Datasets for Evaluating and Improving Large Language Model Safety" index=34>
  <span class="copy-to-clipboard-item">Copy Title<span>
</button>
<div class="toast toast-copied toast-index-34 align-items-center text-bg-secondary border-0 position-absolute top-0 end-0" role="alert" aria-live="assertive" aria-atomic="true">
  <div class="d-flex">
    <div class="toast-body">
      Copied!
    </div>
  </div>
</div>

---
Primary Category: cs.CL  
Categories: cs-AI, cs-CL, cs.CL  
Keyword Score: 23  
Keywords: Benchmarking, Large Language Model, Large Language Model  
<a type="button" class="btn btn-outline-primary" href="http://arxiv.org/abs/2404.05399v1" target="_blank" >Paper Link</a>
<button type="button" class="btn btn-outline-primary download-pdf" url="https://arxiv.org/pdf/2404.05399v1.pdf" filename="2404.05399v1.pdf">Download PDF</button>

---


**ABSTRACT**  
The last two years have seen a rapid growth in concerns around the safety of <b>large</b> <b>language</b> <b>models</b> <b>(LLMs).</b> Researchers and practitioners have met these concerns by introducing an abundance of new datasets for evaluating and improving <b>LLM</b> safety. However, much of this work has happened in parallel, and with very different goals in mind, ranging from the mitigation of near-term risks around bias and toxic content generation to the assessment of longer-term catastrophic risk potential. This makes it difficult for researchers and practitioners to find the most relevant datasets for a given use case, and to identify gaps in dataset coverage that future work may fill. To remedy these issues, we conduct a first systematic review of open datasets for evaluating and improving <b>LLM</b> safety. We review 102 datasets, which we identified through an iterative and community-driven process over the course of several months. We highlight patterns and trends, such as a a trend towards fully synthetic datasets, as well as gaps in dataset coverage, such as a clear lack of non-English datasets. We also examine how <b>LLM</b> safety datasets are used in practice -- in <b>LLM</b> release publications and popular <b>LLM</b> <b>benchmarks</b> -- finding that current evaluation practices are highly idiosyncratic and make use of only a small fraction of available datasets. Our contributions are based on SafetyPrompts.com, a living catalogue of open datasets for <b>LLM</b> safety, which we commit to updating continuously as the field of <b>LLM</b> safety develops.

{{</citation>}}


### (35/43 | 35/266) Eraser: Jailbreaking Defense in Large Language Models via Unlearning Harmful Knowledge (Weikai Lu et al., 2024)

{{<citation>}}

Weikai Lu, Ziqian Zeng, Jianwei Wang, Zhengdong Lu, Zelin Chen, Huiping Zhuang, Cen Chen. (2024)  
**Eraser: Jailbreaking Defense in Large Language Models via Unlearning Harmful Knowledge**
<br/>
<button class="copy-to-clipboard" title="Eraser: Jailbreaking Defense in Large Language Models via Unlearning Harmful Knowledge" index=35>
  <span class="copy-to-clipboard-item">Copy Title<span>
</button>
<div class="toast toast-copied toast-index-35 align-items-center text-bg-secondary border-0 position-absolute top-0 end-0" role="alert" aria-live="assertive" aria-atomic="true">
  <div class="d-flex">
    <div class="toast-body">
      Copied!
    </div>
  </div>
</div>

---
Primary Category: cs.CL  
Categories: cs-CL, cs.CL  
Keyword Score: 20  
Keywords: Large Language Model, Large Language Model  
<a type="button" class="btn btn-outline-primary" href="http://arxiv.org/abs/2404.05880v1" target="_blank" >Paper Link</a>
<button type="button" class="btn btn-outline-primary download-pdf" url="https://arxiv.org/pdf/2404.05880v1.pdf" filename="2404.05880v1.pdf">Download PDF</button>

---


**ABSTRACT**  
Jailbreaking attacks can enable <b>Large</b> <b>Language</b> <b>Models</b> <b>(LLMs)</b> to bypass the safeguard and generate harmful content. Existing jailbreaking defense methods have failed to address the fundamental issue that harmful knowledge resides within the model, leading to potential jailbreak risks for <b>LLMs.</b> In this paper, we propose a novel defense method called Eraser, which mainly includes three goals: unlearning harmful knowledge, retaining general knowledge, and maintaining safety alignment. The intuition is that if an <b>LLM</b> forgets the specific knowledge required to answer a harmful question, it will no longer have the ability to answer harmful questions. The training of Erase does not actually require the model's own harmful knowledge, and it can benefit from unlearning general answers related to harmful queries, which means it does not need assistance from the red team. The experimental results show that Eraser can significantly reduce the jailbreaking success rate for various attacks without compromising the general capabilities of the model.

{{</citation>}}


### (36/43 | 36/266) Causality Extraction from Nuclear Licensee Event Reports Using a Hybrid Framework (Sohag Rahman et al., 2024)

{{<citation>}}

Sohag Rahman, Sai Zhang, Min Xian, Shoukun Sun, Fei Xu, Zhegang Ma. (2024)  
**Causality Extraction from Nuclear Licensee Event Reports Using a Hybrid Framework**
<br/>
<button class="copy-to-clipboard" title="Causality Extraction from Nuclear Licensee Event Reports Using a Hybrid Framework" index=36>
  <span class="copy-to-clipboard-item">Copy Title<span>
</button>
<div class="toast toast-copied toast-index-36 align-items-center text-bg-secondary border-0 position-absolute top-0 end-0" role="alert" aria-live="assertive" aria-atomic="true">
  <div class="d-flex">
    <div class="toast-body">
      Copied!
    </div>
  </div>
</div>

---
Primary Category: cs.CL  
Categories: cs-AI, cs-CL, cs-LG, cs.CL  
Keyword Score: 20  
Keywords: Relation Extraction, Relation Extraction  
<a type="button" class="btn btn-outline-primary" href="http://arxiv.org/abs/2404.05656v1" target="_blank" >Paper Link</a>
<button type="button" class="btn btn-outline-primary download-pdf" url="https://arxiv.org/pdf/2404.05656v1.pdf" filename="2404.05656v1.pdf">Download PDF</button>

---


**ABSTRACT**  
Industry-wide nuclear power plant operating experience is a critical source of raw data for performing parameter estimations in reliability and risk models. Much operating experience information pertains to failure events and is stored as reports containing unstructured data, such as narratives. Event reports are essential for understanding how failures are initiated and propagated, including the numerous causal <b>relations</b> <b>involved.</b> Causal <b>relation</b> <b>extraction</b> using deep learning represents a significant frontier in the field of natural language processing (NLP), and is crucial since it enables the interpretation of intricate narratives and connections contained within vast amounts of written information. This paper proposed a hybrid framework for causality detection and extraction from nuclear licensee event reports. The main contributions include: (1) we compiled an LER corpus with 20,129 text samples for causality analysis, (2) developed an interactive tool for labeling cause effect pairs, (3) built a deep-learning-based approach for causal <b>relation</b> <b>detection,</b> and (4) developed a knowledge based cause-effect extraction approach.

{{</citation>}}


### (37/43 | 37/266) Eagle and Finch: RWKV with Matrix-Valued States and Dynamic Recurrence (Bo Peng et al., 2024)

{{<citation>}}

Bo Peng, Daniel Goldstein, Quentin Anthony, Alon Albalak, Eric Alcaide, Stella Biderman, Eugene Cheah, Xingjian Du, Teddy Ferdinan, Haowen Hou, Przemysław Kazienko, Kranthi Kiran GV, Jan Kocoń, Bartłomiej Koptyra, Satyapriya Krishna, Ronald McClelland Jr., Niklas Muennighoff, Fares Obeid, Atsushi Saito, Guangyu Song, Haoqin Tu, Stanisław Woźniak, Ruichong Zhang, Bingchen Zhao, Qihang Zhao, Peng Zhou, Jian Zhu, Rui-Jie Zhu. (2024)  
**Eagle and Finch: RWKV with Matrix-Valued States and Dynamic Recurrence**
<br/>
<button class="copy-to-clipboard" title="Eagle and Finch: RWKV with Matrix-Valued States and Dynamic Recurrence" index=37>
  <span class="copy-to-clipboard-item">Copy Title<span>
</button>
<div class="toast toast-copied toast-index-37 align-items-center text-bg-secondary border-0 position-absolute top-0 end-0" role="alert" aria-live="assertive" aria-atomic="true">
  <div class="d-flex">
    <div class="toast-body">
      Copied!
    </div>
  </div>
</div>

---
Primary Category: cs.CL  
Categories: cs-AI, cs-CL, cs.CL  
Keyword Score: 13  
Keywords: Benchmarking, Recurrent Neural Network  
<a type="button" class="btn btn-outline-primary" href="http://arxiv.org/abs/2404.05892v2" target="_blank" >Paper Link</a>
<button type="button" class="btn btn-outline-primary download-pdf" url="https://arxiv.org/pdf/2404.05892v2.pdf" filename="2404.05892v2.pdf">Download PDF</button>

---


**ABSTRACT**  
We present Eagle (RWKV-5) and Finch (RWKV-6), sequence models improving upon the RWKV (RWKV-4) architecture. Our architectural design advancements include multi-headed matrix-valued states and a dynamic recurrence mechanism that improve expressivity while maintaining the inference efficiency characteristics of <b>RNNs.</b> We introduce a new multilingual corpus with 1.12 trillion tokens and a fast tokenizer based on greedy matching for enhanced multilinguality. We trained four Eagle models, ranging from 0.46 to 7.5 billion parameters, and two Finch models with 1.6 and 3.1 billion parameters and find that they achieve competitive performance across a wide variety of <b>benchmarks.</b> We release all our models on HuggingFace under the Apache 2.0 license. Models at: https://huggingface.co/RWKV Training code at: https://github.com/RWKV/RWKV-LM Inference code at: https://github.com/RWKV/ChatRWKV Time-parallel training code at: https://github.com/RWKV/RWKV-infctx-trainer

{{</citation>}}


### (38/43 | 38/266) PORTULAN ExtraGLUE Datasets and Models: Kick-starting a Benchmark for the Neural Processing of Portuguese (Tomás Osório et al., 2024)

{{<citation>}}

Tomás Osório, Bernardo Leite, Henrique Lopes Cardoso, Luís Gomes, João Rodrigues, Rodrigo Santos, António Branco. (2024)  
**PORTULAN ExtraGLUE Datasets and Models: Kick-starting a Benchmark for the Neural Processing of Portuguese**
<br/>
<button class="copy-to-clipboard" title="PORTULAN ExtraGLUE Datasets and Models: Kick-starting a Benchmark for the Neural Processing of Portuguese" index=38>
  <span class="copy-to-clipboard-item">Copy Title<span>
</button>
<div class="toast toast-copied toast-index-38 align-items-center text-bg-secondary border-0 position-absolute top-0 end-0" role="alert" aria-live="assertive" aria-atomic="true">
  <div class="d-flex">
    <div class="toast-body">
      Copied!
    </div>
  </div>
</div>

---
Primary Category: cs.CL  
Categories: cs-CL, cs.CL  
Keyword Score: 13  
Keywords: Benchmarking, Fine-tuning  
<a type="button" class="btn btn-outline-primary" href="http://arxiv.org/abs/2404.05333v2" target="_blank" >Paper Link</a>
<button type="button" class="btn btn-outline-primary download-pdf" url="https://arxiv.org/pdf/2404.05333v2.pdf" filename="2404.05333v2.pdf">Download PDF</button>

---


**ABSTRACT**  
Leveraging research on the neural modelling of Portuguese, we contribute a collection of datasets for an array of language processing tasks and a corresponding collection of <b>fine-tuned</b> neural language models on these downstream tasks. To align with mainstream <b>benchmarks</b> in the literature, originally developed in English, and to kick start their Portuguese counterparts, the datasets were machine-translated from English with a state-of-the-art translation engine. The resulting PORTULAN ExtraGLUE <b>benchmark</b> is a basis for research on Portuguese whose improvement can be pursued in future work. Similarly, the respective <b>fine-tuned</b> neural language models, developed with a low-rank adaptation approach, are made available as baselines that can stimulate future work on the neural processing of Portuguese. All datasets and models have been developed and are made available for two variants of Portuguese: European and Brazilian.

{{</citation>}}


### (39/43 | 39/266) GeniL: A Multilingual Dataset on Generalizing Language (Aida Mostafazadeh Davani et al., 2024)

{{<citation>}}

Aida Mostafazadeh Davani, Sagar Gubbi, Sunipa Dev, Shachi Dave, Vinodkumar Prabhakaran. (2024)  
**GeniL: A Multilingual Dataset on Generalizing Language**
<br/>
<button class="copy-to-clipboard" title="GeniL: A Multilingual Dataset on Generalizing Language" index=39>
  <span class="copy-to-clipboard-item">Copy Title<span>
</button>
<div class="toast toast-copied toast-index-39 align-items-center text-bg-secondary border-0 position-absolute top-0 end-0" role="alert" aria-live="assertive" aria-atomic="true">
  <div class="d-flex">
    <div class="toast-body">
      Copied!
    </div>
  </div>
</div>

---
Primary Category: cs.CL  
Categories: cs-CL, cs.CL  
Keyword Score: 10  
Keywords: Large Language Model  
<a type="button" class="btn btn-outline-primary" href="http://arxiv.org/abs/2404.05866v1" target="_blank" >Paper Link</a>
<button type="button" class="btn btn-outline-primary download-pdf" url="https://arxiv.org/pdf/2404.05866v1.pdf" filename="2404.05866v1.pdf">Download PDF</button>

---


**ABSTRACT**  
<b>LLMs</b> are increasingly transforming our digital ecosystem, but they often inherit societal biases learned from their training data, for instance stereotypes associating certain attributes with specific identity groups. While whether and how these biases are mitigated may depend on the specific use cases, being able to effectively detect instances of stereotype perpetuation is a crucial first step. Current methods to assess presence of stereotypes in generated language rely on simple template or co-occurrence based measures, without accounting for the variety of sentential contexts they manifest in. We argue that understanding the sentential context is crucial for detecting instances of generalization. We distinguish two types of generalizations: (1) language that merely mentions the presence of a generalization ("people think the French are very rude"), and (2) language that reinforces such a generalization ("as French they must be rude"), from non-generalizing context ("My French friends think I am rude"). For meaningful stereotype evaluations, we need to reliably distinguish such instances of generalizations. We introduce the new task of detecting generalization in language, and build GeniL, a multilingual dataset of over 50K sentences from 9 languages (English, Arabic, Bengali, Spanish, French, Hindi, Indonesian, Malay, and Portuguese) annotated for instances of generalizations. We demonstrate that the likelihood of a co-occurrence being an instance of generalization is usually low, and varies across different languages, identity groups, and attributes. We build classifiers to detect generalization in language with an overall PR-AUC of 58.7, with varying degrees of performance across languages. Our research provides data and tools to enable a nuanced understanding of stereotype perpetuation, a crucial step towards more inclusive and responsible language technologies.

{{</citation>}}


### (40/43 | 40/266) NLP Progress in Indigenous Latin American Languages (Atnafu Lambebo Tonja et al., 2024)

{{<citation>}}

Atnafu Lambebo Tonja, Fazlourrahman Balouchzahi, Sabur Butt, Olga Kolesnikova, Hector Ceballos, Alexander Gelbukh, Thamar Solorio. (2024)  
**NLP Progress in Indigenous Latin American Languages**
<br/>
<button class="copy-to-clipboard" title="NLP Progress in Indigenous Latin American Languages" index=40>
  <span class="copy-to-clipboard-item">Copy Title<span>
</button>
<div class="toast toast-copied toast-index-40 align-items-center text-bg-secondary border-0 position-absolute top-0 end-0" role="alert" aria-live="assertive" aria-atomic="true">
  <div class="d-flex">
    <div class="toast-body">
      Copied!
    </div>
  </div>
</div>

---
Primary Category: cs.CL  
Categories: cs-CL, cs.CL  
Keyword Score: 10  
Keywords: Low-Resource  
<a type="button" class="btn btn-outline-primary" href="http://arxiv.org/abs/2404.05365v1" target="_blank" >Paper Link</a>
<button type="button" class="btn btn-outline-primary download-pdf" url="https://arxiv.org/pdf/2404.05365v1.pdf" filename="2404.05365v1.pdf">Download PDF</button>

---


**ABSTRACT**  
The paper focuses on the marginalization of indigenous language communities in the face of rapid technological advancements. We highlight the cultural richness of these languages and the risk they face of being overlooked in the realm of Natural Language Processing (NLP). We aim to bridge the gap between these communities and researchers, emphasizing the need for inclusive technological advancements that respect indigenous community perspectives. We show the NLP progress of indigenous Latin American languages and the survey that covers the status of indigenous languages in Latin America, their representation in NLP, and the challenges and innovations required for their preservation and development. The paper contributes to the current literature in understanding the need and progress of NLP for indigenous communities of Latin America, specifically <b>low-resource</b> and indigenous communities in general.

{{</citation>}}


### (41/43 | 41/266) Multi-Task Learning for Features Extraction in Financial Annual Reports (Syrielle Montariol et al., 2024)

{{<citation>}}

Syrielle Montariol, Matej Martinc, Andraž Pelicon, Senja Pollak, Boshko Koloski, Igor Lončarski, Aljoša Valentinčič. (2024)  
**Multi-Task Learning for Features Extraction in Financial Annual Reports**
<br/>
<button class="copy-to-clipboard" title="Multi-Task Learning for Features Extraction in Financial Annual Reports" index=41>
  <span class="copy-to-clipboard-item">Copy Title<span>
</button>
<div class="toast toast-copied toast-index-41 align-items-center text-bg-secondary border-0 position-absolute top-0 end-0" role="alert" aria-live="assertive" aria-atomic="true">
  <div class="d-flex">
    <div class="toast-body">
      Copied!
    </div>
  </div>
</div>

---
Primary Category: cs.CL  
Categories: cs-CL, cs.CL  
Keyword Score: 10  
Keywords: Text Classification  
<a type="button" class="btn btn-outline-primary" href="http://arxiv.org/abs/2404.05281v1" target="_blank" >Paper Link</a>
<button type="button" class="btn btn-outline-primary download-pdf" url="https://arxiv.org/pdf/2404.05281v1.pdf" filename="2404.05281v1.pdf">Download PDF</button>

---


**ABSTRACT**  
For assessing various performance indicators of companies, the focus is shifting from strictly financial (quantitative) publicly disclosed information to qualitative (textual) information. This textual data can provide valuable weak signals, for example through stylistic features, which can complement the quantitative data on financial performance or on Environmental, Social and Governance (ESG) criteria. In this work, we use various multi-task learning methods for financial <b>text</b> <b>classification</b> with the focus on financial sentiment, objectivity, forward-looking sentence prediction and ESG-content detection. We propose different methods to combine the information extracted from training jointly on different tasks; our best-performing method highlights the positive effect of explicitly adding auxiliary task predictions as features for the final target task during the multi-task training. Next, we use these classifiers to extract textual features from annual reports of FTSE350 companies and investigate the link between ESG quantitative scores and these features.

{{</citation>}}


### (42/43 | 42/266) Linguistic Changes in Spontaneous Speech for Detecting Parkinsons Disease Using Large Language Models (Jonathan Crawford, 2024)

{{<citation>}}

Jonathan Crawford. (2024)  
**Linguistic Changes in Spontaneous Speech for Detecting Parkinsons Disease Using Large Language Models**
<br/>
<button class="copy-to-clipboard" title="Linguistic Changes in Spontaneous Speech for Detecting Parkinsons Disease Using Large Language Models" index=42>
  <span class="copy-to-clipboard-item">Copy Title<span>
</button>
<div class="toast toast-copied toast-index-42 align-items-center text-bg-secondary border-0 position-absolute top-0 end-0" role="alert" aria-live="assertive" aria-atomic="true">
  <div class="d-flex">
    <div class="toast-body">
      Copied!
    </div>
  </div>
</div>

---
Primary Category: cs.CL  
Categories: cs-CL, cs.CL, eess-AS  
Keyword Score: 10  
Keywords: Large Language Model  
<a type="button" class="btn btn-outline-primary" href="http://arxiv.org/abs/2404.05160v1" target="_blank" >Paper Link</a>
<button type="button" class="btn btn-outline-primary download-pdf" url="https://arxiv.org/pdf/2404.05160v1.pdf" filename="2404.05160v1.pdf">Download PDF</button>

---


**ABSTRACT**  
Parkinsons disease is the second most prevalent neurodegenerative disorder with over ten million active cases worldwide and one million new diagnoses per year. Detecting and subsequently diagnosing the disease is challenging because of symptom heterogeneity with respect to complexity, as well as the type and timing of phenotypic manifestations. Typically, language impairment can present in the prodromal phase and precede motor symptoms suggesting that a linguistic-based approach could serve as a diagnostic method for incipient Parkinsons disease. Additionally, improved linguistic models may enhance other approaches through ensemble techniques. The field of <b>large</b> <b>language</b> <b>models</b> is advancing rapidly, presenting the opportunity to explore the use of these new models for detecting Parkinsons disease and to improve on current linguistic approaches with high-dimensional representations of linguistics. We evaluate the application of state-of-the-art <b>large</b> <b>language</b> <b>models</b> to detect Parkinsons disease automatically from spontaneous speech with up to 73% accuracy.

{{</citation>}}


### (43/43 | 43/266) Language Models on a Diet: Cost-Efficient Development of Encoders for Closely-Related Languages via Additional Pretraining (Nikola Ljubešić et al., 2024)

{{<citation>}}

Nikola Ljubešić, Vít Suchomel, Peter Rupnik, Taja Kuzman, Rik van Noord. (2024)  
**Language Models on a Diet: Cost-Efficient Development of Encoders for Closely-Related Languages via Additional Pretraining**
<br/>
<button class="copy-to-clipboard" title="Language Models on a Diet: Cost-Efficient Development of Encoders for Closely-Related Languages via Additional Pretraining" index=43>
  <span class="copy-to-clipboard-item">Copy Title<span>
</button>
<div class="toast toast-copied toast-index-43 align-items-center text-bg-secondary border-0 position-absolute top-0 end-0" role="alert" aria-live="assertive" aria-atomic="true">
  <div class="d-flex">
    <div class="toast-body">
      Copied!
    </div>
  </div>
</div>

---
Primary Category: cs.CL  
Categories: cs-CL, cs.CL  
Keyword Score: 3  
Keywords: Benchmarking  
<a type="button" class="btn btn-outline-primary" href="http://arxiv.org/abs/2404.05428v1" target="_blank" >Paper Link</a>
<button type="button" class="btn btn-outline-primary download-pdf" url="https://arxiv.org/pdf/2404.05428v1.pdf" filename="2404.05428v1.pdf">Download PDF</button>

---


**ABSTRACT**  
The world of language models is going through turbulent times, better and ever larger models are coming out at an unprecedented speed. However, we argue that, especially for the scientific community, encoder models of up to 1 billion parameters are still very much needed, their primary usage being in enriching large collections of data with metadata necessary for downstream research. We investigate the best way to ensure the existence of such encoder models on the set of very closely related languages - Croatian, Serbian, Bosnian and Montenegrin, by setting up a diverse <b>benchmark</b> for these languages, and comparing the trained-from-scratch models with the new models constructed via additional pretraining of existing multilingual models. We show that comparable performance to dedicated from-scratch models can be obtained by additionally pretraining available multilingual models even with a limited amount of computation. We also show that neighboring languages, in our case Slovenian, can be included in the additional pretraining with little to no loss in the performance of the final model.

{{</citation>}}


## cs.CV (76)



### (1/76 | 44/266) Test-Time Zero-Shot Temporal Action Localization (Benedetta Liberatori et al., 2024)

{{<citation>}}

Benedetta Liberatori, Alessandro Conti, Paolo Rota, Yiming Wang, Elisa Ricci. (2024)  
**Test-Time Zero-Shot Temporal Action Localization**
<br/>
<button class="copy-to-clipboard" title="Test-Time Zero-Shot Temporal Action Localization" index=44>
  <span class="copy-to-clipboard-item">Copy Title<span>
</button>
<div class="toast toast-copied toast-index-44 align-items-center text-bg-secondary border-0 position-absolute top-0 end-0" role="alert" aria-live="assertive" aria-atomic="true">
  <div class="d-flex">
    <div class="toast-body">
      Copied!
    </div>
  </div>
</div>

---
Primary Category: cs.CV  
Categories: cs-CV, cs.CV  
Keyword Score: 80  
Keywords: Fine-tuning, Self-supervised Learning, Self-supervised Learning, Supervised Learning, Supervised Learning, Zero-shot, Prompt, Vision-and-Language  
<a type="button" class="btn btn-outline-primary" href="http://arxiv.org/abs/2404.05426v2" target="_blank" >Paper Link</a>
<button type="button" class="btn btn-outline-primary download-pdf" url="https://arxiv.org/pdf/2404.05426v2.pdf" filename="2404.05426v2.pdf">Download PDF</button>

---


**ABSTRACT**  
<b>Zero-Shot</b> Temporal Action Localization (ZS-TAL) seeks to identify and locate actions in untrimmed videos unseen during training. Existing ZS-TAL methods involve <b>fine-tuning</b> a model on a large amount of annotated training data. While effective, training-based ZS-TAL approaches assume the availability of labeled data for <b>supervised</b> <b>learning,</b> which can be impractical in some applications. Furthermore, the training process naturally induces a domain bias into the learned model, which may adversely affect the model's generalization ability to arbitrary videos. These considerations <b>prompt</b> us to approach the ZS-TAL problem from a radically novel perspective, relaxing the requirement for training data. To this aim, we introduce a novel method that performs Test-Time adaptation for Temporal Action Localization (T3AL). In a nutshell, T3AL adapts a pre-trained Vision and Language Model (VLM). T3AL operates in three steps. First, a video-level pseudo-label of the action category is computed by aggregating information from the entire video. Then, action localization is performed adopting a novel procedure inspired by <b>self-supervised</b> <b>learning.</b> Finally, frame-level textual descriptions extracted with a state-of-the-art captioning model are employed for refining the action region proposals. We validate the effectiveness of T3AL by conducting experiments on the THUMOS14 and the ActivityNet-v1.3 datasets. Our results demonstrate that T3AL significantly outperforms <b>zero-shot</b> baselines based on state-of-the-art VLMs, confirming the benefit of a test-time adaptation approach.

{{</citation>}}


### (2/76 | 45/266) HAMMR: HierArchical MultiModal React agents for generic VQA (Lluis Castrejon et al., 2024)

{{<citation>}}

Lluis Castrejon, Thomas Mensink, Howard Zhou, Vittorio Ferrari, Andre Araujo, Jasper Uijlings. (2024)  
**HAMMR: HierArchical MultiModal React agents for generic VQA**
<br/>
<button class="copy-to-clipboard" title="HAMMR: HierArchical MultiModal React agents for generic VQA" index=45>
  <span class="copy-to-clipboard-item">Copy Title<span>
</button>
<div class="toast toast-copied toast-index-45 align-items-center text-bg-secondary border-0 position-absolute top-0 end-0" role="alert" aria-live="assertive" aria-atomic="true">
  <div class="d-flex">
    <div class="toast-body">
      Copied!
    </div>
  </div>
</div>

---
Primary Category: cs.CV  
Categories: cs-CV, cs-LG, cs.CV  
Keyword Score: 79  
Keywords: Optical Character Recognition, Benchmarking, Multi-modal, Multi-modal, Question Answering, Reasoning, Visual Question Answering, Visual Question Answering, Large Language Model, Large Language Model  
<a type="button" class="btn btn-outline-primary" href="http://arxiv.org/abs/2404.05465v1" target="_blank" >Paper Link</a>
<button type="button" class="btn btn-outline-primary download-pdf" url="https://arxiv.org/pdf/2404.05465v1.pdf" filename="2404.05465v1.pdf">Download PDF</button>

---


**ABSTRACT**  
Combining <b>Large</b> <b>Language</b> <b>Models</b> <b>(LLMs)</b> with external specialized tools (LLMs+tools) is a recent paradigm to solve <b>multimodal</b> tasks such as <b>Visual</b> <b>Question</b> <b>Answering</b> <b>(VQA).</b> While this approach was demonstrated to work well when optimized and evaluated for each individual <b>benchmark,</b> in practice it is crucial for the next generation of real-world AI systems to handle a broad range of <b>multimodal</b> problems. Therefore we pose the <b>VQA</b> problem from a unified perspective and evaluate a single system on a varied suite of <b>VQA</b> tasks including counting, spatial <b>reasoning,</b> <b>OCR-based</b> <b>reasoning,</b> <b>visual</b> <b>pointing,</b> <b>external</b> knowledge, and more. In this setting, we demonstrate that naively applying the LLM+tools approach using the combined set of all tools leads to poor results. This motivates us to introduce HAMMR: HierArchical <b>MultiModal</b> React. We start from a <b>multimodal</b> ReAct-based system and make it hierarchical by enabling our HAMMR agents to call upon other specialized agents. This enhances the compositionality of the LLM+tools approach, which we show to be critical for obtaining high accuracy on generic <b>VQA.</b> Concretely, on our generic <b>VQA</b> suite, HAMMR outperforms the naive LLM+tools approach by 19.5%. Additionally, HAMMR achieves state-of-the-art results on this task, outperforming the generic standalone PaLI-X <b>VQA</b> model by 5.0%.

{{</citation>}}


### (3/76 | 46/266) MoMA: Multimodal LLM Adapter for Fast Personalized Image Generation (Kunpeng Song et al., 2024)

{{<citation>}}

Kunpeng Song, Yizhe Zhu, Bingchen Liu, Qing Yan, Ahmed Elgammal, Xiao Yang. (2024)  
**MoMA: Multimodal LLM Adapter for Fast Personalized Image Generation**
<br/>
<button class="copy-to-clipboard" title="MoMA: Multimodal LLM Adapter for Fast Personalized Image Generation" index=46>
  <span class="copy-to-clipboard-item">Copy Title<span>
</button>
<div class="toast toast-copied toast-index-46 align-items-center text-bg-secondary border-0 position-absolute top-0 end-0" role="alert" aria-live="assertive" aria-atomic="true">
  <div class="d-flex">
    <div class="toast-body">
      Copied!
    </div>
  </div>
</div>

---
Primary Category: cs.CV  
Categories: cs-CV, cs.CV  
Keyword Score: 76  
Keywords: Diffusion Model, Multi-modal, Multi-modal, Zero-shot, Text2image, Large Language Model, Large Language Model, Prompt, Self-Attention  
<a type="button" class="btn btn-outline-primary" href="http://arxiv.org/abs/2404.05674v1" target="_blank" >Paper Link</a>
<button type="button" class="btn btn-outline-primary download-pdf" url="https://arxiv.org/pdf/2404.05674v1.pdf" filename="2404.05674v1.pdf">Download PDF</button>

---


**ABSTRACT**  
In this paper, we present MoMA: an open-vocabulary, training-free personalized image model that boasts flexible <b>zero-shot</b> capabilities. As foundational <b>text-to-image</b> models rapidly evolve, the demand for robust image-to-image translation grows. Addressing this need, MoMA specializes in subject-driven personalized image generation. Utilizing an open-source, <b>Multimodal</b> <b>Large</b> <b>Language</b> <b>Model</b> (MLLM), we train MoMA to serve a dual role as both a feature extractor and a generator. This approach effectively synergizes reference image and text <b>prompt</b> information to produce valuable image features, facilitating an image <b>diffusion</b> <b>model.</b> To better leverage the generated features, we further introduce a novel <b>self-attention</b> shortcut method that efficiently transfers image features to an image <b>diffusion</b> <b>model,</b> improving the resemblance of the target object in generated images. Remarkably, as a tuning-free plug-and-play module, our model requires only a single reference image and outperforms existing methods in generating images with high detail fidelity, enhanced identity-preservation and <b>prompt</b> faithfulness. Our work is open-source, thereby providing universal access to these advancements.

{{</citation>}}


### (4/76 | 47/266) Progressive Alignment with VLM-LLM Feature to Augment Defect Classification for the ASE Dataset (Chih-Chung Hsu et al., 2024)

{{<citation>}}

Chih-Chung Hsu, Chia-Ming Lee, Chun-Hung Sun, Kuang-Ming Wu. (2024)  
**Progressive Alignment with VLM-LLM Feature to Augment Defect Classification for the ASE Dataset**
<br/>
<button class="copy-to-clipboard" title="Progressive Alignment with VLM-LLM Feature to Augment Defect Classification for the ASE Dataset" index=47>
  <span class="copy-to-clipboard-item">Copy Title<span>
</button>
<div class="toast toast-copied toast-index-47 align-items-center text-bg-secondary border-0 position-absolute top-0 end-0" role="alert" aria-live="assertive" aria-atomic="true">
  <div class="d-flex">
    <div class="toast-body">
      Copied!
    </div>
  </div>
</div>

---
Primary Category: cs.CV  
Categories: cs-CV, cs-LG, cs.CV  
Keyword Score: 70  
Keywords: Few-shot, Zero-shot, Image2text, Large Language Model, Large Language Model, Prompt, Vision-and-Language  
<a type="button" class="btn btn-outline-primary" href="http://arxiv.org/abs/2404.05183v1" target="_blank" >Paper Link</a>
<button type="button" class="btn btn-outline-primary download-pdf" url="https://arxiv.org/pdf/2404.05183v1.pdf" filename="2404.05183v1.pdf">Download PDF</button>

---


**ABSTRACT**  
Traditional defect classification approaches are facing with two barriers. (1) Insufficient training data and unstable data quality. Collecting sufficient defective sample is expensive and time-costing, consequently leading to dataset variance. It introduces the difficulty on recognition and learning. (2) Over-dependence on visual modality. When the image pattern and texture is monotonic for all defect classes in a given dataset, the performance of conventional AOI system cannot be guaranteed. In scenarios where image quality is compromised due to mechanical failures or when defect information is inherently difficult to discern, the performance of deep models cannot be guaranteed. A main question is, "how to solve those two problems when they occur at the same time?" The feasible strategy is to explore another feature within dataset and combine an eminent <b>vision-language</b> model (VLM) and <b>Large-Language</b> <b>model</b> <b>(LLM)</b> with their astonishing <b>zero-shot</b> capability. In this work, we propose the special ASE dataset, including rich data description recorded on image, for defect classification, but the defect feature is uneasy to learn directly. Secondly, We present the <b>prompting</b> for VLM-LLM against defect classification with the proposed ASE dataset to activate extra-modality feature from images to enhance performance. Then, We design the novel progressive feature alignment (PFA) block to refine <b>image-text</b> feature to alleviate the difficulty of alignment under <b>few-shot</b> scenario. Finally, the proposed Cross-modality attention fusion (CMAF) module can effectively fuse different modality feature. Experiment results have demonstrated our method's effectiveness over several defect classification methods for the ASE dataset.

{{</citation>}}


### (5/76 | 48/266) Ferret-UI: Grounded Mobile UI Understanding with Multimodal LLMs (Keen You et al., 2024)

{{<citation>}}

Keen You, Haotian Zhang, Eldon Schoop, Floris Weers, Amanda Swearngin, Jeffrey Nichols, Yinfei Yang, Zhe Gan. (2024)  
**Ferret-UI: Grounded Mobile UI Understanding with Multimodal LLMs**
<br/>
<button class="copy-to-clipboard" title="Ferret-UI: Grounded Mobile UI Understanding with Multimodal LLMs" index=48>
  <span class="copy-to-clipboard-item">Copy Title<span>
</button>
<div class="toast toast-copied toast-index-48 align-items-center text-bg-secondary border-0 position-absolute top-0 end-0" role="alert" aria-live="assertive" aria-atomic="true">
  <div class="d-flex">
    <div class="toast-body">
      Copied!
    </div>
  </div>
</div>

---
Primary Category: cs.CV  
Categories: cs-CL, cs-CV, cs-HC, cs.CV  
Keyword Score: 69  
Keywords: Benchmarking, Multi-modal, Multi-modal, GPT, Grounding, Instruction Following, Reasoning, Large Language Model, Large Language Model  
<a type="button" class="btn btn-outline-primary" href="http://arxiv.org/abs/2404.05719v1" target="_blank" >Paper Link</a>
<button type="button" class="btn btn-outline-primary download-pdf" url="https://arxiv.org/pdf/2404.05719v1.pdf" filename="2404.05719v1.pdf">Download PDF</button>

---


**ABSTRACT**  
Recent advancements in <b>multimodal</b> <b>large</b> <b>language</b> <b>models</b> (MLLMs) have been noteworthy, yet, these general-domain MLLMs often fall short in their ability to comprehend and interact effectively with user interface (UI) screens. In this paper, we present Ferret-UI, a new MLLM tailored for enhanced understanding of mobile UI screens, equipped with referring, <b>grounding,</b> and <b>reasoning</b> capabilities. Given that UI screens typically exhibit a more elongated aspect ratio and contain smaller objects of interest (e.g., icons, texts) than natural images, we incorporate "any resolution" on top of Ferret to magnify details and leverage enhanced visual features. Specifically, each screen is divided into 2 sub-images based on the original aspect ratio (i.e., horizontal division for portrait screens and vertical division for landscape screens). Both sub-images are encoded separately before being sent to <b>LLMs.</b> We meticulously gather training samples from an extensive range of elementary UI tasks, such as icon recognition, find text, and widget listing. These samples are formatted for <b>instruction-following</b> <b>with</b> region annotations to facilitate precise referring and <b>grounding.</b> To augment the model's <b>reasoning</b> ability, we further compile a dataset for advanced tasks, including detailed description, perception/interaction conversations, and function inference. After training on the curated datasets, Ferret-UI exhibits outstanding comprehension of UI screens and the capability to execute open-ended <b>instructions.</b> <b>For</b> model evaluation, we establish a comprehensive <b>benchmark</b> encompassing all the aforementioned tasks. Ferret-UI excels not only beyond most open-source UI MLLMs, but also surpasses <b>GPT-4V</b> on all the elementary UI tasks.

{{</citation>}}


### (6/76 | 49/266) Text-to-Image Synthesis for Any Artistic Styles: Advancements in Personalized Artistic Image Generation via Subdivision and Dual Binding (Junseo Park et al., 2024)

{{<citation>}}

Junseo Park, Beomseok Ko, Hyeryung Jang. (2024)  
**Text-to-Image Synthesis for Any Artistic Styles: Advancements in Personalized Artistic Image Generation via Subdivision and Dual Binding**
<br/>
<button class="copy-to-clipboard" title="Text-to-Image Synthesis for Any Artistic Styles: Advancements in Personalized Artistic Image Generation via Subdivision and Dual Binding" index=49>
  <span class="copy-to-clipboard-item">Copy Title<span>
</button>
<div class="toast toast-copied toast-index-49 align-items-center text-bg-secondary border-0 position-absolute top-0 end-0" role="alert" aria-live="assertive" aria-atomic="true">
  <div class="d-flex">
    <div class="toast-body">
      Copied!
    </div>
  </div>
</div>

---
Primary Category: cs.CV  
Categories: cs-AI, cs-CV, cs.CV  
Keyword Score: 60  
Keywords: Diffusion Model, Fine-tuning, Fine-tuning, Text2image, Text2image, Prompt  
<a type="button" class="btn btn-outline-primary" href="http://arxiv.org/abs/2404.05256v1" target="_blank" >Paper Link</a>
<button type="button" class="btn btn-outline-primary download-pdf" url="https://arxiv.org/pdf/2404.05256v1.pdf" filename="2404.05256v1.pdf">Download PDF</button>

---


**ABSTRACT**  
Recent advancements in <b>text-to-image</b> models, such as Stable <b>Diffusion,</b> <b>have</b> demonstrated their ability to synthesize visual images through natural language <b>prompts.</b> One approach of personalizing <b>text-to-image</b> models, exemplified by DreamBooth, <b>fine-tunes</b> the pre-trained model by binding unique text identifiers with a few images of a specific subject. Although existing <b>fine-tuning</b> methods have demonstrated competence in rendering images according to the styles of famous painters, it is still challenging to learn to produce images encapsulating distinct art styles due to abstract and broad visual perceptions of stylistic attributes such as lines, shapes, textures, and colors. In this paper, we introduce a new method, Single-StyleForge, for personalization. It <b>fine-tunes</b> pre-trained <b>text-to-image</b> <b>diffusion</b> <b>models</b> to generate diverse images in specified styles from text <b>prompts.</b> By using around 15-20 images of the target style, the approach establishes a foundational binding of a unique token identifier with a broad range of the target style. It also utilizes auxiliary images to strengthen this binding, resulting in offering specific guidance on representing elements such as persons in a target style-consistent manner. In addition, we present ways to improve the quality of style and <b>text-image</b> alignment through a method called Multi-StyleForge, which inherits the strategy used in StyleForge and learns tokens in multiple. Experimental evaluation conducted on six distinct artistic styles demonstrates substantial improvements in both the quality of generated images and the perceptual fidelity metrics, such as FID, KID, and CLIP scores.

{{</citation>}}


### (7/76 | 50/266) HSViT: Horizontally Scalable Vision Transformer (Chenhao Xu et al., 2024)

{{<citation>}}

Chenhao Xu, Chang-Tsun Li, Chee Peng Lim, Douglas Creighton. (2024)  
**HSViT: Horizontally Scalable Vision Transformer**
<br/>
<button class="copy-to-clipboard" title="HSViT: Horizontally Scalable Vision Transformer" index=50>
  <span class="copy-to-clipboard-item">Copy Title<span>
</button>
<div class="toast toast-copied toast-index-50 align-items-center text-bg-secondary border-0 position-absolute top-0 end-0" role="alert" aria-live="assertive" aria-atomic="true">
  <div class="d-flex">
    <div class="toast-body">
      Copied!
    </div>
  </div>
</div>

---
Primary Category: cs.CV  
Categories: cs-CV, cs.CV  
Keyword Score: 60  
Keywords: Vision Transformer, Convolution, Convolutional Neural Network, Convolutional Neural Network, Transformer, Vision Transformer  
<a type="button" class="btn btn-outline-primary" href="http://arxiv.org/abs/2404.05196v1" target="_blank" >Paper Link</a>
<button type="button" class="btn btn-outline-primary download-pdf" url="https://arxiv.org/pdf/2404.05196v1.pdf" filename="2404.05196v1.pdf">Download PDF</button>

---


**ABSTRACT**  
While the <b>Vision</b> <b>Transformer</b> (ViT) architecture gains prominence in computer <b>vision</b> <b>and</b> attracts significant attention from multimedia communities, its deficiency in prior knowledge (inductive bias) regarding shift, scale, and rotational invariance necessitates pre-training on large-scale datasets. Furthermore, the growing layers and parameters in both ViT and <b>convolutional</b> <b>neural</b> <b>networks</b> <b>(CNNs)</b> impede their applicability to mobile multimedia services, primarily owing to the constrained computational resources on edge devices. To mitigate the aforementioned challenges, this paper introduces a novel horizontally scalable <b>vision</b> <b>transformer</b> (HSViT). Specifically, a novel image-level feature embedding allows ViT to better leverage the inductive bias inherent in the <b>convolutional</b> <b>layers.</b> <b>Based</b> on this, an innovative horizontally scalable architecture is designed, which reduces the number of layers and parameters of the models while facilitating collaborative training and inference of ViT models across multiple nodes. The experimental results depict that, without pre-training on large-scale datasets, HSViT achieves up to 10% higher top-1 accuracy than state-of-the-art schemes, ascertaining its superior preservation of inductive bias. The code is available at https://github.com/xuchenhao001/HSViT.

{{</citation>}}


### (8/76 | 51/266) LayoutLLM: Layout Instruction Tuning with Large Language Models for Document Understanding (Chuwei Luo et al., 2024)

{{<citation>}}

Chuwei Luo, Yufan Shen, Zhaoqing Zhu, Qi Zheng, Zhi Yu, Cong Yao. (2024)  
**LayoutLLM: Layout Instruction Tuning with Large Language Models for Document Understanding**
<br/>
<button class="copy-to-clipboard" title="LayoutLLM: Layout Instruction Tuning with Large Language Models for Document Understanding" index=51>
  <span class="copy-to-clipboard-item">Copy Title<span>
</button>
<div class="toast toast-copied toast-index-51 align-items-center text-bg-secondary border-0 position-absolute top-0 end-0" role="alert" aria-live="assertive" aria-atomic="true">
  <div class="d-flex">
    <div class="toast-body">
      Copied!
    </div>
  </div>
</div>

---
Primary Category: cs.CV  
Categories: cs-CL, cs-CV, cs.CV  
Keyword Score: 59  
Keywords: Benchmarking, Fine-tuning, Multi-modal, Multi-modal, Supervised Learning, Instruction Tuning, Large Language Model, Large Language Model  
<a type="button" class="btn btn-outline-primary" href="http://arxiv.org/abs/2404.05225v1" target="_blank" >Paper Link</a>
<button type="button" class="btn btn-outline-primary download-pdf" url="https://arxiv.org/pdf/2404.05225v1.pdf" filename="2404.05225v1.pdf">Download PDF</button>

---


**ABSTRACT**  
Recently, leveraging <b>large</b> <b>language</b> <b>models</b> <b>(LLMs)</b> or <b>multimodal</b> <b>large</b> <b>language</b> <b>models</b> (MLLMs) for document understanding has been proven very promising. However, previous works that employ LLMs/MLLMs for document understanding have not fully explored and utilized the document layout information, which is vital for precise document understanding. In this paper, we propose LayoutLLM, an LLM/MLLM based method for document understanding. The core of LayoutLLM is a layout <b>instruction</b> <b>tuning</b> strategy, which is specially designed to enhance the comprehension and utilization of document layouts. The proposed layout <b>instruction</b> <b>tuning</b> strategy consists of two components: Layout-aware Pre-training and Layout-aware <b>Supervised</b> <b>Fine-tuning.</b> To capture the characteristics of document layout in Layout-aware Pre-training, three groups of pre-training tasks, corresponding to document-level, region-level and segment-level information, are introduced. Furthermore, a novel module called layout chain-of-thought (LayoutCoT) is devised to enable LayoutLLM to focus on regions relevant to the question and generate accurate answers. LayoutCoT is effective for boosting the performance of document understanding. Meanwhile, it brings a certain degree of interpretability, which could facilitate manual inspection and correction. Experiments on standard <b>benchmarks</b> show that the proposed LayoutLLM significantly outperforms existing methods that adopt open-source 7B LLMs/MLLMs for document understanding. The training data of the LayoutLLM is publicly available at https://github.com/AlibabaResearch/AdvancedLiterateMachinery/tree/main/DocumentUnderstanding/LayoutLLM

{{</citation>}}


### (9/76 | 52/266) MA-LMM: Memory-Augmented Large Multimodal Model for Long-Term Video Understanding (Bo He et al., 2024)

{{<citation>}}

Bo He, Hengduo Li, Young Kyun Jang, Menglin Jia, Xuefei Cao, Ashish Shah, Abhinav Shrivastava, Ser-Nam Lim. (2024)  
**MA-LMM: Memory-Augmented Large Multimodal Model for Long-Term Video Understanding**
<br/>
<button class="copy-to-clipboard" title="MA-LMM: Memory-Augmented Large Multimodal Model for Long-Term Video Understanding" index=52>
  <span class="copy-to-clipboard-item">Copy Title<span>
</button>
<div class="toast toast-copied toast-index-52 align-items-center text-bg-secondary border-0 position-absolute top-0 end-0" role="alert" aria-live="assertive" aria-atomic="true">
  <div class="d-flex">
    <div class="toast-body">
      Copied!
    </div>
  </div>
</div>

---
Primary Category: cs.CV  
Categories: cs-CV, cs.CV  
Keyword Score: 56  
Keywords: Foundation Model, Multi-modal, Multi-modal, Question Answering, Large Language Model, Large Language Model, Vision-and-Language  
<a type="button" class="btn btn-outline-primary" href="http://arxiv.org/abs/2404.05726v1" target="_blank" >Paper Link</a>
<button type="button" class="btn btn-outline-primary download-pdf" url="https://arxiv.org/pdf/2404.05726v1.pdf" filename="2404.05726v1.pdf">Download PDF</button>

---


**ABSTRACT**  
With the success of <b>large</b> <b>language</b> <b>models</b> <b>(LLMs),</b> integrating the vision model into <b>LLMs</b> to build <b>vision-language</b> <b>foundation</b> <b>models</b> has gained much more interest recently. However, existing <b>LLM-based</b> <b>large</b> <b>multimodal</b> <b>models</b> (e.g., Video-LLaMA, VideoChat) can only take in a limited number of frames for short video understanding. In this study, we mainly focus on designing an efficient and effective model for long-term video understanding. Instead of trying to process more frames simultaneously like most existing work, we propose to process videos in an online manner and store past video information in a memory bank. This allows our model to reference historical video content for long-term analysis without exceeding <b>LLMs'</b> context length constraints or GPU memory limits. Our memory bank can be seamlessly integrated into current <b>multimodal</b> <b>LLMs</b> in an off-the-shelf manner. We conduct extensive experiments on various video understanding tasks, such as long-video understanding, video <b>question</b> <b>answering,</b> and video captioning, and our model can achieve state-of-the-art performances across multiple datasets. Code available at https://boheumd.github.io/MA-LMM/.

{{</citation>}}


### (10/76 | 53/266) iVPT: Improving Task-relevant Information Sharing in Visual Prompt Tuning by Cross-layer Dynamic Connection (Nan Zhou et al., 2024)

{{<citation>}}

Nan Zhou, Jiaxin Chen, Di Huang. (2024)  
**iVPT: Improving Task-relevant Information Sharing in Visual Prompt Tuning by Cross-layer Dynamic Connection**
<br/>
<button class="copy-to-clipboard" title="iVPT: Improving Task-relevant Information Sharing in Visual Prompt Tuning by Cross-layer Dynamic Connection" index=53>
  <span class="copy-to-clipboard-item">Copy Title<span>
</button>
<div class="toast toast-copied toast-index-53 align-items-center text-bg-secondary border-0 position-absolute top-0 end-0" role="alert" aria-live="assertive" aria-atomic="true">
  <div class="d-flex">
    <div class="toast-body">
      Copied!
    </div>
  </div>
</div>

---
Primary Category: cs.CV  
Categories: cs-CV, cs.CV  
Keyword Score: 53  
Keywords: Vision Transformer, Augmented Reality (AR), Benchmarking, Transformer, Prompt, Vision Transformer  
<a type="button" class="btn btn-outline-primary" href="http://arxiv.org/abs/2404.05207v1" target="_blank" >Paper Link</a>
<button type="button" class="btn btn-outline-primary download-pdf" url="https://arxiv.org/pdf/2404.05207v1.pdf" filename="2404.05207v1.pdf">Download PDF</button>

---


**ABSTRACT**  
Recent progress has shown great potential of visual <b>prompt</b> tuning (VPT) when adapting pre-trained <b>vision</b> <b>transformers</b> to various downstream tasks. However, most existing solutions independently optimize <b>prompts</b> at each layer, thereby neglecting the usage of task-relevant information encoded in <b>prompt</b> tokens across layers. Additionally, existing <b>prompt</b> structures are prone to interference from task-irrelevant noise in input images, which can do harm to the sharing of task-relevant information. In this paper, we propose a novel VPT approach, \textbf{iVPT}. It innovatively incorporates a cross-layer dynamic connection (CDC) for input <b>prompt</b> tokens from adjacent layers, enabling effective sharing of task-relevant information. Furthermore, we design a dynamic aggregation (DA) module that facilitates selective sharing of information between layers. The combination of CDC and DA enhances the flexibility of the attention process within the VPT framework. Building upon these foundations, iVPT introduces an attentive reinforcement <b>(AR)</b> mechanism, by automatically identifying salient image tokens, which are further enhanced by <b>prompt</b> tokens in an additive manner. Extensive experiments on 24 image classification and semantic segmentation <b>benchmarks</b> clearly demonstrate the advantage of the proposed iVPT, compared to the state-of-the-art counterparts.

{{</citation>}}


### (11/76 | 54/266) NAF-DPM: A Nonlinear Activation-Free Diffusion Probabilistic Model for Document Enhancement (Giordano Cicchetti et al., 2024)

{{<citation>}}

Giordano Cicchetti, Danilo Comminiello. (2024)  
**NAF-DPM: A Nonlinear Activation-Free Diffusion Probabilistic Model for Document Enhancement**
<br/>
<button class="copy-to-clipboard" title="NAF-DPM: A Nonlinear Activation-Free Diffusion Probabilistic Model for Document Enhancement" index=54>
  <span class="copy-to-clipboard-item">Copy Title<span>
</button>
<div class="toast toast-copied toast-index-54 align-items-center text-bg-secondary border-0 position-absolute top-0 end-0" role="alert" aria-live="assertive" aria-atomic="true">
  <div class="d-flex">
    <div class="toast-body">
      Copied!
    </div>
  </div>
</div>

---
Primary Category: cs.CV  
Categories: cs-CV, cs.CV  
Keyword Score: 50  
Keywords: Optical Character Recognition, Optical Character Recognition, Convolution, Probabilistic Model, Recurrent Neural Network  
<a type="button" class="btn btn-outline-primary" href="http://arxiv.org/abs/2404.05669v1" target="_blank" >Paper Link</a>
<button type="button" class="btn btn-outline-primary download-pdf" url="https://arxiv.org/pdf/2404.05669v1.pdf" filename="2404.05669v1.pdf">Download PDF</button>

---


**ABSTRACT**  
Real-world documents may suffer various forms of degradation, often resulting in lower accuracy in <b>optical</b> <b>character</b> <b>recognition</b> <b>(OCR)</b> systems. Therefore, a crucial preprocessing step is essential to eliminate noise while preserving text and key features of documents. In this paper, we propose NAF-DPM, a novel generative framework based on a diffusion <b>probabilistic</b> <b>model</b> (DPM) designed to restore the original quality of degraded documents. While DPMs are recognized for their high-quality generated images, they are also known for their large inference time. To mitigate this problem we provide the DPM with an efficient nonlinear activation-free (NAF) network and we employ as a sampler a fast solver of ordinary differential equations, which can converge in a few iterations. To better preserve text characters, we introduce an additional differentiable module based on <b>convolutional</b> <b>recurrent</b> <b>neural</b> <b>networks,</b> simulating the behavior of an <b>OCR</b> system during training. Experiments conducted on various datasets showcase the superiority of our approach, achieving state-of-the-art performance in terms of pixel-level and perceptual similarity metrics. Furthermore, the results demonstrate a notable character error reduction made by <b>OCR</b> systems when transcribing real-world document images enhanced by our framework. Code and pre-trained models are available at https://github.com/ispamm/NAF-DPM.

{{</citation>}}


### (12/76 | 55/266) YaART: Yet Another ART Rendering Technology (Sergey Kastryulin et al., 2024)

{{<citation>}}

Sergey Kastryulin, Artem Konev, Alexander Shishenya, Eugene Lyapustin, Artem Khurshudov, Alexander Tselousov, Nikita Vinokurov, Denis Kuznedelev, Alexander Markovich, Grigoriy Livshits, Alexey Kirillov, Anastasiia Tabisheva, Liubov Chubarova, Marina Kaminskaia, Alexander Ustyuzhanin, Artemii Shvetsov, Daniil Shlenskii, Valerii Startsev, Dmitrii Kornilov, Mikhail Romanov, Artem Babenko, Sergei Ovcharenko, Valentin Khrulkov. (2024)  
**YaART: Yet Another ART Rendering Technology**
<br/>
<button class="copy-to-clipboard" title="YaART: Yet Another ART Rendering Technology" index=55>
  <span class="copy-to-clipboard-item">Copy Title<span>
</button>
<div class="toast toast-copied toast-index-55 align-items-center text-bg-secondary border-0 position-absolute top-0 end-0" role="alert" aria-live="assertive" aria-atomic="true">
  <div class="d-flex">
    <div class="toast-body">
      Copied!
    </div>
  </div>
</div>

---
Primary Category: cs.CV  
Categories: cs-CV, cs.CV  
Keyword Score: 50  
Keywords: Diffusion Model, Reinforcement Learning, Reinforcement Learning from Human Feedback, Reinforcement Learning from Human Feedback, Text2image  
<a type="button" class="btn btn-outline-primary" href="http://arxiv.org/abs/2404.05666v1" target="_blank" >Paper Link</a>
<button type="button" class="btn btn-outline-primary download-pdf" url="https://arxiv.org/pdf/2404.05666v1.pdf" filename="2404.05666v1.pdf">Download PDF</button>

---


**ABSTRACT**  
In the rapidly progressing field of generative models, the development of efficient and high-fidelity <b>text-to-image</b> <b>diffusion</b> <b>systems</b> represents a significant frontier. This study introduces YaART, a novel production-grade <b>text-to-image</b> cascaded <b>diffusion</b> <b>model</b> aligned to human preferences using <b>Reinforcement</b> <b>Learning</b> <b>from</b> <b>Human</b> <b>Feedback</b> <b>(RLHF).</b> During the development of YaART, we especially focus on the choices of the model and training dataset sizes, the aspects that were not systematically investigated for <b>text-to-image</b> cascaded <b>diffusion</b> <b>models</b> before. In particular, we comprehensively analyze how these choices affect both the efficiency of the training process and the quality of the generated images, which are highly important in practice. Furthermore, we demonstrate that models trained on smaller datasets of higher-quality images can successfully compete with those trained on larger datasets, establishing a more efficient scenario of <b>diffusion</b> <b>models</b> training. From the quality perspective, YaART is consistently preferred by users over many existing state-of-the-art models.

{{</citation>}}


### (13/76 | 56/266) MLP Can Be A Good Transformer Learner (Sihao Lin et al., 2024)

{{<citation>}}

Sihao Lin, Pumeng Lyu, Dongrui Liu, Tao Tang, Xiaodan Liang, Andy Song, Xiaojun Chang. (2024)  
**MLP Can Be A Good Transformer Learner**
<br/>
<button class="copy-to-clipboard" title="MLP Can Be A Good Transformer Learner" index=56>
  <span class="copy-to-clipboard-item">Copy Title<span>
</button>
<div class="toast toast-copied toast-index-56 align-items-center text-bg-secondary border-0 position-absolute top-0 end-0" role="alert" aria-live="assertive" aria-atomic="true">
  <div class="d-flex">
    <div class="toast-body">
      Copied!
    </div>
  </div>
</div>

---
Primary Category: cs.CV  
Categories: cs-CV, cs.CV  
Keyword Score: 50  
Keywords: Vision Transformer, Pruning, Transformer, Self-Attention, Vision Transformer  
<a type="button" class="btn btn-outline-primary" href="http://arxiv.org/abs/2404.05657v1" target="_blank" >Paper Link</a>
<button type="button" class="btn btn-outline-primary download-pdf" url="https://arxiv.org/pdf/2404.05657v1.pdf" filename="2404.05657v1.pdf">Download PDF</button>

---


**ABSTRACT**  
<b>Self-attention</b> mechanism is the key of the <b>Transformer</b> but often criticized for its computation demands. Previous token <b>pruning</b> works motivate their methods from the view of computation redundancy but still need to load the full network and require same memory costs. This paper introduces a novel strategy that simplifies <b>vision</b> <b>transformers</b> and reduces computational load through the selective removal of non-essential attention layers, guided by entropy considerations. We identify that regarding the attention layer in bottom blocks, their subsequent MLP layers, i.e. two feed-forward layers, can elicit the same entropy quantity. Meanwhile, the accompanied MLPs are under-exploited since they exhibit smaller feature entropy compared to those MLPs in the top blocks. Therefore, we propose to integrate the uninformative attention layers into their subsequent counterparts by degenerating them into identical mapping, yielding only MLP in certain <b>transformer</b> blocks. Experimental results on ImageNet-1k show that the proposed method can remove 40% attention layer of DeiT-B, improving throughput and memory bound without performance compromise. Code is available at https://github.com/sihaoevery/lambda_vit.

{{</citation>}}


### (14/76 | 57/266) Multi-head Attention-based Deep Multiple Instance Learning (Hassan Keshvarikhojasteh et al., 2024)

{{<citation>}}

Hassan Keshvarikhojasteh, Josien Pluim, Mitko Veta. (2024)  
**Multi-head Attention-based Deep Multiple Instance Learning**
<br/>
<button class="copy-to-clipboard" title="Multi-head Attention-based Deep Multiple Instance Learning" index=57>
  <span class="copy-to-clipboard-item">Copy Title<span>
</button>
<div class="toast toast-copied toast-index-57 align-items-center text-bg-secondary border-0 position-absolute top-0 end-0" role="alert" aria-live="assertive" aria-atomic="true">
  <div class="d-flex">
    <div class="toast-body">
      Copied!
    </div>
  </div>
</div>

---
Primary Category: cs.CV  
Categories: cs-CV, cs.CV  
Keyword Score: 50  
Keywords: MNIST, Multiple Instance Learning, Supervised Learning, Weakly-supervised Learning, Transformer  
<a type="button" class="btn btn-outline-primary" href="http://arxiv.org/abs/2404.05362v1" target="_blank" >Paper Link</a>
<button type="button" class="btn btn-outline-primary download-pdf" url="https://arxiv.org/pdf/2404.05362v1.pdf" filename="2404.05362v1.pdf">Download PDF</button>

---


**ABSTRACT**  
This paper introduces MAD-MIL, a Multi-head Attention-based Deep <b>Multiple</b> <b>Instance</b> <b>Learning</b> model, designed for weakly <b>supervised</b> Whole Slide Images (WSIs) classification in digital pathology. Inspired by the multi-head attention mechanism of the <b>Transformer,</b> MAD-MIL simplifies model complexity while achieving competitive results against advanced models like CLAM and DS-MIL. Evaluated on the <b>MNIST-BAGS</b> and public datasets, including TUPAC16, TCGA BRCA, TCGA LUNG, and TCGA KIDNEY, MAD-MIL consistently outperforms ABMIL. This demonstrates enhanced information diversity, interpretability, and efficiency in slide representation. The model's effectiveness, coupled with fewer trainable parameters and lower computational complexity makes it a promising solution for automated pathology workflows. Our code is available at https://github.com/tueimage/MAD-MIL.

{{</citation>}}


### (15/76 | 58/266) PromptAD: Learning Prompts with only Normal Samples for Few-Shot Anomaly Detection (Xiaofan Li et al., 2024)

{{<citation>}}

Xiaofan Li, Zhizhong Zhang, Xin Tan, Chengwei Chen, Yanyun Qu, Yuan Xie, Lizhuang Ma. (2024)  
**PromptAD: Learning Prompts with only Normal Samples for Few-Shot Anomaly Detection**
<br/>
<button class="copy-to-clipboard" title="PromptAD: Learning Prompts with only Normal Samples for Few-Shot Anomaly Detection" index=58>
  <span class="copy-to-clipboard-item">Copy Title<span>
</button>
<div class="toast toast-copied toast-index-58 align-items-center text-bg-secondary border-0 position-absolute top-0 end-0" role="alert" aria-live="assertive" aria-atomic="true">
  <div class="d-flex">
    <div class="toast-body">
      Copied!
    </div>
  </div>
</div>

---
Primary Category: cs.CV  
Categories: cs-CV, cs.CV  
Keyword Score: 50  
Keywords: Anomaly Detection, Few-shot, Prompt, Prompt Learning, Vision-and-Language  
<a type="button" class="btn btn-outline-primary" href="http://arxiv.org/abs/2404.05231v1" target="_blank" >Paper Link</a>
<button type="button" class="btn btn-outline-primary download-pdf" url="https://arxiv.org/pdf/2404.05231v1.pdf" filename="2404.05231v1.pdf">Download PDF</button>

---


**ABSTRACT**  
The <b>vision-language</b> model has brought great improvement to <b>few-shot</b> industrial <b>anomaly</b> <b>detection,</b> which usually needs to design of hundreds of <b>prompts</b> <b>through</b> <b>prompt</b> <b>engineering.</b> For automated scenarios, we first use conventional <b>prompt</b> <b>learning</b> with many-class paradigm as the baseline to automatically learn <b>prompts</b> <b>but</b> found that it can not work well in one-class <b>anomaly</b> <b>detection.</b> To address the above problem, this paper proposes a one-class <b>prompt</b> <b>learning</b> method for <b>few-shot</b> <b>anomaly</b> <b>detection,</b> termed PromptAD. First, we propose semantic concatenation which can transpose normal <b>prompts</b> <b>into</b> <b>anomaly</b> <b>prompts</b> <b>by</b> concatenating normal <b>prompts</b> <b>with</b> <b>anomaly</b> <b>suffixes,</b> thus constructing a large number of negative samples used to guide <b>prompt</b> <b>learning</b> in one-class setting. Furthermore, to mitigate the training challenge caused by the absence of <b>anomaly</b> <b>images,</b> we introduce the concept of explicit <b>anomaly</b> <b>margin,</b> which is used to explicitly control the margin between normal <b>prompt</b> <b>features</b> and <b>anomaly</b> <b>prompt</b> <b>features</b> through a hyper-parameter. For image-level/pixel-level <b>anomaly</b> <b>detection,</b> PromptAD achieves first place in 11/12 <b>few-shot</b> settings on MVTec and VisA.

{{</citation>}}


### (16/76 | 59/266) MULTIFLOW: Shifting Towards Task-Agnostic Vision-Language Pruning (Matteo Farina et al., 2024)

{{<citation>}}

Matteo Farina, Massimiliano Mancini, Elia Cunegatti, Gaowen Liu, Giovanni Iacca, Elisa Ricci. (2024)  
**MULTIFLOW: Shifting Towards Task-Agnostic Vision-Language Pruning**
<br/>
<button class="copy-to-clipboard" title="MULTIFLOW: Shifting Towards Task-Agnostic Vision-Language Pruning" index=59>
  <span class="copy-to-clipboard-item">Copy Title<span>
</button>
<div class="toast toast-copied toast-index-59 align-items-center text-bg-secondary border-0 position-absolute top-0 end-0" role="alert" aria-live="assertive" aria-atomic="true">
  <div class="d-flex">
    <div class="toast-body">
      Copied!
    </div>
  </div>
</div>

---
Primary Category: cs.CV  
Categories: cs-CV, cs.CV  
Keyword Score: 49  
Keywords: Benchmarking, Model Pruning, Multi-modal, Multi-modal, Pruning, Transfer Learning, Vision-and-Language  
<a type="button" class="btn btn-outline-primary" href="http://arxiv.org/abs/2404.05621v1" target="_blank" >Paper Link</a>
<button type="button" class="btn btn-outline-primary download-pdf" url="https://arxiv.org/pdf/2404.05621v1.pdf" filename="2404.05621v1.pdf">Download PDF</button>

---


**ABSTRACT**  
While excellent in <b>transfer</b> <b>learning,</b> <b>Vision-Language</b> <b>models</b> <b>(VLMs)</b> come with high computational costs due to their large number of parameters. To address this issue, removing parameters via <b>model</b> <b>pruning</b> is a viable solution. However, existing techniques for VLMs are task-specific, and thus require <b>pruning</b> the network from scratch for each new task of interest. In this work, we explore a new direction: Task-Agnostic <b>Vision-Language</b> <b>Pruning</b> (TA-VLP). Given a pretrained VLM, the goal is to find a unique pruned counterpart transferable to multiple unknown downstream tasks. In this challenging setting, the transferable representations already encoded in the pretrained <b>model</b> <b>are</b> a key aspect to preserve. Thus, we propose <b>Multimodal</b> Flow <b>Pruning</b> (MULTIFLOW), a first, gradient-free, <b>pruning</b> framework for TA-VLP where: (i) the importance of a parameter is expressed in terms of its magnitude and its information flow, by incorporating the saliency of the neurons it connects; and (ii) <b>pruning</b> is driven by the emergent <b>(multimodal)</b> distribution of the VLM parameters after pretraining. We <b>benchmark</b> eight state-of-the-art <b>pruning</b> algorithms in the context of TA-VLP, experimenting with two VLMs, three <b>vision-language</b> tasks, and three <b>pruning</b> ratios. Our experimental results show that MULTIFLOW outperforms recent sophisticated, combinatorial competitors in the vast majority of the cases, paving the way towards addressing TA-VLP. The code is publicly available at https://github.com/FarinaMatteo/multiflow.

{{</citation>}}


### (17/76 | 60/266) Retrieval-Augmented Open-Vocabulary Object Detection (Jooyeon Kim et al., 2024)

{{<citation>}}

Jooyeon Kim, Eulrang Cho, Sehyung Kim, Hyunwoo J. Kim. (2024)  
**Retrieval-Augmented Open-Vocabulary Object Detection**
<br/>
<button class="copy-to-clipboard" title="Retrieval-Augmented Open-Vocabulary Object Detection" index=60>
  <span class="copy-to-clipboard-item">Copy Title<span>
</button>
<div class="toast toast-copied toast-index-60 align-items-center text-bg-secondary border-0 position-absolute top-0 end-0" role="alert" aria-live="assertive" aria-atomic="true">
  <div class="d-flex">
    <div class="toast-body">
      Copied!
    </div>
  </div>
</div>

---
Primary Category: cs.CV  
Categories: cs-CV, cs.CV  
Keyword Score: 43  
Keywords: Object Detection, Benchmarking, Large Language Model, Large Language Model, Vision-and-Language  
<a type="button" class="btn btn-outline-primary" href="http://arxiv.org/abs/2404.05687v1" target="_blank" >Paper Link</a>
<button type="button" class="btn btn-outline-primary download-pdf" url="https://arxiv.org/pdf/2404.05687v1.pdf" filename="2404.05687v1.pdf">Download PDF</button>

---


**ABSTRACT**  
Open-vocabulary <b>object</b> <b>detection</b> (OVD) has been studied with <b>Vision-Language</b> Models (VLMs) to detect novel <b>objects</b> <b>beyond</b> the pre-trained categories. Previous approaches improve the generalization ability to expand the knowledge of the detector, using 'positive' pseudo-labels with additional 'class' names, e.g., sock, iPod, and alligator. To extend the previous methods in two aspects, we propose Retrieval-Augmented Losses and visual Features (RALF). Our method retrieves related 'negative' classes and augments loss functions. Also, visual features are augmented with 'verbalized concepts' of classes, e.g., worn on the feet, handheld music player, and sharp teeth. Specifically, RALF consists of two modules: Retrieval Augmented Losses (RAL) and Retrieval-Augmented visual Features (RAF). RAL constitutes two losses reflecting the semantic similarity with negative vocabularies. In addition, RAF augments visual features with the verbalized concepts from a <b>large</b> <b>language</b> <b>model</b> <b>(LLM).</b> Our experiments demonstrate the effectiveness of RALF on COCO and LVIS <b>benchmark</b> datasets. We achieve improvement up to 3.4 box AP$_{50}^{\text{N}}$ on novel categories of the COCO dataset and 3.6 mask AP$_{\text{r}}$ gains on the LVIS dataset. Code is available at https://github.com/mlvlab/RALF .

{{</citation>}}


### (18/76 | 61/266) TabConv: Low-Computation CNN Inference via Table Lookups (Neelesh Gupta et al., 2024)

{{<citation>}}

Neelesh Gupta, Narayanan Kannan, Pengmiao Zhang, Viktor Prasanna. (2024)  
**TabConv: Low-Computation CNN Inference via Table Lookups**
<br/>
<button class="copy-to-clipboard" title="TabConv: Low-Computation CNN Inference via Table Lookups" index=61>
  <span class="copy-to-clipboard-item">Copy Title<span>
</button>
<div class="toast toast-copied toast-index-61 align-items-center text-bg-secondary border-0 position-absolute top-0 end-0" role="alert" aria-live="assertive" aria-atomic="true">
  <div class="d-flex">
    <div class="toast-body">
      Copied!
    </div>
  </div>
</div>

---
Primary Category: cs.CV  
Categories: I-5-1, cs-CV, cs-LG, cs-NE, cs.CV  
Keyword Score: 40  
Keywords: MNIST, Convolution, Convolutional Neural Network, Convolutional Neural Network  
<a type="button" class="btn btn-outline-primary" href="http://arxiv.org/abs/2404.05872v1" target="_blank" >Paper Link</a>
<button type="button" class="btn btn-outline-primary download-pdf" url="https://arxiv.org/pdf/2404.05872v1.pdf" filename="2404.05872v1.pdf">Download PDF</button>

---


**ABSTRACT**  
<b>Convolutional</b> <b>Neural</b> <b>Networks</b> <b>(CNNs)</b> have demonstrated remarkable ability throughout the field of computer vision. However, <b>CNN</b> inference requires a large number of arithmetic operations, making them expensive to deploy in hardware. Current approaches alleviate this issue by developing hardware-supported, algorithmic processes to simplify spatial <b>convolution</b> functions. However, these methods still heavily rely on matrix multiplication, leading to significant computational overhead. To bridge the gap between hardware, algorithmic acceleration, and approximate matrix multiplication, we propose TabConv, a novel, table-based approximation for <b>convolution</b> to significantly reduce arithmetic operations during inference. Additionally, we introduce a priority masking technique based on cosine similarity to select layers for table-based approximation, thereby maintaining the model performance. We evaluate our approach on popular <b>CNNs:</b> ResNet-18, ResNet-34, and NetworkInNetwork (NIN). TabConv preserves over 93% of the original model's performance while reducing arithmetic operations by 36.5%, 25.8%, and 99.4% for ResNet-18 on CIFAR-10, CIFAR-100, and <b>MNIST,</b> respectively, 35.6% and 99.3% for ResNet-34 on CIFAR-10 and <b>MNIST,</b> and 98.9% for NIN on <b>MNIST,</b> achieving low-computation inference.

{{</citation>}}


### (19/76 | 62/266) CNN-based Game State Detection for a Foosball Table (David Hagens et al., 2024)

{{<citation>}}

David Hagens, Jan Knaup, Elke Hergenröther, Andreas Weinmann. (2024)  
**CNN-based Game State Detection for a Foosball Table**
<br/>
<button class="copy-to-clipboard" title="CNN-based Game State Detection for a Foosball Table" index=62>
  <span class="copy-to-clipboard-item">Copy Title<span>
</button>
<div class="toast toast-copied toast-index-62 align-items-center text-bg-secondary border-0 position-absolute top-0 end-0" role="alert" aria-live="assertive" aria-atomic="true">
  <div class="d-flex">
    <div class="toast-body">
      Copied!
    </div>
  </div>
</div>

---
Primary Category: cs.CV  
Categories: cs-CV, cs.CV  
Keyword Score: 40  
Keywords: Convolution, Convolutional Neural Network, Convolutional Neural Network, Reinforcement Learning  
<a type="button" class="btn btn-outline-primary" href="http://arxiv.org/abs/2404.05357v1" target="_blank" >Paper Link</a>
<button type="button" class="btn btn-outline-primary download-pdf" url="https://arxiv.org/pdf/2404.05357v1.pdf" filename="2404.05357v1.pdf">Download PDF</button>

---


**ABSTRACT**  
The automation of games using Deep <b>Reinforcement</b> <b>Learning</b> Strategies (DRL) is a well-known challenge in AI research. While for feature extraction in a video game typically the whole image is used, this is hardly practical for many real world games. Instead, using a smaller game state reducing the dimension of the parameter space to include essential parameters only seems to be a promising approach. In the game of Foosball, a compact and comprehensive game state description consists of the positional shifts and rotations of the figures and the position of the ball over time. In particular, velocities and accelerations can be derived from consecutive time samples of the game state. In this paper, a figure detection system to determine the game state in Foosball is presented. We capture a dataset containing the rotations of the rods which were measured using accelerometers and the positional shifts were derived using traditional Computer Vision techniques (in a laboratory setting). This dataset is utilized to train <b>Convolutional</b> <b>Neural</b> <b>Network</b> <b>(CNN)</b> based end-to-end regression models to predict the rotations and shifts of each rod. We present an evaluation of our system using different state-of-the-art <b>CNNs</b> as base architectures for the regression model. We show that our system is able to predict the game state with high accuracy. By providing data for both black and white teams, the presented system is intended to provide the required data for future developments of Imitation Learning techniques w.r.t. to observing human players.

{{</citation>}}


### (20/76 | 63/266) Detecting Every Object from Events (Haitian Zhang et al., 2024)

{{<citation>}}

Haitian Zhang, Chang Xu, Xinya Wang, Bingde Liu, Guang Hua, Lei Yu, Wen Yang. (2024)  
**Detecting Every Object from Events**
<br/>
<button class="copy-to-clipboard" title="Detecting Every Object from Events" index=63>
  <span class="copy-to-clipboard-item">Copy Title<span>
</button>
<div class="toast toast-copied toast-index-63 align-items-center text-bg-secondary border-0 position-absolute top-0 end-0" role="alert" aria-live="assertive" aria-atomic="true">
  <div class="d-flex">
    <div class="toast-body">
      Copied!
    </div>
  </div>
</div>

---
Primary Category: cs.CV  
Categories: cs-CV, cs.CV  
Keyword Score: 40  
Keywords: Vision Transformer, Object Detection, Transformer, Vision Transformer  
<a type="button" class="btn btn-outline-primary" href="http://arxiv.org/abs/2404.05285v1" target="_blank" >Paper Link</a>
<button type="button" class="btn btn-outline-primary download-pdf" url="https://arxiv.org/pdf/2404.05285v1.pdf" filename="2404.05285v1.pdf">Download PDF</button>

---


**ABSTRACT**  
<b>Object</b> <b>detection</b> is critical in autonomous driving, and it is more practical yet challenging to localize <b>objects</b> <b>of</b> unknown categories: an endeavour known as Class-Agnostic <b>Object</b> <b>Detection</b> (CAOD). Existing studies on CAOD predominantly rely on ordinary cameras, but these frame-based sensors usually have high latency and limited dynamic range, leading to safety risks in real-world scenarios. In this study, we turn to a new modality enabled by the so-called event camera, featured by its sub-millisecond latency and high dynamic range, for robust CAOD. We propose Detecting Every <b>Object</b> <b>in</b> Events (DEOE), an approach tailored for achieving high-speed, class-agnostic open-world <b>object</b> <b>detection</b> in event-based <b>vision.</b> <b>Built</b> upon the fast event-based backbone: recurrent <b>vision</b> <b>transformer,</b> we jointly consider the spatial and temporal consistencies to identify potential <b>objects.</b> <b>The</b> discovered potential <b>objects</b> <b>are</b> assimilated as soft positive samples to avoid being suppressed as background. Moreover, we introduce a disentangled objectness head to separate the foreground-background classification and novel <b>object</b> <b>discovery</b> tasks, enhancing the model's generalization in localizing novel <b>objects</b> <b>while</b> maintaining a strong ability to filter out the background. Extensive experiments confirm the superiority of our proposed DEOE in comparison with three strong baseline methods that integrate the state-of-the-art event-based <b>object</b> <b>detector</b> with advancements in RGB-based CAOD. Our code is available at https://github.com/Hatins/DEOE.

{{</citation>}}


### (21/76 | 64/266) Multi-level Graph Subspace Contrastive Learning for Hyperspectral Image Clustering (Jingxin Wang et al., 2024)

{{<citation>}}

Jingxin Wang, Renxiang Guan, Kainan Gao, Zihao Li, Hao Li, Xianju Li, Chang Tang. (2024)  
**Multi-level Graph Subspace Contrastive Learning for Hyperspectral Image Clustering**
<br/>
<button class="copy-to-clipboard" title="Multi-level Graph Subspace Contrastive Learning for Hyperspectral Image Clustering" index=64>
  <span class="copy-to-clipboard-item">Copy Title<span>
</button>
<div class="toast toast-copied toast-index-64 align-items-center text-bg-secondary border-0 position-absolute top-0 end-0" role="alert" aria-live="assertive" aria-atomic="true">
  <div class="d-flex">
    <div class="toast-body">
      Copied!
    </div>
  </div>
</div>

---
Primary Category: cs.CV  
Categories: cs-CV, cs.CV  
Keyword Score: 36  
Keywords: Graph, Graph Embedding, Clustering, Contrastive Learning, Convolution  
<a type="button" class="btn btn-outline-primary" href="http://arxiv.org/abs/2404.05211v1" target="_blank" >Paper Link</a>
<button type="button" class="btn btn-outline-primary download-pdf" url="https://arxiv.org/pdf/2404.05211v1.pdf" filename="2404.05211v1.pdf">Download PDF</button>

---


**ABSTRACT**  
Hyperspectral image (HSI) <b>clustering</b> is a challenging task due to its high complexity. Despite subspace <b>clustering</b> shows impressive performance for HSI, traditional methods tend to ignore the global-local interaction in HSI data. In this study, we proposed a multi-level <b>graph</b> <b>subspace</b> <b>contrastive</b> <b>learning</b> (MLGSC) for HSI <b>clustering.</b> The model is divided into the following main parts. <b>Graph</b> <b>convolution</b> subspace construction: utilizing spectral and texture feautures to construct two <b>graph</b> <b>convolution</b> views. Local-global <b>graph</b> <b>representation:</b> local <b>graph</b> <b>representations</b> were obtained by step-by-step <b>convolutions</b> and a more representative global <b>graph</b> <b>representation</b> was obtained using an attention-based pooling strategy. Multi-level <b>graph</b> <b>subspace</b> <b>contrastive</b> <b>learning:</b> multi-level <b>contrastive</b> <b>learning</b> was conducted to obtain local-global joint <b>graph</b> <b>representations,</b> to improve the consistency of the positive samples between views, and to obtain more robust <b>graph</b> <b>embeddings.</b> Specifically, <b>graph-level</b> <b>contrastive</b> <b>learning</b> is used to better learn global representations of HSI data. Node-level intra-view and inter-view <b>contrastive</b> <b>learning</b> is designed to learn joint representations of local regions of HSI. The proposed model is evaluated on four popular HSI datasets: Indian Pines, Pavia University, Houston, and Xu Zhou. The overall accuracies are 97.75%, 99.96%, 92.28%, and 95.73%, which significantly outperforms the current state-of-the-art <b>clustering</b> methods.

{{</citation>}}


### (22/76 | 65/266) Social-MAE: Social Masked Autoencoder for Multi-person Motion Representation Learning (Mahsa Ehsanpour et al., 2024)

{{<citation>}}

Mahsa Ehsanpour, Ian Reid, Hamid Rezatofighi. (2024)  
**Social-MAE: Social Masked Autoencoder for Multi-person Motion Representation Learning**
<br/>
<button class="copy-to-clipboard" title="Social-MAE: Social Masked Autoencoder for Multi-person Motion Representation Learning" index=65>
  <span class="copy-to-clipboard-item">Copy Title<span>
</button>
<div class="toast toast-copied toast-index-65 align-items-center text-bg-secondary border-0 position-absolute top-0 end-0" role="alert" aria-live="assertive" aria-atomic="true">
  <div class="d-flex">
    <div class="toast-body">
      Copied!
    </div>
  </div>
</div>

---
Primary Category: cs.CV  
Categories: cs-CV, cs.CV  
Keyword Score: 35  
Keywords: Autoencoder, Fine-tuning, Representation Learning, Transformer  
<a type="button" class="btn btn-outline-primary" href="http://arxiv.org/abs/2404.05578v1" target="_blank" >Paper Link</a>
<button type="button" class="btn btn-outline-primary download-pdf" url="https://arxiv.org/pdf/2404.05578v1.pdf" filename="2404.05578v1.pdf">Download PDF</button>

---


**ABSTRACT**  
For a complete comprehension of multi-person scenes, it is essential to go beyond basic tasks like detection and tracking. Higher-level tasks, such as understanding the interactions and social activities among individuals, are also crucial. Progress towards models that can fully understand scenes involving multiple people is hindered by a lack of sufficient annotated data for such high-level tasks. To address this challenge, we introduce Social-MAE, a simple yet effective <b>transformer-based</b> masked <b>autoencoder</b> framework for multi-person human motion data. The framework uses masked modeling to pre-train the encoder to reconstruct masked human joint trajectories, enabling it to learn generalizable and data efficient <b>representations</b> <b>of</b> motion in human crowded scenes. Social-MAE comprises a <b>transformer</b> as the MAE encoder and a lighter-weight <b>transformer</b> as the MAE decoder which operates on multi-person joints' trajectory in the frequency domain. After the reconstruction task, the MAE decoder is replaced with a task-specific decoder and the model is <b>fine-tuned</b> end-to-end for a variety of high-level social tasks. Our proposed model combined with our pre-training approach achieves the state-of-the-art results on various high-level social tasks, including multi-person pose forecasting, social grouping, and social action understanding. These improvements are demonstrated across four popular multi-person datasets encompassing both human 2D and 3D body pose.

{{</citation>}}


### (23/76 | 66/266) CoReS: Orchestrating the Dance of Reasoning and Segmentation (Xiaoyi Bao et al., 2024)

{{<citation>}}

Xiaoyi Bao, Siyang Sun, Shuailei Ma, Kecheng Zheng, Yuxin Guo, Guosheng Zhao, Yun Zheng, Xingang Wang. (2024)  
**CoReS: Orchestrating the Dance of Reasoning and Segmentation**
<br/>
<button class="copy-to-clipboard" title="CoReS: Orchestrating the Dance of Reasoning and Segmentation" index=66>
  <span class="copy-to-clipboard-item">Copy Title<span>
</button>
<div class="toast toast-copied toast-index-66 align-items-center text-bg-secondary border-0 position-absolute top-0 end-0" role="alert" aria-live="assertive" aria-atomic="true">
  <div class="d-flex">
    <div class="toast-body">
      Copied!
    </div>
  </div>
</div>

---
Primary Category: cs.CV  
Categories: cs-CV, cs.CV  
Keyword Score: 33  
Keywords: Multi-modal, Reasoning, In-context Learning, Large Language Model  
<a type="button" class="btn btn-outline-primary" href="http://arxiv.org/abs/2404.05673v1" target="_blank" >Paper Link</a>
<button type="button" class="btn btn-outline-primary download-pdf" url="https://arxiv.org/pdf/2404.05673v1.pdf" filename="2404.05673v1.pdf">Download PDF</button>

---


**ABSTRACT**  
The <b>reasoning</b> segmentation task, which demands a nuanced comprehension of intricate queries to accurately pinpoint object regions, is attracting increasing attention. However, <b>Multi-modal</b> <b>Large</b> <b>Language</b> <b>Models</b> (MLLM) often find it difficult to accurately localize the objects described in complex <b>reasoning</b> contexts. We believe that the act of <b>reasoning</b> segmentation should mirror the cognitive stages of human visual search, where each step is a progressive refinement of thought toward the final object. Thus we introduce the Chains of <b>Reasoning</b> and Segmenting (CoReS) and find this top-down visual hierarchy indeed enhances the visual search process. Specifically, we propose a dual-chain structure that generates <b>multi-modal,</b> chain-like outputs to aid the segmentation process. Furthermore, to steer the MLLM's outputs into this intended hierarchy, we incorporate <b>in-context</b> inputs as guidance. Extensive experiments demonstrate the superior performance of our CoReS, which surpasses the state-of-the-art method by 7.1\% on the ReasonSeg dataset. The code will be released at https://github.com/baoxiaoyi/CoReS.

{{</citation>}}


### (24/76 | 67/266) Mask-ControlNet: Higher-Quality Image Generation with An Additional Mask Prompt (Zhiqi Huang et al., 2024)

{{<citation>}}

Zhiqi Huang, Huixin Xiong, Haoyu Wang, Longguang Wang, Zhiheng Li. (2024)  
**Mask-ControlNet: Higher-Quality Image Generation with An Additional Mask Prompt**
<br/>
<button class="copy-to-clipboard" title="Mask-ControlNet: Higher-Quality Image Generation with An Additional Mask Prompt" index=67>
  <span class="copy-to-clipboard-item">Copy Title<span>
</button>
<div class="toast toast-copied toast-index-67 align-items-center text-bg-secondary border-0 position-absolute top-0 end-0" role="alert" aria-live="assertive" aria-atomic="true">
  <div class="d-flex">
    <div class="toast-body">
      Copied!
    </div>
  </div>
</div>

---
Primary Category: cs.CV  
Categories: cs-CV, cs.CV  
Keyword Score: 33  
Keywords: Diffusion Model, Benchmarking, Text2image, Prompt  
<a type="button" class="btn btn-outline-primary" href="http://arxiv.org/abs/2404.05331v1" target="_blank" >Paper Link</a>
<button type="button" class="btn btn-outline-primary download-pdf" url="https://arxiv.org/pdf/2404.05331v1.pdf" filename="2404.05331v1.pdf">Download PDF</button>

---


**ABSTRACT**  
<b>Text-to-image</b> generation has witnessed great progress, especially with the recent advancements in <b>diffusion</b> <b>models.</b> Since texts cannot provide detailed conditions like object appearance, reference images are usually leveraged for the control of objects in the generated images. However, existing methods still suffer limited accuracy when the relationship between the foreground and background is complicated. To address this issue, we develop a framework termed Mask-ControlNet by introducing an additional mask <b>prompt.</b> Specifically, we first employ large vision models to obtain masks to segment the objects of interest in the reference image. Then, the object images are employed as additional <b>prompts</b> to facilitate the <b>diffusion</b> <b>model</b> to better understand the relationship between foreground and background regions during image generation. Experiments show that the mask <b>prompts</b> enhance the controllability of the <b>diffusion</b> <b>model</b> to maintain higher fidelity to the reference image while achieving better image quality. Comparison with previous <b>text-to-image</b> generation methods demonstrates our method's superior quantitative and qualitative performance on the <b>benchmark</b> datasets.

{{</citation>}}


### (25/76 | 68/266) Towards Improved Semiconductor Defect Inspection for high-NA EUVL based on SEMI-SuperYOLO-NAS (Ying-Lin Chen et al., 2024)

{{<citation>}}

Ying-Lin Chen, Jacob Deforce, Vic De Ridder, Bappaditya Dey, Victor Blanco, Sandip Halder, Philippe Leray. (2024)  
**Towards Improved Semiconductor Defect Inspection for high-NA EUVL based on SEMI-SuperYOLO-NAS**
<br/>
<button class="copy-to-clipboard" title="Towards Improved Semiconductor Defect Inspection for high-NA EUVL based on SEMI-SuperYOLO-NAS" index=68>
  <span class="copy-to-clipboard-item">Copy Title<span>
</button>
<div class="toast toast-copied toast-index-68 align-items-center text-bg-secondary border-0 position-absolute top-0 end-0" role="alert" aria-live="assertive" aria-atomic="true">
  <div class="d-flex">
    <div class="toast-body">
      Copied!
    </div>
  </div>
</div>

---
Primary Category: cs.CV  
Categories: cs-CV, cs.CV  
Keyword Score: 30  
Keywords: Yolo, Data Augmentation, Zero-shot  
<a type="button" class="btn btn-outline-primary" href="http://arxiv.org/abs/2404.05862v1" target="_blank" >Paper Link</a>
<button type="button" class="btn btn-outline-primary download-pdf" url="https://arxiv.org/pdf/2404.05862v1.pdf" filename="2404.05862v1.pdf">Download PDF</button>

---


**ABSTRACT**  
Due to potential pitch reduction, the semiconductor industry is adopting High-NA EUVL technology. However, its low depth of focus presents challenges for High Volume Manufacturing. To address this, suppliers are exploring thinner photoresists and new underlayers/hardmasks. These may suffer from poor SNR, complicating defect detection. Vision-based ML algorithms offer a promising solution for semiconductor defect inspection. However, developing a robust ML model across various image resolutions without explicit training remains a challenge for nano-scale defect inspection. This research's goal is to propose a scale-invariant ADCD framework capable to upscale images, addressing this issue. We propose an improvised ADCD framework as SEMI-SuperYOLO-NAS, which builds upon the baseline <b>YOLO-NAS</b> architecture. This framework integrates a SR assisted branch to aid in learning HR features by the defect detection backbone, particularly for detecting nano-scale defect instances from LR images. Additionally, the SR-assisted branch can recursively generate upscaled images from their corresponding downscaled counterparts, enabling defect detection inference across various image resolutions without requiring explicit training. Moreover, we investigate improved <b>data</b> <b>augmentation</b> strategy aimed at generating diverse and realistic training datasets to enhance model performance. We have evaluated our proposed approach using two original FAB datasets obtained from two distinct processes and captured using two different imaging tools. Finally, we demonstrate <b>zero-shot</b> inference for our model on a new, originating from a process condition distinct from the training dataset and possessing different Pitch characteristics. Experimental validation demonstrates that our proposed ADCD framework aids in increasing the throughput of imaging tools for defect inspection by reducing the required image pixel resolutions.

{{</citation>}}


### (26/76 | 69/266) Self-Explainable Affordance Learning with Embodied Caption (Zhipeng Zhang et al., 2024)

{{<citation>}}

Zhipeng Zhang, Zhimin Wei, Guolei Sun, Peng Wang, Luc Van Gool. (2024)  
**Self-Explainable Affordance Learning with Embodied Caption**
<br/>
<button class="copy-to-clipboard" title="Self-Explainable Affordance Learning with Embodied Caption" index=69>
  <span class="copy-to-clipboard-item">Copy Title<span>
</button>
<div class="toast toast-copied toast-index-69 align-items-center text-bg-secondary border-0 position-absolute top-0 end-0" role="alert" aria-live="assertive" aria-atomic="true">
  <div class="d-flex">
    <div class="toast-body">
      Copied!
    </div>
  </div>
</div>

---
Primary Category: cs.CV  
Categories: cs-AI, cs-CV, cs.CV  
Keyword Score: 30  
Keywords: Human Intervention, Grounding, Vision-and-Language  
<a type="button" class="btn btn-outline-primary" href="http://arxiv.org/abs/2404.05603v1" target="_blank" >Paper Link</a>
<button type="button" class="btn btn-outline-primary download-pdf" url="https://arxiv.org/pdf/2404.05603v1.pdf" filename="2404.05603v1.pdf">Download PDF</button>

---


**ABSTRACT**  
In the field of visual affordance learning, previous methods mainly used abundant images or videos that delineate <b>human</b> <b>behavior</b> patterns to identify action possibility regions for object manipulation, with a variety of applications in robotic tasks. However, they encounter a main challenge of action ambiguity, illustrated by the vagueness like whether to beat or carry a drum, and the complexities involved in processing intricate scenes. Moreover, it is important for <b>human</b> <b>intervention</b> to rectify robot errors in time. To address these issues, we introduce Self-Explainable Affordance learning (SEA) with embodied caption. This innovation enables robots to articulate their intentions and bridge the gap between explainable <b>vision-language</b> caption and visual affordance learning. Due to a lack of appropriate dataset, we unveil a pioneering dataset and metrics tailored for this task, which integrates images, heatmaps, and embodied captions. Furthermore, we propose a novel model to effectively combine affordance <b>grounding</b> with self-explanation in a simple but efficient manner. Extensive quantitative and qualitative experiments demonstrate our method's effectiveness.

{{</citation>}}


### (27/76 | 70/266) Towards More General Video-based Deepfake Detection through Facial Feature Guided Adaptation for Foundation Model (Yue-Hua Han et al., 2024)

{{<citation>}}

Yue-Hua Han, Tai-Ming Huang, Shu-Tzu Lo, Po-Han Huang, Kai-Lung Hua, Jun-Cheng Chen. (2024)  
**Towards More General Video-based Deepfake Detection through Facial Feature Guided Adaptation for Foundation Model**
<br/>
<button class="copy-to-clipboard" title="Towards More General Video-based Deepfake Detection through Facial Feature Guided Adaptation for Foundation Model" index=70>
  <span class="copy-to-clipboard-item">Copy Title<span>
</button>
<div class="toast toast-copied toast-index-70 align-items-center text-bg-secondary border-0 position-absolute top-0 end-0" role="alert" aria-live="assertive" aria-atomic="true">
  <div class="d-flex">
    <div class="toast-body">
      Copied!
    </div>
  </div>
</div>

---
Primary Category: cs.CV  
Categories: cs-CV, cs.CV  
Keyword Score: 30  
Keywords: Fine-tuning, Foundation Model, Zero-shot  
<a type="button" class="btn btn-outline-primary" href="http://arxiv.org/abs/2404.05583v1" target="_blank" >Paper Link</a>
<button type="button" class="btn btn-outline-primary download-pdf" url="https://arxiv.org/pdf/2404.05583v1.pdf" filename="2404.05583v1.pdf">Download PDF</button>

---


**ABSTRACT**  
With the rise of deep learning, generative models have enabled the creation of highly realistic synthetic images, presenting challenges due to their potential misuse. While research in Deepfake detection has grown rapidly in response, many detection methods struggle with unseen Deepfakes generated by new synthesis techniques. To address this generalisation challenge, we propose a novel Deepfake detection approach by adapting rich information encoded inside the <b>Foundation</b> <b>Models</b> with rich information encoded inside, specifically using the image encoder from CLIP which has demonstrated strong <b>zero-shot</b> capability for downstream tasks. Inspired by the recent advances of parameter efficient <b>fine-tuning,</b> we propose a novel side-network-based decoder to extract spatial and temporal cues from the given video clip, with the promotion of the Facial Component Guidance (FCG) to guidencourage the spatial feature to include features of key facial parts for more robust and general Deepfake detection. Through extensive cross-dataset evaluations, our approach exhibits superior effectiveness in identifying unseen Deepfake samples, achieving notable performance improvementsuccess even with limited training samples and manipulation types. Our model secures an average performance enhancement of 0.9% AUROC in cross-dataset assessments comparing with state-of-the-art methods, especiallytablishing a significant lead of achieving 4.4% improvement on the challenging DFDC dataset.

{{</citation>}}


### (28/76 | 71/266) Investigating the Effectiveness of Cross-Attention to Unlock Zero-Shot Editing of Text-to-Video Diffusion Models (Saman Motamed et al., 2024)

{{<citation>}}

Saman Motamed, Wouter Van Gansbeke, Luc Van Gool. (2024)  
**Investigating the Effectiveness of Cross-Attention to Unlock Zero-Shot Editing of Text-to-Video Diffusion Models**
<br/>
<button class="copy-to-clipboard" title="Investigating the Effectiveness of Cross-Attention to Unlock Zero-Shot Editing of Text-to-Video Diffusion Models" index=71>
  <span class="copy-to-clipboard-item">Copy Title<span>
</button>
<div class="toast toast-copied toast-index-71 align-items-center text-bg-secondary border-0 position-absolute top-0 end-0" role="alert" aria-live="assertive" aria-atomic="true">
  <div class="d-flex">
    <div class="toast-body">
      Copied!
    </div>
  </div>
</div>

---
Primary Category: cs.CV  
Categories: cs-CV, cs-LG, cs.CV  
Keyword Score: 30  
Keywords: Diffusion Model, Zero-shot, Text2image  
<a type="button" class="btn btn-outline-primary" href="http://arxiv.org/abs/2404.05519v1" target="_blank" >Paper Link</a>
<button type="button" class="btn btn-outline-primary download-pdf" url="https://arxiv.org/pdf/2404.05519v1.pdf" filename="2404.05519v1.pdf">Download PDF</button>

---


**ABSTRACT**  
With recent advances in image and video <b>diffusion</b> <b>models</b> for content creation, a plethora of techniques have been proposed for customizing their generated content. In particular, manipulating the cross-attention layers of <b>Text-to-Image</b> (T2I) <b>diffusion</b> <b>models</b> has shown great promise in controlling the shape and location of objects in the scene. Transferring image-editing techniques to the video domain, however, is extremely challenging as object motion and temporal consistency are difficult to capture accurately. In this work, we take a first look at the role of cross-attention in Text-to-Video (T2V) <b>diffusion</b> <b>models</b> for <b>zero-shot</b> video editing. While one-shot models have shown potential in controlling motion and camera movement, we demonstrate <b>zero-shot</b> control over object shape, position and movement in T2V models. We show that despite the limitations of current T2V models, cross-attention guidance can be a promising approach for editing videos.

{{</citation>}}


### (29/76 | 72/266) Rethinking the Spatial Inconsistency in Classifier-Free Diffusion Guidance (Dazhong Shen et al., 2024)

{{<citation>}}

Dazhong Shen, Guanglu Song, Zeyue Xue, Fu-Yun Wang, Yu Liu. (2024)  
**Rethinking the Spatial Inconsistency in Classifier-Free Diffusion Guidance**
<br/>
<button class="copy-to-clipboard" title="Rethinking the Spatial Inconsistency in Classifier-Free Diffusion Guidance" index=72>
  <span class="copy-to-clipboard-item">Copy Title<span>
</button>
<div class="toast toast-copied toast-index-72 align-items-center text-bg-secondary border-0 position-absolute top-0 end-0" role="alert" aria-live="assertive" aria-atomic="true">
  <div class="d-flex">
    <div class="toast-body">
      Copied!
    </div>
  </div>
</div>

---
Primary Category: cs.CV  
Categories: cs-AI, cs-CV, cs.CV  
Keyword Score: 30  
Keywords: Diffusion Model, Text2image, Self-Attention  
<a type="button" class="btn btn-outline-primary" href="http://arxiv.org/abs/2404.05384v1" target="_blank" >Paper Link</a>
<button type="button" class="btn btn-outline-primary download-pdf" url="https://arxiv.org/pdf/2404.05384v1.pdf" filename="2404.05384v1.pdf">Download PDF</button>

---


**ABSTRACT**  
Classifier-Free Guidance (CFG) has been widely used in <b>text-to-image</b> <b>diffusion</b> <b>models,</b> where the CFG scale is introduced to control the strength of text guidance on the whole image space. However, we argue that a global CFG scale results in spatial inconsistency on varying semantic strengths and suboptimal image quality. To address this problem, we present a novel approach, Semantic-aware Classifier-Free Guidance (S-CFG), to customize the guidance degrees for different semantic units in <b>text-to-image</b> <b>diffusion</b> <b>models.</b> Specifically, we first design a training-free semantic segmentation method to partition the latent image into relatively independent semantic regions at each denoising step. In particular, the cross-attention map in the denoising U-net backbone is renormalized for assigning each patch to the corresponding token, while the <b>self-attention</b> map is used to complete the semantic regions. Then, to balance the amplification of diverse semantic units, we adaptively adjust the CFG scales across different semantic regions to rescale the text guidance degrees into a uniform level. Finally, extensive experiments demonstrate the superiority of S-CFG over the original CFG strategy on various <b>text-to-image</b> <b>diffusion</b> <b>models,</b> without requiring any extra training cost. our codes are available at https://github.com/SmilesDZgk/S-CFG.

{{</citation>}}


### (30/76 | 73/266) Texture Classification Network Integrating Adaptive Wavelet Transform (Su-Xi Yu et al., 2024)

{{<citation>}}

Su-Xi Yu, Jing-Yuan He, Yi Wang, Yu-Jiao Cai, Jun Yang, Bo Lin, Wei-Bin Yang, Jian Ruan. (2024)  
**Texture Classification Network Integrating Adaptive Wavelet Transform**
<br/>
<button class="copy-to-clipboard" title="Texture Classification Network Integrating Adaptive Wavelet Transform" index=73>
  <span class="copy-to-clipboard-item">Copy Title<span>
</button>
<div class="toast toast-copied toast-index-73 align-items-center text-bg-secondary border-0 position-absolute top-0 end-0" role="alert" aria-live="assertive" aria-atomic="true">
  <div class="d-flex">
    <div class="toast-body">
      Copied!
    </div>
  </div>
</div>

---
Primary Category: cs.CV  
Categories: cs-CV, cs.CV  
Keyword Score: 30  
Keywords: Convolution, Convolutional Neural Network, Convolutional Neural Network  
<a type="button" class="btn btn-outline-primary" href="http://arxiv.org/abs/2404.05300v1" target="_blank" >Paper Link</a>
<button type="button" class="btn btn-outline-primary download-pdf" url="https://arxiv.org/pdf/2404.05300v1.pdf" filename="2404.05300v1.pdf">Download PDF</button>

---


**ABSTRACT**  
Graves' disease is a common condition that is diagnosed clinically by determining the smoothness of the thyroid texture and its morphology in ultrasound images. Currently, the most widely used approach for the automated diagnosis of Graves' disease utilizes <b>Convolutional</b> <b>Neural</b> <b>Networks</b> <b>(CNNs)</b> for both feature extraction and classification. However, these methods demonstrate limited efficacy in capturing texture features. Given the high capacity of wavelets in describing texture features, this research integrates learnable wavelet modules utilizing the Lifting Scheme into <b>CNNs</b> and incorporates a parallel wavelet branch into the ResNet18 model to enhance texture feature extraction. Our model can analyze texture features in spatial and frequency domains simultaneously, leading to optimized classification accuracy. We conducted experiments on collected ultrasound datasets and publicly available natural image texture datasets, our proposed network achieved 97.27% accuracy and 95.60% recall on ultrasound datasets, 60.765% accuracy on natural image texture datasets, surpassing the accuracy of ResNet and conrming the effectiveness of our approach.

{{</citation>}}


### (31/76 | 74/266) Unsupervised Band Selection Using Fused HSI and LiDAR Attention Integrating With Autoencoder (Judy X Yang et al., 2024)

{{<citation>}}

Judy X Yang, Jun Zhou, Jing Wang, Hui Tian, Alan Wee Chung Liew. (2024)  
**Unsupervised Band Selection Using Fused HSI and LiDAR Attention Integrating With Autoencoder**
<br/>
<button class="copy-to-clipboard" title="Unsupervised Band Selection Using Fused HSI and LiDAR Attention Integrating With Autoencoder" index=74>
  <span class="copy-to-clipboard-item">Copy Title<span>
</button>
<div class="toast toast-copied toast-index-74 align-items-center text-bg-secondary border-0 position-absolute top-0 end-0" role="alert" aria-live="assertive" aria-atomic="true">
  <div class="d-flex">
    <div class="toast-body">
      Copied!
    </div>
  </div>
</div>

---
Primary Category: cs.CV  
Categories: F-2-2, I-2-7, cs-CV, cs.CV  
Keyword Score: 30  
Keywords: Autoencoder, Convolution, Unsupervised Learning  
<a type="button" class="btn btn-outline-primary" href="http://arxiv.org/abs/2404.05258v1" target="_blank" >Paper Link</a>
<button type="button" class="btn btn-outline-primary download-pdf" url="https://arxiv.org/pdf/2404.05258v1.pdf" filename="2404.05258v1.pdf">Download PDF</button>

---


**ABSTRACT**  
Band selection in hyperspectral imaging (HSI) is critical for optimising data processing and enhancing analytical accuracy. Traditional approaches have predominantly concentrated on analysing spectral and pixel characteristics within individual bands independently. These approaches overlook the potential benefits of integrating multiple data sources, such as Light Detection and Ranging (LiDAR), and is further challenged by the limited availability of labeled data in HSI processing, which represents a significant obstacle. To address these challenges, this paper introduces a novel <b>unsupervised</b> band selection framework that incorporates attention mechanisms and an <b>Autoencoder</b> for reconstruction-based band selection. Our methodology distinctively integrates HSI with LiDAR data through an attention score, using a <b>convolutional</b> <b>Autoencoder</b> to process the combined feature mask. This fusion effectively captures essential spatial and spectral features and reduces redundancy in hyperspectral datasets. A comprehensive comparative analysis of our innovative fused band selection approach is performed against existing <b>unsupervised</b> band selection and fusion models. We used data sets such as Houston 2013, Trento, and MUUFLE for our experiments. The results demonstrate that our method achieves superior classification accuracy and significantly outperforms existing models. This enhancement in HSI band selection, facilitated by the incorporation of LiDAR features, underscores the considerable advantages of integrating features from different sources.

{{</citation>}}


### (32/76 | 75/266) Stylizing Sparse-View 3D Scenes with Hierarchical Neural Representation (Y. Wang et al., 2024)

{{<citation>}}

Y. Wang, A. Gao, Y. Gong, Y. Zeng. (2024)  
**Stylizing Sparse-View 3D Scenes with Hierarchical Neural Representation**
<br/>
<button class="copy-to-clipboard" title="Stylizing Sparse-View 3D Scenes with Hierarchical Neural Representation" index=75>
  <span class="copy-to-clipboard-item">Copy Title<span>
</button>
<div class="toast toast-copied toast-index-75 align-items-center text-bg-secondary border-0 position-absolute top-0 end-0" role="alert" aria-live="assertive" aria-atomic="true">
  <div class="d-flex">
    <div class="toast-body">
      Copied!
    </div>
  </div>
</div>

---
Primary Category: cs.CV  
Categories: cs-CV, cs-GR, cs.CV  
Keyword Score: 30  
Keywords: Few-shot, Fine-tuning, Style Transfer  
<a type="button" class="btn btn-outline-primary" href="http://arxiv.org/abs/2404.05236v1" target="_blank" >Paper Link</a>
<button type="button" class="btn btn-outline-primary download-pdf" url="https://arxiv.org/pdf/2404.05236v1.pdf" filename="2404.05236v1.pdf">Download PDF</button>

---


**ABSTRACT**  
Recently, a surge of 3D <b>style</b> <b>transfer</b> methods has been proposed that leverage the scene reconstruction power of a pre-trained neural radiance field (NeRF). To successfully stylize a scene this way, one must first reconstruct a photo-realistic radiance field from collected images of the scene. However, when only sparse input views are available, pre-trained <b>few-shot</b> NeRFs often suffer from high-frequency artifacts, which are generated as a by-product of high-frequency details for improving reconstruction quality. Is it possible to generate more faithful stylized scenes from sparse inputs by directly optimizing encoding-based scene representation with target style? In this paper, we consider the stylization of sparse-view scenes in terms of disentangling content semantics and <b>style</b> <b>textures.</b> We propose a coarse-to-fine sparse-view scene stylization framework, where a novel hierarchical encoding-based neural representation is designed to generate high-quality stylized scenes directly from implicit scene representations. We also propose a new optimization strategy with content strength annealing to achieve realistic stylization and better content preservation. Extensive experiments demonstrate that our method can achieve high-quality stylization of sparse-view scenes and outperforms <b>fine-tuning-based</b> baselines in terms of stylization quality and efficiency.

{{</citation>}}


### (33/76 | 76/266) A secure and private ensemble matcher using multi-vault obfuscated templates (Babak Poorebrahim Gilkalaye et al., 2024)

{{<citation>}}

Babak Poorebrahim Gilkalaye, Shubhabrata Mukherjee, Reza Derakhshani. (2024)  
**A secure and private ensemble matcher using multi-vault obfuscated templates**
<br/>
<button class="copy-to-clipboard" title="A secure and private ensemble matcher using multi-vault obfuscated templates" index=76>
  <span class="copy-to-clipboard-item">Copy Title<span>
</button>
<div class="toast toast-copied toast-index-76 align-items-center text-bg-secondary border-0 position-absolute top-0 end-0" role="alert" aria-live="assertive" aria-atomic="true">
  <div class="d-flex">
    <div class="toast-body">
      Copied!
    </div>
  </div>
</div>

---
Primary Category: cs.CV  
Categories: cs-CV, cs.CV  
Keyword Score: 30  
Keywords: Generative Adversarial Network, Generative Adversarial Network, Security  
<a type="button" class="btn btn-outline-primary" href="http://arxiv.org/abs/2404.05205v1" target="_blank" >Paper Link</a>
<button type="button" class="btn btn-outline-primary download-pdf" url="https://arxiv.org/pdf/2404.05205v1.pdf" filename="2404.05205v1.pdf">Download PDF</button>

---


**ABSTRACT**  
Given the irrevocability of biometric samples and mounting privacy concerns, biometric template <b>security</b> and secure matching are among the essential features of any well-designed modern biometric system. In this paper, we propose an obfuscation method that hides the biometric template information with just enough chaff. The main idea is to reduce the number of chaff points to a practical level by creating n sub-templates from the original template and hiding each sub-template with m chaff points. During verification, s closest vectors to the biometric query are retrieved from each vault and then combined to generate hash values that are compared with the stored hash value. We demonstrate the effectiveness of synthetic facial images, generated by a <b>Generative</b> <b>Adversarial</b> <b>Network</b> <b>(GAN),</b> as ``random chaff points'' within a secure-vault authorization system. This approach safeguards user identities during training and deployment. We tested our protocol using the AT&T, GT, and LFW face datasets, with the ROC areas under the curve being 0.99, 0.99, and 0.90, respectively. These numbers were close to those of the unprotected templates, showing that our method does not adversely affect accuracy.

{{</citation>}}


### (34/76 | 77/266) UniMix: Towards Domain Adaptive and Generalizable LiDAR Semantic Segmentation in Adverse Weather (Haimei Zhao et al., 2024)

{{<citation>}}

Haimei Zhao, Jing Zhang, Zhuo Chen, Shanshan Zhao, Dacheng Tao. (2024)  
**UniMix: Towards Domain Adaptive and Generalizable LiDAR Semantic Segmentation in Adverse Weather**
<br/>
<button class="copy-to-clipboard" title="UniMix: Towards Domain Adaptive and Generalizable LiDAR Semantic Segmentation in Adverse Weather" index=77>
  <span class="copy-to-clipboard-item">Copy Title<span>
</button>
<div class="toast toast-copied toast-index-77 align-items-center text-bg-secondary border-0 position-absolute top-0 end-0" role="alert" aria-live="assertive" aria-atomic="true">
  <div class="d-flex">
    <div class="toast-body">
      Copied!
    </div>
  </div>
</div>

---
Primary Category: cs.CV  
Categories: cs-CV, cs.CV  
Keyword Score: 30  
Keywords: Simulation, Simulator, Unsupervised Learning  
<a type="button" class="btn btn-outline-primary" href="http://arxiv.org/abs/2404.05145v1" target="_blank" >Paper Link</a>
<button type="button" class="btn btn-outline-primary download-pdf" url="https://arxiv.org/pdf/2404.05145v1.pdf" filename="2404.05145v1.pdf">Download PDF</button>

---


**ABSTRACT**  
LiDAR semantic segmentation (LSS) is a critical task in autonomous driving and has achieved promising progress. However, prior LSS methods are conventionally investigated and evaluated on datasets within the same domain in clear weather. The robustness of LSS models in unseen scenes and all weather conditions is crucial for ensuring safety and reliability in real applications. To this end, we propose UniMix, a universal method that enhances the adaptability and generalizability of LSS models. UniMix first leverages physically valid adverse weather <b>simulation</b> to construct a Bridge Domain, which serves to bridge the domain gap between the clear weather scenes and the adverse weather scenes. Then, a Universal Mixing operator is defined regarding spatial, intensity, and semantic distributions to create the intermediate domain with mixed samples from given domains. Integrating the proposed two techniques into a teacher-student framework, UniMix efficiently mitigates the domain gap and enables LSS models to learn weather-robust and domain-invariant representations. We devote UniMix to two main setups: 1) <b>unsupervised</b> domain adaption, adapting the model from the clear weather source domain to the adverse weather target domain; 2) domain generalization, learning a model that generalizes well to unseen scenes in adverse weather. Extensive experiments validate the effectiveness of UniMix across different tasks and datasets, all achieving superior performance over state-of-the-art methods. The code will be released.

{{</citation>}}


### (35/76 | 78/266) Self-Supervised Multi-Object Tracking with Path Consistency (Zijia Lu et al., 2024)

{{<citation>}}

Zijia Lu, Bing Shuai, Yanbei Chen, Zhenlin Xu, Davide Modolo. (2024)  
**Self-Supervised Multi-Object Tracking with Path Consistency**
<br/>
<button class="copy-to-clipboard" title="Self-Supervised Multi-Object Tracking with Path Consistency" index=78>
  <span class="copy-to-clipboard-item">Copy Title<span>
</button>
<div class="toast toast-copied toast-index-78 align-items-center text-bg-secondary border-0 position-absolute top-0 end-0" role="alert" aria-live="assertive" aria-atomic="true">
  <div class="d-flex">
    <div class="toast-body">
      Copied!
    </div>
  </div>
</div>

---
Primary Category: cs.CV  
Categories: cs-AI, cs-CV, cs.CV  
Keyword Score: 30  
Keywords: Self-supervised Learning, Supervised Learning, Unsupervised Learning  
<a type="button" class="btn btn-outline-primary" href="http://arxiv.org/abs/2404.05136v1" target="_blank" >Paper Link</a>
<button type="button" class="btn btn-outline-primary download-pdf" url="https://arxiv.org/pdf/2404.05136v1.pdf" filename="2404.05136v1.pdf">Download PDF</button>

---


**ABSTRACT**  
In this paper, we propose a novel concept of path consistency to learn robust object matching without using manual object identity supervision. Our key idea is that, to track a object through frames, we can obtain multiple different association results from a model by varying the frames it can observe, i.e., skipping frames in observation. As the differences in observations do not alter the identities of objects, the obtained association results should be consistent. Based on this rationale, we generate multiple observation paths, each specifying a different set of frames to be skipped, and formulate the Path Consistency Loss that enforces the association results are consistent across different observation paths. We use the proposed loss to train our object matching model with only self-supervision. By extensive experiments on three tracking datasets (MOT17, PersonPath22, KITTI), we demonstrate that our method outperforms existing <b>unsupervised</b> methods with consistent margins on various evaluation metrics, and even achieves performance close to <b>supervised</b> methods.

{{</citation>}}


### (36/76 | 79/266) Towards Explainable Automated Neuroanatomy (Kui Qian et al., 2024)

{{<citation>}}

Kui Qian, Litao Qiao, Beth Friedman, Edward O'Donnell, David Kleinfeld, Yoav Freund. (2024)  
**Towards Explainable Automated Neuroanatomy**
<br/>
<button class="copy-to-clipboard" title="Towards Explainable Automated Neuroanatomy" index=79>
  <span class="copy-to-clipboard-item">Copy Title<span>
</button>
<div class="toast toast-copied toast-index-79 align-items-center text-bg-secondary border-0 position-absolute top-0 end-0" role="alert" aria-live="assertive" aria-atomic="true">
  <div class="d-flex">
    <div class="toast-body">
      Copied!
    </div>
  </div>
</div>

---
Primary Category: cs.CV  
Categories: cs-CV, cs.CV, q-bio-NC  
Keyword Score: 25  
Keywords: Black Box, Convolution, Convolutional Neural Network  
<a type="button" class="btn btn-outline-primary" href="http://arxiv.org/abs/2404.05814v1" target="_blank" >Paper Link</a>
<button type="button" class="btn btn-outline-primary download-pdf" url="https://arxiv.org/pdf/2404.05814v1.pdf" filename="2404.05814v1.pdf">Download PDF</button>

---


**ABSTRACT**  
We present a novel method for quantifying the microscopic structure of brain tissue. It is based on the automated recognition of interpretable features obtained by analyzing the shapes of cells. This contrasts with prevailing methods of brain anatomical analysis in two ways. First, contemporary methods use gray-scale values derived from smoothed version of the anatomical images, which dissipated valuable information from the texture of the images. Second, contemporary analysis uses the output of <b>black-box</b> <b>Convolutional</b> <b>Neural</b> <b>Networks,</b> while our system makes decisions based on interpretable features obtained by analyzing the shapes of individual cells. An important benefit of this open-box approach is that the anatomist can understand and correct the decisions made by the computer. Our proposed system can accurately localize and identify existing brain structures. This can be used to align and coregistar brains and will facilitate connectomic studies for reverse engineering of brain circuitry.

{{</citation>}}


### (37/76 | 80/266) StylizedGS: Controllable Stylization for 3D Gaussian Splatting (Dingxi Zhang et al., 2024)

{{<citation>}}

Dingxi Zhang, Zhuoxun Chen, Yu-Jie Yuan, Fang-Lue Zhang, Zhenliang He, Shiguang Shan, Lin Gao. (2024)  
**StylizedGS: Controllable Stylization for 3D Gaussian Splatting**
<br/>
<button class="copy-to-clipboard" title="StylizedGS: Controllable Stylization for 3D Gaussian Splatting" index=80>
  <span class="copy-to-clipboard-item">Copy Title<span>
</button>
<div class="toast toast-copied toast-index-80 align-items-center text-bg-secondary border-0 position-absolute top-0 end-0" role="alert" aria-live="assertive" aria-atomic="true">
  <div class="d-flex">
    <div class="toast-body">
      Copied!
    </div>
  </div>
</div>

---
Primary Category: cs.CV  
Categories: cs-CV, cs.CV  
Keyword Score: 25  
Keywords: Fine-tuning, Geometry, Style Transfer  
<a type="button" class="btn btn-outline-primary" href="http://arxiv.org/abs/2404.05220v1" target="_blank" >Paper Link</a>
<button type="button" class="btn btn-outline-primary download-pdf" url="https://arxiv.org/pdf/2404.05220v1.pdf" filename="2404.05220v1.pdf">Download PDF</button>

---


**ABSTRACT**  
With the rapid development of XR, 3D generation and editing are becoming more and more important, among which, stylization is an important tool of 3D appearance editing. It can achieve consistent 3D artistic stylization given a single reference <b>style</b> <b>image</b> and thus is a user-friendly editing way. However, recent NeRF-based 3D stylization methods face efficiency issues that affect the actual user experience and the implicit nature limits its ability to transfer the geometric pattern <b>styles.</b> <b>Additionally,</b> the ability for artists to exert flexible control over stylized scenes is considered highly desirable, fostering an environment conducive to creative exploration. In this paper, we introduce StylizedGS, a 3D neural <b>style</b> <b>transfer</b> framework with adaptable control over perceptual factors based on 3D Gaussian Splatting (3DGS) representation. The 3DGS brings the benefits of high efficiency. We propose a GS filter to eliminate floaters in the reconstruction which affects the stylization effects before stylization. Then the nearest neighbor-based <b>style</b> <b>loss</b> is introduced to achieve stylization by <b>fine-tuning</b> the <b>geometry</b> and color parameters of 3DGS, while a depth preservation loss with other regularizations is proposed to prevent the tampering of <b>geometry</b> content. Moreover, facilitated by specially designed losses, StylizedGS enables users to control color, stylized scale and regions during the stylization to possess customized capabilities. Our method can attain high-quality stylization results characterized by faithful brushstrokes and geometric consistency with flexible controls. Extensive experiments across various scenes and <b>styles</b> <b>demonstrate</b> the effectiveness and efficiency of our method concerning both stylization quality and inference FPS.

{{</citation>}}


### (38/76 | 81/266) Learning a Category-level Object Pose Estimator without Pose Annotations (Fengrui Tian et al., 2024)

{{<citation>}}

Fengrui Tian, Yaoyao Liu, Adam Kortylewski, Yueqi Duan, Shaoyi Du, Alan Yuille, Angtian Wang. (2024)  
**Learning a Category-level Object Pose Estimator without Pose Annotations**
<br/>
<button class="copy-to-clipboard" title="Learning a Category-level Object Pose Estimator without Pose Annotations" index=81>
  <span class="copy-to-clipboard-item">Copy Title<span>
</button>
<div class="toast toast-copied toast-index-81 align-items-center text-bg-secondary border-0 position-absolute top-0 end-0" role="alert" aria-live="assertive" aria-atomic="true">
  <div class="d-flex">
    <div class="toast-body">
      Copied!
    </div>
  </div>
</div>

---
Primary Category: cs.CV  
Categories: cs-CV, cs.CV  
Keyword Score: 23  
Keywords: Diffusion Model, Benchmarking, Few-shot  
<a type="button" class="btn btn-outline-primary" href="http://arxiv.org/abs/2404.05626v1" target="_blank" >Paper Link</a>
<button type="button" class="btn btn-outline-primary download-pdf" url="https://arxiv.org/pdf/2404.05626v1.pdf" filename="2404.05626v1.pdf">Download PDF</button>

---


**ABSTRACT**  
3D object pose estimation is a challenging task. Previous works always require thousands of object images with annotated poses for learning the 3D pose correspondence, which is laborious and time-consuming for labeling. In this paper, we propose to learn a category-level 3D object pose estimator without pose annotations. Instead of using manually annotated images, we leverage <b>diffusion</b> <b>models</b> (e.g., Zero-1-to-3) to generate a set of images under controlled pose differences and propose to learn our object pose estimator with those images. Directly using the original <b>diffusion</b> <b>model</b> leads to images with noisy poses and artifacts. To tackle this issue, firstly, we exploit an image encoder, which is learned from a specially designed contrastive pose learning, to filter the unreasonable details and extract image feature maps. Additionally, we propose a novel learning strategy that allows the model to learn object poses from those generated image sets without knowing the alignment of their canonical poses. Experimental results show that our method has the capability of category-level object pose estimation from a single shot setting (as pose definition), while significantly outperforming other state-of-the-art methods on the <b>few-shot</b> category-level object pose estimation <b>benchmarks.</b>

{{</citation>}}


### (39/76 | 82/266) CDAD-Net: Bridging Domain Gaps in Generalized Category Discovery (Sai Bhargav Rongali et al., 2024)

{{<citation>}}

Sai Bhargav Rongali, Sarthak Mehrotra, Ankit Jha, Mohamad Hassan N C, Shirsha Bose, Tanisha Gupta, Mainak Singha, Biplab Banerjee. (2024)  
**CDAD-Net: Bridging Domain Gaps in Generalized Category Discovery**
<br/>
<button class="copy-to-clipboard" title="CDAD-Net: Bridging Domain Gaps in Generalized Category Discovery" index=82>
  <span class="copy-to-clipboard-item">Copy Title<span>
</button>
<div class="toast toast-copied toast-index-82 align-items-center text-bg-secondary border-0 position-absolute top-0 end-0" role="alert" aria-live="assertive" aria-atomic="true">
  <div class="d-flex">
    <div class="toast-body">
      Copied!
    </div>
  </div>
</div>

---
Primary Category: cs.CV  
Categories: cs-CV, cs.CV  
Keyword Score: 23  
Keywords: Adversarial Learning, Benchmarking, Contrastive Learning  
<a type="button" class="btn btn-outline-primary" href="http://arxiv.org/abs/2404.05366v1" target="_blank" >Paper Link</a>
<button type="button" class="btn btn-outline-primary download-pdf" url="https://arxiv.org/pdf/2404.05366v1.pdf" filename="2404.05366v1.pdf">Download PDF</button>

---


**ABSTRACT**  
In Generalized Category Discovery (GCD), we cluster unlabeled samples of known and novel classes, leveraging a training dataset of known classes. A salient challenge arises due to domain shifts between these datasets. To address this, we present a novel setting: Across Domain Generalized Category Discovery (AD-GCD) and bring forth CDAD-NET (Class Discoverer Across Domains) as a remedy. CDAD-NET is architected to synchronize potential known class samples across both the labeled (source) and unlabeled (target) datasets, while emphasizing the distinct categorization of the target data. To facilitate this, we propose an entropy-driven <b>adversarial</b> <b>learning</b> strategy that accounts for the distance distributions of target samples relative to source-domain class prototypes. Parallelly, the discriminative nature of the shared space is upheld through a fusion of three metric learning objectives. In the source domain, our focus is on refining the proximity between samples and their affiliated class prototypes, while in the target domain, we integrate a neighborhood-centric <b>contrastive</b> <b>learning</b> mechanism, enriched with an adept neighborsmining approach. To further accentuate the nuanced feature interrelation among semantically aligned images, we champion the concept of conditional image inpainting, underscoring the premise that semantically analogous images prove more efficacious to the task than their disjointed counterparts. Experimentally, CDAD-NET eclipses existing literature with a performance increment of 8-15% on three AD-GCD <b>benchmarks</b> we present.

{{</citation>}}


### (40/76 | 83/266) MOSE: Boosting Vision-based Roadside 3D Object Detection with Scene Cues (Xiahan Chen et al., 2024)

{{<citation>}}

Xiahan Chen, Mingjian Chen, Sanli Tang, Yi Niu, Jiang Zhu. (2024)  
**MOSE: Boosting Vision-based Roadside 3D Object Detection with Scene Cues**
<br/>
<button class="copy-to-clipboard" title="MOSE: Boosting Vision-based Roadside 3D Object Detection with Scene Cues" index=83>
  <span class="copy-to-clipboard-item">Copy Title<span>
</button>
<div class="toast toast-copied toast-index-83 align-items-center text-bg-secondary border-0 position-absolute top-0 end-0" role="alert" aria-live="assertive" aria-atomic="true">
  <div class="d-flex">
    <div class="toast-body">
      Copied!
    </div>
  </div>
</div>

---
Primary Category: cs.CV  
Categories: cs-CV, cs.CV  
Keyword Score: 23  
Keywords: Object Detection, Benchmarking, Transformer  
<a type="button" class="btn btn-outline-primary" href="http://arxiv.org/abs/2404.05280v1" target="_blank" >Paper Link</a>
<button type="button" class="btn btn-outline-primary download-pdf" url="https://arxiv.org/pdf/2404.05280v1.pdf" filename="2404.05280v1.pdf">Download PDF</button>

---


**ABSTRACT**  
3D <b>object</b> <b>detection</b> based on roadside cameras is an additional way for autonomous driving to alleviate the challenges of occlusion and short perception range from vehicle cameras. Previous methods for roadside 3D <b>object</b> <b>detection</b> mainly focus on modeling the depth or height of <b>objects,</b> <b>neglecting</b> the stationary of cameras and the characteristic of inter-frame consistency. In this work, we propose a novel framework, namely MOSE, for MOnocular 3D <b>object</b> <b>detection</b> with Scene cuEs. The scene cues are the frame-invariant scene-specific features, which are crucial for <b>object</b> <b>localization</b> and can be intuitively regarded as the height between the surface of the real road and the virtual ground plane. In the proposed framework, a scene cue bank is designed to aggregate scene cues from multiple frames of the same scene with a carefully designed extrinsic augmentation strategy. Then, a <b>transformer-based</b> decoder lifts the aggregated scene cues as well as the 3D position embeddings for 3D <b>object</b> <b>location,</b> which boosts generalization ability in heterologous scenes. The extensive experiment results on two public <b>benchmarks</b> demonstrate the state-of-the-art performance of the proposed method, which surpasses the existing methods by a large margin.

{{</citation>}}


### (41/76 | 84/266) Bidirectional Long-Range Parser for Sequential Data Understanding (George Leotescu et al., 2024)

{{<citation>}}

George Leotescu, Daniel Voinea, Alin-Ionut Popa. (2024)  
**Bidirectional Long-Range Parser for Sequential Data Understanding**
<br/>
<button class="copy-to-clipboard" title="Bidirectional Long-Range Parser for Sequential Data Understanding" index=84>
  <span class="copy-to-clipboard-item">Copy Title<span>
</button>
<div class="toast toast-copied toast-index-84 align-items-center text-bg-secondary border-0 position-absolute top-0 end-0" role="alert" aria-live="assertive" aria-atomic="true">
  <div class="d-flex">
    <div class="toast-body">
      Copied!
    </div>
  </div>
</div>

---
Primary Category: cs.CV  
Categories: cs-CL, cs-CV, cs-LG, cs.CV  
Keyword Score: 23  
Keywords: Benchmarking, Transformer, Vision-and-Language  
<a type="button" class="btn btn-outline-primary" href="http://arxiv.org/abs/2404.05210v1" target="_blank" >Paper Link</a>
<button type="button" class="btn btn-outline-primary download-pdf" url="https://arxiv.org/pdf/2404.05210v1.pdf" filename="2404.05210v1.pdf">Download PDF</button>

---


**ABSTRACT**  
The <b>transformer</b> is a powerful data modelling framework responsible for remarkable performance on a wide range of tasks. However, they are limited in terms of scalability as it is suboptimal and inefficient to process long-sequence data. To this purpose we introduce BLRP (Bidirectional Long-Range Parser), a novel and versatile attention mechanism designed to increase performance and efficiency on long-sequence tasks. It leverages short and long range heuristics in the form of a local sliding window approach combined with a global bidirectional latent space synthesis technique. We show the benefits and versatility of our approach on vision and language domains by demonstrating competitive results against state-of-the-art methods on the Long-Range-Arena and CIFAR <b>benchmarks</b> together with ablations demonstrating the computational efficiency.

{{</citation>}}


### (42/76 | 85/266) Finding Visual Task Vectors (Alberto Hojel et al., 2024)

{{<citation>}}

Alberto Hojel, Yutong Bai, Trevor Darrell, Amir Globerson, Amir Bar. (2024)  
**Finding Visual Task Vectors**
<br/>
<button class="copy-to-clipboard" title="Finding Visual Task Vectors" index=85>
  <span class="copy-to-clipboard-item">Copy Title<span>
</button>
<div class="toast toast-copied toast-index-85 align-items-center text-bg-secondary border-0 position-absolute top-0 end-0" role="alert" aria-live="assertive" aria-atomic="true">
  <div class="d-flex">
    <div class="toast-body">
      Copied!
    </div>
  </div>
</div>

---
Primary Category: cs.CV  
Categories: cs-CV, cs.CV  
Keyword Score: 20  
Keywords: In-context Learning, Prompt  
<a type="button" class="btn btn-outline-primary" href="http://arxiv.org/abs/2404.05729v1" target="_blank" >Paper Link</a>
<button type="button" class="btn btn-outline-primary download-pdf" url="https://arxiv.org/pdf/2404.05729v1.pdf" filename="2404.05729v1.pdf">Download PDF</button>

---


**ABSTRACT**  
Visual <b>Prompting</b> is a technique for teaching models to perform a visual task via <b>in-context</b> examples, without any additional training. In this work, we analyze the activations of MAE-VQGAN, a recent Visual <b>Prompting</b> model, and find task vectors, activations that encode task-specific information. Equipped with this insight, we demonstrate that it is possible to identify the task vectors and use them to guide the network towards performing different tasks without providing any input-output examples. To find task vectors, we compute the average intermediate activations per task and use the REINFORCE algorithm to search for the subset of task vectors. The resulting task vectors guide the model towards performing a task better than the original model without the need for input-output examples.

{{</citation>}}


### (43/76 | 86/266) Learning 3D-Aware GANs from Unposed Images with Template Feature Field (Xinya Chen et al., 2024)

{{<citation>}}

Xinya Chen, Hanlei Guo, Yanrui Bin, Shangzhan Zhang, Yuanbo Yang, Yue Wang, Yujun Shen, Yiyi Liao. (2024)  
**Learning 3D-Aware GANs from Unposed Images with Template Feature Field**
<br/>
<button class="copy-to-clipboard" title="Learning 3D-Aware GANs from Unposed Images with Template Feature Field" index=86>
  <span class="copy-to-clipboard-item">Copy Title<span>
</button>
<div class="toast toast-copied toast-index-86 align-items-center text-bg-secondary border-0 position-absolute top-0 end-0" role="alert" aria-live="assertive" aria-atomic="true">
  <div class="d-flex">
    <div class="toast-body">
      Copied!
    </div>
  </div>
</div>

---
Primary Category: cs.CV  
Categories: cs-CV, cs.CV  
Keyword Score: 20  
Keywords: Generative Adversarial Network, Generative Adversarial Network  
<a type="button" class="btn btn-outline-primary" href="http://arxiv.org/abs/2404.05705v1" target="_blank" >Paper Link</a>
<button type="button" class="btn btn-outline-primary download-pdf" url="https://arxiv.org/pdf/2404.05705v1.pdf" filename="2404.05705v1.pdf">Download PDF</button>

---


**ABSTRACT**  
Collecting accurate camera poses of training images has been shown to well serve the learning of 3D-aware <b>generative</b> <b>adversarial</b> <b>networks</b> <b>(GANs)</b> yet can be quite expensive in practice. This work targets learning 3D-aware <b>GANs</b> from unposed images, for which we propose to perform on-the-fly pose estimation of training images with a learned template feature field (TeFF). Concretely, in addition to a <b>generative</b> <b>radiance</b> <b>field</b> as in previous approaches, we ask the generator to also learn a field from 2D semantic features while sharing the density from the radiance field. Such a framework allows us to acquire a canonical 3D feature template leveraging the dataset mean discovered by the <b>generative</b> <b>model,</b> <b>and</b> further efficiently estimate the pose parameters on real data. Experimental results on various challenging datasets demonstrate the superiority of our approach over state-of-the-art alternatives from both the qualitative and the quantitative perspectives.

{{</citation>}}


### (44/76 | 87/266) SphereHead: Stable 3D Full-head Synthesis with Spherical Tri-plane Representation (Heyuan Li et al., 2024)

{{<citation>}}

Heyuan Li, Ce Chen, Tianhao Shi, Yuda Qiu, Sizhe An, Guanying Chen, Xiaoguang Han. (2024)  
**SphereHead: Stable 3D Full-head Synthesis with Spherical Tri-plane Representation**
<br/>
<button class="copy-to-clipboard" title="SphereHead: Stable 3D Full-head Synthesis with Spherical Tri-plane Representation" index=87>
  <span class="copy-to-clipboard-item">Copy Title<span>
</button>
<div class="toast toast-copied toast-index-87 align-items-center text-bg-secondary border-0 position-absolute top-0 end-0" role="alert" aria-live="assertive" aria-atomic="true">
  <div class="d-flex">
    <div class="toast-body">
      Copied!
    </div>
  </div>
</div>

---
Primary Category: cs.CV  
Categories: cs-CV, cs.CV  
Keyword Score: 20  
Keywords: Generative Adversarial Network, Generative Adversarial Network  
<a type="button" class="btn btn-outline-primary" href="http://arxiv.org/abs/2404.05680v1" target="_blank" >Paper Link</a>
<button type="button" class="btn btn-outline-primary download-pdf" url="https://arxiv.org/pdf/2404.05680v1.pdf" filename="2404.05680v1.pdf">Download PDF</button>

---


**ABSTRACT**  
While recent advances in 3D-aware <b>Generative</b> <b>Adversarial</b> <b>Networks</b> <b>(GANs)</b> have aided the development of near-frontal view human face synthesis, the challenge of comprehensively synthesizing a full 3D head viewable from all angles still persists. Although PanoHead proves the possibilities of using a large-scale dataset with images of both frontal and back views for full-head synthesis, it often causes artifacts for back views. Based on our in-depth analysis, we found the reasons are mainly twofold. First, from network architecture perspective, we found each plane in the utilized tri-plane/tri-grid representation space tends to confuse the features from both sides, causing "mirroring" artifacts (e.g., the glasses appear in the back). Second, from data supervision aspect, we found that existing discriminator training in 3D <b>GANs</b> mainly focuses on the quality of the rendered image itself, and does not care much about its plausibility with the perspective from which it was rendered. This makes it possible to generate "face" in non-frontal views, due to its easiness to fool the discriminator. In response, we propose SphereHead, a novel tri-plane representation in the spherical coordinate system that fits the human head's geometric characteristics and efficiently mitigates many of the generated artifacts. We further introduce a view-image consistency loss for the discriminator to emphasize the correspondence of the camera parameters and the images. The combination of these efforts results in visually superior outcomes with significantly fewer artifacts. Our code and dataset are publicly available at https://lhyfst.github.io/spherehead.

{{</citation>}}


### (45/76 | 88/266) BinaryDM: Towards Accurate Binarization of Diffusion Model (Xingyu Zheng et al., 2024)

{{<citation>}}

Xingyu Zheng, Haotong Qin, Xudong Ma, Mingyuan Zhang, Haojie Hao, Jiakai Wang, Zixiang Zhao, Jinyang Guo, Xianglong Liu. (2024)  
**BinaryDM: Towards Accurate Binarization of Diffusion Model**
<br/>
<button class="copy-to-clipboard" title="BinaryDM: Towards Accurate Binarization of Diffusion Model" index=88>
  <span class="copy-to-clipboard-item">Copy Title<span>
</button>
<div class="toast toast-copied toast-index-88 align-items-center text-bg-secondary border-0 position-absolute top-0 end-0" role="alert" aria-live="assertive" aria-atomic="true">
  <div class="d-flex">
    <div class="toast-body">
      Copied!
    </div>
  </div>
</div>

---
Primary Category: cs.CV  
Categories: cs-CV, cs.CV  
Keyword Score: 20  
Keywords: Diffusion Model, Quantization  
<a type="button" class="btn btn-outline-primary" href="http://arxiv.org/abs/2404.05662v1" target="_blank" >Paper Link</a>
<button type="button" class="btn btn-outline-primary download-pdf" url="https://arxiv.org/pdf/2404.05662v1.pdf" filename="2404.05662v1.pdf">Download PDF</button>

---


**ABSTRACT**  
With the advancement of <b>diffusion</b> <b>models</b> (DMs) and the substantially increased computational requirements, <b>quantization</b> emerges as a practical solution to obtain compact and efficient low-bit DMs. However, the highly discrete representation leads to severe accuracy degradation, hindering the <b>quantization</b> of <b>diffusion</b> <b>models</b> to ultra-low bit-widths. In this paper, we propose BinaryDM, a novel accurate <b>quantization-aware</b> training approach to push the weights of <b>diffusion</b> <b>models</b> towards the limit of 1-bit. Firstly, we present a Learnable Multi-basis Binarizer (LMB) to recover the representations generated by the binarized DM, which improves the information in details of representations crucial to the DM. Secondly, a Low-rank Representation Mimicking (LRM) is applied to enhance the binarization-aware optimization of the DM, alleviating the optimization direction ambiguity caused by fine-grained alignment. Moreover, a progressive initialization strategy is applied to training DMs to avoid convergence difficulties. Comprehensive experiments demonstrate that BinaryDM achieves significant accuracy and efficiency gains compared to SOTA <b>quantization</b> methods of DMs under ultra-low bit-widths. As the first binarization method for <b>diffusion</b> <b>models,</b> BinaryDM achieves impressive 16.0 times FLOPs and 27.1 times storage savings with 1-bit weight and 4-bit activation, showcasing its substantial advantages and potential for deploying DMs on resource-limited scenarios.

{{</citation>}}


### (46/76 | 89/266) UniFL: Improve Stable Diffusion via Unified Feedback Learning (Jiacheng Zhang et al., 2024)

{{<citation>}}

Jiacheng Zhang, Jie Wu, Yuxi Ren, Xin Xia, Huafeng Kuang, Pan Xie, Jiashi Li, Xuefeng Xiao, Weilin Huang, Min Zheng, Lean Fu, Guanbin Li. (2024)  
**UniFL: Improve Stable Diffusion via Unified Feedback Learning**
<br/>
<button class="copy-to-clipboard" title="UniFL: Improve Stable Diffusion via Unified Feedback Learning" index=89>
  <span class="copy-to-clipboard-item">Copy Title<span>
</button>
<div class="toast toast-copied toast-index-89 align-items-center text-bg-secondary border-0 position-absolute top-0 end-0" role="alert" aria-live="assertive" aria-atomic="true">
  <div class="d-flex">
    <div class="toast-body">
      Copied!
    </div>
  </div>
</div>

---
Primary Category: cs.CV  
Categories: cs-CV, cs.CV  
Keyword Score: 20  
Keywords: ControlNet, Diffusion Model  
<a type="button" class="btn btn-outline-primary" href="http://arxiv.org/abs/2404.05595v1" target="_blank" >Paper Link</a>
<button type="button" class="btn btn-outline-primary download-pdf" url="https://arxiv.org/pdf/2404.05595v1.pdf" filename="2404.05595v1.pdf">Download PDF</button>

---


**ABSTRACT**  
<b>Diffusion</b> <b>models</b> have revolutionized the field of image generation, leading to the proliferation of high-quality models and diverse downstream applications. However, despite these significant advancements, the current competitive solutions still suffer from several limitations, including inferior visual quality, a lack of aesthetic appeal, and inefficient inference, without a comprehensive solution in sight. To address these challenges, we present UniFL, a unified framework that leverages feedback learning to enhance <b>diffusion</b> <b>models</b> comprehensively. UniFL stands out as a universal, effective, and generalizable solution applicable to various <b>diffusion</b> <b>models,</b> such as SD1.5 and SDXL. Notably, UniFL incorporates three key components: perceptual feedback learning, which enhances visual quality; decoupled feedback learning, which improves aesthetic appeal; and adversarial feedback learning, which optimizes inference speed. In-depth experiments and extensive user studies validate the superior performance of our proposed method in enhancing both the quality of generated models and their acceleration. For instance, UniFL surpasses ImageReward by 17% user preference in terms of generation quality and outperforms LCM and SDXL Turbo by 57% and 20% in 4-step inference. Moreover, we have verified the efficacy of our approach in downstream tasks, including Lora, <b>ControlNet,</b> and AnimateDiff.

{{</citation>}}


### (47/76 | 90/266) TIM: A Time Interval Machine for Audio-Visual Action Recognition (Jacob Chalk et al., 2024)

{{<citation>}}

Jacob Chalk, Jaesung Huh, Evangelos Kazakos, Andrew Zisserman, Dima Damen. (2024)  
**TIM: A Time Interval Machine for Audio-Visual Action Recognition**
<br/>
<button class="copy-to-clipboard" title="TIM: A Time Interval Machine for Audio-Visual Action Recognition" index=90>
  <span class="copy-to-clipboard-item">Copy Title<span>
</button>
<div class="toast toast-copied toast-index-90 align-items-center text-bg-secondary border-0 position-absolute top-0 end-0" role="alert" aria-live="assertive" aria-atomic="true">
  <div class="d-flex">
    <div class="toast-body">
      Copied!
    </div>
  </div>
</div>

---
Primary Category: cs.CV  
Categories: cs-CV, cs.CV  
Keyword Score: 20  
Keywords: Transformer, Large Language Model  
<a type="button" class="btn btn-outline-primary" href="http://arxiv.org/abs/2404.05559v2" target="_blank" >Paper Link</a>
<button type="button" class="btn btn-outline-primary download-pdf" url="https://arxiv.org/pdf/2404.05559v2.pdf" filename="2404.05559v2.pdf">Download PDF</button>

---


**ABSTRACT**  
Diverse actions give rise to rich audio-visual signals in long videos. Recent works showcase that the two modalities of audio and video exhibit different temporal extents of events and distinct labels. We address the interplay between the two modalities in long videos by explicitly modelling the temporal extents of audio and visual events. We propose the Time Interval Machine (TIM) where a modality-specific time interval poses as a query to a <b>transformer</b> encoder that ingests a long video input. The encoder then attends to the specified interval, as well as the surrounding context in both modalities, in order to recognise the ongoing action. We test TIM on three long audio-visual video datasets: EPIC-KITCHENS, Perception Test, and AVE, reporting state-of-the-art (SOTA) for recognition. On EPIC-KITCHENS, we beat previous SOTA that utilises <b>LLMs</b> and significantly larger pre-training by 2.9% top-1 action recognition accuracy. Additionally, we show that TIM can be adapted for action detection, using dense multi-scale interval queries, outperforming SOTA on EPIC-KITCHENS-100 for most metrics, and showing strong performance on the Perception Test. Our ablations show the critical role of integrating the two modalities and modelling their time intervals in achieving this performance. Code and models at: https://github.com/JacobChalk/TIM

{{</citation>}}


### (48/76 | 91/266) Taming Transformers for Realistic Lidar Point Cloud Generation (Hamed Haghighi et al., 2024)

{{<citation>}}

Hamed Haghighi, Amir Samadi, Mehrdad Dianati, Valentina Donzella, Kurt Debattista. (2024)  
**Taming Transformers for Realistic Lidar Point Cloud Generation**
<br/>
<button class="copy-to-clipboard" title="Taming Transformers for Realistic Lidar Point Cloud Generation" index=91>
  <span class="copy-to-clipboard-item">Copy Title<span>
</button>
<div class="toast toast-copied toast-index-91 align-items-center text-bg-secondary border-0 position-absolute top-0 end-0" role="alert" aria-live="assertive" aria-atomic="true">
  <div class="d-flex">
    <div class="toast-body">
      Copied!
    </div>
  </div>
</div>

---
Primary Category: cs.CV  
Categories: cs-CV, cs-LG, cs-RO, cs.CV  
Keyword Score: 20  
Keywords: Diffusion Model, Transformer  
<a type="button" class="btn btn-outline-primary" href="http://arxiv.org/abs/2404.05505v1" target="_blank" >Paper Link</a>
<button type="button" class="btn btn-outline-primary download-pdf" url="https://arxiv.org/pdf/2404.05505v1.pdf" filename="2404.05505v1.pdf">Download PDF</button>

---


**ABSTRACT**  
<b>Diffusion</b> <b>Models</b> (DMs) have achieved State-Of-The-Art (SOTA) results in the Lidar point cloud generation task, benefiting from their stable training and iterative refinement during sampling. However, DMs often fail to realistically model Lidar raydrop noise due to their inherent denoising process. To retain the strength of iterative sampling while enhancing the generation of raydrop noise, we introduce LidarGRIT, a generative model that uses auto-regressive <b>transformers</b> to iteratively sample the range images in the latent space rather than image space. Furthermore, LidarGRIT utilises VQ-VAE to separately decode range images and raydrop masks. Our results show that LidarGRIT achieves superior performance compared to SOTA models on KITTI-360 and KITTI odometry datasets. Code available at:https://github.com/hamedhaghighi/LidarGRIT.

{{</citation>}}


### (49/76 | 92/266) MC$^2$: Multi-concept Guidance for Customized Multi-concept Generation (Jiaxiu Jiang et al., 2024)

{{<citation>}}

Jiaxiu Jiang, Yabo Zhang, Kailai Feng, Xiaohe Wu, Wangmeng Zuo. (2024)  
**MC$^2$: Multi-concept Guidance for Customized Multi-concept Generation**
<br/>
<button class="copy-to-clipboard" title="MC$^2$: Multi-concept Guidance for Customized Multi-concept Generation" index=92>
  <span class="copy-to-clipboard-item">Copy Title<span>
</button>
<div class="toast toast-copied toast-index-92 align-items-center text-bg-secondary border-0 position-absolute top-0 end-0" role="alert" aria-live="assertive" aria-atomic="true">
  <div class="d-flex">
    <div class="toast-body">
      Copied!
    </div>
  </div>
</div>

---
Primary Category: cs.CV  
Categories: cs-CV, cs.CV  
Keyword Score: 20  
Keywords: Text2image, Prompt  
<a type="button" class="btn btn-outline-primary" href="http://arxiv.org/abs/2404.05268v1" target="_blank" >Paper Link</a>
<button type="button" class="btn btn-outline-primary download-pdf" url="https://arxiv.org/pdf/2404.05268v1.pdf" filename="2404.05268v1.pdf">Download PDF</button>

---


**ABSTRACT**  
Customized <b>text-to-image</b> generation aims to synthesize instantiations of user-specified concepts and has achieved unprecedented progress in handling individual concept. However, when extending to multiple customized concepts, existing methods exhibit limitations in terms of flexibility and fidelity, only accommodating the combination of limited types of models and potentially resulting in a mix of characteristics from different concepts. In this paper, we introduce the Multi-concept guidance for Multi-concept customization, termed MC$^2$, for improved flexibility and fidelity. MC$^2$ decouples the requirements for model architecture via inference time optimization, allowing the integration of various heterogeneous single-concept customized models. It adaptively refines the attention weights between visual and textual tokens, directing image regions to focus on their associated words while diminishing the impact of irrelevant ones. Extensive experiments demonstrate that MC$^2$ even surpasses previous methods that require additional training in terms of consistency with input <b>prompt</b> and reference images. Moreover, MC$^2$ can be extended to elevate the compositional capabilities of <b>text-to-image</b> generation, yielding appealing results. Code will be publicly available at https://github.com/JIANGJiaXiu/MC-2.

{{</citation>}}


### (50/76 | 93/266) DiffCJK: Conditional Diffusion Model for High-Quality and Wide-coverage CJK Character Generation (Yingtao Tian, 2024)

{{<citation>}}

Yingtao Tian. (2024)  
**DiffCJK: Conditional Diffusion Model for High-Quality and Wide-coverage CJK Character Generation**
<br/>
<button class="copy-to-clipboard" title="DiffCJK: Conditional Diffusion Model for High-Quality and Wide-coverage CJK Character Generation" index=93>
  <span class="copy-to-clipboard-item">Copy Title<span>
</button>
<div class="toast toast-copied toast-index-93 align-items-center text-bg-secondary border-0 position-absolute top-0 end-0" role="alert" aria-live="assertive" aria-atomic="true">
  <div class="d-flex">
    <div class="toast-body">
      Copied!
    </div>
  </div>
</div>

---
Primary Category: cs.CV  
Categories: cs-CV, cs.CV  
Keyword Score: 20  
Keywords: Diffusion Model, Zero-shot  
<a type="button" class="btn btn-outline-primary" href="http://arxiv.org/abs/2404.05212v1" target="_blank" >Paper Link</a>
<button type="button" class="btn btn-outline-primary download-pdf" url="https://arxiv.org/pdf/2404.05212v1.pdf" filename="2404.05212v1.pdf">Download PDF</button>

---


**ABSTRACT**  
Chinese, Japanese, and Korean (CJK), with a vast number of native speakers, has profound influence on society and culture. The typesetting of CJK languages carries a wide range of requirements due to the complexity of their scripts and unique literary traditions. A critical aspect of this typesetting process is that CJK fonts need to provide a set of consistent-looking glyphs for approximately one hundred thousand characters. However, creating such a font is inherently labor-intensive and expensive, which significantly hampers the development of new CJK fonts for typesetting, historical, aesthetic, or artistic purposes. To bridge this gap, we are motivated by recent advancements in <b>diffusion-based</b> <b>generative</b> models and propose a novel <b>diffusion</b> <b>method</b> for generating glyphs in a targeted style from a \emph{single} conditioned, standard glyph form. Our experiments show that our method is capable of generating fonts of both printed and hand-written styles, the latter of which presents a greater challenge. Moreover, our approach shows remarkable <b>zero-shot</b> generalization capabilities for non-CJK but Chinese-inspired scripts. We also show our method facilitates smooth style interpolation and generates bitmap images suitable for vectorization, which is crucial in the font creation process. In summary, our proposed method opens the door to high-quality, generative model-assisted font creation for CJK characters, for both typesetting and artistic endeavors.

{{</citation>}}


### (51/76 | 94/266) LGSDF: Continual Global Learning of Signed Distance Fields Aided by Local Updating (Yufeng Yue et al., 2024)

{{<citation>}}

Yufeng Yue, Yinan Deng, Jiahui Wang, Yi Yang. (2024)  
**LGSDF: Continual Global Learning of Signed Distance Fields Aided by Local Updating**
<br/>
<button class="copy-to-clipboard" title="LGSDF: Continual Global Learning of Signed Distance Fields Aided by Local Updating" index=94>
  <span class="copy-to-clipboard-item">Copy Title<span>
</button>
<div class="toast toast-copied toast-index-94 align-items-center text-bg-secondary border-0 position-absolute top-0 end-0" role="alert" aria-live="assertive" aria-atomic="true">
  <div class="d-flex">
    <div class="toast-body">
      Copied!
    </div>
  </div>
</div>

---
Primary Category: cs.CV  
Categories: cs-CV, cs-GR, cs-RO, cs.CV  
Keyword Score: 20  
Keywords: Self-supervised Learning, Self-supervised Learning  
<a type="button" class="btn btn-outline-primary" href="http://arxiv.org/abs/2404.05187v1" target="_blank" >Paper Link</a>
<button type="button" class="btn btn-outline-primary download-pdf" url="https://arxiv.org/pdf/2404.05187v1.pdf" filename="2404.05187v1.pdf">Download PDF</button>

---


**ABSTRACT**  
Implicit reconstruction of ESDF (Euclidean Signed Distance Field) involves training a neural network to regress the signed distance from any point to the nearest obstacle, which has the advantages of lightweight storage and continuous querying. However, existing algorithms usually rely on conflicting raw observations as training data, resulting in poor map performance. In this paper, we propose LGSDF, an ESDF continual Global learning algorithm aided by Local updating. At the front end, axis-aligned grids are dynamically updated by pre-processed sensor observations, where incremental fusion alleviates estimation error caused by limited viewing directions. At the back end, a randomly initialized implicit ESDF neural network performs continual <b>self-supervised</b> <b>learning</b> guided by these grids to generate smooth and continuous maps. The results on multiple scenes show that LGSDF can construct more accurate ESDF maps and meshes compared with SOTA (State Of The Art) explicit and implicit mapping algorithms. The source code of LGSDF is publicly available at https://github.com/BIT-DYN/LGSDF.

{{</citation>}}


### (52/76 | 95/266) Improving Deep Learning Predictions with Simulated Images, and Vice Versa (Nazifa Azam Khan et al., 2024)

{{<citation>}}

Nazifa Azam Khan, Mikolaj Cieslak, Ian McQuillan. (2024)  
**Improving Deep Learning Predictions with Simulated Images, and Vice Versa**
<br/>
<button class="copy-to-clipboard" title="Improving Deep Learning Predictions with Simulated Images, and Vice Versa" index=95>
  <span class="copy-to-clipboard-item">Copy Title<span>
</button>
<div class="toast toast-copied toast-index-95 align-items-center text-bg-secondary border-0 position-absolute top-0 end-0" role="alert" aria-live="assertive" aria-atomic="true">
  <div class="d-flex">
    <div class="toast-body">
      Copied!
    </div>
  </div>
</div>

---
Primary Category: cs.CV  
Categories: cs-CV, cs-LG, cs.CV  
Keyword Score: 20  
Keywords: Simulation, Simulator  
<a type="button" class="btn btn-outline-primary" href="http://arxiv.org/abs/2404.05128v1" target="_blank" >Paper Link</a>
<button type="button" class="btn btn-outline-primary download-pdf" url="https://arxiv.org/pdf/2404.05128v1.pdf" filename="2404.05128v1.pdf">Download PDF</button>

---


**ABSTRACT**  
Artificial neural networks are often used to identify features of crop plants. However, training their models requires many annotated images, which can be expensive and time-consuming to acquire. Procedural models of plants, such as those developed with Lindenmayer-systems (L-systems) can be created to produce visually realistic <b>simulations,</b> and hence images of plant <b>simulations,</b> where annotations are implicitly known. These synthetic images can either augment or completely replace real images in training neural networks for phenotyping tasks. In this paper, we systematically vary amounts of real and synthetic images used for training in both maize and canola to better understand situations where synthetic images generated from L-systems can help prediction on real images. This work also explores the degree to which realism in the synthetic images improves prediction. Furthermore, we see how neural network predictions can be used to help calibrate L-systems themselves, creating a feedback loop.

{{</citation>}}


### (53/76 | 96/266) SoundingActions: Learning How Actions Sound from Narrated Egocentric Videos (Changan Chen et al., 2024)

{{<citation>}}

Changan Chen, Kumar Ashutosh, Rohit Girdhar, David Harwath, Kristen Grauman. (2024)  
**SoundingActions: Learning How Actions Sound from Narrated Egocentric Videos**
<br/>
<button class="copy-to-clipboard" title="SoundingActions: Learning How Actions Sound from Narrated Egocentric Videos" index=96>
  <span class="copy-to-clipboard-item">Copy Title<span>
</button>
<div class="toast toast-copied toast-index-96 align-items-center text-bg-secondary border-0 position-absolute top-0 end-0" role="alert" aria-live="assertive" aria-atomic="true">
  <div class="d-flex">
    <div class="toast-body">
      Copied!
    </div>
  </div>
</div>

---
Primary Category: cs.CV  
Categories: cs-CV, cs-MM, cs-SD, cs.CV, eess-AS  
Keyword Score: 16  
Keywords: Multi-modal, Multi-modal, Self-supervised Learning  
<a type="button" class="btn btn-outline-primary" href="http://arxiv.org/abs/2404.05206v1" target="_blank" >Paper Link</a>
<button type="button" class="btn btn-outline-primary download-pdf" url="https://arxiv.org/pdf/2404.05206v1.pdf" filename="2404.05206v1.pdf">Download PDF</button>

---


**ABSTRACT**  
We propose a novel <b>self-supervised</b> embedding to learn how actions sound from narrated in-the-wild egocentric videos. Whereas existing methods rely on curated data with known audio-visual correspondence, our <b>multimodal</b> contrastive-consensus coding (MC3) embedding reinforces the associations between audio, language, and vision when all modality pairs agree, while diminishing those associations when any one pair does not. We show our approach can successfully discover how the long tail of human actions sound from egocentric video, outperforming an array of recent <b>multimodal</b> embedding techniques on two datasets (Ego4D and EPIC-Sounds) and multiple cross-modal tasks.

{{</citation>}}


### (54/76 | 97/266) MindSet: Vision. A toolbox for testing DNNs on key psychological experiments (Valerio Biscione et al., 2024)

{{<citation>}}

Valerio Biscione, Dong Yin, Gaurav Malhotra, Marin Dujmovic, Milton L. Montero, Guillermo Puebla, Federico Adolfi, Rachel F. Heaton, John E. Hummel, Benjamin D. Evans, Karim Habashy, Jeffrey S. Bowers. (2024)  
**MindSet: Vision. A toolbox for testing DNNs on key psychological experiments**
<br/>
<button class="copy-to-clipboard" title="MindSet: Vision. A toolbox for testing DNNs on key psychological experiments" index=97>
  <span class="copy-to-clipboard-item">Copy Title<span>
</button>
<div class="toast toast-copied toast-index-97 align-items-center text-bg-secondary border-0 position-absolute top-0 end-0" role="alert" aria-live="assertive" aria-atomic="true">
  <div class="d-flex">
    <div class="toast-body">
      Copied!
    </div>
  </div>
</div>

---
Primary Category: cs.CV  
Categories: cs-AI, cs-CV, cs.CV  
Keyword Score: 13  
Keywords: Benchmarking, Out-of-distribution  
<a type="button" class="btn btn-outline-primary" href="http://arxiv.org/abs/2404.05290v1" target="_blank" >Paper Link</a>
<button type="button" class="btn btn-outline-primary download-pdf" url="https://arxiv.org/pdf/2404.05290v1.pdf" filename="2404.05290v1.pdf">Download PDF</button>

---


**ABSTRACT**  
Multiple <b>benchmarks</b> have been developed to assess the alignment between deep neural networks (DNNs) and human vision. In almost all cases these <b>benchmarks</b> are observational in the sense they are composed of behavioural and brain responses to naturalistic images that have not been manipulated to test hypotheses regarding how DNNs or humans perceive and identify objects. Here we introduce the toolbox MindSet: Vision, consisting of a collection of image datasets and related scripts designed to test DNNs on 30 psychological findings. In all experimental conditions, the stimuli are systematically manipulated to test specific hypotheses regarding human visual perception and object recognition. In addition to providing pre-generated datasets of images, we provide code to regenerate these datasets, offering many configurable parameters which greatly extend the dataset versatility for different research contexts, and code to facilitate the testing of DNNs on these image datasets using three different methods (similarity judgments, <b>out-of-distribution</b> classification, and decoder method), accessible at https://github.com/MindSetVision/mindset-vision. We test ResNet-152 on each of these methods as an example of how the toolbox can be used.

{{</citation>}}


### (55/76 | 98/266) CodeEnhance: A Codebook-Driven Approach for Low-Light Image Enhancement (Xu Wu et al., 2024)

{{<citation>}}

Xu Wu, XianXu Hou, Zhihui Lai, Jie Zhou, Ya-nan Zhang, Witold Pedrycz, Linlin Shen. (2024)  
**CodeEnhance: A Codebook-Driven Approach for Low-Light Image Enhancement**
<br/>
<button class="copy-to-clipboard" title="CodeEnhance: A Codebook-Driven Approach for Low-Light Image Enhancement" index=98>
  <span class="copy-to-clipboard-item">Copy Title<span>
</button>
<div class="toast toast-copied toast-index-98 align-items-center text-bg-secondary border-0 position-absolute top-0 end-0" role="alert" aria-live="assertive" aria-atomic="true">
  <div class="d-flex">
    <div class="toast-body">
      Copied!
    </div>
  </div>
</div>

---
Primary Category: cs.CV  
Categories: cs-CV, cs.CV  
Keyword Score: 13  
Keywords: Benchmarking, Quantization  
<a type="button" class="btn btn-outline-primary" href="http://arxiv.org/abs/2404.05253v1" target="_blank" >Paper Link</a>
<button type="button" class="btn btn-outline-primary download-pdf" url="https://arxiv.org/pdf/2404.05253v1.pdf" filename="2404.05253v1.pdf">Download PDF</button>

---


**ABSTRACT**  
Low-light image enhancement (LLIE) aims to improve low-illumination images. However, existing methods face two challenges: (1) uncertainty in restoration from diverse brightness degradations; (2) loss of texture and color information caused by noise suppression and light enhancement. In this paper, we propose a novel enhancement approach, CodeEnhance, by leveraging <b>quantized</b> priors and image refinement to address these challenges. In particular, we reframe LLIE as learning an image-to-code mapping from low-light images to discrete codebook, which has been learned from high-quality images. To enhance this process, a Semantic Embedding Module (SEM) is introduced to integrate semantic information with low-level features, and a Codebook Shift (CS) mechanism, designed to adapt the pre-learned codebook to better suit the distinct characteristics of our low-light dataset. Additionally, we present an Interactive Feature Transformation (IFT) module to refine texture and color information during image reconstruction, allowing for interactive enhancement based on user preferences. Extensive experiments on both real-world and synthetic <b>benchmarks</b> demonstrate that the incorporation of prior knowledge and controllable information transfer significantly enhances LLIE performance in terms of quality and fidelity. The proposed CodeEnhance exhibits superior robustness to various degradations, including uneven illumination, noise, and color distortion.

{{</citation>}}


### (56/76 | 99/266) Localizing Moments of Actions in Untrimmed Videos of Infants with Autism Spectrum Disorder (Halil Ismail Helvaci et al., 2024)

{{<citation>}}

Halil Ismail Helvaci, Sen-ching Samson Cheung, Chen-Nee Chuah, Sally Ozonoff. (2024)  
**Localizing Moments of Actions in Untrimmed Videos of Infants with Autism Spectrum Disorder**
<br/>
<button class="copy-to-clipboard" title="Localizing Moments of Actions in Untrimmed Videos of Infants with Autism Spectrum Disorder" index=99>
  <span class="copy-to-clipboard-item">Copy Title<span>
</button>
<div class="toast toast-copied toast-index-99 align-items-center text-bg-secondary border-0 position-absolute top-0 end-0" role="alert" aria-live="assertive" aria-atomic="true">
  <div class="d-flex">
    <div class="toast-body">
      Copied!
    </div>
  </div>
</div>

---
Primary Category: cs.CV  
Categories: cs-CV, cs-LG, cs.CV  
Keyword Score: 10  
Keywords: Self-Attention  
<a type="button" class="btn btn-outline-primary" href="http://arxiv.org/abs/2404.05849v1" target="_blank" >Paper Link</a>
<button type="button" class="btn btn-outline-primary download-pdf" url="https://arxiv.org/pdf/2404.05849v1.pdf" filename="2404.05849v1.pdf">Download PDF</button>

---


**ABSTRACT**  
Autism Spectrum Disorder (ASD) presents significant challenges in early diagnosis and intervention, impacting children and their families. With prevalence rates rising, there is a critical need for accessible and efficient screening tools. Leveraging machine learning (ML) techniques, in particular Temporal Action Localization (TAL), holds promise for automating ASD screening. This paper introduces a <b>self-attention</b> based TAL model designed to identify ASD-related behaviors in infant videos. Unlike existing methods, our approach simplifies complex modeling and emphasizes efficiency, which is essential for practical deployment in real-world scenarios. Importantly, this work underscores the importance of developing computer vision methods capable of operating in naturilistic environments with little equipment control, addressing key challenges in ASD screening. This study is the first to conduct end-to-end temporal action localization in untrimmed videos of infants with ASD, offering promising avenues for early intervention and support. We report baseline results of behavior detection using our TAL model. We achieve 70% accuracy for look face, 79% accuracy for look object, 72% for smile and 65% for vocalization.

{{</citation>}}


### (57/76 | 100/266) SwapAnything: Enabling Arbitrary Object Swapping in Personalized Visual Editing (Jing Gu et al., 2024)

{{<citation>}}

Jing Gu, Yilin Wang, Nanxuan Zhao, Wei Xiong, Qing Liu, Zhifei Zhang, He Zhang, Jianming Zhang, HyunJoon Jung, Xin Eric Wang. (2024)  
**SwapAnything: Enabling Arbitrary Object Swapping in Personalized Visual Editing**
<br/>
<button class="copy-to-clipboard" title="SwapAnything: Enabling Arbitrary Object Swapping in Personalized Visual Editing" index=100>
  <span class="copy-to-clipboard-item">Copy Title<span>
</button>
<div class="toast toast-copied toast-index-100 align-items-center text-bg-secondary border-0 position-absolute top-0 end-0" role="alert" aria-live="assertive" aria-atomic="true">
  <div class="d-flex">
    <div class="toast-body">
      Copied!
    </div>
  </div>
</div>

---
Primary Category: cs.CV  
Categories: cs-AI, cs-CV, cs.CV  
Keyword Score: 10  
Keywords: Automatic Evaluation  
<a type="button" class="btn btn-outline-primary" href="http://arxiv.org/abs/2404.05717v1" target="_blank" >Paper Link</a>
<button type="button" class="btn btn-outline-primary download-pdf" url="https://arxiv.org/pdf/2404.05717v1.pdf" filename="2404.05717v1.pdf">Download PDF</button>

---


**ABSTRACT**  
Effective editing of personal content holds a pivotal role in enabling individuals to express their creativity, weaving captivating narratives within their visual stories, and elevate the overall quality and impact of their visual content. Therefore, in this work, we introduce SwapAnything, a novel framework that can swap any objects in an image with personalized concepts given by the reference, while keeping the context unchanged. Compared with existing methods for personalized subject swapping, SwapAnything has three unique advantages: (1) precise control of arbitrary objects and parts rather than the main subject, (2) more faithful preservation of context pixels, (3) better adaptation of the personalized concept to the image. First, we propose targeted variable swapping to apply region control over latent feature maps and swap masked variables for faithful context preservation and initial semantic concept swapping. Then, we introduce appearance adaptation, to seamlessly adapt the semantic concept into the original image in terms of target location, shape, style, and content during the image generation process. Extensive results on both human and <b>automatic</b> <b>evaluation</b> demonstrate significant improvements of our approach over baseline methods on personalized swapping. Furthermore, SwapAnything shows its precise and faithful swapping abilities across single object, multiple objects, partial object, and cross-domain swapping tasks. SwapAnything also achieves great performance on text-based swapping and tasks beyond swapping such as object insertion.

{{</citation>}}


### (58/76 | 101/266) Evaluating the Efficacy of Cut-and-Paste Data Augmentation in Semantic Segmentation for Satellite Imagery (Ionut M. Motoi et al., 2024)

{{<citation>}}

Ionut M. Motoi, Leonardo Saraceni, Daniele Nardi, Thomas A. Ciarfuglia. (2024)  
**Evaluating the Efficacy of Cut-and-Paste Data Augmentation in Semantic Segmentation for Satellite Imagery**
<br/>
<button class="copy-to-clipboard" title="Evaluating the Efficacy of Cut-and-Paste Data Augmentation in Semantic Segmentation for Satellite Imagery" index=101>
  <span class="copy-to-clipboard-item">Copy Title<span>
</button>
<div class="toast toast-copied toast-index-101 align-items-center text-bg-secondary border-0 position-absolute top-0 end-0" role="alert" aria-live="assertive" aria-atomic="true">
  <div class="d-flex">
    <div class="toast-body">
      Copied!
    </div>
  </div>
</div>

---
Primary Category: cs.CV  
Categories: cs-CV, cs-LG, cs.CV, eess-IV  
Keyword Score: 10  
Keywords: Data Augmentation  
<a type="button" class="btn btn-outline-primary" href="http://arxiv.org/abs/2404.05693v1" target="_blank" >Paper Link</a>
<button type="button" class="btn btn-outline-primary download-pdf" url="https://arxiv.org/pdf/2404.05693v1.pdf" filename="2404.05693v1.pdf">Download PDF</button>

---


**ABSTRACT**  
Satellite imagery is crucial for tasks like environmental monitoring and urban planning. Typically, it relies on semantic segmentation or Land Use Land Cover (LULC) classification to categorize each pixel. Despite the advancements brought about by Deep Neural Networks (DNNs), their performance in segmentation tasks is hindered by challenges such as limited availability of labeled <b>data,</b> <b>class</b> imbalance and the inherent variability and complexity of satellite images. In order to mitigate those issues, our study explores the effectiveness of a Cut-and-Paste augmentation technique for semantic segmentation in satellite images. We adapt this augmentation, which usually requires labeled instances, to the case of semantic segmentation. By leveraging the connected components in the semantic segmentation labels, we extract instances that are then randomly pasted during training. Using the DynamicEarthNet dataset and a U-Net model for evaluation, we found that this augmentation significantly enhances the mIoU score on the test set from 37.9 to 44.1. This finding highlights the potential of the Cut-and-Paste augmentation to improve the generalization capabilities of semantic segmentation models in satellite imagery.

{{</citation>}}


### (59/76 | 102/266) Normalizing Flows on the Product Space of SO(3) Manifolds for Probabilistic Human Pose Modeling (Olaf Dünkel et al., 2024)

{{<citation>}}

Olaf Dünkel, Tim Salzmann, Florian Pfaff. (2024)  
**Normalizing Flows on the Product Space of SO(3) Manifolds for Probabilistic Human Pose Modeling**
<br/>
<button class="copy-to-clipboard" title="Normalizing Flows on the Product Space of SO(3) Manifolds for Probabilistic Human Pose Modeling" index=102>
  <span class="copy-to-clipboard-item">Copy Title<span>
</button>
<div class="toast toast-copied toast-index-102 align-items-center text-bg-secondary border-0 position-absolute top-0 end-0" role="alert" aria-live="assertive" aria-atomic="true">
  <div class="d-flex">
    <div class="toast-body">
      Copied!
    </div>
  </div>
</div>

---
Primary Category: cs.CV  
Categories: cs-CV, cs.CV  
Keyword Score: 10  
Keywords: Probabilistic Model  
<a type="button" class="btn btn-outline-primary" href="http://arxiv.org/abs/2404.05675v1" target="_blank" >Paper Link</a>
<button type="button" class="btn btn-outline-primary download-pdf" url="https://arxiv.org/pdf/2404.05675v1.pdf" filename="2404.05675v1.pdf">Download PDF</button>

---


**ABSTRACT**  
Normalizing flows have proven their efficacy for density estimation in Euclidean space, but their application to rotational representations, crucial in various domains such as robotics or human pose modeling, remains underexplored. <b>Probabilistic</b> <b>models</b> of the human pose can benefit from approaches that rigorously consider the rotational nature of human joints. For this purpose, we introduce HuProSO3, a normalizing flow model that operates on a high-dimensional product space of SO(3) manifolds, modeling the joint distribution for human joints with three degrees of freedom. HuProSO3's advantage over state-of-the-art approaches is demonstrated through its superior modeling accuracy in three different applications and its capability to evaluate the exact likelihood. This work not only addresses the technical challenge of learning densities on SO(3) manifolds, but it also has broader implications for domains where the <b>probabilistic</b> <b>regression</b> of correlated 3D rotations is of importance.

{{</citation>}}


### (60/76 | 103/266) AlignZeg: Mitigating Objective Misalignment for Zero-shot Semantic Segmentation (Jiannan Ge et al., 2024)

{{<citation>}}

Jiannan Ge, Lingxi Xie, Hongtao Xie, Pandeng Li, Xiaopeng Zhang, Yongdong Zhang, Qi Tian. (2024)  
**AlignZeg: Mitigating Objective Misalignment for Zero-shot Semantic Segmentation**
<br/>
<button class="copy-to-clipboard" title="AlignZeg: Mitigating Objective Misalignment for Zero-shot Semantic Segmentation" index=103>
  <span class="copy-to-clipboard-item">Copy Title<span>
</button>
<div class="toast toast-copied toast-index-103 align-items-center text-bg-secondary border-0 position-absolute top-0 end-0" role="alert" aria-live="assertive" aria-atomic="true">
  <div class="d-flex">
    <div class="toast-body">
      Copied!
    </div>
  </div>
</div>

---
Primary Category: cs.CV  
Categories: cs-CV, cs.CV  
Keyword Score: 10  
Keywords: Zero-shot  
<a type="button" class="btn btn-outline-primary" href="http://arxiv.org/abs/2404.05667v1" target="_blank" >Paper Link</a>
<button type="button" class="btn btn-outline-primary download-pdf" url="https://arxiv.org/pdf/2404.05667v1.pdf" filename="2404.05667v1.pdf">Download PDF</button>

---


**ABSTRACT**  
A serious issue that harms the performance of <b>zero-shot</b> visual recognition is named objective misalignment, i.e., the learning objective prioritizes improving the recognition accuracy of seen classes rather than unseen classes, while the latter is the true target to pursue. This issue becomes more significant in <b>zero-shot</b> image segmentation because the stronger (i.e., pixel-level) supervision brings a larger gap between seen and unseen classes. To mitigate it, we propose a novel architecture named AlignZeg, which embodies a comprehensive improvement of the segmentation pipeline, including proposal extraction, classification, and correction, to better fit the goal of <b>zero-shot</b> segmentation. (1) Mutually-Refined Proposal Extraction. AlignZeg harnesses a mutual interaction between mask queries and visual features, facilitating detailed class-agnostic mask proposal extraction. (2) Generalization-Enhanced Proposal Classification. AlignZeg introduces synthetic data and incorporates multiple background prototypes to allocate a more generalizable feature space. (3) Predictive Bias Correction. During the inference stage, AlignZeg uses a class indicator to find potential unseen class proposals followed by a prediction postprocess to correct the prediction bias. Experiments demonstrate that AlignZeg markedly enhances <b>zero-shot</b> semantic segmentation, as shown by an average 3.8% increase in hIoU, primarily attributed to a 7.1% improvement in identifying unseen classes, and we further validate that the improvement comes from alleviating the objective misalignment issue.

{{</citation>}}


### (61/76 | 104/266) A Training-Free Plug-and-Play Watermark Framework for Stable Diffusion (Guokai Zhang et al., 2024)

{{<citation>}}

Guokai Zhang, Lanjun Wang, Yuting Su, An-An Liu. (2024)  
**A Training-Free Plug-and-Play Watermark Framework for Stable Diffusion**
<br/>
<button class="copy-to-clipboard" title="A Training-Free Plug-and-Play Watermark Framework for Stable Diffusion" index=104>
  <span class="copy-to-clipboard-item">Copy Title<span>
</button>
<div class="toast toast-copied toast-index-104 align-items-center text-bg-secondary border-0 position-absolute top-0 end-0" role="alert" aria-live="assertive" aria-atomic="true">
  <div class="d-flex">
    <div class="toast-body">
      Copied!
    </div>
  </div>
</div>

---
Primary Category: cs.CV  
Categories: cs-CV, cs.CV  
Keyword Score: 10  
Keywords: Security  
<a type="button" class="btn btn-outline-primary" href="http://arxiv.org/abs/2404.05607v1" target="_blank" >Paper Link</a>
<button type="button" class="btn btn-outline-primary download-pdf" url="https://arxiv.org/pdf/2404.05607v1.pdf" filename="2404.05607v1.pdf">Download PDF</button>

---


**ABSTRACT**  
Nowadays, the family of Stable Diffusion (SD) models has gained prominence for its high quality outputs and scalability. This has also raised <b>security</b> concerns on social media, as malicious users can create and disseminate harmful content. Existing approaches involve training components or entire SDs to embed a watermark in generated images for traceability and responsibility attribution. However, in the era of AI-generated content (AIGC), the rapid iteration of SDs renders retraining with watermark models costly. To address this, we propose a training-free plug-and-play watermark framework for SDs. Without modifying any components of SDs, we embed diverse watermarks in the latent space, adapting to the denoising process. Our experimental findings reveal that our method effectively harmonizes image quality and watermark invisibility. Furthermore, it performs robustly under various attacks. We also have validated that our method is generalized to multiple versions of SDs, even without retraining the watermark model.

{{</citation>}}


### (62/76 | 105/266) Enhancing Lip Reading with Multi-Scale Video and Multi-Encoder (He Wang et al., 2024)

{{<citation>}}

He Wang, Pengcheng Guo, Xucheng Wan, Huan Zhou, Lei Xie. (2024)  
**Enhancing Lip Reading with Multi-Scale Video and Multi-Encoder**
<br/>
<button class="copy-to-clipboard" title="Enhancing Lip Reading with Multi-Scale Video and Multi-Encoder" index=105>
  <span class="copy-to-clipboard-item">Copy Title<span>
</button>
<div class="toast toast-copied toast-index-105 align-items-center text-bg-secondary border-0 position-absolute top-0 end-0" role="alert" aria-live="assertive" aria-atomic="true">
  <div class="d-flex">
    <div class="toast-body">
      Copied!
    </div>
  </div>
</div>

---
Primary Category: cs.CV  
Categories: cs-CV, cs.CV  
Keyword Score: 10  
Keywords: Transformer  
<a type="button" class="btn btn-outline-primary" href="http://arxiv.org/abs/2404.05466v1" target="_blank" >Paper Link</a>
<button type="button" class="btn btn-outline-primary download-pdf" url="https://arxiv.org/pdf/2404.05466v1.pdf" filename="2404.05466v1.pdf">Download PDF</button>

---


**ABSTRACT**  
Automatic lip-reading (ALR) aims to automatically transcribe spoken content from a speaker's silent lip motion captured in video. Current mainstream lip-reading approaches only use a single visual encoder to model input videos of a single scale. In this paper, we propose to enhance lipreading by incorporating multi-scale video data and multi-encoder. Specifically, we first propose a novel multi-scale lip extraction algorithm based on the size of the speaker's face and an enhanced ResNet3D visual front-end (VFE) to extract lip features at different scales. For the multi-encoder, in addition to the mainstream <b>Transformer</b> and Conformer, we also incorporate the recently proposed Branchformer and EBranchformer as visual encoders. In the experiments, we explore the influence of different video data scales and encoders on ALR system performance and fuse the texts transcribed by all ALR systems using recognizer output voting error reduction (ROVER). Finally, our proposed approach placed second in the ICME 2024 ChatCLR Challenge Task 2, with a 21.52% reduction in character error rate (CER) compared to the official baseline on the evaluation set.

{{</citation>}}


### (63/76 | 106/266) CLIPping the Limits: Finding the Sweet Spot for Relevant Images in Automated Driving Systems Perception Testing (Philipp Rigoll et al., 2024)

{{<citation>}}

Philipp Rigoll, Laurenz Adolph, Lennart Ries, Eric Sax. (2024)  
**CLIPping the Limits: Finding the Sweet Spot for Relevant Images in Automated Driving Systems Perception Testing**
<br/>
<button class="copy-to-clipboard" title="CLIPping the Limits: Finding the Sweet Spot for Relevant Images in Automated Driving Systems Perception Testing" index=106>
  <span class="copy-to-clipboard-item">Copy Title<span>
</button>
<div class="toast toast-copied toast-index-106 align-items-center text-bg-secondary border-0 position-absolute top-0 end-0" role="alert" aria-live="assertive" aria-atomic="true">
  <div class="d-flex">
    <div class="toast-body">
      Copied!
    </div>
  </div>
</div>

---
Primary Category: cs.CV  
Categories: cs-CV, cs-RO, cs.CV  
Keyword Score: 10  
Keywords: Prompt  
<a type="button" class="btn btn-outline-primary" href="http://arxiv.org/abs/2404.05309v1" target="_blank" >Paper Link</a>
<button type="button" class="btn btn-outline-primary download-pdf" url="https://arxiv.org/pdf/2404.05309v1.pdf" filename="2404.05309v1.pdf">Download PDF</button>

---


**ABSTRACT**  
Perception systems, especially cameras, are the eyes of automated driving systems. Ensuring that they function reliably and robustly is therefore an important building block in the automation of vehicles. There are various approaches to test the perception of automated driving systems. Ultimately, however, it always comes down to the investigation of the behavior of perception systems under specific input data. Camera images are a crucial part of the input data. Image data sets are therefore collected for the testing of automated driving systems, but it is non-trivial to find specific images in these data sets. Thanks to recent developments in neural networks, there are now methods for sorting the images in a data set according to their similarity to a <b>prompt</b> in natural language. In order to further automate the provision of search results, we make a contribution by automating the threshold definition in these sorted results and returning only the images relevant to the <b>prompt</b> as a result. Our focus is on preventing false positives and false negatives equally. It is also important that our method is robust and in the case that our assumptions are not fulfilled, we provide a fallback solution.

{{</citation>}}


### (64/76 | 107/266) Human Detection from 4D Radar Data in Low-Visibility Field Conditions (Mikael Skog et al., 2024)

{{<citation>}}

Mikael Skog, Oleksandr Kotlyar, Vladimír Kubelka, Martin Magnusson. (2024)  
**Human Detection from 4D Radar Data in Low-Visibility Field Conditions**
<br/>
<button class="copy-to-clipboard" title="Human Detection from 4D Radar Data in Low-Visibility Field Conditions" index=107>
  <span class="copy-to-clipboard-item">Copy Title<span>
</button>
<div class="toast toast-copied toast-index-107 align-items-center text-bg-secondary border-0 position-absolute top-0 end-0" role="alert" aria-live="assertive" aria-atomic="true">
  <div class="d-flex">
    <div class="toast-body">
      Copied!
    </div>
  </div>
</div>

---
Primary Category: cs.CV  
Categories: cs-CV, cs-RO, cs.CV  
Keyword Score: 10  
Keywords: Convolutional Neural Network  
<a type="button" class="btn btn-outline-primary" href="http://arxiv.org/abs/2404.05307v1" target="_blank" >Paper Link</a>
<button type="button" class="btn btn-outline-primary download-pdf" url="https://arxiv.org/pdf/2404.05307v1.pdf" filename="2404.05307v1.pdf">Download PDF</button>

---


**ABSTRACT**  
Autonomous driving technology is increasingly being used on public roads and in industrial settings such as mines. While it is essential to detect pedestrians, vehicles, or other obstacles, adverse field conditions negatively affect the performance of classical sensors such as cameras or lidars. Radar, on the other hand, is a promising modality that is less affected by, e.g., dust, smoke, water mist or fog. In particular, modern 4D imaging radars provide target responses across the range, vertical angle, horizontal angle and Doppler velocity dimensions. We propose TMVA4D, a <b>CNN</b> architecture that leverages this 4D radar modality for semantic segmentation. The <b>CNN</b> is trained to distinguish between the background and person classes based on a series of 2D projections of the 4D radar data that include the elevation, azimuth, range, and Doppler velocity dimensions. We also outline the process of compiling a novel dataset consisting of data collected in industrial settings with a car-mounted 4D radar and describe how the ground-truth labels were generated from reference thermal images. Using TMVA4D on this dataset, we achieve an mIoU score of 78.2% and an mDice score of 86.1%, evaluated on the two classes background and person

{{</citation>}}


### (65/76 | 108/266) Lightweight Deep Learning for Resource-Constrained Environments: A Survey (Hou-I Liu et al., 2024)

{{<citation>}}

Hou-I Liu, Marco Galindo, Hongxia Xie, Lai-Kuan Wong, Hong-Han Shuai, Yung-Yui Li, Wen-Huang Cheng. (2024)  
**Lightweight Deep Learning for Resource-Constrained Environments: A Survey**
<br/>
<button class="copy-to-clipboard" title="Lightweight Deep Learning for Resource-Constrained Environments: A Survey" index=108>
  <span class="copy-to-clipboard-item">Copy Title<span>
</button>
<div class="toast toast-copied toast-index-108 align-items-center text-bg-secondary border-0 position-absolute top-0 end-0" role="alert" aria-live="assertive" aria-atomic="true">
  <div class="d-flex">
    <div class="toast-body">
      Copied!
    </div>
  </div>
</div>

---
Primary Category: cs.CV  
Categories: cs-CV, cs-LG, cs.CV  
Keyword Score: 10  
Keywords: Large Language Model  
<a type="button" class="btn btn-outline-primary" href="http://arxiv.org/abs/2404.07236v1" target="_blank" >Paper Link</a>
<button type="button" class="btn btn-outline-primary download-pdf" url="https://arxiv.org/pdf/2404.07236v1.pdf" filename="2404.07236v1.pdf">Download PDF</button>

---


**ABSTRACT**  
Over the past decade, the dominance of deep learning has prevailed across various domains of artificial intelligence, including natural language processing, computer vision, and biomedical signal processing. While there have been remarkable improvements in model accuracy, deploying these models on lightweight devices, such as mobile phones and microcontrollers, is constrained by limited resources. In this survey, we provide comprehensive design guidance tailored for these devices, detailing the meticulous design of lightweight models, compression methods, and hardware acceleration strategies. The principal goal of this work is to explore methods and concepts for getting around hardware constraints without compromising the model's accuracy. Additionally, we explore two notable paths for lightweight deep learning in the future: deployment techniques for TinyML and <b>Large</b> <b>Language</b> <b>Models.</b> Although these paths undoubtedly have potential, they also present significant challenges, encouraging research into unexplored areas.

{{</citation>}}


### (66/76 | 109/266) Deep Optics for Video Snapshot Compressive Imaging (Ping Wang et al., 2024)

{{<citation>}}

Ping Wang, Lishun Wang, Xin Yuan. (2024)  
**Deep Optics for Video Snapshot Compressive Imaging**
<br/>
<button class="copy-to-clipboard" title="Deep Optics for Video Snapshot Compressive Imaging" index=109>
  <span class="copy-to-clipboard-item">Copy Title<span>
</button>
<div class="toast toast-copied toast-index-109 align-items-center text-bg-secondary border-0 position-absolute top-0 end-0" role="alert" aria-live="assertive" aria-atomic="true">
  <div class="d-flex">
    <div class="toast-body">
      Copied!
    </div>
  </div>
</div>

---
Primary Category: cs.CV  
Categories: cs-CV, cs.CV  
Keyword Score: 10  
Keywords: Transformer  
<a type="button" class="btn btn-outline-primary" href="http://arxiv.org/abs/2404.05274v1" target="_blank" >Paper Link</a>
<button type="button" class="btn btn-outline-primary download-pdf" url="https://arxiv.org/pdf/2404.05274v1.pdf" filename="2404.05274v1.pdf">Download PDF</button>

---


**ABSTRACT**  
Video snapshot compressive imaging (SCI) aims to capture a sequence of video frames with only a single shot of a 2D detector, whose backbones rest in optical modulation patterns (also known as masks) and a computational reconstruction algorithm. Advanced deep learning algorithms and mature hardware are putting video SCI into practical applications. Yet, there are two clouds in the sunshine of SCI: i) low dynamic range as a victim of high temporal multiplexing, and ii) existing deep learning algorithms' degradation on real system. To address these challenges, this paper presents a deep optics framework to jointly optimize masks and a reconstruction network. Specifically, we first propose a new type of structural mask to realize motion-aware and full-dynamic-range measurement. Considering the motion awareness property in measurement domain, we develop an efficient network for video SCI reconstruction using <b>Transformer</b> to capture long-term temporal dependencies, dubbed Res2former. Moreover, sensor response is introduced into the forward model of video SCI to guarantee end-to-end model training close to real system. Finally, we implement the learned structural masks on a digital micro-mirror device. Experimental results on synthetic and real data validate the effectiveness of the proposed framework. We believe this is a milestone for real-world video SCI. The source code and data are available at https://github.com/pwangcs/DeepOpticsSCI.

{{</citation>}}


### (67/76 | 110/266) Allowing humans to interactively guide machines where to look does not always improve a human-AI team's classification accuracy (Giang Nguyen et al., 2024)

{{<citation>}}

Giang Nguyen, Mohammad Reza Taesiri, Sunnie S. Y. Kim, Anh Nguyen. (2024)  
**Allowing humans to interactively guide machines where to look does not always improve a human-AI team's classification accuracy**
<br/>
<button class="copy-to-clipboard" title="Allowing humans to interactively guide machines where to look does not always improve a human-AI team's classification accuracy" index=110>
  <span class="copy-to-clipboard-item">Copy Title<span>
</button>
<div class="toast toast-copied toast-index-110 align-items-center text-bg-secondary border-0 position-absolute top-0 end-0" role="alert" aria-live="assertive" aria-atomic="true">
  <div class="d-flex">
    <div class="toast-body">
      Copied!
    </div>
  </div>
</div>

---
Primary Category: cs.CV  
Categories: cs-CV, cs-HC, cs.CV  
Keyword Score: 10  
Keywords: Explainable AI  
<a type="button" class="btn btn-outline-primary" href="http://arxiv.org/abs/2404.05238v1" target="_blank" >Paper Link</a>
<button type="button" class="btn btn-outline-primary download-pdf" url="https://arxiv.org/pdf/2404.05238v1.pdf" filename="2404.05238v1.pdf">Download PDF</button>

---


**ABSTRACT**  
Via thousands of papers in <b>Explainable</b> <b>AI</b> (XAI), attention maps \cite{vaswani2017attention} and feature attribution maps \cite{bansal2020sam} have been established as a common means for explaining the input features that are important to AI's decisions. It is an interesting but unexplored question whether allowing users to edit the importance scores of input features at test time would improve the human-AI team's accuracy on downstream tasks. In this paper, we address this question by taking CHM-Corr, a state-of-the-art, ante-hoc explanation method \cite{taesiri2022visual} that first predicts patch-wise correspondences between the input and the training-set images, and then uses them to make classification decisions. We build an interactive interface on top of CHM-Corr, enabling users to directly edit the initial feature attribution map provided by CHM-Corr. Via our CHM-Corr++ interface, users gain insights into if, when, and how the model changes its outputs, enhancing understanding beyond static explanations. Our user study with 18 machine learning researchers who performed $\sim$1,400 decisions shows that our interactive approach does not improve user accuracy on CUB-200 bird image classification over static explanations. This challenges the belief that interactivity inherently boosts XAI effectiveness~\cite{sokol2020one,sun2022exploring,shen2024towards,singh2024rethinking,mindlin2024beyond,lakkaraju2022rethinking,cheng2019explaining,liu2021understanding} and raises needs for future research. Our work contributes to the field by open-sourcing an interactive tool for manipulating model attention, and it lays the groundwork for future research to enable effective human-AI interaction in computer vision. We release code and data on \href{https://anonymous.4open.science/r/CHMCorrPlusPlus/}{github}. Our interface are available \href{http://137.184.82.109:7080/}{here}.

{{</citation>}}


### (68/76 | 111/266) Spatio-Temporal Attention and Gaussian Processes for Personalized Video Gaze Estimation (Swati Jindal et al., 2024)

{{<citation>}}

Swati Jindal, Mohit Yadav, Roberto Manduchi. (2024)  
**Spatio-Temporal Attention and Gaussian Processes for Personalized Video Gaze Estimation**
<br/>
<button class="copy-to-clipboard" title="Spatio-Temporal Attention and Gaussian Processes for Personalized Video Gaze Estimation" index=111>
  <span class="copy-to-clipboard-item">Copy Title<span>
</button>
<div class="toast toast-copied toast-index-111 align-items-center text-bg-secondary border-0 position-absolute top-0 end-0" role="alert" aria-live="assertive" aria-atomic="true">
  <div class="d-flex">
    <div class="toast-body">
      Copied!
    </div>
  </div>
</div>

---
Primary Category: cs.CV  
Categories: cs-CV, cs.CV  
Keyword Score: 10  
Keywords: Prompt  
<a type="button" class="btn btn-outline-primary" href="http://arxiv.org/abs/2404.05215v2" target="_blank" >Paper Link</a>
<button type="button" class="btn btn-outline-primary download-pdf" url="https://arxiv.org/pdf/2404.05215v2.pdf" filename="2404.05215v2.pdf">Download PDF</button>

---


**ABSTRACT**  
Gaze is an essential <b>prompt</b> for analyzing human behavior and attention. Recently, there has been an increasing interest in determining gaze direction from facial videos. However, video gaze estimation faces significant challenges, such as understanding the dynamic evolution of gaze in video sequences, dealing with static backgrounds, and adapting to variations in illumination. To address these challenges, we propose a simple and novel deep learning model designed to estimate gaze from videos, incorporating a specialized attention module. Our method employs a spatial attention mechanism that tracks spatial dynamics within videos. This technique enables accurate gaze direction prediction through a temporal sequence model, adeptly transforming spatial observations into temporal insights, thereby significantly improving gaze estimation accuracy. Additionally, our approach integrates Gaussian processes to include individual-specific traits, facilitating the personalization of our model with just a few labeled samples. Experimental results confirm the efficacy of the proposed approach, demonstrating its success in both within-dataset and cross-dataset settings. Specifically, our proposed approach achieves state-of-the-art performance on the Gaze360 dataset, improving by $2.5^\circ$ without personalization. Further, by personalizing the model with just three samples, we achieved an additional improvement of $0.8^\circ$. The code and pre-trained models are available at \url{https://github.com/jswati31/stage}.

{{</citation>}}


### (69/76 | 112/266) QMix: Quality-aware Learning with Mixed Noise for Robust Retinal Disease Diagnosis (Junlin Hou et al., 2024)

{{<citation>}}

Junlin Hou, Jilan Xu, Rui Feng, Hao Chen. (2024)  
**QMix: Quality-aware Learning with Mixed Noise for Robust Retinal Disease Diagnosis**
<br/>
<button class="copy-to-clipboard" title="QMix: Quality-aware Learning with Mixed Noise for Robust Retinal Disease Diagnosis" index=112>
  <span class="copy-to-clipboard-item">Copy Title<span>
</button>
<div class="toast toast-copied toast-index-112 align-items-center text-bg-secondary border-0 position-absolute top-0 end-0" role="alert" aria-live="assertive" aria-atomic="true">
  <div class="d-flex">
    <div class="toast-body">
      Copied!
    </div>
  </div>
</div>

---
Primary Category: cs.CV  
Categories: cs-CV, cs.CV  
Keyword Score: 10  
Keywords: Semi-Supervised Training  
<a type="button" class="btn btn-outline-primary" href="http://arxiv.org/abs/2404.05169v1" target="_blank" >Paper Link</a>
<button type="button" class="btn btn-outline-primary download-pdf" url="https://arxiv.org/pdf/2404.05169v1.pdf" filename="2404.05169v1.pdf">Download PDF</button>

---


**ABSTRACT**  
Due to the complexity of medical image acquisition and the difficulty of annotation, medical image datasets inevitably contain noise. Noisy data with wrong labels affects the robustness and generalization ability of deep neural networks. Previous noise learning methods mainly considered noise arising from images being mislabeled, i.e. label noise, assuming that all mislabeled images are of high image quality. However, medical images are prone to suffering extreme quality issues, i.e. data noise, where discriminative visual features are missing for disease diagnosis. In this paper, we propose a noise learning framework, termed as QMix, that learns a robust disease diagnosis model under mixed noise. QMix alternates between sample separation and quality-aware <b>semisupervised</b> <b>training</b> in each training epoch. In the sample separation phase, we design a joint uncertainty-loss criterion to effectively separate (1) correctly labeled images; (2) mislabeled images with high quality and (3) mislabeled images with low quality. In the <b>semi-supervised</b> <b>training</b> phase, we train a disease diagnosis model to learn robust feature representation from the separated samples. Specifically, we devise a sample-reweighing loss to mitigate the effect of mislabeled images with low quality during training. Meanwhile, a contrastive enhancement loss is proposed to further distinguish mislabeled images with low quality from correctly labeled images. QMix achieved state-of-the-art disease diagnosis performance on five public retinal image datasets and exhibited substantial improvement on robustness against mixed noise.

{{</citation>}}


### (70/76 | 113/266) Better Monocular 3D Detectors with LiDAR from the Past (Yurong You et al., 2024)

{{<citation>}}

Yurong You, Cheng Perng Phoo, Carlos Andres Diaz-Ruiz, Katie Z Luo, Wei-Lun Chao, Mark Campbell, Bharath Hariharan, Kilian Q Weinberger. (2024)  
**Better Monocular 3D Detectors with LiDAR from the Past**
<br/>
<button class="copy-to-clipboard" title="Better Monocular 3D Detectors with LiDAR from the Past" index=113>
  <span class="copy-to-clipboard-item">Copy Title<span>
</button>
<div class="toast toast-copied toast-index-113 align-items-center text-bg-secondary border-0 position-absolute top-0 end-0" role="alert" aria-live="assertive" aria-atomic="true">
  <div class="d-flex">
    <div class="toast-body">
      Copied!
    </div>
  </div>
</div>

---
Primary Category: cs.CV  
Categories: cs-CV, cs-RO, cs.CV  
Keyword Score: 10  
Keywords: Object Detection  
<a type="button" class="btn btn-outline-primary" href="http://arxiv.org/abs/2404.05139v2" target="_blank" >Paper Link</a>
<button type="button" class="btn btn-outline-primary download-pdf" url="https://arxiv.org/pdf/2404.05139v2.pdf" filename="2404.05139v2.pdf">Download PDF</button>

---


**ABSTRACT**  
Accurate 3D <b>object</b> <b>detection</b> is crucial to autonomous driving. Though LiDAR-based detectors have achieved impressive performance, the high cost of LiDAR sensors precludes their widespread adoption in affordable vehicles. Camera-based detectors are cheaper alternatives but often suffer inferior performance compared to their LiDAR-based counterparts due to inherent depth ambiguities in images. In this work, we seek to improve monocular 3D detectors by leveraging unlabeled historical LiDAR data. Specifically, at inference time, we assume that the camera-based detectors have access to multiple unlabeled LiDAR scans from past traversals at locations of interest (potentially from other high-end vehicles equipped with LiDAR sensors). Under this setup, we proposed a novel, simple, and end-to-end trainable framework, termed AsyncDepth, to effectively extract relevant features from asynchronous LiDAR traversals of the same location for monocular 3D detectors. We show consistent and significant performance gain (up to 9 AP) across multiple state-of-the-art models and datasets with a negligible additional latency of 9.66 ms and a small storage cost.

{{</citation>}}


### (71/76 | 114/266) Class Similarity Transition: Decoupling Class Similarities and Imbalance from Generalized Few-shot Segmentation (Shihong Wang et al., 2024)

{{<citation>}}

Shihong Wang, Ruixun Liu, Kaiyu Li, Jiawei Jiang, Xiangyong Cao. (2024)  
**Class Similarity Transition: Decoupling Class Similarities and Imbalance from Generalized Few-shot Segmentation**
<br/>
<button class="copy-to-clipboard" title="Class Similarity Transition: Decoupling Class Similarities and Imbalance from Generalized Few-shot Segmentation" index=114>
  <span class="copy-to-clipboard-item">Copy Title<span>
</button>
<div class="toast toast-copied toast-index-114 align-items-center text-bg-secondary border-0 position-absolute top-0 end-0" role="alert" aria-live="assertive" aria-atomic="true">
  <div class="d-flex">
    <div class="toast-body">
      Copied!
    </div>
  </div>
</div>

---
Primary Category: cs.CV  
Categories: cs-CV, cs.CV  
Keyword Score: 10  
Keywords: Few-shot  
<a type="button" class="btn btn-outline-primary" href="http://arxiv.org/abs/2404.05111v1" target="_blank" >Paper Link</a>
<button type="button" class="btn btn-outline-primary download-pdf" url="https://arxiv.org/pdf/2404.05111v1.pdf" filename="2404.05111v1.pdf">Download PDF</button>

---


**ABSTRACT**  
In Generalized <b>Few-shot</b> Segmentation (GFSS), a model is trained with a large corpus of base class samples and then adapted on limited samples of novel classes. This paper focuses on the relevance between base and novel classes, and improves GFSS in two aspects: 1) mining the similarity between base and novel classes to promote the learning of novel classes, and 2) mitigating the class imbalance issue caused by the volume difference between the support set and the training set. Specifically, we first propose a similarity transition matrix to guide the learning of novel classes with base class knowledge. Then, we leverage the Label-Distribution-Aware Margin (LDAM) loss and Transductive Inference to the GFSS task to address the problem of class imbalance as well as overfitting the support set. In addition, by extending the probability transition matrix, the proposed method can mitigate the catastrophic forgetting of base classes when learning novel classes. With a simple training phase, our proposed method can be applied to any segmentation network trained on base classes. We validated our methods on the adapted version of OpenEarthMap. Compared to existing GFSS baselines, our method excels them all from 3% to 7% and ranks second in the OpenEarthMap Land Cover Mapping <b>Few-Shot</b> Challenge at the completion of this paper. Code: https://github.com/earth-insights/ClassTrans

{{</citation>}}


### (72/76 | 115/266) Responsible Visual Editing (Minheng Ni et al., 2024)

{{<citation>}}

Minheng Ni, Yeli Shen, Lei Zhang, Wangmeng Zuo. (2024)  
**Responsible Visual Editing**
<br/>
<button class="copy-to-clipboard" title="Responsible Visual Editing" index=115>
  <span class="copy-to-clipboard-item">Copy Title<span>
</button>
<div class="toast toast-copied toast-index-115 align-items-center text-bg-secondary border-0 position-absolute top-0 end-0" role="alert" aria-live="assertive" aria-atomic="true">
  <div class="d-flex">
    <div class="toast-body">
      Copied!
    </div>
  </div>
</div>

---
Primary Category: cs.CV  
Categories: cs-CV, cs.CV  
Keyword Score: 9  
Keywords: Benchmarking, Multi-modal, Multi-modal  
<a type="button" class="btn btn-outline-primary" href="http://arxiv.org/abs/2404.05580v1" target="_blank" >Paper Link</a>
<button type="button" class="btn btn-outline-primary download-pdf" url="https://arxiv.org/pdf/2404.05580v1.pdf" filename="2404.05580v1.pdf">Download PDF</button>

---


**ABSTRACT**  
With recent advancements in visual synthesis, there is a growing risk of encountering images with detrimental effects, such as hate, discrimination, or privacy violations. The research on transforming harmful images into responsible ones remains unexplored. In this paper, we formulate a new task, responsible visual editing, which entails modifying specific concepts within an image to render it more responsible while minimizing changes. However, the concept that needs to be edited is often abstract, making it challenging to locate what needs to be modified and plan how to modify it. To tackle these challenges, we propose a Cognitive Editor (CoEditor) that harnesses the large <b>multimodal</b> model through a two-stage cognitive process: (1) a perceptual cognitive process to focus on what needs to be modified and (2) a behavioral cognitive process to strategize how to modify. To mitigate the negative implications of harmful images on research, we create a transparent and public dataset, AltBear, which expresses harmful information using teddy bears instead of humans. Experiments demonstrate that CoEditor can effectively comprehend abstract concepts within complex scenes and significantly surpass the performance of baseline models for responsible visual editing. We find that the AltBear dataset corresponds well to the harmful content found in real images, offering a consistent experimental evaluation, thereby providing a safer <b>benchmark</b> for future research. Moreover, CoEditor also shows great results in general editing. We release our code and dataset at https://github.com/kodenii/Responsible-Visual-Editing.

{{</citation>}}


### (73/76 | 116/266) Multi-agent Long-term 3D Human Pose Forecasting via Interaction-aware Trajectory Conditioning (Jaewoo Jeong et al., 2024)

{{<citation>}}

Jaewoo Jeong, Daehee Park, Kuk-Jin Yoon. (2024)  
**Multi-agent Long-term 3D Human Pose Forecasting via Interaction-aware Trajectory Conditioning**
<br/>
<button class="copy-to-clipboard" title="Multi-agent Long-term 3D Human Pose Forecasting via Interaction-aware Trajectory Conditioning" index=116>
  <span class="copy-to-clipboard-item">Copy Title<span>
</button>
<div class="toast toast-copied toast-index-116 align-items-center text-bg-secondary border-0 position-absolute top-0 end-0" role="alert" aria-live="assertive" aria-atomic="true">
  <div class="d-flex">
    <div class="toast-body">
      Copied!
    </div>
  </div>
</div>

---
Primary Category: cs.CV  
Categories: cs-AI, cs-CV, cs.CV  
Keyword Score: 6  
Keywords: Graph, Multi-modal  
<a type="button" class="btn btn-outline-primary" href="http://arxiv.org/abs/2404.05218v1" target="_blank" >Paper Link</a>
<button type="button" class="btn btn-outline-primary download-pdf" url="https://arxiv.org/pdf/2404.05218v1.pdf" filename="2404.05218v1.pdf">Download PDF</button>

---


**ABSTRACT**  
Human pose forecasting garners attention for its diverse applications. However, challenges in modeling the <b>multi-modal</b> nature of human motion and intricate interactions among agents persist, particularly with longer timescales and more agents. In this paper, we propose an interaction-aware trajectory-conditioned long-term multi-agent human pose forecasting model, utilizing a coarse-to-fine prediction approach: <b>multi-modal</b> global trajectories are initially forecasted, followed by respective local pose forecasts conditioned on each mode. In doing so, our Trajectory2Pose model introduces a <b>graph-based</b> agent-wise interaction module for a reciprocal forecast of local motion-conditioned global trajectory and trajectory-conditioned local pose. Our model effectively handles the multi-modality of human motion and the complexity of long-term multi-agent interactions, improving performance in complex environments. Furthermore, we address the lack of long-term (6s+) multi-agent (5+) datasets by constructing a new dataset from real-world images and 2D annotations, enabling a comprehensive evaluation of our proposed model. State-of-the-art prediction performance on both complex and simpler datasets confirms the generalized effectiveness of our method. The code is available at https://github.com/Jaewoo97/T2P.

{{</citation>}}


### (74/76 | 117/266) Learning Topology Uniformed Face Mesh by Volume Rendering for Multi-view Reconstruction (Yating Wang et al., 2024)

{{<citation>}}

Yating Wang, Ran Yi, Ke Fan, Jinkun Hao, Jiangbo Lu, Lizhuang Ma. (2024)  
**Learning Topology Uniformed Face Mesh by Volume Rendering for Multi-view Reconstruction**
<br/>
<button class="copy-to-clipboard" title="Learning Topology Uniformed Face Mesh by Volume Rendering for Multi-view Reconstruction" index=117>
  <span class="copy-to-clipboard-item">Copy Title<span>
</button>
<div class="toast toast-copied toast-index-117 align-items-center text-bg-secondary border-0 position-absolute top-0 end-0" role="alert" aria-live="assertive" aria-atomic="true">
  <div class="d-flex">
    <div class="toast-body">
      Copied!
    </div>
  </div>
</div>

---
Primary Category: cs.CV  
Categories: cs-CV, cs.CV  
Keyword Score: 5  
Keywords: Geometry  
<a type="button" class="btn btn-outline-primary" href="http://arxiv.org/abs/2404.05606v1" target="_blank" >Paper Link</a>
<button type="button" class="btn btn-outline-primary download-pdf" url="https://arxiv.org/pdf/2404.05606v1.pdf" filename="2404.05606v1.pdf">Download PDF</button>

---


**ABSTRACT**  
Face meshes in consistent topology serve as the foundation for many face-related applications, such as 3DMM constrained face reconstruction and expression retargeting. Traditional methods commonly acquire topology uniformed face meshes by two separate steps: multi-view stereo (MVS) to reconstruct shapes followed by non-rigid registration to align topology, but struggles with handling noise and non-lambertian surfaces. Recently neural volume rendering techniques have been rapidly evolved and shown great advantages in 3D reconstruction or novel view synthesis. Our goal is to leverage the superiority of neural volume rendering into multi-view reconstruction of face mesh with consistent topology. We propose a mesh volume rendering method that enables directly optimizing mesh <b>geometry</b> while preserving topology, and learning implicit features to model complex facial appearance from multi-view images. The key innovation lies in spreading sparse mesh features into the surrounding space to simulate radiance field required for volume rendering, which facilitates backpropagation of gradients from images to mesh <b>geometry</b> and implicit appearance features. Our proposed feature spreading module exhibits deformation invariance, enabling photorealistic rendering seamlessly after mesh editing. We conduct experiments on multi-view face image dataset to evaluate the reconstruction and implement an application for photorealistic rendering of animated face mesh.

{{</citation>}}


### (75/76 | 118/266) Two Hands Are Better Than One: Resolving Hand to Hand Intersections via Occupancy Networks (Maksym Ivashechkin et al., 2024)

{{<citation>}}

Maksym Ivashechkin, Oscar Mendez, Richard Bowden. (2024)  
**Two Hands Are Better Than One: Resolving Hand to Hand Intersections via Occupancy Networks**
<br/>
<button class="copy-to-clipboard" title="Two Hands Are Better Than One: Resolving Hand to Hand Intersections via Occupancy Networks" index=118>
  <span class="copy-to-clipboard-item">Copy Title<span>
</button>
<div class="toast toast-copied toast-index-118 align-items-center text-bg-secondary border-0 position-absolute top-0 end-0" role="alert" aria-live="assertive" aria-atomic="true">
  <div class="d-flex">
    <div class="toast-body">
      Copied!
    </div>
  </div>
</div>

---
Primary Category: cs.CV  
Categories: cs-CV, cs.CV  
Keyword Score: 3  
Keywords: Benchmarking  
<a type="button" class="btn btn-outline-primary" href="http://arxiv.org/abs/2404.05414v1" target="_blank" >Paper Link</a>
<button type="button" class="btn btn-outline-primary download-pdf" url="https://arxiv.org/pdf/2404.05414v1.pdf" filename="2404.05414v1.pdf">Download PDF</button>

---


**ABSTRACT**  
3D hand pose estimation from images has seen considerable interest from the literature, with new methods improving overall 3D accuracy. One current challenge is to address hand-to-hand interaction where self-occlusions and finger articulation pose a significant problem to estimation. Little work has applied physical constraints that minimize the hand intersections that occur as a result of noisy estimation. This work addresses the intersection of hands by exploiting an occupancy network that represents the hand's volume as a continuous manifold. This allows us to model the probability distribution of points being inside a hand. We designed an intersection loss function to minimize the likelihood of hand-to-point intersections. Moreover, we propose a new hand mesh parameterization that is superior to the commonly used MANO model in many respects including lower mesh complexity, underlying 3D skeleton extraction, watertightness, etc. On the <b>benchmark</b> InterHand2.6M dataset, the models trained using our intersection loss achieve better results than the state-of-the-art by significantly decreasing the number of hand intersections while lowering the mean per-joint positional error. Additionally, we demonstrate superior performance for 3D hand uplift on Re:InterHand and SMILE datasets and show reduced hand-to-hand intersections for complex domains such as sign-language pose estimation.

{{</citation>}}


### (76/76 | 119/266) Adaptive Learning for Multi-view Stereo Reconstruction (Qinglu Min et al., 2024)

{{<citation>}}

Qinglu Min, Jie Zhao, Zhihao Zhang, Chen Min. (2024)  
**Adaptive Learning for Multi-view Stereo Reconstruction**
<br/>
<button class="copy-to-clipboard" title="Adaptive Learning for Multi-view Stereo Reconstruction" index=119>
  <span class="copy-to-clipboard-item">Copy Title<span>
</button>
<div class="toast toast-copied toast-index-119 align-items-center text-bg-secondary border-0 position-absolute top-0 end-0" role="alert" aria-live="assertive" aria-atomic="true">
  <div class="d-flex">
    <div class="toast-body">
      Copied!
    </div>
  </div>
</div>

---
Primary Category: cs.CV  
Categories: cs-CV, cs.CV  
Keyword Score: 3  
Keywords: Benchmarking  
<a type="button" class="btn btn-outline-primary" href="http://arxiv.org/abs/2404.05181v1" target="_blank" >Paper Link</a>
<button type="button" class="btn btn-outline-primary download-pdf" url="https://arxiv.org/pdf/2404.05181v1.pdf" filename="2404.05181v1.pdf">Download PDF</button>

---


**ABSTRACT**  
Deep learning has recently demonstrated its excellent performance on the task of multi-view stereo (MVS). However, loss functions applied for deep MVS are rarely studied. In this paper, we first analyze existing loss functions' properties for deep depth based MVS approaches. Regression based loss leads to inaccurate continuous results by computing mathematical expectation, while classification based loss outputs discretized depth values. To this end, we then propose a novel loss function, named adaptive Wasserstein loss, which is able to narrow down the difference between the true and predicted probability distributions of depth. Besides, a simple but effective offset module is introduced to better achieve sub-pixel prediction accuracy. Extensive experiments on different <b>benchmarks,</b> including DTU, Tanks and Temples and BlendedMVS, show that the proposed method with the adaptive Wasserstein loss and the offset module achieves state-of-the-art performance.

{{</citation>}}


## cs.IT (8)



### (1/8 | 120/266) Cell-Free Multi-User MIMO Equalization via In-Context Learning (Matteo Zecchin et al., 2024)

{{<citation>}}

Matteo Zecchin, Kai Yu, Osvaldo Simeone. (2024)  
**Cell-Free Multi-User MIMO Equalization via In-Context Learning**
<br/>
<button class="copy-to-clipboard" title="Cell-Free Multi-User MIMO Equalization via In-Context Learning" index=120>
  <span class="copy-to-clipboard-item">Copy Title<span>
</button>
<div class="toast toast-copied toast-index-120 align-items-center text-bg-secondary border-0 position-absolute top-0 end-0" role="alert" aria-live="assertive" aria-atomic="true">
  <div class="d-flex">
    <div class="toast-body">
      Copied!
    </div>
  </div>
</div>

---
Primary Category: cs.IT  
Categories: cs-IT, cs-LG, cs.IT, eess-SP, math-IT  
Keyword Score: 70  
Keywords: Few-shot, Quantization, Transformer, In-context Learning, In-context Learning, In-context Learning, Prompt  
<a type="button" class="btn btn-outline-primary" href="http://arxiv.org/abs/2404.05538v2" target="_blank" >Paper Link</a>
<button type="button" class="btn btn-outline-primary download-pdf" url="https://arxiv.org/pdf/2404.05538v2.pdf" filename="2404.05538v2.pdf">Download PDF</button>

---


**ABSTRACT**  
Large pre-trained sequence models, such as <b>transformers,</b> excel as <b>few-shot</b> learners capable of <b>in-context</b> <b>learning</b> <b>(ICL).</b> In <b>ICL,</b> a model is trained to adapt its operation to a new task based on limited contextual information, typically in the form of a few training examples for the given task. Previous work has explored the use of <b>ICL</b> for channel equalization in single-user multi-input and multiple-output (MIMO) systems. In this work, we demonstrate that <b>ICL</b> can be also used to tackle the problem of multi-user equalization in cell-free MIMO systems with limited fronthaul capacity. In this scenario, a task is defined by channel statistics, signal-to-noise ratio, and modulation schemes. The context encompasses the users' pilot sequences, the corresponding <b>quantized</b> received signals, and the current received data signal. Different <b>prompt</b> design strategies are proposed and evaluated that encompass also large-scale fading and modulation information. Experiments demonstrate that <b>ICL-based</b> equalization provides estimates with lower mean squared error as compared to the linear minimum mean squared error equalizer, especially in the presence of limited fronthaul capacity and pilot contamination.

{{</citation>}}


### (2/8 | 121/266) Coherent transceiver architecture enabling data transmission and optical identification (Stella Civelli et al., 2024)

{{<citation>}}

Stella Civelli, Marco Secondini, Pantea Nadimi Goki, Luca Potì. (2024)  
**Coherent transceiver architecture enabling data transmission and optical identification**
<br/>
<button class="copy-to-clipboard" title="Coherent transceiver architecture enabling data transmission and optical identification" index=121>
  <span class="copy-to-clipboard-item">Copy Title<span>
</button>
<div class="toast toast-copied toast-index-121 align-items-center text-bg-secondary border-0 position-absolute top-0 end-0" role="alert" aria-live="assertive" aria-atomic="true">
  <div class="d-flex">
    <div class="toast-body">
      Copied!
    </div>
  </div>
</div>

---
Primary Category: cs.IT  
Categories: cs-IT, cs.IT, math-IT  
Keyword Score: 30  
Keywords: Simulation, Simulator, Security  
<a type="button" class="btn btn-outline-primary" href="http://arxiv.org/abs/2404.05278v1" target="_blank" >Paper Link</a>
<button type="button" class="btn btn-outline-primary download-pdf" url="https://arxiv.org/pdf/2404.05278v1.pdf" filename="2404.05278v1.pdf">Download PDF</button>

---


**ABSTRACT**  
We propose a coherent transceiver architecture able to transmit information and enhance the <b>security</b> of the optical network by identifying other optical systems and subsystems. <b>Simulations</b> show that identification is obtained with sufficient reliability in standard operating conditions.

{{</citation>}}


### (3/8 | 122/266) Interference Reduction Design for Improved Multitarget Detection in ISAC Systems (Mamady Delamou et al., 2024)

{{<citation>}}

Mamady Delamou, El Mehdi Amhoud. (2024)  
**Interference Reduction Design for Improved Multitarget Detection in ISAC Systems**
<br/>
<button class="copy-to-clipboard" title="Interference Reduction Design for Improved Multitarget Detection in ISAC Systems" index=122>
  <span class="copy-to-clipboard-item">Copy Title<span>
</button>
<div class="toast toast-copied toast-index-122 align-items-center text-bg-secondary border-0 position-absolute top-0 end-0" role="alert" aria-live="assertive" aria-atomic="true">
  <div class="d-flex">
    <div class="toast-body">
      Copied!
    </div>
  </div>
</div>

---
Primary Category: cs.IT  
Categories: cs-IT, cs.IT, eess-SP, math-IT  
Keyword Score: 20  
Keywords: Simulation, Simulator  
<a type="button" class="btn btn-outline-primary" href="http://arxiv.org/abs/2404.05895v1" target="_blank" >Paper Link</a>
<button type="button" class="btn btn-outline-primary download-pdf" url="https://arxiv.org/pdf/2404.05895v1.pdf" filename="2404.05895v1.pdf">Download PDF</button>

---


**ABSTRACT**  
The advancement of wireless communication systems toward 5G and beyond is spurred by the demand for high data rates, exceedingly dependable low-latency communication, and extensive connectivity that aligns with sensing requisites such as advanced high-resolution sensing and target detection. Consequently, embedding sensing into communication has gained considerable attention. In this work, we propose an alternative approach for optimizing integrated sensing and communication (ISAC) waveform for target detection by concurrently maximizing the power of the communication signal at an intended user and minimizing the multi-user and sensing interference. We formulate the problem as a non-disciplined convex programming (NDCP) optimization and we use a distribution-based approach for interference cancellation. Precisely, we establish the distribution of the communication signal and the multi-user communication interference received by the intended user, and thereafter, we establish that the sensing interference can be distributed as a centralized Chi-squared if the sensing covariance matrix is idempotent. We design such a matrix based on the symmetrical idempotent property. Additionally, we propose a disciplined convex programming (DCP) form of the problem, and using successive convex approximation (SCA), we show that the solutions can reach a stable waveform for efficient target detection. Furthermore, we compare the proposed waveform with state of the art radar-communication waveform designs and demonstrate its superior performance by computer <b>simulations.</b>

{{</citation>}}


### (4/8 | 123/266) On the Optimal MMSE Channel Estimation for One-Bit Quantized MIMO Systems (Minhua Ding et al., 2024)

{{<citation>}}

Minhua Ding, Italo Atzeni, Antti Tölli, A. Lee Swindlehurst. (2024)  
**On the Optimal MMSE Channel Estimation for One-Bit Quantized MIMO Systems**
<br/>
<button class="copy-to-clipboard" title="On the Optimal MMSE Channel Estimation for One-Bit Quantized MIMO Systems" index=123>
  <span class="copy-to-clipboard-item">Copy Title<span>
</button>
<div class="toast toast-copied toast-index-123 align-items-center text-bg-secondary border-0 position-absolute top-0 end-0" role="alert" aria-live="assertive" aria-atomic="true">
  <div class="d-flex">
    <div class="toast-body">
      Copied!
    </div>
  </div>
</div>

---
Primary Category: cs.IT  
Categories: 94A12, 94A05, cs-IT, cs.IT, eess-SP, math-IT  
Keyword Score: 20  
Keywords: Quantization, Quantization  
<a type="button" class="btn btn-outline-primary" href="http://arxiv.org/abs/2404.05536v1" target="_blank" >Paper Link</a>
<button type="button" class="btn btn-outline-primary download-pdf" url="https://arxiv.org/pdf/2404.05536v1.pdf" filename="2404.05536v1.pdf">Download PDF</button>

---


**ABSTRACT**  
This paper focuses on the minimum mean squared error (MMSE) channel estimator for multiple-input multiple-output (MIMO) systems with one-bit <b>quantization</b> at the receiver side. Despite its optimality and significance in estimation theory, the MMSE channel estimator has not been fully investigated in this context due to its general non-linearity and computational complexity. Instead, the typically suboptimal Bussgang linear MMSE (BLMMSE) estimator has been widely adopted. In this work, we develop a new framework to compute the MMSE channel estimator that hinges on computation of the orthant probability of the multivariate normal distribution. Based on this framework, we determine a necessary and sufficient condition for the BLMMSE channel estimator to be optimal and equivalent to the MMSE estimator. Under the assumption of specific channel correlation or pilot symbols, we further utilize the framework to derive analytical expressions for the MMSE channel estimator that are particularly convenient for computation when certain system dimensions become large, thereby enabling a comparison between the BLMMSE and MMSE channel estimators in these cases.

{{</citation>}}


### (5/8 | 124/266) T3DRIS: Advancing Conformal RIS Design through In-depth Analysis of Mutual Coupling Effects (Placido Mursia et al., 2024)

{{<citation>}}

Placido Mursia, Francesco Devoti, Marco Rossanese, Vincenzo Sciancalepore, Gabriele Gradoni, Marco Di Renzo, Xavier Costa-Perez. (2024)  
**T3DRIS: Advancing Conformal RIS Design through In-depth Analysis of Mutual Coupling Effects**
<br/>
<button class="copy-to-clipboard" title="T3DRIS: Advancing Conformal RIS Design through In-depth Analysis of Mutual Coupling Effects" index=124>
  <span class="copy-to-clipboard-item">Copy Title<span>
</button>
<div class="toast toast-copied toast-index-124 align-items-center text-bg-secondary border-0 position-absolute top-0 end-0" role="alert" aria-live="assertive" aria-atomic="true">
  <div class="d-flex">
    <div class="toast-body">
      Copied!
    </div>
  </div>
</div>

---
Primary Category: cs.IT  
Categories: cs-IT, cs.IT, math-IT  
Keyword Score: 20  
Keywords: Simulation, Simulator  
<a type="button" class="btn btn-outline-primary" href="http://arxiv.org/abs/2404.05261v1" target="_blank" >Paper Link</a>
<button type="button" class="btn btn-outline-primary download-pdf" url="https://arxiv.org/pdf/2404.05261v1.pdf" filename="2404.05261v1.pdf">Download PDF</button>

---


**ABSTRACT**  
This paper presents a theoretical and mathematical framework for the design of a conformal reconfigurable intelligent surface (RIS) that adapts to non-planar geometries, which is a critical advancement for the deployment of RIS on non-planar and irregular surfaces as envisioned in smart radio environments. Previous research focused mainly on the optimization of RISs assuming a predetermined shape, while neglecting the intricate interplay between shape optimization, phase optimization, and mutual coupling effects. Our contribution, the T3DRIS framework, addresses this fundamental problem by integrating the configuration and shape optimization of RISs into a unified model and design framework, thus facilitating the application of RIS technology to a wider spectrum of environmental objects. The mathematical core of T3DRIS is rooted in optimizing the 3D deployment of the unit cells and tuning circuits, aiming at maximizing the communication performance. Through rigorous full-wave <b>simulations</b> and a comprehensive set of numerical analyses, we validate the proposed approach and demonstrate its superior performance and applicability over contemporary designs. This study-the first of its kind-paves the way for a new direction in RIS research, emphasizing the importance of a theoretical and mathematical perspective in tackling the challenges of conformal RISs.

{{</citation>}}


### (6/8 | 125/266) Spatially Correlated RIS-Aided Secure Massive MIMO Under CSI and Hardware Imperfections (Dan Yang et al., 2024)

{{<citation>}}

Dan Yang, Jindan Xu, Wei Xu, Bin Sheng, Xiaohu You, Chau Yuen, Marco Di Renzo. (2024)  
**Spatially Correlated RIS-Aided Secure Massive MIMO Under CSI and Hardware Imperfections**
<br/>
<button class="copy-to-clipboard" title="Spatially Correlated RIS-Aided Secure Massive MIMO Under CSI and Hardware Imperfections" index=125>
  <span class="copy-to-clipboard-item">Copy Title<span>
</button>
<div class="toast toast-copied toast-index-125 align-items-center text-bg-secondary border-0 position-absolute top-0 end-0" role="alert" aria-live="assertive" aria-atomic="true">
  <div class="d-flex">
    <div class="toast-body">
      Copied!
    </div>
  </div>
</div>

---
Primary Category: cs.IT  
Categories: cs-IT, cs.IT, math-IT  
Keyword Score: 20  
Keywords: Simulation, Simulator  
<a type="button" class="btn btn-outline-primary" href="http://arxiv.org/abs/2404.05239v1" target="_blank" >Paper Link</a>
<button type="button" class="btn btn-outline-primary download-pdf" url="https://arxiv.org/pdf/2404.05239v1.pdf" filename="2404.05239v1.pdf">Download PDF</button>

---


**ABSTRACT**  
This paper investigates the integration of a reconfigurable intelligent surface (RIS) into a secure multiuser massive multiple-input multiple-output (MIMO) system in the presence of transceiver hardware impairments (HWI), imperfect channel state information (CSI), and spatially correlated channels. We first introduce a linear minimum-mean-square error estimation algorithm for the aggregate channel by considering the impact of transceiver HWI and RIS phase-shift errors. Then, we derive a lower bound for the achievable ergodic secrecy rate in the presence of a multi-antenna eavesdropper when artificial noise (AN) is employed at the base station (BS). In addition, the obtained expressions of the ergodic secrecy rate are further simplified in some noteworthy special cases to obtain valuable insights. To counteract the effects of HWI, we present a power allocation optimization strategy between the confidential signals and AN, which admits a fixed-point equation solution. Our analysis reveals that a non-zero ergodic secrecy rate is preserved if the total transmit power decreases no faster than $1/N$, where $N$ is the number of RIS elements. Moreover, the ergodic secrecy rate grows logarithmically with the number of BS antennas $M$ and approaches a certain limit in the asymptotic regime $N\rightarrow\infty$. <b>Simulation</b> results are provided to verify the derived analytical results. They reveal the impact of key design parameters on the secrecy rate. It is shown that, with the proposed power allocation strategy, the secrecy rate loss due to HWI can be counteracted by increasing the number of low-cost RIS elements.

{{</citation>}}


### (7/8 | 126/266) Near-Tight Bounds for 3-Query Locally Correctable Binary Linear Codes via Rainbow Cycles (Omar Alrabiah et al., 2024)

{{<citation>}}

Omar Alrabiah, Venkatesan Guruswami. (2024)  
**Near-Tight Bounds for 3-Query Locally Correctable Binary Linear Codes via Rainbow Cycles**
<br/>
<button class="copy-to-clipboard" title="Near-Tight Bounds for 3-Query Locally Correctable Binary Linear Codes via Rainbow Cycles" index=126>
  <span class="copy-to-clipboard-item">Copy Title<span>
</button>
<div class="toast toast-copied toast-index-126 align-items-center text-bg-secondary border-0 position-absolute top-0 end-0" role="alert" aria-live="assertive" aria-atomic="true">
  <div class="d-flex">
    <div class="toast-body">
      Copied!
    </div>
  </div>
</div>

---
Primary Category: cs.IT  
Categories: cs-CC, cs-IT, cs.IT, math-CO, math-IT  
Keyword Score: 3  
Keywords: Graph  
<a type="button" class="btn btn-outline-primary" href="http://arxiv.org/abs/2404.05864v1" target="_blank" >Paper Link</a>
<button type="button" class="btn btn-outline-primary download-pdf" url="https://arxiv.org/pdf/2404.05864v1.pdf" filename="2404.05864v1.pdf">Download PDF</button>

---


**ABSTRACT**  
We prove that a binary linear code of block length $n$ that is locally correctable with $3$ queries against a fraction $\delta > 0$ of adversarial errors must have dimension at most $O_{\delta}(\log^2 n \cdot \log \log n)$. This is almost tight in view of quadratic Reed-Muller codes being a $3$-query locally correctable code (LCC) with dimension $\Theta(\log^2 n)$. Our result improves, for the binary field case, the $O_{\delta}(\log^8 n)$ bound obtained in the recent breakthrough of (Kothari and Manohar, 2023) (arXiv:2311.00558) (and the more recent improvement to $O_{\delta}(\log^4 n)$ for binary linear codes announced in (Yankovitz, 2024)). Previous bounds for $3$-query linear LCCs proceed by constructing a $2$-query locally decodable code (LDC) from the $3$-query linear LCC/LDC and applying the strong bounds known for the former. Our approach is more direct and proceeds by bounding the covering radius of the dual code, borrowing inspiration from (Iceland and Samorodnitsky, 2018) (arXiv:1802.01184). That is, we show that if $x \mapsto (v_1 \cdot x, v_2 \cdot x, \ldots, v_n \cdot x)$ is an arbitrary encoding map $\mathbb{F}_2^k \to \mathbb{F}_2^n$ for the $3$-query LCC, then all vectors in $\mathbb{F}_2^k$ can be written as a $\widetilde{O}_{\delta}(\log n)$-sparse linear combination of the $v_i$'s, which immediately implies $k \le \widetilde{O}_{\delta}((\log n)^2)$. The proof of this fact proceeds by iteratively reducing the size of any arbitrary linear combination of at least $\widetilde{\Omega}_{\delta}(\log n)$ of the $v_i$'s. We achieve this using the recent breakthrough result of (Alon, Buci\'c, Sauermann, Zakharov, and Zamir, 2023) (arXiv:2309.04460) on the existence of rainbow cycles in properly edge-colored <b>graphs,</b> applied to <b>graphs</b> capturing the linear dependencies underlying the local correction property.

{{</citation>}}


### (8/8 | 127/266) A Riemannian Manifold Approach to Constrained Resource Allocation in ISAC (Shayan Zargari et al., 2024)

{{<citation>}}

Shayan Zargari, Diluka Galappaththige, Chintha Tellambura, Vincent Poor. (2024)  
**A Riemannian Manifold Approach to Constrained Resource Allocation in ISAC**
<br/>
<button class="copy-to-clipboard" title="A Riemannian Manifold Approach to Constrained Resource Allocation in ISAC" index=127>
  <span class="copy-to-clipboard-item">Copy Title<span>
</button>
<div class="toast toast-copied toast-index-127 align-items-center text-bg-secondary border-0 position-absolute top-0 end-0" role="alert" aria-live="assertive" aria-atomic="true">
  <div class="d-flex">
    <div class="toast-body">
      Copied!
    </div>
  </div>
</div>

---
Primary Category: cs.IT  
Categories: cs-IT, cs.IT, eess-SP, math-IT  
Keyword Score: 3  
Keywords: Benchmarking  
<a type="button" class="btn btn-outline-primary" href="http://arxiv.org/abs/2404.05173v1" target="_blank" >Paper Link</a>
<button type="button" class="btn btn-outline-primary download-pdf" url="https://arxiv.org/pdf/2404.05173v1.pdf" filename="2404.05173v1.pdf">Download PDF</button>

---


**ABSTRACT**  
This paper introduces a new resource allocation framework for integrated sensing and communication (ISAC) systems, which are expected to be fundamental aspects of sixth-generation networks. In particular, we develop an augmented Lagrangian manifold optimization (ALMO) framework designed to maximize communication sum rate while satisfying sensing beampattern gain targets and base station (BS) transmit power limits. ALMO applies the principles of Riemannian manifold optimization (MO) to navigate the complex, non-convex landscape of the resource allocation problem. It efficiently leverages the augmented Lagrangian method to ensure adherence to constraints. We present comprehensive numerical results to validate our framework, which illustrates the ALMO method's superior capability to enhance the dual functionalities of communication and sensing in ISAC systems. For instance, with 12 antennas and 30 dBm BS transmit power, our proposed ALMO algorithm delivers a 10.1% sum rate gain over a <b>benchmark</b> optimization-based algorithm. This work demonstrates significant improvements in system performance and contributes a new algorithmic perspective to ISAC resource management.

{{</citation>}}


## cs.RO (17)



### (1/17 | 128/266) LLM-BT: Performing Robotic Adaptive Tasks based on Large Language Models and Behavior Trees (Haotian Zhou et al., 2024)

{{<citation>}}

Haotian Zhou, Yunhan Lin, Longwu Yan, Jihong Zhu, Huasong Min. (2024)  
**LLM-BT: Performing Robotic Adaptive Tasks based on Large Language Models and Behavior Trees**
<br/>
<button class="copy-to-clipboard" title="LLM-BT: Performing Robotic Adaptive Tasks based on Large Language Models and Behavior Trees" index=128>
  <span class="copy-to-clipboard-item">Copy Title<span>
</button>
<div class="toast toast-copied toast-index-128 align-items-center text-bg-secondary border-0 position-absolute top-0 end-0" role="alert" aria-live="assertive" aria-atomic="true">
  <div class="d-flex">
    <div class="toast-body">
      Copied!
    </div>
  </div>
</div>

---
Primary Category: cs.RO  
Categories: cs-RO, cs.RO  
Keyword Score: 70  
Keywords: Simulation, Simulator, BERT, ChatGPT, Transformer, Large Language Model, Large Language Model  
<a type="button" class="btn btn-outline-primary" href="http://arxiv.org/abs/2404.05134v1" target="_blank" >Paper Link</a>
<button type="button" class="btn btn-outline-primary download-pdf" url="https://arxiv.org/pdf/2404.05134v1.pdf" filename="2404.05134v1.pdf">Download PDF</button>

---


**ABSTRACT**  
<b>Large</b> <b>Language</b> <b>Models</b> <b>(LLMs)</b> have been widely utilized to perform complex robotic tasks. However, handling external disturbances during tasks is still an open challenge. This paper proposes a novel method to achieve robotic adaptive tasks based on <b>LLMs</b> and Behavior Trees (BTs). It utilizes <b>ChatGPT</b> to reason the descriptive steps of tasks. In order to enable <b>ChatGPT</b> to understand the environment, semantic maps are constructed by an object recognition algorithm. Then, we design a Parser module based on Bidirectional Encoder Representations from <b>Transformers</b> <b>(BERT)</b> to parse these steps into initial BTs. Subsequently, a BTs Update algorithm is proposed to expand the initial BTs dynamically to control robots to perform adaptive tasks. Different from other <b>LLM-based</b> methods for complex robotic tasks, our method outputs variable BTs that can add and execute new actions according to environmental changes, which is robust to external disturbances. Our method is validated with <b>simulation</b> in different practical scenarios.

{{</citation>}}


### (2/17 | 129/266) Long-horizon Locomotion and Manipulation on a Quadrupedal Robot with Large Language Models (Yutao Ouyang et al., 2024)

{{<citation>}}

Yutao Ouyang, Jinhan Li, Yunfei Li, Zhongyu Li, Chao Yu, Koushil Sreenath, Yi Wu. (2024)  
**Long-horizon Locomotion and Manipulation on a Quadrupedal Robot with Large Language Models**
<br/>
<button class="copy-to-clipboard" title="Long-horizon Locomotion and Manipulation on a Quadrupedal Robot with Large Language Models" index=129>
  <span class="copy-to-clipboard-item">Copy Title<span>
</button>
<div class="toast toast-copied toast-index-129 align-items-center text-bg-secondary border-0 position-absolute top-0 end-0" role="alert" aria-live="assertive" aria-atomic="true">
  <div class="d-flex">
    <div class="toast-body">
      Copied!
    </div>
  </div>
</div>

---
Primary Category: cs.RO  
Categories: cs-RO, cs.RO  
Keyword Score: 60  
Keywords: Reinforcement Learning, Simulation, Simulator, Reasoning, Large Language Model, Large Language Model  
<a type="button" class="btn btn-outline-primary" href="http://arxiv.org/abs/2404.05291v1" target="_blank" >Paper Link</a>
<button type="button" class="btn btn-outline-primary download-pdf" url="https://arxiv.org/pdf/2404.05291v1.pdf" filename="2404.05291v1.pdf">Download PDF</button>

---


**ABSTRACT**  
We present a <b>large</b> <b>language</b> <b>model</b> <b>(LLM)</b> based system to empower quadrupedal robots with problem-solving abilities for long-horizon tasks beyond short-term motions. Long-horizon tasks for quadrupeds are challenging since they require both a high-level understanding of the semantics of the problem for task planning and a broad range of locomotion and manipulation skills to interact with the environment. Our system builds a high-level <b>reasoning</b> layer with <b>large</b> <b>language</b> <b>models,</b> which generates hybrid discrete-continuous plans as robot code from task descriptions. It comprises multiple <b>LLM</b> agents: a semantic planner for sketching a plan, a parameter calculator for predicting arguments in the plan, and a code generator to convert the plan into executable robot code. At the low level, we adopt <b>reinforcement</b> <b>learning</b> to train a set of motion planning and control skills to unleash the flexibility of quadrupeds for rich environment interactions. Our system is tested on long-horizon tasks that are infeasible to complete with one single skill. <b>Simulation</b> and real-world experiments show that it successfully figures out multi-step strategies and demonstrates non-trivial behaviors, including building tools or notifying a human for help.

{{</citation>}}


### (3/17 | 130/266) Humanoid-Gym: Reinforcement Learning for Humanoid Robot with Zero-Shot Sim2Real Transfer (Xinyang Gu et al., 2024)

{{<citation>}}

Xinyang Gu, Yen-Jen Wang, Jianyu Chen. (2024)  
**Humanoid-Gym: Reinforcement Learning for Humanoid Robot with Zero-Shot Sim2Real Transfer**
<br/>
<button class="copy-to-clipboard" title="Humanoid-Gym: Reinforcement Learning for Humanoid Robot with Zero-Shot Sim2Real Transfer" index=130>
  <span class="copy-to-clipboard-item">Copy Title<span>
</button>
<div class="toast toast-copied toast-index-130 align-items-center text-bg-secondary border-0 position-absolute top-0 end-0" role="alert" aria-live="assertive" aria-atomic="true">
  <div class="d-flex">
    <div class="toast-body">
      Copied!
    </div>
  </div>
</div>

---
Primary Category: cs.RO  
Categories: cs-AI, cs-LG, cs-RO, cs-SY, cs.RO, eess-SY  
Keyword Score: 40  
Keywords: Reinforcement Learning, Simulation, Simulator, Zero-shot  
<a type="button" class="btn btn-outline-primary" href="http://arxiv.org/abs/2404.05695v1" target="_blank" >Paper Link</a>
<button type="button" class="btn btn-outline-primary download-pdf" url="https://arxiv.org/pdf/2404.05695v1.pdf" filename="2404.05695v1.pdf">Download PDF</button>

---


**ABSTRACT**  
Humanoid-Gym is an easy-to-use <b>reinforcement</b> <b>learning</b> (RL) framework based on Nvidia Isaac Gym, designed to train locomotion skills for humanoid robots, emphasizing <b>zero-shot</b> transfer from <b>simulation</b> to the real-world environment. Humanoid-Gym also integrates a sim-to-sim framework from Isaac Gym to Mujoco that allows users to verify the trained policies in different physical <b>simulations</b> to ensure the robustness and generalization of the policies. This framework is verified by RobotEra's XBot-S (1.2-meter tall humanoid robot) and XBot-L (1.65-meter tall humanoid robot) in a real-world environment with <b>zero-shot</b> sim-to-real transfer. The project website and source code can be found at: https://sites.google.com/view/humanoid-gym/.

{{</citation>}}


### (4/17 | 131/266) MeSA-DRL: Memory-Enhanced Deep Reinforcement Learning for Advanced Socially Aware Robot Navigation in Crowded Environments (Mannan Saeed Muhammad et al., 2024)

{{<citation>}}

Mannan Saeed Muhammad, Estrella Montero. (2024)  
**MeSA-DRL: Memory-Enhanced Deep Reinforcement Learning for Advanced Socially Aware Robot Navigation in Crowded Environments**
<br/>
<button class="copy-to-clipboard" title="MeSA-DRL: Memory-Enhanced Deep Reinforcement Learning for Advanced Socially Aware Robot Navigation in Crowded Environments" index=131>
  <span class="copy-to-clipboard-item">Copy Title<span>
</button>
<div class="toast toast-copied toast-index-131 align-items-center text-bg-secondary border-0 position-absolute top-0 end-0" role="alert" aria-live="assertive" aria-atomic="true">
  <div class="d-flex">
    <div class="toast-body">
      Copied!
    </div>
  </div>
</div>

---
Primary Category: cs.RO  
Categories: cs-RO, cs.RO  
Keyword Score: 30  
Keywords: Reinforcement Learning, Simulation, Simulator  
<a type="button" class="btn btn-outline-primary" href="http://arxiv.org/abs/2404.05203v1" target="_blank" >Paper Link</a>
<button type="button" class="btn btn-outline-primary download-pdf" url="https://arxiv.org/pdf/2404.05203v1.pdf" filename="2404.05203v1.pdf">Download PDF</button>

---


**ABSTRACT**  
Autonomous navigation capabilities play a critical role in service robots operating in environments where human interactions are pivotal, due to the dynamic and unpredictable nature of these environments. However, the variability in human behavior presents a substantial challenge for robots in predicting and anticipating movements, particularly in crowded scenarios. To address this issue, a memory-enabled deep <b>reinforcement</b> <b>learning</b> framework is proposed for autonomous robot navigation in diverse pedestrian scenarios. The proposed framework leverages long-term memory to retain essential information about the surroundings and model sequential dependencies effectively. The importance of human-robot interactions is also encoded to assign higher attention to these interactions. A global planning mechanism is incorporated into the memory-enabled architecture. Additionally, a multi-term reward system is designed to prioritize and encourage long-sighted robot behaviors by incorporating dynamic warning zones. Simultaneously, it promotes smooth trajectories and minimizes the time taken to reach the robot's desired goal. Extensive <b>simulation</b> experiments show that the suggested approach outperforms representative state-of-the-art methods, showcasing its ability to a navigation efficiency and safety in real-world scenarios.

{{</citation>}}


### (5/17 | 132/266) Semi-Supervised Novelty Detection for Precise Ultra-Wideband Error Signal Prediction (Umberto Albertin et al., 2024)

{{<citation>}}

Umberto Albertin, Alessandro Navone, Mauro Martini, Marcello Chiaberge. (2024)  
**Semi-Supervised Novelty Detection for Precise Ultra-Wideband Error Signal Prediction**
<br/>
<button class="copy-to-clipboard" title="Semi-Supervised Novelty Detection for Precise Ultra-Wideband Error Signal Prediction" index=132>
  <span class="copy-to-clipboard-item">Copy Title<span>
</button>
<div class="toast toast-copied toast-index-132 align-items-center text-bg-secondary border-0 position-absolute top-0 end-0" role="alert" aria-live="assertive" aria-atomic="true">
  <div class="d-flex">
    <div class="toast-body">
      Copied!
    </div>
  </div>
</div>

---
Primary Category: cs.RO  
Categories: cs-RO, cs.RO  
Keyword Score: 25  
Keywords: Autoencoder, Geometry, Unsupervised Learning  
<a type="button" class="btn btn-outline-primary" href="http://arxiv.org/abs/2404.05351v1" target="_blank" >Paper Link</a>
<button type="button" class="btn btn-outline-primary download-pdf" url="https://arxiv.org/pdf/2404.05351v1.pdf" filename="2404.05351v1.pdf">Download PDF</button>

---


**ABSTRACT**  
Ultra-Wideband (UWB) technology is an emerging low-cost solution for localization in a generic environment. However, UWB signal can be affected by signal reflections and non-line-of-sight (NLoS) conditions between anchors; hence, in a broader sense, the specific <b>geometry</b> of the environment and the disposition of obstructing elements in the map may drastically hinder the reliability of UWB for precise robot localization. This work aims to mitigate this problem by learning a map-specific characterization of the UWB quality signal with a fingerprint semi-supervised novelty detection methodology. An <b>unsupervised</b> <b>autoencoder</b> neural network is trained on nominal UWB map conditions, and then it is used to predict errors derived from the introduction of perturbing novelties in the environment. This work poses a step change in the understanding of UWB localization and its reliability in evolving environmental conditions. The resulting performance of the proposed method is proved by fine-grained experiments obtained with a visual tracking ground truth.

{{</citation>}}


### (6/17 | 133/266) Collision-Free Trajectory Optimization in Cluttered Environments with Sums-of-Squares Programming (Yulin Li et al., 2024)

{{<citation>}}

Yulin Li, Chunxin Zheng, Kai Chen, Yusen Xie, Xindong Tang, Michael Yu Wang, Jun Ma. (2024)  
**Collision-Free Trajectory Optimization in Cluttered Environments with Sums-of-Squares Programming**
<br/>
<button class="copy-to-clipboard" title="Collision-Free Trajectory Optimization in Cluttered Environments with Sums-of-Squares Programming" index=133>
  <span class="copy-to-clipboard-item">Copy Title<span>
</button>
<div class="toast toast-copied toast-index-133 align-items-center text-bg-secondary border-0 position-absolute top-0 end-0" role="alert" aria-live="assertive" aria-atomic="true">
  <div class="d-flex">
    <div class="toast-body">
      Copied!
    </div>
  </div>
</div>

---
Primary Category: cs.RO  
Categories: cs-RO, cs.RO  
Keyword Score: 25  
Keywords: Geometry, Simulation, Simulator  
<a type="button" class="btn btn-outline-primary" href="http://arxiv.org/abs/2404.05242v1" target="_blank" >Paper Link</a>
<button type="button" class="btn btn-outline-primary download-pdf" url="https://arxiv.org/pdf/2404.05242v1.pdf" filename="2404.05242v1.pdf">Download PDF</button>

---


**ABSTRACT**  
In this work, we propose a trajectory optimization approach for robot navigation in cluttered 3D environments. We represent the robot's <b>geometry</b> as a semialgebraic set defined by polynomial inequalities such that robots with general shapes can be suitably characterized. To address the robot navigation task in obstacle-dense environments, we exploit the free space directly to construct a sequence of free regions, and allocate each waypoint on the trajectory to a specific region. Then, we incorporate a uniform scaling factor for each free region, and formulate a Sums-of-Squares (SOS) optimization problem that renders the containment relationship between the robot and the free space computationally tractable. The SOS optimization problem is further reformulated to a semidefinite program (SDP), and the collision-free constraints are shown to be equivalent to limiting the scaling factor along the entire trajectory. In this context, the robot at a specific configuration is tailored to stay within the free region. Next, to solve the trajectory optimization problem with the proposed safety constraints (which are implicitly dependent on the robot configurations), we derive the analytical solution to the gradient of the minimum scaling factor with respect to the robot configuration. As a result, this seamlessly facilitates the use of gradient-based methods in efficient solving of the trajectory optimization problem. Through a series of <b>simulations</b> and real-world experiments, the proposed trajectory optimization approach is validated in various challenging scenarios, and the results demonstrate its effectiveness in generating collision-free trajectories in dense and intricate environments populated with obstacles.

{{</citation>}}


### (7/17 | 134/266) A Realistic Surgical Simulator for Non-Rigid and Contact-Rich Manipulation in Surgeries with the da Vinci Research Kit (Yafei Ou et al., 2024)

{{<citation>}}

Yafei Ou, Sadra Zargarzadeh, Paniz Sedighi, Mahdi Tavakoli. (2024)  
**A Realistic Surgical Simulator for Non-Rigid and Contact-Rich Manipulation in Surgeries with the da Vinci Research Kit**
<br/>
<button class="copy-to-clipboard" title="A Realistic Surgical Simulator for Non-Rigid and Contact-Rich Manipulation in Surgeries with the da Vinci Research Kit" index=134>
  <span class="copy-to-clipboard-item">Copy Title<span>
</button>
<div class="toast toast-copied toast-index-134 align-items-center text-bg-secondary border-0 position-absolute top-0 end-0" role="alert" aria-live="assertive" aria-atomic="true">
  <div class="d-flex">
    <div class="toast-body">
      Copied!
    </div>
  </div>
</div>

---
Primary Category: cs.RO  
Categories: cs-RO, cs.RO  
Keyword Score: 20  
Keywords: Virtual Reality (VR), Virtual Reality (VR)  
<a type="button" class="btn btn-outline-primary" href="http://arxiv.org/abs/2404.05888v1" target="_blank" >Paper Link</a>
<button type="button" class="btn btn-outline-primary download-pdf" url="https://arxiv.org/pdf/2404.05888v1.pdf" filename="2404.05888v1.pdf">Download PDF</button>

---


**ABSTRACT**  
Realistic real-time surgical simulators play an increasingly important role in surgical robotics research, such as surgical robot learning and automation, and surgical skills assessment. Although there are a number of existing surgical simulators for research, they generally lack the ability to simulate the diverse types of objects and contact-rich manipulation tasks typically present in surgeries, such as tissue cutting and blood suction. In this work, we introduce CRESSim, a realistic surgical simulator based on PhysX 5 for the da Vinci Research Kit (dVRK) that enables simulating various contact-rich surgical tasks involving different surgical instruments, soft tissue, and body fluids. The real-world dVRK console and the master tool manipulator (MTM) robots are incorporated into the system to allow for teleoperation through <b>virtual</b> <b>reality</b> <b>(VR).</b> To showcase the advantages and potentials of the simulator, we present three examples of surgical tasks, including tissue grasping and deformation, blood suction, and tissue cutting. These tasks are performed using the simulated surgical instruments, including the large needle driver, suction irrigator, and curved scissor, through <b>VR-based</b> teleoperation.

{{</citation>}}


### (8/17 | 135/266) Robust Control using Control Lyapunov Function and Hamilton-Jacobi Reachability (Chun-Ming Yang et al., 2024)

{{<citation>}}

Chun-Ming Yang, Pranav A. Bhounsule. (2024)  
**Robust Control using Control Lyapunov Function and Hamilton-Jacobi Reachability**
<br/>
<button class="copy-to-clipboard" title="Robust Control using Control Lyapunov Function and Hamilton-Jacobi Reachability" index=135>
  <span class="copy-to-clipboard-item">Copy Title<span>
</button>
<div class="toast toast-copied toast-index-135 align-items-center text-bg-secondary border-0 position-absolute top-0 end-0" role="alert" aria-live="assertive" aria-atomic="true">
  <div class="d-flex">
    <div class="toast-body">
      Copied!
    </div>
  </div>
</div>

---
Primary Category: cs.RO  
Categories: cs-RO, cs.RO  
Keyword Score: 20  
Keywords: Simulation, Simulator  
<a type="button" class="btn btn-outline-primary" href="http://arxiv.org/abs/2404.05625v1" target="_blank" >Paper Link</a>
<button type="button" class="btn btn-outline-primary download-pdf" url="https://arxiv.org/pdf/2404.05625v1.pdf" filename="2404.05625v1.pdf">Download PDF</button>

---


**ABSTRACT**  
The paper presents a robust control technique that combines the Control Lyapunov function and Hamilton-Jacobi Reachability to compute a controller and its Region of Attraction (ROA). The Control Lyapunov function uses a linear system model with an assumed additive uncertainty to calculate a control gain and the level sets of the ROA as a function of the uncertainty. Next, Hamilton-Jacobi reachability uses the nonlinear model with the modeled uncertainty, which need not be additive, to compute the backward reachable set (BRS). Finally, by juxtaposing the level sets of the ROA with BRS, we can calculate the worst-case additive disturbance and the ROA of the nonlinear model. We illustrate our approach on a 2D quadcopter tracking trajectory and a 2D quadcopter with height and velocity regulation in <b>simulation.</b>

{{</citation>}}


### (9/17 | 136/266) Design and Simulation of Time-energy Optimal Anti-swing Trajectory Planner for Autonomous Tower Cranes (Souravik Dutta et al., 2024)

{{<citation>}}

Souravik Dutta, Yiyu Cai. (2024)  
**Design and Simulation of Time-energy Optimal Anti-swing Trajectory Planner for Autonomous Tower Cranes**
<br/>
<button class="copy-to-clipboard" title="Design and Simulation of Time-energy Optimal Anti-swing Trajectory Planner for Autonomous Tower Cranes" index=136>
  <span class="copy-to-clipboard-item">Copy Title<span>
</button>
<div class="toast toast-copied toast-index-136 align-items-center text-bg-secondary border-0 position-absolute top-0 end-0" role="alert" aria-live="assertive" aria-atomic="true">
  <div class="d-flex">
    <div class="toast-body">
      Copied!
    </div>
  </div>
</div>

---
Primary Category: cs.RO  
Categories: cs-RO, cs-SY, cs.RO, eess-SY  
Keyword Score: 20  
Keywords: Simulation, Simulator  
<a type="button" class="btn btn-outline-primary" href="http://arxiv.org/abs/2404.05581v1" target="_blank" >Paper Link</a>
<button type="button" class="btn btn-outline-primary download-pdf" url="https://arxiv.org/pdf/2404.05581v1.pdf" filename="2404.05581v1.pdf">Download PDF</button>

---


**ABSTRACT**  
For autonomous crane lifting, optimal trajectories of the crane are required as reference inputs to the crane controller to facilitate feedforward control. Reducing the unactuated payload motion is a crucial issue for under-actuated tower cranes with spherical pendulum dynamics. The planned trajectory should be optimal in terms of both operating time and energy consumption, to facilitate optimum output spending optimum effort. This article proposes an anti-swing tower crane trajectory planner that can provide time-energy optimal solutions for the Computer-Aided Lift Planning (CALP) system developed at Nanyang Technological University, which facilitates collision-free lifting path planning of robotized tower cranes in autonomous construction sites. The current work introduces a trajectory planning module to the system that utilizes the geometric outputs from the path planning module and optimally scales them with time information. Firstly, analyzing the non-linear dynamics of the crane operations, the tower crane is established as differentially flat. Subsequently, the multi-objective trajectory optimization problems for all the crane operations are formulated in the flat output space through consideration of the mechanical and safety constraints. Two multi-objective evolutionary algorithms, namely Non-dominated Sorting Genetic Algorithm (NSGA-II) and Generalized Differential Evolution 3 (GDE3), are extensively compared via statistical measures based on the closeness of solutions to the Pareto front, distribution of solutions in the solution space and the runtime, to select the optimization engine of the planner. Finally, the crane operation trajectories are obtained via the corresponding planned flat output trajectories. Studies simulating real-world lifting scenarios are conducted to verify the effectiveness and reliability of the proposed module of the lift planning system.

{{</citation>}}


### (10/17 | 137/266) Robust STL Control Synthesis under Maximal Disturbance Sets (Joris Verhagen et al., 2024)

{{<citation>}}

Joris Verhagen, Lars Lindemann, Jana Tumova. (2024)  
**Robust STL Control Synthesis under Maximal Disturbance Sets**
<br/>
<button class="copy-to-clipboard" title="Robust STL Control Synthesis under Maximal Disturbance Sets" index=137>
  <span class="copy-to-clipboard-item">Copy Title<span>
</button>
<div class="toast toast-copied toast-index-137 align-items-center text-bg-secondary border-0 position-absolute top-0 end-0" role="alert" aria-live="assertive" aria-atomic="true">
  <div class="d-flex">
    <div class="toast-body">
      Copied!
    </div>
  </div>
</div>

---
Primary Category: cs.RO  
Categories: cs-RO, cs.RO  
Keyword Score: 20  
Keywords: Simulation, Simulator  
<a type="button" class="btn btn-outline-primary" href="http://arxiv.org/abs/2404.05535v1" target="_blank" >Paper Link</a>
<button type="button" class="btn btn-outline-primary download-pdf" url="https://arxiv.org/pdf/2404.05535v1.pdf" filename="2404.05535v1.pdf">Download PDF</button>

---


**ABSTRACT**  
This work addresses maximally robust control synthesis under unknown disturbances. We consider a general nonlinear system, subject to a Signal Temporal Logic (STL) specification, and wish to jointly synthesize the maximal possible disturbance bounds and the corresponding controllers that ensure the STL specification is satisfied under these bounds. Many works have considered STL satisfaction under given bounded disturbances. Yet, to the authors' best knowledge, this is the first work that aims to maximize the permissible disturbance set and find the corresponding controllers that ensure satisfying the STL specification with maximum disturbance robustness. We extend the notion of disturbance-robust semantics for STL, which is a property of a specification, dynamical system, and controller, and provide an algorithm to get the maximal disturbance robust controllers satisfying an STL specification using Hamilton-Jacobi reachability. We show its soundness and provide a <b>simulation</b> example with an Autonomous Underwater Vehicle (AUV).

{{</citation>}}


### (11/17 | 138/266) GPS-free Autonomous Navigation in Cluttered Tree Rows with Deep Semantic Segmentation (Alessandro Navone et al., 2024)

{{<citation>}}

Alessandro Navone, Mauro Martini, Marco Ambrosio, Andrea Ostuni, Simone Angarano, Marcello Chiaberge. (2024)  
**GPS-free Autonomous Navigation in Cluttered Tree Rows with Deep Semantic Segmentation**
<br/>
<button class="copy-to-clipboard" title="GPS-free Autonomous Navigation in Cluttered Tree Rows with Deep Semantic Segmentation" index=138>
  <span class="copy-to-clipboard-item">Copy Title<span>
</button>
<div class="toast toast-copied toast-index-138 align-items-center text-bg-secondary border-0 position-absolute top-0 end-0" role="alert" aria-live="assertive" aria-atomic="true">
  <div class="d-flex">
    <div class="toast-body">
      Copied!
    </div>
  </div>
</div>

---
Primary Category: cs.RO  
Categories: cs-RO, cs.RO  
Keyword Score: 20  
Keywords: Simulation, Simulator  
<a type="button" class="btn btn-outline-primary" href="http://arxiv.org/abs/2404.05338v1" target="_blank" >Paper Link</a>
<button type="button" class="btn btn-outline-primary download-pdf" url="https://arxiv.org/pdf/2404.05338v1.pdf" filename="2404.05338v1.pdf">Download PDF</button>

---


**ABSTRACT**  
Segmentation-based autonomous navigation has recently been presented as an appealing approach to guiding robotic platforms through crop rows without requiring perfect GPS localization. Nevertheless, current techniques are restricted to situations where the distinct separation between the plants and the sky allows for the identification of the row's center. However, tall, dense vegetation, such as high tree rows and orchards, is the primary cause of GPS signal blockage. In this study, we increase the overall robustness and adaptability of the control algorithm by extending the segmentation-based robotic guiding to those cases where canopies and branches occlude the sky and prevent the utilization of GPS and earlier approaches. An efficient Deep Neural Network architecture has been used to address semantic segmentation, performing the training with synthetic data only. Numerous vineyards and tree fields have undergone extensive testing in both <b>simulation</b> and real-world to show the solution's competitive benefits.

{{</citation>}}


### (12/17 | 139/266) On the Fly Robotic-Assisted Medical Instrument Planning and Execution Using Mixed Reality (Letian Ai et al., 2024)

{{<citation>}}

Letian Ai, Yihao Liu, Mehran Armand, Amir Kheradmand, Alejandro Martin-Gomez. (2024)  
**On the Fly Robotic-Assisted Medical Instrument Planning and Execution Using Mixed Reality**
<br/>
<button class="copy-to-clipboard" title="On the Fly Robotic-Assisted Medical Instrument Planning and Execution Using Mixed Reality" index=139>
  <span class="copy-to-clipboard-item">Copy Title<span>
</button>
<div class="toast toast-copied toast-index-139 align-items-center text-bg-secondary border-0 position-absolute top-0 end-0" role="alert" aria-live="assertive" aria-atomic="true">
  <div class="d-flex">
    <div class="toast-body">
      Copied!
    </div>
  </div>
</div>

---
Primary Category: cs.RO  
Categories: cs-RO, cs.RO  
Keyword Score: 10  
Keywords: Mixed Reality (MR)  
<a type="button" class="btn btn-outline-primary" href="http://arxiv.org/abs/2404.05887v1" target="_blank" >Paper Link</a>
<button type="button" class="btn btn-outline-primary download-pdf" url="https://arxiv.org/pdf/2404.05887v1.pdf" filename="2404.05887v1.pdf">Download PDF</button>

---


**ABSTRACT**  
Robotic-assisted medical systems (RAMS) have gained significant attention for their advantages in alleviating surgeons' fatigue and improving patients' outcomes. These systems comprise a range of human-computer interactions, including medical scene monitoring, anatomical target planning, and robot manipulation. However, despite its versatility and effectiveness, RAMS demands expertise in robotics, leading to a high learning cost for the operator. In this work, we introduce a novel framework using <b>mixed</b> <b>reality</b> technologies to ease the use of RAMS. The proposed framework achieves real-time planning and execution of medical instruments by providing 3D anatomical image overlay, human-robot collision detection, and robot programming interface. These features, integrated with an easy-to-use calibration method for head-mounted display, improve the effectiveness of human-robot interactions. To assess the feasibility of the framework, two medical applications are presented in this work: 1) coil placement during transcranial magnetic stimulation and 2) drill and injector device positioning during femoroplasty. Results from these use cases demonstrate its potential to extend to a wider range of medical scenarios.

{{</citation>}}


### (13/17 | 140/266) A Neuromorphic Approach to Obstacle Avoidance in Robot Manipulation (Ahmed Faisal Abdelrahman et al., 2024)

{{<citation>}}

Ahmed Faisal Abdelrahman, Matias Valdenegro-Toro, Maren Bennewitz, Paul G. Plöger. (2024)  
**A Neuromorphic Approach to Obstacle Avoidance in Robot Manipulation**
<br/>
<button class="copy-to-clipboard" title="A Neuromorphic Approach to Obstacle Avoidance in Robot Manipulation" index=140>
  <span class="copy-to-clipboard-item">Copy Title<span>
</button>
<div class="toast toast-copied toast-index-140 align-items-center text-bg-secondary border-0 position-absolute top-0 end-0" role="alert" aria-live="assertive" aria-atomic="true">
  <div class="d-flex">
    <div class="toast-body">
      Copied!
    </div>
  </div>
</div>

---
Primary Category: cs.RO  
Categories: cs-LG, cs-NE, cs-RO, cs.RO  
Keyword Score: 10  
Keywords: Convolution  
<a type="button" class="btn btn-outline-primary" href="http://arxiv.org/abs/2404.05858v1" target="_blank" >Paper Link</a>
<button type="button" class="btn btn-outline-primary download-pdf" url="https://arxiv.org/pdf/2404.05858v1.pdf" filename="2404.05858v1.pdf">Download PDF</button>

---


**ABSTRACT**  
Neuromorphic computing mimics computational principles of the brain in $\textit{silico}$ and motivates research into event-based vision and spiking neural networks (SNNs). Event cameras (ECs) exclusively capture local intensity changes and offer superior power consumption, response latencies, and dynamic ranges. SNNs replicate biological neuronal dynamics and have demonstrated potential as alternatives to conventional artificial neural networks (ANNs), such as in reducing energy expenditure and inference time in visual classification. Nevertheless, these novel paradigms remain scarcely explored outside the domain of aerial robots. To investigate the utility of brain-inspired sensing and data processing, we developed a neuromorphic approach to obstacle avoidance on a camera-equipped manipulator. Our approach adapts high-level trajectory plans with reactive maneuvers by processing emulated event data in a <b>convolutional</b> SNN, decoding neural activations into avoidance motions, and adjusting plans using a dynamic motion primitive. We conducted experiments with a Kinova Gen3 arm performing simple reaching tasks that involve obstacles in sets of distinct task scenarios and in comparison to a non-adaptive baseline. Our neuromorphic approach facilitated reliable avoidance of imminent collisions in simulated and real-world experiments, where the baseline consistently failed. Trajectory adaptations had low impacts on safety and predictability criteria. Among the notable SNN properties were the correlation of computations with the magnitude of perceived motions and a robustness to different event emulation methods. Tests with a DAVIS346 EC showed similar performance, validating our experimental event emulation. Our results motivate incorporating SNN learning, utilizing neuromorphic processors, and further exploring the potential of neuromorphic methods.

{{</citation>}}


### (14/17 | 141/266) Learning Prehensile Dexterity by Imitating and Emulating State-only Observations (Yunhai Han et al., 2024)

{{<citation>}}

Yunhai Han, Zhenyang Chen, Harish Ravichandar. (2024)  
**Learning Prehensile Dexterity by Imitating and Emulating State-only Observations**
<br/>
<button class="copy-to-clipboard" title="Learning Prehensile Dexterity by Imitating and Emulating State-only Observations" index=141>
  <span class="copy-to-clipboard-item">Copy Title<span>
</button>
<div class="toast toast-copied toast-index-141 align-items-center text-bg-secondary border-0 position-absolute top-0 end-0" role="alert" aria-live="assertive" aria-atomic="true">
  <div class="d-flex">
    <div class="toast-body">
      Copied!
    </div>
  </div>
</div>

---
Primary Category: cs.RO  
Categories: cs-RO, cs.RO  
Keyword Score: 10  
Keywords: Zero-shot  
<a type="button" class="btn btn-outline-primary" href="http://arxiv.org/abs/2404.05582v1" target="_blank" >Paper Link</a>
<button type="button" class="btn btn-outline-primary download-pdf" url="https://arxiv.org/pdf/2404.05582v1.pdf" filename="2404.05582v1.pdf">Download PDF</button>

---


**ABSTRACT**  
When humans learn physical skills (e.g., learn to play tennis), we tend to first observe and learn what an expert is doing. But this is often insufficient. Therefore, we subsequently engage in practice, where we try to emulate the expert. Inspired by this observation, we introduce Combining IMitation and Emulation for Motion Refinement (CIMER) -- a two-stage framework to learn dexterous prehensile manipulation skills from state-only observations. CIMER's first stage involves imitation: simultaneously encode the complex interdependent motions of the robot hand and the object in a structured dynamical system. This results in a reactive motion generation policy that provides a reasonable motion prior, but lacks the ability to reason about contact effects due to the lack of action labels. The second stage involves emulation: learn a motion refinement policy to make adjustments to the motion prior of the robot hand such that the desired object motion is reenacted. CIMER is both task-agnostic (no task-specific reward design or shaping) and intervention-free (no need for additional teleoperated or labeled demonstrations). Detailed experiments reveal that i) Imitation alone is insufficient, but adding emulation drastically improves performance, ii) CIMER outperforms existing methods in terms of sample efficiency and the ability to generate realistic and stable motions, iii) CIMER can either <b>zero-shot</b> generalize or learn to adapt to novel objects from the YCB dataset, even outperforming expert policies trained with action labels in most cases.

{{</citation>}}


### (15/17 | 142/266) Rendering-Enhanced Automatic Image-to-Point Cloud Registration for Roadside Scenes (Yu Sheng et al., 2024)

{{<citation>}}

Yu Sheng, Lu Zhang, Xingchen Li, Yifan Duan, Yanyong Zhang, Yu Zhang, Jianmin Ji. (2024)  
**Rendering-Enhanced Automatic Image-to-Point Cloud Registration for Roadside Scenes**
<br/>
<button class="copy-to-clipboard" title="Rendering-Enhanced Automatic Image-to-Point Cloud Registration for Roadside Scenes" index=142>
  <span class="copy-to-clipboard-item">Copy Title<span>
</button>
<div class="toast toast-copied toast-index-142 align-items-center text-bg-secondary border-0 position-absolute top-0 end-0" role="alert" aria-live="assertive" aria-atomic="true">
  <div class="d-flex">
    <div class="toast-body">
      Copied!
    </div>
  </div>
</div>

---
Primary Category: cs.RO  
Categories: cs-RO, cs.RO  
Keyword Score: 10  
Keywords: Object Detection  
<a type="button" class="btn btn-outline-primary" href="http://arxiv.org/abs/2404.05164v1" target="_blank" >Paper Link</a>
<button type="button" class="btn btn-outline-primary download-pdf" url="https://arxiv.org/pdf/2404.05164v1.pdf" filename="2404.05164v1.pdf">Download PDF</button>

---


**ABSTRACT**  
Prior point cloud provides 3D environmental context, which enhances the capabilities of monocular camera in downstream vision tasks, such as 3D <b>object</b> <b>detection,</b> via data fusion. However, the absence of accurate and automated registration methods for estimating camera extrinsic parameters in roadside scene point clouds notably constrains the potential applications of roadside cameras. This paper proposes a novel approach for the automatic registration between prior point clouds and images from roadside scenes. The main idea involves rendering photorealistic grayscale views taken at specific perspectives from the prior point cloud with the help of their features like RGB or intensity values. These generated views can reduce the modality differences between images and prior point clouds, thereby improve the robustness and accuracy of the registration results. Particularly, we specify an efficient algorithm, named neighbor rendering, for the rendering process. Then we introduce a method for automatically estimating the initial guess using only rough guesses of camera's position. At last, we propose a procedure for iteratively refining the extrinsic parameters by minimizing the reprojection error for line features extracted from both generated and camera images using Segment Anything Model (SAM). We assess our method using a self-collected dataset, comprising eight cameras strategically positioned throughout the university campus. Experiments demonstrate our method's capability to automatically align prior point cloud with roadside camera image, achieving a rotation accuracy of 0.202 degrees and a translation precision of 0.079m. Furthermore, we validate our approach's effectiveness in visual applications by substantially improving monocular 3D <b>object</b> <b>detection</b> performance.

{{</citation>}}


### (16/17 | 143/266) STITCH: Augmented Dexterity for Suture Throws Including Thread Coordination and Handoffs (Kush Hari et al., 2024)

{{<citation>}}

Kush Hari, Hansoul Kim, Will Panitch, Kishore Srinivas, Vincent Schorp, Karthik Dharmarajan, Shreya Ganti, Tara Sadjadpour, Ken Goldberg. (2024)  
**STITCH: Augmented Dexterity for Suture Throws Including Thread Coordination and Handoffs**
<br/>
<button class="copy-to-clipboard" title="STITCH: Augmented Dexterity for Suture Throws Including Thread Coordination and Handoffs" index=143>
  <span class="copy-to-clipboard-item">Copy Title<span>
</button>
<div class="toast toast-copied toast-index-143 align-items-center text-bg-secondary border-0 position-absolute top-0 end-0" role="alert" aria-live="assertive" aria-atomic="true">
  <div class="d-flex">
    <div class="toast-body">
      Copied!
    </div>
  </div>
</div>

---
Primary Category: cs.RO  
Categories: cs-RO, cs.RO  
Keyword Score: 10  
Keywords: Human Intervention  
<a type="button" class="btn btn-outline-primary" href="http://arxiv.org/abs/2404.05151v1" target="_blank" >Paper Link</a>
<button type="button" class="btn btn-outline-primary download-pdf" url="https://arxiv.org/pdf/2404.05151v1.pdf" filename="2404.05151v1.pdf">Download PDF</button>

---


**ABSTRACT**  
We present STITCH: an augmented dexterity pipeline that performs Suture Throws Including Thread Coordination and Handoffs. STITCH iteratively performs needle insertion, thread sweeping, needle extraction, suture cinching, needle handover, and needle pose correction with failure recovery policies. We introduce a novel visual 6D needle pose estimation framework using a stereo camera pair and new suturing motion primitives. We compare STITCH to baselines, including a proprioception-only and a policy without visual servoing. In physical experiments across 15 trials, STITCH achieves an average of 2.93 sutures without <b>human</b> <b>intervention</b> and 4.47 sutures with <b>human</b> <b>intervention.</b> See https://sites.google.com/berkeley.edu/stitch for code and supplemental materials.

{{</citation>}}


### (17/17 | 144/266) GBEC: Geometry-Based Hand-Eye Calibration (Yihao Liu et al., 2024)

{{<citation>}}

Yihao Liu, Jiaming Zhang, Zhangcong She, Amir Kheradmand, Mehran Armand. (2024)  
**GBEC: Geometry-Based Hand-Eye Calibration**
<br/>
<button class="copy-to-clipboard" title="GBEC: Geometry-Based Hand-Eye Calibration" index=144>
  <span class="copy-to-clipboard-item">Copy Title<span>
</button>
<div class="toast toast-copied toast-index-144 align-items-center text-bg-secondary border-0 position-absolute top-0 end-0" role="alert" aria-live="assertive" aria-atomic="true">
  <div class="d-flex">
    <div class="toast-body">
      Copied!
    </div>
  </div>
</div>

---
Primary Category: cs.RO  
Categories: cs-RO, cs.RO  
Keyword Score: 5  
Keywords: Geometry  
<a type="button" class="btn btn-outline-primary" href="http://arxiv.org/abs/2404.05884v1" target="_blank" >Paper Link</a>
<button type="button" class="btn btn-outline-primary download-pdf" url="https://arxiv.org/pdf/2404.05884v1.pdf" filename="2404.05884v1.pdf">Download PDF</button>

---


**ABSTRACT**  
Hand-eye calibration is the problem of solving the transformation from the end-effector of a robot to the sensor attached to it. Commonly employed techniques, such as AXXB or AXZB formulations, rely on regression methods that require collecting pose data from different robot configurations, which can produce low accuracy and repeatability. However, the derived transformation should solely depend on the <b>geometry</b> of the end-effector and the sensor attachment. We propose <b>Geometry-Based</b> End-Effector Calibration (GBEC) that enhances the repeatability and accuracy of the derived transformation compared to traditional hand-eye calibrations. To demonstrate improvements, we apply the approach to two different robot-assisted procedures: Transcranial Magnetic Stimulation (TMS) and femoroplasty. We also discuss the generalizability of GBEC for camera-in-hand and marker-in-hand sensor mounting methods. In the experiments, we perform GBEC between the robot end-effector and an optical tracker's rigid body marker attached to the TMS coil or femoroplasty drill guide. Previous research documents low repeatability and accuracy of the conventional methods for robot-assisted TMS hand-eye calibration. When compared to some existing methods, the proposed method relies solely on the <b>geometry</b> of the flange and the pose of the rigid-body marker, making it independent of workspace constraints or robot accuracy, without sacrificing the orthogonality of the rotation matrix. Our results validate the accuracy and applicability of the approach, providing a new and generalizable methodology for obtaining the transformation from the end-effector to a sensor.

{{</citation>}}


## cs.LG (34)



### (1/34 | 145/266) Evaluating Interventional Reasoning Capabilities of Large Language Models (Tejas Kasetty et al., 2024)

{{<citation>}}

Tejas Kasetty, Divyat Mahajan, Gintare Karolina Dziugaite, Alexandre Drouin, Dhanya Sridhar. (2024)  
**Evaluating Interventional Reasoning Capabilities of Large Language Models**
<br/>
<button class="copy-to-clipboard" title="Evaluating Interventional Reasoning Capabilities of Large Language Models" index=145>
  <span class="copy-to-clipboard-item">Copy Title<span>
</button>
<div class="toast toast-copied toast-index-145 align-items-center text-bg-secondary border-0 position-absolute top-0 end-0" role="alert" aria-live="assertive" aria-atomic="true">
  <div class="d-flex">
    <div class="toast-body">
      Copied!
    </div>
  </div>
</div>

---
Primary Category: cs.LG  
Categories: cs-AI, cs-CL, cs-LG, cs.LG, stat-ME  
Keyword Score: 56  
Keywords: Graph, Benchmarking, GPT-4, Reasoning, Large Language Model, Large Language Model, Prompt  
<a type="button" class="btn btn-outline-primary" href="http://arxiv.org/abs/2404.05545v1" target="_blank" >Paper Link</a>
<button type="button" class="btn btn-outline-primary download-pdf" url="https://arxiv.org/pdf/2404.05545v1.pdf" filename="2404.05545v1.pdf">Download PDF</button>

---


**ABSTRACT**  
Numerous decision-making tasks require estimating causal effects under interventions on different parts of a system. As practitioners consider using <b>large</b> <b>language</b> <b>models</b> <b>(LLMs)</b> to automate decisions, studying their causal <b>reasoning</b> capabilities becomes crucial. A recent line of work evaluates <b>LLMs</b> ability to retrieve commonsense causal facts, but these evaluations do not sufficiently assess how <b>LLMs</b> reason about interventions. Motivated by the role that interventions play in causal inference, in this paper, we conduct empirical analyses to evaluate whether <b>LLMs</b> can accurately update their knowledge of a data-generating process in response to an intervention. We create <b>benchmarks</b> that span diverse causal <b>graphs</b> (e.g., confounding, mediation) and variable types, and enable a study of intervention-based <b>reasoning.</b> These <b>benchmarks</b> allow us to isolate the ability of <b>LLMs</b> to accurately predict changes resulting from their ability to memorize facts or find other shortcuts. Our analysis on four <b>LLMs</b> highlights that while GPT- 4 models show promising accuracy at predicting the intervention effects, they remain sensitive to distracting factors in the <b>prompts.</b>

{{</citation>}}


### (2/34 | 146/266) Tangling-Untangling Cycle for Efficient Learning (Xin Li, 2024)

{{<citation>}}

Xin Li. (2024)  
**Tangling-Untangling Cycle for Efficient Learning**
<br/>
<button class="copy-to-clipboard" title="Tangling-Untangling Cycle for Efficient Learning" index=146>
  <span class="copy-to-clipboard-item">Copy Title<span>
</button>
<div class="toast toast-copied toast-index-146 align-items-center text-bg-secondary border-0 position-absolute top-0 end-0" role="alert" aria-live="assertive" aria-atomic="true">
  <div class="d-flex">
    <div class="toast-body">
      Copied!
    </div>
  </div>
</div>

---
Primary Category: cs.LG  
Categories: cs-LG, cs.LG, stat-ML  
Keyword Score: 45  
Keywords: Geometry, Supervised Learning, Supervised Learning, Unsupervised Learning, Unsupervised Learning  
<a type="button" class="btn btn-outline-primary" href="http://arxiv.org/abs/2404.05484v1" target="_blank" >Paper Link</a>
<button type="button" class="btn btn-outline-primary download-pdf" url="https://arxiv.org/pdf/2404.05484v1.pdf" filename="2404.05484v1.pdf">Download PDF</button>

---


**ABSTRACT**  
The conventional wisdom of manifold learning is based on nonlinear dimensionality reduction techniques such as IsoMAP and locally linear embedding (LLE). We challenge this paradigm by exploiting the blessing of dimensionality. Our intuition is simple: it is easier to untangle a low-dimensional manifold in a higher-dimensional space due to its vastness, as guaranteed by Whitney embedding theorem. A new insight brought by this work is to introduce class labels as the context variables in the lifted higher-dimensional space (so <b>supervised</b> <b>learning</b> becomes <b>unsupervised</b> <b>learning).</b> We rigorously show that manifold untangling leads to linearly separable classifiers in the lifted space. To correct the inevitable overfitting, we consider the dual process of manifold untangling -- tangling or aliasing -- which is important for generalization. Using context as the bonding element, we construct a pair of manifold untangling and tangling operators, known as tangling-untangling cycle (TUC). Untangling operator maps context-independent representations (CIR) in low-dimensional space to context-dependent representations (CDR) in high-dimensional space by inducing context as hidden variables. The tangling operator maps CDR back to CIR by a simple integral transformation for invariance and generalization. We also present the hierarchical extensions of TUC based on the Cartesian product and the fractal <b>geometry.</b> Despite the conceptual simplicity, TUC admits a biologically plausible and energy-efficient implementation based on the time-locking behavior of polychronization neural groups (PNG) and sleep-wake cycle (SWC). The TUC-based theory applies to the computational modeling of various cognitive functions by hippocampal-neocortical systems.

{{</citation>}}


### (3/34 | 147/266) Investigating the Impact of Quantization on Adversarial Robustness (Qun Li et al., 2024)

{{<citation>}}

Qun Li, Yuan Meng, Chen Tang, Jiacheng Jiang, Zhi Wang. (2024)  
**Investigating the Impact of Quantization on Adversarial Robustness**
<br/>
<button class="copy-to-clipboard" title="Investigating the Impact of Quantization on Adversarial Robustness" index=147>
  <span class="copy-to-clipboard-item">Copy Title<span>
</button>
<div class="toast toast-copied toast-index-147 align-items-center text-bg-secondary border-0 position-absolute top-0 end-0" role="alert" aria-live="assertive" aria-atomic="true">
  <div class="d-flex">
    <div class="toast-body">
      Copied!
    </div>
  </div>
</div>

---
Primary Category: cs.LG  
Categories: cs-AI, cs-CR, cs-LG, cs.LG  
Keyword Score: 40  
Keywords: Quantization, Quantization, Prompt, Adversarial Attack  
<a type="button" class="btn btn-outline-primary" href="http://arxiv.org/abs/2404.05639v1" target="_blank" >Paper Link</a>
<button type="button" class="btn btn-outline-primary download-pdf" url="https://arxiv.org/pdf/2404.05639v1.pdf" filename="2404.05639v1.pdf">Download PDF</button>

---


**ABSTRACT**  
<b>Quantization</b> is a promising technique for reducing the bit-width of deep models to improve their runtime performance and storage efficiency, and thus becomes a fundamental step for deployment. In real-world scenarios, <b>quantized</b> models are often faced with <b>adversarial</b> <b>attacks</b> which cause the model to make incorrect inferences by introducing slight perturbations. However, recent studies have paid less attention to the impact of <b>quantization</b> on the model robustness. More surprisingly, existing studies on this topic even present inconsistent conclusions, which <b>prompted</b> our in-depth investigation. In this paper, we conduct a first-time analysis of the impact of the <b>quantization</b> pipeline components that can incorporate robust optimization under the settings of Post-Training <b>Quantization</b> and <b>Quantization-Aware</b> Training. Through our detailed analysis, we discovered that this inconsistency arises from the use of different pipelines in different studies, specifically regarding whether robust optimization is performed and at which <b>quantization</b> stage it occurs. Our research findings contribute insights into deploying more secure and robust <b>quantized</b> networks, assisting practitioners in reference for scenarios with high-security requirements and limited resources.

{{</citation>}}


### (4/34 | 148/266) DLoRA: Distributed Parameter-Efficient Fine-Tuning Solution for Large Language Model (Chao Gao et al., 2024)

{{<citation>}}

Chao Gao, Sai Qian Zhang. (2024)  
**DLoRA: Distributed Parameter-Efficient Fine-Tuning Solution for Large Language Model**
<br/>
<button class="copy-to-clipboard" title="DLoRA: Distributed Parameter-Efficient Fine-Tuning Solution for Large Language Model" index=148>
  <span class="copy-to-clipboard-item">Copy Title<span>
</button>
<div class="toast toast-copied toast-index-148 align-items-center text-bg-secondary border-0 position-absolute top-0 end-0" role="alert" aria-live="assertive" aria-atomic="true">
  <div class="d-flex">
    <div class="toast-body">
      Copied!
    </div>
  </div>
</div>

---
Primary Category: cs.LG  
Categories: cs-AI, cs-CL, cs-DC, cs-LG, cs.LG  
Keyword Score: 40  
Keywords: Fine-tuning, Fine-tuning, Large Language Model, Large Language Model  
<a type="button" class="btn btn-outline-primary" href="http://arxiv.org/abs/2404.05182v1" target="_blank" >Paper Link</a>
<button type="button" class="btn btn-outline-primary download-pdf" url="https://arxiv.org/pdf/2404.05182v1.pdf" filename="2404.05182v1.pdf">Download PDF</button>

---


**ABSTRACT**  
To enhance the performance of <b>large</b> <b>language</b> <b>models</b> <b>(LLM)</b> on downstream tasks, one solution is to <b>fine-tune</b> certain <b>LLM</b> parameters and make it better align with the characteristics of the training dataset. This process is commonly known as parameter-efficient <b>fine-tuning</b> (PEFT). Due to the scale of <b>LLM,</b> PEFT operations are usually executed in the public environment (e.g., cloud server). This necessitates the sharing of sensitive user data across public environments, thereby raising potential privacy concerns. To tackle these challenges, we propose a distributed PEFT framework called DLoRA. DLoRA enables scalable PEFT operations to be performed collaboratively between the cloud and user devices. Coupled with the proposed Kill and Revive algorithm, the evaluation results demonstrate that DLoRA can significantly reduce the computation and communication workload over the user devices while achieving superior accuracy and privacy protection.

{{</citation>}}


### (5/34 | 149/266) Natural Learning (Hadi Fanaee-T, 2024)

{{<citation>}}

Hadi Fanaee-T. (2024)  
**Natural Learning**
<br/>
<button class="copy-to-clipboard" title="Natural Learning" index=149>
  <span class="copy-to-clipboard-item">Copy Title<span>
</button>
<div class="toast toast-copied toast-index-149 align-items-center text-bg-secondary border-0 position-absolute top-0 end-0" role="alert" aria-live="assertive" aria-atomic="true">
  <div class="d-flex">
    <div class="toast-body">
      Copied!
    </div>
  </div>
</div>

---
Primary Category: cs.LG  
Categories: cs-AI, cs-LG, cs.LG  
Keyword Score: 38  
Keywords: MNIST, Benchmarking, Black Box, Fine-tuning, Logistic Regression  
<a type="button" class="btn btn-outline-primary" href="http://arxiv.org/abs/2404.05903v1" target="_blank" >Paper Link</a>
<button type="button" class="btn btn-outline-primary download-pdf" url="https://arxiv.org/pdf/2404.05903v1.pdf" filename="2404.05903v1.pdf">Download PDF</button>

---


**ABSTRACT**  
We introduce Natural Learning (NL), a novel algorithm that elevates the explainability and interpretability of machine learning to an extreme level. NL simplifies decisions into intuitive rules, like "We rejected your loan because your income, employment status, and age collectively resemble a rejected prototype more than an accepted prototype." When applied to real-life datasets, NL produces impressive results. For example, in a colon cancer dataset with 1545 patients and 10935 genes, NL achieves 98.1% accuracy, comparable to DNNs and RF, by analyzing just 3 genes of test samples against 2 discovered prototypes. Similarly, in the UCI's WDBC dataset, NL achieves 98.3% accuracy using only 7 features and 2 prototypes. Even on the <b>MNIST</b> dataset (0 vs. 1), NL achieves 99.5% accuracy with only 3 pixels from 2 prototype images. NL is inspired by prototype theory, an old concept in cognitive psychology suggesting that people learn single sparse prototypes to categorize objects. Leveraging this relaxed assumption, we redesign Support Vector Machines (SVM), replacing its mathematical formulation with a fully nearest-neighbor-based solution, and to address the curse of dimensionality, we utilize locality-sensitive hashing. Following theory's generalizability principle, we propose a recursive method to prune non-core features. As a result, NL efficiently discovers the sparsest prototypes in O(n^2pL) with high parallelization capacity in terms of n. Evaluation of NL with 17 <b>benchmark</b> datasets shows its significant outperformance compared to decision trees and <b>logistic</b> <b>regression,</b> two methods widely favored in healthcare for their interpretability. Moreover, NL achieves performance comparable to <b>finetuned</b> <b>black-box</b> <b>models</b> such as deep neural networks and random forests in 40% of cases, with only a 1-2% lower average accuracy. The code is available via http://natural-learning.cc.

{{</citation>}}


### (6/34 | 150/266) Learning Heuristics for Transit Network Design and Improvement with Deep Reinforcement Learning (Andrew Holliday et al., 2024)

{{<citation>}}

Andrew Holliday, Ahmed El-Geneidy, Gregory Dudek. (2024)  
**Learning Heuristics for Transit Network Design and Improvement with Deep Reinforcement Learning**
<br/>
<button class="copy-to-clipboard" title="Learning Heuristics for Transit Network Design and Improvement with Deep Reinforcement Learning" index=150>
  <span class="copy-to-clipboard-item">Copy Title<span>
</button>
<div class="toast toast-copied toast-index-150 align-items-center text-bg-secondary border-0 position-absolute top-0 end-0" role="alert" aria-live="assertive" aria-atomic="true">
  <div class="d-flex">
    <div class="toast-body">
      Copied!
    </div>
  </div>
</div>

---
Primary Category: cs.LG  
Categories: cs-AI, cs-LG, cs-NE, cs.LG  
Keyword Score: 36  
Keywords: Graph, Benchmarking, Reinforcement Learning, Simulation, Simulator  
<a type="button" class="btn btn-outline-primary" href="http://arxiv.org/abs/2404.05894v1" target="_blank" >Paper Link</a>
<button type="button" class="btn btn-outline-primary download-pdf" url="https://arxiv.org/pdf/2404.05894v1.pdf" filename="2404.05894v1.pdf">Download PDF</button>

---


**ABSTRACT**  
Transit agencies world-wide face tightening budgets. To maintain quality of service while cutting costs, efficient transit network design is essential. But planning a network of public transit routes is a challenging optimization problem. The most successful approaches to date use metaheuristic algorithms to search through the space of solutions by applying low-level heuristics that randomly alter routes in a network. The design of these low-level heuristics has a major impact on the quality of the result. In this paper we use deep <b>reinforcement</b> <b>learning</b> with <b>graph</b> neural nets to learn low-level heuristics for an evolutionary algorithm, instead of designing them manually. These learned heuristics improve the algorithm's results on <b>benchmark</b> synthetic cities with 70 nodes or more, and obtain state-of-the-art results when optimizing operating costs. They also improve upon a <b>simulation</b> of the real transit network in the city of Laval, Canada, by as much as 54% and 18% on two key metrics, and offer cost savings of up to 12% over the city's existing transit network.

{{</citation>}}


### (7/34 | 151/266) Rapid and Precise Topological Comparison with Merge Tree Neural Networks (Yu Qin et al., 2024)

{{<citation>}}

Yu Qin, Brittany Terese Fasy, Carola Wenk, Brian Summa. (2024)  
**Rapid and Precise Topological Comparison with Merge Tree Neural Networks**
<br/>
<button class="copy-to-clipboard" title="Rapid and Precise Topological Comparison with Merge Tree Neural Networks" index=151>
  <span class="copy-to-clipboard-item">Copy Title<span>
</button>
<div class="toast toast-copied toast-index-151 align-items-center text-bg-secondary border-0 position-absolute top-0 end-0" role="alert" aria-live="assertive" aria-atomic="true">
  <div class="d-flex">
    <div class="toast-body">
      Copied!
    </div>
  </div>
</div>

---
Primary Category: cs.LG  
Categories: cs-CG, cs-LG, cs.LG  
Keyword Score: 36  
Keywords: Graph, Graph Neural Network, Graph Neural Network, Node Embedding, Benchmarking  
<a type="button" class="btn btn-outline-primary" href="http://arxiv.org/abs/2404.05879v1" target="_blank" >Paper Link</a>
<button type="button" class="btn btn-outline-primary download-pdf" url="https://arxiv.org/pdf/2404.05879v1.pdf" filename="2404.05879v1.pdf">Download PDF</button>

---


**ABSTRACT**  
Merge trees are a valuable tool in scientific visualization of scalar fields; however, current methods for merge tree comparisons are computationally expensive, primarily due to the exhaustive matching between tree <b>nodes.</b> <b>To</b> address this challenge, we introduce the merge tree neural networks (MTNN), a learned neural network model designed for merge tree comparison. The MTNN enables rapid and high-quality similarity computation. We first demonstrate how <b>graph</b> <b>neural</b> <b>networks</b> <b>(GNNs),</b> which emerged as an effective encoder for <b>graphs,</b> <b>can</b> <b>be</b> trained to produce embeddings of merge trees in vector spaces that enable efficient similarity comparison. Next, we formulate the novel MTNN model that further improves the similarity comparisons by integrating the tree and <b>node</b> <b>embeddings</b> with a new topological attention mechanism. We demonstrate the effectiveness of our model on real-world data in different domains and examine our model's generalizability across various datasets. Our experimental analysis demonstrates our approach's superiority in accuracy and efficiency. In particular, we speed up the prior state-of-the-art by more than 100x on the <b>benchmark</b> datasets while maintaining an error rate below 0.1%.

{{</citation>}}


### (8/34 | 152/266) Technical Report: The Graph Spectral Token -- Enhancing Graph Transformers with Spectral Information (Zihan Pengmei et al., 2024)

{{<citation>}}

Zihan Pengmei, Zimu Li. (2024)  
**Technical Report: The Graph Spectral Token -- Enhancing Graph Transformers with Spectral Information**
<br/>
<button class="copy-to-clipboard" title="Technical Report: The Graph Spectral Token -- Enhancing Graph Transformers with Spectral Information" index=152>
  <span class="copy-to-clipboard-item">Copy Title<span>
</button>
<div class="toast toast-copied toast-index-152 align-items-center text-bg-secondary border-0 position-absolute top-0 end-0" role="alert" aria-live="assertive" aria-atomic="true">
  <div class="d-flex">
    <div class="toast-body">
      Copied!
    </div>
  </div>
</div>

---
Primary Category: cs.LG  
Categories: cs-LG, cs.LG  
Keyword Score: 36  
Keywords: Message-Passing, Graph, Graph Neural Network, Benchmarking, Transformer  
<a type="button" class="btn btn-outline-primary" href="http://arxiv.org/abs/2404.05604v1" target="_blank" >Paper Link</a>
<button type="button" class="btn btn-outline-primary download-pdf" url="https://arxiv.org/pdf/2404.05604v1.pdf" filename="2404.05604v1.pdf">Download PDF</button>

---


**ABSTRACT**  
<b>Graph</b> <b>Transformers</b> <b>have</b> emerged as a powerful alternative to <b>Message-Passing</b> <b>Graph</b> <b>Neural</b> <b>Networks</b> (MP-GNNs) to address limitations such as over-squashing of information exchange. However, incorporating <b>graph</b> <b>inductive</b> <b>bias</b> into <b>transformer</b> architectures remains a significant challenge. In this report, we propose the <b>Graph</b> <b>Spectral</b> <b>Token,</b> a novel approach to directly encode <b>graph</b> <b>spectral</b> <b>information,</b> which captures the global structure of the <b>graph,</b> <b>into</b> <b>the</b> <b>transformer</b> architecture. By parameterizing the auxiliary [CLS] token and leaving other tokens representing <b>graph</b> <b>nodes,</b> <b>our</b> method seamlessly integrates spectral information into the learning process. We <b>benchmark</b> the effectiveness of our approach by enhancing two existing <b>graph</b> <b>transformers,</b> <b>GraphTrans</b> and SubFormer. The improved GraphTrans, dubbed GraphTrans-Spec, achieves over 10% improvements on large <b>graph</b> <b>benchmark</b> <b>datasets</b> while maintaining efficiency comparable to MP-GNNs. SubFormer-Spec demonstrates strong performance across various datasets.

{{</citation>}}


### (9/34 | 153/266) BruSLeAttack: A Query-Efficient Score-Based Black-Box Sparse Adversarial Attack (Viet Quoc Vo et al., 2024)

{{<citation>}}

Viet Quoc Vo, Ehsan Abbasnejad, Damith C. Ranasinghe. (2024)  
**BruSLeAttack: A Query-Efficient Score-Based Black-Box Sparse Adversarial Attack**
<br/>
<button class="copy-to-clipboard" title="BruSLeAttack: A Query-Efficient Score-Based Black-Box Sparse Adversarial Attack" index=153>
  <span class="copy-to-clipboard-item">Copy Title<span>
</button>
<div class="toast toast-copied toast-index-153 align-items-center text-bg-secondary border-0 position-absolute top-0 end-0" role="alert" aria-live="assertive" aria-atomic="true">
  <div class="d-flex">
    <div class="toast-body">
      Copied!
    </div>
  </div>
</div>

---
Primary Category: cs.LG  
Categories: cs-CR, cs-LG, cs.LG  
Keyword Score: 35  
Keywords: Adversarial Learning, Black Box, Adversarial Attack, Security  
<a type="button" class="btn btn-outline-primary" href="http://arxiv.org/abs/2404.05311v1" target="_blank" >Paper Link</a>
<button type="button" class="btn btn-outline-primary download-pdf" url="https://arxiv.org/pdf/2404.05311v1.pdf" filename="2404.05311v1.pdf">Download PDF</button>

---


**ABSTRACT**  
We study the unique, less-well understood problem of generating sparse <b>adversarial</b> <b>samples</b> simply by observing the score-based replies to model queries. Sparse attacks aim to discover a minimum number-the l0 bounded-perturbations to model inputs to craft <b>adversarial</b> <b>examples</b> and misguide model decisions. But, in contrast to query-based dense attack counterparts against <b>black-box</b> <b>models,</b> constructing sparse <b>adversarial</b> <b>perturbations,</b> even when models serve confidence score information to queries in a score-based setting, is non-trivial. Because, such an attack leads to i) an NP-hard problem; and ii) a non-differentiable search space. We develop the BruSLeAttack-a new, faster (more query-efficient) Bayesian algorithm for the problem. We conduct extensive attack evaluations including an attack demonstration against a Machine Learning as a Service (MLaaS) offering exemplified by Google Cloud Vision and robustness testing of <b>adversarial</b> <b>training</b> regimes and a recent defense against <b>black-box</b> <b>attacks.</b> The proposed attack scales to achieve state-of-the-art attack success rates and query efficiency on standard computer vision tasks such as ImageNet across different model architectures. Our artefacts and DIY attack samples are available on GitHub. Importantly, our work facilitates faster evaluation of model vulnerabilities and raises our vigilance on the safety, <b>security</b> and reliability of deployed systems.

{{</citation>}}


### (10/34 | 154/266) Robust Data Pruning: Uncovering and Overcoming Implicit Bias (Artem Vysogorets et al., 2024)

{{<citation>}}

Artem Vysogorets, Kartik Ahuja, Julia Kempe. (2024)  
**Robust Data Pruning: Uncovering and Overcoming Implicit Bias**
<br/>
<button class="copy-to-clipboard" title="Robust Data Pruning: Uncovering and Overcoming Implicit Bias" index=154>
  <span class="copy-to-clipboard-item">Copy Title<span>
</button>
<div class="toast toast-copied toast-index-154 align-items-center text-bg-secondary border-0 position-absolute top-0 end-0" role="alert" aria-live="assertive" aria-atomic="true">
  <div class="d-flex">
    <div class="toast-body">
      Copied!
    </div>
  </div>
</div>

---
Primary Category: cs.LG  
Categories: cs-CV, cs-LG, cs.LG  
Keyword Score: 33  
Keywords: Benchmarking, Fairness, Pruning, Scaling Law  
<a type="button" class="btn btn-outline-primary" href="http://arxiv.org/abs/2404.05579v1" target="_blank" >Paper Link</a>
<button type="button" class="btn btn-outline-primary download-pdf" url="https://arxiv.org/pdf/2404.05579v1.pdf" filename="2404.05579v1.pdf">Download PDF</button>

---


**ABSTRACT**  
In the era of exceptionally data-hungry models, careful selection of the training data is essential to mitigate the extensive costs of deep learning. Data <b>pruning</b> offers a solution by removing redundant or uninformative samples from the dataset, which yields faster convergence and improved neural <b>scaling</b> <b>laws.</b> However, little is known about its impact on classification bias of the trained models. We conduct the first systematic study of this effect and reveal that existing data <b>pruning</b> algorithms can produce highly biased classifiers. At the same time, we argue that random data <b>pruning</b> with appropriate class ratios has potential to improve the worst-class performance. We propose a <b>"fairness-aware"</b> approach to <b>pruning</b> and empirically demonstrate its performance on standard computer vision <b>benchmarks.</b> In sharp contrast to existing algorithms, our proposed method continues improving robustness at a tolerable drop of average performance as we prune more from the datasets. We present theoretical analysis of the classification risk in a mixture of Gaussians to further motivate our algorithm and support our findings.

{{</citation>}}


### (11/34 | 155/266) On the Convergence of Continual Learning with Adaptive Methods (Seungyub Han et al., 2024)

{{<citation>}}

Seungyub Han, Yeongmo Kim, Taehyun Cho, Jungwoo Lee. (2024)  
**On the Convergence of Continual Learning with Adaptive Methods**
<br/>
<button class="copy-to-clipboard" title="On the Convergence of Continual Learning with Adaptive Methods" index=155>
  <span class="copy-to-clipboard-item">Copy Title<span>
</button>
<div class="toast toast-copied toast-index-155 align-items-center text-bg-secondary border-0 position-absolute top-0 end-0" role="alert" aria-live="assertive" aria-atomic="true">
  <div class="d-flex">
    <div class="toast-body">
      Copied!
    </div>
  </div>
</div>

---
Primary Category: cs.LG  
Categories: cs-AI, cs-LG, cs.LG, stat-ML  
Keyword Score: 30  
Keywords: Continual Learning, Stochastic Gradient Descent, Stochastic Gradient Descent  
<a type="button" class="btn btn-outline-primary" href="http://arxiv.org/abs/2404.05555v1" target="_blank" >Paper Link</a>
<button type="button" class="btn btn-outline-primary download-pdf" url="https://arxiv.org/pdf/2404.05555v1.pdf" filename="2404.05555v1.pdf">Download PDF</button>

---


**ABSTRACT**  
One of the objectives of <b>continual</b> <b>learning</b> is to prevent catastrophic forgetting in learning multiple tasks sequentially, and the existing solutions have been driven by the conceptualization of the plasticity-stability dilemma. However, the convergence of <b>continual</b> <b>learning</b> for each sequential task is less studied so far. In this paper, we provide a convergence analysis of memory-based <b>continual</b> <b>learning</b> with <b>stochastic</b> <b>gradient</b> <b>descent</b> and empirical evidence that training current tasks causes the cumulative degradation of previous tasks. We propose an adaptive method for nonconvex <b>continual</b> <b>learning</b> (NCCL), which adjusts step sizes of both previous and current tasks with the gradients. The proposed method can achieve the same convergence rate as the <b>SGD</b> method when the catastrophic forgetting term which we define in the paper is suppressed at each iteration. Further, we demonstrate that the proposed algorithm improves the performance of <b>continual</b> <b>learning</b> over existing methods for several image classification tasks.

{{</citation>}}


### (12/34 | 156/266) Out-of-Distribution Data: An Acquaintance of Adversarial Examples -- A Survey (Naveen Karunanayake et al., 2024)

{{<citation>}}

Naveen Karunanayake, Ravin Gunawardena, Suranga Seneviratne, Sanjay Chawla. (2024)  
**Out-of-Distribution Data: An Acquaintance of Adversarial Examples -- A Survey**
<br/>
<button class="copy-to-clipboard" title="Out-of-Distribution Data: An Acquaintance of Adversarial Examples -- A Survey" index=156>
  <span class="copy-to-clipboard-item">Copy Title<span>
</button>
<div class="toast toast-copied toast-index-156 align-items-center text-bg-secondary border-0 position-absolute top-0 end-0" role="alert" aria-live="assertive" aria-atomic="true">
  <div class="d-flex">
    <div class="toast-body">
      Copied!
    </div>
  </div>
</div>

---
Primary Category: cs.LG  
Categories: cs-LG, cs.LG  
Keyword Score: 30  
Keywords: Anomaly Detection, Out-of-distribution, Adversarial Attack  
<a type="button" class="btn btn-outline-primary" href="http://arxiv.org/abs/2404.05219v1" target="_blank" >Paper Link</a>
<button type="button" class="btn btn-outline-primary download-pdf" url="https://arxiv.org/pdf/2404.05219v1.pdf" filename="2404.05219v1.pdf">Download PDF</button>

---


**ABSTRACT**  
Deep neural networks (DNNs) deployed in real-world applications can encounter <b>out-of-distribution</b> (OOD) data and <b>adversarial</b> <b>examples.</b> These represent distinct forms of distributional shifts that can significantly impact DNNs' reliability and robustness. Traditionally, research has addressed OOD detection and <b>adversarial</b> <b>robustness</b> as separate challenges. This survey focuses on the intersection of these two areas, examining how the research community has investigated them together. Consequently, we identify two key research directions: robust OOD detection and unified robustness. Robust OOD detection aims to differentiate between in-distribution (ID) data and OOD data, even when they are adversarially manipulated to deceive the OOD detector. Unified robustness seeks a single approach to make DNNs robust against both <b>adversarial</b> <b>attacks</b> and OOD inputs. Accordingly, first, we establish a taxonomy based on the concept of distributional shifts. This framework clarifies how robust OOD detection and unified robustness relate to other research areas addressing distributional shifts, such as OOD detection, open set recognition, and <b>anomaly</b> <b>detection.</b> Subsequently, we review existing work on robust OOD detection and unified robustness. Finally, we highlight the limitations of the existing work and propose promising research directions that explore <b>adversarial</b> <b>and</b> OOD inputs within a unified framework.

{{</citation>}}


### (13/34 | 157/266) Certified PEFTSmoothing: Parameter-Efficient Fine-Tuning with Randomized Smoothing (Chengyan Fu et al., 2024)

{{<citation>}}

Chengyan Fu, Wenjie Wang. (2024)  
**Certified PEFTSmoothing: Parameter-Efficient Fine-Tuning with Randomized Smoothing**
<br/>
<button class="copy-to-clipboard" title="Certified PEFTSmoothing: Parameter-Efficient Fine-Tuning with Randomized Smoothing" index=157>
  <span class="copy-to-clipboard-item">Copy Title<span>
</button>
<div class="toast toast-copied toast-index-157 align-items-center text-bg-secondary border-0 position-absolute top-0 end-0" role="alert" aria-live="assertive" aria-atomic="true">
  <div class="d-flex">
    <div class="toast-body">
      Copied!
    </div>
  </div>
</div>

---
Primary Category: cs.LG  
Categories: cs-CR, cs-LG, cs.LG  
Keyword Score: 25  
Keywords: Black Box, Convolutional Neural Network, Fine-tuning  
<a type="button" class="btn btn-outline-primary" href="http://arxiv.org/abs/2404.05350v1" target="_blank" >Paper Link</a>
<button type="button" class="btn btn-outline-primary download-pdf" url="https://arxiv.org/pdf/2404.05350v1.pdf" filename="2404.05350v1.pdf">Download PDF</button>

---


**ABSTRACT**  
Randomized smoothing is the primary certified robustness method for accessing the robustness of deep learning models to adversarial perturbations in the l2-norm, by adding isotropic Gaussian noise to the input image and returning the majority votes over the base classifier. Theoretically, it provides a certified norm bound, ensuring predictions of adversarial examples are stable within this bound. A notable constraint limiting widespread adoption is the necessity to retrain base models entirely from scratch to attain a robust version. This is because the base model fails to learn the noise-augmented data distribution to give an accurate vote. One intuitive way to overcome this challenge is to involve a custom-trained denoiser to eliminate the noise. However, this approach is inefficient and sub-optimal. Inspired by recent large model training procedures, we explore an alternative way named PEFTSmoothing to adapt the base model to learn the Gaussian noise-augmented data with Parameter-Efficient <b>Fine-Tuning</b> (PEFT) methods in both white-box and <b>black-box</b> <b>settings.</b> Extensive results demonstrate the effectiveness and efficiency of PEFTSmoothing, which allow us to certify over 98% accuracy for ViT on CIFAR-10, 20% higher than SoTA denoised smoothing, and over 61% accuracy on ImageNet which is 30% higher than <b>CNN-based</b> denoiser and comparable to the Diffusion-based denoiser.

{{</citation>}}


### (14/34 | 158/266) Negative Preference Optimization: From Catastrophic Collapse to Effective Unlearning (Ruiqi Zhang et al., 2024)

{{<citation>}}

Ruiqi Zhang, Licong Lin, Yu Bai, Song Mei. (2024)  
**Negative Preference Optimization: From Catastrophic Collapse to Effective Unlearning**
<br/>
<button class="copy-to-clipboard" title="Negative Preference Optimization: From Catastrophic Collapse to Effective Unlearning" index=158>
  <span class="copy-to-clipboard-item">Copy Title<span>
</button>
<div class="toast toast-copied toast-index-158 align-items-center text-bg-secondary border-0 position-absolute top-0 end-0" role="alert" aria-live="assertive" aria-atomic="true">
  <div class="d-flex">
    <div class="toast-body">
      Copied!
    </div>
  </div>
</div>

---
Primary Category: cs.LG  
Categories: cs-AI, cs-CL, cs-LG, cs.LG, stat-ML  
Keyword Score: 23  
Keywords: Benchmarking, Large Language Model, Large Language Model  
<a type="button" class="btn btn-outline-primary" href="http://arxiv.org/abs/2404.05868v1" target="_blank" >Paper Link</a>
<button type="button" class="btn btn-outline-primary download-pdf" url="https://arxiv.org/pdf/2404.05868v1.pdf" filename="2404.05868v1.pdf">Download PDF</button>

---


**ABSTRACT**  
<b>Large</b> <b>Language</b> <b>Models</b> <b>(LLMs)</b> often memorize sensitive, private, or copyrighted data during pre-training. <b>LLM</b> unlearning aims to eliminate the influence of undesirable data from the pre-trained model while preserving the model's utilities on other tasks. Several practical methods have recently been proposed for <b>LLM</b> unlearning, mostly based on gradient ascent (GA) on the loss of undesirable data. However, on certain unlearning tasks, these methods either fail to effectively unlearn the target data or suffer from catastrophic collapse -- a drastic degradation of the model's utilities. In this paper, we propose Negative Preference Optimization (NPO), a simple alignment-inspired method that could efficiently and effectively unlearn a target dataset. We theoretically show that the progression toward catastrophic collapse by minimizing the NPO loss is exponentially slower than GA. Through experiments on synthetic data and the <b>benchmark</b> TOFU dataset, we demonstrate that NPO-based methods achieve a better balance between unlearning the undesirable data and maintaining the model's utilities. We also observe that NPO-based methods generate more sensible outputs than GA-based methods, whose outputs are often gibberish. Remarkably, on TOFU, NPO-based methods are the first to achieve reasonable unlearning results in forgetting 50% (or more) of the training data, whereas existing methods already struggle with forgetting 10% of training data.

{{</citation>}}


### (15/34 | 159/266) Self-Labeling in Multivariate Causality and Quantification for Adaptive Machine Learning (Yutian Ren et al., 2024)

{{<citation>}}

Yutian Ren, Aaron Haohua Yen, G. P. Li. (2024)  
**Self-Labeling in Multivariate Causality and Quantification for Adaptive Machine Learning**
<br/>
<button class="copy-to-clipboard" title="Self-Labeling in Multivariate Causality and Quantification for Adaptive Machine Learning" index=159>
  <span class="copy-to-clipboard-item">Copy Title<span>
</button>
<div class="toast toast-copied toast-index-159 align-items-center text-bg-secondary border-0 position-absolute top-0 end-0" role="alert" aria-live="assertive" aria-atomic="true">
  <div class="d-flex">
    <div class="toast-body">
      Copied!
    </div>
  </div>
</div>

---
Primary Category: cs.LG  
Categories: cs-AI, cs-LG, cs.LG, stat-ME  
Keyword Score: 23  
Keywords: Graph, Semi-Supervised Learning, Domain Adaptation  
<a type="button" class="btn btn-outline-primary" href="http://arxiv.org/abs/2404.05809v1" target="_blank" >Paper Link</a>
<button type="button" class="btn btn-outline-primary download-pdf" url="https://arxiv.org/pdf/2404.05809v1.pdf" filename="2404.05809v1.pdf">Download PDF</button>

---


**ABSTRACT**  
Adaptive machine learning (ML) aims to allow ML models to adapt to ever-changing environments with potential concept drift after model deployment. Traditionally, adaptive ML requires a new dataset to be manually labeled to tailor deployed models to altered data distributions. Recently, an interactive causality based self-labeling method was proposed to autonomously associate causally related data streams for <b>domain</b> <b>adaptation,</b> showing promising results compared to traditional feature similarity-based <b>semi-supervised</b> <b>learning.</b> Several unanswered research questions remain, including self-labeling's compatibility with multivariate causality and the quantitative analysis of the auxiliary models used in the self-labeling. The auxiliary models, the interaction time model (ITM) and the effect state detector (ESD), are vital to the success of self-labeling. This paper further develops the self-labeling framework and its theoretical foundations to address these research questions. A framework for the application of self-labeling to multivariate causal <b>graphs</b> is proposed using four basic causal relationships, and the impact of non-ideal ITM and ESD performance is analyzed. A simulated experiment is conducted based on a multivariate causal <b>graph,</b> validating the proposed theory.

{{</citation>}}


### (16/34 | 160/266) Graph Neural Networks Automated Design and Deployment on Device-Edge Co-Inference Systems (Ao Zhou et al., 2024)

{{<citation>}}

Ao Zhou, Jianlei Yang, Tong Qiao, Yingjie Qi, Zhi Yang, Weisheng Zhao, Chunming Hu. (2024)  
**Graph Neural Networks Automated Design and Deployment on Device-Edge Co-Inference Systems**
<br/>
<button class="copy-to-clipboard" title="Graph Neural Networks Automated Design and Deployment on Device-Edge Co-Inference Systems" index=160>
  <span class="copy-to-clipboard-item">Copy Title<span>
</button>
<div class="toast toast-copied toast-index-160 align-items-center text-bg-secondary border-0 position-absolute top-0 end-0" role="alert" aria-live="assertive" aria-atomic="true">
  <div class="d-flex">
    <div class="toast-body">
      Copied!
    </div>
  </div>
</div>

---
Primary Category: cs.LG  
Categories: cs-AI, cs-LG, cs.LG  
Keyword Score: 23  
Keywords: Graph, Graph Neural Network, Graph Neural Network  
<a type="button" class="btn btn-outline-primary" href="http://arxiv.org/abs/2404.05605v1" target="_blank" >Paper Link</a>
<button type="button" class="btn btn-outline-primary download-pdf" url="https://arxiv.org/pdf/2404.05605v1.pdf" filename="2404.05605v1.pdf">Download PDF</button>

---


**ABSTRACT**  
The key to device-edge co-inference paradigm is to partition models into computation-friendly and computation-intensive parts across the device and the edge, respectively. However, for <b>Graph</b> <b>Neural</b> <b>Networks</b> <b>(GNNs),</b> we find that simply partitioning without altering their structures can hardly achieve the full potential of the co-inference paradigm due to various computational-communication overheads of <b>GNN</b> operations over heterogeneous devices. We present GCoDE, the first automatic framework for <b>GNN</b> that innovatively Co-designs the architecture search and the mapping of each operation on Device-Edge hierarchies. GCoDE abstracts the device communication process into an explicit operation and fuses the search of architecture and the operations mapping in a unified space for joint-optimization. Also, the performance-awareness approach, utilized in the constraint-based search process of GCoDE, enables effective evaluation of architecture efficiency in diverse heterogeneous systems. We implement the co-inference engine and runtime dispatcher in GCoDE to enhance the deployment efficiency. Experimental results show that GCoDE can achieve up to $44.9\times$ speedup and $98.2\%$ energy reduction compared to existing approaches across various applications and system configurations.

{{</citation>}}


### (17/34 | 161/266) Back to the Future: GNN-based NO$_2$ Forecasting via Future Covariates (Antonio Giganti et al., 2024)

{{<citation>}}

Antonio Giganti, Sara Mandelli, Paolo Bestagini, Umberto Giuriato, Alessandro D'Ausilio, Marco Marcon, Stefano Tubaro. (2024)  
**Back to the Future: GNN-based NO$_2$ Forecasting via Future Covariates**
<br/>
<button class="copy-to-clipboard" title="Back to the Future: GNN-based NO$_2$ Forecasting via Future Covariates" index=161>
  <span class="copy-to-clipboard-item">Copy Title<span>
</button>
<div class="toast toast-copied toast-index-161 align-items-center text-bg-secondary border-0 position-absolute top-0 end-0" role="alert" aria-live="assertive" aria-atomic="true">
  <div class="d-flex">
    <div class="toast-body">
      Copied!
    </div>
  </div>
</div>

---
Primary Category: cs.LG  
Categories: cs-AI, cs-LG, cs.LG, eess-SP  
Keyword Score: 23  
Keywords: Graph, Graph Neural Network, Graph Neural Network  
<a type="button" class="btn btn-outline-primary" href="http://arxiv.org/abs/2404.05324v1" target="_blank" >Paper Link</a>
<button type="button" class="btn btn-outline-primary download-pdf" url="https://arxiv.org/pdf/2404.05324v1.pdf" filename="2404.05324v1.pdf">Download PDF</button>

---


**ABSTRACT**  
Due to the latest environmental concerns in keeping at bay contaminants emissions in urban areas, air pollution forecasting has been rising the forefront of all researchers around the world. When predicting pollutant concentrations, it is common to include the effects of environmental factors that influence these concentrations within an extended period, like traffic, meteorological conditions and geographical information. Most of the existing approaches exploit this information as past covariates, i.e., past exogenous variables that affected the pollutant but were not affected by it. In this paper, we present a novel forecasting methodology to predict NO$_2$ concentration via both past and future covariates. Future covariates are represented by weather forecasts and future calendar events, which are already known at prediction time. In particular, we deal with air quality observations in a city-wide network of ground monitoring stations, modeling the data structure and estimating the predictions with a Spatiotemporal <b>Graph</b> <b>Neural</b> <b>Network</b> (STGNN). We propose a conditioning block that embeds past and future covariates into the current observations. After extracting meaningful spatiotemporal representations, these are fused together and projected into the forecasting horizon to generate the final prediction. To the best of our knowledge, it is the first time that future covariates are included in time series predictions in a structured way. Remarkably, we find that conditioning on future weather information has a greater impact than considering past traffic conditions. We release our code implementation at https://github.com/polimi-ispl/MAGCRN.

{{</citation>}}


### (18/34 | 162/266) A Large-Scale Exploration of $μ$-Transfer (Lucas Lingle, 2024)

{{<citation>}}

Lucas Lingle. (2024)  
**A Large-Scale Exploration of $μ$-Transfer**
<br/>
<button class="copy-to-clipboard" title="A Large-Scale Exploration of $μ$-Transfer" index=162>
  <span class="copy-to-clipboard-item">Copy Title<span>
</button>
<div class="toast toast-copied toast-index-162 align-items-center text-bg-secondary border-0 position-absolute top-0 end-0" role="alert" aria-live="assertive" aria-atomic="true">
  <div class="d-flex">
    <div class="toast-body">
      Copied!
    </div>
  </div>
</div>

---
Primary Category: cs.LG  
Categories: cs-LG, cs.LG  
Keyword Score: 20  
Keywords: Zero-shot, Transformer  
<a type="button" class="btn btn-outline-primary" href="http://arxiv.org/abs/2404.05728v2" target="_blank" >Paper Link</a>
<button type="button" class="btn btn-outline-primary download-pdf" url="https://arxiv.org/pdf/2404.05728v2.pdf" filename="2404.05728v2.pdf">Download PDF</button>

---


**ABSTRACT**  
Large neural network models have become a mainstay of natural language processing and computer vision, yet their initialization and learning rates are set in a largely heuristic fashion, potentially varying from paper to paper and one model size to the next. The $\mu$-Parameterization ($\mu$P) offers a potential solution to these challenges, yielding scaling rules for model initialization and learning rates, and reportedly enabling <b>zero-shot</b> hyperparameter transfer from small to large models in a variety of cases. Despite the evident promise, the $\mu$P scaling rules are not yet widely adopted, perhaps due to higher implementation complexity, many variations, or complex theoretical background. This work investigates $\mu$P empirically, focusing on the ubiquitous <b>transformer</b> architecture, and aims to answer a simple question: does $\mu$-Transfer yield optimal learning rates in practice? From models with 2M to 10B parameters, we show that $\mu$-Transfer works as intended for the majority of important cases, but also identify some surprising cases where it may not. Our experiment codebase is available at https://github.com/lucaslingle/mu_transformer/

{{</citation>}}


### (19/34 | 163/266) Dynamic Backtracking in GFlowNets: Enhancing Decision Steps with Reward-Dependent Adjustment Mechanisms (Shuai Guo et al., 2024)

{{<citation>}}

Shuai Guo, Jielei Chu, Lei Zhu, Tianrui Li. (2024)  
**Dynamic Backtracking in GFlowNets: Enhancing Decision Steps with Reward-Dependent Adjustment Mechanisms**
<br/>
<button class="copy-to-clipboard" title="Dynamic Backtracking in GFlowNets: Enhancing Decision Steps with Reward-Dependent Adjustment Mechanisms" index=163>
  <span class="copy-to-clipboard-item">Copy Title<span>
</button>
<div class="toast toast-copied toast-index-163 align-items-center text-bg-secondary border-0 position-absolute top-0 end-0" role="alert" aria-live="assertive" aria-atomic="true">
  <div class="d-flex">
    <div class="toast-body">
      Copied!
    </div>
  </div>
</div>

---
Primary Category: cs.LG  
Categories: cs-LG, cs.LG  
Keyword Score: 20  
Keywords: Probabilistic Model, Reinforcement Learning  
<a type="button" class="btn btn-outline-primary" href="http://arxiv.org/abs/2404.05576v2" target="_blank" >Paper Link</a>
<button type="button" class="btn btn-outline-primary download-pdf" url="https://arxiv.org/pdf/2404.05576v2.pdf" filename="2404.05576v2.pdf">Download PDF</button>

---


**ABSTRACT**  
Generative Flow Networks (GFlowNets) are <b>probabilistic</b> <b>models</b> predicated on Markov flows, employing specific amortization algorithms to learn stochastic policies that generate compositional substances including biomolecules, chemical materials, and more. Demonstrating formidable prowess in generating high-performance biochemical molecules, GFlowNets accelerate the discovery of scientific substances, effectively circumventing the time-consuming, labor-intensive, and costly shortcomings intrinsic to conventional material discovery. However, previous work often struggles to accumulate exploratory experience and is prone to becoming disoriented within expansive sampling spaces. Attempts to address this issue, such as LS-GFN, are limited to local greedy searches and lack broader global adjustments. This paper introduces a novel GFlowNets variant, the Dynamic Backtracking GFN (DB-GFN), which enhances the adaptability of decision-making steps through a reward-based dynamic backtracking mechanism. DB-GFN permits backtracking during the network construction process according to the current state's reward value, thus correcting disadvantageous decisions and exploring alternative pathways during the exploration process. Applied to generative tasks of biochemical molecules and genetic material sequences, DB-GFN surpasses existing GFlowNets models and traditional <b>reinforcement</b> <b>learning</b> methods in terms of sample quality, exploration sample quantity, and training convergence speed. Furthermore, the orthogonal nature of DB-GFN suggests its potential as a powerful tool for future improvements in GFlowNets, with the promise of integrating with other strategies to achieve more efficient search performance.

{{</citation>}}


### (20/34 | 164/266) Dense Training, Sparse Inference: Rethinking Training of Mixture-of-Experts Language Models (Bowen Pan et al., 2024)

{{<citation>}}

Bowen Pan, Yikang Shen, Haokun Liu, Mayank Mishra, Gaoyuan Zhang, Aude Oliva, Colin Raffel, Rameswar Panda. (2024)  
**Dense Training, Sparse Inference: Rethinking Training of Mixture-of-Experts Language Models**
<br/>
<button class="copy-to-clipboard" title="Dense Training, Sparse Inference: Rethinking Training of Mixture-of-Experts Language Models" index=164>
  <span class="copy-to-clipboard-item">Copy Title<span>
</button>
<div class="toast toast-copied toast-index-164 align-items-center text-bg-secondary border-0 position-absolute top-0 end-0" role="alert" aria-live="assertive" aria-atomic="true">
  <div class="d-flex">
    <div class="toast-body">
      Copied!
    </div>
  </div>
</div>

---
Primary Category: cs.LG  
Categories: cs-AI, cs-CL, cs-LG, cs.LG  
Keyword Score: 20  
Keywords: Mistral, Large Language Model  
<a type="button" class="btn btn-outline-primary" href="http://arxiv.org/abs/2404.05567v1" target="_blank" >Paper Link</a>
<button type="button" class="btn btn-outline-primary download-pdf" url="https://arxiv.org/pdf/2404.05567v1.pdf" filename="2404.05567v1.pdf">Download PDF</button>

---


**ABSTRACT**  
Mixture-of-Experts (MoE) language models can reduce computational costs by 2-4$\times$ compared to dense models without sacrificing performance, making them more efficient in computation-bounded scenarios. However, MoE models generally require 2-4$\times$ times more parameters to achieve comparable performance to a dense model, which incurs larger GPU memory requirements and makes MoE models less efficient in I/O-bounded scenarios like autoregressive generation. In this work, we propose a hybrid dense training and sparse inference framework for MoE models (DS-MoE) which achieves strong computation and parameter efficiency by employing dense computation across all experts during training and sparse computation during inference. Our experiments on training <b>LLMs</b> demonstrate that our DS-MoE models are more parameter-efficient than standard sparse MoEs and are on par with dense models in terms of total parameter size and performance while being computationally cheaper (activating 30-40% of the model's parameters). Performance tests using vLLM show that our DS-MoE-6B model runs up to $1.86\times$ faster than similar dense models like <b>Mistral-7B,</b> and between $1.50\times$ and $1.71\times$ faster than comparable MoEs, such as DeepSeekMoE-16B and Qwen1.5-MoE-A2.7B.

{{</citation>}}


### (21/34 | 165/266) Stochastic Online Optimization for Cyber-Physical and Robotic Systems (Hao Ma et al., 2024)

{{<citation>}}

Hao Ma, Melanie Zeilinger, Michael Muehlebach. (2024)  
**Stochastic Online Optimization for Cyber-Physical and Robotic Systems**
<br/>
<button class="copy-to-clipboard" title="Stochastic Online Optimization for Cyber-Physical and Robotic Systems" index=165>
  <span class="copy-to-clipboard-item">Copy Title<span>
</button>
<div class="toast toast-copied toast-index-165 align-items-center text-bg-secondary border-0 position-absolute top-0 end-0" role="alert" aria-live="assertive" aria-atomic="true">
  <div class="d-flex">
    <div class="toast-body">
      Copied!
    </div>
  </div>
</div>

---
Primary Category: cs.LG  
Categories: cs-LG, cs-RO, cs.LG  
Keyword Score: 20  
Keywords: Simulation, Simulator  
<a type="button" class="btn btn-outline-primary" href="http://arxiv.org/abs/2404.05318v1" target="_blank" >Paper Link</a>
<button type="button" class="btn btn-outline-primary download-pdf" url="https://arxiv.org/pdf/2404.05318v1.pdf" filename="2404.05318v1.pdf">Download PDF</button>

---


**ABSTRACT**  
We propose a novel gradient-based online optimization framework for solving stochastic programming problems that frequently arise in the context of cyber-physical and robotic systems. Our problem formulation accommodates constraints that model the evolution of a cyber-physical system, which has, in general, a continuous state and action space, is nonlinear, and where the state is only partially observed. We also incorporate an approximate model of the dynamics as prior knowledge into the learning process and show that even rough estimates of the dynamics can significantly improve the convergence of our algorithms. Our online optimization framework encompasses both gradient descent and quasi-Newton methods, and we provide a unified convergence analysis of our algorithms in a non-convex setting. We also characterize the impact of modeling errors in the system dynamics on the convergence rate of the algorithms. Finally, we evaluate our algorithms in <b>simulations</b> of a flexible beam, a four-legged walking robot, and in real-world experiments with a ping-pong playing robot.

{{</citation>}}


### (22/34 | 166/266) Empirical Upscaling of Point-scale Soil Moisture Measurements for Spatial Evaluation of Model Simulations and Satellite Retrievals (Yi Yu et al., 2024)

{{<citation>}}

Yi Yu, Brendan P. Malone, Luigi J. Renzullo. (2024)  
**Empirical Upscaling of Point-scale Soil Moisture Measurements for Spatial Evaluation of Model Simulations and Satellite Retrievals**
<br/>
<button class="copy-to-clipboard" title="Empirical Upscaling of Point-scale Soil Moisture Measurements for Spatial Evaluation of Model Simulations and Satellite Retrievals" index=166>
  <span class="copy-to-clipboard-item">Copy Title<span>
</button>
<div class="toast toast-copied toast-index-166 align-items-center text-bg-secondary border-0 position-absolute top-0 end-0" role="alert" aria-live="assertive" aria-atomic="true">
  <div class="d-flex">
    <div class="toast-body">
      Copied!
    </div>
  </div>
</div>

---
Primary Category: cs.LG  
Categories: cs-LG, cs.LG  
Keyword Score: 20  
Keywords: Simulation, Simulator  
<a type="button" class="btn btn-outline-primary" href="http://arxiv.org/abs/2404.05229v1" target="_blank" >Paper Link</a>
<button type="button" class="btn btn-outline-primary download-pdf" url="https://arxiv.org/pdf/2404.05229v1.pdf" filename="2404.05229v1.pdf">Download PDF</button>

---


**ABSTRACT**  
The evaluation of modelled or satellite-derived soil moisture (SM) estimates is usually dependent on comparisons against in-situ SM measurements. However, the inherent mismatch in spatial support (i.e., scale) necessitates a cautious interpretation of point-to-pixel comparisons. The upscaling of the in-situ measurements to a commensurate resolution to that of the modelled or retrieved SM will lead to a fairer comparison and statistically more defensible evaluation. In this study, we presented an upscaling approach that combines spatiotemporal fusion with machine learning to extrapolate point-scale SM measurements from 28 in-situ sites to a 100 m resolution for an agricultural area of 100 km by 100 km. We conducted a four-fold cross-validation, which consistently demonstrated comparable correlation performance across folds, ranging from 0.6 to 0.9. The proposed approach was further validated based on a cross-cluster strategy by using two spatial subsets within the study area, denoted as cluster A and B, each of which equally comprised of 12 in-situ sites. The cross-cluster validation underscored the capability of the upscaling approach to map the spatial variability of SM within areas that were not covered by in-situ sites, with correlation performance ranging between 0.6 and 0.8. In general, our proposed upscaling approach offers an avenue to extrapolate point measurements of SM to a spatial scale more akin to climatic model grids or remotely sensed observations. Future investigations should delve into a further evaluation of the upscaling approach using independent data, such as model <b>simulations,</b> satellite retrievals or field campaign data.

{{</citation>}}


### (23/34 | 167/266) On the price of exact truthfulness in incentive-compatible online learning with bandit feedback: A regret lower bound for WSU-UX (Ali Mortazavi et al., 2024)

{{<citation>}}

Ali Mortazavi, Junhao Lin, Nishant A. Mehta. (2024)  
**On the price of exact truthfulness in incentive-compatible online learning with bandit feedback: A regret lower bound for WSU-UX**
<br/>
<button class="copy-to-clipboard" title="On the price of exact truthfulness in incentive-compatible online learning with bandit feedback: A regret lower bound for WSU-UX" index=167>
  <span class="copy-to-clipboard-item">Copy Title<span>
</button>
<div class="toast toast-copied toast-index-167 align-items-center text-bg-secondary border-0 position-absolute top-0 end-0" role="alert" aria-live="assertive" aria-atomic="true">
  <div class="d-flex">
    <div class="toast-body">
      Copied!
    </div>
  </div>
</div>

---
Primary Category: cs.LG  
Categories: cs-GT, cs-LG, cs.LG, stat-ML  
Keyword Score: 20  
Keywords: Bandit Algorithm, Bandit Algorithm  
<a type="button" class="btn btn-outline-primary" href="http://arxiv.org/abs/2404.05155v1" target="_blank" >Paper Link</a>
<button type="button" class="btn btn-outline-primary download-pdf" url="https://arxiv.org/pdf/2404.05155v1.pdf" filename="2404.05155v1.pdf">Download PDF</button>

---


**ABSTRACT**  
In one view of the classical game of prediction with expert advice with binary outcomes, in each round, each expert maintains an adversarially chosen belief and honestly reports this belief. We consider a recently introduced, strategic variant of this problem with selfish (reputation-seeking) experts, where each expert strategically reports in order to maximize their expected future reputation based on their belief. In this work, our goal is to design an algorithm for the selfish experts problem that is incentive-compatible (IC, or \emph{truthful}), meaning each expert's best strategy is to report truthfully, while also ensuring the algorithm enjoys sublinear regret with respect to the expert with the best belief. Freeman et al. (2020) recently studied this problem in the full information and <b>bandit</b> <b>settings</b> and obtained truthful, no-regret algorithms by leveraging prior work on wagering mechanisms. While their results under full information match the minimax rate for the classical ("honest experts") problem, the best-known regret for their <b>bandit</b> <b>algorithm</b> WSU-UX is $O(T^{2/3})$, which does not match the minimax rate for the classical ("honest <b>bandits")</b> <b>setting.</b> It was unclear whether the higher regret was an artifact of their analysis or a limitation of WSU-UX. We show, via explicit construction of loss sequences, that the algorithm suffers a worst-case $\Omega(T^{2/3})$ lower bound. Left open is the possibility that a different IC algorithm obtains $O(\sqrt{T})$ regret. Yet, WSU-UX was a natural choice for such an algorithm owing to the limited design room for IC algorithms in this setting.

{{</citation>}}


### (24/34 | 168/266) HOEG: A New Approach for Object-Centric Predictive Process Monitoring (Tim K. Smit et al., 2024)

{{<citation>}}

Tim K. Smit, Hajo A. Reijers, Xixi Lu. (2024)  
**HOEG: A New Approach for Object-Centric Predictive Process Monitoring**
<br/>
<button class="copy-to-clipboard" title="HOEG: A New Approach for Object-Centric Predictive Process Monitoring" index=168>
  <span class="copy-to-clipboard-item">Copy Title<span>
</button>
<div class="toast toast-copied toast-index-168 align-items-center text-bg-secondary border-0 position-absolute top-0 end-0" role="alert" aria-live="assertive" aria-atomic="true">
  <div class="d-flex">
    <div class="toast-body">
      Copied!
    </div>
  </div>
</div>

---
Primary Category: cs.LG  
Categories: cs-LG, cs.LG  
Keyword Score: 19  
Keywords: Graph, Graph Neural Network, Benchmarking, Benchmarking  
<a type="button" class="btn btn-outline-primary" href="http://arxiv.org/abs/2404.05316v1" target="_blank" >Paper Link</a>
<button type="button" class="btn btn-outline-primary download-pdf" url="https://arxiv.org/pdf/2404.05316v1.pdf" filename="2404.05316v1.pdf">Download PDF</button>

---


**ABSTRACT**  
Predictive Process Monitoring focuses on predicting future states of ongoing process executions, such as forecasting the remaining time. Recent developments in Object-Centric Process Mining have enriched event data with objects and their explicit relations between events. To leverage this enriched data, we propose the Heterogeneous Object Event <b>Graph</b> <b>encoding</b> <b>(HOEG),</b> which integrates events and objects into a <b>graph</b> <b>structure</b> <b>with</b> diverse node types. It does so without aggregating object features, thus creating a more nuanced and informative representation. We then adopt a heterogeneous <b>Graph</b> <b>Neural</b> <b>Network</b> architecture, which incorporates these diverse object features in prediction tasks. We evaluate the performance and scalability of HOEG in predicting remaining time, <b>benchmarking</b> it against two established <b>graph-based</b> <b>encodings</b> <b>and</b> two baseline models. Our evaluation uses three Object-Centric Event Logs (OCELs), including one from a real-life process at a major Dutch financial institution. The results indicate that HOEG competes well with existing models and surpasses them when OCELs contain informative object attributes and event-object interactions.

{{</citation>}}


### (25/34 | 169/266) Interpretability in Symbolic Regression: a benchmark of Explanatory Methods using the Feynman data set (Guilherme Seidyo Imai Aldeia et al., 2024)

{{<citation>}}

Guilherme Seidyo Imai Aldeia, Fabricio Olivetti de Franca. (2024)  
**Interpretability in Symbolic Regression: a benchmark of Explanatory Methods using the Feynman data set**
<br/>
<button class="copy-to-clipboard" title="Interpretability in Symbolic Regression: a benchmark of Explanatory Methods using the Feynman data set" index=169>
  <span class="copy-to-clipboard-item">Copy Title<span>
</button>
<div class="toast toast-copied toast-index-169 align-items-center text-bg-secondary border-0 position-absolute top-0 end-0" role="alert" aria-live="assertive" aria-atomic="true">
  <div class="d-flex">
    <div class="toast-body">
      Copied!
    </div>
  </div>
</div>

---
Primary Category: cs.LG  
Categories: cs-AI, cs-LG, cs.LG  
Keyword Score: 18  
Keywords: Benchmarking, Black Box, Fairness  
<a type="button" class="btn btn-outline-primary" href="http://arxiv.org/abs/2404.05908v1" target="_blank" >Paper Link</a>
<button type="button" class="btn btn-outline-primary download-pdf" url="https://arxiv.org/pdf/2404.05908v1.pdf" filename="2404.05908v1.pdf">Download PDF</button>

---


**ABSTRACT**  
In some situations, the interpretability of the machine learning models plays a role as important as the model accuracy. Interpretability comes from the need to trust the prediction model, verify some of its properties, or even enforce them to improve <b>fairness.</b> Many model-agnostic explanatory methods exists to provide explanations for <b>black-box</b> <b>models.</b> In the regression task, the practitioner can use white-boxes or gray-boxes models to achieve more interpretable results, which is the case of symbolic regression. When using an explanatory method, and since interpretability lacks a rigorous definition, there is a need to evaluate and compare the quality and different explainers. This paper proposes a <b>benchmark</b> scheme to evaluate explanatory methods to explain regression models, mainly symbolic regression models. Experiments were performed using 100 physics equations with different interpretable and non-interpretable regression methods and popular explanation methods, evaluating the performance of the explainers performance with several explanation measures. In addition, we further analyzed four <b>benchmarks</b> from the GP community. The results have shown that Symbolic Regression models can be an interesting alternative to white-box and <b>black-box</b> <b>models</b> that is capable of returning accurate models with appropriate explanations. Regarding the explainers, we observed that Partial Effects and SHAP were the most robust explanation models, with Integrated Gradients being unstable only with tree-based models. This <b>benchmark</b> is publicly available for further experiments.

{{</citation>}}


### (26/34 | 170/266) Deep Representation Learning for Multi-functional Degradation Modeling of Community-dwelling Aging Population (Suiyao Chen et al., 2024)

{{<citation>}}

Suiyao Chen, Xinyi Liu, Yulei Li, Jing Wu, Handong Yao. (2024)  
**Deep Representation Learning for Multi-functional Degradation Modeling of Community-dwelling Aging Population**
<br/>
<button class="copy-to-clipboard" title="Deep Representation Learning for Multi-functional Degradation Modeling of Community-dwelling Aging Population" index=170>
  <span class="copy-to-clipboard-item">Copy Title<span>
</button>
<div class="toast toast-copied toast-index-170 align-items-center text-bg-secondary border-0 position-absolute top-0 end-0" role="alert" aria-live="assertive" aria-atomic="true">
  <div class="d-flex">
    <div class="toast-body">
      Copied!
    </div>
  </div>
</div>

---
Primary Category: cs.LG  
Categories: cs-AI, cs-LG, cs.LG  
Keyword Score: 15  
Keywords: Representation Learning, Stemming  
<a type="button" class="btn btn-outline-primary" href="http://arxiv.org/abs/2404.05613v1" target="_blank" >Paper Link</a>
<button type="button" class="btn btn-outline-primary download-pdf" url="https://arxiv.org/pdf/2404.05613v1.pdf" filename="2404.05613v1.pdf">Download PDF</button>

---


**ABSTRACT**  
As the aging population grows, particularly for the baby boomer generation, the United States is witnessing a significant increase in the elderly population experiencing multifunctional disabilities. These disabilities, <b>stemming</b> from a variety of chronic diseases, injuries, and impairments, present a complex challenge due to their multidimensional nature, encompassing both physical and cognitive aspects. Traditional methods often use univariate regression-based methods to model and predict single degradation conditions and assume population homogeneity, which is inadequate to address the complexity and diversity of aging-related degradation. This study introduces a novel framework for multi-functional degradation modeling that captures the multidimensional (e.g., physical and cognitive) and heterogeneous nature of elderly disabilities. Utilizing deep learning, our approach predicts health degradation scores and uncovers latent heterogeneity from elderly health histories, offering both efficient estimation and explainable insights into the diverse effects and causes of aging-related degradation. A real-case study demonstrates the effectiveness and marks a pivotal contribution to accurately modeling the intricate dynamics of elderly degradation, and addresses the healthcare challenges in the aging population.

{{</citation>}}


### (27/34 | 171/266) Softmax Attention with Constant Cost per Token (Franz A. Heinsen, 2024)

{{<citation>}}

Franz A. Heinsen. (2024)  
**Softmax Attention with Constant Cost per Token**
<br/>
<button class="copy-to-clipboard" title="Softmax Attention with Constant Cost per Token" index=171>
  <span class="copy-to-clipboard-item">Copy Title<span>
</button>
<div class="toast toast-copied toast-index-171 align-items-center text-bg-secondary border-0 position-absolute top-0 end-0" role="alert" aria-live="assertive" aria-atomic="true">
  <div class="d-flex">
    <div class="toast-body">
      Copied!
    </div>
  </div>
</div>

---
Primary Category: cs.LG  
Categories: cs-CL, cs-LG, cs.LG  
Keyword Score: 10  
Keywords: Transformer  
<a type="button" class="btn btn-outline-primary" href="http://arxiv.org/abs/2404.05843v1" target="_blank" >Paper Link</a>
<button type="button" class="btn btn-outline-primary download-pdf" url="https://arxiv.org/pdf/2404.05843v1.pdf" filename="2404.05843v1.pdf">Download PDF</button>

---


**ABSTRACT**  
We propose a simple modification to the conventional attention mechanism applied by <b>Transformers:</b> Instead of quantifying pairwise query-key similarity with scaled dot-products, we quantify it with the logarithms of scaled dot-products of exponentials. Attention becomes expressible as a composition of log-sums of exponentials that is linearizable, with a latent space of constant size, enabling sequential application with constant time and space complexity per token. We implement our modification, verify that it works in practice, and conclude that it is a promising alternative to conventional attention.

{{</citation>}}


### (28/34 | 172/266) Attention-Driven Multi-Agent Reinforcement Learning: Enhancing Decisions with Expertise-Informed Tasks (Andre R Kuroswiski et al., 2024)

{{<citation>}}

Andre R Kuroswiski, Annie S Wu, Angelo Passaro. (2024)  
**Attention-Driven Multi-Agent Reinforcement Learning: Enhancing Decisions with Expertise-Informed Tasks**
<br/>
<button class="copy-to-clipboard" title="Attention-Driven Multi-Agent Reinforcement Learning: Enhancing Decisions with Expertise-Informed Tasks" index=172>
  <span class="copy-to-clipboard-item">Copy Title<span>
</button>
<div class="toast toast-copied toast-index-172 align-items-center text-bg-secondary border-0 position-absolute top-0 end-0" role="alert" aria-live="assertive" aria-atomic="true">
  <div class="d-flex">
    <div class="toast-body">
      Copied!
    </div>
  </div>
</div>

---
Primary Category: cs.LG  
Categories: cs-AI, cs-LG, cs-MA, cs.LG  
Keyword Score: 10  
Keywords: Reinforcement Learning  
<a type="button" class="btn btn-outline-primary" href="http://arxiv.org/abs/2404.05840v1" target="_blank" >Paper Link</a>
<button type="button" class="btn btn-outline-primary download-pdf" url="https://arxiv.org/pdf/2404.05840v1.pdf" filename="2404.05840v1.pdf">Download PDF</button>

---


**ABSTRACT**  
In this paper, we introduce an alternative approach to enhancing Multi-Agent <b>Reinforcement</b> <b>Learning</b> (MARL) through the integration of domain knowledge and attention-based policy mechanisms. Our methodology focuses on the incorporation of domain-specific expertise into the learning process, which simplifies the development of collaborative behaviors. This approach aims to reduce the complexity and learning overhead typically associated with MARL by enabling agents to concentrate on essential aspects of complex tasks, thus optimizing the learning curve. The utilization of attention mechanisms plays a key role in our model. It allows for the effective processing of dynamic context data and nuanced agent interactions, leading to more refined decision-making. Applied in standard MARL scenarios, such as the Stanford Intelligent Systems Laboratory (SISL) Pursuit and Multi-Particle Environments (MPE) Simple Spread, our method has been shown to improve both learning efficiency and the effectiveness of collaborative behaviors. The results indicate that our attention-based approach can be a viable approach for improving the efficiency of MARL training process, integrating domain-specific knowledge at the action level.

{{</citation>}}


### (29/34 | 173/266) David and Goliath: An Empirical Evaluation of Attacks and Defenses for QNNs at the Deep Edge (Miguel Costa et al., 2024)

{{<citation>}}

Miguel Costa, Sandro Pinto. (2024)  
**David and Goliath: An Empirical Evaluation of Attacks and Defenses for QNNs at the Deep Edge**
<br/>
<button class="copy-to-clipboard" title="David and Goliath: An Empirical Evaluation of Attacks and Defenses for QNNs at the Deep Edge" index=173>
  <span class="copy-to-clipboard-item">Copy Title<span>
</button>
<div class="toast toast-copied toast-index-173 align-items-center text-bg-secondary border-0 position-absolute top-0 end-0" role="alert" aria-live="assertive" aria-atomic="true">
  <div class="d-flex">
    <div class="toast-body">
      Copied!
    </div>
  </div>
</div>

---
Primary Category: cs.LG  
Categories: I-2-0, cs-AI, cs-CR, cs-LG, cs.LG  
Keyword Score: 10  
Keywords: Quantization  
<a type="button" class="btn btn-outline-primary" href="http://arxiv.org/abs/2404.05688v1" target="_blank" >Paper Link</a>
<button type="button" class="btn btn-outline-primary download-pdf" url="https://arxiv.org/pdf/2404.05688v1.pdf" filename="2404.05688v1.pdf">Download PDF</button>

---


**ABSTRACT**  
ML is shifting from the cloud to the edge. Edge computing reduces the surface exposing private data and enables reliable throughput guarantees in real-time applications. Of the panoply of devices deployed at the edge, resource-constrained MCUs, e.g., Arm Cortex-M, are more prevalent, orders of magnitude cheaper, and less power-hungry than application processors or GPUs. Thus, enabling intelligence at the deep edge is the zeitgeist, with researchers focusing on unveiling novel approaches to deploy ANNs on these constrained devices. <b>Quantization</b> is a well-established technique that has proved effective in enabling the deployment of neural networks on MCUs; however, it is still an open question to understand the robustness of QNNs in the face of adversarial examples. To fill this gap, we empirically evaluate the effectiveness of attacks and defenses from (full-precision) ANNs on (constrained) QNNs. Our evaluation includes three QNNs targeting TinyML applications, ten attacks, and six defenses. With this study, we draw a set of interesting findings. First, <b>quantization</b> increases the point distance to the decision boundary and leads the gradient estimated by some attacks to explode or vanish. Second, <b>quantization</b> can act as a noise attenuator or amplifier, depending on the noise magnitude, and causes gradient misalignment. Regarding adversarial defenses, we conclude that input pre-processing defenses show impressive results on small perturbations; however, they fall short as the perturbation increases. At the same time, train-based defenses increase the average point distance to the decision boundary, which holds after <b>quantization.</b> However, we argue that train-based defenses still need to smooth the <b>quantization-shift</b> and gradient misalignment phenomenons to counteract adversarial example transferability to QNNs. All artifacts are open-sourced to enable independent validation of results.

{{</citation>}}


### (30/34 | 174/266) AnchorAL: Computationally Efficient Active Learning for Large and Imbalanced Datasets (Pietro Lesci et al., 2024)

{{<citation>}}

Pietro Lesci, Andreas Vlachos. (2024)  
**AnchorAL: Computationally Efficient Active Learning for Large and Imbalanced Datasets**
<br/>
<button class="copy-to-clipboard" title="AnchorAL: Computationally Efficient Active Learning for Large and Imbalanced Datasets" index=174>
  <span class="copy-to-clipboard-item">Copy Title<span>
</button>
<div class="toast toast-copied toast-index-174 align-items-center text-bg-secondary border-0 position-absolute top-0 end-0" role="alert" aria-live="assertive" aria-atomic="true">
  <div class="d-flex">
    <div class="toast-body">
      Copied!
    </div>
  </div>
</div>

---
Primary Category: cs.LG  
Categories: cs-CL, cs-LG, cs.LG  
Keyword Score: 10  
Keywords: Active Learning  
<a type="button" class="btn btn-outline-primary" href="http://arxiv.org/abs/2404.05623v1" target="_blank" >Paper Link</a>
<button type="button" class="btn btn-outline-primary download-pdf" url="https://arxiv.org/pdf/2404.05623v1.pdf" filename="2404.05623v1.pdf">Download PDF</button>

---


**ABSTRACT**  
<b>Active</b> <b>learning</b> for imbalanced classification tasks is challenging as the minority classes naturally occur rarely. Gathering a large pool of unlabelled data is thus essential to capture minority instances. Standard pool-based <b>active</b> <b>learning</b> is computationally expensive on large pools and often reaches low accuracy by overfitting the initial decision boundary, thus failing to explore the input space and find minority instances. To address these issues we propose AnchorAL. At each iteration, AnchorAL chooses class-specific instances from the labelled set, or anchors, and retrieves the most similar unlabelled instances from the pool. This resulting subpool is then used for <b>active</b> <b>learning.</b> Using a small, fixed-sized subpool AnchorAL allows scaling any <b>active</b> <b>learning</b> strategy to large pools. By dynamically selecting different anchors at each iteration it promotes class balance and prevents overfitting the initial decision boundary, thus promoting the discovery of new clusters of minority instances. Experiments across different classification tasks, <b>active</b> <b>learning</b> strategies, and model architectures AnchorAL is (i) faster, often reducing runtime from hours to minutes, (ii) trains more performant models, (iii) and returns more balanced datasets than competing methods.

{{</citation>}}


### (31/34 | 175/266) Lightweight Inference for Forward-Forward Algorithm (Amin Aminifar et al., 2024)

{{<citation>}}

Amin Aminifar, Baichuan Huang, Azra Abtahi, Amir Aminifar. (2024)  
**Lightweight Inference for Forward-Forward Algorithm**
<br/>
<button class="copy-to-clipboard" title="Lightweight Inference for Forward-Forward Algorithm" index=175>
  <span class="copy-to-clipboard-item">Copy Title<span>
</button>
<div class="toast toast-copied toast-index-175 align-items-center text-bg-secondary border-0 position-absolute top-0 end-0" role="alert" aria-live="assertive" aria-atomic="true">
  <div class="d-flex">
    <div class="toast-body">
      Copied!
    </div>
  </div>
</div>

---
Primary Category: cs.LG  
Categories: cs-LG, cs.LG  
Keyword Score: 10  
Keywords: MNIST  
<a type="button" class="btn btn-outline-primary" href="http://arxiv.org/abs/2404.05241v2" target="_blank" >Paper Link</a>
<button type="button" class="btn btn-outline-primary download-pdf" url="https://arxiv.org/pdf/2404.05241v2.pdf" filename="2404.05241v2.pdf">Download PDF</button>

---


**ABSTRACT**  
The human brain performs tasks with an outstanding energy-efficiency, i.e., with approximately 20 Watts. The state-of-the-art Artificial/Deep Neural Networks (ANN/DNN), on the other hand, have recently been shown to consume massive amounts of energy. The training of these ANNs/DNNs is done almost exclusively based on the back-propagation algorithm, which is known to be biologically implausible. This has led to a new generation of forward-only techniques, including the Forward-Forward algorithm. In this paper, we propose a lightweight inference scheme specifically designed for DNNs trained using the Forward-Forward algorithm. We have evaluated our proposed lightweight inference scheme in the case of the <b>MNIST</b> and CIFAR datasets, as well as two real-world applications, namely, epileptic seizure detection and cardiac arrhythmia classification using wearable technologies, where complexity overheads/energy consumption is a major constraint, and demonstrate its relevance.

{{</citation>}}


### (32/34 | 176/266) Adapting to Covariate Shift in Real-time by Encoding Trees with Motion Equations (Tham Yik Foong et al., 2024)

{{<citation>}}

Tham Yik Foong, Heng Zhang, Mao Po Yuan, Danilo Vasconcellos Vargas. (2024)  
**Adapting to Covariate Shift in Real-time by Encoding Trees with Motion Equations**
<br/>
<button class="copy-to-clipboard" title="Adapting to Covariate Shift in Real-time by Encoding Trees with Motion Equations" index=176>
  <span class="copy-to-clipboard-item">Copy Title<span>
</button>
<div class="toast toast-copied toast-index-176 align-items-center text-bg-secondary border-0 position-absolute top-0 end-0" role="alert" aria-live="assertive" aria-atomic="true">
  <div class="d-flex">
    <div class="toast-body">
      Copied!
    </div>
  </div>
</div>

---
Primary Category: cs.LG  
Categories: cs-LG, cs.LG  
Keyword Score: 10  
Keywords: Distribution Shift, Distribution Shift  
<a type="button" class="btn btn-outline-primary" href="http://arxiv.org/abs/2404.05168v1" target="_blank" >Paper Link</a>
<button type="button" class="btn btn-outline-primary download-pdf" url="https://arxiv.org/pdf/2404.05168v1.pdf" filename="2404.05168v1.pdf">Download PDF</button>

---


**ABSTRACT**  
Input <b>distribution</b> <b>shift</b> presents a significant problem in many real-world systems. Here we present Xenovert, an adaptive algorithm that can dynamically adapt to changes in input <b>distribution.</b> <b>It</b> is a perfect binary tree that adaptively divides a continuous input space into several intervals of uniform density while receiving a continuous stream of input. This process indirectly maps the source <b>distribution</b> <b>to</b> the shifted target <b>distribution,</b> <b>preserving</b> the data's relationship with the downstream decoder/operation, even after the shift occurs. In this paper, we demonstrated how a neural network integrated with Xenovert achieved better results in 4 out of 5 shifted datasets, saving the hurdle of retraining a machine learning model. We anticipate that Xenovert can be applied to many more applications that require adaptation to unforeseen input <b>distribution</b> <b>shifts,</b> even when the <b>distribution</b> <b>shift</b> is drastic.

{{</citation>}}


### (33/34 | 177/266) A parameter-free clustering algorithm for missing datasets (Qi Li et al., 2024)

{{<citation>}}

Qi Li, Xianjun Zeng, Shuliang Wang, Wenhao Zhu, Shijie Ruan, Zhimeng Yuan. (2024)  
**A parameter-free clustering algorithm for missing datasets**
<br/>
<button class="copy-to-clipboard" title="A parameter-free clustering algorithm for missing datasets" index=177>
  <span class="copy-to-clipboard-item">Copy Title<span>
</button>
<div class="toast toast-copied toast-index-177 align-items-center text-bg-secondary border-0 position-absolute top-0 end-0" role="alert" aria-live="assertive" aria-atomic="true">
  <div class="d-flex">
    <div class="toast-body">
      Copied!
    </div>
  </div>
</div>

---
Primary Category: cs.LG  
Categories: cs-LG, cs.LG  
Keyword Score: 6  
Keywords: Graph, Clustering  
<a type="button" class="btn btn-outline-primary" href="http://arxiv.org/abs/2404.05363v1" target="_blank" >Paper Link</a>
<button type="button" class="btn btn-outline-primary download-pdf" url="https://arxiv.org/pdf/2404.05363v1.pdf" filename="2404.05363v1.pdf">Download PDF</button>

---


**ABSTRACT**  
Missing datasets, in which some objects have missing values in certain dimensions, are prevalent in the Real-world. Existing <b>clustering</b> algorithms for missing datasets first impute the missing values and then perform <b>clustering.</b> However, both the imputation and <b>clustering</b> processes require input parameters. Too many input parameters inevitably increase the difficulty of obtaining accurate <b>clustering</b> results. Although some studies have shown that decision <b>graphs</b> can replace the input parameters of <b>clustering</b> algorithms, current decision <b>graphs</b> require equivalent dimensions among objects and are therefore not suitable for missing datasets. To this end, we propose a Single-Dimensional <b>Clustering</b> algorithm, i.e., SDC. SDC, which removes the imputation process and adapts the decision <b>graph</b> to the missing datasets by splitting dimension and partition intersection fusion, can obtain valid <b>clustering</b> results on the missing datasets without input parameters. Experiments demonstrate that, across three evaluation metrics, SDC outperforms baseline algorithms by at least 13.7%(NMI), 23.8%(ARI), and 8.1%(Purity).

{{</citation>}}


### (34/34 | 178/266) Dynamical stability and chaos in artificial neural network trajectories along training (Kaloyan Danovski et al., 2024)

{{<citation>}}

Kaloyan Danovski, Miguel C. Soriano, Lucas Lacasa. (2024)  
**Dynamical stability and chaos in artificial neural network trajectories along training**
<br/>
<button class="copy-to-clipboard" title="Dynamical stability and chaos in artificial neural network trajectories along training" index=178>
  <span class="copy-to-clipboard-item">Copy Title<span>
</button>
<div class="toast toast-copied toast-index-178 align-items-center text-bg-secondary border-0 position-absolute top-0 end-0" role="alert" aria-live="assertive" aria-atomic="true">
  <div class="d-flex">
    <div class="toast-body">
      Copied!
    </div>
  </div>
</div>

---
Primary Category: cs.LG  
Categories: cond-mat-dis-nn, cs-LG, cs.LG, nlin-CD, physics-data-an  
Keyword Score: 3  
Keywords: Graph  
<a type="button" class="btn btn-outline-primary" href="http://arxiv.org/abs/2404.05782v1" target="_blank" >Paper Link</a>
<button type="button" class="btn btn-outline-primary download-pdf" url="https://arxiv.org/pdf/2404.05782v1.pdf" filename="2404.05782v1.pdf">Download PDF</button>

---


**ABSTRACT**  
The process of training an artificial neural network involves iteratively adapting its parameters so as to minimize the error of the network's prediction, when confronted with a learning task. This iterative change can be naturally interpreted as a trajectory in network space -- a time series of networks -- and thus the training algorithm (e.g. gradient descent optimization of a suitable loss function) can be interpreted as a dynamical system in <b>graph</b> space. In order to illustrate this interpretation, here we study the dynamical properties of this process by analyzing through this lens the network trajectories of a shallow neural network, and its evolution through learning a simple classification task. We systematically consider different ranges of the learning rate and explore both the dynamical and orbital stability of the resulting network trajectories, finding hints of regular and chaotic behavior depending on the learning rate regime. Our findings are put in contrast to common wisdom on convergence properties of neural networks and dynamical systems theory. This work also contributes to the cross-fertilization of ideas between dynamical systems theory, network theory and machine learning

{{</citation>}}


## cs.SE (5)



### (1/5 | 179/266) Guiding Large Language Models to Generate Computer-Parsable Content (Jiaye Wang, 2024)

{{<citation>}}

Jiaye Wang. (2024)  
**Guiding Large Language Models to Generate Computer-Parsable Content**
<br/>
<button class="copy-to-clipboard" title="Guiding Large Language Models to Generate Computer-Parsable Content" index=179>
  <span class="copy-to-clipboard-item">Copy Title<span>
</button>
<div class="toast toast-copied toast-index-179 align-items-center text-bg-secondary border-0 position-absolute top-0 end-0" role="alert" aria-live="assertive" aria-atomic="true">
  <div class="d-flex">
    <div class="toast-body">
      Copied!
    </div>
  </div>
</div>

---
Primary Category: cs.SE  
Categories: cs-AI, cs-SE, cs.SE  
Keyword Score: 53  
Keywords: Benchmarking, Fine-tuning, GPT, GPT-2, Large Language Model, Large Language Model  
<a type="button" class="btn btn-outline-primary" href="http://arxiv.org/abs/2404.05499v2" target="_blank" >Paper Link</a>
<button type="button" class="btn btn-outline-primary download-pdf" url="https://arxiv.org/pdf/2404.05499v2.pdf" filename="2404.05499v2.pdf">Download PDF</button>

---


**ABSTRACT**  
We propose a method to guide <b>Large</b> <b>Language</b> <b>Models</b> <b>(LLMs)</b> in generating structured content adhering to specific conventions without <b>fine-tuning.</b> By utilizing coroutine-based content generation constraints through a pre-agreed context-free grammar (CFG), <b>LLMs</b> are directed during decoding to produce formal language compliant outputs. This enhances stability and consistency in generating target data structures, types, or instructions, reducing application development complexities. Experimentally, error rates of <b>GPT-2</b> and Gemma exceed 95% for DSLs longer than 36 and 282 tokens, respectively. We introduce YieldLang, a coroutine-based DSL generation framework, and evaluate it with <b>LLMs</b> on various tasks including JSON and Mermaid flowchart generation. Compared to <b>benchmarks,</b> our approach improves accuracy by 1.09 to 11.6 times, with <b>LLMs</b> requiring only about 16.5% of the samples to generate JSON effectively. This enhances usability of <b>LLM-generated</b> content for computer programs.

{{</citation>}}


### (2/5 | 180/266) The Fact Selection Problem in LLM-Based Program Repair (Nikhil Parasaram et al., 2024)

{{<citation>}}

Nikhil Parasaram, Huijie Yan, Boyu Yang, Zineb Flahy, Abriele Qudsi, Damian Ziaber, Earl Barr, Sergey Mechtaev. (2024)  
**The Fact Selection Problem in LLM-Based Program Repair**
<br/>
<button class="copy-to-clipboard" title="The Fact Selection Problem in LLM-Based Program Repair" index=180>
  <span class="copy-to-clipboard-item">Copy Title<span>
</button>
<div class="toast toast-copied toast-index-180 align-items-center text-bg-secondary border-0 position-absolute top-0 end-0" role="alert" aria-live="assertive" aria-atomic="true">
  <div class="d-flex">
    <div class="toast-body">
      Copied!
    </div>
  </div>
</div>

---
Primary Category: cs.SE  
Categories: cs-SE, cs.SE  
Keyword Score: 43  
Keywords: Benchmarking, Zero-shot, Large Language Model, Large Language Model, Prompt  
<a type="button" class="btn btn-outline-primary" href="http://arxiv.org/abs/2404.05520v2" target="_blank" >Paper Link</a>
<button type="button" class="btn btn-outline-primary download-pdf" url="https://arxiv.org/pdf/2404.05520v2.pdf" filename="2404.05520v2.pdf">Download PDF</button>

---


**ABSTRACT**  
Recent research has shown that incorporating bug-related facts, such as stack traces and GitHub issues, into <b>prompts</b> enhances the bug-fixing capabilities of <b>large</b> <b>language</b> <b>models</b> <b>(LLMs).</b> Considering the ever-increasing context window of these models, a critical question arises: what and how many facts should be included in <b>prompts</b> to maximise the chance of correctly fixing bugs? To answer this question, we conducted a <b>large-scale</b> <b>study,</b> <b>employing</b> over 19K <b>prompts</b> featuring various combinations of seven diverse facts to rectify 314 bugs from open-source Python projects within the BugsInPy <b>benchmark.</b> Our findings revealed that each fact, ranging from simple syntactic details like code context to semantic information previously unexplored in the context of <b>LLMs</b> such as angelic values, is beneficial. Specifically, each fact aids in fixing some bugs that would remain unresolved or only be fixed with a low success rate without it. Importantly, we discovered that the effectiveness of program repair <b>prompts</b> is non-monotonic over the number of used facts; using too many facts leads to subpar outcomes. These insights led us to define the fact selection problem: determining the optimal set of facts for inclusion in a <b>prompt</b> to maximise <b>LLM's</b> performance on a given task instance. We found that there is no one-size-fits-all set of facts for bug repair. Therefore, we developed a basic statistical model, named Maniple, which selects facts specific to a given bug to include in the <b>prompt.</b> This model significantly surpasses the performance of the best generic fact set. To underscore the significance of the fact selection problem, we <b>benchmarked</b> Maniple against the state-of-the-art <b>zero-shot,</b> non-conversational <b>LLM-based</b> bug repair methods. On our testing dataset of 157 bugs, Maniple repairs 88 bugs, 17% above the best configuration.

{{</citation>}}


### (3/5 | 181/266) Synergy of Large Language Model and Model Driven Engineering for Automated Development of Centralized Vehicular Systems (Nenad Petrovic et al., 2024)

{{<citation>}}

Nenad Petrovic, Fengjunjie Pan, Krzysztof Lebioda, Vahid Zolfaghari, Sven Kirchner, Nils Purschke, Muhammad Aqib Khan, Viktor Vorobev, Alois Knoll. (2024)  
**Synergy of Large Language Model and Model Driven Engineering for Automated Development of Centralized Vehicular Systems**
<br/>
<button class="copy-to-clipboard" title="Synergy of Large Language Model and Model Driven Engineering for Automated Development of Centralized Vehicular Systems" index=181>
  <span class="copy-to-clipboard-item">Copy Title<span>
</button>
<div class="toast toast-copied toast-index-181 align-items-center text-bg-secondary border-0 position-absolute top-0 end-0" role="alert" aria-live="assertive" aria-atomic="true">
  <div class="d-flex">
    <div class="toast-body">
      Copied!
    </div>
  </div>
</div>

---
Primary Category: cs.SE  
Categories: D-2-1; D-2-2; D-2-4; I-2-7; I-2-2; I-7-0, cs-AI, cs-CL, cs-SE, cs.SE  
Keyword Score: 30  
Keywords: Code Generation, Large Language Model, Large Language Model  
<a type="button" class="btn btn-outline-primary" href="http://arxiv.org/abs/2404.05508v1" target="_blank" >Paper Link</a>
<button type="button" class="btn btn-outline-primary download-pdf" url="https://arxiv.org/pdf/2404.05508v1.pdf" filename="2404.05508v1.pdf">Download PDF</button>

---


**ABSTRACT**  
We present a prototype of a tool leveraging the synergy of model driven engineering (MDE) and <b>Large</b> <b>Language</b> <b>Models</b> <b>(LLM)</b> for the purpose of software development process automation in the automotive industry. In this approach, the user-provided input is free form textual requirements, which are first translated to Ecore model instance representation using an <b>LLM,</b> which is afterwards checked for consistency using Object Constraint Language (OCL) rules. After successful consistency check, the model instance is fed as input to another <b>LLM</b> for the purpose of <b>code</b> <b>generation.</b> The generated <b>code</b> <b>is</b> evaluated in a simulated environment using CARLA simulator connected to an example centralized vehicle architecture, in an emergency brake scenario.

{{</citation>}}


### (4/5 | 182/266) AutoCodeRover: Autonomous Program Improvement (Yuntong Zhang et al., 2024)

{{<citation>}}

Yuntong Zhang, Haifeng Ruan, Zhiyu Fan, Abhik Roychoudhury. (2024)  
**AutoCodeRover: Autonomous Program Improvement**
<br/>
<button class="copy-to-clipboard" title="AutoCodeRover: Autonomous Program Improvement" index=182>
  <span class="copy-to-clipboard-item">Copy Title<span>
</button>
<div class="toast toast-copied toast-index-182 align-items-center text-bg-secondary border-0 position-absolute top-0 end-0" role="alert" aria-live="assertive" aria-atomic="true">
  <div class="d-flex">
    <div class="toast-body">
      Copied!
    </div>
  </div>
</div>

---
Primary Category: cs.SE  
Categories: cs-AI, cs-SE, cs.SE  
Keyword Score: 30  
Keywords: Large Language Model, Large Language Model, Summarization  
<a type="button" class="btn btn-outline-primary" href="http://arxiv.org/abs/2404.05427v1" target="_blank" >Paper Link</a>
<button type="button" class="btn btn-outline-primary download-pdf" url="https://arxiv.org/pdf/2404.05427v1.pdf" filename="2404.05427v1.pdf">Download PDF</button>

---


**ABSTRACT**  
Researchers have made significant progress in automating the software development process in the past decades. Automated techniques for issue <b>summarization,</b> bug reproduction, fault localization, and program repair have been built to ease the workload of developers. Recent progress in <b>Large</b> <b>Language</b> <b>Models</b> <b>(LLMs)</b> has significantly impacted the development process, where developers can use <b>LLM-based</b> programming assistants to achieve automated coding. Nevertheless software engineering involves the process of program improvement apart from coding, specifically to enable software maintenance (e.g. program repair to fix bugs) and software evolution (e.g. feature additions). In this paper, we propose an automated approach for solving Github issues to autonomously achieve program improvement. In our approach called AutoCodeRover, <b>LLMs</b> are combined with sophisticated code search capabilities, ultimately leading to a program modification or patch. In contrast to recent <b>LLM</b> agent approaches from AI researchers and practitioners, our outlook is more software engineering oriented. We work on a program representation (abstract syntax tree) as opposed to viewing a software project as a mere collection of files. Our code search exploits the program structure in the form of classes/methods to enhance <b>LLM's</b> understanding of the issue's root cause, and effectively retrieve a context via iterative search. The use of spectrum based fault localization using tests, further sharpens the context. Experiments on the recently proposed SWE-bench-lite which consists of 300 real-life Github issues involving bug fixing and feature additions show increased efficacy (resolving more than 20% on SWE-bench-lite), as compared to recent efforts from the AI community. We posit that our workflow enables autonomous software engineering, where, in future, auto-generated code from <b>LLMs</b> can be autonomously improved.

{{</citation>}}


### (5/5 | 183/266) The Argument for Meta-Modeling-Based Approaches to Hardware Generation Languages (Johannes Schreiner et al., 2024)

{{<citation>}}

Johannes Schreiner, Daniel Gerl, Robert Kunzelmann, Paritosh Kumar Sinha, Wolfgang Ecker. (2024)  
**The Argument for Meta-Modeling-Based Approaches to Hardware Generation Languages**
<br/>
<button class="copy-to-clipboard" title="The Argument for Meta-Modeling-Based Approaches to Hardware Generation Languages" index=183>
  <span class="copy-to-clipboard-item">Copy Title<span>
</button>
<div class="toast toast-copied toast-index-183 align-items-center text-bg-secondary border-0 position-absolute top-0 end-0" role="alert" aria-live="assertive" aria-atomic="true">
  <div class="d-flex">
    <div class="toast-body">
      Copied!
    </div>
  </div>
</div>

---
Primary Category: cs.SE  
Categories: cs-AR, cs-PL, cs-SE, cs.SE  
Keyword Score: 20  
Keywords: Code Generation, Summarization  
<a type="button" class="btn btn-outline-primary" href="http://arxiv.org/abs/2404.05599v1" target="_blank" >Paper Link</a>
<button type="button" class="btn btn-outline-primary download-pdf" url="https://arxiv.org/pdf/2404.05599v1.pdf" filename="2404.05599v1.pdf">Download PDF</button>

---


**ABSTRACT**  
The rapid evolution of Integrated Circuit (IC) development necessitates innovative methodologies such as <b>code</b> <b>generation</b> to manage complexity and increase productivity. Using the right methodology for generator development to maximize the capability and, most notably, the feasibility of generators is a crucial part of this work. Meta-Modeling-based approaches drawing on the principles of Model Driven Architecture (MDA) are a promising methodology for generator development. The goal of this paper is to show why such an MDA-based approach can provide extremely powerful generators with minimal implementation effort and to demonstrate that this approach is a superior alternative to the most advanced hardware generation languages such as SpinalHDL and Chisel. For this purpose, this paper provides an in-depth comparison of the Meta-Modeling approach against these hardware generation languages, highlighting the unique advantages of a Meta-Modeling-based approach and <b>summarizes</b> the benefits.

{{</citation>}}


## cs.AI (6)



### (1/6 | 184/266) Use of a Structured Knowledge Base Enhances Metadata Curation by Large Language Models (Sowmya S. Sundaram et al., 2024)

{{<citation>}}

Sowmya S. Sundaram, Benjamin Solomon, Avani Khatri, Anisha Laumas, Purvesh Khatri, Mark A. Musen. (2024)  
**Use of a Structured Knowledge Base Enhances Metadata Curation by Large Language Models**
<br/>
<button class="copy-to-clipboard" title="Use of a Structured Knowledge Base Enhances Metadata Curation by Large Language Models" index=184>
  <span class="copy-to-clipboard-item">Copy Title<span>
</button>
<div class="toast toast-copied toast-index-184 align-items-center text-bg-secondary border-0 position-absolute top-0 end-0" role="alert" aria-live="assertive" aria-atomic="true">
  <div class="d-flex">
    <div class="toast-body">
      Copied!
    </div>
  </div>
</div>

---
Primary Category: cs.AI  
Categories: cs-AI, cs-CL, cs-IR, cs.AI  
Keyword Score: 50  
Keywords: GPT, GPT-4, Large Language Model, Large Language Model, Prompt  
<a type="button" class="btn btn-outline-primary" href="http://arxiv.org/abs/2404.05893v1" target="_blank" >Paper Link</a>
<button type="button" class="btn btn-outline-primary download-pdf" url="https://arxiv.org/pdf/2404.05893v1.pdf" filename="2404.05893v1.pdf">Download PDF</button>

---


**ABSTRACT**  
Metadata play a crucial role in ensuring the findability, accessibility, interoperability, and reusability of datasets. This paper investigates the potential of <b>large</b> <b>language</b> <b>models</b> <b>(LLMs),</b> specifically <b>GPT-4,</b> to improve adherence to metadata standards. We conducted experiments on 200 random data records describing human samples relating to lung cancer from the NCBI BioSample repository, evaluating <b>GPT-4's</b> ability to suggest edits for adherence to metadata standards. We computed the adherence accuracy of field name-field value pairs through a peer review process, and we observed a marginal average improvement in adherence to the standard data dictionary from 79% to 80% (p<0.01). We then <b>prompted</b> <b>GPT-4</b> with domain information in the form of the textual descriptions of CEDAR templates and recorded a significant improvement to 97% from 79% (p<0.01). These results indicate that, while <b>LLMs</b> may not be able to correct legacy metadata to ensure satisfactory adherence to standards when unaided, they do show promise for use in automated metadata curation when integrated with a structured knowledge base.

{{</citation>}}


### (2/6 | 185/266) 360°REA: Towards A Reusable Experience Accumulation with 360° Assessment for Multi-Agent System (Shen Gao et al., 2024)

{{<citation>}}

Shen Gao, Hao Li, Zhengliang Shi, Chengrui Huang, Quan Tu, Zhiliang Tian, Minlie Huang, Shuo Shang. (2024)  
**360°REA: Towards A Reusable Experience Accumulation with 360° Assessment for Multi-Agent System**
<br/>
<button class="copy-to-clipboard" title="360°REA: Towards A Reusable Experience Accumulation with 360° Assessment for Multi-Agent System" index=185>
  <span class="copy-to-clipboard-item">Copy Title<span>
</button>
<div class="toast toast-copied toast-index-185 align-items-center text-bg-secondary border-0 position-absolute top-0 end-0" role="alert" aria-live="assertive" aria-atomic="true">
  <div class="d-flex">
    <div class="toast-body">
      Copied!
    </div>
  </div>
</div>

---
Primary Category: cs.AI  
Categories: cs-AI, cs-CL, cs-MA, cs.AI  
Keyword Score: 20  
Keywords: Large Language Model, Large Language Model  
<a type="button" class="btn btn-outline-primary" href="http://arxiv.org/abs/2404.05569v1" target="_blank" >Paper Link</a>
<button type="button" class="btn btn-outline-primary download-pdf" url="https://arxiv.org/pdf/2404.05569v1.pdf" filename="2404.05569v1.pdf">Download PDF</button>

---


**ABSTRACT**  
<b>Large</b> <b>language</b> <b>model</b> agents have demonstrated remarkable advancements across various complex tasks. Recent works focus on optimizing the agent team or employing self-reflection to iteratively solve complex tasks. Since these agents are all based on the same <b>LLM,</b> only conducting self-evaluation or removing underperforming agents does not substantively enhance the capability of the agents. We argue that a comprehensive evaluation and accumulating experience from evaluation feedback is an effective approach to improving system performance. In this paper, we propose Reusable Experience Accumulation with 360{\deg} Assessment (360{\deg}REA), a hierarchical multi-agent framework inspired by corporate organizational practices. The framework employs a novel 360{\deg} performance assessment method for multi-perspective performance evaluation with fine-grained assessment. To enhance the capability of agents in addressing complex tasks, we introduce dual-level experience pool for agents to accumulate experience through fine-grained assessment. Extensive experiments on complex task datasets demonstrate the effectiveness of 360{\deg}REA.

{{</citation>}}


### (3/6 | 186/266) Tree Search-Based Policy Optimization under Stochastic Execution Delay (David Valensi et al., 2024)

{{<citation>}}

David Valensi, Esther Derman, Shie Mannor, Gal Dalal. (2024)  
**Tree Search-Based Policy Optimization under Stochastic Execution Delay**
<br/>
<button class="copy-to-clipboard" title="Tree Search-Based Policy Optimization under Stochastic Execution Delay" index=186>
  <span class="copy-to-clipboard-item">Copy Title<span>
</button>
<div class="toast toast-copied toast-index-186 align-items-center text-bg-secondary border-0 position-absolute top-0 end-0" role="alert" aria-live="assertive" aria-atomic="true">
  <div class="d-flex">
    <div class="toast-body">
      Copied!
    </div>
  </div>
</div>

---
Primary Category: cs.AI  
Categories: cs-AI, cs-LG, cs.AI  
Keyword Score: 10  
Keywords: Markov Decision Process  
<a type="button" class="btn btn-outline-primary" href="http://arxiv.org/abs/2404.05440v1" target="_blank" >Paper Link</a>
<button type="button" class="btn btn-outline-primary download-pdf" url="https://arxiv.org/pdf/2404.05440v1.pdf" filename="2404.05440v1.pdf">Download PDF</button>

---


**ABSTRACT**  
The standard formulation of Markov decision processes <b>(MDPs)</b> assumes that the agent's decisions are executed immediately. However, in numerous realistic applications such as robotics or healthcare, actions are performed with a delay whose value can even be stochastic. In this work, we introduce stochastic delayed execution <b>MDPs,</b> a new formalism addressing random delays without resorting to state augmentation. We show that given observed delay values, it is sufficient to perform a policy search in the class of Markov policies in order to reach optimal performance, thus extending the deterministic fixed delay case. Armed with this insight, we devise DEZ, a model-based algorithm that optimizes over the class of Markov policies. DEZ leverages Monte-Carlo tree search similar to its non-delayed variant EfficientZero to accurately infer future states from the action queue. Thus, it handles delayed execution while preserving the sample efficiency of EfficientZero. Through a series of experiments on the Atari suite, we demonstrate that although the previous baseline outperforms the naive method in scenarios with constant delay, it underperforms in the face of stochastic delays. In contrast, our approach significantly outperforms the baselines, for both constant and stochastic delays. The code is available at http://github.com/davidva1/Delayed-EZ .

{{</citation>}}


### (4/6 | 187/266) What Are the Odds? Improving the foundations of Statistical Model Checking (Tobias Meggendorfer et al., 2024)

{{<citation>}}

Tobias Meggendorfer, Maximilian Weininger, Patrick Wienhöft. (2024)  
**What Are the Odds? Improving the foundations of Statistical Model Checking**
<br/>
<button class="copy-to-clipboard" title="What Are the Odds? Improving the foundations of Statistical Model Checking" index=187>
  <span class="copy-to-clipboard-item">Copy Title<span>
</button>
<div class="toast toast-copied toast-index-187 align-items-center text-bg-secondary border-0 position-absolute top-0 end-0" role="alert" aria-live="assertive" aria-atomic="true">
  <div class="d-flex">
    <div class="toast-body">
      Copied!
    </div>
  </div>
</div>

---
Primary Category: cs.AI  
Categories: cs-AI, cs-LG, cs-SY, cs.AI, eess-SY  
Keyword Score: 10  
Keywords: Markov Decision Process  
<a type="button" class="btn btn-outline-primary" href="http://arxiv.org/abs/2404.05424v1" target="_blank" >Paper Link</a>
<button type="button" class="btn btn-outline-primary download-pdf" url="https://arxiv.org/pdf/2404.05424v1.pdf" filename="2404.05424v1.pdf">Download PDF</button>

---


**ABSTRACT**  
Markov decision processes <b>(MDPs)</b> are a fundamental model for decision making under uncertainty. They exhibit non-deterministic choice as well as probabilistic uncertainty. Traditionally, verification algorithms assume exact knowledge of the probabilities that govern the behaviour of an MDP. As this assumption is often unrealistic in practice, statistical model checking (SMC) was developed in the past two decades. It allows to analyse <b>MDPs</b> with unknown transition probabilities and provide probably approximately correct (PAC) guarantees on the result. Model-based SMC algorithms sample the MDP and build a model of it by estimating all transition probabilities, essentially for every transition answering the question: ``What are the odds?'' However, so far the statistical methods employed by the state of the art SMC algorithms are quite naive. Our contribution are several fundamental improvements to those methods: On the one hand, we survey statistics literature for better concentration inequalities; on the other hand, we propose specialised approaches that exploit our knowledge of the MDP. Our improvements are generally applicable to many kinds of problem statements because they are largely independent of the setting. Moreover, our experimental evaluation shows that they lead to significant gains, reducing the number of samples that the SMC algorithm has to collect by up to two orders of magnitude.

{{</citation>}}


### (5/6 | 188/266) Cellular automata, many-valued logic, and deep neural networks (Yani Zhang et al., 2024)

{{<citation>}}

Yani Zhang, Helmut Bölcskei. (2024)  
**Cellular automata, many-valued logic, and deep neural networks**
<br/>
<button class="copy-to-clipboard" title="Cellular automata, many-valued logic, and deep neural networks" index=188>
  <span class="copy-to-clipboard-item">Copy Title<span>
</button>
<div class="toast toast-copied toast-index-188 align-items-center text-bg-secondary border-0 position-absolute top-0 end-0" role="alert" aria-live="assertive" aria-atomic="true">
  <div class="d-flex">
    <div class="toast-body">
      Copied!
    </div>
  </div>
</div>

---
Primary Category: cs.AI  
Categories: cs-AI, cs.AI  
Keyword Score: 10  
Keywords: Recurrent Neural Network  
<a type="button" class="btn btn-outline-primary" href="http://arxiv.org/abs/2404.05259v1" target="_blank" >Paper Link</a>
<button type="button" class="btn btn-outline-primary download-pdf" url="https://arxiv.org/pdf/2404.05259v1.pdf" filename="2404.05259v1.pdf">Download PDF</button>

---


**ABSTRACT**  
We develop a theory characterizing the fundamental capability of deep neural networks to learn, from evolution traces, the logical rules governing the behavior of cellular automata (CA). This is accomplished by first establishing a novel connection between CA and Lukasiewicz propositional logic. While binary CA have been known for decades to essentially perform operations in Boolean logic, no such relationship exists for general CA. We demonstrate that many-valued (MV) logic, specifically Lukasiewicz propositional logic, constitutes a suitable language for characterizing general CA as logical machines. This is done by interpolating CA transition functions to continuous piecewise linear functions, which, by virtue of the McNaughton theorem, yield formulae in MV logic characterizing the CA. Recognizing that deep rectified linear unit (ReLU) networks realize continuous piecewise linear functions, it follows that these formulae are naturally extracted from CA evolution traces by deep ReLU networks. A corresponding algorithm together with a software implementation is provided. Finally, we show that the dynamical behavior of CA can be realized by <b>recurrent</b> <b>neural</b> <b>networks.</b>

{{</citation>}}


### (6/6 | 189/266) Iof-maint -- Modular maintenance ontology (Melinda Hodkiewicz et al., 2024)

{{<citation>}}

Melinda Hodkiewicz, Caitlin Woods, Matt Selway, Markus Stumptner. (2024)  
**Iof-maint -- Modular maintenance ontology**
<br/>
<button class="copy-to-clipboard" title="Iof-maint -- Modular maintenance ontology" index=189>
  <span class="copy-to-clipboard-item">Copy Title<span>
</button>
<div class="toast toast-copied toast-index-189 align-items-center text-bg-secondary border-0 position-absolute top-0 end-0" role="alert" aria-live="assertive" aria-atomic="true">
  <div class="d-flex">
    <div class="toast-body">
      Copied!
    </div>
  </div>
</div>

---
Primary Category: cs.AI  
Categories: cs-AI, cs-LO, cs.AI  
Keyword Score: 10  
Keywords: Reasoning  
<a type="button" class="btn btn-outline-primary" href="http://arxiv.org/abs/2404.05224v1" target="_blank" >Paper Link</a>
<button type="button" class="btn btn-outline-primary download-pdf" url="https://arxiv.org/pdf/2404.05224v1.pdf" filename="2404.05224v1.pdf">Download PDF</button>

---


**ABSTRACT**  
In this paper we present a publicly-available maintenance ontology (Iof-maint). Iof-maint is a modular ontology aligned with the Industrial Ontology Foundry Core (IOF Core) and contains 20 classes and 2 relations. It provides a set of maintenance-specific terms used in a wide variety of practical data-driven use cases. Iof-maint supports OWL DL <b>reasoning,</b> is documented, and is actively maintained on GitHub. In this paper, we describe the evolution of the Iof-maint reference ontology based on the extraction of common concepts identified in a number of application ontologies working with industry maintenance work order, procedure and failure mode data.

{{</citation>}}


## cs.AR (4)



### (1/4 | 190/266) Exploring Quantization and Mapping Synergy in Hardware-Aware Deep Neural Network Accelerators (Jan Klhufek et al., 2024)

{{<citation>}}

Jan Klhufek, Miroslav Safar, Vojtech Mrazek, Zdenek Vasicek, Lukas Sekanina. (2024)  
**Exploring Quantization and Mapping Synergy in Hardware-Aware Deep Neural Network Accelerators**
<br/>
<button class="copy-to-clipboard" title="Exploring Quantization and Mapping Synergy in Hardware-Aware Deep Neural Network Accelerators" index=190>
  <span class="copy-to-clipboard-item">Copy Title<span>
</button>
<div class="toast toast-copied toast-index-190 align-items-center text-bg-secondary border-0 position-absolute top-0 end-0" role="alert" aria-live="assertive" aria-atomic="true">
  <div class="d-flex">
    <div class="toast-body">
      Copied!
    </div>
  </div>
</div>

---
Primary Category: cs.AR  
Categories: cs-AR, cs-LG, cs.AR  
Keyword Score: 50  
Keywords: Convolution, Convolutional Neural Network, Convolutional Neural Network, Quantization, Quantization  
<a type="button" class="btn btn-outline-primary" href="http://arxiv.org/abs/2404.05368v1" target="_blank" >Paper Link</a>
<button type="button" class="btn btn-outline-primary download-pdf" url="https://arxiv.org/pdf/2404.05368v1.pdf" filename="2404.05368v1.pdf">Download PDF</button>

---


**ABSTRACT**  
Energy efficiency and memory footprint of a <b>convolutional</b> <b>neural</b> <b>network</b> <b>(CNN)</b> implemented on a <b>CNN</b> inference accelerator depend on many factors, including a weight <b>quantization</b> strategy (i.e., data types and bit-widths) and mapping (i.e., placement and scheduling of DNN elementary operations on hardware units of the accelerator). We show that enabling rich mixed <b>quantization</b> schemes during the implementation can open a previously hidden space of mappings that utilize the hardware resources more effectively. <b>CNNs</b> utilizing <b>quantized</b> weights and activations and suitable mappings can significantly improve trade-offs among the accuracy, energy, and memory requirements compared to less carefully optimized <b>CNN</b> implementations. To find, analyze, and exploit these mappings, we: (i) extend a general-purpose state-of-the-art mapping tool (Timeloop) to support mixed <b>quantization,</b> which is not currently available; (ii) propose an efficient multi-objective optimization algorithm to find the most suitable bit-widths and mapping for each DNN layer executed on the accelerator; and (iii) conduct a detailed experimental evaluation to validate the proposed method. On two <b>CNNs</b> (MobileNetV1 and MobileNetV2) and two accelerators (Eyeriss and Simba) we show that for a given quality metric (such as the accuracy on ImageNet), energy savings are up to 37% without any accuracy drop.

{{</citation>}}


### (2/4 | 191/266) SRAM-PG: Power Delivery Network Benchmarks from SRAM Circuits (Shan Shen et al., 2024)

{{<citation>}}

Shan Shen, Zhiqiang Liu, Wenjian Yu. (2024)  
**SRAM-PG: Power Delivery Network Benchmarks from SRAM Circuits**
<br/>
<button class="copy-to-clipboard" title="SRAM-PG: Power Delivery Network Benchmarks from SRAM Circuits" index=191>
  <span class="copy-to-clipboard-item">Copy Title<span>
</button>
<div class="toast toast-copied toast-index-191 align-items-center text-bg-secondary border-0 position-absolute top-0 end-0" role="alert" aria-live="assertive" aria-atomic="true">
  <div class="d-flex">
    <div class="toast-body">
      Copied!
    </div>
  </div>
</div>

---
Primary Category: cs.AR  
Categories: cs-AR, cs.AR  
Keyword Score: 23  
Keywords: Benchmarking, Simulation, Simulator  
<a type="button" class="btn btn-outline-primary" href="http://arxiv.org/abs/2404.05260v1" target="_blank" >Paper Link</a>
<button type="button" class="btn btn-outline-primary download-pdf" url="https://arxiv.org/pdf/2404.05260v1.pdf" filename="2404.05260v1.pdf">Download PDF</button>

---


**ABSTRACT**  
Designing the power delivery network (PDN) in very large-scale integrated (VLSI) circuits is increasingly important, especially for nowadays low-power integrated circuit (IC) design. In order to ensure that the designed PDN enables a low level of voltage drop and noise which is required for the success of IC design, accurate analysis of PDN is largely demanded and brings a challenge of computation during the whole process of IC design. This promotes the research of efficient and scalable <b>simulation</b> methods for PDN. However, the lack of sufficient public PDN <b>benchmarks</b> hinders the relevant research. % on this aspect since it is hard to conduct a rapid and clear comparison between different approaches to solving this problem. To this end, we construct and release a set of PDN <b>benchmarks</b> (named \emph{SRAM-PG}) from SRAM circuit design in this work. The <b>benchmarks</b> are obtained from realistic and state-of-the-art SRAM designs, following a workflow for generating the post-layout PDN netlists with full RC parasitics. With careful modeling of load currents, the <b>benchmarks</b> reflect the dynamic work mode of the IC and can be used for both transient and DC analysis. The <b>benchmarks</b> are derived from the designs for diverse applications. And, sharing them in the public domain with detailed descriptions would largely benefit the relevant research. The whole set of <b>benchmarks</b> is available at \href{github}{https://github.com/ShenShan123/SRAM-PG}.

{{</citation>}}


### (3/4 | 192/266) Resistive Memory-based Neural Differential Equation Solver for Score-based Diffusion Model (Jichang Yang et al., 2024)

{{<citation>}}

Jichang Yang, Hegan Chen, Jia Chen, Songqi Wang, Shaocong Wang, Yifei Yu, Xi Chen, Bo Wang, Xinyuan Zhang, Binbin Cui, Yi Li, Ning Lin, Meng Xu, Yi Li, Xiaoxin Xu, Xiaojuan Qi, Zhongrui Wang, Xumeng Zhang, Dashan Shang, Han Wang, Qi Liu, Kwang-Ting Cheng, Ming Liu. (2024)  
**Resistive Memory-based Neural Differential Equation Solver for Score-based Diffusion Model**
<br/>
<button class="copy-to-clipboard" title="Resistive Memory-based Neural Differential Equation Solver for Score-based Diffusion Model" index=192>
  <span class="copy-to-clipboard-item">Copy Title<span>
</button>
<div class="toast toast-copied toast-index-192 align-items-center text-bg-secondary border-0 position-absolute top-0 end-0" role="alert" aria-live="assertive" aria-atomic="true">
  <div class="d-flex">
    <div class="toast-body">
      Copied!
    </div>
  </div>
</div>

---
Primary Category: cs.AR  
Categories: cs-AI, cs-AR, cs-ET, cs-NE, cs.AR  
Keyword Score: 20  
Keywords: Diffusion Model, Generative AI  
<a type="button" class="btn btn-outline-primary" href="http://arxiv.org/abs/2404.05648v1" target="_blank" >Paper Link</a>
<button type="button" class="btn btn-outline-primary download-pdf" url="https://arxiv.org/pdf/2404.05648v1.pdf" filename="2404.05648v1.pdf">Download PDF</button>

---


**ABSTRACT**  
Human brains image complicated scenes when reading a novel. Replicating this imagination is one of the ultimate goals of AI-Generated Content (AIGC). However, current AIGC methods, such as score-based <b>diffusion,</b> <b>are</b> still deficient in terms of rapidity and efficiency. This deficiency is rooted in the difference between the brain and digital computers. Digital computers have physically separated storage and processing units, resulting in frequent data transfers during iterative calculations, incurring large time and energy overheads. This issue is further intensified by the conversion of inherently continuous and analog generation dynamics, which can be formulated by neural differential equations, into discrete and digital operations. Inspired by the brain, we propose a time-continuous and analog in-memory neural differential equation solver for score-based <b>diffusion,</b> <b>employing</b> emerging resistive memory. The integration of storage and computation within resistive memory synapses surmount the von Neumann bottleneck, benefiting the <b>generative</b> <b>speed</b> and energy efficiency. The closed-loop feedback integrator is time-continuous, analog, and compact, physically implementing an infinite-depth neural network. Moreover, the software-hardware co-design is intrinsically robust to analog noise. We experimentally validate our solution with 180 nm resistive memory in-memory computing macros. Demonstrating equivalent <b>generative</b> <b>quality</b> to the software baseline, our system achieved remarkable enhancements in <b>generative</b> <b>speed</b> for both unconditional and conditional generation tasks, by factors of 64.8 and 156.5, respectively. Moreover, it accomplished reductions in energy consumption by factors of 5.2 and 4.1. Our approach heralds a new horizon for hardware solutions in edge computing for <b>generative</b> <b>AI</b> applications.

{{</citation>}}


### (4/4 | 193/266) Design and implementation of a synchronous Hardware Performance Monitor for a RISC-V space-oriented processor (Miguel Jiménez Arribas et al., 2024)

{{<citation>}}

Miguel Jiménez Arribas, Agustín Martínez Hellín, Manuel Prieto Mateo, Iván Gamino del Río, Andrea Fernandez Gallego, Oscar Rodríguez Polo, Antonio da Silva, Pablo Parra, Sebastián Sánchez. (2024)  
**Design and implementation of a synchronous Hardware Performance Monitor for a RISC-V space-oriented processor**
<br/>
<button class="copy-to-clipboard" title="Design and implementation of a synchronous Hardware Performance Monitor for a RISC-V space-oriented processor" index=193>
  <span class="copy-to-clipboard-item">Copy Title<span>
</button>
<div class="toast toast-copied toast-index-193 align-items-center text-bg-secondary border-0 position-absolute top-0 end-0" role="alert" aria-live="assertive" aria-atomic="true">
  <div class="d-flex">
    <div class="toast-body">
      Copied!
    </div>
  </div>
</div>

---
Primary Category: cs.AR  
Categories: B-8-2; C-1-1, cs-AR, cs.AR  
Keyword Score: 3  
Keywords: Benchmarking  
<a type="button" class="btn btn-outline-primary" href="http://arxiv.org/abs/2404.05389v1" target="_blank" >Paper Link</a>
<button type="button" class="btn btn-outline-primary download-pdf" url="https://arxiv.org/pdf/2404.05389v1.pdf" filename="2404.05389v1.pdf">Download PDF</button>

---


**ABSTRACT**  
The ability to collect statistics about the execution of a program within a CPU is of the utmost importance across all fields of computing since it allows characterizing the timing performance of a program. This capability is even more relevant in safety-critical software systems, where it is mandatory to analyze software timing requirements to ensure the correct operation of the programs. Moreover, in order to properly evaluate and verify the extra-functional properties of these systems, besides timing performance, there are many other statistics available on a CPU, such as those associated with resource utilization. In this paper, we showcase a Performance Measurement Unit, also known as Hardware Performance Monitor, integrated into a RISC-V On-Board Computer designed for space applications by our research group. The monitoring technique features a novel approach whereby the events triggered are not counted immediately but instead are propagated through the pipeline so that their annotation is synchronized with the executed instruction. Additionally, we demonstrate the use of this PMU in a process to characterize the execution model of the processor. Finally, as an example of the statistics provided by the PMU, the results obtained running the CoreMark and Dhrystone <b>benchmarks</b> on the RISC-V OBC are shown.

{{</citation>}}


## eess.SP (3)



### (1/3 | 194/266) Decision Transformer for Wireless Communications: A New Paradigm of Resource Management (Jie Zhang et al., 2024)

{{<citation>}}

Jie Zhang, Jun Li, Long Shi, Zhe Wang, Shi Jin, Wen Chen, H. Vincent Poor. (2024)  
**Decision Transformer for Wireless Communications: A New Paradigm of Resource Management**
<br/>
<button class="copy-to-clipboard" title="Decision Transformer for Wireless Communications: A New Paradigm of Resource Management" index=194>
  <span class="copy-to-clipboard-item">Copy Title<span>
</button>
<div class="toast toast-copied toast-index-194 align-items-center text-bg-secondary border-0 position-absolute top-0 end-0" role="alert" aria-live="assertive" aria-atomic="true">
  <div class="d-flex">
    <div class="toast-body">
      Copied!
    </div>
  </div>
</div>

---
Primary Category: eess.SP  
Categories: cs-IT, eess-SP, eess.SP, math-IT  
Keyword Score: 50  
Keywords: Fine-tuning, Reinforcement Learning, Simulation, Simulator, Transformer  
<a type="button" class="btn btn-outline-primary" href="http://arxiv.org/abs/2404.05199v1" target="_blank" >Paper Link</a>
<button type="button" class="btn btn-outline-primary download-pdf" url="https://arxiv.org/pdf/2404.05199v1.pdf" filename="2404.05199v1.pdf">Download PDF</button>

---


**ABSTRACT**  
As the next generation of mobile systems evolves, artificial intelligence (AI) is expected to deeply integrate with wireless communications for resource management in variable environments. In particular, deep <b>reinforcement</b> <b>learning</b> (DRL) is an important tool for addressing stochastic optimization issues of resource allocation. However, DRL has to start each new training process from the beginning once the state and action spaces change, causing low sample efficiency and poor generalization ability. Moreover, each DRL training process may take a large number of epochs to converge, which is unacceptable for time-sensitive scenarios. In this paper, we adopt an alternative AI technology, namely, the Decision <b>Transformer</b> (DT), and propose a DT-based adaptive decision architecture for wireless resource management. This architecture innovates through constructing pre-trained models in the cloud and then <b>fine-tuning</b> personalized models at the edges. By leveraging the power of DT models learned over extensive datasets, the proposed architecture is expected to achieve rapid convergence with many fewer training epochs and higher performance in a new context, e.g., similar tasks with different state and action spaces, compared with DRL. We then design DT frameworks for two typical communication scenarios: Intelligent reflecting surfaces-aided communications and unmanned aerial vehicle-aided edge computing. <b>Simulations</b> demonstrate that the proposed DT frameworks achieve over $3$-$6$ times speedup in convergence and better performance relative to the classic DRL method, namely, proximal policy optimization.

{{</citation>}}


### (2/3 | 195/266) Condition Monitoring with Incomplete Data: An Integrated Variational Autoencoder and Distance Metric Framework (Maryam Ahang et al., 2024)

{{<citation>}}

Maryam Ahang, Mostafa Abbasi, Todd Charter, Homayoun Najjaran. (2024)  
**Condition Monitoring with Incomplete Data: An Integrated Variational Autoencoder and Distance Metric Framework**
<br/>
<button class="copy-to-clipboard" title="Condition Monitoring with Incomplete Data: An Integrated Variational Autoencoder and Distance Metric Framework" index=195>
  <span class="copy-to-clipboard-item">Copy Title<span>
</button>
<div class="toast toast-copied toast-index-195 align-items-center text-bg-secondary border-0 position-absolute top-0 end-0" role="alert" aria-live="assertive" aria-atomic="true">
  <div class="d-flex">
    <div class="toast-body">
      Copied!
    </div>
  </div>
</div>

---
Primary Category: eess.SP  
Categories: cs-AI, cs-LG, eess-SP, eess.SP  
Keyword Score: 40  
Keywords: Autoencoder, Variational Autoencoder, Zero-shot, Zero-shot Learning  
<a type="button" class="btn btn-outline-primary" href="http://arxiv.org/abs/2404.05891v1" target="_blank" >Paper Link</a>
<button type="button" class="btn btn-outline-primary download-pdf" url="https://arxiv.org/pdf/2404.05891v1.pdf" filename="2404.05891v1.pdf">Download PDF</button>

---


**ABSTRACT**  
Condition monitoring of industrial systems is crucial for ensuring safety and maintenance planning, yet notable challenges arise in real-world settings due to the limited or non-existent availability of fault samples. This paper introduces an innovative solution to this problem by proposing a new method for fault detection and condition monitoring for unseen data. Adopting an approach inspired by <b>zero-shot</b> <b>learning,</b> our method can identify faults and assign a relative health index to various operational conditions. Typically, we have plenty of data on normal operations, some data on compromised conditions, and very few (if any) samples of severe faults. We use a <b>variational</b> <b>autoencoder</b> to capture the probabilistic distribution of previously seen and new unseen conditions. The health status is determined by comparing each sample's deviation from a normal operation reference distribution in the latent space. Faults are detected by establishing a threshold for the health indexes, allowing the model to identify severe, unseen faults with high accuracy, even amidst noise. We validate our approach using the run-to-failure IMS-bearing dataset and compare it with other methods. The health indexes generated by our model closely match the established descriptive model of bearing wear, attesting to the robustness and reliability of our method. These findings highlight the potential of our methodology in augmenting fault detection capabilities within industrial domains, thereby contributing to heightened safety protocols and optimized maintenance practices.

{{</citation>}}


### (3/3 | 196/266) Jammer-Resilient Time Synchronization in the MIMO Uplink (Gian Marti et al., 2024)

{{<citation>}}

Gian Marti, Flurin Arquint, Christoph Studer. (2024)  
**Jammer-Resilient Time Synchronization in the MIMO Uplink**
<br/>
<button class="copy-to-clipboard" title="Jammer-Resilient Time Synchronization in the MIMO Uplink" index=196>
  <span class="copy-to-clipboard-item">Copy Title<span>
</button>
<div class="toast toast-copied toast-index-196 align-items-center text-bg-secondary border-0 position-absolute top-0 end-0" role="alert" aria-live="assertive" aria-atomic="true">
  <div class="d-flex">
    <div class="toast-body">
      Copied!
    </div>
  </div>
</div>

---
Primary Category: eess.SP  
Categories: cs-IT, eess-SP, eess.SP, math-IT  
Keyword Score: 20  
Keywords: Simulation, Simulator  
<a type="button" class="btn btn-outline-primary" href="http://arxiv.org/abs/2404.05335v1" target="_blank" >Paper Link</a>
<button type="button" class="btn btn-outline-primary download-pdf" url="https://arxiv.org/pdf/2404.05335v1.pdf" filename="2404.05335v1.pdf">Download PDF</button>

---


**ABSTRACT**  
Spatial filtering based on multiple-input multiple-output (MIMO) processing is a promising approach to jammer mitigation. Effective MIMO data detectors that mitigate smart jammers have recently been proposed, but they all assume perfect time synchronization between transmitter(s) and receiver. However, to the best of our knowledge, there are no methods for resilient time synchronization in the presence of smart jammers. To remedy this situation, we propose JASS, the first method that enables reliable time synchronization for the single-user MIMO uplink while mitigating smart jamming attacks. JASS detects a randomized synchronization sequence based on a novel optimization problem that fits a spatial filter to the time-windowed receive signal in order to mitigate the jammer. We underscore the efficacy of the proposed optimization problem by proving that it ensures successful time synchronization under certain intuitive conditions. We then derive an efficient algorithm for approximately solving our optimization problem. Finally, we use <b>simulations</b> to demonstrate the effectiveness of JASS against a wide range of different jammer types.

{{</citation>}}


## cs.IR (3)



### (1/3 | 197/266) LLM-Augmented Retrieval: Enhancing Retrieval Models Through Language Models and Doc-Level Embedding (Mingrui Wu et al., 2024)

{{<citation>}}

Mingrui Wu, Sheng Cao. (2024)  
**LLM-Augmented Retrieval: Enhancing Retrieval Models Through Language Models and Doc-Level Embedding**
<br/>
<button class="copy-to-clipboard" title="LLM-Augmented Retrieval: Enhancing Retrieval Models Through Language Models and Doc-Level Embedding" index=197>
  <span class="copy-to-clipboard-item">Copy Title<span>
</button>
<div class="toast toast-copied toast-index-197 align-items-center text-bg-secondary border-0 position-absolute top-0 end-0" role="alert" aria-live="assertive" aria-atomic="true">
  <div class="d-flex">
    <div class="toast-body">
      Copied!
    </div>
  </div>
</div>

---
Primary Category: cs.IR  
Categories: cs-AI, cs-IR, cs.IR  
Keyword Score: 40  
Keywords: Dense Retrieval, Bag-of-Words, Large Language Model, Large Language Model  
<a type="button" class="btn btn-outline-primary" href="http://arxiv.org/abs/2404.05825v1" target="_blank" >Paper Link</a>
<button type="button" class="btn btn-outline-primary download-pdf" url="https://arxiv.org/pdf/2404.05825v1.pdf" filename="2404.05825v1.pdf">Download PDF</button>

---


**ABSTRACT**  
Recently embedding-based retrieval or <b>dense</b> <b>retrieval</b> have shown state of the art results, compared with traditional sparse or <b>bag-of-words</b> based approaches. This paper introduces a model-agnostic doc-level embedding framework through <b>large</b> <b>language</b> <b>model</b> <b>(LLM)</b> augmentation. In addition, it also improves some important components in the retrieval model training process, such as negative sampling, loss function, etc. By implementing this <b>LLM-augmented</b> retrieval framework, we have been able to significantly improve the effectiveness of widely-used retriever models such as Bi-encoders (Contriever, DRAGON) and late-interaction models (ColBERTv2), thereby achieving state-of-the-art results on LoTTE datasets and BEIR datasets.

{{</citation>}}


### (2/3 | 198/266) MealRec$^+$: A Meal Recommendation Dataset with Meal-Course Affiliation for Personalization and Healthiness (Ming Li et al., 2024)

{{<citation>}}

Ming Li, Lin Li, Xiaohui Tao, Jimmy Xiangji Huang. (2024)  
**MealRec$^+$: A Meal Recommendation Dataset with Meal-Course Affiliation for Personalization and Healthiness**
<br/>
<button class="copy-to-clipboard" title="MealRec$^+$: A Meal Recommendation Dataset with Meal-Course Affiliation for Personalization and Healthiness" index=198>
  <span class="copy-to-clipboard-item">Copy Title<span>
</button>
<div class="toast toast-copied toast-index-198 align-items-center text-bg-secondary border-0 position-absolute top-0 end-0" role="alert" aria-live="assertive" aria-atomic="true">
  <div class="d-flex">
    <div class="toast-body">
      Copied!
    </div>
  </div>
</div>

---
Primary Category: cs.IR  
Categories: cs-IR, cs.IR  
Keyword Score: 33  
Keywords: Benchmarking, Recommendation, Simulation, Simulator  
<a type="button" class="btn btn-outline-primary" href="http://arxiv.org/abs/2404.05386v1" target="_blank" >Paper Link</a>
<button type="button" class="btn btn-outline-primary download-pdf" url="https://arxiv.org/pdf/2404.05386v1.pdf" filename="2404.05386v1.pdf">Download PDF</button>

---


**ABSTRACT**  
Meal <b>recommendation,</b> as a typical health-related <b>recommendation</b> task, contains complex relationships between users, courses, and meals. Among them, meal-course affiliation associates user-meal and user-course interactions. However, an extensive literature review demonstrates that there is a lack of publicly available meal <b>recommendation</b> datasets including meal-course affiliation. Meal <b>recommendation</b> research has been constrained in exploring the impact of cooperation between two levels of interaction on personalization and healthiness. To pave the way for meal <b>recommendation</b> research, we introduce a new <b>benchmark</b> dataset called MealRec$^+$. Due to constraints related to user health privacy and meal scenario characteristics, the collection of data that includes both meal-course affiliation and two levels of interactions is impeded. Therefore, a <b>simulation</b> method is adopted to derive meal-course affiliation and user-meal interaction from the user's dining sessions simulated based on user-course interaction data. Then, two well-known nutritional standards are used to calculate the healthiness scores of meals. Moreover, we experiment with several baseline models, including separate and cooperative interaction learning methods. Our experiment demonstrates that cooperating the two levels of interaction in appropriate ways is beneficial for meal <b>recommendations.</b> Furthermore, in response to the less healthy <b>recommendation</b> phenomenon found in the experiment, we explore methods to enhance the healthiness of meal <b>recommendations.</b> The dataset is available on GitHub (https://github.com/WUT-IDEA/MealRecPlus).

{{</citation>}}


### (3/3 | 199/266) Beyond the Sequence: Statistics-Driven Pre-training for Stabilizing Sequential Recommendation Model (Sirui Wang et al., 2024)

{{<citation>}}

Sirui Wang, Peiguang Li, Yunsen Xian, Hongzhi Zhang. (2024)  
**Beyond the Sequence: Statistics-Driven Pre-training for Stabilizing Sequential Recommendation Model**
<br/>
<button class="copy-to-clipboard" title="Beyond the Sequence: Statistics-Driven Pre-training for Stabilizing Sequential Recommendation Model" index=199>
  <span class="copy-to-clipboard-item">Copy Title<span>
</button>
<div class="toast toast-copied toast-index-199 align-items-center text-bg-secondary border-0 position-absolute top-0 end-0" role="alert" aria-live="assertive" aria-atomic="true">
  <div class="d-flex">
    <div class="toast-body">
      Copied!
    </div>
  </div>
</div>

---
Primary Category: cs.IR  
Categories: cs-IR, cs.IR  
Keyword Score: 10  
Keywords: Recommendation  
<a type="button" class="btn btn-outline-primary" href="http://arxiv.org/abs/2404.05342v1" target="_blank" >Paper Link</a>
<button type="button" class="btn btn-outline-primary download-pdf" url="https://arxiv.org/pdf/2404.05342v1.pdf" filename="2404.05342v1.pdf">Download PDF</button>

---


**ABSTRACT**  
The sequential <b>recommendation</b> task aims to predict the item that user is interested in according to his/her historical action sequence. However, inevitable random action, i.e. user randomly accesses an item among multiple candidates or clicks several items at random order, cause the sequence fails to provide stable and high-quality signals. To alleviate the issue, we propose the StatisTics-Driven Pre-traing framework (called STDP briefly). The main idea of the work lies in the exploration of utilizing the statistics information along with the pre-training paradigm to stabilize the optimization of <b>recommendation</b> model. Specifically, we derive two types of statistical information: item co-occurrence across sequence and attribute frequency within the sequence. And we design the following pre-training tasks: 1) The co-occurred items prediction task, which encourages the model to distribute its attention on multiple suitable targets instead of just focusing on the next item that may be unstable. 2) We generate a paired sequence by replacing items with their co-occurred items and enforce its representation close with the original one, thus enhancing the model's robustness to the random noise. 3) To reduce the impact of random on user's long-term preferences, we encourage the model to capture sequence-level frequent attributes. The significant improvement over six datasets demonstrates the effectiveness and superiority of the proposal, and further analysis verified the generalization of the STDP framework on other models.

{{</citation>}}


## quant-ph (3)



### (1/3 | 200/266) Quantum Adversarial Learning for Kernel Methods (Giuseppe Montalbano et al., 2024)

{{<citation>}}

Giuseppe Montalbano, Leonardo Banchi. (2024)  
**Quantum Adversarial Learning for Kernel Methods**
<br/>
<button class="copy-to-clipboard" title="Quantum Adversarial Learning for Kernel Methods" index=200>
  <span class="copy-to-clipboard-item">Copy Title<span>
</button>
<div class="toast toast-copied toast-index-200 align-items-center text-bg-secondary border-0 position-absolute top-0 end-0" role="alert" aria-live="assertive" aria-atomic="true">
  <div class="d-flex">
    <div class="toast-body">
      Copied!
    </div>
  </div>
</div>

---
Primary Category: quant-ph  
Categories: cs-CR, cs-LG, quant-ph, quant-ph  
Keyword Score: 40  
Keywords: Adversarial Learning, Data Augmentation, Adversarial Attack, Security  
<a type="button" class="btn btn-outline-primary" href="http://arxiv.org/abs/2404.05824v1" target="_blank" >Paper Link</a>
<button type="button" class="btn btn-outline-primary download-pdf" url="https://arxiv.org/pdf/2404.05824v1.pdf" filename="2404.05824v1.pdf">Download PDF</button>

---


**ABSTRACT**  
We show that hybrid quantum classifiers based on quantum kernel methods and support vector machines are vulnerable against <b>adversarial</b> <b>attacks,</b> namely small engineered perturbations of the input <b>data</b> <b>can</b> deceive the classifier into predicting the wrong result. Nonetheless, we also show that simple defence strategies based on <b>data</b> <b>augmentation</b> with a few crafted perturbations can make the classifier robust against new attacks. Our results find applications in <b>security-critical</b> learning problems and in mitigating the effect of some forms of quantum noise, since the attacker can also be understood as part of the surrounding environment.

{{</citation>}}


### (2/3 | 201/266) Quantum Annealers Chain Strengths: A Simple Heuristic to Set Them All (Valentin Gilbert et al., 2024)

{{<citation>}}

Valentin Gilbert, Stéphane Louise. (2024)  
**Quantum Annealers Chain Strengths: A Simple Heuristic to Set Them All**
<br/>
<button class="copy-to-clipboard" title="Quantum Annealers Chain Strengths: A Simple Heuristic to Set Them All" index=201>
  <span class="copy-to-clipboard-item">Copy Title<span>
</button>
<div class="toast toast-copied toast-index-201 align-items-center text-bg-secondary border-0 position-absolute top-0 end-0" role="alert" aria-live="assertive" aria-atomic="true">
  <div class="d-flex">
    <div class="toast-body">
      Copied!
    </div>
  </div>
</div>

---
Primary Category: quant-ph  
Categories: cs-ET, quant-ph, quant-ph  
Keyword Score: 10  
Keywords: Question Answering  
<a type="button" class="btn btn-outline-primary" href="http://arxiv.org/abs/2404.05443v1" target="_blank" >Paper Link</a>
<button type="button" class="btn btn-outline-primary download-pdf" url="https://arxiv.org/pdf/2404.05443v1.pdf" filename="2404.05443v1.pdf">Download PDF</button>

---


**ABSTRACT**  
Quantum annealers <b>(QA),</b> such as D-Wave systems, become increasingly efficient and competitive at solving combinatorial optimization problems. However, solving problems that do not directly map the chip topology remains challenging for this type of quantum computer. The creation of logical qubits as sets of interconnected physical qubits overcomes limitations imposed by the sparsity of the chip at the expense of increasing the problem size and adding new parameters to optimize. This paper explores the advantages and drawbacks provided by the structure of the logical qubits and the impact of the rescaling of coupler strength on the minimum spectral gap of Ising models. We show that densely connected logical qubits require a lower chain strength to maintain the ferromagnetic coupling. We also analyze the optimal chain strength variations considering different minor embeddings of the same instance. This experimental study suggests that the chain strength can be optimized for each instance. We design a heuristic that optimizes the chain strength using a very low number of shots during the pre-processing step. This heuristic outperforms the default method used to initialize the chain strength on D-Wave systems, increasing the quality of the best solution by up to 17.2% for tested instances on the max-cut problem.

{{</citation>}}


### (3/3 | 202/266) A Note on the Common Haar State Model (Prabhanjan Ananth et al., 2024)

{{<citation>}}

Prabhanjan Ananth, Aditya Gulati, Yao-Ting Lin. (2024)  
**A Note on the Common Haar State Model**
<br/>
<button class="copy-to-clipboard" title="A Note on the Common Haar State Model" index=202>
  <span class="copy-to-clipboard-item">Copy Title<span>
</button>
<div class="toast toast-copied toast-index-202 align-items-center text-bg-secondary border-0 position-absolute top-0 end-0" role="alert" aria-live="assertive" aria-atomic="true">
  <div class="d-flex">
    <div class="toast-body">
      Copied!
    </div>
  </div>
</div>

---
Primary Category: quant-ph  
Categories: cs-CR, quant-ph, quant-ph  
Keyword Score: 10  
Keywords: Security  
<a type="button" class="btn btn-outline-primary" href="http://arxiv.org/abs/2404.05227v1" target="_blank" >Paper Link</a>
<button type="button" class="btn btn-outline-primary download-pdf" url="https://arxiv.org/pdf/2404.05227v1.pdf" filename="2404.05227v1.pdf">Download PDF</button>

---


**ABSTRACT**  
Common random string model is a popular model in classical cryptography with many constructions proposed in this model. We study a quantum analogue of this model called the common Haar state model, which was also studied in an independent work by Chen, Coladangelo and Sattath (arXiv 2024). In this model, every party in the cryptographic system receives many copies of one or more i.i.d Haar states. Our main result is the construction of a statistically secure PRSG with: (a) the output length of the PRSG is strictly larger than the key size, (b) the <b>security</b> holds even if the adversary receives $O\left(\frac{\lambda}{(\log(\lambda))^{1.01}} \right)$ copies of the pseudorandom state. We show the optimality of our construction by showing a matching lower bound. Our construction is simple and its analysis uses elementary techniques.

{{</citation>}}


## eess.SY (6)



### (1/6 | 203/266) Enhance Low-Carbon Power System Operation via Carbon-Aware Demand Response (Xin Chen, 2024)

{{<citation>}}

Xin Chen. (2024)  
**Enhance Low-Carbon Power System Operation via Carbon-Aware Demand Response**
<br/>
<button class="copy-to-clipboard" title="Enhance Low-Carbon Power System Operation via Carbon-Aware Demand Response" index=203>
  <span class="copy-to-clipboard-item">Copy Title<span>
</button>
<div class="toast toast-copied toast-index-203 align-items-center text-bg-secondary border-0 position-absolute top-0 end-0" role="alert" aria-live="assertive" aria-atomic="true">
  <div class="d-flex">
    <div class="toast-body">
      Copied!
    </div>
  </div>
</div>

---
Primary Category: eess.SY  
Categories: cs-SY, eess-SY, eess.SY  
Keyword Score: 40  
Keywords: Karush-Kuhn-Tucker, Karush-Kuhn-Tucker, Simulation, Simulator  
<a type="button" class="btn btn-outline-primary" href="http://arxiv.org/abs/2404.05713v1" target="_blank" >Paper Link</a>
<button type="button" class="btn btn-outline-primary download-pdf" url="https://arxiv.org/pdf/2404.05713v1.pdf" filename="2404.05713v1.pdf">Download PDF</button>

---


**ABSTRACT**  
As the electrification process advances, enormous power flexibility is becoming available on the demand side, which can be harnessed to facilitate power system decarbonization. Hence, this paper studies the carbon-aware demand response (C-DR) paradigm, where individual users aim to minimize their carbon footprints through the optimal scheduling of flexible load devices. The specific operational dynamics and constraints of deferrable loads and thermostatically controlled loads are considered, and the carbon emission flow method is employed to determine users' carbon footprints using nodal carbon intensities. Then, an optimal power dispatch model that integrates the C-DR mechanism is proposed for low-carbon power system operation, based on the carbon-aware optimal power flow (C-OPF) method. Two solution algorithms, including a centralized <b>Karush-Kuhn-Tucker</b> <b>(KKT)</b> reformulation algorithm and an iterative solution algorithm, are developed to solve the bi-level power dispatch optimization model. Numerical <b>simulations</b> on the IEEE New England 39-bus system demonstrate the effectiveness of the proposed methods.

{{</citation>}}


### (2/6 | 204/266) Model Predictive Control based Energy Management System for Home Energy Resiliency (Ninad Gaikwad et al., 2024)

{{<citation>}}

Ninad Gaikwad, Shishir Lamichhane, Anamika Dubey. (2024)  
**Model Predictive Control based Energy Management System for Home Energy Resiliency**
<br/>
<button class="copy-to-clipboard" title="Model Predictive Control based Energy Management System for Home Energy Resiliency" index=204>
  <span class="copy-to-clipboard-item">Copy Title<span>
</button>
<div class="toast toast-copied toast-index-204 align-items-center text-bg-secondary border-0 position-absolute top-0 end-0" role="alert" aria-live="assertive" aria-atomic="true">
  <div class="d-flex">
    <div class="toast-body">
      Copied!
    </div>
  </div>
</div>

---
Primary Category: eess.SY  
Categories: cs-SY, eess-SY, eess.SY  
Keyword Score: 20  
Keywords: Simulation, Simulator  
<a type="button" class="btn btn-outline-primary" href="http://arxiv.org/abs/2404.05873v1" target="_blank" >Paper Link</a>
<button type="button" class="btn btn-outline-primary download-pdf" url="https://arxiv.org/pdf/2404.05873v1.pdf" filename="2404.05873v1.pdf">Download PDF</button>

---


**ABSTRACT**  
As the occurrence of extreme weather events is increasing so are the outages caused by them. During such unplanned outages, a house needs to be provided with an energy supply to maintain habitable conditions by maintaining thermal comfort and servicing at least critical loads. An energy system consisting of rooftop photovoltaic (PV) panels along with battery storage is an excellent carbon-free choice to provide energy resiliency to houses against extreme weather-related outages. However, to provide habitable conditions this energy system has to provide not only for the non-air-conditioning (non-AC) load demand but also for the turning on of the AC system which has a considerably higher startup power requirement as compared to its rated power. Hence, an intelligent automated decision-making controller is needed which can manage the trade-off between competing requirements. In this paper, we propose such an intelligent controller based on Model Predictive Control (MPC). We compare its performance with a Baseline controller which is unintelligent, and a Rule-Based controller which has some intelligence, based on three resiliency metrics that we have developed. We perform extensive <b>simulations</b> for numerous scenarios involving different energy system sizes and AC startup power requirements. Every <b>simulation</b> is one week long and is carried out for a single-family detached house located in Florida in the aftermath of Hurricane Irma in 2017. The <b>simulation</b> results show that the MPC controller performs better than the other controllers in the more energy-constrained scenarios (smaller PV-battery size, larger AC startup power requirement) in providing both thermal comfort and servicing non-AC loads in a balanced manner.

{{</citation>}}


### (3/6 | 205/266) Stability Enhancement of LCL-Type Grid-Following Inverters Using Capacitor Voltage Active Damping (Naser Souri et al., 2024)

{{<citation>}}

Naser Souri, Ali Mehrizi-Sani, Kambiz Tehrani. (2024)  
**Stability Enhancement of LCL-Type Grid-Following Inverters Using Capacitor Voltage Active Damping**
<br/>
<button class="copy-to-clipboard" title="Stability Enhancement of LCL-Type Grid-Following Inverters Using Capacitor Voltage Active Damping" index=205>
  <span class="copy-to-clipboard-item">Copy Title<span>
</button>
<div class="toast toast-copied toast-index-205 align-items-center text-bg-secondary border-0 position-absolute top-0 end-0" role="alert" aria-live="assertive" aria-atomic="true">
  <div class="d-flex">
    <div class="toast-body">
      Copied!
    </div>
  </div>
</div>

---
Primary Category: eess.SY  
Categories: cs-SY, eess-SY, eess.SY  
Keyword Score: 20  
Keywords: Simulation, Simulator  
<a type="button" class="btn btn-outline-primary" href="http://arxiv.org/abs/2404.05640v1" target="_blank" >Paper Link</a>
<button type="button" class="btn btn-outline-primary download-pdf" url="https://arxiv.org/pdf/2404.05640v1.pdf" filename="2404.05640v1.pdf">Download PDF</button>

---


**ABSTRACT**  
An LCL filter offers superior attenuation for high-frequency harmonics for three-phase grid-following inverters compared to LC and L filters. However, it also introduces an inherent resonance peak, which can lead to power quality issues or even instability of the inverter control system. Active damping (AD) is widely employed to effectively mitigate this resonance. Capacitor voltage feedback (CVF) and capacitor current feedback (CCF) are effective AD methods for LCL resonance damping. CVF is preferred due to its lower sensor requirement compared to CCF. However, a derivative term appears in the active damping loop, which introduces high-frequency noise into the system. This paper proposes a noise-immune approach by replacing the derivative term with a discrete function suitable for digital implementation. The LCL resonance can be damped effectively, resulting in enhanced stability of the inverter control system. <b>Simulation</b> results verify the proposed effectiveness of the method with grid inductance variation and weak grid conditions

{{</citation>}}


### (4/6 | 206/266) Contouring Error Bounded Control for Biaxial Switched Linear Systems (Meng Yuan et al., 2024)

{{<citation>}}

Meng Yuan, Ye Wang, Chris Manzie, Zhezhuang Xu, Tianyou Chai. (2024)  
**Contouring Error Bounded Control for Biaxial Switched Linear Systems**
<br/>
<button class="copy-to-clipboard" title="Contouring Error Bounded Control for Biaxial Switched Linear Systems" index=206>
  <span class="copy-to-clipboard-item">Copy Title<span>
</button>
<div class="toast toast-copied toast-index-206 align-items-center text-bg-secondary border-0 position-absolute top-0 end-0" role="alert" aria-live="assertive" aria-atomic="true">
  <div class="d-flex">
    <div class="toast-body">
      Copied!
    </div>
  </div>
</div>

---
Primary Category: eess.SY  
Categories: cs-SY, eess-SY, eess.SY  
Keyword Score: 20  
Keywords: Simulation, Simulator  
<a type="button" class="btn btn-outline-primary" href="http://arxiv.org/abs/2404.05404v1" target="_blank" >Paper Link</a>
<button type="button" class="btn btn-outline-primary download-pdf" url="https://arxiv.org/pdf/2404.05404v1.pdf" filename="2404.05404v1.pdf">Download PDF</button>

---


**ABSTRACT**  
Biaxial motion control systems are used extensively in manufacturing and printing industries. To improve throughput and reduce machine cost, lightweight materials are being proposed in structural components but may result in higher flexibility in the machine links. This flexibility is often position dependent and compromises precision of the end effector of the machine. To address the need for improved contouring accuracy in industrial machines with position-dependent structural flexibility, this paper introduces a novel contouring error-bounded control algorithm for biaxial switched linear systems. The proposed algorithm utilizes model predictive control to guarantee the satisfaction of state, input, and contouring error constraints for any admissible mode switching. In this paper, the switching signal remains unknown to the controller, although information about the minimum time the system is expected to stay in a specific mode is considered to be available. The proposed algorithm has the property of recursive feasibility and ensures the stability of the closed-loop system. The effectiveness of the proposed method is demonstrated by applying it to a high-fidelity <b>simulation</b> of a dual-drive industrial laser machine. The results show that the contouring error is successfully bounded within the given tolerance.

{{</citation>}}


### (5/6 | 207/266) Optimal robust exact first-order differentiators with Lipschitz continuous output (Rodrigo Aldana-Lopez et al., 2024)

{{<citation>}}

Rodrigo Aldana-Lopez, Richard Seeber, Hernan Haimovich, David Gomez-Gutierrez. (2024)  
**Optimal robust exact first-order differentiators with Lipschitz continuous output**
<br/>
<button class="copy-to-clipboard" title="Optimal robust exact first-order differentiators with Lipschitz continuous output" index=207>
  <span class="copy-to-clipboard-item">Copy Title<span>
</button>
<div class="toast toast-copied toast-index-207 align-items-center text-bg-secondary border-0 position-absolute top-0 end-0" role="alert" aria-live="assertive" aria-atomic="true">
  <div class="d-flex">
    <div class="toast-body">
      Copied!
    </div>
  </div>
</div>

---
Primary Category: eess.SY  
Categories: cs-SY, eess-SY, eess.SY  
Keyword Score: 10  
Keywords: Continuous Time, Continuous Time  
<a type="button" class="btn btn-outline-primary" href="http://arxiv.org/abs/2404.05863v1" target="_blank" >Paper Link</a>
<button type="button" class="btn btn-outline-primary download-pdf" url="https://arxiv.org/pdf/2404.05863v1.pdf" filename="2404.05863v1.pdf">Download PDF</button>

---


**ABSTRACT**  
The signal differentiation problem involves the development of algorithms that allow to recover a signal's derivatives from noisy measurements. This paper develops a first-order differentiator with the following combination of properties: robustness to measurement noise, exactness in the absence of noise, optimal worst-case differentiation error, and Lipschitz <b>continuous</b> <b>output</b> where the output's Lipschitz constant is a tunable parameter. This combination of advantageous properties is not shared by any existing differentiator. Both <b>continuous-time</b> <b>and</b> sample-based versions of the differentiator are developed and theoretical guarantees are established for both. The <b>continuous-time</b> <b>version</b> of the differentiator consists in a regularized and sliding-mode-filtered linear adaptive differentiator. The sample-based, implementable version is then obtained through appropriate discretization. An illustrative example is provided to highlight the features of the developed differentiator.

{{</citation>}}


### (6/6 | 208/266) Optimized LinDistFlow for High-Fidelity Power Flow Modeling of Distribution Networks (Babak Taheri et al., 2024)

{{<citation>}}

Babak Taheri, Rahul K. Gupta, Daniel K. Molzahn. (2024)  
**Optimized LinDistFlow for High-Fidelity Power Flow Modeling of Distribution Networks**
<br/>
<button class="copy-to-clipboard" title="Optimized LinDistFlow for High-Fidelity Power Flow Modeling of Distribution Networks" index=208>
  <span class="copy-to-clipboard-item">Copy Title<span>
</button>
<div class="toast toast-copied toast-index-208 align-items-center text-bg-secondary border-0 position-absolute top-0 end-0" role="alert" aria-live="assertive" aria-atomic="true">
  <div class="d-flex">
    <div class="toast-body">
      Copied!
    </div>
  </div>
</div>

---
Primary Category: eess.SY  
Categories: cs-SY, eess-SY, eess.SY  
Keyword Score: 10  
Keywords: Fine-tuning  
<a type="button" class="btn btn-outline-primary" href="http://arxiv.org/abs/2404.05125v1" target="_blank" >Paper Link</a>
<button type="button" class="btn btn-outline-primary download-pdf" url="https://arxiv.org/pdf/2404.05125v1.pdf" filename="2404.05125v1.pdf">Download PDF</button>

---


**ABSTRACT**  
The DistFlow model accurately represents power flows in distribution systems, but the model's nonlinearities result in computational challenges for many optimization applications. Accordingly, a linear approximation known as LinDistFlow is commonly employed. This paper introduces an algorithm for enhancing the accuracy of the LinDistFlow approximation, with the goal of aligning the outputs more closely with those from the nonlinear DistFlow model. Using sensitivity information, our algorithm optimizes the LinDistFlow approximation's coefficient and bias parameters to minimize discrepancies in predictions of voltage magnitudes relative to the nonlinear DistFlow model. The algorithm employs the Truncated Newton Conjugate-Gradient (TNC) optimization method to <b>fine-tune</b> coefficients and bias parameters during an offline training phase in order to improve the LinDistFlow approximation's accuracy in optimization applications. This improves the model's effectiveness across various system scenarios, leading to a marked improvement in predictive accuracy. Numerical results underscore the algorithm's efficacy, showcasing accuracy improvements in $L_{1}$-norm and $L_{\infty}$-norm losses of up to $92\%$ and $88\%$, respectively, relative to the traditional LinDistFlow model. We assess how the optimized parameters perform under changes in the network topology and also validate the optimized LinDistFlow approximation's efficacy in a hosting capacity optimization problem.

{{</citation>}}


## stat.ML (2)



### (1/2 | 209/266) Flexible Fairness Learning via Inverse Conditional Permutation (Yuheng Lai et al., 2024)

{{<citation>}}

Yuheng Lai, Leying Guan. (2024)  
**Flexible Fairness Learning via Inverse Conditional Permutation**
<br/>
<button class="copy-to-clipboard" title="Flexible Fairness Learning via Inverse Conditional Permutation" index=209>
  <span class="copy-to-clipboard-item">Copy Title<span>
</button>
<div class="toast toast-copied toast-index-209 align-items-center text-bg-secondary border-0 position-absolute top-0 end-0" role="alert" aria-live="assertive" aria-atomic="true">
  <div class="d-flex">
    <div class="toast-body">
      Copied!
    </div>
  </div>
</div>

---
Primary Category: stat.ML  
Categories: cs-CY, cs-LG, stat-ML, stat.ML  
Keyword Score: 40  
Keywords: Adversarial Learning, Fairness, Simulation, Simulator  
<a type="button" class="btn btn-outline-primary" href="http://arxiv.org/abs/2404.05678v2" target="_blank" >Paper Link</a>
<button type="button" class="btn btn-outline-primary download-pdf" url="https://arxiv.org/pdf/2404.05678v2.pdf" filename="2404.05678v2.pdf">Download PDF</button>

---


**ABSTRACT**  
Equalized odds, as a popular notion of algorithmic <b>fairness,</b> aims to ensure that sensitive variables, such as race and gender, do not unfairly influence the algorithm prediction when conditioning on the true outcome. Despite rapid advancements, most of the current research focuses on the violation of equalized odds caused by one sensitive attribute, leaving the challenge of simultaneously accounting for multiple attributes under-addressed. We address this gap by introducing a <b>fairness</b> learning approach that integrates <b>adversarial</b> <b>learning</b> with a novel inverse conditional permutation. This approach effectively and flexibly handles multiple sensitive attributes, potentially of mixed data types. The efficacy and flexibility of our method are demonstrated through both <b>simulation</b> studies and empirical analysis of real-world datasets.

{{</citation>}}


### (2/2 | 210/266) Just Wing It: Optimal Estimation of Missing Mass in a Markovian Sequence (Ashwin Pananjady et al., 2024)

{{<citation>}}

Ashwin Pananjady, Vidya Muthukumar, Andrew Thangaraj. (2024)  
**Just Wing It: Optimal Estimation of Missing Mass in a Markovian Sequence**
<br/>
<button class="copy-to-clipboard" title="Just Wing It: Optimal Estimation of Missing Mass in a Markovian Sequence" index=210>
  <span class="copy-to-clipboard-item">Copy Title<span>
</button>
<div class="toast toast-copied toast-index-210 align-items-center text-bg-secondary border-0 position-absolute top-0 end-0" role="alert" aria-live="assertive" aria-atomic="true">
  <div class="d-flex">
    <div class="toast-body">
      Copied!
    </div>
  </div>
</div>

---
Primary Category: stat.ML  
Categories: cs-IT, cs-LG, math-IT, math-PR, math-ST, stat-ML, stat-TH, stat.ML  
Keyword Score: 30  
Keywords: Discrete Time, Discrete Time, Simulation, Simulator  
<a type="button" class="btn btn-outline-primary" href="http://arxiv.org/abs/2404.05819v1" target="_blank" >Paper Link</a>
<button type="button" class="btn btn-outline-primary download-pdf" url="https://arxiv.org/pdf/2404.05819v1.pdf" filename="2404.05819v1.pdf">Download PDF</button>

---


**ABSTRACT**  
We study the problem of estimating the stationary mass -- also called the unigram mass -- that is missing from a single trajectory of a <b>discrete-time,</b> <b>ergodic</b> Markov chain. This problem has several applications -- for example, estimating the stationary missing mass is critical for accurately smoothing probability estimates in sequence models. While the classical Good--Turing estimator from the 1950s has appealing properties for i.i.d. data, it is known to be biased in the Markov setting, and other heuristic estimators do not come equipped with guarantees. Operating in the general setting in which the size of the state space may be much larger than the length $n$ of the trajectory, we develop a linear-runtime estimator called \emph{Windowed Good--Turing} (\textsc{WingIt}) and show that its risk decays as $\widetilde{\mathcal{O}}(\mathsf{T_{mix}}/n)$, where $\mathsf{T_{mix}}$ denotes the mixing time of the chain in total variation distance. Notably, this rate is independent of the size of the state space and minimax-optimal up to a logarithmic factor in $n / \mathsf{T_{mix}}$. We also present a bound on the variance of the missing mass random variable, which may be of independent interest. We extend our estimator to approximate the stationary mass placed on elements occurring with small frequency in $X^n$. Finally, we demonstrate the efficacy of our estimators both in <b>simulations</b> on canonical chains and on sequences constructed from a popular natural language corpus.

{{</citation>}}


## cs.HC (6)



### (1/6 | 211/266) Unlocking Adaptive User Experience with Generative AI (Yutan Huang et al., 2024)

{{<citation>}}

Yutan Huang, Tanjila Kanij, Anuradha Madugalla, Shruti Mahajan, Chetan Arora, John Grundy. (2024)  
**Unlocking Adaptive User Experience with Generative AI**
<br/>
<button class="copy-to-clipboard" title="Unlocking Adaptive User Experience with Generative AI" index=211>
  <span class="copy-to-clipboard-item">Copy Title<span>
</button>
<div class="toast toast-copied toast-index-211 align-items-center text-bg-secondary border-0 position-absolute top-0 end-0" role="alert" aria-live="assertive" aria-atomic="true">
  <div class="d-flex">
    <div class="toast-body">
      Copied!
    </div>
  </div>
</div>

---
Primary Category: cs.HC  
Categories: cs-HC, cs-SE, cs.HC  
Keyword Score: 40  
Keywords: Generative AI, ChatGPT, Large Language Model, Large Language Model  
<a type="button" class="btn btn-outline-primary" href="http://arxiv.org/abs/2404.05442v1" target="_blank" >Paper Link</a>
<button type="button" class="btn btn-outline-primary download-pdf" url="https://arxiv.org/pdf/2404.05442v1.pdf" filename="2404.05442v1.pdf">Download PDF</button>

---


**ABSTRACT**  
Developing user-centred applications that address diverse user needs requires rigorous user research. This is time, effort and cost-consuming. With the recent rise of <b>generative</b> <b>AI</b> techniques based on <b>Large</b> <b>Language</b> <b>Models</b> <b>(LLMs),</b> there is a possibility that these powerful tools can be used to develop adaptive interfaces. This paper presents a novel approach to develop user personas and adaptive interface candidates for a specific domain using <b>ChatGPT.</b> We develop user personas and adaptive interfaces using both <b>ChatGPT</b> and a traditional manual process and compare these outcomes. To obtain data for the personas we collected data from 37 survey participants and 4 interviews in collaboration with a not-for-profit organisation. The comparison of <b>ChatGPT</b> generated content and manual content indicates promising results that encourage using <b>LLMs</b> in the adaptive interfaces design process.

{{</citation>}}


### (2/6 | 212/266) Evaluation of an LLM in Identifying Logical Fallacies: A Call for Rigor When Adopting LLMs in HCI Research (Gionnieve Lim et al., 2024)

{{<citation>}}

Gionnieve Lim, Simon T. Perrault. (2024)  
**Evaluation of an LLM in Identifying Logical Fallacies: A Call for Rigor When Adopting LLMs in HCI Research**
<br/>
<button class="copy-to-clipboard" title="Evaluation of an LLM in Identifying Logical Fallacies: A Call for Rigor When Adopting LLMs in HCI Research" index=212>
  <span class="copy-to-clipboard-item">Copy Title<span>
</button>
<div class="toast toast-copied toast-index-212 align-items-center text-bg-secondary border-0 position-absolute top-0 end-0" role="alert" aria-live="assertive" aria-atomic="true">
  <div class="d-flex">
    <div class="toast-body">
      Copied!
    </div>
  </div>
</div>

---
Primary Category: cs.HC  
Categories: cs-AI, cs-HC, cs.HC  
Keyword Score: 30  
Keywords: GPT, GPT-4, Large Language Model  
<a type="button" class="btn btn-outline-primary" href="http://arxiv.org/abs/2404.05213v1" target="_blank" >Paper Link</a>
<button type="button" class="btn btn-outline-primary download-pdf" url="https://arxiv.org/pdf/2404.05213v1.pdf" filename="2404.05213v1.pdf">Download PDF</button>

---


**ABSTRACT**  
There is increasing interest in the adoption of <b>LLMs</b> in HCI research. However, <b>LLMs</b> may often be regarded as a panacea because of their powerful capabilities with an accompanying oversight on whether they are suitable for their intended tasks. We contend that <b>LLMs</b> should be adopted in a critical manner following rigorous evaluation. Accordingly, we present the evaluation of an <b>LLM</b> in identifying logical fallacies that will form part of a digital misinformation intervention. By comparing to a labeled dataset, we found that <b>GPT-4</b> achieves an accuracy of 0.79, and for our intended use case that excludes invalid or unidentified instances, an accuracy of 0.90. This gives us the confidence to proceed with the application of the <b>LLM</b> while keeping in mind the areas where it still falls short. The paper describes our evaluation approach, results and reflections on the use of the <b>LLM</b> for our intended task.

{{</citation>}}


### (3/6 | 213/266) Fair Machine Guidance to Enhance Fair Decision Making in Biased People (Mingzhe Yang et al., 2024)

{{<citation>}}

Mingzhe Yang, Hiromi Arai, Naomi Yamashita, Yukino Baba. (2024)  
**Fair Machine Guidance to Enhance Fair Decision Making in Biased People**
<br/>
<button class="copy-to-clipboard" title="Fair Machine Guidance to Enhance Fair Decision Making in Biased People" index=213>
  <span class="copy-to-clipboard-item">Copy Title<span>
</button>
<div class="toast toast-copied toast-index-213 align-items-center text-bg-secondary border-0 position-absolute top-0 end-0" role="alert" aria-live="assertive" aria-atomic="true">
  <div class="d-flex">
    <div class="toast-body">
      Copied!
    </div>
  </div>
</div>

---
Primary Category: cs.HC  
Categories: cs-HC, cs.HC  
Keyword Score: 20  
Keywords: Fairness, Prompt  
<a type="button" class="btn btn-outline-primary" href="http://arxiv.org/abs/2404.05228v1" target="_blank" >Paper Link</a>
<button type="button" class="btn btn-outline-primary download-pdf" url="https://arxiv.org/pdf/2404.05228v1.pdf" filename="2404.05228v1.pdf">Download PDF</button>

---


**ABSTRACT**  
Teaching unbiased decision-making is crucial for addressing biased decision-making in daily life. Although both raising awareness of personal biases and providing guidance on unbiased decision-making are essential, the latter topics remains under-researched. In this study, we developed and evaluated an AI system aimed at educating individuals on making unbiased decisions using <b>fairness-aware</b> machine learning. In a between-subjects experimental design, 99 participants who were prone to bias performed personal assessment tasks. They were divided into two groups: a) those who received AI guidance for fair decision-making before the task and b) those who received no such guidance but were informed of their biases. The results suggest that although several participants doubted the <b>fairness</b> of the AI system, fair machine guidance <b>prompted</b> them to reassess their views regarding <b>fairness,</b> reflect on their biases, and modify their decision-making criteria. Our findings provide insights into the design of AI systems for guiding fair decision-making in humans.

{{</citation>}}


### (4/6 | 214/266) With or Without Permission: Site-Specific Augmented Reality for Social Justice CHI 2024 Workshop Proceedings (Rafael M. L. Silva et al., 2024)

{{<citation>}}

Rafael M. L. Silva, Ana María Cárdenas Gasca, Joshua A. Fisher, Erica Principe Cruz, Cinthya Jauregui, Amy Lueck, Fannie Liu, Andrés Monroy-Hernández, Kai Lukoff. (2024)  
**With or Without Permission: Site-Specific Augmented Reality for Social Justice CHI 2024 Workshop Proceedings**
<br/>
<button class="copy-to-clipboard" title="With or Without Permission: Site-Specific Augmented Reality for Social Justice CHI 2024 Workshop Proceedings" index=214>
  <span class="copy-to-clipboard-item">Copy Title<span>
</button>
<div class="toast toast-copied toast-index-214 align-items-center text-bg-secondary border-0 position-absolute top-0 end-0" role="alert" aria-live="assertive" aria-atomic="true">
  <div class="d-flex">
    <div class="toast-body">
      Copied!
    </div>
  </div>
</div>

---
Primary Category: cs.HC  
Categories: cs-HC, cs.HC  
Keyword Score: 10  
Keywords: Augmented Reality (AR)  
<a type="button" class="btn btn-outline-primary" href="http://arxiv.org/abs/2404.05889v2" target="_blank" >Paper Link</a>
<button type="button" class="btn btn-outline-primary download-pdf" url="https://arxiv.org/pdf/2404.05889v2.pdf" filename="2404.05889v2.pdf">Download PDF</button>

---


**ABSTRACT**  
This volume represents the proceedings of With or Without Permission: Site-Specific <b>Augmented</b> <b>Reality</b> for Social Justice CHI 2024 workshop.

{{</citation>}}


### (5/6 | 215/266) Human-Machine Interaction in Automated Vehicles: Reducing Voluntary Driver Intervention (Xinzhi Zhong et al., 2024)

{{<citation>}}

Xinzhi Zhong, Yang Zhou, Varshini Kamaraj, Zhenhao Zhou, Wissam Kontar, Dan Negrut, John D. Lee, Soyoung Ahn. (2024)  
**Human-Machine Interaction in Automated Vehicles: Reducing Voluntary Driver Intervention**
<br/>
<button class="copy-to-clipboard" title="Human-Machine Interaction in Automated Vehicles: Reducing Voluntary Driver Intervention" index=215>
  <span class="copy-to-clipboard-item">Copy Title<span>
</button>
<div class="toast toast-copied toast-index-215 align-items-center text-bg-secondary border-0 position-absolute top-0 end-0" role="alert" aria-live="assertive" aria-atomic="true">
  <div class="d-flex">
    <div class="toast-body">
      Copied!
    </div>
  </div>
</div>

---
Primary Category: cs.HC  
Categories: cs-HC, cs-SY, cs.HC, eess-SY  
Keyword Score: 10  
Keywords: Reinforcement Learning  
<a type="button" class="btn btn-outline-primary" href="http://arxiv.org/abs/2404.05832v1" target="_blank" >Paper Link</a>
<button type="button" class="btn btn-outline-primary download-pdf" url="https://arxiv.org/pdf/2404.05832v1.pdf" filename="2404.05832v1.pdf">Download PDF</button>

---


**ABSTRACT**  
This paper develops a novel car-following control method to reduce voluntary driver interventions and improve traffic stability in Automated Vehicles (AVs). Through a combination of experimental and empirical analysis, we show how voluntary driver interventions can instigate substantial traffic disturbances that are amplified along the traffic upstream. Motivated by these findings, we present a framework for driver intervention based on evidence accumulation (EA), which describes the evolution of the driver's distrust in automation, ultimately resulting in intervention. Informed through the EA framework, we propose a deep <b>reinforcement</b> <b>learning</b> (DRL)-based car-following control for AVs that is strategically designed to mitigate unnecessary driver intervention and improve traffic stability. Numerical experiments are conducted to demonstrate the effectiveness of the proposed control model.

{{</citation>}}


### (6/6 | 216/266) ClusterRadar: an Interactive Web-Tool for the Multi-Method Exploration of Spatial Clusters Over Time (Lee Mason et al., 2024)

{{<citation>}}

Lee Mason, Blánaid Hicks, Jonas S. Almeida. (2024)  
**ClusterRadar: an Interactive Web-Tool for the Multi-Method Exploration of Spatial Clusters Over Time**
<br/>
<button class="copy-to-clipboard" title="ClusterRadar: an Interactive Web-Tool for the Multi-Method Exploration of Spatial Clusters Over Time" index=216>
  <span class="copy-to-clipboard-item">Copy Title<span>
</button>
<div class="toast toast-copied toast-index-216 align-items-center text-bg-secondary border-0 position-absolute top-0 end-0" role="alert" aria-live="assertive" aria-atomic="true">
  <div class="d-flex">
    <div class="toast-body">
      Copied!
    </div>
  </div>
</div>

---
Primary Category: cs.HC  
Categories: cs-HC, cs.HC  
Keyword Score: 3  
Keywords: Clustering  
<a type="button" class="btn btn-outline-primary" href="http://arxiv.org/abs/2404.05897v1" target="_blank" >Paper Link</a>
<button type="button" class="btn btn-outline-primary download-pdf" url="https://arxiv.org/pdf/2404.05897v1.pdf" filename="2404.05897v1.pdf">Download PDF</button>

---


**ABSTRACT**  
Spatial cluster analysis, the detection of localized patterns of similarity in geospatial data, has a wide-range of applications for scientific discovery and practical decision making. One way to detect spatial clusters is by using local indicators of spatial association, such as Local Moran's I or Getis-Ord Gi*. However, different indicators tend to produce substantially different results due to their distinct operational characteristics. Choosing a suitable method or comparing results from multiple methods is a complex task. Furthermore, spatial clusters are dynamic and it is often useful to track their evolution over time, which adds an additional layer of complexity. ClusterRadar is a web-tool designed to address these analytical challenges. The tool allows users to easily perform spatial <b>clustering</b> and analyze the results in an interactive environment, uniquely prioritizing temporal analysis and the comparison of multiple methods. The tool's interactive dashboard presents several visualizations, each offering a distinct perspective of the temporal and methodological aspects of the spatial <b>clustering</b> results. ClusterRadar has several features designed to maximize its utility to a broad user-base, including support for various geospatial formats, and a fully in-browser execution environment to preserve the privacy of sensitive data. Feedback from a varied set of researchers suggests ClusterRadar's potential for enhancing the temporal analysis of spatial clusters.

{{</citation>}}


## cs.CR (10)



### (1/10 | 217/266) Unbridled Icarus: A Survey of the Potential Perils of Image Inputs in Multimodal Large Language Model Security (Yihe Fan et al., 2024)

{{<citation>}}

Yihe Fan, Yuxin Cao, Ziyu Zhao, Ziyao Liu, Shaofeng Li. (2024)  
**Unbridled Icarus: A Survey of the Potential Perils of Image Inputs in Multimodal Large Language Model Security**
<br/>
<button class="copy-to-clipboard" title="Unbridled Icarus: A Survey of the Potential Perils of Image Inputs in Multimodal Large Language Model Security" index=217>
  <span class="copy-to-clipboard-item">Copy Title<span>
</button>
<div class="toast toast-copied toast-index-217 align-items-center text-bg-secondary border-0 position-absolute top-0 end-0" role="alert" aria-live="assertive" aria-atomic="true">
  <div class="d-flex">
    <div class="toast-body">
      Copied!
    </div>
  </div>
</div>

---
Primary Category: cs.CR  
Categories: cs-CR, cs-CV, cs.CR  
Keyword Score: 36  
Keywords: Multi-modal, Multi-modal, Large Language Model, Summarization, Security  
<a type="button" class="btn btn-outline-primary" href="http://arxiv.org/abs/2404.05264v1" target="_blank" >Paper Link</a>
<button type="button" class="btn btn-outline-primary download-pdf" url="https://arxiv.org/pdf/2404.05264v1.pdf" filename="2404.05264v1.pdf">Download PDF</button>

---


**ABSTRACT**  
<b>Multimodal</b> <b>Large</b> <b>Language</b> <b>Models</b> (MLLMs) demonstrate remarkable capabilities that increasingly influence various aspects of our daily lives, constantly defining the new boundary of Artificial General Intelligence (AGI). Image modalities, enriched with profound semantic information and a more continuous mathematical nature compared to other modalities, greatly enhance the functionalities of MLLMs when integrated. However, this integration serves as a double-edged sword, providing attackers with expansive vulnerabilities to exploit for highly covert and harmful attacks. The pursuit of reliable AI systems like powerful MLLMs has emerged as a pivotal area of contemporary research. In this paper, we endeavor to demostrate the multifaceted risks associated with the incorporation of image modalities into MLLMs. Initially, we delineate the foundational components and training processes of MLLMs. Subsequently, we construct a threat model, outlining the <b>security</b> vulnerabilities intrinsic to MLLMs. Moreover, we analyze and <b>summarize</b> existing scholarly discourses on MLLMs' attack and defense mechanisms, culminating in suggestions for the future research on MLLM <b>security.</b> Through this comprehensive analysis, we aim to deepen the academic understanding of MLLM <b>security</b> challenges and propel forward the development of trustworthy MLLM systems.

{{</citation>}}


### (2/10 | 218/266) Have You Merged My Model? On The Robustness of Large Language Model IP Protection Methods Against Model Merging (Tianshuo Cong et al., 2024)

{{<citation>}}

Tianshuo Cong, Delong Ran, Zesen Liu, Xinlei He, Jinyuan Liu, Yichen Gong, Qi Li, Anyu Wang, Xiaoyun Wang. (2024)  
**Have You Merged My Model? On The Robustness of Large Language Model IP Protection Methods Against Model Merging**
<br/>
<button class="copy-to-clipboard" title="Have You Merged My Model? On The Robustness of Large Language Model IP Protection Methods Against Model Merging" index=218>
  <span class="copy-to-clipboard-item">Copy Title<span>
</button>
<div class="toast toast-copied toast-index-218 align-items-center text-bg-secondary border-0 position-absolute top-0 end-0" role="alert" aria-live="assertive" aria-atomic="true">
  <div class="d-flex">
    <div class="toast-body">
      Copied!
    </div>
  </div>
</div>

---
Primary Category: cs.CR  
Categories: cs-AI, cs-CL, cs-CR, cs.CR  
Keyword Score: 30  
Keywords: Quantization, Large Language Model, Large Language Model  
<a type="button" class="btn btn-outline-primary" href="http://arxiv.org/abs/2404.05188v1" target="_blank" >Paper Link</a>
<button type="button" class="btn btn-outline-primary download-pdf" url="https://arxiv.org/pdf/2404.05188v1.pdf" filename="2404.05188v1.pdf">Download PDF</button>

---


**ABSTRACT**  
Model merging is a promising lightweight model empowerment technique that does not rely on expensive computing devices (e.g., GPUs) or require the collection of specific training data. Instead, it involves editing different upstream model parameters to absorb their downstream task capabilities. However, uncertified model merging can infringe upon the Intellectual Property (IP) rights of the original upstream models. In this paper, we conduct the first study on the robustness of IP protection methods in model merging scenarios. We investigate two state-of-the-art IP protection techniques: <b>Quantization</b> Watermarking and Instructional Fingerprint, along with various advanced model merging technologies, such as Task Arithmetic, TIES-MERGING, and so on. Experimental results indicate that current <b>Large</b> <b>Language</b> <b>Model</b> <b>(LLM)</b> watermarking techniques cannot survive in the merged models, whereas model fingerprinting techniques can. Our research aims to highlight that model merging should be an indispensable consideration in the robustness assessment of model IP protection techniques, thereby promoting the healthy development of the open-source <b>LLM</b> community.

{{</citation>}}


### (3/10 | 219/266) Enabling Privacy-Preserving Cyber Threat Detection with Federated Learning (Yu Bi et al., 2024)

{{<citation>}}

Yu Bi, Yekai Li, Xuan Feng, Xianghang Mi. (2024)  
**Enabling Privacy-Preserving Cyber Threat Detection with Federated Learning**
<br/>
<button class="copy-to-clipboard" title="Enabling Privacy-Preserving Cyber Threat Detection with Federated Learning" index=219>
  <span class="copy-to-clipboard-item">Copy Title<span>
</button>
<div class="toast toast-copied toast-index-219 align-items-center text-bg-secondary border-0 position-absolute top-0 end-0" role="alert" aria-live="assertive" aria-atomic="true">
  <div class="d-flex">
    <div class="toast-body">
      Copied!
    </div>
  </div>
</div>

---
Primary Category: cs.CR  
Categories: cs-CR, cs.CR  
Keyword Score: 30  
Keywords: Federated Learning, Malware, Security  
<a type="button" class="btn btn-outline-primary" href="http://arxiv.org/abs/2404.05130v1" target="_blank" >Paper Link</a>
<button type="button" class="btn btn-outline-primary download-pdf" url="https://arxiv.org/pdf/2404.05130v1.pdf" filename="2404.05130v1.pdf">Download PDF</button>

---


**ABSTRACT**  
Despite achieving good performance and wide adoption, machine learning based <b>security</b> detection models (e.g., <b>malware</b> classifiers) are subject to concept drift and evasive evolution of attackers, which renders up-to-date threat data as a necessity. However, due to enforcement of various privacy protection regulations (e.g., GDPR), it is becoming increasingly challenging or even prohibitive for <b>security</b> vendors to collect individual-relevant and privacy-sensitive threat datasets, e.g., SMS spam/non-spam messages from mobile devices. To address such obstacles, this study systematically profiles the (in)feasibility of <b>federated</b> <b>learning</b> for privacy-preserving cyber threat detection in terms of effectiveness, byzantine resilience, and efficiency. This is made possible by the build-up of multiple threat datasets and threat detection models, and more importantly, the design of realistic and <b>security-specific</b> experiments. We evaluate FL on two representative threat detection tasks, namely SMS spam detection and Android <b>malware</b> detection. It shows that FL-trained detection models can achieve a performance that is comparable to centrally trained counterparts. Also, most non-IID data distributions have either minor or negligible impact on the model performance, while a label-based non-IID distribution of a high extent can incur non-negligible fluctuation and delay in FL training. Then, under a realistic threat model, FL turns out to be adversary-resistant to attacks of both data poisoning and model poisoning. Particularly, the attacking impact of a practical data poisoning attack is no more than 0.14\% loss in model accuracy. Regarding FL efficiency, a bootstrapping strategy turns out to be effective to mitigate the training delay as observed in label-based non-IID scenarios.

{{</citation>}}


### (4/10 | 220/266) AI-Enabled System for Efficient and Effective Cyber Incident Detection and Response in Cloud Environments (Mohammed Ashfaaq M. Farzaan et al., 2024)

{{<citation>}}

Mohammed Ashfaaq M. Farzaan, Mohamed Chahine Ghanem, Ayman El-Hajjar, Deepthi N. Ratnayake. (2024)  
**AI-Enabled System for Efficient and Effective Cyber Incident Detection and Response in Cloud Environments**
<br/>
<button class="copy-to-clipboard" title="AI-Enabled System for Efficient and Effective Cyber Incident Detection and Response in Cloud Environments" index=220>
  <span class="copy-to-clipboard-item">Copy Title<span>
</button>
<div class="toast toast-copied toast-index-220 align-items-center text-bg-secondary border-0 position-absolute top-0 end-0" role="alert" aria-live="assertive" aria-atomic="true">
  <div class="d-flex">
    <div class="toast-body">
      Copied!
    </div>
  </div>
</div>

---
Primary Category: cs.CR  
Categories: cs-CR, cs-ET, cs-NI, cs.CR  
Keyword Score: 20  
Keywords: Malware, Security  
<a type="button" class="btn btn-outline-primary" href="http://arxiv.org/abs/2404.05602v2" target="_blank" >Paper Link</a>
<button type="button" class="btn btn-outline-primary download-pdf" url="https://arxiv.org/pdf/2404.05602v2.pdf" filename="2404.05602v2.pdf">Download PDF</button>

---


**ABSTRACT**  
The escalating sophistication and volume of cyber threats in cloud environments necessitate a paradigm shift in strategies. Recognising the need for an automated and precise response to cyber threats, this research explores the application of AI and ML and proposes an AI-powered cyber incident response system for cloud environments. This system, encompassing Network Traffic Classification, Web Intrusion Detection, and post-incident <b>Malware</b> Analysis (built as a Flask application), achieves seamless integration across platforms like Google Cloud and Microsoft Azure. The findings from this research highlight the effectiveness of the Random Forest model, achieving an accuracy of 90% for the Network Traffic Classifier and 96% for the <b>Malware</b> Analysis Dual Model application. Our research highlights the strengths of AI-powered cyber <b>security.</b> The Random Forest model excels at classifying cyber threats, offering an efficient and robust solution. Deep learning models significantly improve accuracy, and their resource demands can be managed using cloud-based TPUs and GPUs. Cloud environments themselves provide a perfect platform for hosting these AI/ML systems, while container technology ensures both efficiency and scalability. These findings demonstrate the contribution of the AI-led system in guaranteeing a robust and scalable cyber incident response solution in the cloud.

{{</citation>}}


### (5/10 | 221/266) Privacy and Security of Women's Reproductive Health Apps in a Changing Legal Landscape (Shalini Saini et al., 2024)

{{<citation>}}

Shalini Saini, Nitesh Saxena. (2024)  
**Privacy and Security of Women's Reproductive Health Apps in a Changing Legal Landscape**
<br/>
<button class="copy-to-clipboard" title="Privacy and Security of Women's Reproductive Health Apps in a Changing Legal Landscape" index=221>
  <span class="copy-to-clipboard-item">Copy Title<span>
</button>
<div class="toast toast-copied toast-index-221 align-items-center text-bg-secondary border-0 position-absolute top-0 end-0" role="alert" aria-live="assertive" aria-atomic="true">
  <div class="d-flex">
    <div class="toast-body">
      Copied!
    </div>
  </div>
</div>

---
Primary Category: cs.CR  
Categories: cs-CR, cs-ET, cs.CR  
Keyword Score: 10  
Keywords: Security  
<a type="button" class="btn btn-outline-primary" href="http://arxiv.org/abs/2404.05876v1" target="_blank" >Paper Link</a>
<button type="button" class="btn btn-outline-primary download-pdf" url="https://arxiv.org/pdf/2404.05876v1.pdf" filename="2404.05876v1.pdf">Download PDF</button>

---


**ABSTRACT**  
FemTech, a rising trend in mobile apps, empowers women to digitally manage their health and family planning. However, privacy and <b>security</b> vulnerabilities in period-tracking and fertility-monitoring apps present significant risks, such as unintended pregnancies and legal consequences. Our approach involves manual observations of privacy policies and app permissions, along with dynamic and static analysis using multiple evaluation frameworks. Our research reveals that many of these apps gather personally identifiable information (PII) and sensitive healthcare data. Furthermore, our analysis identifies that 61% of the code vulnerabilities found in the apps are classified under the top-ten Open Web Application <b>Security</b> Project (OWASP) vulnerabilities. Our research emphasizes the significance of tackling the privacy and <b>security</b> vulnerabilities present in period-tracking and fertility-monitoring mobile apps. By highlighting these crucial risks, we aim to initiate a vital discussion and advocate for increased accountability and transparency of digital tools for women's health. We encourage the industry to prioritize user privacy and <b>security,</b> ultimately promoting a safer and more secure environment for women's health management.

{{</citation>}}


### (6/10 | 222/266) Exploiting CPU Clock Modulation for Covert Communication Channel (Shariful Alam et al., 2024)

{{<citation>}}

Shariful Alam, Jidong Xiao, Nasir U. Eisty. (2024)  
**Exploiting CPU Clock Modulation for Covert Communication Channel**
<br/>
<button class="copy-to-clipboard" title="Exploiting CPU Clock Modulation for Covert Communication Channel" index=222>
  <span class="copy-to-clipboard-item">Copy Title<span>
</button>
<div class="toast toast-copied toast-index-222 align-items-center text-bg-secondary border-0 position-absolute top-0 end-0" role="alert" aria-live="assertive" aria-atomic="true">
  <div class="d-flex">
    <div class="toast-body">
      Copied!
    </div>
  </div>
</div>

---
Primary Category: cs.CR  
Categories: cs-CR, cs.CR  
Keyword Score: 10  
Keywords: Security  
<a type="button" class="btn btn-outline-primary" href="http://arxiv.org/abs/2404.05823v1" target="_blank" >Paper Link</a>
<button type="button" class="btn btn-outline-primary download-pdf" url="https://arxiv.org/pdf/2404.05823v1.pdf" filename="2404.05823v1.pdf">Download PDF</button>

---


**ABSTRACT**  
Covert channel attacks represent a significant threat to system <b>security,</b> leveraging shared resources to clandestinely transmit information from highly secure systems, thereby violating the system's <b>security</b> policies. These attacks exploit shared resources as communication channels, necessitating resource partitioning and isolation techniques as countermeasures. However, mitigating attacks exploiting modern processors' hardware features to leak information is challenging because successful attacks can conceal the channel's existence. In this paper, we unveil a novel covert channel exploiting the duty cycle modulation feature of modern x86 processors. Specifically, we illustrate how two collaborating processes, a sender and a receiver can manipulate this feature to transmit sensitive information surreptitiously. Our live system implementation demonstrates that this covert channel can achieve a data transfer rate of up to 55.24 bits per second.

{{</citation>}}


### (7/10 | 223/266) Case Study: Neural Network Malware Detection Verification for Feature and Image Datasets (Preston K. Robinette et al., 2024)

{{<citation>}}

Preston K. Robinette, Diego Manzanas Lopez, Serena Serbinowska, Kevin Leach, Taylor T. Johnson. (2024)  
**Case Study: Neural Network Malware Detection Verification for Feature and Image Datasets**
<br/>
<button class="copy-to-clipboard" title="Case Study: Neural Network Malware Detection Verification for Feature and Image Datasets" index=223>
  <span class="copy-to-clipboard-item">Copy Title<span>
</button>
<div class="toast toast-copied toast-index-223 align-items-center text-bg-secondary border-0 position-absolute top-0 end-0" role="alert" aria-live="assertive" aria-atomic="true">
  <div class="d-flex">
    <div class="toast-body">
      Copied!
    </div>
  </div>
</div>

---
Primary Category: cs.CR  
Categories: cs-CR, cs.CR  
Keyword Score: 10  
Keywords: Malware  
<a type="button" class="btn btn-outline-primary" href="http://arxiv.org/abs/2404.05703v1" target="_blank" >Paper Link</a>
<button type="button" class="btn btn-outline-primary download-pdf" url="https://arxiv.org/pdf/2404.05703v1.pdf" filename="2404.05703v1.pdf">Download PDF</button>

---


**ABSTRACT**  
<b>Malware,</b> or software designed with harmful intent, is an ever-evolving threat that can have drastic effects on both individuals and institutions. Neural network <b>malware</b> classification systems are key tools for combating these threats but are vulnerable to adversarial machine learning attacks. These attacks perturb input data to cause misclassification, bypassing protective systems. Existing defenses often rely on enhancing the training process, thereby increasing the model's robustness to these perturbations, which is quantified using verification. While training improvements are necessary, we propose focusing on the verification process used to evaluate improvements to training. As such, we present a case study that evaluates a novel verification domain that will help to ensure tangible safeguards against adversaries and provide a more reliable means of evaluating the robustness and effectiveness of anti-malware systems. To do so, we describe <b>malware</b> classification and two types of common <b>malware</b> datasets (feature and image datasets), demonstrate the certified robustness accuracy of <b>malware</b> classifiers using the Neural Network Verification (NNV) and Neural Network Enumeration (nnenum) tools, and outline the challenges and future considerations necessary for the improvement and refinement of the verification of <b>malware</b> classification. By evaluating this novel domain as a case study, we hope to increase its visibility, encourage further research and scrutiny, and ultimately enhance the resilience of digital systems against malicious attacks.

{{</citation>}}


### (8/10 | 224/266) Simplifying MBA Expression Using E-Graphs (Seoksu Lee et al., 2024)

{{<citation>}}

Seoksu Lee, Hyeongchang Jeon, Eun-Sun Cho. (2024)  
**Simplifying MBA Expression Using E-Graphs**
<br/>
<button class="copy-to-clipboard" title="Simplifying MBA Expression Using E-Graphs" index=224>
  <span class="copy-to-clipboard-item">Copy Title<span>
</button>
<div class="toast toast-copied toast-index-224 align-items-center text-bg-secondary border-0 position-absolute top-0 end-0" role="alert" aria-live="assertive" aria-atomic="true">
  <div class="d-flex">
    <div class="toast-body">
      Copied!
    </div>
  </div>
</div>

---
Primary Category: cs.CR  
Categories: cs-CR, cs.CR  
Keyword Score: 10  
Keywords: Malware  
<a type="button" class="btn btn-outline-primary" href="http://arxiv.org/abs/2404.05431v1" target="_blank" >Paper Link</a>
<button type="button" class="btn btn-outline-primary download-pdf" url="https://arxiv.org/pdf/2404.05431v1.pdf" filename="2404.05431v1.pdf">Download PDF</button>

---


**ABSTRACT**  
Code obfuscation involves the addition of meaningless code or the complication of existing code in order to make a program difficult to reverse engineer. In recent years, MBA (Mixed Boolean Arithmetic) obfuscation has been applied to virus and <b>malware</b> code to impede expert analysis. Among the various obfuscation techniques, Mixed Boolean Arithmetic (MBA) obfuscation is considered the most challenging to decipher using existing code deobfuscation techniques. In this paper, we have attempted to simplify the MBA expression. We use an e-graph data structure to efficiently hold multiple expressions of the same semantics to systematically rewrite terms and find simpler expressions. The preliminary experimental result shows that our e-graph based MBA deobfuscation approach works faster with reasonable performance than other approaches do.

{{</citation>}}


### (9/10 | 225/266) SoK: Gradient Leakage in Federated Learning (Jiacheng Du et al., 2024)

{{<citation>}}

Jiacheng Du, Jiahui Hu, Zhibo Wang, Peng Sun, Neil Zhenqiang Gong, Kui Ren. (2024)  
**SoK: Gradient Leakage in Federated Learning**
<br/>
<button class="copy-to-clipboard" title="SoK: Gradient Leakage in Federated Learning" index=225>
  <span class="copy-to-clipboard-item">Copy Title<span>
</button>
<div class="toast toast-copied toast-index-225 align-items-center text-bg-secondary border-0 position-absolute top-0 end-0" role="alert" aria-live="assertive" aria-atomic="true">
  <div class="d-flex">
    <div class="toast-body">
      Copied!
    </div>
  </div>
</div>

---
Primary Category: cs.CR  
Categories: cs-AI, cs-CR, cs.CR  
Keyword Score: 10  
Keywords: Federated Learning  
<a type="button" class="btn btn-outline-primary" href="http://arxiv.org/abs/2404.05403v1" target="_blank" >Paper Link</a>
<button type="button" class="btn btn-outline-primary download-pdf" url="https://arxiv.org/pdf/2404.05403v1.pdf" filename="2404.05403v1.pdf">Download PDF</button>

---


**ABSTRACT**  
<b>Federated</b> <b>learning</b> (FL) enables collaborative model training among multiple clients without raw data exposure. However, recent studies have shown that clients' private training data can be reconstructed from the gradients they share in FL, known as gradient inversion attacks (GIAs). While GIAs have demonstrated effectiveness under \emph{ideal settings and auxiliary assumptions}, their actual efficacy against \emph{practical FL systems} remains under-explored. To address this gap, we conduct a comprehensive study on GIAs in this work. We start with a survey of GIAs that establishes a milestone to trace their evolution and develops a systematization to uncover their inherent threats. Specifically, we categorize the auxiliary assumptions used by existing GIAs based on their practical accessibility to potential adversaries. To facilitate deeper analysis, we highlight the challenges that GIAs face in practical FL systems from three perspectives: \textit{local training}, \textit{model}, and \textit{post-processing}. We then perform extensive theoretical and empirical evaluations of state-of-the-art GIAs across diverse settings, utilizing eight datasets and thirteen models. Our findings indicate that GIAs have inherent limitations when reconstructing data under practical local training settings. Furthermore, their efficacy is sensitive to the trained model, and even simple post-processing measures applied to gradients can be effective defenses. Overall, our work provides crucial insights into the limited effectiveness of GIAs in practical FL systems. By rectifying prior misconceptions, we hope to inspire more accurate and realistic investigations on this topic.

{{</citation>}}


### (10/10 | 226/266) Reflected Search Poisoning for Illicit Promotion (Sangyi Wu et al., 2024)

{{<citation>}}

Sangyi Wu, Jialong Xue, Shaoxuan Zhou, Xianghang Mi. (2024)  
**Reflected Search Poisoning for Illicit Promotion**
<br/>
<button class="copy-to-clipboard" title="Reflected Search Poisoning for Illicit Promotion" index=226>
  <span class="copy-to-clipboard-item">Copy Title<span>
</button>
<div class="toast toast-copied toast-index-226 align-items-center text-bg-secondary border-0 position-absolute top-0 end-0" role="alert" aria-live="assertive" aria-atomic="true">
  <div class="d-flex">
    <div class="toast-body">
      Copied!
    </div>
  </div>
</div>

---
Primary Category: cs.CR  
Categories: cs-CR, cs.CR  
Keyword Score: 10  
Keywords: Security  
<a type="button" class="btn btn-outline-primary" href="http://arxiv.org/abs/2404.05320v2" target="_blank" >Paper Link</a>
<button type="button" class="btn btn-outline-primary download-pdf" url="https://arxiv.org/pdf/2404.05320v2.pdf" filename="2404.05320v2.pdf">Download PDF</button>

---


**ABSTRACT**  
As an emerging black hat search engine optimization (SEO) technique, reflected search poisoning (RSP) allows a miscreant to free-ride the reputation of high-ranking websites, poisoning search engines with illicit promotion texts (IPTs) in an efficient and stealthy manner, while avoiding the burden of continuous website compromise as required by traditional promotion infections. However, little is known about the <b>security</b> implications of RSP, e.g., what illicit promotion campaigns are being distributed by RSP, and to what extent regular search users can be exposed to illicit promotion texts distributed by RSP. In this study, we conduct the first <b>security</b> study on RSP-based illicit promotion, which is made possible through an end-to-end methodology for capturing, analyzing, and infiltrating IPTs. As a result, IPTs distributed via RSP are found to be large-scale, continuously growing, and diverse in both illicit categories and natural languages. Particularly, we have identified over 11 million distinct IPTs belonging to 14 different illicit categories, with typical examples including drug trading, data theft, counterfeit goods, and hacking services. Also, the underlying RSP cases have abused tens of thousands of high-ranking websites, as well as extensively poisoning all four popular search engines we studied, especially Google Search and Bing. Furthermore, it is observed that benign search users are being exposed to IPTs at a concerning extent. To facilitate interaction with potential customers (victim search users), miscreants tend to embed various types of contacts in IPTs, especially instant messaging accounts. Further infiltration of these IPT contacts reveals that the underlying illicit campaigns are operated on a large scale. All these findings highlight the negative <b>security</b> implications of IPTs and RSPs, and thus call for more efforts to mitigate RSP-driven illicit promotion.

{{</citation>}}


## cs.CY (3)



### (1/3 | 227/266) Responsible Generative AI: What to Generate and What Not (Jindong Gu, 2024)

{{<citation>}}

Jindong Gu. (2024)  
**Responsible Generative AI: What to Generate and What Not**
<br/>
<button class="copy-to-clipboard" title="Responsible Generative AI: What to Generate and What Not" index=227>
  <span class="copy-to-clipboard-item">Copy Title<span>
</button>
<div class="toast toast-copied toast-index-227 align-items-center text-bg-secondary border-0 position-absolute top-0 end-0" role="alert" aria-live="assertive" aria-atomic="true">
  <div class="d-flex">
    <div class="toast-body">
      Copied!
    </div>
  </div>
</div>

---
Primary Category: cs.CY  
Categories: cs-AI, cs-CL, cs-CV, cs-CY, cs.CY  
Keyword Score: 30  
Keywords: Generative AI, Text2image, Large Language Model  
<a type="button" class="btn btn-outline-primary" href="http://arxiv.org/abs/2404.05783v1" target="_blank" >Paper Link</a>
<button type="button" class="btn btn-outline-primary download-pdf" url="https://arxiv.org/pdf/2404.05783v1.pdf" filename="2404.05783v1.pdf">Download PDF</button>

---


**ABSTRACT**  
In recent years, <b>generative</b> <b>AI</b> (GenAI), like <b>large</b> <b>language</b> <b>models</b> and <b>text-to-image</b> models, has received significant attention across various domains. However, ensuring the responsible generation of content by these models is crucial for their real-world applicability. This raises an interesting question: \textit{What should responsible GenAI generate, and what should it not?} To answer the question, this paper investigates the practical responsible requirements of both textual and visual <b>generative</b> <b>models,</b> outlining five key considerations: generating truthful content, avoiding toxic content, refusing harmful instruction, leaking no training data-related content, and ensuring generated content identifiable. Specifically, we review recent advancements and challenges in addressing these requirements. Besides, we discuss and emphasize the importance of responsible GenAI across healthcare, education, finance, and artificial general intelligence domains. Through a unified perspective on both textual and visual <b>generative</b> <b>models,</b> this paper aims to provide insights into practical safety-related issues and further benefit the community in building responsible GenAI.

{{</citation>}}


### (2/3 | 228/266) Unveiling Latent Topics in Robotic Process Automation -- an Approach based on Latent Dirichlet Allocation Smart Review (Petr Prucha et al., 2024)

{{<citation>}}

Petr Prucha, Peter Madzik, Lukas Falat, Hajo A. Reijers. (2024)  
**Unveiling Latent Topics in Robotic Process Automation -- an Approach based on Latent Dirichlet Allocation Smart Review**
<br/>
<button class="copy-to-clipboard" title="Unveiling Latent Topics in Robotic Process Automation -- an Approach based on Latent Dirichlet Allocation Smart Review" index=228>
  <span class="copy-to-clipboard-item">Copy Title<span>
</button>
<div class="toast toast-copied toast-index-228 align-items-center text-bg-secondary border-0 position-absolute top-0 end-0" role="alert" aria-live="assertive" aria-atomic="true">
  <div class="d-flex">
    <div class="toast-body">
      Copied!
    </div>
  </div>
</div>

---
Primary Category: cs.CY  
Categories: cs-CY, cs.CY  
Keyword Score: 10  
Keywords: Unsupervised Learning  
<a type="button" class="btn btn-outline-primary" href="http://arxiv.org/abs/2404.05836v1" target="_blank" >Paper Link</a>
<button type="button" class="btn btn-outline-primary download-pdf" url="https://arxiv.org/pdf/2404.05836v1.pdf" filename="2404.05836v1.pdf">Download PDF</button>

---


**ABSTRACT**  
Robotic process automation (RPA) is a software technology that in recent years has gained a lot of attention and popularity. By now, research on RPA has spread into multiple research streams. This study aims to create a science map of RPA and its aspects by revealing latent topics related to RPA, their research interest, impact, and time development. We provide a systematic framework that is helpful to develop further research into this technology. By using an <b>unsupervised</b> machine learning method based on Latent Dirichlet Allocation, we were able to analyse over 2000 paper abstracts. Among these, we found 100 distinct study topics, 15 of which have been included in the science map we provide.

{{</citation>}}


### (3/3 | 229/266) Ordre public exceptions for algorithmic surveillance patents (Alina Wernick, 2024)

{{<citation>}}

Alina Wernick. (2024)  
**Ordre public exceptions for algorithmic surveillance patents**
<br/>
<button class="copy-to-clipboard" title="Ordre public exceptions for algorithmic surveillance patents" index=229>
  <span class="copy-to-clipboard-item">Copy Title<span>
</button>
<div class="toast toast-copied toast-index-229 align-items-center text-bg-secondary border-0 position-absolute top-0 end-0" role="alert" aria-live="assertive" aria-atomic="true">
  <div class="d-flex">
    <div class="toast-body">
      Copied!
    </div>
  </div>
</div>

---
Primary Category: cs.CY  
Categories: cs-AI, cs-CY, cs.CY  
Keyword Score: 5  
Keywords: Black Box  
<a type="button" class="btn btn-outline-primary" href="http://arxiv.org/abs/2404.05534v1" target="_blank" >Paper Link</a>
<button type="button" class="btn btn-outline-primary download-pdf" url="https://arxiv.org/pdf/2404.05534v1.pdf" filename="2404.05534v1.pdf">Download PDF</button>

---


**ABSTRACT**  
This chapter explores the role of patent protection in algorithmic surveillance and whether ordre public exceptions from patentability should apply to such patents, due to their potential to enable human rights violations. It concludes that in most cases, it is undesirable to exclude algorithmic surveillance patents from patentability, as the patent system is ill-equipped to evaluate the impacts of the exploitation of such technologies. Furthermore, the disclosure of such patents has positive externalities from the societal perspective by opening the <b>black</b> <b>box</b> of surveillance for public scrutiny.

{{</citation>}}


## stat.ME (1)



### (1/1 | 230/266) Unsupervised Training of Convex Regularizers using Maximum Likelihood Estimation (Hong Ye Tan et al., 2024)

{{<citation>}}

Hong Ye Tan, Ziruo Cai, Marcelo Pereyra, Subhadip Mukherjee, Junqi Tang, Carola-Bibiane Schönlieb. (2024)  
**Unsupervised Training of Convex Regularizers using Maximum Likelihood Estimation**
<br/>
<button class="copy-to-clipboard" title="Unsupervised Training of Convex Regularizers using Maximum Likelihood Estimation" index=230>
  <span class="copy-to-clipboard-item">Copy Title<span>
</button>
<div class="toast toast-copied toast-index-230 align-items-center text-bg-secondary border-0 position-absolute top-0 end-0" role="alert" aria-live="assertive" aria-atomic="true">
  <div class="d-flex">
    <div class="toast-body">
      Copied!
    </div>
  </div>
</div>

---
Primary Category: stat.ME  
Categories: 62C12, 62F15, 65C40, 65J22, cs-LG, stat-CO, stat-ME, stat.ME  
Keyword Score: 30  
Keywords: Supervised Learning, Unsupervised Learning, Unsupervised Learning  
<a type="button" class="btn btn-outline-primary" href="http://arxiv.org/abs/2404.05445v1" target="_blank" >Paper Link</a>
<button type="button" class="btn btn-outline-primary download-pdf" url="https://arxiv.org/pdf/2404.05445v1.pdf" filename="2404.05445v1.pdf">Download PDF</button>

---


**ABSTRACT**  
<b>Unsupervised</b> <b>learning</b> is a training approach in the situation where ground truth data is unavailable, such as inverse imaging problems. We present an <b>unsupervised</b> <b>Bayesian</b> training approach to learning convex neural network regularizers using a fixed noisy dataset, based on a dual Markov chain estimation method. Compared to classical <b>supervised</b> adversarial regularization methods, where there is access to both clean images as well as unlimited to noisy copies, we demonstrate close performance on natural image Gaussian deconvolution and Poisson denoising tasks.

{{</citation>}}


## eess.IV (3)



### (1/3 | 231/266) Anatomical Conditioning for Contrastive Unpaired Image-to-Image Translation of Optical Coherence Tomography Images (Marc S. Seibel et al., 2024)

{{<citation>}}

Marc S. Seibel, Hristina Uzunova, Timo Kepp, Heinz Handels. (2024)  
**Anatomical Conditioning for Contrastive Unpaired Image-to-Image Translation of Optical Coherence Tomography Images**
<br/>
<button class="copy-to-clipboard" title="Anatomical Conditioning for Contrastive Unpaired Image-to-Image Translation of Optical Coherence Tomography Images" index=231>
  <span class="copy-to-clipboard-item">Copy Title<span>
</button>
<div class="toast toast-copied toast-index-231 align-items-center text-bg-secondary border-0 position-absolute top-0 end-0" role="alert" aria-live="assertive" aria-atomic="true">
  <div class="d-flex">
    <div class="toast-body">
      Copied!
    </div>
  </div>
</div>

---
Primary Category: eess.IV  
Categories: cs-CV, eess-IV, eess.IV  
Keyword Score: 30  
Keywords: Contrastive Learning, Unsupervised Learning, Domain Adaptation  
<a type="button" class="btn btn-outline-primary" href="http://arxiv.org/abs/2404.05409v1" target="_blank" >Paper Link</a>
<button type="button" class="btn btn-outline-primary download-pdf" url="https://arxiv.org/pdf/2404.05409v1.pdf" filename="2404.05409v1.pdf">Download PDF</button>

---


**ABSTRACT**  
For a unified analysis of medical images from different modalities, data harmonization using image-to-image (I2I) translation is desired. We study this problem employing an optical coherence tomography (OCT) data set of Spectralis-OCT and Home-OCT images. I2I translation is challenging because the images are unpaired, and a bijective mapping does not exist due to the information discrepancy between both <b>domains.</b> <b>This</b> problem has been addressed by the <b>Contrastive</b> <b>Learning</b> for Unpaired I2I Translation (CUT) approach, but it reduces semantic consistency. To restore the semantic consistency, we support the style decoder using an additional segmentation decoder. Our approach increases the similarity between the style-translated images and the target distribution. Importantly, we improve the segmentation of biomarkers in Home-OCT images in an <b>unsupervised</b> <b>domain</b> <b>adaptation</b> scenario. Our data harmonization approach provides potential for the monitoring of diseases, e.g., age related macular disease, using different OCT devices.

{{</citation>}}


### (2/3 | 232/266) Comparative Analysis of Image Enhancement Techniques for Brain Tumor Segmentation: Contrast, Histogram, and Hybrid Approaches (Shoffan Saifullah et al., 2024)

{{<citation>}}

Shoffan Saifullah, Andri Pranolo, Rafał Dreżewski. (2024)  
**Comparative Analysis of Image Enhancement Techniques for Brain Tumor Segmentation: Contrast, Histogram, and Hybrid Approaches**
<br/>
<button class="copy-to-clipboard" title="Comparative Analysis of Image Enhancement Techniques for Brain Tumor Segmentation: Contrast, Histogram, and Hybrid Approaches" index=232>
  <span class="copy-to-clipboard-item">Copy Title<span>
</button>
<div class="toast toast-copied toast-index-232 align-items-center text-bg-secondary border-0 position-absolute top-0 end-0" role="alert" aria-live="assertive" aria-atomic="true">
  <div class="d-flex">
    <div class="toast-body">
      Copied!
    </div>
  </div>
</div>

---
Primary Category: eess.IV  
Categories: I-4-3; I-4-6, cs-CV, eess-IV, eess.IV  
Keyword Score: 30  
Keywords: Convolution, Convolutional Neural Network, Convolutional Neural Network  
<a type="button" class="btn btn-outline-primary" href="http://arxiv.org/abs/2404.05341v1" target="_blank" >Paper Link</a>
<button type="button" class="btn btn-outline-primary download-pdf" url="https://arxiv.org/pdf/2404.05341v1.pdf" filename="2404.05341v1.pdf">Download PDF</button>

---


**ABSTRACT**  
This study systematically investigates the impact of image enhancement techniques on <b>Convolutional</b> <b>Neural</b> <b>Network</b> <b>(CNN)-based</b> Brain Tumor Segmentation, focusing on Histogram Equalization (HE), Contrast Limited Adaptive Histogram Equalization (CLAHE), and their hybrid variations. Employing the U-Net architecture on a dataset of 3064 Brain MRI images, the research delves into preprocessing steps, including resizing and enhancement, to optimize segmentation accuracy. A detailed analysis of the <b>CNN-based</b> U-Net architecture, training, and validation processes is provided. The comparative analysis, utilizing metrics such as Accuracy, Loss, MSE, IoU, and DSC, reveals that the hybrid approach CLAHE-HE consistently outperforms others. Results highlight its superior accuracy (0.9982, 0.9939, 0.9936 for training, testing, and validation, respectively) and robust segmentation overlap, with Jaccard values of 0.9862, 0.9847, and 0.9864, and Dice values of 0.993, 0.9923, and 0.9932 for the same phases, emphasizing its potential in neuro-oncological applications. The study concludes with a call for refinement in segmentation methodologies to further enhance diagnostic precision and treatment planning in neuro-oncology.

{{</citation>}}


### (3/3 | 233/266) Unravelling the Power of Single-Pass Look-Ahead in Modern Codecs for Optimized Transcoding Deployment (Vibhoothi Vibhoothi et al., 2024)

{{<citation>}}

Vibhoothi Vibhoothi, Julien Zouein, François Pitié, Anil Kokaram. (2024)  
**Unravelling the Power of Single-Pass Look-Ahead in Modern Codecs for Optimized Transcoding Deployment**
<br/>
<button class="copy-to-clipboard" title="Unravelling the Power of Single-Pass Look-Ahead in Modern Codecs for Optimized Transcoding Deployment" index=233>
  <span class="copy-to-clipboard-item">Copy Title<span>
</button>
<div class="toast toast-copied toast-index-233 align-items-center text-bg-secondary border-0 position-absolute top-0 end-0" role="alert" aria-live="assertive" aria-atomic="true">
  <div class="d-flex">
    <div class="toast-body">
      Copied!
    </div>
  </div>
</div>

---
Primary Category: eess.IV  
Categories: cs-MM, eess-IV, eess.IV  
Keyword Score: 10  
Keywords: Recommendation  
<a type="button" class="btn btn-outline-primary" href="http://arxiv.org/abs/2404.05321v1" target="_blank" >Paper Link</a>
<button type="button" class="btn btn-outline-primary download-pdf" url="https://arxiv.org/pdf/2404.05321v1.pdf" filename="2404.05321v1.pdf">Download PDF</button>

---


**ABSTRACT**  
Modern video encoders have evolved into sophisticated pieces of software in which various coding tools interact with each other. In the past, singlepass encoding was not considered for Video-On-Demand (VOD) use cases. In this work, we evaluate production-ready encoders for H.264 (x264), H.265 (HEVC), AV1 (SVT-AV1) along with direct comparisons to the latest AV1 encoder inside NVIDIA GPUs (40 series), and AWS Mediaconvert's AV1 implementation. Our experimental results demonstrate single pass encoding inside modern encoder implementations can give us very good quality at a reasonable compute cost. The results are presented as three different scenarios targeting High, Medium, and Low complexity accounting quality/bitrate/compute load. Finally, a set of <b>recommendations</b> is presented for end-users to help decide which encoder/preset combination might be more suited to their use case.

{{</citation>}}


## cs.DM (1)



### (1/1 | 234/266) Space-time deterministic graph rewriting (Pablo Arrighi et al., 2024)

{{<citation>}}

Pablo Arrighi, Marin Costes, Gilles Dowek, Luidnel Maignan. (2024)  
**Space-time deterministic graph rewriting**
<br/>
<button class="copy-to-clipboard" title="Space-time deterministic graph rewriting" index=234>
  <span class="copy-to-clipboard-item">Copy Title<span>
</button>
<div class="toast toast-copied toast-index-234 align-items-center text-bg-secondary border-0 position-absolute top-0 end-0" role="alert" aria-live="assertive" aria-atomic="true">
  <div class="d-flex">
    <div class="toast-body">
      Copied!
    </div>
  </div>
</div>

---
Primary Category: cs.DM  
Categories: cs-DC, cs-DM, cs.DM, gr-qc, math-DS, nlin-CG  
Keyword Score: 23  
Keywords: Graph, Simulation, Simulator  
<a type="button" class="btn btn-outline-primary" href="http://arxiv.org/abs/2404.05838v1" target="_blank" >Paper Link</a>
<button type="button" class="btn btn-outline-primary download-pdf" url="https://arxiv.org/pdf/2404.05838v1.pdf" filename="2404.05838v1.pdf">Download PDF</button>

---


**ABSTRACT**  
We study non-terminating <b>graph</b> rewriting models, whose local rules are applied non-deterministically -- and yet enjoy a strong form of determinism, namely space-time determinism. Of course in the case of terminating computation it is well-known that the mess introduced by asynchronous rule applications may not matter to the end result, as confluence conspires to produce a unique normal form. In the context of non-terminating computation however, confluence is a very weak property, and (almost) synchronous rule applications is always preferred e.g. when it comes to simulating dynamical systems. Here we provide sufficient conditions so that asynchronous local rule applications conspire to produce well-determined events in the space-time unfolding of the <b>graph,</b> regardless of their application orders. Our first example is an asynchronous <b>simulation</b> of a dynamical system. Our second example features time dilation, in the spirit of general relativity.

{{</citation>}}


## cs.DC (1)



### (1/1 | 235/266) KaMPIng: Flexible and (Near) Zero-overhead C++ Bindings for MPI (Demian Hespe et al., 2024)

{{<citation>}}

Demian Hespe, Lukas Hübner, Florian Kurpicz, Peter Sanders, Matthias Schimek, Daniel Seemaier, Christoph Stelz, Tim Niklas Uhl. (2024)  
**KaMPIng: Flexible and (Near) Zero-overhead C++ Bindings for MPI**
<br/>
<button class="copy-to-clipboard" title="KaMPIng: Flexible and (Near) Zero-overhead C++ Bindings for MPI" index=235>
  <span class="copy-to-clipboard-item">Copy Title<span>
</button>
<div class="toast toast-copied toast-index-235 align-items-center text-bg-secondary border-0 position-absolute top-0 end-0" role="alert" aria-live="assertive" aria-atomic="true">
  <div class="d-flex">
    <div class="toast-body">
      Copied!
    </div>
  </div>
</div>

---
Primary Category: cs.DC  
Categories: cs-DC, cs.DC  
Keyword Score: 23  
Keywords: Message-Passing, Benchmarking, Fine-tuning  
<a type="button" class="btn btn-outline-primary" href="http://arxiv.org/abs/2404.05610v1" target="_blank" >Paper Link</a>
<button type="button" class="btn btn-outline-primary download-pdf" url="https://arxiv.org/pdf/2404.05610v1.pdf" filename="2404.05610v1.pdf">Download PDF</button>

---


**ABSTRACT**  
The <b>Message-Passing</b> Interface (MPI) and C++ form the backbone of high-performance computing, but MPI only provides C and Fortran bindings. While this offers great language interoperability, high-level programming languages like C++ make software development quicker and less error-prone. We propose novel C++ language bindings that cover all abstraction levels from low-level MPI calls to convenient STL-style bindings, where most parameters are inferred from a small subset of parameters, by bringing named parameters to C++. This enables rapid prototyping and <b>fine-tuning</b> runtime behavior and memory management. A flexible type system and additional safeness guarantees help to prevent programming errors. By exploiting C++'s template-metaprogramming capabilities, this has (near) zero-overhead, as only required code paths are generated at compile time. We demonstrate that our library is a strong foundation for a future distributed standard library using multiple application <b>benchmarks,</b> ranging from text-book sorting algorithms to phylogenetic interference.

{{</citation>}}


## cs.CG (2)



### (1/2 | 236/266) Box Filtration (Enrique Alvarado et al., 2024)

{{<citation>}}

Enrique Alvarado, Prashant Gupta, Bala Krishnamoorthy. (2024)  
**Box Filtration**
<br/>
<button class="copy-to-clipboard" title="Box Filtration" index=236>
  <span class="copy-to-clipboard-item">Copy Title<span>
</button>
<div class="toast toast-copied toast-index-236 align-items-center text-bg-secondary border-0 position-absolute top-0 end-0" role="alert" aria-live="assertive" aria-atomic="true">
  <div class="d-flex">
    <div class="toast-body">
      Copied!
    </div>
  </div>
</div>

---
Primary Category: cs.CG  
Categories: 55N31, 62R40,, cs-CG, cs.CG, math-AT  
Keyword Score: 20  
Keywords: Virtual Reality (VR), Summarization  
<a type="button" class="btn btn-outline-primary" href="http://arxiv.org/abs/2404.05859v2" target="_blank" >Paper Link</a>
<button type="button" class="btn btn-outline-primary download-pdf" url="https://arxiv.org/pdf/2404.05859v2.pdf" filename="2404.05859v2.pdf">Download PDF</button>

---


**ABSTRACT**  
We define a new framework that unifies the filtration and mapper approaches from TDA, and present efficient algorithms to compute it. Termed the box filtration of a PCD, we grow boxes (hyperrectangles) that are not necessarily centered at each point (in place of balls centered at points). We grow the boxes non-uniformly and asymmetrically in different dimensions based on the distribution of points. We present two approaches to handle the boxes: a point cover where each point is assigned its own box at start, and a pixel cover that works with a pixelization of the space of the PCD. Any box cover in either setting automatically gives a mapper of the PCD. We show that the persistence diagrams generated by the box filtration using both point and pixel covers satisfy the classical stability based on the Gromov-Hausdorff distance. Using boxes also implies that the box filtration is identical for pairwise or higher order intersections whereas the <b>VR</b> and Cech filtration are not the same. Growth in each dimension is computed by solving a linear program (LP) that optimizes a cost functional balancing the cost of expansion and benefit of including more points in the box. The box filtration algorithm runs in $O(m|U(0)|\log(mn\pi)L(q))$ time, where $m$ is number of steps of increments considered for box growth, $|U(0)|$ is the number of boxes in the initial cover ($\leq$ number of points), $\pi$ is the step length for increasing each box dimension, each LP is solved in $O(L(q))$ time, $n$ is the PCD dimension, and $q = n \times |X|$. We demonstrate through multiple examples that the box filtration can produce more accurate results to <b>summarize</b> the topology of the PCD than <b>VR</b> and distance-to-measure (DTM) filtrations. Software for our implementation is available at https://github.com/pragup/Box-Filteration.

{{</citation>}}


### (2/2 | 237/266) Walking Your Frog Fast in 4 LoC (Nis Meinert, 2024)

{{<citation>}}

Nis Meinert. (2024)  
**Walking Your Frog Fast in 4 LoC**
<br/>
<button class="copy-to-clipboard" title="Walking Your Frog Fast in 4 LoC" index=237>
  <span class="copy-to-clipboard-item">Copy Title<span>
</button>
<div class="toast toast-copied toast-index-237 align-items-center text-bg-secondary border-0 position-absolute top-0 end-0" role="alert" aria-live="assertive" aria-atomic="true">
  <div class="d-flex">
    <div class="toast-body">
      Copied!
    </div>
  </div>
</div>

---
Primary Category: cs.CG  
Categories: cs-CG, cs.CG  
Keyword Score: 3  
Keywords: Benchmarking  
<a type="button" class="btn btn-outline-primary" href="http://arxiv.org/abs/2404.05708v1" target="_blank" >Paper Link</a>
<button type="button" class="btn btn-outline-primary download-pdf" url="https://arxiv.org/pdf/2404.05708v1.pdf" filename="2404.05708v1.pdf">Download PDF</button>

---


**ABSTRACT**  
Given two polygonal curves, there are many ways to define a notion of similarity between them. One popular measure is the Fr\'echet distance which has many desirable properties but is notoriously expensive to calculate, especially for non-trivial metrics. In 1994, Eiter and Mannila introduced the discrete Fr\'echet distance which is much easier to implement and approximates the continuous Fr\'echet distance with a quadratic runtime overhead. However, this algorithm relies on recursions and is not well suited for modern hardware. To that end, we introduce the Fast Fr\'echet Distance algorithm, a recursion-free algorithm that calculates the discrete Fr\'echet distance with a linear memory overhead and that can utilize modern hardware more effectively. We showcase an implementation with only four lines of code and present <b>benchmarks</b> of our algorithm running fast on modern CPUs and GPGPUs.

{{</citation>}}


## math.ST (2)



### (1/2 | 238/266) Centrality Estimators for Probability Density Functions (Djemel Ziou, 2024)

{{<citation>}}

Djemel Ziou. (2024)  
**Centrality Estimators for Probability Density Functions**
<br/>
<button class="copy-to-clipboard" title="Centrality Estimators for Probability Density Functions" index=238>
  <span class="copy-to-clipboard-item">Copy Title<span>
</button>
<div class="toast toast-copied toast-index-238 align-items-center text-bg-secondary border-0 position-absolute top-0 end-0" role="alert" aria-live="assertive" aria-atomic="true">
  <div class="d-flex">
    <div class="toast-body">
      Copied!
    </div>
  </div>
</div>

---
Primary Category: math.ST  
Categories: cs-LG, math-ST, math.ST, stat-TH  
Keyword Score: 20  
Keywords: Simulation, Simulator  
<a type="button" class="btn btn-outline-primary" href="http://arxiv.org/abs/2404.05816v1" target="_blank" >Paper Link</a>
<button type="button" class="btn btn-outline-primary download-pdf" url="https://arxiv.org/pdf/2404.05816v1.pdf" filename="2404.05816v1.pdf">Download PDF</button>

---


**ABSTRACT**  
In this report, we explore the data selection leading to a family of estimators maximizing a centrality. The family allows a nice properties leading to accurate and robust probability density function fitting according to some criteria we define. We establish a link between the centrality estimator and the maximum likelihood, showing that the latter is a particular case. Therefore, a new probability interpretation of Fisher maximum likelihood is provided. We will introduce and study two specific centralities that we have named H\"older and Lehmer estimators. A numerical <b>simulation</b> is provided showing the effectiveness of the proposed families of estimators opening the door to development of new concepts and algorithms in machine learning, data mining, statistics, and data analysis.

{{</citation>}}


### (2/2 | 239/266) Quickest Change Detection for Multiple Data Streams Using the James-Stein Estimator (Topi Halme et al., 2024)

{{<citation>}}

Topi Halme, Venugopal V. Veeravalli, Visa Koivunen. (2024)  
**Quickest Change Detection for Multiple Data Streams Using the James-Stein Estimator**
<br/>
<button class="copy-to-clipboard" title="Quickest Change Detection for Multiple Data Streams Using the James-Stein Estimator" index=239>
  <span class="copy-to-clipboard-item">Copy Title<span>
</button>
<div class="toast toast-copied toast-index-239 align-items-center text-bg-secondary border-0 position-absolute top-0 end-0" role="alert" aria-live="assertive" aria-atomic="true">
  <div class="d-flex">
    <div class="toast-body">
      Copied!
    </div>
  </div>
</div>

---
Primary Category: math.ST  
Categories: cs-IT, math-IT, math-ST, math.ST, stat-TH  
Keyword Score: 20  
Keywords: Simulation, Simulator  
<a type="button" class="btn btn-outline-primary" href="http://arxiv.org/abs/2404.05486v1" target="_blank" >Paper Link</a>
<button type="button" class="btn btn-outline-primary download-pdf" url="https://arxiv.org/pdf/2404.05486v1.pdf" filename="2404.05486v1.pdf">Download PDF</button>

---


**ABSTRACT**  
The problem of quickest change detection is studied in the context of detecting an arbitrary unknown mean-shift in multiple independent Gaussian data streams. The James-Stein estimator is used in constructing detection schemes that exhibit strong detection performance both asymptotically and non-asymptotically. First, a James-Stein-based extension of the recently developed windowed CuSum test is introduced. Our results indicate that the proposed scheme constitutes a uniform improvement over its typical maximum likelihood variant. That is, the proposed James-Stein version achieves a smaller detection delay simultaneously for all possible post-change parameter values and every false alarm rate constraint, as long as the number of parallel data streams is greater than three. Additionally, an alternative detection procedure that utilizes the James-Stein estimator is shown to have asymptotic detection delay properties that compare favorably to existing tests. The second-order term of the asymptotic average detection delay is reduced in a predefined low-dimensional subspace of the parameter space, while second-order asymptotic minimaxity is preserved. The results are verified in <b>simulations,</b> where the proposed schemes are shown to achieve smaller detection delays compared to existing alternatives, especially when the number of data streams is large.

{{</citation>}}


## cs.CE (1)



### (1/1 | 240/266) BatSort: Enhanced Battery Classification with Transfer Learning for Battery Sorting and Recycling (Yunyi Zhao et al., 2024)

{{<citation>}}

Yunyi Zhao, Wei Zhang, Erhai Hu, Qingyu Yan, Cheng Xiang, King Jet Tseng, Dusit Niyato. (2024)  
**BatSort: Enhanced Battery Classification with Transfer Learning for Battery Sorting and Recycling**
<br/>
<button class="copy-to-clipboard" title="BatSort: Enhanced Battery Classification with Transfer Learning for Battery Sorting and Recycling" index=240>
  <span class="copy-to-clipboard-item">Copy Title<span>
</button>
<div class="toast toast-copied toast-index-240 align-items-center text-bg-secondary border-0 position-absolute top-0 end-0" role="alert" aria-live="assertive" aria-atomic="true">
  <div class="d-flex">
    <div class="toast-body">
      Copied!
    </div>
  </div>
</div>

---
Primary Category: cs.CE  
Categories: cs-CE, cs-CV, cs-MM, cs.CE  
Keyword Score: 20  
Keywords: Knowledge Transfer, Transfer Learning  
<a type="button" class="btn btn-outline-primary" href="http://arxiv.org/abs/2404.05802v1" target="_blank" >Paper Link</a>
<button type="button" class="btn btn-outline-primary download-pdf" url="https://arxiv.org/pdf/2404.05802v1.pdf" filename="2404.05802v1.pdf">Download PDF</button>

---


**ABSTRACT**  
Battery recycling is a critical process for minimizing environmental harm and resource waste for used batteries. However, it is challenging, largely because sorting batteries is costly and hardly automated to group batteries based on battery types. In this paper, we introduce a machine learning-based approach for battery-type classification and address the daunting problem of data scarcity for the application. We propose BatSort which applies <b>transfer</b> <b>learning</b> to utilize the existing <b>knowledge</b> <b>optimized</b> with large-scale datasets and customizes ResNet to be specialized for classifying battery types. We collected our in-house battery-type dataset of small-scale to guide the <b>knowledge</b> <b>transfer</b> <b>as</b> a case study and evaluate the system performance. We conducted an experimental study and the results show that BatSort can achieve outstanding accuracy of 92.1% on average and up to 96.2% and the performance is stable for battery-type classification. Our solution helps realize fast and automated battery sorting with minimized cost and can be transferred to related industry applications with insufficient data.

{{</citation>}}


## cs.ET (2)



### (1/2 | 241/266) Multi Digit Ising Mapping for Low Precision Ising Solvers (Abhishek Kumar Singh et al., 2024)

{{<citation>}}

Abhishek Kumar Singh, Kyle Jamieson. (2024)  
**Multi Digit Ising Mapping for Low Precision Ising Solvers**
<br/>
<button class="copy-to-clipboard" title="Multi Digit Ising Mapping for Low Precision Ising Solvers" index=241>
  <span class="copy-to-clipboard-item">Copy Title<span>
</button>
<div class="toast toast-copied toast-index-241 align-items-center text-bg-secondary border-0 position-absolute top-0 end-0" role="alert" aria-live="assertive" aria-atomic="true">
  <div class="d-flex">
    <div class="toast-body">
      Copied!
    </div>
  </div>
</div>

---
Primary Category: cs.ET  
Categories: cs-ET, cs.ET  
Keyword Score: 20  
Keywords: Simulation, Simulator  
<a type="button" class="btn btn-outline-primary" href="http://arxiv.org/abs/2404.05631v1" target="_blank" >Paper Link</a>
<button type="button" class="btn btn-outline-primary download-pdf" url="https://arxiv.org/pdf/2404.05631v1.pdf" filename="2404.05631v1.pdf">Download PDF</button>

---


**ABSTRACT**  
The last couple of years have seen an ever-increasing interest in using different Ising solvers, like Quantum annealers, Coherent Ising machines, and Oscillator-based Ising machines, for solving tough computational problems in various domains. Although the <b>simulations</b> predict massive performance improvements for several tough computational problems, the real implementations of the Ising solvers tend to have limited precision, which can cause significant performance deterioration. This paper presents a novel methodology for mapping the problem on the Ising solvers to artificially increase the effective precision. We further evaluate our method for the Multiple-Input-Multiple-Output signal detection problem.

{{</citation>}}


### (2/2 | 242/266) Intelligent Reflecting Surface Aided Target Localization With Unknown Transceiver-IRS Channel State Information (Taotao Ji et al., 2024)

{{<citation>}}

Taotao Ji, Meng Hua, Xuanhong Yan, Chunguo Li, Yongming Huang, Luxi Yang. (2024)  
**Intelligent Reflecting Surface Aided Target Localization With Unknown Transceiver-IRS Channel State Information**
<br/>
<button class="copy-to-clipboard" title="Intelligent Reflecting Surface Aided Target Localization With Unknown Transceiver-IRS Channel State Information" index=242>
  <span class="copy-to-clipboard-item">Copy Title<span>
</button>
<div class="toast toast-copied toast-index-242 align-items-center text-bg-secondary border-0 position-absolute top-0 end-0" role="alert" aria-live="assertive" aria-atomic="true">
  <div class="d-flex">
    <div class="toast-body">
      Copied!
    </div>
  </div>
</div>

---
Primary Category: cs.ET  
Categories: cs-ET, cs.ET, eess-SP  
Keyword Score: 20  
Keywords: Simulation, Simulator  
<a type="button" class="btn btn-outline-primary" href="http://arxiv.org/abs/2404.05149v1" target="_blank" >Paper Link</a>
<button type="button" class="btn btn-outline-primary download-pdf" url="https://arxiv.org/pdf/2404.05149v1.pdf" filename="2404.05149v1.pdf">Download PDF</button>

---


**ABSTRACT**  
Integrating wireless sensing capabilities into base stations (BSs) has become a widespread trend in the future beyond fifth-generation (B5G)/sixth-generation (6G) wireless networks. In this paper, we investigate intelligent reflecting surface (IRS) enabled wireless localization, in which an IRS is deployed to assist a BS in locating a target in its non-line-of-sight (NLoS) region. In particular, we consider the case where the BS-IRS channel state information (CSI) is unknown. Specifically, we first propose a separate BS-IRS channel estimation scheme in which the BS operates in full-duplex mode (FDM), i.e., a portion of the BS antennas send downlink pilot signals to the IRS, while the remaining BS antennas receive the uplink pilot signals reflected by the IRS. However, we can only obtain an incomplete BS-IRS channel matrix based on our developed iterative coordinate descent-based channel estimation algorithm due to the "sign ambiguity issue". Then, we employ the multiple hypotheses testing framework to perform target localization based on the incomplete estimated channel, in which the probability of each hypothesis is updated using Bayesian inference at each cycle. Moreover, we formulate a joint BS transmit waveform and IRS phase shifts optimization problem to improve the target localization performance by maximizing the weighted sum distance between each two hypotheses. However, the objective function is essentially a quartic function of the IRS phase shift vector, thus motivating us to resort to the penalty-based method to tackle this challenge. <b>Simulation</b> results validate the effectiveness of our proposed target localization scheme and show that the scheme's performance can be further improved by finely designing the BS transmit waveform and IRS phase shifts intending to maximize the weighted sum distance between different hypotheses.

{{</citation>}}


## cs.NI (3)



### (1/3 | 243/266) Optimal Flow Admission Control in Edge Computing via Safe Reinforcement Learning (A. Fox et al., 2024)

{{<citation>}}

A. Fox, F. De Pellegrini, F. Faticanti, E. Altman, F. Bronzino. (2024)  
**Optimal Flow Admission Control in Edge Computing via Safe Reinforcement Learning**
<br/>
<button class="copy-to-clipboard" title="Optimal Flow Admission Control in Edge Computing via Safe Reinforcement Learning" index=243>
  <span class="copy-to-clipboard-item">Copy Title<span>
</button>
<div class="toast toast-copied toast-index-243 align-items-center text-bg-secondary border-0 position-absolute top-0 end-0" role="alert" aria-live="assertive" aria-atomic="true">
  <div class="d-flex">
    <div class="toast-body">
      Copied!
    </div>
  </div>
</div>

---
Primary Category: cs.NI  
Categories: cs-NI, cs.NI  
Keyword Score: 20  
Keywords: Markov Decision Process, Reinforcement Learning  
<a type="button" class="btn btn-outline-primary" href="http://arxiv.org/abs/2404.05564v1" target="_blank" >Paper Link</a>
<button type="button" class="btn btn-outline-primary download-pdf" url="https://arxiv.org/pdf/2404.05564v1.pdf" filename="2404.05564v1.pdf">Download PDF</button>

---


**ABSTRACT**  
With the uptake of intelligent data-driven applications, edge computing infrastructures necessitate a new generation of admission control algorithms to maximize system performance under limited and highly heterogeneous resources. In this paper, we study how to optimally select information flows which belong to different classes and dispatch them to multiple edge servers where deployed applications perform flow analytic tasks. The optimal policy is obtained via constrained <b>Markov</b> <b>decision</b> <b>process</b> (CMDP) theory accounting for the demand of each edge application for specific classes of flows, the constraints on computing capacity of edge servers and of the access network. We develop DR-CPO, a specialized primal-dual Safe <b>Reinforcement</b> <b>Learning</b> (SRL) method which solves the resulting optimal admission control problem by reward decomposition. DR-CPO operates optimal decentralized control and mitigates effectively state-space explosion while preserving optimality. Compared to existing Deep <b>Reinforcement</b> <b>Learning</b> (DRL) solutions, extensive results show that DR-CPO achieves 15\% higher reward on a wide variety of environments, while requiring on average only 50\% of the amount of learning episodes to converge. Finally, we show how to match DR-CPO and load-balancing to dispatch optimally information streams to available edge servers and further improve system performance.

{{</citation>}}


### (2/3 | 244/266) Liquid Neural Network-based Adaptive Learning vs. Incremental Learning for Link Load Prediction amid Concept Drift due to Network Failures (Omran Ayoub et al., 2024)

{{<citation>}}

Omran Ayoub, Davide Andreoletti, Aleksandra Knapińska, Róża Goścień, Piotr Lechowicz, Tiziano Leidi, Silvia Giordano, Cristina Rottondi, Krzysztof Walkowiak. (2024)  
**Liquid Neural Network-based Adaptive Learning vs. Incremental Learning for Link Load Prediction amid Concept Drift due to Network Failures**
<br/>
<button class="copy-to-clipboard" title="Liquid Neural Network-based Adaptive Learning vs. Incremental Learning for Link Load Prediction amid Concept Drift due to Network Failures" index=244>
  <span class="copy-to-clipboard-item">Copy Title<span>
</button>
<div class="toast toast-copied toast-index-244 align-items-center text-bg-secondary border-0 position-absolute top-0 end-0" role="alert" aria-live="assertive" aria-atomic="true">
  <div class="d-flex">
    <div class="toast-body">
      Copied!
    </div>
  </div>
</div>

---
Primary Category: cs.NI  
Categories: cs-LG, cs-NI, cs.NI  
Keyword Score: 20  
Keywords: Simulation, Simulator  
<a type="button" class="btn btn-outline-primary" href="http://arxiv.org/abs/2404.05304v1" target="_blank" >Paper Link</a>
<button type="button" class="btn btn-outline-primary download-pdf" url="https://arxiv.org/pdf/2404.05304v1.pdf" filename="2404.05304v1.pdf">Download PDF</button>

---


**ABSTRACT**  
Adapting to concept drift is a challenging task in machine learning, which is usually tackled using incremental learning techniques that periodically re-fit a learning model leveraging newly available data. A primary limitation of these techniques is their reliance on substantial amounts of data for retraining. The necessity of acquiring fresh data introduces temporal delays prior to retraining, potentially rendering the models inaccurate if a sudden concept drift occurs in-between two consecutive retrainings. In communication networks, such issue emerges when performing traffic forecasting following a~failure event: post-failure re-routing may induce a drastic shift in distribution and pattern of traffic data, thus requiring a timely model adaptation. In this work, we address this challenge for the problem of traffic forecasting and propose an approach that exploits adaptive learning algorithms, namely, liquid neural networks, which are capable of self-adaptation to abrupt changes in data patterns without requiring any retraining. Through extensive <b>simulations</b> of failure scenarios, we compare the predictive performance of our proposed approach to that of a reference method based on incremental learning. Experimental results show that our proposed approach outperforms incremental learning-based methods in situations where the shifts in traffic patterns are drastic.

{{</citation>}}


### (3/3 | 245/266) Can Edge Computing fulfill the requirements of automated vehicular services using 5G network ? (Wendlasida Ouedraogo et al., 2024)

{{<citation>}}

Wendlasida Ouedraogo, Andrea Araldo, Badii Jouaber, Hind Castel, Remy Grunblatt. (2024)  
**Can Edge Computing fulfill the requirements of automated vehicular services using 5G network ?**
<br/>
<button class="copy-to-clipboard" title="Can Edge Computing fulfill the requirements of automated vehicular services using 5G network ?" index=245>
  <span class="copy-to-clipboard-item">Copy Title<span>
</button>
<div class="toast toast-copied toast-index-245 align-items-center text-bg-secondary border-0 position-absolute top-0 end-0" role="alert" aria-live="assertive" aria-atomic="true">
  <div class="d-flex">
    <div class="toast-body">
      Copied!
    </div>
  </div>
</div>

---
Primary Category: cs.NI  
Categories: cs-NI, cs.NI  
Keyword Score: 20  
Keywords: Simulation, Simulator  
<a type="button" class="btn btn-outline-primary" href="http://arxiv.org/abs/2404.05296v1" target="_blank" >Paper Link</a>
<button type="button" class="btn btn-outline-primary download-pdf" url="https://arxiv.org/pdf/2404.05296v1.pdf" filename="2404.05296v1.pdf">Download PDF</button>

---


**ABSTRACT**  
Communication and computation services supporting Connected and Automated Vehicles (CAVs) are characterized by stringent requirements, in terms of response time and reliability. Fulfilling these requirements is crucial for ensuring road safety and traffic optimization. The conceptually simple solution of hosting these services in the vehicles increases their cost (mainly due to the installation and maintenance of computation infrastructure) and may drain their battery excessively. Such disadvantages can be tackled via Multi-Access Edge Computing (MEC), consisting in deploying computation capability in network nodes deployed close to the devices (vehicles in this case), such as to satisfy the stringent CAV requirements. However, it is not yet clear under which conditions MEC can support CAV requirements and for which services. To shed light on this question, we conduct a <b>simulation</b> campaign using well-known open-source <b>simulation</b> tools, namely OMNeT++, Simu5G, Veins, INET, and SUMO. We are thus able to provide a reality check on MEC for CAV, pinpointing what are the computation capacities that must be installed in the MEC, to support the different services, and the amount of vehicles that a single MEC node can support. We find that such parameters must vary a lot, depending on the service considered. This study can serve as a preliminary basis for network operators to plan future deployment of MEC to support CAV.

{{</citation>}}


## physics.flu-dyn (1)



### (1/1 | 246/266) Wall-modeled large-eddy simulation based on spectral-element discretization (Timofey Mukha et al., 2024)

{{<citation>}}

Timofey Mukha, Philipp Schlatter. (2024)  
**Wall-modeled large-eddy simulation based on spectral-element discretization**
<br/>
<button class="copy-to-clipboard" title="Wall-modeled large-eddy simulation based on spectral-element discretization" index=246>
  <span class="copy-to-clipboard-item">Copy Title<span>
</button>
<div class="toast toast-copied toast-index-246 align-items-center text-bg-secondary border-0 position-absolute top-0 end-0" role="alert" aria-live="assertive" aria-atomic="true">
  <div class="d-flex">
    <div class="toast-body">
      Copied!
    </div>
  </div>
</div>

---
Primary Category: physics.flu-dyn  
Categories: cs-NA, math-NA, physics-flu-dyn, physics.flu-dyn  
Keyword Score: 20  
Keywords: Simulation, Simulator  
<a type="button" class="btn btn-outline-primary" href="http://arxiv.org/abs/2404.05378v1" target="_blank" >Paper Link</a>
<button type="button" class="btn btn-outline-primary download-pdf" url="https://arxiv.org/pdf/2404.05378v1.pdf" filename="2404.05378v1.pdf">Download PDF</button>

---


**ABSTRACT**  
This article analyses the <b>simulation</b> methodology for wall-modeled large-eddy <b>simulations</b> using solvers based on the spectral-element method (SEM). To that end, algebraic wall modeling is implemented in the popular SEM solver Nek5000. It is combined with explicit subgrid-scale (SGS) modeling, which is shown to perform better than the high-frequency filtering traditionally used with the SEM. In particular, the Vreman model exhibits a good balance in terms stabilizing the <b>simulations,</b> yet retaining good resolution of the turbulent scales. Some difficulties associated with SEM <b>simulations</b> on relatively coarse grids are also revealed: jumps in derivatives across element boundaries, lack of convergence for weakly formulated boundary conditions, and the necessity for the SGS model as a damper for high-frequency modes. In spite of these, state-of-the-art accuracy is achieved for turbulent channel flow and flat-plate turbulent boundary layer flow cases, proving the SEM to be a an excellent numerical framework for massively-parallel high-order WMLES.

{{</citation>}}


## cs.MA (1)



### (1/1 | 247/266) EVLearn: Extending the CityLearn Framework with Electric Vehicle Simulation (Tiago Fonseca et al., 2024)

{{<citation>}}

Tiago Fonseca, Luis Ferreira, Bernardo Cabral, Ricardo Severino, Kingsley Nweye, Dipanjan Ghose, Zoltan Nagy. (2024)  
**EVLearn: Extending the CityLearn Framework with Electric Vehicle Simulation**
<br/>
<button class="copy-to-clipboard" title="EVLearn: Extending the CityLearn Framework with Electric Vehicle Simulation" index=247>
  <span class="copy-to-clipboard-item">Copy Title<span>
</button>
<div class="toast toast-copied toast-index-247 align-items-center text-bg-secondary border-0 position-absolute top-0 end-0" role="alert" aria-live="assertive" aria-atomic="true">
  <div class="d-flex">
    <div class="toast-body">
      Copied!
    </div>
  </div>
</div>

---
Primary Category: cs.MA  
Categories: cs-MA, cs-SY, cs.MA, eess-SY  
Keyword Score: 20  
Keywords: Simulation, Simulator  
<a type="button" class="btn btn-outline-primary" href="http://arxiv.org/abs/2404.06521v1" target="_blank" >Paper Link</a>
<button type="button" class="btn btn-outline-primary download-pdf" url="https://arxiv.org/pdf/2404.06521v1.pdf" filename="2404.06521v1.pdf">Download PDF</button>

---


**ABSTRACT**  
Intelligent energy management strategies, such as Vehicle-to-Grid (V2G) and Grid-to-Vehicle (G2V) emerge as a potential solution to the Electric Vehicles' (EVs) integration into the energy grid. These strategies promise enhanced grid resilience and economic benefits for both vehicle owners and grid operators. Despite the announced prospective, the adoption of these strategies is still hindered by an array of operational problems. Key among these is the lack of a <b>simulation</b> platform that allows to validate and refine V2G and G2V strategies. Including the development, training, and testing in the context of Energy Communities (ECs) incorporating multiple flexible energy assets. Addressing this gap, first we introduce the EVLearn, a <b>simulation</b> module for researching in both V2G and G2V energy management strategies, that models EVs, their charging infrastructure and associated energy flexibility dynamics; second, this paper integrates EVLearn with the existing CityLearn framework, providing V2G and G2V <b>simulation</b> capabilities into the study of broader energy management strategies. Results validated EVLearn and its integration into CityLearn, where the impact of these strategies is highlighted through a comparative <b>simulation</b> scenario.

{{</citation>}}


## cs.SY (1)



### (1/1 | 248/266) Optimal Controller Realizations against False Data Injections in Cooperative Driving (Mischa Huisman et al., 2024)

{{<citation>}}

Mischa Huisman, Carlos Murguia, Erjen Lefeber, Nathan van de Wouw. (2024)  
**Optimal Controller Realizations against False Data Injections in Cooperative Driving**
<br/>
<button class="copy-to-clipboard" title="Optimal Controller Realizations against False Data Injections in Cooperative Driving" index=248>
  <span class="copy-to-clipboard-item">Copy Title<span>
</button>
<div class="toast toast-copied toast-index-248 align-items-center text-bg-secondary border-0 position-absolute top-0 end-0" role="alert" aria-live="assertive" aria-atomic="true">
  <div class="d-flex">
    <div class="toast-body">
      Copied!
    </div>
  </div>
</div>

---
Primary Category: cs.SY  
Categories: cs-CR, cs-SY, cs.SY, eess-SY  
Keyword Score: 20  
Keywords: Simulation, Simulator  
<a type="button" class="btn btn-outline-primary" href="http://arxiv.org/abs/2404.05361v1" target="_blank" >Paper Link</a>
<button type="button" class="btn btn-outline-primary download-pdf" url="https://arxiv.org/pdf/2404.05361v1.pdf" filename="2404.05361v1.pdf">Download PDF</button>

---


**ABSTRACT**  
To enhance the robustness of cooperative driving to cyberattacks, we study a controller-oriented approach to mitigate the effect of a class of False-Data Injection (FDI) attacks. By reformulating a given dynamic Cooperative Adaptive Cruise Control (CACC) scheme (the base controller), we recognize that the base controller can be represented by a class of new but equivalent controllers (base controller realizations) that exhibits the same platooning behavior with varying robustness in the presence of attacks. We propose a prescriptive synthesis framework where the base controller and the system dynamics are written in new coordinates via an invertible coordinate transformation on the controller state. Because the input-output behavior is invariant under coordinate transformations, the input-output behavior is unaffected (so controller realizations do not change the system's closed-loop performance). However, each base controller realization may require a different combination of sensors. To this end, we obtain the optimal combination of sensors that minimizes the effect of FDI attacks by solving a Linear Matrix Inequality (LMI), while quantifying the FDI's attack impact through reachability analysis. Through <b>simulation</b> studies, we demonstrate that this approach enhances the robustness of cooperative driving, without relying on a detection scheme and maintaining all system properties.

{{</citation>}}


## cs.SI (3)



### (1/3 | 249/266) Modeling the Dynamic Process of Inventions for Reducing Knowledge Search Costs (Haiying Ren et al., 2024)

{{<citation>}}

Haiying Ren, Yuanyuan Song, Rui Peng. (2024)  
**Modeling the Dynamic Process of Inventions for Reducing Knowledge Search Costs**
<br/>
<button class="copy-to-clipboard" title="Modeling the Dynamic Process of Inventions for Reducing Knowledge Search Costs" index=249>
  <span class="copy-to-clipboard-item">Copy Title<span>
</button>
<div class="toast toast-copied toast-index-249 align-items-center text-bg-secondary border-0 position-absolute top-0 end-0" role="alert" aria-live="assertive" aria-atomic="true">
  <div class="d-flex">
    <div class="toast-body">
      Copied!
    </div>
  </div>
</div>

---
Primary Category: cs.SI  
Categories: J-4, cs-SI, cs.SI  
Keyword Score: 20  
Keywords: Simulation, Simulator  
<a type="button" class="btn btn-outline-primary" href="http://arxiv.org/abs/2404.05334v1" target="_blank" >Paper Link</a>
<button type="button" class="btn btn-outline-primary download-pdf" url="https://arxiv.org/pdf/2404.05334v1.pdf" filename="2404.05334v1.pdf">Download PDF</button>

---


**ABSTRACT**  
A knowledge search is a key process for inventions. However, there is inadequate quantitative modeling of dynamic knowledge search processes and associated search costs. In this study, agent-based and complex network methodologies were proposed to quantitatively describe the dynamic process of knowledge search for actual inventions. Prior knowledge networks (PKNs), the search space of historical patents, were constructed, representative search rules were formulated for R&D agents, and measures for knowledge search cost were designed to serve as search objectives. <b>Simulation</b> results in the field of photolithographic technology show that search costs differ significantly with different search rules. Familiarity and Degree rules significantly outperform BFS, DFS and Recency rules in terms of knowledge search costs, and are less affected by the size and density of PKNs. Interestingly, there is no significant correlation between the mean and variance of search costs and patent value, indicating that high-value patents are not particularly difficult to obtain. The implications for innovation theories and R&D practices are drawn from the models and results.

{{</citation>}}


### (2/3 | 250/266) Computational Propaganda Theory and Bot Detection System: Critical Literature Review (Manita Pote, 2024)

{{<citation>}}

Manita Pote. (2024)  
**Computational Propaganda Theory and Bot Detection System: Critical Literature Review**
<br/>
<button class="copy-to-clipboard" title="Computational Propaganda Theory and Bot Detection System: Critical Literature Review" index=250>
  <span class="copy-to-clipboard-item">Copy Title<span>
</button>
<div class="toast toast-copied toast-index-250 align-items-center text-bg-secondary border-0 position-absolute top-0 end-0" role="alert" aria-live="assertive" aria-atomic="true">
  <div class="d-flex">
    <div class="toast-body">
      Copied!
    </div>
  </div>
</div>

---
Primary Category: cs.SI  
Categories: cs-SI, cs.SI  
Keyword Score: 20  
Keywords: Supervised Learning, Botnet Detection  
<a type="button" class="btn btn-outline-primary" href="http://arxiv.org/abs/2404.05240v1" target="_blank" >Paper Link</a>
<button type="button" class="btn btn-outline-primary download-pdf" url="https://arxiv.org/pdf/2404.05240v1.pdf" filename="2404.05240v1.pdf">Download PDF</button>

---


**ABSTRACT**  
According to the classical definition, propaganda is the management of collective attitudes by manipulation of significant symbols. However this definition has changed to computational propaganda, the way manipulation takes place in digital medium. Computational propaganda is the use of algorithms, automation and human curation to purposefully distribute misleading information over social media networks to manipulate public opinion, for political polarization etc. Digital media platforms have introduced new modalities of propaganda such as the use of social <b>bots</b> <b>and</b> state-organized 'troll armies' for social astroturfing to simulate public support or opposition towards a particular topic. Along with this digital media has blurred the line between different forms of propaganda. Hence existing conceptual and epistemological frameworks in propaganda studies need a revision. One of the methods to detect the computational propaganda is to identify automation and <b>bots.</b> <b>Many</b> <b>supervised</b> machine learning based frameworks have been proposed for <b>bot</b> <b>detection</b> but these systems can only identify single accounts, not the coordinated activities of botnets and also these systems depend on the data structure provided by the social media platforms. Similarly, current systems have not included the image features in their detection system. Most of the systems are mainly built for Twitter while there are still uncharted areas of research in other social media platforms. Therefore, there are many unexplored research questions and methods in <b>bot</b> <b>detection</b> systems.

{{</citation>}}


### (3/3 | 251/266) Design of Transit-Centric Multimodal Urban Mobility System with Autonomous Mobility-on-Demand (Xiaotong Guo et al., 2024)

{{<citation>}}

Xiaotong Guo, Jinhua Zhao. (2024)  
**Design of Transit-Centric Multimodal Urban Mobility System with Autonomous Mobility-on-Demand**
<br/>
<button class="copy-to-clipboard" title="Design of Transit-Centric Multimodal Urban Mobility System with Autonomous Mobility-on-Demand" index=251>
  <span class="copy-to-clipboard-item">Copy Title<span>
</button>
<div class="toast toast-copied toast-index-251 align-items-center text-bg-secondary border-0 position-absolute top-0 end-0" role="alert" aria-live="assertive" aria-atomic="true">
  <div class="d-flex">
    <div class="toast-body">
      Copied!
    </div>
  </div>
</div>

---
Primary Category: cs.SI  
Categories: cs-SI, cs.SI, math-OC  
Keyword Score: 6  
Keywords: Multi-modal, Multi-modal  
<a type="button" class="btn btn-outline-primary" href="http://arxiv.org/abs/2404.05885v1" target="_blank" >Paper Link</a>
<button type="button" class="btn btn-outline-primary download-pdf" url="https://arxiv.org/pdf/2404.05885v1.pdf" filename="2404.05885v1.pdf">Download PDF</button>

---


**ABSTRACT**  
This paper addresses the pressing challenge of urban mobility in the context of growing urban populations, changing demand patterns for urban mobility, and emerging technologies like Mobility-on-Demand (MoD) platforms and Autonomous Vehicle (AV). As urban areas swell and demand pattern changes, the integration of Autonomous Mobility-on-Demand (AMoD) systems with existing public transit (PT) networks presents great opportunities to enhancing urban mobility. We propose a novel optimization framework for solving the Transit-Centric <b>Multimodal</b> Urban Mobility with Autonomous Mobility-on-Demand (TCMUM-AMoD) at scale. The system operator (public transit agency) determines the network design and frequency settings of the PT network, fleet sizing and allocations of AMoD system, and the pricing for using the <b>multimodal</b> system with the goal of minimizing passenger disutility. Passengers' mode and route choice behaviors are modeled explicitly using discrete choice models. A first-order approximation algorithm is introduced to solve the problem at scale. Using a case study in Chicago, we showcase the potential to optimize urban mobility across different demand scenarios. To our knowledge, ours is the first paper to jointly optimize transit network design, fleet sizing, and pricing for the <b>multimodal</b> mobility system while considering passengers' mode and route choices.

{{</citation>}}


## physics.comp-ph (1)



### (1/1 | 252/266) Computing Transition Pathways for the Study of Rare Events Using Deep Reinforcement Learning (Bo Lin et al., 2024)

{{<citation>}}

Bo Lin, Yangzheng Zhong, Weiqing Ren. (2024)  
**Computing Transition Pathways for the Study of Rare Events Using Deep Reinforcement Learning**
<br/>
<button class="copy-to-clipboard" title="Computing Transition Pathways for the Study of Rare Events Using Deep Reinforcement Learning" index=252>
  <span class="copy-to-clipboard-item">Copy Title<span>
</button>
<div class="toast toast-copied toast-index-252 align-items-center text-bg-secondary border-0 position-absolute top-0 end-0" role="alert" aria-live="assertive" aria-atomic="true">
  <div class="d-flex">
    <div class="toast-body">
      Copied!
    </div>
  </div>
</div>

---
Primary Category: physics.comp-ph  
Categories: cs-LG, cs-NA, math-NA, physics-comp-ph, physics.comp-ph, stat-ML  
Keyword Score: 13  
Keywords: Benchmarking, Reinforcement Learning  
<a type="button" class="btn btn-outline-primary" href="http://arxiv.org/abs/2404.05905v1" target="_blank" >Paper Link</a>
<button type="button" class="btn btn-outline-primary download-pdf" url="https://arxiv.org/pdf/2404.05905v1.pdf" filename="2404.05905v1.pdf">Download PDF</button>

---


**ABSTRACT**  
Understanding the transition events between metastable states in complex systems is an important subject in the fields of computational physics, chemistry and biology. The transition pathway plays an important role in characterizing the mechanism underlying the transition, for example, in the study of conformational changes of bio-molecules. In fact, computing the transition pathway is a challenging task for complex and high-dimensional systems. In this work, we formulate the path-finding task as a cost minimization problem over a particular path space. The cost function is adapted from the Freidlin-Wentzell action functional so that it is able to deal with rough potential landscapes. The path-finding problem is then solved using a actor-critic method based on the deep deterministic policy gradient algorithm (DDPG). The method incorporates the potential force of the system in the policy for generating episodes and combines physical properties of the system with the learning process for molecular systems. The exploitation and exploration nature of <b>reinforcement</b> <b>learning</b> enables the method to efficiently sample the transition events and compute the globally optimal transition pathway. We illustrate the effectiveness of the proposed method using three <b>benchmark</b> systems including an extended Mueller system and the Lennard-Jones system of seven particles.

{{</citation>}}


## cs.DB (1)



### (1/1 | 253/266) IA2: Leveraging Instance-Aware Index Advisor with Reinforcement Learning for Diverse Workloads (Taiyi Wang et al., 2024)

{{<citation>}}

Taiyi Wang, Eiko Yoneki. (2024)  
**IA2: Leveraging Instance-Aware Index Advisor with Reinforcement Learning for Diverse Workloads**
<br/>
<button class="copy-to-clipboard" title="IA2: Leveraging Instance-Aware Index Advisor with Reinforcement Learning for Diverse Workloads" index=253>
  <span class="copy-to-clipboard-item">Copy Title<span>
</button>
<div class="toast toast-copied toast-index-253 align-items-center text-bg-secondary border-0 position-absolute top-0 end-0" role="alert" aria-live="assertive" aria-atomic="true">
  <div class="d-flex">
    <div class="toast-body">
      Copied!
    </div>
  </div>
</div>

---
Primary Category: cs.DB  
Categories: cs-AI, cs-DB, cs.DB  
Keyword Score: 13  
Keywords: Benchmarking, Reinforcement Learning  
<a type="button" class="btn btn-outline-primary" href="http://arxiv.org/abs/2404.05777v2" target="_blank" >Paper Link</a>
<button type="button" class="btn btn-outline-primary download-pdf" url="https://arxiv.org/pdf/2404.05777v2.pdf" filename="2404.05777v2.pdf">Download PDF</button>

---


**ABSTRACT**  
This study introduces the Instance-Aware Index Advisor (IA2), a novel deep <b>reinforcement</b> <b>learning</b> (DRL)-based approach for optimizing index selection in databases facing large action spaces of potential candidates. IA2 introduces the Twin Delayed Deep Deterministic Policy Gradient - Temporal Difference State-Wise Action Refinery (TD3-TD-SWAR) model, enabling efficient index selection by understanding workload-index dependencies and employing adaptive action masking. This method includes a comprehensive workload model, enhancing its ability to adapt to unseen workloads and ensuring robust performance across diverse database environments. Evaluation on <b>benchmarks</b> such as TPC-H reveals IA2's suggested indexes' performance in enhancing runtime, securing a 40% reduction in runtime for complex TPC-H workloads compared to scenarios without indexes, and delivering a 20% improvement over existing state-of-the-art DRL-based index advisors.

{{</citation>}}


## cs.DS (2)



### (1/2 | 254/266) Even Faster Knapsack via Rectangular Monotone Min-Plus Convolution and Balancing (Karl Bringmann et al., 2024)

{{<citation>}}

Karl Bringmann, Anita Dürr, Adam Polak. (2024)  
**Even Faster Knapsack via Rectangular Monotone Min-Plus Convolution and Balancing**
<br/>
<button class="copy-to-clipboard" title="Even Faster Knapsack via Rectangular Monotone Min-Plus Convolution and Balancing" index=254>
  <span class="copy-to-clipboard-item">Copy Title<span>
</button>
<div class="toast toast-copied toast-index-254 align-items-center text-bg-secondary border-0 position-absolute top-0 end-0" role="alert" aria-live="assertive" aria-atomic="true">
  <div class="d-flex">
    <div class="toast-body">
      Copied!
    </div>
  </div>
</div>

---
Primary Category: cs.DS  
Categories: cs-DS, cs.DS  
Keyword Score: 10  
Keywords: Convolution  
<a type="button" class="btn btn-outline-primary" href="http://arxiv.org/abs/2404.05681v1" target="_blank" >Paper Link</a>
<button type="button" class="btn btn-outline-primary download-pdf" url="https://arxiv.org/pdf/2404.05681v1.pdf" filename="2404.05681v1.pdf">Download PDF</button>

---


**ABSTRACT**  
We present a pseudopolynomial-time algorithm for the Knapsack problem that has running time $\widetilde{O}(n + t\sqrt{p_{\max}})$, where $n$ is the number of items, $t$ is the knapsack capacity, and $p_{\max}$ is the maximum item profit. This improves over the $\widetilde{O}(n + t \, p_{\max})$-time algorithm based on the <b>convolution</b> and prediction technique by Bateni et al.~(STOC 2018). Moreover, we give some evidence, based on a strengthening of the Min-Plus <b>Convolution</b> Hypothesis, that our running time might be optimal. Our algorithm uses two new technical tools, which might be of independent interest. First, we generalize the $\widetilde{O}(n^{1.5})$-time algorithm for bounded monotone min-plus <b>convolution</b> by Chi et al.~(STOC 2022) to the \emph{rectangular} case where the range of entries can be different from the sequence length. Second, we give a reduction from general knapsack instances to \emph{balanced} instances, where all items have nearly the same profit-to-weight ratio, up to a constant factor. Using these techniques, we can also obtain algorithms that run in time $\widetilde{O}(n + OPT\sqrt{w_{\max}})$, $\widetilde{O}(n + (nw_{\max}p_{\max})^{1/3}t^{2/3})$, and $\widetilde{O}(n + (nw_{\max}p_{\max})^{1/3} OPT^{2/3})$, where $OPT$ is the optimal total profit and $w_{\max}$ is the maximum item weight.

{{</citation>}}


### (2/2 | 255/266) Combinatorial Correlation Clustering (Vincent Cohen-Addad et al., 2024)

{{<citation>}}

Vincent Cohen-Addad, David Rasmussen Lolck, Marcin Pilipczuk, Mikkel Thorup, Shuyi Yan, Hanwen Zhang. (2024)  
**Combinatorial Correlation Clustering**
<br/>
<button class="copy-to-clipboard" title="Combinatorial Correlation Clustering" index=255>
  <span class="copy-to-clipboard-item">Copy Title<span>
</button>
<div class="toast toast-copied toast-index-255 align-items-center text-bg-secondary border-0 position-absolute top-0 end-0" role="alert" aria-live="assertive" aria-atomic="true">
  <div class="d-flex">
    <div class="toast-body">
      Copied!
    </div>
  </div>
</div>

---
Primary Category: cs.DS  
Categories: cs-DS, cs.DS  
Keyword Score: 6  
Keywords: Graph, Clustering  
<a type="button" class="btn btn-outline-primary" href="http://arxiv.org/abs/2404.05433v1" target="_blank" >Paper Link</a>
<button type="button" class="btn btn-outline-primary download-pdf" url="https://arxiv.org/pdf/2404.05433v1.pdf" filename="2404.05433v1.pdf">Download PDF</button>

---


**ABSTRACT**  
Correlation <b>Clustering</b> is a classic <b>clustering</b> objective arising in numerous machine learning and data mining applications. Given a <b>graph</b> $G=(V,E)$, the goal is to partition the vertex set into clusters so as to minimize the number of edges between clusters plus the number of edges missing within clusters. The problem is APX-hard and the best known polynomial time approximation factor is 1.73 by Cohen-Addad, Lee, Li, and Newman [FOCS'23]. They use an LP with $|V|^{1/\epsilon^{\Theta(1)}}$ variables for some small $\epsilon$. However, due to the practical relevance of correlation <b>clustering,</b> there has also been great interest in getting more efficient sequential and parallel algorithms. The classic combinatorial pivot algorithm of Ailon, Charikar and Newman [JACM'08] provides a 3-approximation in linear time. Like most other algorithms discussed here, this uses randomization. Recently, Behnezhad, Charikar, Ma and Tan [FOCS'22] presented a $3+\epsilon$-approximate solution for solving problem in a constant number of rounds in the Massively Parallel Computation (MPC) setting. Very recently, Cao, Huang, Su [SODA'24] provided a 2.4-approximation in a polylogarithmic number of rounds in the MPC model and in $\tilde{O}(|E|^{1.5})$ time in the classic sequential setting. They asked whether it is possible to get a better than 3-approximation in near-linear time? We resolve this problem with an efficient combinatorial algorithm providing a drastically better approximation factor. It achieves a $\sim 2-2/13 < 1.847$-approximation in sub-linear ($\tilde O(|V|)$) sequential time or in sub-linear ($\tilde O(|V|)$) space in the streaming setting, and it uses only a constant number of rounds in the MPC model.

{{</citation>}}


## math.OC (3)



### (1/3 | 256/266) Semi-Infinite Programs for Robust Control and Optimization: Efficient Solutions and Extensions to Existence Constraints (Jad Wehbeh et al., 2024)

{{<citation>}}

Jad Wehbeh, Eric C. Kerrigan. (2024)  
**Semi-Infinite Programs for Robust Control and Optimization: Efficient Solutions and Extensions to Existence Constraints**
<br/>
<button class="copy-to-clipboard" title="Semi-Infinite Programs for Robust Control and Optimization: Efficient Solutions and Extensions to Existence Constraints" index=256>
  <span class="copy-to-clipboard-item">Copy Title<span>
</button>
<div class="toast toast-copied toast-index-256 align-items-center text-bg-secondary border-0 position-absolute top-0 end-0" role="alert" aria-live="assertive" aria-atomic="true">
  <div class="d-flex">
    <div class="toast-body">
      Copied!
    </div>
  </div>
</div>

---
Primary Category: math.OC  
Categories: 93C10 (Primary), 90C34, 90C47 (Secondary), cs-SY, eess-SY, math-OC, math.OC  
Keyword Score: 10  
Keywords: Discrete Time, Discrete Time  
<a type="button" class="btn btn-outline-primary" href="http://arxiv.org/abs/2404.05635v1" target="_blank" >Paper Link</a>
<button type="button" class="btn btn-outline-primary download-pdf" url="https://arxiv.org/pdf/2404.05635v1.pdf" filename="2404.05635v1.pdf">Download PDF</button>

---


**ABSTRACT**  
<b>Discrete-time</b> <b>robust</b> optimal control problems generally take a min-max structure over continuous variable spaces, which can be difficult to solve in practice. In this paper, we extend the class of such problems that can be solved through a previously proposed local reduction method to consider those with existence constraints on the uncountable variables. We also consider the possibility of non-unique trajectories that satisfy equality and inequality constraints. Crucially, we show that the problems of interest can be cast into a standard semi-infinite program and demonstrate how to generate optimal uncertainty scenario sets in order to obtain numerical solutions. We also include examples on model predictive control for obstacle avoidance with logical conditions, control with input saturation affected by uncertainty, and optimal parameter estimation to highlight the need for the proposed extension. Our method solves each of the examples considered, producing violation-free and locally optimal solutions.

{{</citation>}}


### (2/3 | 257/266) A High-Performant Multi-Parametric Quadratic Programming Solver (Daniel Arnström et al., 2024)

{{<citation>}}

Daniel Arnström, Daniel Axehill. (2024)  
**A High-Performant Multi-Parametric Quadratic Programming Solver**
<br/>
<button class="copy-to-clipboard" title="A High-Performant Multi-Parametric Quadratic Programming Solver" index=257>
  <span class="copy-to-clipboard-item">Copy Title<span>
</button>
<div class="toast toast-copied toast-index-257 align-items-center text-bg-secondary border-0 position-absolute top-0 end-0" role="alert" aria-live="assertive" aria-atomic="true">
  <div class="d-flex">
    <div class="toast-body">
      Copied!
    </div>
  </div>
</div>

---
Primary Category: math.OC  
Categories: cs-SY, eess-SY, math-OC, math.OC  
Keyword Score: 3  
Keywords: Graph  
<a type="button" class="btn btn-outline-primary" href="http://arxiv.org/abs/2404.05511v1" target="_blank" >Paper Link</a>
<button type="button" class="btn btn-outline-primary download-pdf" url="https://arxiv.org/pdf/2404.05511v1.pdf" filename="2404.05511v1.pdf">Download PDF</button>

---


**ABSTRACT**  
We propose a combinatorial method for computing explicit solutions to multi-parametric quadratic programs, which can be used to compute explicit control laws for linear model predictive control. In contrast to classical methods, which are based on geometrical adjacency, the proposed method is based on combinatorial adjacency. After introducing the notion of combinatorial adjacency, we show that the explicit solution forms a connected <b>graph</b> in terms of it. We then leverage this connectedness to propose an algorithm that computes the explicit solution. The purely combinatorial nature of the algorithm leads to computational advantages since it enables demanding geometrical operations (such as computing facets of polytopes) to be avoided. Compared with classical combinatorial methods, the proposed method requires fewer combinations to be considered by exploiting combinatorial connectedness. We show that an implementation of the proposed method can yield a speedup of about two orders of magnitude compared with state-of-the-art software packages such as MPT and POP.

{{</citation>}}


### (3/3 | 258/266) Convergence analysis of controlled particle systems arising in deep learning: from finite to infinite sample size (Huafu Liao et al., 2024)

{{<citation>}}

Huafu Liao, Alpár R. Mészáros, Chenchen Mou, Chao Zhou. (2024)  
**Convergence analysis of controlled particle systems arising in deep learning: from finite to infinite sample size**
<br/>
<button class="copy-to-clipboard" title="Convergence analysis of controlled particle systems arising in deep learning: from finite to infinite sample size" index=258>
  <span class="copy-to-clipboard-item">Copy Title<span>
</button>
<div class="toast toast-copied toast-index-258 align-items-center text-bg-secondary border-0 position-absolute top-0 end-0" role="alert" aria-live="assertive" aria-atomic="true">
  <div class="d-flex">
    <div class="toast-body">
      Copied!
    </div>
  </div>
</div>

---
Primary Category: math.OC  
Categories: 49N80, 65C35, 49L12, 62M45, cs-LG, math-OC, math-PR, math.OC, stat-ML  
Keyword Score: 3  
Keywords: Sample Size  
<a type="button" class="btn btn-outline-primary" href="http://arxiv.org/abs/2404.05185v1" target="_blank" >Paper Link</a>
<button type="button" class="btn btn-outline-primary download-pdf" url="https://arxiv.org/pdf/2404.05185v1.pdf" filename="2404.05185v1.pdf">Download PDF</button>

---


**ABSTRACT**  
This paper deals with a class of neural SDEs and studies the limiting behavior of the associated <b>sampled</b> <b>optimal</b> control problems as the <b>sample</b> <b>size</b> grows to infinity. The neural SDEs with N <b>samples</b> <b>can</b> be linked to the N-particle systems with centralized control. We analyze the Hamilton--Jacobi--Bellman equation corresponding to the N-particle system and establish regularity results which are uniform in N. The uniform regularity estimates are obtained by the stochastic maximum principle and the analysis of a backward stochastic Riccati equation. Using these uniform regularity results, we show the convergence of the minima of objective functionals and optimal parameters of the neural SDEs as the <b>sample</b> <b>size</b> N tends to infinity. The limiting objects can be identified with suitable functions defined on the Wasserstein space of Borel probability measures. Furthermore, quantitative algebraic convergence rates are also obtained.

{{</citation>}}


## math.NA (1)



### (1/1 | 259/266) Tensor neural networks for high-dimensional Fokker-Planck equations (Taorui Wang et al., 2024)

{{<citation>}}

Taorui Wang, Zheyuan Hu, Kenji Kawaguchi, Zhongqiang Zhang, George Em Karniadakis. (2024)  
**Tensor neural networks for high-dimensional Fokker-Planck equations**
<br/>
<button class="copy-to-clipboard" title="Tensor neural networks for high-dimensional Fokker-Planck equations" index=259>
  <span class="copy-to-clipboard-item">Copy Title<span>
</button>
<div class="toast toast-copied toast-index-259 align-items-center text-bg-secondary border-0 position-absolute top-0 end-0" role="alert" aria-live="assertive" aria-atomic="true">
  <div class="d-flex">
    <div class="toast-body">
      Copied!
    </div>
  </div>
</div>

---
Primary Category: math.NA  
Categories: cs-NA, math-NA, math.NA  
Keyword Score: 10  
Keywords: Stochastic Gradient Descent  
<a type="button" class="btn btn-outline-primary" href="http://arxiv.org/abs/2404.05615v1" target="_blank" >Paper Link</a>
<button type="button" class="btn btn-outline-primary download-pdf" url="https://arxiv.org/pdf/2404.05615v1.pdf" filename="2404.05615v1.pdf">Download PDF</button>

---


**ABSTRACT**  
We solve high-dimensional steady-state Fokker-Planck equations on the whole space by applying tensor neural networks. The tensor networks are a tensor product of one-dimensional feedforward networks or a linear combination of several selected radial basis functions. The use of tensor feedforward networks allows us to efficiently exploit auto-differentiation in major Python packages while using radial basis functions can fully avoid auto-differentiation, which is rather expensive in high dimensions. We then use the physics-informed neural networks and <b>stochastic</b> <b>gradient</b> <b>descent</b> methods to learn the tensor networks. One essential step is to determine a proper truncated bounded domain or numerical support for the Fokker-Planck equation. To better train the tensor radial basis function networks, we impose some constraints on parameters, which lead to relatively high accuracy. We demonstrate numerically that the tensor neural networks in physics-informed machine learning are efficient for steady-state Fokker-Planck equations from two to ten dimensions.

{{</citation>}}


## cs.GT (1)



### (1/1 | 260/266) Fair Lotteries for Participatory Budgeting (Haris Aziz et al., 2024)

{{<citation>}}

Haris Aziz, Xinhang Lu, Mashbat Suzuki, Jeremy Vollen, Toby Walsh. (2024)  
**Fair Lotteries for Participatory Budgeting**
<br/>
<button class="copy-to-clipboard" title="Fair Lotteries for Participatory Budgeting" index=260>
  <span class="copy-to-clipboard-item">Copy Title<span>
</button>
<div class="toast toast-copied toast-index-260 align-items-center text-bg-secondary border-0 position-absolute top-0 end-0" role="alert" aria-live="assertive" aria-atomic="true">
  <div class="d-flex">
    <div class="toast-body">
      Copied!
    </div>
  </div>
</div>

---
Primary Category: cs.GT  
Categories: cs-GT, cs.GT  
Keyword Score: 10  
Keywords: Fairness  
<a type="button" class="btn btn-outline-primary" href="http://arxiv.org/abs/2404.05198v2" target="_blank" >Paper Link</a>
<button type="button" class="btn btn-outline-primary download-pdf" url="https://arxiv.org/pdf/2404.05198v2.pdf" filename="2404.05198v2.pdf">Download PDF</button>

---


**ABSTRACT**  
In pursuit of participatory budgeting (PB) outcomes with broader <b>fairness</b> guarantees, we initiate the study of lotteries over discrete PB outcomes. As the projects have heterogeneous costs, the amount spent may not be equal ex ante and ex post. To address this, we develop a technique to bound the amount by which the ex-post spend differs from the ex-ante spend -- the property is termed budget balanced up to one project (BB1). With respect to <b>fairness,</b> we take a best-of-both-worlds perspective, seeking outcomes that are both ex-ante and ex-post fair. Towards this goal, we initiate a study of ex-ante <b>fairness</b> properties in PB, including Individual Fair Share (IFS), Unanimous Fair Share (UFS) and their stronger variants, as well as Group Fair Share (GFS). We show several incompatibility results between these ex-ante <b>fairness</b> notions and existing ex-post concepts based on justified representation. One of our main contributions is a randomized algorithm which simultaneously satisfies ex-ante Strong UFS, ex-post full justified representation (FJR) and ex-post BB1 for PB with binary utilities.

{{</citation>}}


## physics.geo-ph (1)



### (1/1 | 261/266) Predicting the Geothermal Gradient in Colombia: a Machine Learning Approach (Juan C. Mej ıa-Fragoso et al., 2024)

{{<citation>}}

Juan C. Mej ıa-Fragoso, Manuel A. Florez, Rocıo Bernal-Olaya. (2024)  
**Predicting the Geothermal Gradient in Colombia: a Machine Learning Approach**
<br/>
<button class="copy-to-clipboard" title="Predicting the Geothermal Gradient in Colombia: a Machine Learning Approach" index=261>
  <span class="copy-to-clipboard-item">Copy Title<span>
</button>
<div class="toast toast-copied toast-index-261 align-items-center text-bg-secondary border-0 position-absolute top-0 end-0" role="alert" aria-live="assertive" aria-atomic="true">
  <div class="d-flex">
    <div class="toast-body">
      Copied!
    </div>
  </div>
</div>

---
Primary Category: physics.geo-ph  
Categories: cs-LG, physics-geo-ph, physics.geo-ph  
Keyword Score: 10  
Keywords: Supervised Learning  
<a type="button" class="btn btn-outline-primary" href="http://arxiv.org/abs/2404.05184v1" target="_blank" >Paper Link</a>
<button type="button" class="btn btn-outline-primary download-pdf" url="https://arxiv.org/pdf/2404.05184v1.pdf" filename="2404.05184v1.pdf">Download PDF</button>

---


**ABSTRACT**  
Accurate determination of the geothermal gradient is critical for assessing the geothermal energy potential of a given region. Of particular interest is the case of Colombia, a country with abundant geothermal resources. A history of active oil and gas exploration and production has left drilled boreholes in different geological settings, providing direct measurements of the geothermal gradient. Unfortunately, large regions of the country where geothermal resources might exist lack such measurements. Indirect geophysical measurements are costly and difficult to perform at regional scales. Computational thermal models could be constructed, but they require very detailed knowledge of the underlying geology and uniform sampling of subsurface temperatures to be well-constrained. We present an alternative approach that leverages recent advances in <b>supervised</b> machine learning and available direct measurements to predict the geothermal gradient in regions where only global-scale geophysical datasets and course geological knowledge are available. We find that a Gradient Boosted Regression Tree algorithm yields optimal predictions and extensively validate the trained model. We show that predictions of our model are within 12\% accuracy and that independent measurements performed by other authors agree well with our model. Finnally, we present a geothermal gradient map for Colombia that highlights regions where futher exploration and data collection should be performed.

{{</citation>}}


## cs.NE (1)



### (1/1 | 262/266) Minimum variance threshold for epsilon-lexicase selection (Guilherme Seidyo Imai Aldeia et al., 2024)

{{<citation>}}

Guilherme Seidyo Imai Aldeia, Fabricio Olivetti de Franca, William G. La Cava. (2024)  
**Minimum variance threshold for epsilon-lexicase selection**
<br/>
<button class="copy-to-clipboard" title="Minimum variance threshold for epsilon-lexicase selection" index=262>
  <span class="copy-to-clipboard-item">Copy Title<span>
</button>
<div class="toast toast-copied toast-index-262 align-items-center text-bg-secondary border-0 position-absolute top-0 end-0" role="alert" aria-live="assertive" aria-atomic="true">
  <div class="d-flex">
    <div class="toast-body">
      Copied!
    </div>
  </div>
</div>

---
Primary Category: cs.NE  
Categories: cs-NE, cs.NE  
Keyword Score: 5  
Keywords: Black Box  
<a type="button" class="btn btn-outline-primary" href="http://arxiv.org/abs/2404.05909v1" target="_blank" >Paper Link</a>
<button type="button" class="btn btn-outline-primary download-pdf" url="https://arxiv.org/pdf/2404.05909v1.pdf" filename="2404.05909v1.pdf">Download PDF</button>

---


**ABSTRACT**  
Parent selection plays an important role in evolutionary algorithms, and many strategies exist to select the parent pool before breeding the next generation. Methods often rely on average error over the entire dataset as a criterion to select the parents, which can lead to an information loss due to aggregation of all test cases. Under epsilon-lexicase selection, the population goes to a selection pool that is iteratively reduced by using each test individually, discarding individuals with an error higher than the elite error plus the median absolute deviation (MAD) of errors for that particular test case. In an attempt to better capture differences in performance of individuals on cases, we propose a new criteria that splits errors into two partitions that minimize the total variance within partitions. Our method was embedded into the FEAT symbolic regression algorithm, and evaluated with the SRBench framework, containing 122 <b>black-box</b> <b>synthetic</b> and real-world regression problems. The empirical results show a better performance of our approach compared to traditional epsilon-lexicase selection in the real-world datasets while showing equivalent performance on the synthetic dataset.

{{</citation>}}


## cs.MS (1)



### (1/1 | 263/266) Predefined Software Environment Runtimes As A Measure For Reproducibility (Aaruni Kaushik, 2024)

{{<citation>}}

Aaruni Kaushik. (2024)  
**Predefined Software Environment Runtimes As A Measure For Reproducibility**
<br/>
<button class="copy-to-clipboard" title="Predefined Software Environment Runtimes As A Measure For Reproducibility" index=263>
  <span class="copy-to-clipboard-item">Copy Title<span>
</button>
<div class="toast toast-copied toast-index-263 align-items-center text-bg-secondary border-0 position-absolute top-0 end-0" role="alert" aria-live="assertive" aria-atomic="true">
  <div class="d-flex">
    <div class="toast-body">
      Copied!
    </div>
  </div>
</div>

---
Primary Category: cs.MS  
Categories: cs-MS, cs.MS  
Keyword Score: 5  
Keywords: Geometry  
<a type="button" class="btn btn-outline-primary" href="http://arxiv.org/abs/2404.05563v1" target="_blank" >Paper Link</a>
<button type="button" class="btn btn-outline-primary download-pdf" url="https://arxiv.org/pdf/2404.05563v1.pdf" filename="2404.05563v1.pdf">Download PDF</button>

---


**ABSTRACT**  
As part of Mathematical Research Data Initiative (MaRDI), we have developed a way to preserve a software package into an easy to deploy and use sandbox environment we call a "runtime", via a program we developed called MaPS : MaRDI Packaging System. The program relies on Linux user namespaces to isolate a library environment from the host system, making the sandboxed software reproducible on other systems, with minimal effort. Moreover an overlay filesystem makes local edits persistent. This project will aid reproducibility efforts of research papers: both mathematical and from other disciplines. As a proof of concept, we provide runtimes for the OSCAR Computer Algebra System, polymake software for research in polyhedral <b>geometry,</b> and VIBRANT Virus Identification By iteRative ANnoTation. The software is in a prerelease state: the interface for creating, deploying, and executing runtimes is final, and an interface for easily publishing runtimes is under active development. We thus propose publishing predefined, distributable software environment runtimes along with research papers in an effort to make research with software based results reproducible.

{{</citation>}}


## cs.GR (1)



### (1/1 | 264/266) Nanouniverse: Virtual Instancing of Structural Detail and Adaptive Shell Mapping (Ruwayda Alharbi et al., 2024)

{{<citation>}}

Ruwayda Alharbi, Ondřej Strnad, Markus Hadwiger, Ivan Viola. (2024)  
**Nanouniverse: Virtual Instancing of Structural Detail and Adaptive Shell Mapping**
<br/>
<button class="copy-to-clipboard" title="Nanouniverse: Virtual Instancing of Structural Detail and Adaptive Shell Mapping" index=264>
  <span class="copy-to-clipboard-item">Copy Title<span>
</button>
<div class="toast toast-copied toast-index-264 align-items-center text-bg-secondary border-0 position-absolute top-0 end-0" role="alert" aria-live="assertive" aria-atomic="true">
  <div class="d-flex">
    <div class="toast-body">
      Copied!
    </div>
  </div>
</div>

---
Primary Category: cs.GR  
Categories: cs-GR, cs.GR  
Keyword Score: 5  
Keywords: Geometry  
<a type="button" class="btn btn-outline-primary" href="http://arxiv.org/abs/2404.05116v1" target="_blank" >Paper Link</a>
<button type="button" class="btn btn-outline-primary download-pdf" url="https://arxiv.org/pdf/2404.05116v1.pdf" filename="2404.05116v1.pdf">Download PDF</button>

---


**ABSTRACT**  
Rendering huge biological scenes with atomistic detail presents a significant challenge in molecular visualization due to the memory limitations inherent in traditional rendering approaches. In this paper, we propose a novel method for the interactive rendering of massive molecular scenes based on hardware-accelerated ray tracing. Our approach circumvents GPU memory constraints by introducing virtual instantiation of full-detail scene elements. Using instancing significantly reduces memory consumption while preserving the full atomistic detail of scenes comprising trillions of atoms, with interactive rendering performance and completely free user exploration. We utilize coarse meshes as proxy geometries to approximate the overall shape of biological compartments, and access all atomistic detail dynamically during ray tracing. We do this via a novel adaptive technique utilizing a volumetric shell layer of prisms extruded around proxy <b>geometry</b> triangles, and a virtual volume grid for the interior of each compartment. Our algorithm scales to enormous molecular scenes with minimal memory consumption and the potential to accommodate even larger scenes. Our method also supports advanced effects such as clipping planes and animations. We demonstrate the efficiency and scalability of our approach by rendering tens of instances of Red Blood Cell and SARS-CoV-2 models theoretically containing more than 20 trillion atoms.

{{</citation>}}


## cs.PL (1)



### (1/1 | 265/266) Three Subtyping Algorithms for Binary Session Types and their Complexity Analyses (Thien Udomsrirungruang et al., 2024)

{{<citation>}}

Thien Udomsrirungruang, Nobuko Yoshida. (2024)  
**Three Subtyping Algorithms for Binary Session Types and their Complexity Analyses**
<br/>
<button class="copy-to-clipboard" title="Three Subtyping Algorithms for Binary Session Types and their Complexity Analyses" index=265>
  <span class="copy-to-clipboard-item">Copy Title<span>
</button>
<div class="toast toast-copied toast-index-265 align-items-center text-bg-secondary border-0 position-absolute top-0 end-0" role="alert" aria-live="assertive" aria-atomic="true">
  <div class="d-flex">
    <div class="toast-body">
      Copied!
    </div>
  </div>
</div>

---
Primary Category: cs.PL  
Categories: cs-PL, cs.PL  
Keyword Score: 3  
Keywords: Graph  
<a type="button" class="btn btn-outline-primary" href="http://arxiv.org/abs/2404.05480v1" target="_blank" >Paper Link</a>
<button type="button" class="btn btn-outline-primary download-pdf" url="https://arxiv.org/pdf/2404.05480v1.pdf" filename="2404.05480v1.pdf">Download PDF</button>

---


**ABSTRACT**  
Session types are a type discipline for describing and specifying communication behaviours of concurrent processes. Session subtyping, firstly introduced by Gay and Hole, is widely used for enlarging typability of session programs. This paper gives the complexity analysis of three algorithms for subtyping of synchronous binary session types. First, we analyse the complexity of the algorithm from the original paper, which is based on an inductive tree search. We then introduce its optimised version, which improves the complexity, but is still exponential against the size of the two types. Finally, we propose a new quadratic algorithm based on a <b>graph</b> search using the concept of XYZW-simulation, recently introduced by Silva et al.

{{</citation>}}


## math.CO (1)



### (1/1 | 266/266) Association schemes arising from non-weakly regular bent functions (Yadi Wei et al., 2024)

{{<citation>}}

Yadi Wei, Jiaxin Wang, Fang-Wei Fu. (2024)  
**Association schemes arising from non-weakly regular bent functions**
<br/>
<button class="copy-to-clipboard" title="Association schemes arising from non-weakly regular bent functions" index=266>
  <span class="copy-to-clipboard-item">Copy Title<span>
</button>
<div class="toast toast-copied toast-index-266 align-items-center text-bg-secondary border-0 position-absolute top-0 end-0" role="alert" aria-live="assertive" aria-atomic="true">
  <div class="d-flex">
    <div class="toast-body">
      Copied!
    </div>
  </div>
</div>

---
Primary Category: math.CO  
Categories: cs-IT, math-CO, math-IT, math.CO  
Keyword Score: 3  
Keywords: Graph  
<a type="button" class="btn btn-outline-primary" href="http://arxiv.org/abs/2404.05251v1" target="_blank" >Paper Link</a>
<button type="button" class="btn btn-outline-primary download-pdf" url="https://arxiv.org/pdf/2404.05251v1.pdf" filename="2404.05251v1.pdf">Download PDF</button>

---


**ABSTRACT**  
Association schemes play an important role in algebraic combinatorics and have important applications in coding theory, <b>graph</b> theory and design theory. The methods to construct association schemes by using bent functions have been extensively studied. Recently, in [13], {\"O}zbudak and Pelen constructed infinite families of symmetric association schemes of classes $5$ and $6$ by using ternary non-weakly regular bent functions.They also stated that constructing $2p$-class association schemes from $p$-ary non-weakly regular bent functions is an interesting problem, where $p>3$ is an odd prime. In this paper, using non-weakly regular bent functions, we construct infinite families of symmetric association schemes of classes $2p$, $(2p+1)$ and $\frac{3p+1}{2}$ for any odd prime $p$. Fusing those association schemes, we also obtain $t$-class symmetric association schemes, where $t=4,5,6,7$. In addition, we give the sufficient and necessary conditions for the partitions $P$, $D$, $T$, $U$ and $V$ (defined in this paper) to induce symmetric association schemes.

{{</citation>}}
