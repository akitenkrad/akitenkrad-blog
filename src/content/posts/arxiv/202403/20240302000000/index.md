---
draft: false
title: "arXiv @ 2024.03.02"
date: 2024-03-02
author: "akitenkrad"
description: ""
tags: ["arXiv", "Published:2024"]
menu:
  sidebar:
    name: "arXiv @ 2024.03.02"
    identifier: arxiv_20240302
    parent: 202403_arxiv
    weight: 10
math: true
---

<figure style="border:none; width:100%; display:flex; justify-content: center">
    <iframe src="pie.html" width=900 height=620 style="border:none"></iframe>
</figure>


## Primary Categories

- [cond-mat.mtrl-sci (2)](#cond-matmtrl-sci-2)
- [cs.AI (6)](#csai-6)
- [cs.AR (3)](#csar-3)
- [cs.CC (1)](#cscc-1)
- [cs.CE (2)](#csce-2)
- [cs.CL (48)](#cscl-48)
- [cs.CR (11)](#cscr-11)
- [cs.CV (69)](#cscv-69)
- [cs.CY (7)](#cscy-7)
- [cs.DC (2)](#csdc-2)
- [cs.DM (1)](#csdm-1)
- [cs.DS (2)](#csds-2)
- [cs.GR (1)](#csgr-1)
- [cs.GT (2)](#csgt-2)
- [cs.HC (8)](#cshc-8)
- [cs.IR (8)](#csir-8)
- [cs.IT (6)](#csit-6)
- [cs.LG (68)](#cslg-68)
- [cs.LO (5)](#cslo-5)
- [cs.MA (1)](#csma-1)
- [cs.NE (2)](#csne-2)
- [cs.NI (4)](#csni-4)
- [cs.RO (13)](#csro-13)
- [cs.SD (2)](#cssd-2)
- [cs.SE (8)](#csse-8)
- [cs.SI (4)](#cssi-4)
- [eess.AS (2)](#eessas-2)
- [eess.IV (12)](#eessiv-12)
- [eess.SP (1)](#eesssp-1)
- [eess.SY (5)](#eesssy-5)
- [math.AP (1)](#mathap-1)
- [math.CO (3)](#mathco-3)
- [math.NA (3)](#mathna-3)
- [math.OC (2)](#mathoc-2)
- [physics.soc-ph (1)](#physicssoc-ph-1)
- [q-bio.BM (1)](#q-biobm-1)
- [q-bio.NC (2)](#q-bionc-2)
- [quant-ph (1)](#quant-ph-1)
- [stat.ML (1)](#statml-1)

## Keywords

<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th>keyword</th>
      <th>cs.CL</th>
      <th>cs.CR</th>
      <th>cs.CV</th>
      <th>cs.LG</th>
      <th>cs.RO</th>
      <th>eess.IV</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td>Active Learning</td>
      <td></td>
      <td></td>
      <td>1</td>
      <td></td>
      <td></td>
      <td></td>
    </tr>
    <tr>
      <td>Adversarial Attack</td>
      <td></td>
      <td></td>
      <td></td>
      <td>2</td>
      <td></td>
      <td></td>
    </tr>
    <tr>
      <td>Adversarial Learning</td>
      <td>1</td>
      <td>1</td>
      <td></td>
      <td>2</td>
      <td></td>
      <td>1</td>
    </tr>
    <tr>
      <td>Anomaly Detection</td>
      <td></td>
      <td></td>
      <td>3</td>
      <td>2</td>
      <td></td>
      <td></td>
    </tr>
    <tr>
      <td>Autoencoder</td>
      <td></td>
      <td></td>
      <td>1</td>
      <td>1</td>
      <td></td>
      <td></td>
    </tr>
    <tr>
      <td>Automatic Evaluation</td>
      <td>1</td>
      <td></td>
      <td></td>
      <td></td>
      <td></td>
      <td></td>
    </tr>
    <tr>
      <td>Automatic Speech Recognition</td>
      <td>4</td>
      <td></td>
      <td></td>
      <td></td>
      <td></td>
      <td></td>
    </tr>
    <tr>
      <td>BERT</td>
      <td>1</td>
      <td></td>
      <td></td>
      <td></td>
      <td></td>
      <td></td>
    </tr>
    <tr>
      <td>BERTScore</td>
      <td>1</td>
      <td></td>
      <td></td>
      <td></td>
      <td></td>
      <td></td>
    </tr>
    <tr>
      <td>BLEU</td>
      <td>2</td>
      <td></td>
      <td></td>
      <td></td>
      <td></td>
      <td></td>
    </tr>
    <tr>
      <td>Bandit Algorithm</td>
      <td></td>
      <td></td>
      <td>1</td>
      <td>3</td>
      <td></td>
      <td></td>
    </tr>
    <tr>
      <td>Benchmarking</td>
      <td>8</td>
      <td>1</td>
      <td>19</td>
      <td>13</td>
      <td></td>
      <td>1</td>
    </tr>
    <tr>
      <td>Black Box</td>
      <td>1</td>
      <td></td>
      <td>1</td>
      <td>1</td>
      <td></td>
      <td></td>
    </tr>
    <tr>
      <td>ChatGPT</td>
      <td>1</td>
      <td></td>
      <td></td>
      <td></td>
      <td></td>
      <td></td>
    </tr>
    <tr>
      <td>Chatbot</td>
      <td></td>
      <td></td>
      <td></td>
      <td>1</td>
      <td></td>
      <td></td>
    </tr>
    <tr>
      <td>Clustering</td>
      <td></td>
      <td>2</td>
      <td>2</td>
      <td>2</td>
      <td></td>
      <td></td>
    </tr>
    <tr>
      <td>Code Generation</td>
      <td></td>
      <td></td>
      <td></td>
      <td>1</td>
      <td></td>
      <td></td>
    </tr>
    <tr>
      <td>Common-sense Reasoning</td>
      <td></td>
      <td></td>
      <td>1</td>
      <td></td>
      <td></td>
      <td></td>
    </tr>
    <tr>
      <td>Continual Learning</td>
      <td></td>
      <td></td>
      <td></td>
      <td>1</td>
      <td></td>
      <td></td>
    </tr>
    <tr>
      <td>Contrastive Learning</td>
      <td></td>
      <td>1</td>
      <td>4</td>
      <td></td>
      <td></td>
      <td></td>
    </tr>
    <tr>
      <td>Convolution</td>
      <td></td>
      <td></td>
      <td>8</td>
      <td>1</td>
      <td></td>
      <td>2</td>
    </tr>
    <tr>
      <td>Convolutional Neural Network</td>
      <td></td>
      <td></td>
      <td>4</td>
      <td>2</td>
      <td></td>
      <td>2</td>
    </tr>
    <tr>
      <td>Counter-factual</td>
      <td>1</td>
      <td></td>
      <td>1</td>
      <td>4</td>
      <td></td>
      <td></td>
    </tr>
    <tr>
      <td>Curriculum Learning</td>
      <td>1</td>
      <td></td>
      <td></td>
      <td>1</td>
      <td></td>
      <td></td>
    </tr>
    <tr>
      <td>Data Augmentation</td>
      <td></td>
      <td></td>
      <td>2</td>
      <td>1</td>
      <td></td>
      <td></td>
    </tr>
    <tr>
      <td>Differential Privacy</td>
      <td></td>
      <td></td>
      <td></td>
      <td>2</td>
      <td></td>
      <td></td>
    </tr>
    <tr>
      <td>Diffusion Model</td>
      <td>1</td>
      <td></td>
      <td>5</td>
      <td>3</td>
      <td></td>
      <td>3</td>
    </tr>
    <tr>
      <td>Distribution Shift</td>
      <td></td>
      <td></td>
      <td>2</td>
      <td>2</td>
      <td></td>
      <td></td>
    </tr>
    <tr>
      <td>Emotion Recognition</td>
      <td>1</td>
      <td></td>
      <td></td>
      <td></td>
      <td></td>
      <td></td>
    </tr>
    <tr>
      <td>Face Recognition</td>
      <td></td>
      <td></td>
      <td>1</td>
      <td></td>
      <td></td>
      <td></td>
    </tr>
    <tr>
      <td>Fairness</td>
      <td>1</td>
      <td></td>
      <td>1</td>
      <td>1</td>
      <td></td>
      <td></td>
    </tr>
    <tr>
      <td>Federated Learning</td>
      <td></td>
      <td>1</td>
      <td>1</td>
      <td>8</td>
      <td></td>
      <td></td>
    </tr>
    <tr>
      <td>Few-shot</td>
      <td>1</td>
      <td></td>
      <td>3</td>
      <td>1</td>
      <td></td>
      <td></td>
    </tr>
    <tr>
      <td>Fine-tuning</td>
      <td>8</td>
      <td>2</td>
      <td>8</td>
      <td>14</td>
      <td>1</td>
      <td></td>
    </tr>
    <tr>
      <td>Foundation Model</td>
      <td></td>
      <td></td>
      <td>5</td>
      <td>2</td>
      <td>1</td>
      <td></td>
    </tr>
    <tr>
      <td>GPT</td>
      <td>6</td>
      <td></td>
      <td>1</td>
      <td></td>
      <td></td>
      <td></td>
    </tr>
    <tr>
      <td>GPT-3</td>
      <td>1</td>
      <td></td>
      <td>1</td>
      <td></td>
      <td></td>
      <td></td>
    </tr>
    <tr>
      <td>GPT-3.5</td>
      <td>1</td>
      <td></td>
      <td></td>
      <td></td>
      <td></td>
      <td></td>
    </tr>
    <tr>
      <td>GPT-4</td>
      <td>5</td>
      <td></td>
      <td></td>
      <td></td>
      <td></td>
      <td></td>
    </tr>
    <tr>
      <td>Gaussian Process</td>
      <td></td>
      <td></td>
      <td></td>
      <td>1</td>
      <td></td>
      <td></td>
    </tr>
    <tr>
      <td>Gemini</td>
      <td></td>
      <td></td>
      <td>1</td>
      <td></td>
      <td></td>
      <td></td>
    </tr>
    <tr>
      <td>Generative AI</td>
      <td>1</td>
      <td></td>
      <td></td>
      <td>1</td>
      <td></td>
      <td>1</td>
    </tr>
    <tr>
      <td>Generative Adversarial Network</td>
      <td>1</td>
      <td></td>
      <td>1</td>
      <td>4</td>
      <td></td>
      <td>4</td>
    </tr>
    <tr>
      <td>Geometry</td>
      <td></td>
      <td></td>
      <td>1</td>
      <td>2</td>
      <td>1</td>
      <td>1</td>
    </tr>
    <tr>
      <td>Graph</td>
      <td></td>
      <td>1</td>
      <td>5</td>
      <td>6</td>
      <td>1</td>
      <td>1</td>
    </tr>
    <tr>
      <td>Graph Attention Networks</td>
      <td></td>
      <td></td>
      <td></td>
      <td>1</td>
      <td></td>
      <td></td>
    </tr>
    <tr>
      <td>Graph Neural Network</td>
      <td></td>
      <td>2</td>
      <td>2</td>
      <td>5</td>
      <td></td>
      <td></td>
    </tr>
    <tr>
      <td>Grounding</td>
      <td>2</td>
      <td></td>
      <td></td>
      <td>1</td>
      <td></td>
      <td></td>
    </tr>
    <tr>
      <td>Human Intervention</td>
      <td></td>
      <td></td>
      <td></td>
      <td></td>
      <td>1</td>
      <td></td>
    </tr>
    <tr>
      <td>Image2text</td>
      <td></td>
      <td></td>
      <td>1</td>
      <td></td>
      <td></td>
      <td></td>
    </tr>
    <tr>
      <td>In-context Learning</td>
      <td>2</td>
      <td>1</td>
      <td></td>
      <td>6</td>
      <td></td>
      <td></td>
    </tr>
    <tr>
      <td>Information Retrieval</td>
      <td>1</td>
      <td></td>
      <td>2</td>
      <td></td>
      <td></td>
      <td></td>
    </tr>
    <tr>
      <td>Instruction Tuning</td>
      <td></td>
      <td></td>
      <td>1</td>
      <td></td>
      <td></td>
      <td></td>
    </tr>
    <tr>
      <td>Knowledge Distillation</td>
      <td>2</td>
      <td></td>
      <td>6</td>
      <td>3</td>
      <td></td>
      <td></td>
    </tr>
    <tr>
      <td>Knowledge Graph</td>
      <td></td>
      <td></td>
      <td>3</td>
      <td></td>
      <td></td>
      <td></td>
    </tr>
    <tr>
      <td>Knowledge Transfer</td>
      <td></td>
      <td></td>
      <td>2</td>
      <td></td>
      <td></td>
      <td></td>
    </tr>
    <tr>
      <td>LLaMA</td>
      <td>1</td>
      <td></td>
      <td></td>
      <td>2</td>
      <td></td>
      <td></td>
    </tr>
    <tr>
      <td>Large Language Model</td>
      <td>44</td>
      <td>7</td>
      <td>8</td>
      <td>13</td>
      <td>1</td>
      <td></td>
    </tr>
    <tr>
      <td>Low-Resource</td>
      <td>2</td>
      <td></td>
      <td></td>
      <td></td>
      <td></td>
      <td></td>
    </tr>
    <tr>
      <td>Machine Unlearning</td>
      <td></td>
      <td></td>
      <td></td>
      <td>1</td>
      <td></td>
      <td></td>
    </tr>
    <tr>
      <td>Massive Multitask Language Understanding (MMLU)</td>
      <td>1</td>
      <td></td>
      <td></td>
      <td></td>
      <td></td>
      <td></td>
    </tr>
    <tr>
      <td>Mathematical Reasoning</td>
      <td>1</td>
      <td></td>
      <td></td>
      <td></td>
      <td></td>
      <td></td>
    </tr>
    <tr>
      <td>Message-Passing</td>
      <td></td>
      <td></td>
      <td>1</td>
      <td></td>
      <td></td>
      <td></td>
    </tr>
    <tr>
      <td>Meta Learning</td>
      <td></td>
      <td></td>
      <td></td>
      <td>2</td>
      <td></td>
      <td></td>
    </tr>
    <tr>
      <td>Mistral</td>
      <td>3</td>
      <td></td>
      <td></td>
      <td></td>
      <td></td>
      <td></td>
    </tr>
    <tr>
      <td>Multi-modal</td>
      <td>4</td>
      <td></td>
      <td>21</td>
      <td>1</td>
      <td>3</td>
      <td></td>
    </tr>
    <tr>
      <td>Multiple Instance Learning</td>
      <td></td>
      <td></td>
      <td>1</td>
      <td></td>
      <td></td>
      <td></td>
    </tr>
    <tr>
      <td>Mutual Information</td>
      <td>3</td>
      <td></td>
      <td></td>
      <td>1</td>
      <td></td>
      <td>1</td>
    </tr>
    <tr>
      <td>Natural Language Understanding</td>
      <td>1</td>
      <td>1</td>
      <td></td>
      <td></td>
      <td></td>
      <td></td>
    </tr>
    <tr>
      <td>Neural Machine Translation</td>
      <td>2</td>
      <td></td>
      <td></td>
      <td></td>
      <td></td>
      <td></td>
    </tr>
    <tr>
      <td>Node Classification</td>
      <td></td>
      <td></td>
      <td></td>
      <td>1</td>
      <td></td>
      <td></td>
    </tr>
    <tr>
      <td>Object Detection</td>
      <td></td>
      <td></td>
      <td>9</td>
      <td></td>
      <td>1</td>
      <td></td>
    </tr>
    <tr>
      <td>Out-of-distribution</td>
      <td>2</td>
      <td></td>
      <td>2</td>
      <td>3</td>
      <td></td>
      <td></td>
    </tr>
    <tr>
      <td>PaLM</td>
      <td>1</td>
      <td></td>
      <td></td>
      <td></td>
      <td></td>
      <td></td>
    </tr>
    <tr>
      <td>Perplexity</td>
      <td></td>
      <td>1</td>
      <td></td>
      <td></td>
      <td></td>
      <td></td>
    </tr>
    <tr>
      <td>Planning Domain Descrition Language</td>
      <td>1</td>
      <td></td>
      <td></td>
      <td></td>
      <td></td>
      <td></td>
    </tr>
    <tr>
      <td>Pre-trained Language Model</td>
      <td>5</td>
      <td>2</td>
      <td></td>
      <td></td>
      <td></td>
      <td></td>
    </tr>
    <tr>
      <td>Probabilistic Model</td>
      <td></td>
      <td></td>
      <td></td>
      <td>2</td>
      <td></td>
      <td></td>
    </tr>
    <tr>
      <td>Prompt</td>
      <td>8</td>
      <td>1</td>
      <td>8</td>
      <td>4</td>
      <td></td>
      <td></td>
    </tr>
    <tr>
      <td>Prompt Learning</td>
      <td></td>
      <td></td>
      <td></td>
      <td>2</td>
      <td></td>
      <td></td>
    </tr>
    <tr>
      <td>Pruning</td>
      <td></td>
      <td>1</td>
      <td>1</td>
      <td>3</td>
      <td></td>
      <td></td>
    </tr>
    <tr>
      <td>Quantization</td>
      <td></td>
      <td></td>
      <td>1</td>
      <td></td>
      <td></td>
      <td>1</td>
    </tr>
    <tr>
      <td>Question Answering</td>
      <td>8</td>
      <td></td>
      <td></td>
      <td></td>
      <td></td>
      <td></td>
    </tr>
    <tr>
      <td>Reasoning</td>
      <td>8</td>
      <td></td>
      <td>2</td>
      <td></td>
      <td></td>
      <td></td>
    </tr>
    <tr>
      <td>Recommendation</td>
      <td></td>
      <td></td>
      <td></td>
      <td>2</td>
      <td></td>
      <td></td>
    </tr>
    <tr>
      <td>Recommender System</td>
      <td></td>
      <td></td>
      <td></td>
      <td>2</td>
      <td></td>
      <td></td>
    </tr>
    <tr>
      <td>Recurrent Neural Network</td>
      <td></td>
      <td></td>
      <td></td>
      <td>2</td>
      <td></td>
      <td></td>
    </tr>
    <tr>
      <td>Reinforcement Learning</td>
      <td>1</td>
      <td>1</td>
      <td>1</td>
      <td>8</td>
      <td>3</td>
      <td></td>
    </tr>
    <tr>
      <td>Relation Extraction</td>
      <td>1</td>
      <td></td>
      <td></td>
      <td></td>
      <td></td>
      <td></td>
    </tr>
    <tr>
      <td>Representation Learning</td>
      <td></td>
      <td>1</td>
      <td>6</td>
      <td>1</td>
      <td></td>
      <td></td>
    </tr>
    <tr>
      <td>Retrieval-Augmented Generation</td>
      <td>2</td>
      <td></td>
      <td>3</td>
      <td></td>
      <td></td>
      <td></td>
    </tr>
    <tr>
      <td>RoBERTa</td>
      <td>2</td>
      <td></td>
      <td></td>
      <td></td>
      <td></td>
      <td></td>
    </tr>
    <tr>
      <td>Rouge</td>
      <td>1</td>
      <td></td>
      <td></td>
      <td></td>
      <td></td>
      <td></td>
    </tr>
    <tr>
      <td>Rouge-L</td>
      <td>1</td>
      <td></td>
      <td></td>
      <td></td>
      <td></td>
      <td></td>
    </tr>
    <tr>
      <td>Sample Size</td>
      <td></td>
      <td></td>
      <td></td>
      <td>1</td>
      <td></td>
      <td></td>
    </tr>
    <tr>
      <td>Scaling Law</td>
      <td>1</td>
      <td></td>
      <td></td>
      <td></td>
      <td></td>
      <td></td>
    </tr>
    <tr>
      <td>Self-Attention</td>
      <td>1</td>
      <td></td>
      <td>1</td>
      <td>1</td>
      <td></td>
      <td></td>
    </tr>
    <tr>
      <td>Self-Distillation</td>
      <td></td>
      <td></td>
      <td>1</td>
      <td></td>
      <td></td>
      <td></td>
    </tr>
    <tr>
      <td>Self-supervised Learning</td>
      <td>2</td>
      <td></td>
      <td>5</td>
      <td>2</td>
      <td>1</td>
      <td>1</td>
    </tr>
    <tr>
      <td>Self-supervised Pre-training</td>
      <td></td>
      <td></td>
      <td>1</td>
      <td></td>
      <td></td>
      <td></td>
    </tr>
    <tr>
      <td>Semi-Supervised Learning</td>
      <td></td>
      <td></td>
      <td>1</td>
      <td></td>
      <td></td>
      <td></td>
    </tr>
    <tr>
      <td>Sentiment Analysis</td>
      <td></td>
      <td></td>
      <td>1</td>
      <td></td>
      <td></td>
      <td></td>
    </tr>
    <tr>
      <td>Simulation</td>
      <td></td>
      <td></td>
      <td>2</td>
      <td>5</td>
      <td>7</td>
      <td></td>
    </tr>
    <tr>
      <td>Simulator</td>
      <td></td>
      <td></td>
      <td>2</td>
      <td>5</td>
      <td>7</td>
      <td></td>
    </tr>
    <tr>
      <td>Speech-to-Speech Translation</td>
      <td>1</td>
      <td></td>
      <td></td>
      <td></td>
      <td></td>
      <td></td>
    </tr>
    <tr>
      <td>Stemming</td>
      <td></td>
      <td></td>
      <td></td>
      <td>2</td>
      <td></td>
      <td></td>
    </tr>
    <tr>
      <td>Summarization</td>
      <td>6</td>
      <td></td>
      <td>2</td>
      <td></td>
      <td></td>
      <td></td>
    </tr>
    <tr>
      <td>Supervised Learning</td>
      <td></td>
      <td>2</td>
      <td>4</td>
      <td>1</td>
      <td></td>
      <td>2</td>
    </tr>
    <tr>
      <td>Text Classification</td>
      <td>2</td>
      <td></td>
      <td></td>
      <td></td>
      <td></td>
      <td></td>
    </tr>
    <tr>
      <td>Text Generation</td>
      <td>2</td>
      <td></td>
      <td>2</td>
      <td>1</td>
      <td></td>
      <td></td>
    </tr>
    <tr>
      <td>Text Understanding</td>
      <td>1</td>
      <td></td>
      <td></td>
      <td></td>
      <td></td>
      <td></td>
    </tr>
    <tr>
      <td>Text2image</td>
      <td></td>
      <td></td>
      <td>1</td>
      <td></td>
      <td></td>
      <td></td>
    </tr>
    <tr>
      <td>Tokenization</td>
      <td>1</td>
      <td></td>
      <td></td>
      <td></td>
      <td></td>
      <td></td>
    </tr>
    <tr>
      <td>Transfer Learning</td>
      <td></td>
      <td></td>
      <td>1</td>
      <td></td>
      <td></td>
      <td></td>
    </tr>
    <tr>
      <td>Transformer</td>
      <td>7</td>
      <td></td>
      <td>10</td>
      <td>8</td>
      <td>1</td>
      <td>1</td>
    </tr>
    <tr>
      <td>Unsupervised Learning</td>
      <td>2</td>
      <td></td>
      <td>5</td>
      <td>1</td>
      <td></td>
      <td>2</td>
    </tr>
    <tr>
      <td>Variational Autoencoder</td>
      <td></td>
      <td></td>
      <td></td>
      <td>1</td>
      <td></td>
      <td></td>
    </tr>
    <tr>
      <td>Vision Transformer</td>
      <td></td>
      <td></td>
      <td>10</td>
      <td>2</td>
      <td></td>
      <td></td>
    </tr>
    <tr>
      <td>Vision-and-Language</td>
      <td></td>
      <td></td>
      <td>5</td>
      <td></td>
      <td></td>
      <td></td>
    </tr>
    <tr>
      <td>Weakly-supervised Learning</td>
      <td>2</td>
      <td></td>
      <td>1</td>
      <td></td>
      <td></td>
      <td></td>
    </tr>
    <tr>
      <td>Yolo</td>
      <td></td>
      <td></td>
      <td>1</td>
      <td></td>
      <td></td>
      <td></td>
    </tr>
    <tr>
      <td>Zero-shot</td>
      <td>4</td>
      <td></td>
      <td>5</td>
      <td>3</td>
      <td>4</td>
      <td></td>
    </tr>
    <tr>
      <td>human-in-the-loop</td>
      <td></td>
      <td></td>
      <td></td>
      <td></td>
      <td>1</td>
      <td></td>
    </tr>
  </tbody>
</table>

<script>
$(function() {
  $("table").addClass("keyword-table table-bordered border-success");
  $("table thead").addClass("sticky-top");
  $("table tbody td").css("text-align", "");
});
</script>


## cs.CL (48)



### (1/48 | 1/321) Query-OPT: Optimizing Inference of Large Language Models via Multi-Query Instructions in Meeting Summarization (Md Tahmid Rahman Laskar et al., 2024)

{{<citation>}}

Md Tahmid Rahman Laskar, Elena Khasanova, Xue-Yong Fu, Cheng Chen, Shashi Bhushan TN. (2024)  
**Query-OPT: Optimizing Inference of Large Language Models via Multi-Query Instructions in Meeting Summarization**
<br/>
<button class="copy-to-clipboard" title="Query-OPT: Optimizing Inference of Large Language Models via Multi-Query Instructions in Meeting Summarization" index=1>
  <span class="copy-to-clipboard-item">Copy Title<span>
</button>
<div class="toast toast-copied toast-index-1 align-items-center text-bg-secondary border-0 position-absolute top-0 end-0" role="alert" aria-live="assertive" aria-atomic="true">
  <div class="d-flex">
    <div class="toast-body">
      Copied!
    </div>
  </div>
</div>

---
Primary Category: cs.CL  
Categories: cs-CL, cs.CL  
Keyword Score: 100  
Keywords: Fine-tuning, GPT, GPT-4, LLaMA, Mistral, PaLM, Large Language Model, Large Language Model, Prompt, Summarization  
<a type="button" class="btn btn-outline-primary" href="http://arxiv.org/abs/2403.00067v1" target="_blank" >Paper Link</a>
<button type="button" class="btn btn-outline-primary download-pdf" url="https://arxiv.org/pdf/2403.00067v1.pdf" filename="2403.00067v1.pdf">Download PDF</button>

---


**ABSTRACT**  
This work focuses on the task of query-based meeting <b>summarization</b> in which the summary of a context (meeting transcript) is generated in response to a specific query. When using <b>Large</b> <b>Language</b> <b>Models</b> <b>(LLMs)</b> for this task, a new call to the <b>LLM</b> inference endpoint/API is required for each new query even if the context stays the same. However, repeated calls to the <b>LLM</b> inference endpoints would significantly increase the costs of using them in production, making <b>LLMs</b> impractical for many real-world use cases. To address this problem, in this paper, we investigate whether combining the queries for the same input context in a single <b>prompt</b> to minimize repeated calls can be successfully used in meeting <b>summarization.</b> In this regard, we conduct extensive experiments by comparing the performance of various popular <b>LLMs:</b> <b>GPT-4,</b> <b>PaLM-2,</b> <b>LLaMA-2,</b> <b>Mistral,</b> and FLAN-T5 in single-query and multi-query settings. We observe that while most <b>LLMs</b> tend to respond to the multi-query instructions, almost all of them (except <b>GPT-4),</b> even after <b>fine-tuning,</b> could not properly generate the response in the required output format. We conclude that while multi-query <b>prompting</b> could be useful to optimize the inference costs by reducing calls to the inference endpoints/APIs for the task of meeting <b>summarization,</b> this capability to reliably generate the response in the expected format is only limited to certain <b>LLMs.</b>

{{</citation>}}


### (2/48 | 2/321) Compact Speech Translation Models via Discrete Speech Units Pretraining (Tsz Kin Lam et al., 2024)

{{<citation>}}

Tsz Kin Lam, Alexandra Birch, Barry Haddow. (2024)  
**Compact Speech Translation Models via Discrete Speech Units Pretraining**
<br/>
<button class="copy-to-clipboard" title="Compact Speech Translation Models via Discrete Speech Units Pretraining" index=2>
  <span class="copy-to-clipboard-item">Copy Title<span>
</button>
<div class="toast toast-copied toast-index-2 align-items-center text-bg-secondary border-0 position-absolute top-0 end-0" role="alert" aria-live="assertive" aria-atomic="true">
  <div class="d-flex">
    <div class="toast-body">
      Copied!
    </div>
  </div>
</div>

---
Primary Category: cs.CL  
Categories: cs-CL, cs-SD, cs.CL, eess-AS  
Keyword Score: 90  
Keywords: Fine-tuning, Fine-tuning, Low-Resource, Self-supervised Learning, Self-supervised Learning, Automatic Speech Recognition, Speech-to-Speech Translation, Tokenization, BLEU  
<a type="button" class="btn btn-outline-primary" href="http://arxiv.org/abs/2402.19333v1" target="_blank" >Paper Link</a>
<button type="button" class="btn btn-outline-primary download-pdf" url="https://arxiv.org/pdf/2402.19333v1.pdf" filename="2402.19333v1.pdf">Download PDF</button>

---


**ABSTRACT**  
Using <b>Self-Supervised</b> <b>Learning</b> (SSL) as model initialization is now common to obtain strong results in <b>Speech</b> <b>Translation</b> (ST). However, they also impose a large memory footprint, hindering on-device deployment. In this paper, we leverage the SSL models by pretraining smaller models on their Discrete <b>Speech</b> <b>Units</b> (DSU). We pretrain encoder-decoder models on 1) Filterbank-to-DSU and 2) DSU-to-Translation data, and take the encoder from 1) and the decoder from 2) to initialise a new model, <b>finetuning</b> this on limited <b>speech-translation</b> <b>data.</b> The final model becomes compact by using the DSU pretraining to distil the knowledge of the SSL model. Our method has several benefits over using DSU as model inputs, such as shorter inference pipeline and robustness over (DSU) <b>tokenization.</b> In contrast to <b>ASR</b> pretraining, it does not require transcripts, making it applicable to <b>low-resource</b> settings. Evaluation on CoVoST-2 X-En shows that our method is >$0.5$ <b>BLEU</b> better than a ST model that directly <b>finetune</b> the SSL model, given only half the model size, and on a par with <b>ASR</b> pretraining.

{{</citation>}}


### (3/48 | 3/321) Teaching Large Language Models an Unseen Language on the Fly (Chen Zhang et al., 2024)

{{<citation>}}

Chen Zhang, Xiao Liu, Jiuheng Lin, Yansong Feng. (2024)  
**Teaching Large Language Models an Unseen Language on the Fly**
<br/>
<button class="copy-to-clipboard" title="Teaching Large Language Models an Unseen Language on the Fly" index=3>
  <span class="copy-to-clipboard-item">Copy Title<span>
</button>
<div class="toast toast-copied toast-index-3 align-items-center text-bg-secondary border-0 position-absolute top-0 end-0" role="alert" aria-live="assertive" aria-atomic="true">
  <div class="d-flex">
    <div class="toast-body">
      Copied!
    </div>
  </div>
</div>

---
Primary Category: cs.CL  
Categories: cs-CL, cs.CL  
Keyword Score: 90  
Keywords: Low-Resource, GPT, GPT-4, BLEU, In-context Learning, In-context Learning, Large Language Model, Large Language Model, Prompt  
<a type="button" class="btn btn-outline-primary" href="http://arxiv.org/abs/2402.19167v1" target="_blank" >Paper Link</a>
<button type="button" class="btn btn-outline-primary download-pdf" url="https://arxiv.org/pdf/2402.19167v1.pdf" filename="2402.19167v1.pdf">Download PDF</button>

---


**ABSTRACT**  
Existing <b>large</b> <b>language</b> <b>models</b> struggle to support numerous <b>low-resource</b> languages, particularly the extremely <b>low-resource</b> ones where there is minimal training data available for effective parameter updating. We thus investigate whether <b>LLMs</b> can learn a new language on the fly solely through <b>prompting.</b> To study this question, we collect a research suite for Zhuang, a language supported by no <b>LLMs</b> currently. We introduce \textsc{DiPMT++}, a framework for adapting <b>LLMs</b> to unseen languages by <b>in-context</b> <b>learning.</b> Using a dictionary and only 5K parallel sentences, \textsc{DiPMT++} significantly enhances the performance of <b>GPT-4</b> from 0 to 16 <b>BLEU</b> for Chinese-to-Zhuang translation and achieves 32 <b>BLEU</b> for Zhuang-to-Chinese translation. Furthermore, we demonstrate the practical utility of this framework in aiding humans to translate completely unseen languages, which could contribute to the preservation of linguistic diversity.

{{</citation>}}


### (4/48 | 4/321) OpenMedLM: Prompt engineering can out-perform fine-tuning in medical question-answering with open-source large language models (Jenish Maharjan et al., 2024)

{{<citation>}}

Jenish Maharjan, Anurag Garikipati, Navan Preet Singh, Leo Cyrus, Mayank Sharma, Madalina Ciobanu, Gina Barnes, Rahul Thapa, Qingqing Mao, Ritankar Das. (2024)  
**OpenMedLM: Prompt engineering can out-perform fine-tuning in medical question-answering with open-source large language models**
<br/>
<button class="copy-to-clipboard" title="OpenMedLM: Prompt engineering can out-perform fine-tuning in medical question-answering with open-source large language models" index=4>
  <span class="copy-to-clipboard-item">Copy Title<span>
</button>
<div class="toast toast-copied toast-index-4 align-items-center text-bg-secondary border-0 position-absolute top-0 end-0" role="alert" aria-live="assertive" aria-atomic="true">
  <div class="d-flex">
    <div class="toast-body">
      Copied!
    </div>
  </div>
</div>

---
Primary Category: cs.CL  
Categories: cs-AI, cs-CL, cs-IR, cs.CL  
Keyword Score: 83  
Keywords: Benchmarking, Few-shot, Fine-tuning, Zero-shot, Massive Multitask Language Understanding (MMLU), Question Answering, Large Language Model, Large Language Model, Prompt  
<a type="button" class="btn btn-outline-primary" href="http://arxiv.org/abs/2402.19371v1" target="_blank" >Paper Link</a>
<button type="button" class="btn btn-outline-primary download-pdf" url="https://arxiv.org/pdf/2402.19371v1.pdf" filename="2402.19371v1.pdf">Download PDF</button>

---


**ABSTRACT**  
<b>LLMs</b> have become increasingly capable at accomplishing a range of specialized-tasks and can be utilized to expand equitable access to medical knowledge. Most medical <b>LLMs</b> have involved extensive <b>fine-tuning,</b> leveraging specialized medical data and significant, thus costly, amounts of computational power. Many of the top performing <b>LLMs</b> are proprietary and their access is limited to very few research groups. However, open-source (OS) models represent a key area of growth for medical <b>LLMs</b> due to significant improvements in performance and an inherent ability to provide the transparency and compliance required in healthcare. We present OpenMedLM, a <b>prompting</b> platform which delivers state-of-the-art (SOTA) performance for OS <b>LLMs</b> on medical <b>benchmarks.</b> We evaluated a range of OS foundation <b>LLMs</b> (7B-70B) on four medical <b>benchmarks</b> (MedQA, MedMCQA, PubMedQA, <b>MMLU</b> medical-subset). We employed a series of <b>prompting</b> strategies, including <b>zero-shot,</b> <b>few-shot,</b> chain-of-thought (random selection and kNN selection), and ensemble/self-consistency voting. We found that OpenMedLM delivers OS SOTA results on three common medical <b>LLM</b> <b>benchmarks,</b> surpassing the previous best performing OS models that leveraged computationally costly extensive <b>fine-tuning.</b> The model delivers a 72.6% accuracy on the MedQA <b>benchmark,</b> outperforming the previous SOTA by 2.4%, and achieves 81.7% accuracy on the <b>MMLU</b> medical-subset, establishing itself as the first OS <b>LLM</b> to surpass 80% accuracy on this <b>benchmark.</b> Our results highlight medical-specific emergent properties in OS <b>LLMs</b> which have not yet been documented to date elsewhere, and showcase the benefits of further leveraging <b>prompt</b> engineering to improve the performance of accessible <b>LLMs</b> for medical applications.

{{</citation>}}


### (5/48 | 5/321) Exploring the Efficacy of Large Language Models in Summarizing Mental Health Counseling Sessions: A Benchmark Study (Prottay Kumar Adhikary et al., 2024)

{{<citation>}}

Prottay Kumar Adhikary, Aseem Srivastava, Shivani Kumar, Salam Michael Singh, Puneet Manuja, Jini K Gopinath, Vijay Krishnan, Swati Kedia, Koushik Sinha Deb, Tanmoy Chakraborty. (2024)  
**Exploring the Efficacy of Large Language Models in Summarizing Mental Health Counseling Sessions: A Benchmark Study**
<br/>
<button class="copy-to-clipboard" title="Exploring the Efficacy of Large Language Models in Summarizing Mental Health Counseling Sessions: A Benchmark Study" index=5>
  <span class="copy-to-clipboard-item">Copy Title<span>
</button>
<div class="toast toast-copied toast-index-5 align-items-center text-bg-secondary border-0 position-absolute top-0 end-0" role="alert" aria-live="assertive" aria-atomic="true">
  <div class="d-flex">
    <div class="toast-body">
      Copied!
    </div>
  </div>
</div>

---
Primary Category: cs.CL  
Categories: cs-CL, cs-HC, cs.CL  
Keyword Score: 73  
Keywords: Benchmarking, Mistral, BERTScore, Large Language Model, Large Language Model, Rouge, Rouge-L, Summarization  
<a type="button" class="btn btn-outline-primary" href="http://arxiv.org/abs/2402.19052v1" target="_blank" >Paper Link</a>
<button type="button" class="btn btn-outline-primary download-pdf" url="https://arxiv.org/pdf/2402.19052v1.pdf" filename="2402.19052v1.pdf">Download PDF</button>

---


**ABSTRACT**  
Comprehensive summaries of sessions enable an effective continuity in mental health counseling, facilitating informed therapy planning. Yet, manual <b>summarization</b> presents a significant challenge, diverting experts' attention from the core counseling process. This study evaluates the effectiveness of state-of-the-art <b>Large</b> <b>Language</b> <b>Models</b> <b>(LLMs)</b> in selectively summarizing various components of therapy sessions through aspect-based <b>summarization,</b> aiming to <b>benchmark</b> their performance. We introduce MentalCLOUDS, a counseling-component guided <b>summarization</b> dataset consisting of 191 counseling sessions with summaries focused on three distinct counseling components (aka counseling aspects). Additionally, we assess the capabilities of 11 state-of-the-art <b>LLMs</b> in addressing the task of component-guided <b>summarization</b> in counseling. The generated summaries are evaluated quantitatively using standard <b>summarization</b> metrics and verified qualitatively by mental health professionals. Our findings demonstrate the superior performance of task-specific <b>LLMs</b> such as MentalLlama, <b>Mistral,</b> and MentalBART in terms of standard quantitative metrics such as <b>Rouge-1,</b> <b>Rouge-2,</b> <b>Rouge-L,</b> and <b>BERTScore</b> across all aspects of counseling components. Further, expert evaluation reveals that <b>Mistral</b> supersedes both MentalLlama and MentalBART based on six parameters -- affective attitude, burden, ethicality, coherence, opportunity costs, and perceived effectiveness. However, these models share the same weakness by demonstrating a potential for improvement in the opportunity costs and perceived effectiveness metrics.

{{</citation>}}


### (6/48 | 6/321) TELEClass: Taxonomy Enrichment and LLM-Enhanced Hierarchical Text Classification with Minimal Supervision (Yunyi Zhang et al., 2024)

{{<citation>}}

Yunyi Zhang, Ruozhen Yang, Xueqiang Xu, Jinfeng Xiao, Jiaming Shen, Jiawei Han. (2024)  
**TELEClass: Taxonomy Enrichment and LLM-Enhanced Hierarchical Text Classification with Minimal Supervision**
<br/>
<button class="copy-to-clipboard" title="TELEClass: Taxonomy Enrichment and LLM-Enhanced Hierarchical Text Classification with Minimal Supervision" index=6>
  <span class="copy-to-clipboard-item">Copy Title<span>
</button>
<div class="toast toast-copied toast-index-6 align-items-center text-bg-secondary border-0 position-absolute top-0 end-0" role="alert" aria-live="assertive" aria-atomic="true">
  <div class="d-flex">
    <div class="toast-body">
      Copied!
    </div>
  </div>
</div>

---
Primary Category: cs.CL  
Categories: cs-CL, cs-LG, cs.CL  
Keyword Score: 60  
Keywords: Weakly-supervised Learning, Zero-shot, Text Classification, Large Language Model, Large Language Model, Prompt  
<a type="button" class="btn btn-outline-primary" href="http://arxiv.org/abs/2403.00165v1" target="_blank" >Paper Link</a>
<button type="button" class="btn btn-outline-primary download-pdf" url="https://arxiv.org/pdf/2403.00165v1.pdf" filename="2403.00165v1.pdf">Download PDF</button>

---


**ABSTRACT**  
Hierarchical <b>text</b> <b>classification</b> aims to categorize each document into a set of classes in a label taxonomy. Most earlier works focus on fully or semi-supervised methods that require a <b>large</b> <b>amount</b> <b>of</b> human annotated data which is costly and time-consuming to acquire. To alleviate human efforts, in this paper, we work on hierarchical <b>text</b> <b>classification</b> with the minimal amount of supervision: using the sole class name of each node as the only supervision. Recently, <b>large</b> <b>language</b> <b>models</b> <b>(LLM)</b> show competitive performance on various tasks through <b>zero-shot</b> <b>prompting,</b> but this method performs poorly in the hierarchical setting, because it is ineffective to include the <b>large</b> <b>and</b> <b>structured</b> label space in a <b>prompt.</b> On the other hand, previous <b>weakly-supervised</b> hierarchical <b>text</b> <b>classification</b> methods only utilize the raw taxonomy skeleton and ignore the rich information hidden in the <b>text</b> <b>corpus</b> that can serve as additional class-indicative features. To tackle the above challenges, we propose TELEClass, Taxonomy Enrichment and <b>LLM-Enhanced</b> <b>weakly-supervised</b> hierarchical <b>text</b> <b>classification,</b> which (1) automatically enriches the label taxonomy with class-indicative topical terms mined from the corpus to facilitate classifier training and (2) utilizes <b>LLMs</b> for both data annotation and creation tailored for the hierarchical label space. Experiments show that TELEClass can outperform previous <b>weakly-supervised</b> hierarchical <b>text</b> <b>classification</b> methods and <b>LLM-based</b> <b>zero-shot</b> <b>prompting</b> methods on two public datasets.

{{</citation>}}


### (7/48 | 7/321) PROC2PDDL: Open-Domain Planning Representations from Texts (Tianyi Zhang et al., 2024)

{{<citation>}}

Tianyi Zhang, Li Zhang, Zhaoyi Hou, Ziyu Wang, Yuling Gu, Peter Clark, Chris Callison-Burch, Niket Tandon. (2024)  
**PROC2PDDL: Open-Domain Planning Representations from Texts**
<br/>
<button class="copy-to-clipboard" title="PROC2PDDL: Open-Domain Planning Representations from Texts" index=7>
  <span class="copy-to-clipboard-item">Copy Title<span>
</button>
<div class="toast toast-copied toast-index-7 align-items-center text-bg-secondary border-0 position-absolute top-0 end-0" role="alert" aria-live="assertive" aria-atomic="true">
  <div class="d-flex">
    <div class="toast-body">
      Copied!
    </div>
  </div>
</div>

---
Primary Category: cs.CL  
Categories: cs-CL, cs.CL  
Keyword Score: 60  
Keywords: Planning Domain Descrition Language, GPT, GPT-3, GPT-3.5, GPT-4, Reasoning  
<a type="button" class="btn btn-outline-primary" href="http://arxiv.org/abs/2403.00092v1" target="_blank" >Paper Link</a>
<button type="button" class="btn btn-outline-primary download-pdf" url="https://arxiv.org/pdf/2403.00092v1.pdf" filename="2403.00092v1.pdf">Download PDF</button>

---


**ABSTRACT**  
Planning in a text-based environment continues to be a major challenge for AI systems. Recent approaches have used language models to predict a planning domain definition (e.g., <b>PDDL)</b> but have only been evaluated in closed-domain simulated environments. To address this, we present Proc2PDDL , the first dataset containing open-domain procedural texts paired with expert-annotated <b>PDDL</b> representations. Using this dataset, we evaluate state-of-the-art models on defining the preconditions and effects of actions. We show that Proc2PDDL is highly challenging, with <b>GPT-3.5's</b> success rate close to 0% and <b>GPT-4's</b> around 35%. Our analysis shows both syntactic and semantic errors, indicating LMs' deficiency in both generating domain-specific prgorams and <b>reasoning</b> about events. We hope this analysis and dataset helps future progress towards integrating the best of LMs and formal planning.

{{</citation>}}


### (8/48 | 8/321) Prompting Explicit and Implicit Knowledge for Multi-hop Question Answering Based on Human Reading Process (Guangming Huang et al., 2024)

{{<citation>}}

Guangming Huang, Yunfei Long, Cunjin Luo, Jiaxing Shen, Xia Sun. (2024)  
**Prompting Explicit and Implicit Knowledge for Multi-hop Question Answering Based on Human Reading Process**
<br/>
<button class="copy-to-clipboard" title="Prompting Explicit and Implicit Knowledge for Multi-hop Question Answering Based on Human Reading Process" index=8>
  <span class="copy-to-clipboard-item">Copy Title<span>
</button>
<div class="toast toast-copied toast-index-8 align-items-center text-bg-secondary border-0 position-absolute top-0 end-0" role="alert" aria-live="assertive" aria-atomic="true">
  <div class="d-flex">
    <div class="toast-body">
      Copied!
    </div>
  </div>
</div>

---
Primary Category: cs.CL  
Categories: cs-CL, cs.CL  
Keyword Score: 60  
Keywords: Question Answering, Question Answering, Reasoning, Pre-trained Language Model, Pre-trained Language Model, Prompt  
<a type="button" class="btn btn-outline-primary" href="http://arxiv.org/abs/2402.19350v3" target="_blank" >Paper Link</a>
<button type="button" class="btn btn-outline-primary download-pdf" url="https://arxiv.org/pdf/2402.19350v3.pdf" filename="2402.19350v3.pdf">Download PDF</button>

---


**ABSTRACT**  
<b>Pre-trained</b> <b>language</b> <b>models</b> <b>(PLMs)</b> leverage chains-of-thought (CoT) to simulate human <b>reasoning</b> and inference processes, achieving proficient performance in multi-hop <b>QA.</b> However, a gap persists between <b>PLMs'</b> <b>reasoning</b> abilities and those of humans when tackling complex problems. Psychological studies suggest a vital connection between explicit information in passages and human prior knowledge during reading. Nevertheless, current research has given insufficient attention to linking input passages and <b>PLMs'</b> pre-training-based knowledge from the perspective of human cognition studies. In this study, we introduce a <b>Prompting</b> Explicit and Implicit knowledge (PEI) framework, which uses <b>prompts</b> to connect explicit and implicit knowledge, aligning with human reading process for multi-hop <b>QA.</b> We consider the input passages as explicit knowledge, employing them to elicit implicit knowledge through unified <b>prompt</b> <b>reasoning.</b> Furthermore, our model incorporates type-specific <b>reasoning</b> via <b>prompts,</b> a form of implicit knowledge. Experimental results show that PEI performs comparably to the state-of-the-art on HotpotQA. Ablation studies confirm the efficacy of our model in bridging and integrating explicit and implicit knowledge.

{{</citation>}}


### (9/48 | 9/321) On the Decision-Making Abilities in Role-Playing using Large Language Models (Chenglei Shen et al., 2024)

{{<citation>}}

Chenglei Shen, Guofu Xie, Xiao Zhang, Jun Xu. (2024)  
**On the Decision-Making Abilities in Role-Playing using Large Language Models**
<br/>
<button class="copy-to-clipboard" title="On the Decision-Making Abilities in Role-Playing using Large Language Models" index=9>
  <span class="copy-to-clipboard-item">Copy Title<span>
</button>
<div class="toast toast-copied toast-index-9 align-items-center text-bg-secondary border-0 position-absolute top-0 end-0" role="alert" aria-live="assertive" aria-atomic="true">
  <div class="d-flex">
    <div class="toast-body">
      Copied!
    </div>
  </div>
</div>

---
Primary Category: cs.CL  
Categories: cs-AI, cs-CL, cs.CL  
Keyword Score: 60  
Keywords: GPT, GPT-4, Reasoning, Large Language Model, Large Language Model, Prompt  
<a type="button" class="btn btn-outline-primary" href="http://arxiv.org/abs/2402.18807v1" target="_blank" >Paper Link</a>
<button type="button" class="btn btn-outline-primary download-pdf" url="https://arxiv.org/pdf/2402.18807v1.pdf" filename="2402.18807v1.pdf">Download PDF</button>

---


**ABSTRACT**  
<b>Large</b> <b>language</b> <b>models</b> <b>(LLMs)</b> are now increasingly utilized for role-playing tasks, especially in impersonating domain-specific experts, primarily through role-playing <b>prompts.</b> When interacting in real-world scenarios, the decision-making abilities of a role significantly shape its behavioral patterns. In this paper, we concentrate on evaluating the decision-making abilities of <b>LLMs</b> post role-playing thereby validating the efficacy of role-playing. Our goal is to provide metrics and guidance for enhancing the decision-making abilities of <b>LLMs</b> in role-playing tasks. Specifically, we first use <b>LLMs</b> to generate virtual role descriptions corresponding to the 16 personality types of Myers-Briggs Type Indicator (abbreviated as MBTI) representing a segmentation of the population. Then we design specific quantitative operations to evaluate the decision-making abilities of <b>LLMs</b> post role-playing from four aspects: adaptability, exploration$\&$exploitation trade-off ability, <b>reasoning</b> ability, and safety. Finally, we analyze the association between the performance of decision-making and the corresponding MBTI types through <b>GPT-4.</b> Extensive experiments demonstrate stable differences in the four aspects of decision-making abilities across distinct roles, signifying a robust correlation between decision-making abilities and the roles emulated by <b>LLMs.</b> These results underscore that <b>LLMs</b> can effectively impersonate varied roles while embodying their genuine sociological characteristics.

{{</citation>}}


### (10/48 | 10/321) NewsBench: Systematic Evaluation of LLMs for Writing Proficiency and Safety Adherence in Chinese Journalistic Editorial Applications (Miao Li et al., 2024)

{{<citation>}}

Miao Li, Ming-Bin Chen, Bo Tang, Shengbin Hou, Pengyu Wang, Haiying Deng, Zhiyu Li, Feiyu Xiong, Keming Mao, Peng Cheng, Yi Luo. (2024)  
**NewsBench: Systematic Evaluation of LLMs for Writing Proficiency and Safety Adherence in Chinese Journalistic Editorial Applications**
<br/>
<button class="copy-to-clipboard" title="NewsBench: Systematic Evaluation of LLMs for Writing Proficiency and Safety Adherence in Chinese Journalistic Editorial Applications" index=10>
  <span class="copy-to-clipboard-item">Copy Title<span>
</button>
<div class="toast toast-copied toast-index-10 align-items-center text-bg-secondary border-0 position-absolute top-0 end-0" role="alert" aria-live="assertive" aria-atomic="true">
  <div class="d-flex">
    <div class="toast-body">
      Copied!
    </div>
  </div>
</div>

---
Primary Category: cs.CL  
Categories: cs-AI, cs-CL, cs.CL  
Keyword Score: 53  
Keywords: Automatic Evaluation, Benchmarking, GPT, GPT-4, Large Language Model, Large Language Model  
<a type="button" class="btn btn-outline-primary" href="http://arxiv.org/abs/2403.00862v1" target="_blank" >Paper Link</a>
<button type="button" class="btn btn-outline-primary download-pdf" url="https://arxiv.org/pdf/2403.00862v1.pdf" filename="2403.00862v1.pdf">Download PDF</button>

---


**ABSTRACT**  
This study presents NewsBench, a novel <b>benchmark</b> framework developed to evaluate the capability of <b>Large</b> <b>Language</b> <b>Models</b> <b>(LLMs)</b> in Chinese Journalistic Writing Proficiency (JWP) and their Safety Adherence (SA), addressing the gap between journalistic ethics and the risks associated with AI utilization. Comprising 1,267 tasks across 5 editorial applications, 7 aspects (including safety and journalistic writing with 4 detailed facets), and spanning 24 news topics domains, NewsBench employs two <b>GPT-4</b> based <b>automatic</b> <b>evaluation</b> protocols validated by human assessment. Our comprehensive analysis of 11 <b>LLMs</b> highlighted <b>GPT-4</b> and ERNIE Bot as top performers, yet revealed a relative deficiency in journalistic ethic adherence during creative writing tasks. These findings underscore the need for enhanced ethical guidance in AI-generated journalistic content, marking a step forward in aligning AI capabilities with journalistic standards and safety considerations.

{{</citation>}}


### (11/48 | 11/321) GSM-Plus: A Comprehensive Benchmark for Evaluating the Robustness of LLMs as Mathematical Problem Solvers (Qintong Li et al., 2024)

{{<citation>}}

Qintong Li, Leyang Cui, Xueliang Zhao, Lingpeng Kong, Wei Bi. (2024)  
**GSM-Plus: A Comprehensive Benchmark for Evaluating the Robustness of LLMs as Mathematical Problem Solvers**
<br/>
<button class="copy-to-clipboard" title="GSM-Plus: A Comprehensive Benchmark for Evaluating the Robustness of LLMs as Mathematical Problem Solvers" index=11>
  <span class="copy-to-clipboard-item">Copy Title<span>
</button>
<div class="toast toast-copied toast-index-11 align-items-center text-bg-secondary border-0 position-absolute top-0 end-0" role="alert" aria-live="assertive" aria-atomic="true">
  <div class="d-flex">
    <div class="toast-body">
      Copied!
    </div>
  </div>
</div>

---
Primary Category: cs.CL  
Categories: cs-CL, cs.CL  
Keyword Score: 53  
Keywords: Benchmarking, Mathematical Reasoning, Reasoning, Large Language Model, Large Language Model, Prompt  
<a type="button" class="btn btn-outline-primary" href="http://arxiv.org/abs/2402.19255v1" target="_blank" >Paper Link</a>
<button type="button" class="btn btn-outline-primary download-pdf" url="https://arxiv.org/pdf/2402.19255v1.pdf" filename="2402.19255v1.pdf">Download PDF</button>

---


**ABSTRACT**  
<b>Large</b> <b>language</b> <b>models</b> <b>(LLMs)</b> have achieved impressive performance across various <b>mathematical</b> <b>reasoning</b> <b>benchmarks.</b> However, there are increasing debates regarding whether these models truly understand and apply <b>mathematical</b> <b>knowledge</b> or merely rely on shortcuts for <b>mathematical</b> <b>reasoning.</b> One essential and frequently occurring evidence is that when the math questions are slightly changed, <b>LLMs</b> can behave incorrectly. This motivates us to evaluate the robustness of <b>LLMs'</b> math <b>reasoning</b> capability by testing a wide range of question variations. We introduce the adversarial grade school math (\datasetname) dataset, an extension of GSM8K augmented with various <b>mathematical</b> <b>perturbations.</b> Our experiments on 25 <b>LLMs</b> and 4 <b>prompting</b> techniques show that while <b>LLMs</b> exhibit different levels of math <b>reasoning</b> abilities, their performances are far from robust. In particular, even for problems that have been solved in GSM8K, <b>LLMs</b> can make mistakes when new statements are added or the question targets are altered. We also explore whether more robust performance can be achieved by composing existing <b>prompting</b> methods, in which we try an iterative method that generates and verifies each intermediate thought based on its <b>reasoning</b> goal and calculation result. Code and data are available at \url{https://github.com/qtli/GSM-Plus}.

{{</citation>}}


### (12/48 | 12/321) EyeGPT: Ophthalmic Assistant with Large Language Models (Xiaolan Chen et al., 2024)

{{<citation>}}

Xiaolan Chen, Ziwei Zhao, Weiyi Zhang, Pusheng Xu, Le Gao, Mingpu Xu, Yue Wu, Yinwen Li, Danli Shi, Mingguang He. (2024)  
**EyeGPT: Ophthalmic Assistant with Large Language Models**
<br/>
<button class="copy-to-clipboard" title="EyeGPT: Ophthalmic Assistant with Large Language Models" index=12>
  <span class="copy-to-clipboard-item">Copy Title<span>
</button>
<div class="toast toast-copied toast-index-12 align-items-center text-bg-secondary border-0 position-absolute top-0 end-0" role="alert" aria-live="assertive" aria-atomic="true">
  <div class="d-flex">
    <div class="toast-body">
      Copied!
    </div>
  </div>
</div>

---
Primary Category: cs.CL  
Categories: cs-AI, cs-CL, cs.CL  
Keyword Score: 50  
Keywords: Fine-tuning, Retrieval-Augmented Generation, Retrieval-Augmented Generation, Large Language Model, Large Language Model  
<a type="button" class="btn btn-outline-primary" href="http://arxiv.org/abs/2403.00840v1" target="_blank" >Paper Link</a>
<button type="button" class="btn btn-outline-primary download-pdf" url="https://arxiv.org/pdf/2403.00840v1.pdf" filename="2403.00840v1.pdf">Download PDF</button>

---


**ABSTRACT**  
Artificial intelligence (AI) has gained significant attention in healthcare consultation due to its potential to improve clinical workflow and enhance medical communication. However, owing to the complex nature of medical information, <b>large</b> <b>language</b> <b>models</b> <b>(LLM)</b> trained with general world knowledge might not possess the capability to tackle medical-related tasks at an expert level. Here, we introduce EyeGPT, a specialized <b>LLM</b> designed specifically for ophthalmology, using three optimization strategies including role-playing, <b>finetuning,</b> and <b>retrieval-augmented</b> <b>generation.</b> <b>In</b> particular, we proposed a comprehensive evaluation framework that encompasses a diverse dataset, covering various subspecialties of ophthalmology, different users, and diverse inquiry intents. Moreover, we considered multiple evaluation metrics, including accuracy, understandability, trustworthiness, empathy, and the proportion of hallucinations. By assessing the performance of different EyeGPT variants, we identify the most effective one, which exhibits comparable levels of understandability, trustworthiness, and empathy to human ophthalmologists (all Ps>0.05). Overall, ur study provides valuable insights for future research, facilitating comprehensive comparisons and evaluations of different strategies for developing specialized <b>LLMs</b> in ophthalmology. The potential benefits include enhancing the patient experience in eye care and optimizing ophthalmologists' services.

{{</citation>}}


### (13/48 | 13/321) How to Understand 'Support'? An Implicit-enhanced Causal Inference Approach for Weakly-supervised Phrase Grounding (Jiamin Luo et al., 2024)

{{<citation>}}

Jiamin Luo, Jianing Zhao, Jingjing Wang, Guodong Zhou. (2024)  
**How to Understand 'Support'? An Implicit-enhanced Causal Inference Approach for Weakly-supervised Phrase Grounding**
<br/>
<button class="copy-to-clipboard" title="How to Understand 'Support'? An Implicit-enhanced Causal Inference Approach for Weakly-supervised Phrase Grounding" index=13>
  <span class="copy-to-clipboard-item">Copy Title<span>
</button>
<div class="toast toast-copied toast-index-13 align-items-center text-bg-secondary border-0 position-absolute top-0 end-0" role="alert" aria-live="assertive" aria-atomic="true">
  <div class="d-flex">
    <div class="toast-body">
      Copied!
    </div>
  </div>
</div>

---
Primary Category: cs.CL  
Categories: cs-AI, cs-CL, cs.CL  
Keyword Score: 46  
Keywords: Counter-factual, Multi-modal, Multi-modal, Weakly-supervised Learning, Grounding, Large Language Model  
<a type="button" class="btn btn-outline-primary" href="http://arxiv.org/abs/2402.19116v2" target="_blank" >Paper Link</a>
<button type="button" class="btn btn-outline-primary download-pdf" url="https://arxiv.org/pdf/2402.19116v2.pdf" filename="2402.19116v2.pdf">Download PDF</button>

---


**ABSTRACT**  
<b>Weakly-supervised</b> Phrase <b>Grounding</b> (WPG) is an emerging task of inferring the fine-grained phrase-region matching, while merely leveraging the coarse-grained sentence-image pairs for training. However, existing studies on WPG largely ignore the implicit phrase-region matching relations, which are crucial for evaluating the capability of models in understanding the deep <b>multimodal</b> semantics. To this end, this paper proposes an Implicit-Enhanced Causal Inference (IECI) approach to address the challenges of modeling the implicit relations and highlighting them beyond the explicit. Specifically, this approach leverages both the intervention and <b>counterfactual</b> techniques to tackle the above two challenges respectively. Furthermore, a high-quality implicit-enhanced dataset is annotated to evaluate IECI and detailed evaluations show the great advantages of IECI over the state-of-the-art baselines. Particularly, we observe an interesting finding that IECI outperforms the advanced <b>multimodal</b> <b>LLMs</b> by a large margin on this implicit-enhanced dataset, which may facilitate more research to evaluate the <b>multimodal</b> <b>LLMs</b> in this direction.

{{</citation>}}


### (14/48 | 14/321) Resonance RoPE: Improving Context Length Generalization of Large Language Models (Suyuchen Wang et al., 2024)

{{<citation>}}

Suyuchen Wang, Ivan Kobyzev, Peng Lu, Mehdi Rezagholizadeh, Bang Liu. (2024)  
**Resonance RoPE: Improving Context Length Generalization of Large Language Models**
<br/>
<button class="copy-to-clipboard" title="Resonance RoPE: Improving Context Length Generalization of Large Language Models" index=14>
  <span class="copy-to-clipboard-item">Copy Title<span>
</button>
<div class="toast toast-copied toast-index-14 align-items-center text-bg-secondary border-0 position-absolute top-0 end-0" role="alert" aria-live="assertive" aria-atomic="true">
  <div class="d-flex">
    <div class="toast-body">
      Copied!
    </div>
  </div>
</div>

---
Primary Category: cs.CL  
Categories: cs-AI, cs-CL, cs.CL  
Keyword Score: 43  
Keywords: Benchmarking, Out-of-distribution, Transformer, Large Language Model, Large Language Model  
<a type="button" class="btn btn-outline-primary" href="http://arxiv.org/abs/2403.00071v1" target="_blank" >Paper Link</a>
<button type="button" class="btn btn-outline-primary download-pdf" url="https://arxiv.org/pdf/2403.00071v1.pdf" filename="2403.00071v1.pdf">Download PDF</button>

---


**ABSTRACT**  
This paper addresses the challenge of train-short-test-long (TSTL) scenarios in <b>Large</b> <b>Language</b> <b>Models</b> <b>(LLMs)</b> equipped with Rotary Position Embedding (RoPE), where models pre-trained on shorter sequences face difficulty with <b>out-of-distribution</b> (OOD) token positions in longer sequences. We introduce Resonance RoPE, a novel approach designed to narrow the generalization gap in TSTL scenarios by refining the interpolation of RoPE features for OOD positions, significantly improving the model performance without additional online computational costs. Furthermore, we present PosGen, a new synthetic <b>benchmark</b> specifically designed for fine-grained behavior analysis in TSTL scenarios, aiming to isolate the constantly increasing difficulty of token generation on long contexts from the challenges of recognizing new token positions. Our experiments on synthetic tasks show that after applying Resonance RoPE, <b>Transformers</b> recognize OOD position better and more robustly. Our extensive <b>LLM</b> experiments also show superior performance after applying Resonance RoPE to the current state-of-the-art RoPE scaling method, YaRN, on both upstream language modeling tasks and a variety of downstream long-text applications.

{{</citation>}}


### (15/48 | 15/321) Let LLMs Take on the Latest Challenges! A Chinese Dynamic Question Answering Benchmark (Zhikun Xu et al., 2024)

{{<citation>}}

Zhikun Xu, Yinghui Li, Ruixue Ding, Xinyu Wang, Boli Chen, Yong Jiang, Hai-Tao Zheng, Wenlian Lu, Pengjun Xie, Fei Huang. (2024)  
**Let LLMs Take on the Latest Challenges! A Chinese Dynamic Question Answering Benchmark**
<br/>
<button class="copy-to-clipboard" title="Let LLMs Take on the Latest Challenges! A Chinese Dynamic Question Answering Benchmark" index=15>
  <span class="copy-to-clipboard-item">Copy Title<span>
</button>
<div class="toast toast-copied toast-index-15 align-items-center text-bg-secondary border-0 position-absolute top-0 end-0" role="alert" aria-live="assertive" aria-atomic="true">
  <div class="d-flex">
    <div class="toast-body">
      Copied!
    </div>
  </div>
</div>

---
Primary Category: cs.CL  
Categories: cs-CL, cs.CL  
Keyword Score: 43  
Keywords: Benchmarking, Question Answering, Question Answering, Large Language Model, Large Language Model  
<a type="button" class="btn btn-outline-primary" href="http://arxiv.org/abs/2402.19248v2" target="_blank" >Paper Link</a>
<button type="button" class="btn btn-outline-primary download-pdf" url="https://arxiv.org/pdf/2402.19248v2.pdf" filename="2402.19248v2.pdf">Download PDF</button>

---


**ABSTRACT**  
How to better evaluate the capabilities of <b>Large</b> <b>Language</b> <b>Models</b> <b>(LLMs)</b> is the focal point and hot topic in current <b>LLMs</b> research. Previous work has noted that due to the extremely high cost of iterative updates of <b>LLMs,</b> they are often unable to answer the latest dynamic <b>questions</b> <b>well.</b> To promote the improvement of Chinese <b>LLMs'</b> ability to answer dynamic <b>questions,</b> <b>in</b> this paper, we introduce CDQA, a Chinese Dynamic <b>QA</b> <b>benchmark</b> containing <b>question-answer</b> <b>pairs</b> related to the latest news on the Chinese Internet. We obtain high-quality data through a pipeline that combines humans and models, and carefully classify the samples according to the frequency of answer changes to facilitate a more fine-grained observation of <b>LLMs'</b> capabilities. We have also evaluated and analyzed mainstream and advanced Chinese <b>LLMs</b> on CDQA. Extensive experiments and valuable insights suggest that our proposed CDQA is challenging and worthy of more further study. We believe that the <b>benchmark</b> we provide will become one of the key data resources for improving <b>LLMs'</b> Chinese <b>question-answering</b> <b>ability</b> in the future.

{{</citation>}}


### (16/48 | 16/321) TV-TREES: Multimodal Entailment Trees for Neuro-Symbolic Video Reasoning (Kate Sanders et al., 2024)

{{<citation>}}

Kate Sanders, Nathaniel Weir, Benjamin Van Durme. (2024)  
**TV-TREES: Multimodal Entailment Trees for Neuro-Symbolic Video Reasoning**
<br/>
<button class="copy-to-clipboard" title="TV-TREES: Multimodal Entailment Trees for Neuro-Symbolic Video Reasoning" index=16>
  <span class="copy-to-clipboard-item">Copy Title<span>
</button>
<div class="toast toast-copied toast-index-16 align-items-center text-bg-secondary border-0 position-absolute top-0 end-0" role="alert" aria-live="assertive" aria-atomic="true">
  <div class="d-flex">
    <div class="toast-body">
      Copied!
    </div>
  </div>
</div>

---
Primary Category: cs.CL  
Categories: I-2-7; I-2-10, cs-AI, cs-CL, cs-CV, cs.CL  
Keyword Score: 41  
Keywords: Black Box, Multi-modal, Multi-modal, Zero-shot, Question Answering, Reasoning  
<a type="button" class="btn btn-outline-primary" href="http://arxiv.org/abs/2402.19467v2" target="_blank" >Paper Link</a>
<button type="button" class="btn btn-outline-primary download-pdf" url="https://arxiv.org/pdf/2402.19467v2.pdf" filename="2402.19467v2.pdf">Download PDF</button>

---


**ABSTRACT**  
It is challenging to perform <b>question-answering</b> <b>over</b> complex, <b>multimodal</b> content such as television clips. This is in part because current video-language models rely on single-modality <b>reasoning,</b> have lowered performance on long inputs, and lack interpetability. We propose TV-TREES, the first <b>multimodal</b> entailment tree generator. TV-TREES serves as an approach to video understanding that promotes interpretable joint-modality <b>reasoning</b> by producing trees of entailment relationships between simple premises directly entailed by the videos and higher-level conclusions. We then introduce the task of <b>multimodal</b> entailment tree generation to evaluate the <b>reasoning</b> quality of such methods. Our method's experimental results on the challenging TVQA dataset demonstrate intepretable, state-of-the-art <b>zero-shot</b> performance on full video clips, illustrating a best of both worlds contrast to <b>black-box</b> <b>methods.</b>

{{</citation>}}


### (17/48 | 17/321) EBBS: An Ensemble with Bi-Level Beam Search for Zero-Shot Machine Translation (Yuqiao Wen et al., 2024)

{{<citation>}}

Yuqiao Wen, Behzad Shayegh, Chenyang Huang, Yanshuai Cao, Lili Mou. (2024)  
**EBBS: An Ensemble with Bi-Level Beam Search for Zero-Shot Machine Translation**
<br/>
<button class="copy-to-clipboard" title="EBBS: An Ensemble with Bi-Level Beam Search for Zero-Shot Machine Translation" index=17>
  <span class="copy-to-clipboard-item">Copy Title<span>
</button>
<div class="toast toast-copied toast-index-17 align-items-center text-bg-secondary border-0 position-absolute top-0 end-0" role="alert" aria-live="assertive" aria-atomic="true">
  <div class="d-flex">
    <div class="toast-body">
      Copied!
    </div>
  </div>
</div>

---
Primary Category: cs.CL  
Categories: I-2-7; I-2-6; I-2-m; I-5-1; I-7-m, cs-AI, cs-CL, cs-LG, cs.CL  
Keyword Score: 40  
Keywords: Knowledge Distillation, Knowledge Distillation, Zero-shot, Neural Machine Translation  
<a type="button" class="btn btn-outline-primary" href="http://arxiv.org/abs/2403.00144v1" target="_blank" >Paper Link</a>
<button type="button" class="btn btn-outline-primary download-pdf" url="https://arxiv.org/pdf/2403.00144v1.pdf" filename="2403.00144v1.pdf">Download PDF</button>

---


**ABSTRACT**  
The ability of <b>zero-shot</b> translation emerges when we train a multilingual model with certain translation directions; the model can then directly translate in unseen directions. Alternatively, <b>zero-shot</b> translation can be accomplished by pivoting through a third language (e.g., English). In our work, we observe that both direct and pivot translations are noisy and achieve less satisfactory performance. We propose EBBS, an ensemble method with a novel bi-level beam search algorithm, where each ensemble component explores its own prediction step by step at the lower level but they are synchronized by a "soft voting" mechanism at the upper level. Results on two popular multilingual translation datasets show that EBBS consistently outperforms direct and pivot translations as well as existing ensemble techniques. Further, we can <b>distill</b> the ensemble's knowledge back to the multilingual model to improve inference efficiency; profoundly, our EBBS-based <b>distillation</b> does not sacrifice, or even improves, the translation quality.

{{</citation>}}


### (18/48 | 18/321) FAC$^2$E: Better Understanding Large Language Model Capabilities by Dissociating Language and Cognition (Xiaoqiang Wang et al., 2024)

{{<citation>}}

Xiaoqiang Wang, Bang Liu, Lingfei Wu. (2024)  
**FAC$^2$E: Better Understanding Large Language Model Capabilities by Dissociating Language and Cognition**
<br/>
<button class="copy-to-clipboard" title="FAC$^2$E: Better Understanding Large Language Model Capabilities by Dissociating Language and Cognition" index=18>
  <span class="copy-to-clipboard-item">Copy Title<span>
</button>
<div class="toast toast-copied toast-index-18 align-items-center text-bg-secondary border-0 position-absolute top-0 end-0" role="alert" aria-live="assertive" aria-atomic="true">
  <div class="d-flex">
    <div class="toast-body">
      Copied!
    </div>
  </div>
</div>

---
Primary Category: cs.CL  
Categories: cs-CL, cs.CL  
Keyword Score: 40  
Keywords: Reasoning, Large Language Model, Large Language Model, Text Understanding  
<a type="button" class="btn btn-outline-primary" href="http://arxiv.org/abs/2403.00126v1" target="_blank" >Paper Link</a>
<button type="button" class="btn btn-outline-primary download-pdf" url="https://arxiv.org/pdf/2403.00126v1.pdf" filename="2403.00126v1.pdf">Download PDF</button>

---


**ABSTRACT**  
<b>Large</b> <b>language</b> <b>models</b> <b>(LLMs)</b> are primarily evaluated by overall performance on various <b>text</b> <b>understanding</b> and generation tasks. However, such a paradigm fails to comprehensively differentiate the fine-grained language and cognitive skills, rendering the lack of sufficient interpretation to <b>LLMs'</b> capabilities. In this paper, we present FAC$^2$E, a framework for Fine-grAined and Cognition-grounded <b>LLMs'</b> Capability Evaluation. Specifically, we formulate <b>LLMs'</b> evaluation in a multi-dimensional and explainable manner by dissociating the language-related capabilities and the cognition-related ones. Besides, through extracting the intermediate <b>reasoning</b> from <b>LLMs,</b> we further break down the process of applying a specific capability into three sub-steps: recalling relevant knowledge, utilizing knowledge, and solving problems. Finally, FAC$^2$E evaluates each sub-step of each fine-grained capability, providing a two-faceted diagnosis for <b>LLMs.</b> Utilizing FAC$^2$E, we identify a common shortfall in knowledge utilization among models and propose a straightforward, knowledge-enhanced method to mitigate this issue. Our results not only showcase promising performance enhancements but also highlight a direction for future <b>LLM</b> advancements.

{{</citation>}}


### (19/48 | 19/321) Loose LIPS Sink Ships: Asking Questions in Battleship with Language-Informed Program Sampling (Gabriel Grand et al., 2024)

{{<citation>}}

Gabriel Grand, Valerio Pepe, Jacob Andreas, Joshua B. Tenenbaum. (2024)  
**Loose LIPS Sink Ships: Asking Questions in Battleship with Language-Informed Program Sampling**
<br/>
<button class="copy-to-clipboard" title="Loose LIPS Sink Ships: Asking Questions in Battleship with Language-Informed Program Sampling" index=19>
  <span class="copy-to-clipboard-item">Copy Title<span>
</button>
<div class="toast toast-copied toast-index-19 align-items-center text-bg-secondary border-0 position-absolute top-0 end-0" role="alert" aria-live="assertive" aria-atomic="true">
  <div class="d-flex">
    <div class="toast-body">
      Copied!
    </div>
  </div>
</div>

---
Primary Category: cs.CL  
Categories: cs-AI, cs-CL, cs.CL  
Keyword Score: 40  
Keywords: GPT, Reasoning, Large Language Model, Large Language Model  
<a type="button" class="btn btn-outline-primary" href="http://arxiv.org/abs/2402.19471v1" target="_blank" >Paper Link</a>
<button type="button" class="btn btn-outline-primary download-pdf" url="https://arxiv.org/pdf/2402.19471v1.pdf" filename="2402.19471v1.pdf">Download PDF</button>

---


**ABSTRACT**  
Questions combine our mastery of language with our remarkable facility for <b>reasoning</b> about uncertainty. How do people navigate vast hypothesis spaces to pose informative questions given limited cognitive resources? We study these tradeoffs in a classic grounded question-asking task based on the board game Battleship. Our language-informed program sampling (LIPS) model uses <b>large</b> <b>language</b> <b>models</b> <b>(LLMs)</b> to generate natural language questions, translate them into symbolic programs, and evaluate their expected information gain. We find that with a surprisingly modest resource budget, this simple Monte Carlo optimization strategy yields informative questions that mirror human performance across varied Battleship board scenarios. In contrast, <b>LLM-only</b> baselines struggle to ground questions in the board state; notably, <b>GPT-4V</b> provides no improvement over non-visual baselines. Our results illustrate how Bayesian models of question-asking can leverage the statistics of language to capture human priors, while highlighting some shortcomings of pure <b>LLMs</b> as grounded reasoners.

{{</citation>}}


### (20/48 | 20/321) Towards Tracing Trustworthiness Dynamics: Revisiting Pre-training Period of Large Language Models (Chen Qian et al., 2024)

{{<citation>}}

Chen Qian, Jie Zhang, Wei Yao, Dongrui Liu, Zhenfei Yin, Yu Qiao, Yong Liu, Jing Shao. (2024)  
**Towards Tracing Trustworthiness Dynamics: Revisiting Pre-training Period of Large Language Models**
<br/>
<button class="copy-to-clipboard" title="Towards Tracing Trustworthiness Dynamics: Revisiting Pre-training Period of Large Language Models" index=20>
  <span class="copy-to-clipboard-item">Copy Title<span>
</button>
<div class="toast toast-copied toast-index-20 align-items-center text-bg-secondary border-0 position-absolute top-0 end-0" role="alert" aria-live="assertive" aria-atomic="true">
  <div class="d-flex">
    <div class="toast-body">
      Copied!
    </div>
  </div>
</div>

---
Primary Category: cs.CL  
Categories: cs-AI, cs-CL, cs.CL  
Keyword Score: 40  
Keywords: Fairness, Mutual Information, Large Language Model, Large Language Model  
<a type="button" class="btn btn-outline-primary" href="http://arxiv.org/abs/2402.19465v1" target="_blank" >Paper Link</a>
<button type="button" class="btn btn-outline-primary download-pdf" url="https://arxiv.org/pdf/2402.19465v1.pdf" filename="2402.19465v1.pdf">Download PDF</button>

---


**ABSTRACT**  
Ensuring the trustworthiness of <b>large</b> <b>language</b> <b>models</b> <b>(LLMs)</b> is crucial. Most studies concentrate on fully pre-trained <b>LLMs</b> to better understand and improve <b>LLMs'</b> trustworthiness. In this paper, to reveal the untapped potential of pre-training, we pioneer the exploration of <b>LLMs'</b> trustworthiness during this period, focusing on five key dimensions: reliability, privacy, toxicity, <b>fairness,</b> and robustness. To begin with, we apply linear probing to <b>LLMs.</b> The high probing accuracy suggests that \textit{LLMs in early pre-training can already distinguish concepts in each trustworthiness dimension}. Therefore, to further uncover the hidden possibilities of pre-training, we extract steering vectors from a <b>LLM's</b> pre-training checkpoints to enhance the <b>LLM's</b> trustworthiness. Finally, inspired by~\citet{choi2023understanding} that <b>mutual</b> <b>information</b> estimation is bounded by linear probing accuracy, we also probe <b>LLMs</b> with <b>mutual</b> <b>information</b> to investigate the dynamics of trustworthiness during pre-training. We are the first to observe a similar two-phase phenomenon: fitting and compression~\citep{shwartz2017opening}. This research provides an initial exploration of trustworthiness modeling during <b>LLM</b> pre-training, seeking to unveil new insights and spur further developments in the field. We will make our code publicly accessible at \url{https://github.com/ChnQ/TracingLLM}.

{{</citation>}}


### (21/48 | 21/321) Here's a Free Lunch: Sanitizing Backdoored Models with Model Merge (Ansh Arora et al., 2024)

{{<citation>}}

Ansh Arora, Xuanli He, Maximilian Mozes, Srinibas Swain, Mark Dras, Qiongkai Xu. (2024)  
**Here's a Free Lunch: Sanitizing Backdoored Models with Model Merge**
<br/>
<button class="copy-to-clipboard" title="Here's a Free Lunch: Sanitizing Backdoored Models with Model Merge" index=21>
  <span class="copy-to-clipboard-item">Copy Title<span>
</button>
<div class="toast toast-copied toast-index-21 align-items-center text-bg-secondary border-0 position-absolute top-0 end-0" role="alert" aria-live="assertive" aria-atomic="true">
  <div class="d-flex">
    <div class="toast-body">
      Copied!
    </div>
  </div>
</div>

---
Primary Category: cs.CL  
Categories: cs-CL, cs.CL  
Keyword Score: 40  
Keywords: BERT, Mistral, RoBERTa, Pre-trained Language Model  
<a type="button" class="btn btn-outline-primary" href="http://arxiv.org/abs/2402.19334v1" target="_blank" >Paper Link</a>
<button type="button" class="btn btn-outline-primary download-pdf" url="https://arxiv.org/pdf/2402.19334v1.pdf" filename="2402.19334v1.pdf">Download PDF</button>

---


**ABSTRACT**  
The democratization of <b>pre-trained</b> <b>language</b> <b>models</b> through open-source initiatives has rapidly advanced innovation and expanded access to cutting-edge technologies. However, this openness also brings significant security risks, including backdoor attacks, where hidden malicious behaviors are triggered by specific inputs, compromising natural language processing (NLP) system integrity and reliability. This paper suggests that merging a backdoored model with other homogeneous models can remediate backdoor vulnerabilities even if such models are not entirely secure. In our experiments, we explore various models <b>(BERT-Base,</b> <b>RoBERTa-Large,</b> Llama2-7B, and <b>Mistral-7B)</b> and datasets (SST-2, OLID, AG News, and QNLI). Compared to multiple advanced defensive approaches, our method offers an effective and efficient inference-stage defense against backdoor attacks without additional resources or specific knowledge. Our approach consistently outperforms the other advanced baselines, leading to an average of 75% reduction in the attack success rate. Since model merging has been an established approach for improving model performance, the extra advantage it provides regarding defense can be seen as a cost-free bonus.

{{</citation>}}


### (22/48 | 22/321) PeLLE: Encoder-based language models for Brazilian Portuguese based on open data (Guilherme Lamartine de Mello et al., 2024)

{{<citation>}}

Guilherme Lamartine de Mello, Marcelo Finger, and Felipe Serras, Miguel de Mello Carpi, Marcos Menon Jose, Pedro Henrique Domingues, Paulo Cavalim. (2024)  
**PeLLE: Encoder-based language models for Brazilian Portuguese based on open data**
<br/>
<button class="copy-to-clipboard" title="PeLLE: Encoder-based language models for Brazilian Portuguese based on open data" index=22>
  <span class="copy-to-clipboard-item">Copy Title<span>
</button>
<div class="toast toast-copied toast-index-22 align-items-center text-bg-secondary border-0 position-absolute top-0 end-0" role="alert" aria-live="assertive" aria-atomic="true">
  <div class="d-flex">
    <div class="toast-body">
      Copied!
    </div>
  </div>
</div>

---
Primary Category: cs.CL  
Categories: I-2-7, cs-CL, cs.CL  
Keyword Score: 40  
Keywords: RoBERTa, Transformer, Large Language Model, Large Language Model  
<a type="button" class="btn btn-outline-primary" href="http://arxiv.org/abs/2402.19204v1" target="_blank" >Paper Link</a>
<button type="button" class="btn btn-outline-primary download-pdf" url="https://arxiv.org/pdf/2402.19204v1.pdf" filename="2402.19204v1.pdf">Download PDF</button>

---


**ABSTRACT**  
In this paper we present PeLLE, a family of <b>large</b> <b>language</b> <b>models</b> based on the <b>RoBERTa</b> architecture, for Brazilian Portuguese, trained on curated, open data from the Carolina corpus. Aiming at reproducible results, we describe details of the pretraining of the models. We also evaluate PeLLE models against a set of existing multilingual and PT-BR refined pretrained <b>Transformer-based</b> <b>LLM</b> encoders, contrasting performance of <b>large</b> <b>versus</b> <b>smaller-but-curated</b> pretrained models in several downstream tasks. We conclude that several tasks perform better with larger models, but some tasks benefit from smaller-but-curated data in its pretraining.

{{</citation>}}


### (23/48 | 23/321) TEncDM: Understanding the Properties of Diffusion Model in the Space of Language Model Encodings (Alexander Shabalin et al., 2024)

{{<citation>}}

Alexander Shabalin, Viacheslav Meshchaninov, Tingir Badmaev, Dmitry Molchanov, Grigory Bartosh, Sergey Markov, Dmitry Vetrov. (2024)  
**TEncDM: Understanding the Properties of Diffusion Model in the Space of Language Model Encodings**
<br/>
<button class="copy-to-clipboard" title="TEncDM: Understanding the Properties of Diffusion Model in the Space of Language Model Encodings" index=23>
  <span class="copy-to-clipboard-item">Copy Title<span>
</button>
<div class="toast toast-copied toast-index-23 align-items-center text-bg-secondary border-0 position-absolute top-0 end-0" role="alert" aria-live="assertive" aria-atomic="true">
  <div class="d-flex">
    <div class="toast-body">
      Copied!
    </div>
  </div>
</div>

---
Primary Category: cs.CL  
Categories: I-2; I-7, cs-CL, cs.CL  
Keyword Score: 40  
Keywords: Diffusion Model, Transformer, Text Generation, Large Language Model  
<a type="button" class="btn btn-outline-primary" href="http://arxiv.org/abs/2402.19097v1" target="_blank" >Paper Link</a>
<button type="button" class="btn btn-outline-primary download-pdf" url="https://arxiv.org/pdf/2402.19097v1.pdf" filename="2402.19097v1.pdf">Download PDF</button>

---


**ABSTRACT**  
Drawing inspiration from the success of <b>diffusion</b> <b>models</b> in various domains, numerous research papers proposed methods for adapting them to <b>text</b> <b>data.</b> Despite these efforts, none of them has managed to achieve the quality of the <b>large</b> <b>language</b> <b>models.</b> In this paper, we conduct a comprehensive analysis of key components of the <b>text</b> <b>diffusion</b> <b>models</b> and introduce a novel approach named <b>Text</b> <b>Encoding</b> <b>Diffusion</b> <b>Model</b> (TEncDM). Instead of the commonly used token embedding space, we train our model in the space of the language model encodings. Additionally, we propose to use a <b>Transformer-based</b> decoder that utilizes contextual information for <b>text</b> <b>reconstruction.</b> We also analyse self-conditioning and find that it increases the magnitude of the model outputs, allowing the reduction of the number of denoising steps at the inference stage. Evaluation of TEncDM on two downstream <b>text</b> <b>generation</b> tasks, QQP and XSum, demonstrates its superiority over existing non-autoregressive models.

{{</citation>}}


### (24/48 | 24/321) Prompting ChatGPT for Translation: A Comparative Analysis of Translation Brief and Persona Prompts (Sui He, 2024)

{{<citation>}}

Sui He. (2024)  
**Prompting ChatGPT for Translation: A Comparative Analysis of Translation Brief and Persona Prompts**
<br/>
<button class="copy-to-clipboard" title="Prompting ChatGPT for Translation: A Comparative Analysis of Translation Brief and Persona Prompts" index=24>
  <span class="copy-to-clipboard-item">Copy Title<span>
</button>
<div class="toast toast-copied toast-index-24 align-items-center text-bg-secondary border-0 position-absolute top-0 end-0" role="alert" aria-live="assertive" aria-atomic="true">
  <div class="d-flex">
    <div class="toast-body">
      Copied!
    </div>
  </div>
</div>

---
Primary Category: cs.CL  
Categories: cs-CL, cs-CY, cs-HC, cs.CL  
Keyword Score: 30  
Keywords: ChatGPT, Large Language Model, Prompt  
<a type="button" class="btn btn-outline-primary" href="http://arxiv.org/abs/2403.00127v1" target="_blank" >Paper Link</a>
<button type="button" class="btn btn-outline-primary download-pdf" url="https://arxiv.org/pdf/2403.00127v1.pdf" filename="2403.00127v1.pdf">Download PDF</button>

---


**ABSTRACT**  
<b>Prompt</b> engineering in <b>LLMs</b> has shown potential for improving translation quality. However, the potential of incorporating translation concepts in <b>prompt</b> design remains largely underexplored. Against this backdrop, this paper discusses the effectiveness of incorporating the conceptual tool of translation brief and the personas of translator and author into <b>prompt</b> design for translation tasks in <b>ChatGPT.</b> Findings suggest that, although certain elements are constructive in facilitating human to human communication for translation tasks, their effectiveness is limited for improving translation quality in <b>ChatGPT.</b> This accentuates the need for more explorative research on how translation theorists and practitioners can develop the current set of conceptual tools rooted in the human to human communication paradigm for translation purposes in this emerging workflow involving human machine interaction.

{{</citation>}}


### (25/48 | 25/321) On the Scaling Laws of Geographical Representation in Language Models (Nathan Godey et al., 2024)

{{<citation>}}

Nathan Godey, Éric de la Clergerie, Benoît Sagot. (2024)  
**On the Scaling Laws of Geographical Representation in Language Models**
<br/>
<button class="copy-to-clipboard" title="On the Scaling Laws of Geographical Representation in Language Models" index=25>
  <span class="copy-to-clipboard-item">Copy Title<span>
</button>
<div class="toast toast-copied toast-index-25 align-items-center text-bg-secondary border-0 position-absolute top-0 end-0" role="alert" aria-live="assertive" aria-atomic="true">
  <div class="d-flex">
    <div class="toast-body">
      Copied!
    </div>
  </div>
</div>

---
Primary Category: cs.CL  
Categories: cs-AI, cs-CL, cs.CL  
Keyword Score: 30  
Keywords: Large Language Model, Large Language Model, Scaling Law  
<a type="button" class="btn btn-outline-primary" href="http://arxiv.org/abs/2402.19406v2" target="_blank" >Paper Link</a>
<button type="button" class="btn btn-outline-primary download-pdf" url="https://arxiv.org/pdf/2402.19406v2.pdf" filename="2402.19406v2.pdf">Download PDF</button>

---


**ABSTRACT**  
Language models have long been shown to embed geographical information in their hidden representations. This line of work has recently been revisited by extending this result to <b>Large</b> <b>Language</b> <b>Models</b> <b>(LLMs).</b> In this paper, we propose to fill the gap between well-established and recent literature by observing how geographical knowledge evolves when <b>scaling</b> <b>language</b> models. We show that geographical knowledge is observable even for tiny models, and that it scales consistently as we increase the model size. Notably, we observe that larger language models cannot mitigate the geographical bias that is inherent to the training data.

{{</citation>}}


### (26/48 | 26/321) Memory-Augmented Generative Adversarial Transformers (Stephan Raaijmakers et al., 2024)

{{<citation>}}

Stephan Raaijmakers, Roos Bakker, Anita Cremers, Roy de Kleijn, Tom Kouwenhoven, Tessa Verhoef. (2024)  
**Memory-Augmented Generative Adversarial Transformers**
<br/>
<button class="copy-to-clipboard" title="Memory-Augmented Generative Adversarial Transformers" index=26>
  <span class="copy-to-clipboard-item">Copy Title<span>
</button>
<div class="toast toast-copied toast-index-26 align-items-center text-bg-secondary border-0 position-absolute top-0 end-0" role="alert" aria-live="assertive" aria-atomic="true">
  <div class="d-flex">
    <div class="toast-body">
      Copied!
    </div>
  </div>
</div>

---
Primary Category: cs.CL  
Categories: cs-CL, cs.CL  
Keyword Score: 30  
Keywords: Generative Adversarial Network, Transformer, Large Language Model  
<a type="button" class="btn btn-outline-primary" href="http://arxiv.org/abs/2402.19218v1" target="_blank" >Paper Link</a>
<button type="button" class="btn btn-outline-primary download-pdf" url="https://arxiv.org/pdf/2402.19218v1.pdf" filename="2402.19218v1.pdf">Download PDF</button>

---


**ABSTRACT**  
Conversational AI systems that rely on <b>Large</b> <b>Language</b> <b>Models,</b> like <b>Transformers,</b> have difficulty interweaving external data (like facts) with the language they generate. Vanilla <b>Transformer</b> architectures are not designed for answering factual questions with high accuracy. This paper investigates a possible route for addressing this problem. We propose to extend the standard <b>Transformer</b> architecture with an additional memory bank holding extra information (such as facts drawn from a knowledge base), and an extra attention layer for addressing this memory. We add this augmented memory to a <b>Generative</b> <b>Adversarial</b> <b>Network-inspired</b> <b>Transformer</b> architecture. This setup allows for implementing arbitrary felicity conditions on the generated language of the <b>Transformer.</b> We first demonstrate how this machinery can be deployed for handling factual questions in goal-oriented dialogues. Secondly, we demonstrate that our approach can be useful for applications like {\it style adaptation} as well: the adaptation of utterances according to certain stylistic (external) constraints, like social properties of human interlocutors in dialogues.

{{</citation>}}


### (27/48 | 27/321) Survey in Characterization of Semantic Change (Jader Martins Camboim de Sá et al., 2024)

{{<citation>}}

Jader Martins Camboim de Sá, Marcos Da Silveira, Cédric Pruski. (2024)  
**Survey in Characterization of Semantic Change**
<br/>
<button class="copy-to-clipboard" title="Survey in Characterization of Semantic Change" index=27>
  <span class="copy-to-clipboard-item">Copy Title<span>
</button>
<div class="toast toast-copied toast-index-27 align-items-center text-bg-secondary border-0 position-absolute top-0 end-0" role="alert" aria-live="assertive" aria-atomic="true">
  <div class="d-flex">
    <div class="toast-body">
      Copied!
    </div>
  </div>
</div>

---
Primary Category: cs.CL  
Categories: cs-AI, cs-CL, cs.CL  
Keyword Score: 30  
Keywords: Information Retrieval, Question Answering, Summarization  
<a type="button" class="btn btn-outline-primary" href="http://arxiv.org/abs/2402.19088v1" target="_blank" >Paper Link</a>
<button type="button" class="btn btn-outline-primary download-pdf" url="https://arxiv.org/pdf/2402.19088v1.pdf" filename="2402.19088v1.pdf">Download PDF</button>

---


**ABSTRACT**  
Live languages continuously evolve to integrate the cultural change of human societies. This evolution manifests through neologisms (new words) or \textbf{semantic changes} of words (new meaning to existing words). Understanding the meaning of words is vital for interpreting texts coming from different cultures (regionalism or slang), domains (e.g., technical terms), or periods. In computer science, these words are relevant to computational linguistics algorithms such as translation, <b>information</b> <b>retrieval,</b> <b>question</b> <b>answering,</b> etc. Semantic changes can potentially impact the quality of the outcomes of these algorithms. Therefore, it is important to understand and characterize these changes formally. The study of this impact is a recent problem that has attracted the attention of the computational linguistics community. Several approaches propose methods to detect semantic changes with good precision, but more effort is needed to characterize how the meaning of words changes and to reason about how to reduce the impact of semantic change. This survey provides an understandable overview of existing approaches to the \textit{characterization of semantic changes} and also formally defines three classes of characterizations: if the meaning of a word becomes more general or narrow (change in dimension) if the word is used in a more pejorative or positive/ameliorated sense (change in orientation), and if there is a trend to use the word in a, for instance, metaphoric or metonymic context (change in relation). We <b>summarized</b> the main aspects of the selected publications in a table and discussed the needs and trends in the research activities on semantic change characterization.

{{</citation>}}


### (28/48 | 28/321) Pointing out the Shortcomings of Relation Extraction Models with Semantically Motivated Adversarials (Gennaro Nolano et al., 2024)

{{<citation>}}

Gennaro Nolano, Moritz Blum, Basil Ell, Philipp Cimiano. (2024)  
**Pointing out the Shortcomings of Relation Extraction Models with Semantically Motivated Adversarials**
<br/>
<button class="copy-to-clipboard" title="Pointing out the Shortcomings of Relation Extraction Models with Semantically Motivated Adversarials" index=28>
  <span class="copy-to-clipboard-item">Copy Title<span>
</button>
<div class="toast toast-copied toast-index-28 align-items-center text-bg-secondary border-0 position-absolute top-0 end-0" role="alert" aria-live="assertive" aria-atomic="true">
  <div class="d-flex">
    <div class="toast-body">
      Copied!
    </div>
  </div>
</div>

---
Primary Category: cs.CL  
Categories: cs-CL, cs.CL  
Keyword Score: 30  
Keywords: Out-of-distribution, Relation Extraction, Large Language Model  
<a type="button" class="btn btn-outline-primary" href="http://arxiv.org/abs/2402.19076v1" target="_blank" >Paper Link</a>
<button type="button" class="btn btn-outline-primary download-pdf" url="https://arxiv.org/pdf/2402.19076v1.pdf" filename="2402.19076v1.pdf">Download PDF</button>

---


**ABSTRACT**  
In recent years, <b>large</b> <b>language</b> <b>models</b> have achieved state-of-the-art performance across various NLP tasks. However, investigations have shown that these models tend to rely on shortcut features, leading to inaccurate predictions and causing the models to be unreliable at generalization to <b>out-of-distribution</b> (OOD) samples. For instance, in the context of <b>relation</b> <b>extraction</b> (RE), we would expect a model to identify the same <b>relation</b> <b>independently</b> of the entities involved in it. For example, consider the sentence "Leonardo da Vinci painted the Mona Lisa" expressing the created(Leonardo_da_Vinci, Mona_Lisa) <b>relation.</b> <b>If</b> we substiute "Leonardo da Vinci" with "Barack Obama", then the sentence still expresses the created <b>relation.</b> <b>A</b> robust model is supposed to detect the same <b>relation</b> <b>in</b> both cases. In this work, we describe several semantically-motivated strategies to generate adversarial examples by replacing entity mentions and investigate how state-of-the-art RE models perform under pressure. Our analyses show that the performance of these models significantly deteriorates on the modified datasets (avg. of -48.5% in F1), which indicates that these models rely to a great extent on shortcuts, such as surface forms (or patterns therein) of entities, without making full use of the information present in the sentences.

{{</citation>}}


### (29/48 | 29/321) Inappropriate Pause Detection In Dysarthric Speech Using Large-Scale Speech Recognition (Jeehyun Lee et al., 2024)

{{<citation>}}

Jeehyun Lee, Yerin Choi, Tae-Jin Song, Myoung-Wan Koo. (2024)  
**Inappropriate Pause Detection In Dysarthric Speech Using Large-Scale Speech Recognition**
<br/>
<button class="copy-to-clipboard" title="Inappropriate Pause Detection In Dysarthric Speech Using Large-Scale Speech Recognition" index=29>
  <span class="copy-to-clipboard-item">Copy Title<span>
</button>
<div class="toast toast-copied toast-index-29 align-items-center text-bg-secondary border-0 position-absolute top-0 end-0" role="alert" aria-live="assertive" aria-atomic="true">
  <div class="d-flex">
    <div class="toast-body">
      Copied!
    </div>
  </div>
</div>

---
Primary Category: cs.CL  
Categories: cs-CL, cs-SD, cs.CL, eess-AS  
Keyword Score: 30  
Keywords: Automatic Speech Recognition, Automatic Speech Recognition, Automatic Speech Recognition  
<a type="button" class="btn btn-outline-primary" href="http://arxiv.org/abs/2402.18923v1" target="_blank" >Paper Link</a>
<button type="button" class="btn btn-outline-primary download-pdf" url="https://arxiv.org/pdf/2402.18923v1.pdf" filename="2402.18923v1.pdf">Download PDF</button>

---


**ABSTRACT**  
Dysarthria, a common issue among stroke patients, severely impacts <b>speech</b> <b>intelligibility.</b> Inappropriate pauses are crucial indicators in severity assessment and <b>speech-language</b> <b>therapy.</b> We propose to extend a large-scale <b>speech</b> <b>recognition</b> model for inappropriate pause detection in dysarthric <b>speech.</b> <b>To</b> this end, we propose task design, labeling strategy, and a <b>speech</b> <b>recognition</b> model with an inappropriate pause prediction layer. First, we treat pause detection as <b>speech</b> <b>recognition,</b> using an <b>automatic</b> <b>speech</b> <b>recognition</b> <b>(ASR)</b> model to convert <b>speech</b> <b>into</b> text with pause tags. According to the newly designed task, we label pause locations at the text level and their appropriateness. We collaborate with <b>speech-language</b> <b>pathologists</b> to establish labeling criteria, ensuring high-quality annotated data. Finally, we extend the <b>ASR</b> model with an inappropriate pause prediction layer for end-to-end inappropriate pause detection. Moreover, we propose a task-tailored metric for evaluating inappropriate pause detection independent of <b>ASR</b> performance. Our experiments show that the proposed method better detects inappropriate pauses in dysarthric <b>speech</b> <b>than</b> baselines. (Inappropriate Pause Error Rate: 14.47%)

{{</citation>}}


### (30/48 | 30/321) AdaMergeX: Cross-Lingual Transfer with Large Language Models via Adaptive Adapter Merging (Yiran Zhao et al., 2024)

{{<citation>}}

Yiran Zhao, Wenxuan Zhang, Huiming Wang, Kenji Kawaguchi, Lidong Bing. (2024)  
**AdaMergeX: Cross-Lingual Transfer with Large Language Models via Adaptive Adapter Merging**
<br/>
<button class="copy-to-clipboard" title="AdaMergeX: Cross-Lingual Transfer with Large Language Models via Adaptive Adapter Merging" index=30>
  <span class="copy-to-clipboard-item">Copy Title<span>
</button>
<div class="toast toast-copied toast-index-30 align-items-center text-bg-secondary border-0 position-absolute top-0 end-0" role="alert" aria-live="assertive" aria-atomic="true">
  <div class="d-flex">
    <div class="toast-body">
      Copied!
    </div>
  </div>
</div>

---
Primary Category: cs.CL  
Categories: cs-AI, cs-CL, cs.CL  
Keyword Score: 30  
Keywords: Fine-tuning, Fine-tuning, Large Language Model  
<a type="button" class="btn btn-outline-primary" href="http://arxiv.org/abs/2402.18913v1" target="_blank" >Paper Link</a>
<button type="button" class="btn btn-outline-primary download-pdf" url="https://arxiv.org/pdf/2402.18913v1.pdf" filename="2402.18913v1.pdf">Download PDF</button>

---


**ABSTRACT**  
As an effective alternative to the direct <b>fine-tuning</b> on target tasks in specific languages, cross-lingual transfer addresses the challenges of limited training data by decoupling ''task ability'' and ''language ability'' by <b>fine-tuning</b> on the target task in the source language and another selected task in the target language, respectively. However, they fail to fully separate the task ability from the source language or the language ability from the chosen task. In this paper, we acknowledge the mutual reliance between task ability and language ability and direct our attention toward the gap between the target language and the source language on tasks. As the gap removes the impact of tasks, we assume that it remains consistent across tasks. Based on this assumption, we propose a new cross-lingual transfer method called $\texttt{AdaMergeX}$ that utilizes adaptive adapter merging. By introducing a reference task, we can determine that the divergence of adapters <b>fine-tuned</b> on the reference task in both languages follows the same distribution as the divergence of adapters <b>fine-tuned</b> on the target task in both languages. Hence, we can obtain target adapters by combining the other three adapters. Furthermore, we propose a structure-adaptive adapter merging method. Our empirical results demonstrate that our approach yields new and effective cross-lingual transfer, outperforming existing methods across all settings.

{{</citation>}}


### (31/48 | 31/321) Reducing Hallucinations in Entity Abstract Summarization with Facts-Template Decomposition (Fangwei Zhu et al., 2024)

{{<citation>}}

Fangwei Zhu, Peiyi Wang, Zhifang Sui. (2024)  
**Reducing Hallucinations in Entity Abstract Summarization with Facts-Template Decomposition**
<br/>
<button class="copy-to-clipboard" title="Reducing Hallucinations in Entity Abstract Summarization with Facts-Template Decomposition" index=31>
  <span class="copy-to-clipboard-item">Copy Title<span>
</button>
<div class="toast toast-copied toast-index-31 align-items-center text-bg-secondary border-0 position-absolute top-0 end-0" role="alert" aria-live="assertive" aria-atomic="true">
  <div class="d-flex">
    <div class="toast-body">
      Copied!
    </div>
  </div>
</div>

---
Primary Category: cs.CL  
Categories: cs-CL, cs.CL  
Keyword Score: 30  
Keywords: Pre-trained Language Model, Pre-trained Language Model, Summarization  
<a type="button" class="btn btn-outline-primary" href="http://arxiv.org/abs/2402.18873v1" target="_blank" >Paper Link</a>
<button type="button" class="btn btn-outline-primary download-pdf" url="https://arxiv.org/pdf/2402.18873v1.pdf" filename="2402.18873v1.pdf">Download PDF</button>

---


**ABSTRACT**  
Entity abstract <b>summarization</b> aims to generate a coherent description of a given entity based on a set of relevant Internet documents. <b>Pretrained</b> <b>language</b> <b>models</b> <b>(PLMs)</b> have achieved significant success in this task, but they may suffer from hallucinations, i.e. generating non-factual information about the entity. To address this issue, we decompose the summary into two components: Facts that represent the factual information about the given entity, which <b>PLMs</b> are prone to fabricate; and Template that comprises generic content with designated slots for facts, which <b>PLMs</b> can generate competently. Based on the facts-template decomposition, we propose SlotSum, an explainable framework for entity abstract <b>summarization.</b> SlotSum first creates the template and then predicts the fact for each template slot based on the input documents. Benefiting from our facts-template decomposition, SlotSum can easily locate errors and further rectify hallucinated predictions with external knowledge. We construct a new dataset WikiFactSum to evaluate the performance of SlotSum. Experimental results demonstrate that SlotSum could generate summaries that are significantly more factual with credible external knowledge.

{{</citation>}}


### (32/48 | 32/321) How do Large Language Models Handle Multilingualism? (Yiran Zhao et al., 2024)

{{<citation>}}

Yiran Zhao, Wenxuan Zhang, Guizhen Chen, Kenji Kawaguchi, Lidong Bing. (2024)  
**How do Large Language Models Handle Multilingualism?**
<br/>
<button class="copy-to-clipboard" title="How do Large Language Models Handle Multilingualism?" index=32>
  <span class="copy-to-clipboard-item">Copy Title<span>
</button>
<div class="toast toast-copied toast-index-32 align-items-center text-bg-secondary border-0 position-absolute top-0 end-0" role="alert" aria-live="assertive" aria-atomic="true">
  <div class="d-flex">
    <div class="toast-body">
      Copied!
    </div>
  </div>
</div>

---
Primary Category: cs.CL  
Categories: cs-AI, cs-CL, cs.CL  
Keyword Score: 30  
Keywords: Large Language Model, Large Language Model, Self-Attention  
<a type="button" class="btn btn-outline-primary" href="http://arxiv.org/abs/2402.18815v1" target="_blank" >Paper Link</a>
<button type="button" class="btn btn-outline-primary download-pdf" url="https://arxiv.org/pdf/2402.18815v1.pdf" filename="2402.18815v1.pdf">Download PDF</button>

---


**ABSTRACT**  
<b>Large</b> <b>language</b> <b>models</b> <b>(LLMs)</b> demonstrate remarkable performance across a spectrum of languages. In this work, we delve into the question: How do <b>LLMs</b> handle multilingualism? We introduce a framework that depicts <b>LLMs'</b> processing of multilingual inputs: In the first several layers, <b>LLMs</b> understand the question, converting multilingual inputs into English to facilitate the task-solving phase. In the intermediate layers, <b>LLMs</b> engage in problem-solving by thinking in English and incorporating multilingual knowledge to obtain factual content, leveraging the <b>self-attention</b> and feed-forward structures, respectively. In the last several layers, <b>LLMs</b> generate responses that align with the original language of the query. In addition, we investigate the existence of language-specific neurons when processing a certain language. To detect neurons activated by the input language, even without labels, we innovatively design a Parallel Language specific Neuron Detection ($\texttt{PLND}$) method that effectively measures the significance of neurons when handling multilingual inputs. By comprehensive ablation analysis through deactivating neurons of different layers and structures, we verify the framework that we propose. Additionally, we demonstrate that we can utilize such a framework to effectively enhance the multilingual ability with much less training effort.

{{</citation>}}


### (33/48 | 33/321) $\texttt{COSMIC}$: Mutual Information for Task-Agnostic Summarization Evaluation (Maxime Darrin et al., 2024)

{{<citation>}}

Maxime Darrin, Philippe Formont, Jackie Chi Kit Cheung, Pablo Piantanida. (2024)  
**$\texttt{COSMIC}$: Mutual Information for Task-Agnostic Summarization Evaluation**
<br/>
<button class="copy-to-clipboard" title="$\texttt{COSMIC}$: Mutual Information for Task-Agnostic Summarization Evaluation" index=33>
  <span class="copy-to-clipboard-item">Copy Title<span>
</button>
<div class="toast toast-copied toast-index-33 align-items-center text-bg-secondary border-0 position-absolute top-0 end-0" role="alert" aria-live="assertive" aria-atomic="true">
  <div class="d-flex">
    <div class="toast-body">
      Copied!
    </div>
  </div>
</div>

---
Primary Category: cs.CL  
Categories: cs-AI, cs-CL, cs.CL  
Keyword Score: 20  
Keywords: Mutual Information, Summarization  
<a type="button" class="btn btn-outline-primary" href="http://arxiv.org/abs/2402.19457v2" target="_blank" >Paper Link</a>
<button type="button" class="btn btn-outline-primary download-pdf" url="https://arxiv.org/pdf/2402.19457v2.pdf" filename="2402.19457v2.pdf">Download PDF</button>

---


**ABSTRACT**  
Assessing the quality of summarizers poses significant challenges. In response, we propose a novel task-oriented evaluation approach that assesses summarizers based on their capacity to produce summaries that are useful for downstream tasks, while preserving task outcomes. We theoretically establish a direct relationship between the resulting error probability of these tasks and the <b>mutual</b> <b>information</b> between source texts and generated summaries. We introduce $\texttt{COSMIC}$ as a practical implementation of this metric, demonstrating its strong correlation with human judgment-based metrics and its effectiveness in predicting downstream task performance. Comparative analyses against established metrics like $\texttt{BERTScore}$ and $\texttt{ROUGE}$ highlight the competitive performance of $\texttt{COSMIC}$.

{{</citation>}}


### (34/48 | 34/321) PlanGPT: Enhancing Urban Planning with Tailored Language Model and Efficient Retrieval (He Zhu et al., 2024)

{{<citation>}}

He Zhu, Wenjia Zhang, Nuoxian Huang, Boyang Li, Luyao Niu, Zipei Fan, Tianle Lun, Yicheng Tao, Junyou Su, Zhaoya Gong, Chenyu Fang, Xing Liu. (2024)  
**PlanGPT: Enhancing Urban Planning with Tailored Language Model and Efficient Retrieval**
<br/>
<button class="copy-to-clipboard" title="PlanGPT: Enhancing Urban Planning with Tailored Language Model and Efficient Retrieval" index=34>
  <span class="copy-to-clipboard-item">Copy Title<span>
</button>
<div class="toast toast-copied toast-index-34 align-items-center text-bg-secondary border-0 position-absolute top-0 end-0" role="alert" aria-live="assertive" aria-atomic="true">
  <div class="d-flex">
    <div class="toast-body">
      Copied!
    </div>
  </div>
</div>

---
Primary Category: cs.CL  
Categories: cs-CL, cs.CL  
Keyword Score: 20  
Keywords: Fine-tuning, Large Language Model  
<a type="button" class="btn btn-outline-primary" href="http://arxiv.org/abs/2402.19273v1" target="_blank" >Paper Link</a>
<button type="button" class="btn btn-outline-primary download-pdf" url="https://arxiv.org/pdf/2402.19273v1.pdf" filename="2402.19273v1.pdf">Download PDF</button>

---


**ABSTRACT**  
In the field of urban planning, general-purpose <b>large</b> <b>language</b> <b>models</b> often struggle to meet the specific needs of planners. Tasks like generating urban planning texts, retrieving related information, and evaluating planning documents pose unique challenges. To enhance the efficiency of urban professionals and overcome these obstacles, we introduce PlanGPT, the first specialized <b>Large</b> <b>Language</b> <b>Model</b> tailored for urban and spatial planning. Developed through collaborative efforts with institutions like the Chinese Academy of Urban Planning, PlanGPT leverages a customized local database retrieval framework, domain-specific <b>fine-tuning</b> of base models, and advanced tooling capabilities. Empirical tests demonstrate that PlanGPT has achieved advanced performance, delivering responses of superior quality precisely tailored to the intricacies of urban planning.

{{</citation>}}


### (35/48 | 35/321) Robust Guidance for Unsupervised Data Selection: Capturing Perplexing Named Entities for Domain-Specific Machine Translation (Seunghyun Ji et al., 2024)

{{<citation>}}

Seunghyun Ji, Hagai Raja Sinulingga, Darongsae Kwon. (2024)  
**Robust Guidance for Unsupervised Data Selection: Capturing Perplexing Named Entities for Domain-Specific Machine Translation**
<br/>
<button class="copy-to-clipboard" title="Robust Guidance for Unsupervised Data Selection: Capturing Perplexing Named Entities for Domain-Specific Machine Translation" index=35>
  <span class="copy-to-clipboard-item">Copy Title<span>
</button>
<div class="toast toast-copied toast-index-35 align-items-center text-bg-secondary border-0 position-absolute top-0 end-0" role="alert" aria-live="assertive" aria-atomic="true">
  <div class="d-flex">
    <div class="toast-body">
      Copied!
    </div>
  </div>
</div>

---
Primary Category: cs.CL  
Categories: cs-AI, cs-CL, cs.CL  
Keyword Score: 20  
Keywords: Unsupervised Learning, Neural Machine Translation  
<a type="button" class="btn btn-outline-primary" href="http://arxiv.org/abs/2402.19267v1" target="_blank" >Paper Link</a>
<button type="button" class="btn btn-outline-primary download-pdf" url="https://arxiv.org/pdf/2402.19267v1.pdf" filename="2402.19267v1.pdf">Download PDF</button>

---


**ABSTRACT**  
Employing extensive datasets enables the training of multilingual <b>machine</b> <b>translation</b> models; however, these models often fail to accurately translate sentences within specialized domains. Although obtaining and translating domain-specific data incurs high costs, it is inevitable for high-quality translations. Hence, finding the most 'effective' data with an <b>unsupervised</b> setting becomes a practical strategy for reducing labeling costs. Recent research indicates that this effective data could be found by selecting 'properly difficult data' based on its volume. This means the data should not be excessively challenging or overly simplistic, especially if the amount of data is limited. However, we found that establishing a criterion for <b>unsupervised</b> data selection remains challenging, as the 'proper difficulty' might vary based on the data domain being trained on. We introduce a novel <b>unsupervised</b> data selection method, 'Capturing Perplexing Named Entities', which adopts the maximum inference entropy in translated named entities as a selection measure. The motivation was that named entities in domain-specific data are considered the most complex portion of the data and should be predicted with high confidence. When verified with the 'Korean-English Parallel Corpus of Specialized Domains,' our method served as a robust guidance for <b>unsupervised</b> data selection, in contrast to existing methods.

{{</citation>}}


### (36/48 | 36/321) Evaluating Webcam-based Gaze Data as an Alternative for Human Rationale Annotations (Stephanie Brandl et al., 2024)

{{<citation>}}

Stephanie Brandl, Oliver Eberle, Tiago Ribeiro, Anders Søgaard, Nora Hollenstein. (2024)  
**Evaluating Webcam-based Gaze Data as an Alternative for Human Rationale Annotations**
<br/>
<button class="copy-to-clipboard" title="Evaluating Webcam-based Gaze Data as an Alternative for Human Rationale Annotations" index=36>
  <span class="copy-to-clipboard-item">Copy Title<span>
</button>
<div class="toast toast-copied toast-index-36 align-items-center text-bg-secondary border-0 position-absolute top-0 end-0" role="alert" aria-live="assertive" aria-atomic="true">
  <div class="d-flex">
    <div class="toast-body">
      Copied!
    </div>
  </div>
</div>

---
Primary Category: cs.CL  
Categories: cs-CL, cs.CL  
Keyword Score: 20  
Keywords: Transformer, Question Answering  
<a type="button" class="btn btn-outline-primary" href="http://arxiv.org/abs/2402.19133v1" target="_blank" >Paper Link</a>
<button type="button" class="btn btn-outline-primary download-pdf" url="https://arxiv.org/pdf/2402.19133v1.pdf" filename="2402.19133v1.pdf">Download PDF</button>

---


**ABSTRACT**  
Rationales in the form of manually annotated input spans usually serve as ground truth when evaluating explainability methods in NLP. They are, however, time-consuming and often biased by the annotation process. In this paper, we debate whether human gaze, in the form of webcam-based eye-tracking recordings, poses a valid alternative when evaluating importance scores. We evaluate the additional information provided by gaze data, such as total reading times, gaze entropy, and decoding accuracy with respect to human rationale annotations. We compare WebQAmGaze, a multilingual dataset for information-seeking <b>QA,</b> with attention and explainability-based importance scores for 4 different multilingual <b>Transformer-based</b> language models (mBERT, distil-mBERT, XLMR, and XLMR-L) and 3 languages (English, Spanish, and German). Our pipeline can easily be applied to other tasks and languages. Our findings suggest that gaze data offers valuable linguistic insights that could be leveraged to infer task difficulty and further show a comparable ranking of explainability methods to that of human rationales.

{{</citation>}}


### (37/48 | 37/321) Whispers that Shake Foundations: Analyzing and Mitigating False Premise Hallucinations in Large Language Models (Hongbang Yuan et al., 2024)

{{<citation>}}

Hongbang Yuan, Pengfei Cao, Zhuoran Jin, Yubo Chen, Daojian Zeng, Kang Liu, Jun Zhao. (2024)  
**Whispers that Shake Foundations: Analyzing and Mitigating False Premise Hallucinations in Large Language Models**
<br/>
<button class="copy-to-clipboard" title="Whispers that Shake Foundations: Analyzing and Mitigating False Premise Hallucinations in Large Language Models" index=37>
  <span class="copy-to-clipboard-item">Copy Title<span>
</button>
<div class="toast toast-copied toast-index-37 align-items-center text-bg-secondary border-0 position-absolute top-0 end-0" role="alert" aria-live="assertive" aria-atomic="true">
  <div class="d-flex">
    <div class="toast-body">
      Copied!
    </div>
  </div>
</div>

---
Primary Category: cs.CL  
Categories: cs-AI, cs-CL, cs.CL  
Keyword Score: 20  
Keywords: Large Language Model, Large Language Model  
<a type="button" class="btn btn-outline-primary" href="http://arxiv.org/abs/2402.19103v1" target="_blank" >Paper Link</a>
<button type="button" class="btn btn-outline-primary download-pdf" url="https://arxiv.org/pdf/2402.19103v1.pdf" filename="2402.19103v1.pdf">Download PDF</button>

---


**ABSTRACT**  
<b>Large</b> <b>Language</b> <b>Models</b> <b>(LLMs)</b> have shown impressive capabilities but still suffer from the issue of hallucinations. A significant type of this issue is the false premise hallucination, which we define as the phenomenon when <b>LLMs</b> generate hallucinated text when confronted with false premise questions. In this paper, we perform a comprehensive analysis of the false premise hallucination and elucidate its internal working mechanism: a small subset of attention heads (which we designate as false premise heads) disturb the knowledge extraction process, leading to the occurrence of false premise hallucination. Based on our analysis, we propose \textbf{FAITH} (\textbf{F}alse premise \textbf{A}ttention head constra\textbf{I}ining for mi\textbf{T}igating \textbf{H}allucinations), a novel and effective method to mitigate false premise hallucinations. It constrains the false premise attention heads during the model inference process. Impressively, extensive experiments demonstrate that constraining only approximately $1\%$ of the attention heads in the model yields a notable increase of nearly $20\%$ of model performance.

{{</citation>}}


### (38/48 | 38/321) Controllable Preference Optimization: Toward Controllable Multi-Objective Alignment (Yiju Guo et al., 2024)

{{<citation>}}

Yiju Guo, Ganqu Cui, Lifan Yuan, Ning Ding, Jiexin Wang, Huimin Chen, Bowen Sun, Ruobing Xie, Jie Zhou, Yankai Lin, Zhiyuan Liu, Maosong Sun. (2024)  
**Controllable Preference Optimization: Toward Controllable Multi-Objective Alignment**
<br/>
<button class="copy-to-clipboard" title="Controllable Preference Optimization: Toward Controllable Multi-Objective Alignment" index=38>
  <span class="copy-to-clipboard-item">Copy Title<span>
</button>
<div class="toast toast-copied toast-index-38 align-items-center text-bg-secondary border-0 position-absolute top-0 end-0" role="alert" aria-live="assertive" aria-atomic="true">
  <div class="d-flex">
    <div class="toast-body">
      Copied!
    </div>
  </div>
</div>

---
Primary Category: cs.CL  
Categories: cs-AI, cs-CL, cs-SY, cs.CL, eess-SY  
Keyword Score: 20  
Keywords: Grounding, Large Language Model  
<a type="button" class="btn btn-outline-primary" href="http://arxiv.org/abs/2402.19085v1" target="_blank" >Paper Link</a>
<button type="button" class="btn btn-outline-primary download-pdf" url="https://arxiv.org/pdf/2402.19085v1.pdf" filename="2402.19085v1.pdf">Download PDF</button>

---


**ABSTRACT**  
Alignment in artificial intelligence pursues the consistency between model responses and human preferences as well as values. In practice, the multifaceted nature of human preferences inadvertently introduces what is known as the "alignment tax" -a compromise where enhancements in alignment within one objective (e.g.,harmlessness) can diminish performance in others (e.g.,helpfulness). However, existing alignment techniques are mostly unidirectional, leading to suboptimal trade-offs and poor flexibility over various objectives. To navigate this challenge, we argue the prominence of <b>grounding</b> <b>LLMs</b> with evident preferences. We introduce controllable preference optimization (CPO), which explicitly specifies preference scores for different objectives, thereby guiding the model to generate responses that meet the requirements. Our experimental analysis reveals that the aligned models can provide responses that match various preferences among the "3H" (helpfulness, honesty, harmlessness) desiderata. Furthermore, by introducing diverse data and alignment goals, we surpass baseline methods in aligning with single objectives, hence mitigating the impact of the alignment tax and achieving Pareto improvements in multi-objective alignment.

{{</citation>}}


### (39/48 | 39/321) PopALM: Popularity-Aligned Language Models for Social Media Trendy Response Prediction (Erxin Yu et al., 2024)

{{<citation>}}

Erxin Yu, Jing Li, Chunpu Xu. (2024)  
**PopALM: Popularity-Aligned Language Models for Social Media Trendy Response Prediction**
<br/>
<button class="copy-to-clipboard" title="PopALM: Popularity-Aligned Language Models for Social Media Trendy Response Prediction" index=39>
  <span class="copy-to-clipboard-item">Copy Title<span>
</button>
<div class="toast toast-copied toast-index-39 align-items-center text-bg-secondary border-0 position-absolute top-0 end-0" role="alert" aria-live="assertive" aria-atomic="true">
  <div class="d-flex">
    <div class="toast-body">
      Copied!
    </div>
  </div>
</div>

---
Primary Category: cs.CL  
Categories: cs-CL, cs.CL  
Keyword Score: 20  
Keywords: Curriculum Learning, Reinforcement Learning  
<a type="button" class="btn btn-outline-primary" href="http://arxiv.org/abs/2402.18950v1" target="_blank" >Paper Link</a>
<button type="button" class="btn btn-outline-primary download-pdf" url="https://arxiv.org/pdf/2402.18950v1.pdf" filename="2402.18950v1.pdf">Download PDF</button>

---


**ABSTRACT**  
Social media platforms are daily exhibiting millions of events. To preliminarily predict the mainstream public reaction to these events, we study trendy response prediction to automatically generate top-liked user replies to social media events. While previous works focus on generating responses without factoring in popularity, we propose Popularity-Aligned Language Models (PopALM) to distinguish responses liked by a larger audience through <b>reinforcement</b> <b>learning.</b> Recognizing the noisy labels from user "likes", we tailor-make <b>curriculum</b> <b>learning</b> in proximal policy optimization (PPO) to help models capture the essential samples for easy-to-hard training. In experiments, we build a large-scale Weibo dataset for trendy response prediction, and its results show that PopALM can help boost the performance of advanced language models.

{{</citation>}}


### (40/48 | 40/321) SemEval 2024 -- Task 10: Emotion Discovery and Reasoning its Flip in Conversation (EDiReF) (Shivani Kumar et al., 2024)

{{<citation>}}

Shivani Kumar, Md Shad Akhtar, Erik Cambria, Tanmoy Chakraborty. (2024)  
**SemEval 2024 -- Task 10: Emotion Discovery and Reasoning its Flip in Conversation (EDiReF)**
<br/>
<button class="copy-to-clipboard" title="SemEval 2024 -- Task 10: Emotion Discovery and Reasoning its Flip in Conversation (EDiReF)" index=40>
  <span class="copy-to-clipboard-item">Copy Title<span>
</button>
<div class="toast toast-copied toast-index-40 align-items-center text-bg-secondary border-0 position-absolute top-0 end-0" role="alert" aria-live="assertive" aria-atomic="true">
  <div class="d-flex">
    <div class="toast-body">
      Copied!
    </div>
  </div>
</div>

---
Primary Category: cs.CL  
Categories: cs-AI, cs-CL, cs.CL  
Keyword Score: 20  
Keywords: Emotion Recognition, Reasoning  
<a type="button" class="btn btn-outline-primary" href="http://arxiv.org/abs/2402.18944v1" target="_blank" >Paper Link</a>
<button type="button" class="btn btn-outline-primary download-pdf" url="https://arxiv.org/pdf/2402.18944v1.pdf" filename="2402.18944v1.pdf">Download PDF</button>

---


**ABSTRACT**  
We present SemEval-2024 Task 10, a shared task centred on identifying <b>emotions</b> <b>and</b> finding the rationale behind their flips within monolingual English and Hindi-English code-mixed dialogues. This task comprises three distinct subtasks - <b>emotion</b> <b>recognition</b> in conversation for code-mixed dialogues, <b>emotion</b> <b>flip</b> <b>reasoning</b> for code-mixed dialogues, and <b>emotion</b> <b>flip</b> <b>reasoning</b> for English dialogues. Participating systems were tasked to automatically execute one or more of these subtasks. The datasets for these tasks comprise manually annotated conversations focusing on <b>emotions</b> <b>and</b> triggers for <b>emotion</b> <b>shifts</b> (The task data is available at https://github.com/LCS2-IIITD/EDiReF-SemEval2024.git). A total of 84 participants engaged in this task, with the most adept systems attaining F1-scores of 0.70, 0.79, and 0.76 for the respective subtasks. This paper summarises the results and findings from 24 teams alongside their system descriptions.

{{</citation>}}


### (41/48 | 41/321) When does word order matter and when doesn't it? (Xuanda Chen et al., 2024)

{{<citation>}}

Xuanda Chen, Timothy O'Donnell, Siva Reddy. (2024)  
**When does word order matter and when doesn't it?**
<br/>
<button class="copy-to-clipboard" title="When does word order matter and when doesn't it?" index=41>
  <span class="copy-to-clipboard-item">Copy Title<span>
</button>
<div class="toast toast-copied toast-index-41 align-items-center text-bg-secondary border-0 position-absolute top-0 end-0" role="alert" aria-live="assertive" aria-atomic="true">
  <div class="d-flex">
    <div class="toast-body">
      Copied!
    </div>
  </div>
</div>

---
Primary Category: cs.CL  
Categories: cs-CL, cs.CL  
Keyword Score: 20  
Keywords: Mutual Information, Natural Language Understanding  
<a type="button" class="btn btn-outline-primary" href="http://arxiv.org/abs/2402.18838v2" target="_blank" >Paper Link</a>
<button type="button" class="btn btn-outline-primary download-pdf" url="https://arxiv.org/pdf/2402.18838v2.pdf" filename="2402.18838v2.pdf">Download PDF</button>

---


**ABSTRACT**  
Language models (LMs) may appear insensitive to word order changes in <b>natural</b> <b>language</b> <b>understanding</b> (NLU) tasks. In this paper, we propose that linguistic redundancy can explain this phenomenon, whereby word order and other linguistic cues such as case markers provide overlapping and thus redundant information. Our hypothesis is that models exhibit insensitivity to word order when the order provides redundant information, and the degree of insensitivity varies across tasks. We quantify how informative word order is using <b>mutual</b> <b>information</b> (MI) between unscrambled and scrambled sentences. Our results show the effect that the less informative word order is, the more consistent the model's predictions are between unscrambled and scrambled sentences. We also find that the effect varies across tasks: for some tasks, like SST-2, LMs' prediction is almost always consistent with the original one even if the Pointwise-MI (PMI) changes, while for others, like RTE, the consistency is near random when the PMI gets lower, i.e., word order is really important.

{{</citation>}}


### (42/48 | 42/321) Utilizing Local Hierarchy with Adversarial Training for Hierarchical Text Classification (Zihan Wang et al., 2024)

{{<citation>}}

Zihan Wang, Peiyi Wang, Houfeng Wang. (2024)  
**Utilizing Local Hierarchy with Adversarial Training for Hierarchical Text Classification**
<br/>
<button class="copy-to-clipboard" title="Utilizing Local Hierarchy with Adversarial Training for Hierarchical Text Classification" index=42>
  <span class="copy-to-clipboard-item">Copy Title<span>
</button>
<div class="toast toast-copied toast-index-42 align-items-center text-bg-secondary border-0 position-absolute top-0 end-0" role="alert" aria-live="assertive" aria-atomic="true">
  <div class="d-flex">
    <div class="toast-body">
      Copied!
    </div>
  </div>
</div>

---
Primary Category: cs.CL  
Categories: cs-CL, cs.CL  
Keyword Score: 20  
Keywords: Adversarial Learning, Text Classification  
<a type="button" class="btn btn-outline-primary" href="http://arxiv.org/abs/2402.18825v1" target="_blank" >Paper Link</a>
<button type="button" class="btn btn-outline-primary download-pdf" url="https://arxiv.org/pdf/2402.18825v1.pdf" filename="2402.18825v1.pdf">Download PDF</button>

---


**ABSTRACT**  
Hierarchical <b>text</b> <b>classification</b> (HTC) is a challenging subtask of multi-label classification due to its complex taxonomic structure. Nearly all recent HTC works focus on how the labels are structured but ignore the sub-structure of ground-truth labels according to each input <b>text</b> <b>which</b> contains fruitful label co-occurrence information. In this work, we introduce this local hierarchy with an <b>adversarial</b> <b>framework.</b> We propose a HiAdv framework that can fit in nearly all HTC models and optimize them with the local hierarchy as auxiliary information. We test on two typical HTC models and find that HiAdv is effective in all scenarios and is adept at dealing with complex taxonomic hierarchies. Further experiments demonstrate that the promotion of our framework indeed comes from the local hierarchy and the local hierarchy is beneficial for rare classes which have insufficient training data.

{{</citation>}}


### (43/48 | 43/321) Advancing Generative AI for Portuguese with Open Decoder Gervásio PT* (Rodrigo Santos et al., 2024)

{{<citation>}}

Rodrigo Santos, João Silva, Luís Gomes, João Rodrigues, António Branco. (2024)  
**Advancing Generative AI for Portuguese with Open Decoder Gervásio PT***
<br/>
<button class="copy-to-clipboard" title="Advancing Generative AI for Portuguese with Open Decoder Gervásio PT*" index=43>
  <span class="copy-to-clipboard-item">Copy Title<span>
</button>
<div class="toast toast-copied toast-index-43 align-items-center text-bg-secondary border-0 position-absolute top-0 end-0" role="alert" aria-live="assertive" aria-atomic="true">
  <div class="d-flex">
    <div class="toast-body">
      Copied!
    </div>
  </div>
</div>

---
Primary Category: cs.CL  
Categories: cs-CL, cs.CL  
Keyword Score: 20  
Keywords: Generative AI, Transformer  
<a type="button" class="btn btn-outline-primary" href="http://arxiv.org/abs/2402.18766v2" target="_blank" >Paper Link</a>
<button type="button" class="btn btn-outline-primary download-pdf" url="https://arxiv.org/pdf/2402.18766v2.pdf" filename="2402.18766v2.pdf">Download PDF</button>

---


**ABSTRACT**  
To advance the neural decoding of Portuguese, in this paper we present a fully open <b>Transformer-based,</b> instruction-tuned decoder model that sets a new state of the art in this respect. To develop this decoder, which we named Gerv\'asio PT*, a strong LLaMA~2 7B model was used as a starting point, and its further improvement through additional training was done over language resources that include new instruction data sets of Portuguese prepared for this purpose, which are also contributed in this paper. All versions of Gerv\'asio are open source and distributed for free under an open license, including for either research or commercial usage, and can be run on consumer-grade hardware, thus seeking to contribute to the advancement of research and innovation in language technology for Portuguese.

{{</citation>}}


### (44/48 | 44/321) 'Flex Tape Can't Fix That': Bias and Misinformation in Edited Language Models (Karina Halevy et al., 2024)

{{<citation>}}

Karina Halevy, Anna Sotnikova, Badr AlKhamissi, Syrielle Montariol, Antoine Bosselut. (2024)  
**'Flex Tape Can't Fix That': Bias and Misinformation in Edited Language Models**
<br/>
<button class="copy-to-clipboard" title="'Flex Tape Can't Fix That': Bias and Misinformation in Edited Language Models" index=44>
  <span class="copy-to-clipboard-item">Copy Title<span>
</button>
<div class="toast toast-copied toast-index-44 align-items-center text-bg-secondary border-0 position-absolute top-0 end-0" role="alert" aria-live="assertive" aria-atomic="true">
  <div class="d-flex">
    <div class="toast-body">
      Copied!
    </div>
  </div>
</div>

---
Primary Category: cs.CL  
Categories: cs-CL, cs.CL  
Keyword Score: 13  
Keywords: Benchmarking, Text Generation  
<a type="button" class="btn btn-outline-primary" href="http://arxiv.org/abs/2403.00180v1" target="_blank" >Paper Link</a>
<button type="button" class="btn btn-outline-primary download-pdf" url="https://arxiv.org/pdf/2403.00180v1.pdf" filename="2403.00180v1.pdf">Download PDF</button>

---


**ABSTRACT**  
Model editing has emerged as a cost-effective strategy to update knowledge stored in language models. However, model editing can have unintended consequences after edits are applied: information unrelated to the edits can also be changed, and other general behaviors of the model can be wrongly altered. In this work, we investigate how model editing methods unexpectedly amplify model biases post-edit. We introduce a novel <b>benchmark</b> dataset, Seesaw-CF, for measuring bias-related harms of model editing and conduct the first in-depth investigation of how different weight-editing methods impact model bias. Specifically, we focus on biases with respect to demographic attributes such as race, geographic origin, and gender, as well as qualitative flaws in long-form <b>texts</b> <b>generated</b> by edited language models. We find that edited models exhibit, to various degrees, more biased behavior as they become less confident in attributes for Asian, African, and South American subjects. Furthermore, edited models amplify sexism and xenophobia in <b>text</b> <b>generations</b> while remaining seemingly coherent and logical. Finally, editing facts about place of birth, country of citizenship, or gender have particularly negative effects on the model's knowledge about unrelated features like field of work.

{{</citation>}}


### (45/48 | 45/321) Ensemble-Based Unsupervised Discontinuous Constituency Parsing by Tree Averaging (Behzad Shayegh et al., 2024)

{{<citation>}}

Behzad Shayegh, Yuqiao Wen, Lili Mou. (2024)  
**Ensemble-Based Unsupervised Discontinuous Constituency Parsing by Tree Averaging**
<br/>
<button class="copy-to-clipboard" title="Ensemble-Based Unsupervised Discontinuous Constituency Parsing by Tree Averaging" index=45>
  <span class="copy-to-clipboard-item">Copy Title<span>
</button>
<div class="toast toast-copied toast-index-45 align-items-center text-bg-secondary border-0 position-absolute top-0 end-0" role="alert" aria-live="assertive" aria-atomic="true">
  <div class="d-flex">
    <div class="toast-body">
      Copied!
    </div>
  </div>
</div>

---
Primary Category: cs.CL  
Categories: cs-AI, cs-CL, cs-LG, cs.CL  
Keyword Score: 10  
Keywords: Unsupervised Learning  
<a type="button" class="btn btn-outline-primary" href="http://arxiv.org/abs/2403.00143v1" target="_blank" >Paper Link</a>
<button type="button" class="btn btn-outline-primary download-pdf" url="https://arxiv.org/pdf/2403.00143v1.pdf" filename="2403.00143v1.pdf">Download PDF</button>

---


**ABSTRACT**  
We address <b>unsupervised</b> discontinuous constituency parsing, where we observe a high variance in the performance of the only previous model. We propose to build an ensemble of different runs of the existing discontinuous parser by averaging the predicted trees, to stabilize and boost performance. To begin with, we provide comprehensive computational complexity analysis (in terms of P and NP-complete) for tree averaging under different setups of binarity and continuity. We then develop an efficient exact algorithm to tackle the task, which runs in a reasonable time for all samples in our experiments. Results on three datasets show our method outperforms all baselines in all metrics; we also provide in-depth analyses of our approach.

{{</citation>}}


### (46/48 | 46/321) EROS: Entity-Driven Controlled Policy Document Summarization (Joykirat Singh et al., 2024)

{{<citation>}}

Joykirat Singh, Sehban Fazili, Rohan Jain, Md Shad Akhtar. (2024)  
**EROS: Entity-Driven Controlled Policy Document Summarization**
<br/>
<button class="copy-to-clipboard" title="EROS: Entity-Driven Controlled Policy Document Summarization" index=46>
  <span class="copy-to-clipboard-item">Copy Title<span>
</button>
<div class="toast toast-copied toast-index-46 align-items-center text-bg-secondary border-0 position-absolute top-0 end-0" role="alert" aria-live="assertive" aria-atomic="true">
  <div class="d-flex">
    <div class="toast-body">
      Copied!
    </div>
  </div>
</div>

---
Primary Category: cs.CL  
Categories: cs-AI, cs-CL, cs.CL  
Keyword Score: 10  
Keywords: Summarization  
<a type="button" class="btn btn-outline-primary" href="http://arxiv.org/abs/2403.00141v1" target="_blank" >Paper Link</a>
<button type="button" class="btn btn-outline-primary download-pdf" url="https://arxiv.org/pdf/2403.00141v1.pdf" filename="2403.00141v1.pdf">Download PDF</button>

---


**ABSTRACT**  
Privacy policy documents have a crucial role in educating individuals about the collection, usage, and protection of users' personal data by organizations. However, they are notorious for their lengthy, complex, and convoluted language especially involving privacy-related entities. Hence, they pose a significant challenge to users who attempt to comprehend organization's data usage policy. In this paper, we propose to enhance the interpretability and readability of policy documents by using controlled abstractive <b>summarization</b> -- we enforce the generated summaries to include critical privacy-related entities (e.g., data and medium) and organization's rationale (e.g.,target and reason) in collecting those entities. To achieve this, we develop PD-Sum, a policy-document <b>summarization</b> dataset with marked privacy-related entity labels. Our proposed model, EROS, identifies critical entities through a span-based entity extraction model and employs them to control the information content of the summaries using proximal policy optimization (PPO). Comparison shows encouraging improvement over various baselines. Furthermore, we furnish qualitative and human evaluations to establish the efficacy of EROS.

{{</citation>}}


### (47/48 | 47/321) Improving Legal Judgement Prediction in Romanian with Long Text Encoders (Mihai Masala et al., 2024)

{{<citation>}}

Mihai Masala, Traian Rebedea, Horia Velicu. (2024)  
**Improving Legal Judgement Prediction in Romanian with Long Text Encoders**
<br/>
<button class="copy-to-clipboard" title="Improving Legal Judgement Prediction in Romanian with Long Text Encoders" index=47>
  <span class="copy-to-clipboard-item">Copy Title<span>
</button>
<div class="toast toast-copied toast-index-47 align-items-center text-bg-secondary border-0 position-absolute top-0 end-0" role="alert" aria-live="assertive" aria-atomic="true">
  <div class="d-flex">
    <div class="toast-body">
      Copied!
    </div>
  </div>
</div>

---
Primary Category: cs.CL  
Categories: cs-AI, cs-CL, cs.CL  
Keyword Score: 10  
Keywords: Transformer  
<a type="button" class="btn btn-outline-primary" href="http://arxiv.org/abs/2402.19170v2" target="_blank" >Paper Link</a>
<button type="button" class="btn btn-outline-primary download-pdf" url="https://arxiv.org/pdf/2402.19170v2.pdf" filename="2402.19170v2.pdf">Download PDF</button>

---


**ABSTRACT**  
In recent years,the entire field of Natural Language Processing (NLP) has enjoyed amazing novel results achieving almost human-like performance on a variety of tasks. Legal NLP domain has also been part of this process, as it has seen an impressive growth. However, general-purpose models are not readily applicable for legal domain. Due to the nature of the domain (e.g. specialized vocabulary, long documents) specific models and methods are often needed for Legal NLP. In this work we investigate both specialized and general models for predicting the final ruling of a legal case, task known as Legal Judgment Prediction (LJP). We particularly focus on methods to extend to sequence length of <b>Transformer-based</b> models to better understand the long documents present in legal corpora. Extensive experiments on 4 LJP datasets in Romanian, originating from 2 sources with significantly different sizes and document lengths, show that specialized models and handling long texts are critical for a good performance.

{{</citation>}}


### (48/48 | 48/321) Updating Language Models with Unstructured Facts: Towards Practical Knowledge Editing (Xiaobao Wu et al., 2024)

{{<citation>}}

Xiaobao Wu, Liangming Pan, William Yang Wang, Anh Tuan Luu. (2024)  
**Updating Language Models with Unstructured Facts: Towards Practical Knowledge Editing**
<br/>
<button class="copy-to-clipboard" title="Updating Language Models with Unstructured Facts: Towards Practical Knowledge Editing" index=48>
  <span class="copy-to-clipboard-item">Copy Title<span>
</button>
<div class="toast toast-copied toast-index-48 align-items-center text-bg-secondary border-0 position-absolute top-0 end-0" role="alert" aria-live="assertive" aria-atomic="true">
  <div class="d-flex">
    <div class="toast-body">
      Copied!
    </div>
  </div>
</div>

---
Primary Category: cs.CL  
Categories: cs-AI, cs-CL, cs.CL  
Keyword Score: 3  
Keywords: Benchmarking  
<a type="button" class="btn btn-outline-primary" href="http://arxiv.org/abs/2402.18909v1" target="_blank" >Paper Link</a>
<button type="button" class="btn btn-outline-primary download-pdf" url="https://arxiv.org/pdf/2402.18909v1.pdf" filename="2402.18909v1.pdf">Download PDF</button>

---


**ABSTRACT**  
Knowledge editing aims to inject knowledge updates into language models to keep them correct and up-to-date. However, its current evaluation strategies are notably impractical: they solely update with well-curated structured facts (triplets with subjects, relations, and objects), whereas real-world knowledge updates commonly emerge in unstructured texts like news articles. In this paper, we propose a new <b>benchmark,</b> Unstructured Knowledge Editing (UKE). It evaluates editing performance directly using unstructured texts as knowledge updates, termed unstructured facts. Hence UKE avoids the laborious construction of structured facts and enables efficient and responsive knowledge editing, becoming a more practical <b>benchmark.</b> We conduct extensive experiments on newly built datasets and demonstrate that UKE poses a significant challenge to state-of-the-art knowledge editing methods, resulting in their critical performance declines. We further show that this challenge persists even if we extract triplets as structured facts. Our analysis discloses key insights to motivate future research in UKE for more practical knowledge editing.

{{</citation>}}


## cs.CV (69)



### (1/69 | 49/321) Typographic Attacks in Large Multimodal Models Can be Alleviated by More Informative Prompts (Hao Cheng et al., 2024)

{{<citation>}}

Hao Cheng, Erjia Xiao, Renjing Xu. (2024)  
**Typographic Attacks in Large Multimodal Models Can be Alleviated by More Informative Prompts**
<br/>
<button class="copy-to-clipboard" title="Typographic Attacks in Large Multimodal Models Can be Alleviated by More Informative Prompts" index=49>
  <span class="copy-to-clipboard-item">Copy Title<span>
</button>
<div class="toast toast-copied toast-index-49 align-items-center text-bg-secondary border-0 position-absolute top-0 end-0" role="alert" aria-live="assertive" aria-atomic="true">
  <div class="d-flex">
    <div class="toast-body">
      Copied!
    </div>
  </div>
</div>

---
Primary Category: cs.CV  
Categories: cs-CV, cs.CV  
Keyword Score: 86  
Keywords: Multi-modal, Multi-modal, Zero-shot, Common-sense Reasoning, Reasoning, Large Language Model, Large Language Model, Prompt, Vision-and-Language, Vision-and-Language  
<a type="button" class="btn btn-outline-primary" href="http://arxiv.org/abs/2402.19150v1" target="_blank" >Paper Link</a>
<button type="button" class="btn btn-outline-primary download-pdf" url="https://arxiv.org/pdf/2402.19150v1.pdf" filename="2402.19150v1.pdf">Download PDF</button>

---


**ABSTRACT**  
<b>Large</b> <b>Multimodal</b> <b>Models</b> (LMMs) rely on pre-trained Vision Language Models (VLMs) and <b>Large</b> <b>Language</b> <b>Models</b> <b>(LLMs)</b> to perform amazing emergent abilities on various <b>multimodal</b> tasks in the joint space of vision and language. However, the Typographic Attack, which shows disruption to VLMs, has also been certified as a security vulnerability to LMMs. In this work, we first comprehensively investigate the distractibility of LMMs by typography. In particular, we introduce the Typographic Dataset designed to evaluate distractibility across various <b>multi-modal</b> subtasks, such as object recognition, visual attributes detection, enumeration, arithmetic computation, and <b>commonsense</b> <b>reasoning.</b> To further study the effect of typographic patterns on performance, we also scrutinize the effect of tuning various typographic factors, encompassing font size, color, opacity, and spatial positioning of typos. We discover that LMMs can partially distinguish visual contents and typos when confronting typographic attacks, which suggests that embeddings from vision encoders contain enough information to distinguish visual contents and typos in images. Inspired by such phenomena, we demonstrate that CLIP's performance of <b>zero-shot</b> classification on typo-ridden images can be significantly improved by providing more informative texts to match images. Furthermore, we also prove that LMMs can utilize more informative <b>prompts</b> to leverage information in embeddings to differentiate between visual content and typos. Finally, we propose a <b>prompt</b> information enhancement method that can effectively mitigate the effects of typography.

{{</citation>}}


### (2/69 | 50/321) VideoMAC: Video Masked Autoencoders Meet ConvNets (Gensheng Pei et al., 2024)

{{<citation>}}

Gensheng Pei, Tao Chen, Xiruo Jiang, Huafeng Liu, Zeren Sun, Yazhou Yao. (2024)  
**VideoMAC: Video Masked Autoencoders Meet ConvNets**
<br/>
<button class="copy-to-clipboard" title="VideoMAC: Video Masked Autoencoders Meet ConvNets" index=50>
  <span class="copy-to-clipboard-item">Copy Title<span>
</button>
<div class="toast toast-copied toast-index-50 align-items-center text-bg-secondary border-0 position-absolute top-0 end-0" role="alert" aria-live="assertive" aria-atomic="true">
  <div class="d-flex">
    <div class="toast-body">
      Copied!
    </div>
  </div>
</div>

---
Primary Category: cs.CV  
Categories: cs-CV, cs.CV  
Keyword Score: 75  
Keywords: Vision Transformer, Autoencoder, Convolution, Representation Learning, Self-supervised Learning, Self-supervised Learning, Transformer, Vision Transformer  
<a type="button" class="btn btn-outline-primary" href="http://arxiv.org/abs/2402.19082v1" target="_blank" >Paper Link</a>
<button type="button" class="btn btn-outline-primary download-pdf" url="https://arxiv.org/pdf/2402.19082v1.pdf" filename="2402.19082v1.pdf">Download PDF</button>

---


**ABSTRACT**  
Recently, the advancement of <b>self-supervised</b> <b>learning</b> techniques, like masked <b>autoencoders</b> (MAE), has greatly influenced visual <b>representation</b> <b>learning</b> for images and videos. Nevertheless, it is worth noting that the predominant approaches in existing masked image / video modeling rely excessively on resource-intensive <b>vision</b> <b>transformers</b> (ViTs) as the feature encoder. In this paper, we propose a new approach termed as \textbf{VideoMAC}, which combines video masked <b>autoencoders</b> with resource-friendly ConvNets. Specifically, VideoMAC employs symmetric masking on randomly sampled pairs of video frames. To prevent the issue of mask pattern dissipation, we utilize ConvNets which are implemented with sparse <b>convolutional</b> operators as encoders. Simultaneously, we present a simple yet effective masked video modeling (MVM) approach, a dual encoder architecture comprising an online encoder and an exponential moving average target encoder, aimed to facilitate inter-frame reconstruction consistency in videos. Additionally, we demonstrate that VideoMAC, empowering classical (ResNet) / modern (ConvNeXt) <b>convolutional</b> encoders to harness the benefits of MVM, outperforms ViT-based approaches on downstream tasks, including video object segmentation (+\textbf{5.2\%} / \textbf{6.4\%} $\mathcal{J}\&\mathcal{F}$), body part propagation (+\textbf{6.3\%} / \textbf{3.1\%} mIoU), and human pose tracking (+\textbf{10.2\%} / \textbf{11.1\%} PCK@0.1).

{{</citation>}}


### (3/69 | 51/321) Retrieval-Augmented Generation for AI-Generated Content: A Survey (Penghao Zhao et al., 2024)

{{<citation>}}

Penghao Zhao, Hailin Zhang, Qinhan Yu, Zhengren Wang, Yunteng Geng, Fangcheng Fu, Ling Yang, Wentao Zhang, Bin Cui. (2024)  
**Retrieval-Augmented Generation for AI-Generated Content: A Survey**
<br/>
<button class="copy-to-clipboard" title="Retrieval-Augmented Generation for AI-Generated Content: A Survey" index=51>
  <span class="copy-to-clipboard-item">Copy Title<span>
</button>
<div class="toast toast-copied toast-index-51 align-items-center text-bg-secondary border-0 position-absolute top-0 end-0" role="alert" aria-live="assertive" aria-atomic="true">
  <div class="d-flex">
    <div class="toast-body">
      Copied!
    </div>
  </div>
</div>

---
Primary Category: cs.CV  
Categories: cs-CV, cs.CV  
Keyword Score: 73  
Keywords: Benchmarking, Foundation Model, Knowledge Distillation, Retrieval-Augmented Generation, Retrieval-Augmented Generation, Retrieval-Augmented Generation, Information Retrieval, Summarization  
<a type="button" class="btn btn-outline-primary" href="http://arxiv.org/abs/2402.19473v1" target="_blank" >Paper Link</a>
<button type="button" class="btn btn-outline-primary download-pdf" url="https://arxiv.org/pdf/2402.19473v1.pdf" filename="2402.19473v1.pdf">Download PDF</button>

---


**ABSTRACT**  
The development of Artificial Intelligence Generated Content (AIGC) has been facilitated by advancements in model algorithms, scalable <b>foundation</b> <b>model</b> architectures, and the availability of ample high-quality datasets. While AIGC has achieved remarkable performance, it still faces challenges, such as the difficulty of maintaining up-to-date and long-tail knowledge, the risk of data leakage, and the high costs associated with training and inference. <b>Retrieval-Augmented</b> <b>Generation</b> <b>(RAG)</b> has recently emerged as a paradigm to address such challenges. In particular, <b>RAG</b> introduces the <b>information</b> <b>retrieval</b> <b>process,</b> <b>which</b> enhances AIGC results by retrieving relevant objects from available data stores, leading to greater accuracy and robustness. In this paper, we comprehensively review existing efforts that integrate <b>RAG</b> technique into AIGC scenarios. We first classify <b>RAG</b> <b>foundations</b> <b>according</b> to how the retriever augments the generator. We <b>distill</b> the fundamental abstractions of the augmentation methodologies for various retrievers and generators. This unified perspective encompasses all <b>RAG</b> scenarios, illuminating advancements and pivotal technologies that help with potential future progress. We also <b>summarize</b> additional enhancements methods for <b>RAG,</b> facilitating effective engineering and implementation of <b>RAG</b> systems. Then from another view, we survey on practical applications of <b>RAG</b> across different modalities and tasks, offering valuable references for researchers and practitioners. Furthermore, we introduce the <b>benchmarks</b> for <b>RAG,</b> discuss the limitations of current <b>RAG</b> systems, and suggest potential directions for future research. Project: https://github.com/hymie122/RAG-Survey

{{</citation>}}


### (4/69 | 52/321) LLMs in Political Science: Heralding a New Era of Visual Analysis (Yu Wang et al., 2024)

{{<citation>}}

Yu Wang, Mengying Xing. (2024)  
**LLMs in Political Science: Heralding a New Era of Visual Analysis**
<br/>
<button class="copy-to-clipboard" title="LLMs in Political Science: Heralding a New Era of Visual Analysis" index=52>
  <span class="copy-to-clipboard-item">Copy Title<span>
</button>
<div class="toast toast-copied toast-index-52 align-items-center text-bg-secondary border-0 position-absolute top-0 end-0" role="alert" aria-live="assertive" aria-atomic="true">
  <div class="d-flex">
    <div class="toast-body">
      Copied!
    </div>
  </div>
</div>

---
Primary Category: cs.CV  
Categories: cs-AI, cs-CV, cs.CV  
Keyword Score: 60  
Keywords: Object Detection, Gemini, Sentiment Analysis, Large Language Model, Large Language Model, Prompt  
<a type="button" class="btn btn-outline-primary" href="http://arxiv.org/abs/2403.00154v1" target="_blank" >Paper Link</a>
<button type="button" class="btn btn-outline-primary download-pdf" url="https://arxiv.org/pdf/2403.00154v1.pdf" filename="2403.00154v1.pdf">Download PDF</button>

---


**ABSTRACT**  
Interest is increasing among political scientists in leveraging the extensive information available in images. However, the challenge of interpreting these images lies in the need for specialized knowledge in computer vision and access to specialized hardware. As a result, image analysis has been limited to a relatively small group within the political science community. This landscape could potentially change thanks to the rise of <b>large</b> <b>language</b> <b>models</b> <b>(LLMs).</b> This paper aims to raise awareness of the feasibility of using <b>Gemini</b> for image content analysis. A retrospective analysis was conducted on a corpus of 688 images. Content reports were elicited from <b>Gemini</b> for each image and then manually evaluated by the authors. We find that <b>Gemini</b> is highly accurate in performing <b>object</b> <b>detection,</b> which is arguably the most common and fundamental task in image analysis for political scientists. Equally important, we show that it is easy to implement as the entire command consists of a single <b>prompt</b> in natural language; it is fast to run and should meet the time budget of most researchers; and it is free to use and does not require any specialized hardware. In addition, we illustrate how political scientists can leverage <b>Gemini</b> for other image understanding tasks, including face identification, <b>sentiment</b> <b>analysis,</b> and caption generation. Our findings suggest that <b>Gemini</b> and other similar <b>LLMs</b> have the potential to drastically stimulate and accelerate image research in political science and social sciences more broadly.

{{</citation>}}


### (5/69 | 53/321) Generalizable Whole Slide Image Classification with Fine-Grained Visual-Semantic Interaction (Hao Li et al., 2024)

{{<citation>}}

Hao Li, Ying Chen, Yifei Chen, Wenxian Yang, Bowen Ding, Yuchen Han, Liansheng Wang, Rongshan Yu. (2024)  
**Generalizable Whole Slide Image Classification with Fine-Grained Visual-Semantic Interaction**
<br/>
<button class="copy-to-clipboard" title="Generalizable Whole Slide Image Classification with Fine-Grained Visual-Semantic Interaction" index=53>
  <span class="copy-to-clipboard-item">Copy Title<span>
</button>
<div class="toast toast-copied toast-index-53 align-items-center text-bg-secondary border-0 position-absolute top-0 end-0" role="alert" aria-live="assertive" aria-atomic="true">
  <div class="d-flex">
    <div class="toast-body">
      Copied!
    </div>
  </div>
</div>

---
Primary Category: cs.CV  
Categories: cs-CV, cs.CV  
Keyword Score: 55  
Keywords: Few-shot, Multiple Instance Learning, Representation Learning, Large Language Model, Prompt, Vision-and-Language  
<a type="button" class="btn btn-outline-primary" href="http://arxiv.org/abs/2402.19326v1" target="_blank" >Paper Link</a>
<button type="button" class="btn btn-outline-primary download-pdf" url="https://arxiv.org/pdf/2402.19326v1.pdf" filename="2402.19326v1.pdf">Download PDF</button>

---


**ABSTRACT**  
Whole Slide Image (WSI) classification is often formulated as a <b>Multiple</b> <b>Instance</b> <b>Learning</b> (MIL) problem. Recently, <b>Vision-Language</b> Models (VLMs) have demonstrated remarkable performance in WSI classification. However, existing methods leverage coarse-grained pathogenetic descriptions for visual <b>representation</b> <b>supervision,</b> which are insufficient to capture the complex visual appearance of pathogenetic images, hindering the generalizability of models on diverse downstream tasks. Additionally, processing high-resolution WSIs can be computationally expensive. In this paper, we propose a novel "Fine-grained Visual-Semantic Interaction" (FiVE) framework for WSI classification. It is designed to enhance the model's generalizability by leveraging the interplay between localized visual patterns and fine-grained pathological semantics. Specifically, with meticulously designed queries, we start by utilizing a <b>large</b> <b>language</b> <b>model</b> to extract fine-grained pathological descriptions from various non-standardized raw reports. The output descriptions are then reconstructed into fine-grained labels used for training. By introducing a Task-specific Fine-grained Semantics (TFS) module, we enable <b>prompts</b> to capture crucial visual information in WSIs, which enhances <b>representation</b> <b>learning</b> and augments generalization capabilities significantly. Furthermore, given that pathological visual patterns are redundantly distributed across tissue slices, we sample a subset of visual instances during training. Our method demonstrates robust generalizability and strong transferability, dominantly outperforming the counterparts on the TCGA Lung Cancer dataset with at least 9.19% higher accuracy in <b>few-shot</b> experiments.

{{</citation>}}


### (6/69 | 54/321) Assessing Visually-Continuous Corruption Robustness of Neural Networks Relative to Human Performance (Huakun Shen et al., 2024)

{{<citation>}}

Huakun Shen, Boyue Caroline Hu, Krzysztof Czarnecki, Lina Marsso, Marsha Chechik. (2024)  
**Assessing Visually-Continuous Corruption Robustness of Neural Networks Relative to Human Performance**
<br/>
<button class="copy-to-clipboard" title="Assessing Visually-Continuous Corruption Robustness of Neural Networks Relative to Human Performance" index=54>
  <span class="copy-to-clipboard-item">Copy Title<span>
</button>
<div class="toast toast-copied toast-index-54 align-items-center text-bg-secondary border-0 position-absolute top-0 end-0" role="alert" aria-live="assertive" aria-atomic="true">
  <div class="d-flex">
    <div class="toast-body">
      Copied!
    </div>
  </div>
</div>

---
Primary Category: cs.CV  
Categories: cs-CV, cs.CV  
Keyword Score: 53  
Keywords: Vision Transformer, Benchmarking, Convolution, Data Augmentation, Transformer, Vision Transformer  
<a type="button" class="btn btn-outline-primary" href="http://arxiv.org/abs/2402.19401v1" target="_blank" >Paper Link</a>
<button type="button" class="btn btn-outline-primary download-pdf" url="https://arxiv.org/pdf/2402.19401v1.pdf" filename="2402.19401v1.pdf">Download PDF</button>

---


**ABSTRACT**  
While Neural Networks (NNs) have surpassed human accuracy in image classification on ImageNet, they often lack robustness against image corruption, i.e., corruption robustness. Yet such robustness is seemingly effortless for human perception. In this paper, we propose visually-continuous corruption robustness (VCR) -- an extension of corruption robustness to allow assessing it over the wide and continuous range of changes that correspond to the human perceptive quality (i.e., from the original image to the full distortion of all perceived visual information), along with two novel human-aware metrics for NN evaluation. To compare VCR of NNs with human perception, we conducted extensive experiments on 14 commonly used image corruptions with 7,718 human participants and state-of-the-art robust NN models with different training objectives (e.g., standard, adversarial, corruption robustness), different architectures (e.g., <b>convolution</b> NNs, <b>vision</b> <b>transformers),</b> and different amounts of training <b>data</b> <b>augmentation.</b> Our study showed that: 1) assessing robustness against continuous corruption can reveal insufficient robustness undetected by existing <b>benchmarks;</b> as a result, 2) the gap between NN and human robustness is larger than previously known; and finally, 3) some image corruptions have a similar impact on human perception, offering opportunities for more cost-effective robustness assessments. Our validation set with 14 image corruptions, human robustness <b>data,</b> <b>and</b> the evaluation code is provided as a toolbox and a <b>benchmark.</b>

{{</citation>}}


### (7/69 | 55/321) VIXEN: Visual Text Comparison Network for Image Difference Captioning (Alexander Black et al., 2024)

{{<citation>}}

Alexander Black, Jing Shi, Yifei Fai, Tu Bui, John Collomosse. (2024)  
**VIXEN: Visual Text Comparison Network for Image Difference Captioning**
<br/>
<button class="copy-to-clipboard" title="VIXEN: Visual Text Comparison Network for Image Difference Captioning" index=55>
  <span class="copy-to-clipboard-item">Copy Title<span>
</button>
<div class="toast toast-copied toast-index-55 align-items-center text-bg-secondary border-0 position-absolute top-0 end-0" role="alert" aria-live="assertive" aria-atomic="true">
  <div class="d-flex">
    <div class="toast-body">
      Copied!
    </div>
  </div>
</div>

---
Primary Category: cs.CV  
Categories: cs-CL, cs-CV, cs.CV  
Keyword Score: 50  
Keywords: GPT, GPT-3, Large Language Model, Prompt, Summarization  
<a type="button" class="btn btn-outline-primary" href="http://arxiv.org/abs/2402.19119v1" target="_blank" >Paper Link</a>
<button type="button" class="btn btn-outline-primary download-pdf" url="https://arxiv.org/pdf/2402.19119v1.pdf" filename="2402.19119v1.pdf">Download PDF</button>

---


**ABSTRACT**  
We present VIXEN - a technique that succinctly <b>summarizes</b> in text the visual differences between a pair of images in order to highlight any content manipulation present. Our proposed network linearly maps image features in a pairwise manner, constructing a soft <b>prompt</b> for a pretrained <b>large</b> <b>language</b> <b>model.</b> We address the challenge of low volume of training data and lack of manipulation variety in existing image difference captioning (IDC) datasets by training on synthetically manipulated images from the recent InstructPix2Pix dataset generated via <b>prompt-to-prompt</b> editing framework. We augment this dataset with change summaries produced via <b>GPT-3.</b> We show that VIXEN produces state-of-the-art, comprehensible difference captions for diverse image contents and edit types, offering a potential mitigation against misinformation disseminated via manipulated image content. Code and data are available at http://github.com/alexblck/vixen

{{</citation>}}


### (8/69 | 56/321) RSAM-Seg: A SAM-based Approach with Prior Knowledge Integration for Remote Sensing Image Semantic Segmentation (Jie Zhang et al., 2024)

{{<citation>}}

Jie Zhang, Xubing Yang, Rui Jiang, Wei Shao, Li Zhang. (2024)  
**RSAM-Seg: A SAM-based Approach with Prior Knowledge Integration for Remote Sensing Image Semantic Segmentation**
<br/>
<button class="copy-to-clipboard" title="RSAM-Seg: A SAM-based Approach with Prior Knowledge Integration for Remote Sensing Image Semantic Segmentation" index=56>
  <span class="copy-to-clipboard-item">Copy Title<span>
</button>
<div class="toast toast-copied toast-index-56 align-items-center text-bg-secondary border-0 position-absolute top-0 end-0" role="alert" aria-live="assertive" aria-atomic="true">
  <div class="d-flex">
    <div class="toast-body">
      Copied!
    </div>
  </div>
</div>

---
Primary Category: cs.CV  
Categories: cs-CV, cs.CV, eess-IV  
Keyword Score: 50  
Keywords: Vision Transformer, Few-shot, Transformer, Prompt, Vision Transformer  
<a type="button" class="btn btn-outline-primary" href="http://arxiv.org/abs/2402.19004v1" target="_blank" >Paper Link</a>
<button type="button" class="btn btn-outline-primary download-pdf" url="https://arxiv.org/pdf/2402.19004v1.pdf" filename="2402.19004v1.pdf">Download PDF</button>

---


**ABSTRACT**  
The development of high-resolution remote sensing satellites has provided great convenience for research work related to remote sensing. Segmentation and extraction of specific targets are essential tasks when facing the vast and complex remote sensing images. Recently, the introduction of Segment Anything Model (SAM) provides a universal pre-training model for image segmentation tasks. While the direct application of SAM to remote sensing image segmentation tasks does not yield satisfactory results, we propose RSAM-Seg, which stands for Remote Sensing SAM with Semantic Segmentation, as a tailored modification of SAM for the remote sensing field and eliminates the need for manual intervention to provide <b>prompts.</b> Adapter-Scale, a set of supplementary scaling modules, are proposed in the multi-head attention blocks of the encoder part of SAM. Furthermore, Adapter-Feature are inserted between the <b>Vision</b> <b>Transformer</b> (ViT) blocks. These modules aim to incorporate high-frequency image information and image embedding features to generate image-informed <b>prompts.</b> Experiments are conducted on four distinct remote sensing scenarios, encompassing cloud detection, field monitoring, building detection and road mapping tasks . The experimental results not only showcase the improvement over the original SAM and U-Net across cloud, buildings, fields and roads scenarios, but also highlight the capacity of RSAM-Seg to discern absent areas within the ground truth of certain datasets, affirming its potential as an auxiliary annotation method. In addition, the performance in <b>few-shot</b> scenarios is commendable, underscores its potential in dealing with limited datasets.

{{</citation>}}


### (9/69 | 57/321) Edge Computing Enabled Real-Time Video Analysis via Adaptive Spatial-Temporal Semantic Filtering (Xiang Chen et al., 2024)

{{<citation>}}

Xiang Chen, Wenjie Zhu, Jiayuan Chen, Tong Zhang, Changyan Yi, Jun Cai. (2024)  
**Edge Computing Enabled Real-Time Video Analysis via Adaptive Spatial-Temporal Semantic Filtering**
<br/>
<button class="copy-to-clipboard" title="Edge Computing Enabled Real-Time Video Analysis via Adaptive Spatial-Temporal Semantic Filtering" index=57>
  <span class="copy-to-clipboard-item">Copy Title<span>
</button>
<div class="toast toast-copied toast-index-57 align-items-center text-bg-secondary border-0 position-absolute top-0 end-0" role="alert" aria-live="assertive" aria-atomic="true">
  <div class="d-flex">
    <div class="toast-body">
      Copied!
    </div>
  </div>
</div>

---
Primary Category: cs.CV  
Categories: cs-CV, cs-MM, cs-NI, cs.CV  
Keyword Score: 50  
Keywords: Object Detection, Bandit Algorithm, Reinforcement Learning, Simulation, Simulator  
<a type="button" class="btn btn-outline-primary" href="http://arxiv.org/abs/2402.18927v1" target="_blank" >Paper Link</a>
<button type="button" class="btn btn-outline-primary download-pdf" url="https://arxiv.org/pdf/2402.18927v1.pdf" filename="2402.18927v1.pdf">Download PDF</button>

---


**ABSTRACT**  
This paper proposes a novel edge computing enabled real-time video analysis system for intelligent visual devices. The proposed system consists of a tracking-assisted <b>object</b> <b>detection</b> module (TAODM) and a region of interesting module (ROIM). TAODM adaptively determines the offloading decision to process each video frame locally with a tracking algorithm or to offload it to the edge server inferred by an <b>object</b> <b>detection</b> model. ROIM determines each offloading frame's resolution and detection model configuration to ensure that the analysis results can return in time. TAODM and ROIM interact jointly to filter the repetitive spatial-temporal semantic information to maximize the processing rate while ensuring high video analysis accuracy. Unlike most existing works, this paper investigates the real-time video analysis systems where the intelligent visual device connects to the edge server through a wireless network with fluctuating network conditions. We decompose the real-time video analysis problem into the offloading decision and configurations selection sub-problems. To solve these two sub-problems, we introduce a double deep Q network (DDQN) based offloading approach and a contextual multi-armed <b>bandit</b> (CMAB) based adaptive configurations selection approach, respectively. A DDQN-CMAB <b>reinforcement</b> <b>learning</b> (DCRL) training framework is further developed to integrate these two approaches to improve the overall video analyzing performance. Extensive <b>simulations</b> are conducted to evaluate the performance of the proposed solution, and demonstrate its superiority over counterparts.

{{</citation>}}


### (10/69 | 58/321) Stitching Gaps: Fusing Situated Perceptual Knowledge with Vision Transformers for High-Level Image Classification (Delfina Sol Martinez Pandiani et al., 2024)

{{<citation>}}

Delfina Sol Martinez Pandiani, Nicolas Lazzari, Valentina Presutti. (2024)  
**Stitching Gaps: Fusing Situated Perceptual Knowledge with Vision Transformers for High-Level Image Classification**
<br/>
<button class="copy-to-clipboard" title="Stitching Gaps: Fusing Situated Perceptual Knowledge with Vision Transformers for High-Level Image Classification" index=58>
  <span class="copy-to-clipboard-item">Copy Title<span>
</button>
<div class="toast toast-copied toast-index-58 align-items-center text-bg-secondary border-0 position-absolute top-0 end-0" role="alert" aria-live="assertive" aria-atomic="true">
  <div class="d-flex">
    <div class="toast-body">
      Copied!
    </div>
  </div>
</div>

---
Primary Category: cs.CV  
Categories: cs-AI, cs-CV, cs.CV  
Keyword Score: 43  
Keywords: Vision Transformer, Graph, Knowledge Graph, Knowledge Graph, Transformer, Vision Transformer  
<a type="button" class="btn btn-outline-primary" href="http://arxiv.org/abs/2402.19339v1" target="_blank" >Paper Link</a>
<button type="button" class="btn btn-outline-primary download-pdf" url="https://arxiv.org/pdf/2402.19339v1.pdf" filename="2402.19339v1.pdf">Download PDF</button>

---


**ABSTRACT**  
The increasing demand for automatic high-level image understanding, particularly in detecting abstract concepts (AC) within images, underscores the necessity for innovative and more interpretable approaches. These approaches need to harmonize traditional deep <b>vision</b> <b>methods</b> with the nuanced, context-dependent <b>knowledge</b> <b>humans</b> employ to interpret images at intricate semantic levels. In this work, we leverage situated perceptual <b>knowledge</b> <b>of</b> cultural images to enhance performance and interpretability in AC image classification. We automatically extract perceptual semantic units from images, which we then model and integrate into the ARTstract <b>Knowledge</b> <b>Graph</b> (AKG). This resource captures situated perceptual semantics gleaned from over 14,000 cultural images labeled with ACs. Additionally, we enhance the AKG with high-level linguistic frames. We compute <b>KG</b> embeddings and experiment with relative representations and hybrid approaches that fuse these embeddings with visual <b>transformer</b> embeddings. Finally, for interpretability, we conduct posthoc qualitative analyses by examining model similarities with training instances. Our results show that our hybrid KGE-ViT methods outperform existing techniques in AC image classification. The posthoc interpretability analyses reveal the visual <b>transformer's</b> proficiency in capturing pixel-level visual attributes, contrasting with our method's efficacy in representing more abstract and semantic scene elements. We demonstrate the synergy and complementarity between KGE embeddings' situated perceptual <b>knowledge</b> <b>and</b> deep visual model's sensory-perceptual understanding for AC image classification. This work suggests a strong potential of neuro-symbolic methods for <b>knowledge</b> <b>integration</b> and robust image representation for use in downstream intricate visual comprehension tasks. All the materials and code are available online.

{{</citation>}}


### (11/69 | 59/321) A Simple yet Effective Network based on Vision Transformer for Camouflaged Object and Salient Object Detection (Chao Hao et al., 2024)

{{<citation>}}

Chao Hao, Zitong Yu, Xin Liu, Jun Xu, Huanjing Yue, Jingyu Yang. (2024)  
**A Simple yet Effective Network based on Vision Transformer for Camouflaged Object and Salient Object Detection**
<br/>
<button class="copy-to-clipboard" title="A Simple yet Effective Network based on Vision Transformer for Camouflaged Object and Salient Object Detection" index=59>
  <span class="copy-to-clipboard-item">Copy Title<span>
</button>
<div class="toast toast-copied toast-index-59 align-items-center text-bg-secondary border-0 position-absolute top-0 end-0" role="alert" aria-live="assertive" aria-atomic="true">
  <div class="d-flex">
    <div class="toast-body">
      Copied!
    </div>
  </div>
</div>

---
Primary Category: cs.CV  
Categories: cs-CV, cs.CV  
Keyword Score: 43  
Keywords: Vision Transformer, Object Detection, Benchmarking, Transformer, Vision Transformer  
<a type="button" class="btn btn-outline-primary" href="http://arxiv.org/abs/2402.18922v1" target="_blank" >Paper Link</a>
<button type="button" class="btn btn-outline-primary download-pdf" url="https://arxiv.org/pdf/2402.18922v1.pdf" filename="2402.18922v1.pdf">Download PDF</button>

---


**ABSTRACT**  
Camouflaged <b>object</b> <b>detection</b> (COD) and salient <b>object</b> <b>detection</b> (SOD) are two distinct yet closely-related computer <b>vision</b> <b>tasks</b> widely studied during the past decades. Though sharing the same purpose of segmenting an image into binary foreground and background regions, their distinction lies in the fact that COD focuses on concealed <b>objects</b> <b>hidden</b> in the image, while SOD concentrates on the most prominent <b>objects</b> <b>in</b> the image. Previous works achieved good performance by stacking various hand-designed modules and multi-scale features. However, these carefully-designed complex networks often performed well on one task but not on another. In this work, we propose a simple yet effective network (SENet) based on <b>vision</b> <b>Transformer</b> (ViT), by employing a simple design of an asymmetric ViT-based encoder-decoder structure, we yield competitive results on both tasks, exhibiting greater versatility than meticulously crafted ones. Furthermore, to enhance the <b>Transformer's</b> ability to model local information, which is important for pixel-level binary segmentation tasks, we propose a local information capture module (LICM). We also propose a dynamic weighted loss (DW loss) based on Binary Cross-Entropy (BCE) and Intersection over Union (IoU) loss, which guides the network to pay more attention to those smaller and more difficult-to-find target <b>objects</b> <b>according</b> to their size. Moreover, we explore the issue of joint training of SOD and COD, and propose a preliminary solution to the conflict in joint training, further improving the performance of SOD. Extensive experiments on multiple <b>benchmark</b> datasets demonstrate the effectiveness of our method. The code is available at https://github.com/linuxsino/SENet.

{{</citation>}}


### (12/69 | 60/321) MaskFi: Unsupervised Learning of WiFi and Vision Representations for Multimodal Human Activity Recognition (Jianfei Yang et al., 2024)

{{<citation>}}

Jianfei Yang, Shijie Tang, Yuecong Xu, Yunjiao Zhou, Lihua Xie. (2024)  
**MaskFi: Unsupervised Learning of WiFi and Vision Representations for Multimodal Human Activity Recognition**
<br/>
<button class="copy-to-clipboard" title="MaskFi: Unsupervised Learning of WiFi and Vision Representations for Multimodal Human Activity Recognition" index=60>
  <span class="copy-to-clipboard-item">Copy Title<span>
</button>
<div class="toast toast-copied toast-index-60 align-items-center text-bg-secondary border-0 position-absolute top-0 end-0" role="alert" aria-live="assertive" aria-atomic="true">
  <div class="d-flex">
    <div class="toast-body">
      Copied!
    </div>
  </div>
</div>

---
Primary Category: cs.CV  
Categories: cs-CV, cs.CV  
Keyword Score: 41  
Keywords: Fine-tuning, Multi-modal, Multi-modal, Representation Learning, Unsupervised Learning, Unsupervised Learning  
<a type="button" class="btn btn-outline-primary" href="http://arxiv.org/abs/2402.19258v1" target="_blank" >Paper Link</a>
<button type="button" class="btn btn-outline-primary download-pdf" url="https://arxiv.org/pdf/2402.19258v1.pdf" filename="2402.19258v1.pdf">Download PDF</button>

---


**ABSTRACT**  
Human activity recognition (HAR) has been playing an increasingly important role in various domains such as healthcare, security monitoring, and metaverse gaming. Though numerous HAR methods based on computer vision have been developed to show prominent performance, they still suffer from poor robustness in adverse visual conditions in particular low illumination, which motivates WiFi-based HAR to serve as a good complementary modality. Existing solutions using WiFi and vision modalities rely on massive labeled data that are very cumbersome to collect. In this paper, we propose a novel <b>unsupervised</b> <b>multimodal</b> HAR solution, MaskFi, that leverages only unlabeled video and WiFi activity data for model training. We propose a new algorithm, masked WiFi-vision modeling (MI2M), that enables the model to learn cross-modal and single-modal features by predicting the masked sections in <b>representation</b> <b>learning.</b> Benefiting from our <b>unsupervised</b> <b>learning</b> procedure, the network requires only a small amount of annotated data for <b>finetuning</b> and can adapt to the new environment with better performance. We conduct extensive experiments on two WiFi-vision datasets collected in-house, and our method achieves human activity recognition and human identification in terms of both robustness and accuracy.

{{</citation>}}


### (13/69 | 61/321) T3DNet: Compressing Point Cloud Models for Lightweight 3D Recognition (Zhiyuan Yang et al., 2024)

{{<citation>}}

Zhiyuan Yang, Yunjiao Zhou, Lihua Xie, Jianfei Yang. (2024)  
**T3DNet: Compressing Point Cloud Models for Lightweight 3D Recognition**
<br/>
<button class="copy-to-clipboard" title="T3DNet: Compressing Point Cloud Models for Lightweight 3D Recognition" index=61>
  <span class="copy-to-clipboard-item">Copy Title<span>
</button>
<div class="toast toast-copied toast-index-61 align-items-center text-bg-secondary border-0 position-absolute top-0 end-0" role="alert" aria-live="assertive" aria-atomic="true">
  <div class="d-flex">
    <div class="toast-body">
      Copied!
    </div>
  </div>
</div>

---
Primary Category: cs.CV  
Categories: cs-CV, cs.CV  
Keyword Score: 40  
Keywords: Knowledge Distillation, Knowledge Distillation, Pruning, Quantization  
<a type="button" class="btn btn-outline-primary" href="http://arxiv.org/abs/2402.19264v1" target="_blank" >Paper Link</a>
<button type="button" class="btn btn-outline-primary download-pdf" url="https://arxiv.org/pdf/2402.19264v1.pdf" filename="2402.19264v1.pdf">Download PDF</button>

---


**ABSTRACT**  
3D point cloud has been widely used in many mobile application scenarios, including autonomous driving and 3D sensing on mobile devices. However, existing 3D point cloud models tend to be large and cumbersome, making them hard to deploy on edged devices due to their high memory requirements and non-real-time latency. There has been a lack of research on how to compress 3D point cloud models into lightweight models. In this paper, we propose a method called T3DNet (Tiny 3D Network with augmEntation and <b>disTillation)</b> to address this issue. We find that the tiny model after network augmentation is much easier for a teacher to <b>distill.</b> Instead of gradually reducing the parameters through techniques such as <b>pruning</b> or <b>quantization,</b> we pre-define a tiny model and improve its performance through auxiliary supervision from augmented networks and the original model. We evaluate our method on several public datasets, including ModelNet40, ShapeNet, and ScanObjectNN. Our method can achieve high compression rates without significant accuracy sacrifice, achieving state-of-the-art performances on three datasets against existing methods. Amazingly, our T3DNet is 58 times smaller and 54 times faster than the original model yet with only 1.4% accuracy descent on the ModelNet40 dataset.

{{</citation>}}


### (14/69 | 62/321) Weakly Supervised Monocular 3D Detection with a Single-View Image (Xueying Jiang et al., 2024)

{{<citation>}}

Xueying Jiang, Sheng Jin, Lewei Lu, Xiaoqin Zhang, Shijian Lu. (2024)  
**Weakly Supervised Monocular 3D Detection with a Single-View Image**
<br/>
<button class="copy-to-clipboard" title="Weakly Supervised Monocular 3D Detection with a Single-View Image" index=62>
  <span class="copy-to-clipboard-item">Copy Title<span>
</button>
<div class="toast toast-copied toast-index-62 align-items-center text-bg-secondary border-0 position-absolute top-0 end-0" role="alert" aria-live="assertive" aria-atomic="true">
  <div class="d-flex">
    <div class="toast-body">
      Copied!
    </div>
  </div>
</div>

---
Primary Category: cs.CV  
Categories: cs-CV, cs.CV  
Keyword Score: 40  
Keywords: Knowledge Distillation, Knowledge Transfer, Supervised Learning, Weakly-supervised Learning  
<a type="button" class="btn btn-outline-primary" href="http://arxiv.org/abs/2402.19144v1" target="_blank" >Paper Link</a>
<button type="button" class="btn btn-outline-primary download-pdf" url="https://arxiv.org/pdf/2402.19144v1.pdf" filename="2402.19144v1.pdf">Download PDF</button>

---


**ABSTRACT**  
Monocular 3D detection (M3D) aims for precise 3D object localization from a single-view image which usually involves labor-intensive annotation of 3D detection boxes. Weakly <b>supervised</b> M3D has recently been studied to obviate the 3D annotation process by leveraging many existing 2D annotations, but it often requires extra training data such as LiDAR point clouds or multi-view images which greatly degrades its applicability and usability in various applications. We propose SKD-WM3D, a weakly <b>supervised</b> monocular 3D detection framework that exploits depth information to achieve M3D with a single-view image exclusively without any 3D annotations or other training data. One key design in SKD-WM3D is a self-knowledge <b>distillation</b> framework, which transforms image features into 3D-like representations by fusing depth information and effectively mitigates the inherent depth ambiguity in monocular scenarios with little computational overhead in inference. In addition, we design an uncertainty-aware <b>distillation</b> loss and a gradient-targeted transfer modulation strategy which facilitate <b>knowledge</b> <b>acquisition</b> and <b>knowledge</b> <b>transfer,</b> respectively. Extensive experiments show that SKD-WM3D surpasses the state-of-the-art clearly and is even on par with many fully <b>supervised</b> methods.

{{</citation>}}


### (15/69 | 63/321) COFT-AD: COntrastive Fine-Tuning for Few-Shot Anomaly Detection (Jingyi Liao et al., 2024)

{{<citation>}}

Jingyi Liao, Xun Xu, Manh Cuong Nguyen, Adam Goodge, Chuan Sheng Foo. (2024)  
**COFT-AD: COntrastive Fine-Tuning for Few-Shot Anomaly Detection**
<br/>
<button class="copy-to-clipboard" title="COFT-AD: COntrastive Fine-Tuning for Few-Shot Anomaly Detection" index=63>
  <span class="copy-to-clipboard-item">Copy Title<span>
</button>
<div class="toast toast-copied toast-index-63 align-items-center text-bg-secondary border-0 position-absolute top-0 end-0" role="alert" aria-live="assertive" aria-atomic="true">
  <div class="d-flex">
    <div class="toast-body">
      Copied!
    </div>
  </div>
</div>

---
Primary Category: cs.CV  
Categories: cs-CV, cs.CV  
Keyword Score: 40  
Keywords: Anomaly Detection, Few-shot, Fine-tuning, Fine-tuning  
<a type="button" class="btn btn-outline-primary" href="http://arxiv.org/abs/2402.18998v1" target="_blank" >Paper Link</a>
<button type="button" class="btn btn-outline-primary download-pdf" url="https://arxiv.org/pdf/2402.18998v1.pdf" filename="2402.18998v1.pdf">Download PDF</button>

---


**ABSTRACT**  
Existing approaches towards <b>anomaly</b> <b>detection~(AD)</b> often rely on a substantial amount of <b>anomaly-free</b> <b>data</b> to train representation and density models. However, large <b>anomaly-free</b> <b>datasets</b> may not always be available before the inference stage; in which case an <b>anomaly</b> <b>detection</b> model must be trained with only a handful of normal samples, a.k.a. <b>few-shot</b> <b>anomaly</b> <b>detection</b> (FSAD). In this paper, we propose a novel methodology to address the challenge of FSAD which incorporates two important techniques. Firstly, we employ a model pre-trained on a large source dataset to initialize model weights. Secondly, to ameliorate the covariate shift between source and target domains, we adopt contrastive training to <b>fine-tune</b> on the <b>few-shot</b> target domain data. To learn suitable representations for the downstream AD task, we additionally incorporate cross-instance positive pairs to encourage a tight cluster of the normal samples, and negative pairs for better separation between normal and synthesized negative samples. We evaluate <b>few-shot</b> <b>anomaly</b> <b>detection</b> on on 3 controlled AD tasks and 4 real-world AD tasks to demonstrate the effectiveness of the proposed method.

{{</citation>}}


### (16/69 | 64/321) Dose Prediction Driven Radiotherapy Paramters Regression via Intra- and Inter-Relation Modeling (Jiaqi Cui et al., 2024)

{{<citation>}}

Jiaqi Cui, Yuanyuan Xu, Jianghong Xiao, Yuchen Fei, Jiliu Zhou, Xingcheng Peng, Yan Wang. (2024)  
**Dose Prediction Driven Radiotherapy Paramters Regression via Intra- and Inter-Relation Modeling**
<br/>
<button class="copy-to-clipboard" title="Dose Prediction Driven Radiotherapy Paramters Regression via Intra- and Inter-Relation Modeling" index=64>
  <span class="copy-to-clipboard-item">Copy Title<span>
</button>
<div class="toast toast-copied toast-index-64 align-items-center text-bg-secondary border-0 position-absolute top-0 end-0" role="alert" aria-live="assertive" aria-atomic="true">
  <div class="d-flex">
    <div class="toast-body">
      Copied!
    </div>
  </div>
</div>

---
Primary Category: cs.CV  
Categories: cs-CV, cs.CV  
Keyword Score: 40  
Keywords: Convolution, Convolutional Neural Network, Convolutional Neural Network, Transformer  
<a type="button" class="btn btn-outline-primary" href="http://arxiv.org/abs/2402.18879v1" target="_blank" >Paper Link</a>
<button type="button" class="btn btn-outline-primary download-pdf" url="https://arxiv.org/pdf/2402.18879v1.pdf" filename="2402.18879v1.pdf">Download PDF</button>

---


**ABSTRACT**  
Deep learning has facilitated the automation of radiotherapy by predicting accurate dose distribution maps. However, existing methods fail to derive the desirable radiotherapy parameters that can be directly input into the treatment planning system (TPS), impeding the full automation of radiotherapy. To enable more thorough automatic radiotherapy, in this paper, we propose a novel two-stage framework to directly regress the radiotherapy parameters, including a dose map prediction stage and a radiotherapy parameters regression stage. In stage one, we combine <b>transformer</b> and <b>convolutional</b> <b>neural</b> <b>network</b> <b>(CNN)</b> to predict realistic dose maps with rich global and local information, providing accurate dosimetric knowledge for the subsequent parameters regression. In stage two, two elaborate modules, i.e., an intra-relation modeling (Intra-RM) module and an inter-relation modeling (Inter-RM) module, are designed to exploit the organ-specific and organ-shared features for precise parameters regression. Experimental results on a rectal cancer dataset demonstrate the effectiveness of our method.

{{</citation>}}


### (17/69 | 65/321) The All-Seeing Project V2: Towards General Relation Comprehension of the Open World (Weiyun Wang et al., 2024)

{{<citation>}}

Weiyun Wang, Yiming Ren, Haowen Luo, Tiantong Li, Chenxiang Yan, Zhe Chen, Wenhai Wang, Qingyun Li, Lewei Lu, Xizhou Zhu, Yu Qiao, Jifeng Dai. (2024)  
**The All-Seeing Project V2: Towards General Relation Comprehension of the Open World**
<br/>
<button class="copy-to-clipboard" title="The All-Seeing Project V2: Towards General Relation Comprehension of the Open World" index=65>
  <span class="copy-to-clipboard-item">Copy Title<span>
</button>
<div class="toast toast-copied toast-index-65 align-items-center text-bg-secondary border-0 position-absolute top-0 end-0" role="alert" aria-live="assertive" aria-atomic="true">
  <div class="d-flex">
    <div class="toast-body">
      Copied!
    </div>
  </div>
</div>

---
Primary Category: cs.CV  
Categories: cs-CV, cs.CV  
Keyword Score: 39  
Keywords: Graph, Benchmarking, Multi-modal, Text Generation, Instruction Tuning, Large Language Model  
<a type="button" class="btn btn-outline-primary" href="http://arxiv.org/abs/2402.19474v1" target="_blank" >Paper Link</a>
<button type="button" class="btn btn-outline-primary download-pdf" url="https://arxiv.org/pdf/2402.19474v1.pdf" filename="2402.19474v1.pdf">Download PDF</button>

---


**ABSTRACT**  
We present the All-Seeing Project V2: a new model and dataset designed for understanding object relations in images. Specifically, we propose the All-Seeing Model V2 (ASMv2) that integrates the formulation of <b>text</b> <b>generation,</b> object localization, and relation comprehension into a relation conversation (ReC) task. Leveraging this unified task, our model excels not only in perceiving and recognizing all objects within the image but also in grasping the intricate relation <b>graph</b> between them, diminishing the relation hallucination often encountered by <b>Multi-modal</b> <b>Large</b> <b>Language</b> <b>Models</b> (MLLMs). To facilitate training and evaluation of MLLMs in relation understanding, we created the first high-quality ReC dataset ({AS-V2) which is aligned with the format of standard <b>instruction</b> <b>tuning</b> data. In addition, we design a new <b>benchmark,</b> termed Circular-based Relation Probing Evaluation (CRPE) for comprehensively evaluating the relation comprehension capabilities of MLLMs. Notably, our ASMv2 achieves an overall accuracy of 52.04 on this relation-aware <b>benchmark,</b> surpassing the 43.14 of LLaVA-1.5 by a <b>large</b> <b>margin.</b> <b>We</b> hope that our work can inspire more future research and contribute to the evolution towards artificial general intelligence. Our project is released at https://github.com/OpenGVLab/all-seeing.

{{</citation>}}


### (18/69 | 66/321) Navigating Hallucinations for Reasoning of Unintentional Activities (Shresth Grover et al., 2024)

{{<citation>}}

Shresth Grover, Vibhav Vineet, Yogesh S Rawat. (2024)  
**Navigating Hallucinations for Reasoning of Unintentional Activities**
<br/>
<button class="copy-to-clipboard" title="Navigating Hallucinations for Reasoning of Unintentional Activities" index=66>
  <span class="copy-to-clipboard-item">Copy Title<span>
</button>
<div class="toast toast-copied toast-index-66 align-items-center text-bg-secondary border-0 position-absolute top-0 end-0" role="alert" aria-live="assertive" aria-atomic="true">
  <div class="d-flex">
    <div class="toast-body">
      Copied!
    </div>
  </div>
</div>

---
Primary Category: cs.CV  
Categories: cs-CV, cs.CV  
Keyword Score: 36  
Keywords: Multi-modal, Multi-modal, Zero-shot, Reasoning, Prompt  
<a type="button" class="btn btn-outline-primary" href="http://arxiv.org/abs/2402.19405v2" target="_blank" >Paper Link</a>
<button type="button" class="btn btn-outline-primary download-pdf" url="https://arxiv.org/pdf/2402.19405v2.pdf" filename="2402.19405v2.pdf">Download PDF</button>

---


**ABSTRACT**  
In this work we present a novel task of understanding unintentional human activities in videos. We formalize this problem as a <b>reasoning</b> task under <b>zero-shot</b> scenario, where given a video of an unintentional activity we want to know why it transitioned from intentional to unintentional. We first evaluate the effectiveness of current state-of-the-art Large <b>Multimodal</b> Models on this <b>reasoning</b> task and observe that they suffer from hallucination. We further propose a novel <b>prompting</b> technique,termed as Dream of Thoughts (DoT), which allows the model to navigate through hallucinated thoughts to achieve better <b>reasoning.</b> To evaluate the performance on this task, we also introduce three different specialized metrics designed to quantify the models <b>reasoning</b> capability. We perform our experiments on two different datasets, OOPs and UCF-Crimes, and our findings show that DOT <b>prompting</b> technique is able to outperform standard <b>prompting,</b> while minimizing hallucinations.

{{</citation>}}


### (19/69 | 67/321) Entity-Aware Multimodal Alignment Framework for News Image Captioning (Junzhe Zhang et al., 2024)

{{<citation>}}

Junzhe Zhang, Huixuan Zhang, Xiaojun Wan. (2024)  
**Entity-Aware Multimodal Alignment Framework for News Image Captioning**
<br/>
<button class="copy-to-clipboard" title="Entity-Aware Multimodal Alignment Framework for News Image Captioning" index=67>
  <span class="copy-to-clipboard-item">Copy Title<span>
</button>
<div class="toast toast-copied toast-index-67 align-items-center text-bg-secondary border-0 position-absolute top-0 end-0" role="alert" aria-live="assertive" aria-atomic="true">
  <div class="d-flex">
    <div class="toast-body">
      Copied!
    </div>
  </div>
</div>

---
Primary Category: cs.CV  
Categories: cs-CL, cs-CV, cs.CV  
Keyword Score: 36  
Keywords: Fine-tuning, Multi-modal, Multi-modal, Zero-shot, Large Language Model  
<a type="button" class="btn btn-outline-primary" href="http://arxiv.org/abs/2402.19404v1" target="_blank" >Paper Link</a>
<button type="button" class="btn btn-outline-primary download-pdf" url="https://arxiv.org/pdf/2402.19404v1.pdf" filename="2402.19404v1.pdf">Download PDF</button>

---


**ABSTRACT**  
News image captioning task is a variant of image captioning task which requires model to generate a more informative caption with news image and the associated news article. <b>Multimodal</b> <b>Large</b> <b>Language</b> <b>models</b> have developed rapidly in recent years and is promising in news image captioning task. However, according to our experiments, common MLLMs are not good at generating the entities in <b>zero-shot</b> setting. Their abilities to deal with the entities information are still limited after simply <b>fine-tuned</b> on news image captioning dataset. To obtain a more powerful model to handle the <b>multimodal</b> entity information, we design two <b>multimodal</b> entity-aware alignment tasks and an alignment framework to align the model and generate the news image captions. Our method achieves better results than previous state-of-the-art models in CIDEr score (72.33 -> 86.29) on GoodNews dataset and (70.83 -> 85.61) on NYTimes800k dataset.

{{</citation>}}


### (20/69 | 68/321) CricaVPR: Cross-image Correlation-aware Representation Learning for Visual Place Recognition (Feng Lu et al., 2024)

{{<citation>}}

Feng Lu, Xiangyuan Lan, Lijun Zhang, Dongmei Jiang, Yaowei Wang, Chun Yuan. (2024)  
**CricaVPR: Cross-image Correlation-aware Representation Learning for Visual Place Recognition**
<br/>
<button class="copy-to-clipboard" title="CricaVPR: Cross-image Correlation-aware Representation Learning for Visual Place Recognition" index=68>
  <span class="copy-to-clipboard-item">Copy Title<span>
</button>
<div class="toast toast-copied toast-index-68 align-items-center text-bg-secondary border-0 position-absolute top-0 end-0" role="alert" aria-live="assertive" aria-atomic="true">
  <div class="d-flex">
    <div class="toast-body">
      Copied!
    </div>
  </div>
</div>

---
Primary Category: cs.CV  
Categories: cs-CV, cs-RO, cs.CV  
Keyword Score: 35  
Keywords: Convolution, Foundation Model, Representation Learning, Self-Attention  
<a type="button" class="btn btn-outline-primary" href="http://arxiv.org/abs/2402.19231v1" target="_blank" >Paper Link</a>
<button type="button" class="btn btn-outline-primary download-pdf" url="https://arxiv.org/pdf/2402.19231v1.pdf" filename="2402.19231v1.pdf">Download PDF</button>

---


**ABSTRACT**  
Over the past decade, most methods in visual place recognition (VPR) have used neural networks to produce feature <b>representations.</b> <b>These</b> networks typically produce a global <b>representation</b> <b>of</b> a place image using only this image itself and neglect the cross-image variations (e.g. viewpoint and illumination), which limits their robustness in challenging scenes. In this paper, we propose a robust global <b>representation</b> <b>method</b> with cross-image correlation awareness for VPR, named CricaVPR. Our method uses the <b>self-attention</b> mechanism to correlate multiple images within a batch. These images can be taken in the same place with different conditions or viewpoints, or even captured from different places. Therefore, our method can utilize the cross-image variations as a cue to guide the <b>representation</b> <b>learning,</b> which ensures more robust features are produced. To further facilitate the robustness, we propose a multi-scale <b>convolution-enhanced</b> adaptation method to adapt pre-trained visual <b>foundation</b> <b>models</b> to the VPR task, which introduces the multi-scale local information to further enhance the cross-image correlation-aware <b>representation.</b> <b>Experimental</b> results show that our method outperforms state-of-the-art methods by a large margin with significantly less training time. Our method achieves 94.5% R@1 on Pitts30k using 512-dim global features. The code is released at https://github.com/Lu-Feng/CricaVPR.

{{</citation>}}


### (21/69 | 69/321) DiffAssemble: A Unified Graph-Diffusion Model for 2D and 3D Reassembly (Gianluca Scarpellini et al., 2024)

{{<citation>}}

Gianluca Scarpellini, Stefano Fiorini, Francesco Giuliari, Pietro Morerio, Alessio Del Bue. (2024)  
**DiffAssemble: A Unified Graph-Diffusion Model for 2D and 3D Reassembly**
<br/>
<button class="copy-to-clipboard" title="DiffAssemble: A Unified Graph-Diffusion Model for 2D and 3D Reassembly" index=69>
  <span class="copy-to-clipboard-item">Copy Title<span>
</button>
<div class="toast toast-copied toast-index-69 align-items-center text-bg-secondary border-0 position-absolute top-0 end-0" role="alert" aria-live="assertive" aria-atomic="true">
  <div class="d-flex">
    <div class="toast-body">
      Copied!
    </div>
  </div>
</div>

---
Primary Category: cs.CV  
Categories: cs-CV, cs.CV  
Keyword Score: 33  
Keywords: Diffusion Model, Graph, Graph Neural Network, Graph Neural Network  
<a type="button" class="btn btn-outline-primary" href="http://arxiv.org/abs/2402.19302v1" target="_blank" >Paper Link</a>
<button type="button" class="btn btn-outline-primary download-pdf" url="https://arxiv.org/pdf/2402.19302v1.pdf" filename="2402.19302v1.pdf">Download PDF</button>

---


**ABSTRACT**  
Reassembly tasks play a fundamental role in many fields and multiple approaches exist to solve specific reassembly problems. In this context, we posit that a general unified model can effectively address them all, irrespective of the input data type (images, 3D, etc.). We introduce DiffAssemble, a <b>Graph</b> <b>Neural</b> <b>Network</b> <b>(GNN)-based</b> architecture that learns to solve reassembly tasks using a <b>diffusion</b> <b>model</b> formulation. Our method treats the elements of a set, whether pieces of 2D patch or 3D object fragments, as nodes of a spatial <b>graph.</b> <b>Training</b> <b>is</b> performed by introducing noise into the position and rotation of the elements and iteratively denoising them to reconstruct the coherent initial pose. DiffAssemble achieves state-of-the-art (SOTA) results in most 2D and 3D reassembly tasks and is the first learning-based approach that solves 2D puzzles for both rotation and translation. Furthermore, we highlight its remarkable reduction in run-time, performing 11 times faster than the quickest optimization-based method for puzzle solving. Code available at https://github.com/IIT-PAVIS/DiffAssemble

{{</citation>}}


### (22/69 | 70/321) A Novel Approach to Industrial Defect Generation through Blended Latent Diffusion Model with Online Adaptation (Hanxi Li et al., 2024)

{{<citation>}}

Hanxi Li, Zhengxun Zhang, Hao Chen, Lin Wu, Bo Li, Deyin Liu, Mingwen Wang. (2024)  
**A Novel Approach to Industrial Defect Generation through Blended Latent Diffusion Model with Online Adaptation**
<br/>
<button class="copy-to-clipboard" title="A Novel Approach to Industrial Defect Generation through Blended Latent Diffusion Model with Online Adaptation" index=70>
  <span class="copy-to-clipboard-item">Copy Title<span>
</button>
<div class="toast toast-copied toast-index-70 align-items-center text-bg-secondary border-0 position-absolute top-0 end-0" role="alert" aria-live="assertive" aria-atomic="true">
  <div class="d-flex">
    <div class="toast-body">
      Copied!
    </div>
  </div>
</div>

---
Primary Category: cs.CV  
Categories: cs-CV, cs-MM, cs.CV  
Keyword Score: 30  
Keywords: Diffusion Model, Anomaly Detection, Prompt  
<a type="button" class="btn btn-outline-primary" href="http://arxiv.org/abs/2402.19330v1" target="_blank" >Paper Link</a>
<button type="button" class="btn btn-outline-primary download-pdf" url="https://arxiv.org/pdf/2402.19330v1.pdf" filename="2402.19330v1.pdf">Download PDF</button>

---


**ABSTRACT**  
Effectively addressing the challenge of industrial <b>Anomaly</b> <b>Detection</b> (AD) necessitates an ample supply of defective samples, a constraint often hindered by their scarcity in industrial contexts. This paper introduces a novel algorithm designed to augment defective samples, thereby enhancing AD performance. The proposed method tailors the blended latent <b>diffusion</b> <b>model</b> for defect sample generation, employing a <b>diffusion</b> <b>model</b> to generate defective samples in the latent space. A feature editing process, controlled by a "trimap" mask and text <b>prompts,</b> refines the generated samples. The image generation inference process is structured into three stages: a free <b>diffusion</b> <b>stage,</b> an editing <b>diffusion</b> <b>stage,</b> and an online decoder adaptation stage. This sophisticated inference strategy yields high-quality synthetic defective samples with diverse pattern variations, leading to significantly improved AD accuracies based on the augmented training set. Specifically, on the widely recognized MVTec AD dataset, the proposed method elevates the state-of-the-art (SOTA) performance of AD with augmented data by 1.5%, 1.9%, and 3.1% for AD metrics AP, IAP, and IAP90, respectively. The implementation code of this work can be found at the GitHub repository https://github.com/GrandpaXun242/AdaBLDM.git

{{</citation>}}


### (23/69 | 71/321) BigGait: Learning Gait Representation You Want by Large Vision Models (Dingqiang Ye et al., 2024)

{{<citation>}}

Dingqiang Ye, Chao Fan, Jingzhe Ma, Xiaoming Liu, Shiqi Yu. (2024)  
**BigGait: Learning Gait Representation You Want by Large Vision Models**
<br/>
<button class="copy-to-clipboard" title="BigGait: Learning Gait Representation You Want by Large Vision Models" index=71>
  <span class="copy-to-clipboard-item">Copy Title<span>
</button>
<div class="toast toast-copied toast-index-71 align-items-center text-bg-secondary border-0 position-absolute top-0 end-0" role="alert" aria-live="assertive" aria-atomic="true">
  <div class="d-flex">
    <div class="toast-body">
      Copied!
    </div>
  </div>
</div>

---
Primary Category: cs.CV  
Categories: cs-CV, cs.CV  
Keyword Score: 30  
Keywords: Supervised Learning, Supervised Learning, Unsupervised Learning  
<a type="button" class="btn btn-outline-primary" href="http://arxiv.org/abs/2402.19122v1" target="_blank" >Paper Link</a>
<button type="button" class="btn btn-outline-primary download-pdf" url="https://arxiv.org/pdf/2402.19122v1.pdf" filename="2402.19122v1.pdf">Download PDF</button>

---


**ABSTRACT**  
Gait recognition stands as one of the most pivotal remote identification technologies and progressively expands across research and industrial communities. However, existing gait recognition methods heavily rely on task-specific upstream driven by <b>supervised</b> <b>learning</b> to provide explicit gait representations, which inevitably introduce expensive annotation costs and potentially cause cumulative errors. Escaping from this trend, this work explores effective gait representations based on the all-purpose knowledge produced by task-agnostic Large Vision Models (LVMs) and proposes a simple yet efficient gait framework, termed BigGait. Specifically, the Gait Representation Extractor (GRE) in BigGait effectively transforms all-purpose knowledge into implicit gait features in an <b>unsupervised</b> manner, drawing from design principles of established gait representation construction approaches. Experimental results on CCPG, CAISA-B* and SUSTech1K indicate that BigGait significantly outperforms the previous methods in both self-domain and cross-domain tasks in most cases, and provides a more practical paradigm for learning the next-generation gait representation. Eventually, we delve into prospective challenges and promising directions in LVMs-based gait recognition, aiming to inspire future work in this emerging topic. The source code will be available at https://github.com/ShiqiYu/OpenGait.

{{</citation>}}


### (24/69 | 72/321) Analysis of the Two-Step Heterogeneous Transfer Learning for Laryngeal Blood Vessel Classification: Issue and Improvement (Xinyi Fang et al., 2024)

{{<citation>}}

Xinyi Fang, Chak Fong Chong, Kei Long Wong, Yapeng Wang, Wei Ke, Tiankui Zhang, Sio-Kei Im. (2024)  
**Analysis of the Two-Step Heterogeneous Transfer Learning for Laryngeal Blood Vessel Classification: Issue and Improvement**
<br/>
<button class="copy-to-clipboard" title="Analysis of the Two-Step Heterogeneous Transfer Learning for Laryngeal Blood Vessel Classification: Issue and Improvement" index=72>
  <span class="copy-to-clipboard-item">Copy Title<span>
</button>
<div class="toast toast-copied toast-index-72 align-items-center text-bg-secondary border-0 position-absolute top-0 end-0" role="alert" aria-live="assertive" aria-atomic="true">
  <div class="d-flex">
    <div class="toast-body">
      Copied!
    </div>
  </div>
</div>

---
Primary Category: cs.CV  
Categories: cs-CV, cs.CV  
Keyword Score: 30  
Keywords: Fine-tuning, Fine-tuning, Transfer Learning  
<a type="button" class="btn btn-outline-primary" href="http://arxiv.org/abs/2402.19001v2" target="_blank" >Paper Link</a>
<button type="button" class="btn btn-outline-primary download-pdf" url="https://arxiv.org/pdf/2402.19001v2.pdf" filename="2402.19001v2.pdf">Download PDF</button>

---


**ABSTRACT**  
Transferring features learned from natural to medical images for classification is common. However, challenges arise due to the scarcity of certain medical image types and the feature disparities between natural and medical images. Two-step <b>transfer</b> <b>learning</b> has been recognized as a promising solution for this issue. However, choosing an appropriate intermediate domain would be critical in further improving the classification performance. In this work, we explore the effectiveness of using color fundus photographs of the diabetic retina dataset as an intermediate domain for two-step heterogeneous learning (THTL) to classify laryngeal vascular images with nine deep-learning models. Experiment results confirm that although the images in both the intermediate and target domains share vascularized characteristics, the accuracy is drastically reduced compared to one-step <b>transfer</b> <b>learning,</b> where only the last layer is <b>fine-tuned</b> (e.g., ResNet18 drops 14.7%, ResNet50 drops 14.8%). By analyzing the Layer Class Activation Maps (LayerCAM), we uncover a novel finding that the prevalent radial vascular pattern in the intermediate domain prevents learning the features of twisted and tangled vessels that distinguish the malignant class in the target domain. To address the performance drop, we propose the Step-Wise <b>Fine-Tuning</b> (SWFT) method on ResNet in the second step of THTL, resulting in substantial accuracy improvements. Compared to THTL's second step, where only the last layer is <b>fine-tuned,</b> accuracy increases by 26.1% for ResNet18 and 20.4% for ResNet50. Additionally, compared to training from scratch, using ImageNet as the source domain could slightly improve classification performance for laryngeal vascular, but the differences are insignificant.

{{</citation>}}


### (25/69 | 73/321) Boosting Semi-Supervised Object Detection in Remote Sensing Images With Active Teaching (Boxuan Zhang et al., 2024)

{{<citation>}}

Boxuan Zhang, Zengmao Wang, Bo Du. (2024)  
**Boosting Semi-Supervised Object Detection in Remote Sensing Images With Active Teaching**
<br/>
<button class="copy-to-clipboard" title="Boosting Semi-Supervised Object Detection in Remote Sensing Images With Active Teaching" index=73>
  <span class="copy-to-clipboard-item">Copy Title<span>
</button>
<div class="toast toast-copied toast-index-73 align-items-center text-bg-secondary border-0 position-absolute top-0 end-0" role="alert" aria-live="assertive" aria-atomic="true">
  <div class="d-flex">
    <div class="toast-body">
      Copied!
    </div>
  </div>
</div>

---
Primary Category: cs.CV  
Categories: cs-CV, cs.CV  
Keyword Score: 30  
Keywords: Object Detection, Active Learning, Semi-Supervised Learning  
<a type="button" class="btn btn-outline-primary" href="http://arxiv.org/abs/2402.18958v1" target="_blank" >Paper Link</a>
<button type="button" class="btn btn-outline-primary download-pdf" url="https://arxiv.org/pdf/2402.18958v1.pdf" filename="2402.18958v1.pdf">Download PDF</button>

---


**ABSTRACT**  
The lack of <b>object-level</b> <b>annotations</b> poses a significant challenge for <b>object</b> <b>detection</b> in remote sensing images (RSIs). To address this issue, <b>active</b> <b>learning</b> (AL) and <b>semi-supervised</b> <b>learning</b> (SSL) techniques have been proposed to enhance the quality and quantity of annotations. AL focuses on selecting the most informative samples for annotation, while SSL leverages the knowledge from unlabeled samples. In this letter, we propose a novel AL method to boost <b>semi-supervised</b> <b>object</b> <b>detection</b> (SSOD) for remote sensing images with a teacher student network, called SSOD-AT. The proposed method incorporates an RoI comparison module (RoICM) to generate high-confidence pseudo-labels for regions of interest (RoIs). Meanwhile, the RoICM is utilized to identify the top-K uncertain images. To reduce redundancy in the top-K uncertain images for human labeling, a diversity criterion is introduced based on <b>object-level</b> <b>prototypes</b> of different categories using both labeled and pseudo-labeled images. Extensive experiments on DOTA and DIOR, two popular datasets, demonstrate that our proposed method outperforms state-of-the-art methods for <b>object</b> <b>detection</b> in RSIs. Compared with the best performance in the SOTA methods, the proposed method achieves 1 percent improvement in most cases in the whole AL.

{{</citation>}}


### (26/69 | 74/321) Decompose-and-Compose: A Compositional Approach to Mitigating Spurious Correlation (Fahimeh Hosseini Noohdani et al., 2024)

{{<citation>}}

Fahimeh Hosseini Noohdani, Parsa Hosseini, Aryan Yazdan Parast, Hamidreza Yaghoubi Araghi, Mahdieh Soleymani Baghshah. (2024)  
**Decompose-and-Compose: A Compositional Approach to Mitigating Spurious Correlation**
<br/>
<button class="copy-to-clipboard" title="Decompose-and-Compose: A Compositional Approach to Mitigating Spurious Correlation" index=74>
  <span class="copy-to-clipboard-item">Copy Title<span>
</button>
<div class="toast toast-copied toast-index-74 align-items-center text-bg-secondary border-0 position-absolute top-0 end-0" role="alert" aria-live="assertive" aria-atomic="true">
  <div class="d-flex">
    <div class="toast-body">
      Copied!
    </div>
  </div>
</div>

---
Primary Category: cs.CV  
Categories: cs-CV, cs-LG, cs.CV  
Keyword Score: 30  
Keywords: Counter-factual, Distribution Shift, Distribution Shift, Out-of-distribution  
<a type="button" class="btn btn-outline-primary" href="http://arxiv.org/abs/2402.18919v2" target="_blank" >Paper Link</a>
<button type="button" class="btn btn-outline-primary download-pdf" url="https://arxiv.org/pdf/2402.18919v2.pdf" filename="2402.18919v2.pdf">Download PDF</button>

---


**ABSTRACT**  
While standard Empirical Risk Minimization (ERM) training is proven effective for image classification on in-distribution data, it fails to perform well on <b>out-of-distribution</b> samples. One of the main sources of <b>distribution</b> <b>shift</b> for image classification is the compositional nature of images. Specifically, in addition to the main object or component(s) determining the label, some other image components usually exist, which may lead to the shift of input <b>distribution</b> <b>between</b> train and test environments. More importantly, these components may have spurious correlations with the label. To address this issue, we propose Decompose-and-Compose (DaC), which improves robustness to correlation shift by a compositional approach based on combining elements of images. Based on our observations, models trained with ERM usually highly attend to either the causal components or the components having a high spurious correlation with the label (especially in datapoints on which models have a high confidence). In fact, according to the amount of spurious correlation and the easiness of classification based on the causal or non-causal components, the model usually attends to one of these more (on samples with high confidence). Following this, we first try to identify the causal components of images using class activation maps of models trained with ERM. Afterward, we intervene on images by combining them and retraining the model on the augmented data, including the <b>counterfactual</b> ones. Along with its high interpretability, this work proposes a group-balancing method by intervening on images without requiring group labels or information regarding the spurious features during training. The method has an overall better worst group accuracy compared to previous methods with the same amount of supervision on the group labels in correlation shift.

{{</citation>}}


### (27/69 | 75/321) BFRFormer: Transformer-based generator for Real-World Blind Face Restoration (Guojing Ge et al., 2024)

{{<citation>}}

Guojing Ge, Qi Song, Guibo Zhu, Yuting Zhang, Jinglu Chen, Miao Xin, Ming Tang, Jinqiao Wang. (2024)  
**BFRFormer: Transformer-based generator for Real-World Blind Face Restoration**
<br/>
<button class="copy-to-clipboard" title="BFRFormer: Transformer-based generator for Real-World Blind Face Restoration" index=75>
  <span class="copy-to-clipboard-item">Copy Title<span>
</button>
<div class="toast toast-copied toast-index-75 align-items-center text-bg-secondary border-0 position-absolute top-0 end-0" role="alert" aria-live="assertive" aria-atomic="true">
  <div class="d-flex">
    <div class="toast-body">
      Copied!
    </div>
  </div>
</div>

---
Primary Category: cs.CV  
Categories: cs-CV, cs.CV  
Keyword Score: 30  
Keywords: Convolution, Convolutional Neural Network, Transformer  
<a type="button" class="btn btn-outline-primary" href="http://arxiv.org/abs/2402.18811v1" target="_blank" >Paper Link</a>
<button type="button" class="btn btn-outline-primary download-pdf" url="https://arxiv.org/pdf/2402.18811v1.pdf" filename="2402.18811v1.pdf">Download PDF</button>

---


**ABSTRACT**  
Blind face restoration is a challenging task due to the unknown and complex degradation. Although face prior-based methods and reference-based methods have recently demonstrated high-quality results, the restored images tend to contain over-smoothed results and lose identity-preserved details when the degradation is severe. It is observed that this is attributed to short-range dependencies, the intrinsic limitation of <b>convolutional</b> <b>neural</b> <b>networks.</b> To model long-range dependencies, we propose a <b>Transformer-based</b> blind face restoration method, named BFRFormer, to reconstruct images with more identity-preserved details in an end-to-end manner. In BFRFormer, to remove blocking artifacts, the wavelet discriminator and aggregated attention module are developed, and spectral normalization and balanced consistency regulation are adaptively applied to address the training instability and over-fitting problem, respectively. Extensive experiments show that our method outperforms state-of-the-art methods on a synthetic dataset and four real-world datasets. The source code, Casia-Test dataset, and pre-trained models are released at https://github.com/s8Znk/BFRFormer.

{{</citation>}}


### (28/69 | 76/321) A Quantitative Evaluation of Score Distillation Sampling Based Text-to-3D (Xiaohan Fei et al., 2024)

{{<citation>}}

Xiaohan Fei, Chethan Parameshwara, Jiawei Mo, Xiaolong Li, Ashwin Swaminathan, CJ Taylor, Paolo Favaro, Stefano Soatto. (2024)  
**A Quantitative Evaluation of Score Distillation Sampling Based Text-to-3D**
<br/>
<button class="copy-to-clipboard" title="A Quantitative Evaluation of Score Distillation Sampling Based Text-to-3D" index=76>
  <span class="copy-to-clipboard-item">Copy Title<span>
</button>
<div class="toast toast-copied toast-index-76 align-items-center text-bg-secondary border-0 position-absolute top-0 end-0" role="alert" aria-live="assertive" aria-atomic="true">
  <div class="d-flex">
    <div class="toast-body">
      Copied!
    </div>
  </div>
</div>

---
Primary Category: cs.CV  
Categories: cs-CV, cs.CV  
Keyword Score: 30  
Keywords: Diffusion Model, Knowledge Distillation, Prompt  
<a type="button" class="btn btn-outline-primary" href="http://arxiv.org/abs/2402.18780v1" target="_blank" >Paper Link</a>
<button type="button" class="btn btn-outline-primary download-pdf" url="https://arxiv.org/pdf/2402.18780v1.pdf" filename="2402.18780v1.pdf">Download PDF</button>

---


**ABSTRACT**  
The development of generative models that create 3D content from a text <b>prompt</b> has made considerable strides thanks to the use of the score <b>distillation</b> sampling (SDS) method on pre-trained <b>diffusion</b> <b>models</b> for image generation. However, the SDS method is also the source of several artifacts, such as the Janus problem, the misalignment between the text <b>prompt</b> and the generated 3D model, and 3D model inaccuracies. While existing methods heavily rely on the qualitative assessment of these artifacts through visual inspection of a limited set of samples, in this work we propose more objective quantitative evaluation metrics, which we cross-validate via human ratings, and show analysis of the failure cases of the SDS technique. We demonstrate the effectiveness of this analysis by designing a novel computationally efficient baseline model that achieves state-of-the-art performance on the proposed metrics while addressing all the above-mentioned artifacts.

{{</citation>}}


### (29/69 | 77/321) Enhancing Visual Document Understanding with Contrastive Learning in Large Visual-Language Models (Xin Li et al., 2024)

{{<citation>}}

Xin Li, Yunfei Wu, Xinghua Jiang, Zhihao Guo, Mingming Gong, Haoyu Cao, Yinsong Liu, Deqiang Jiang, Xing Sun. (2024)  
**Enhancing Visual Document Understanding with Contrastive Learning in Large Visual-Language Models**
<br/>
<button class="copy-to-clipboard" title="Enhancing Visual Document Understanding with Contrastive Learning in Large Visual-Language Models" index=77>
  <span class="copy-to-clipboard-item">Copy Title<span>
</button>
<div class="toast toast-copied toast-index-77 align-items-center text-bg-secondary border-0 position-absolute top-0 end-0" role="alert" aria-live="assertive" aria-atomic="true">
  <div class="d-flex">
    <div class="toast-body">
      Copied!
    </div>
  </div>
</div>

---
Primary Category: cs.CV  
Categories: cs-CV, cs.CV  
Keyword Score: 29  
Keywords: Benchmarking, Contrastive Learning, Multi-modal, Multi-modal, Vision-and-Language  
<a type="button" class="btn btn-outline-primary" href="http://arxiv.org/abs/2402.19014v1" target="_blank" >Paper Link</a>
<button type="button" class="btn btn-outline-primary download-pdf" url="https://arxiv.org/pdf/2402.19014v1.pdf" filename="2402.19014v1.pdf">Download PDF</button>

---


**ABSTRACT**  
Recently, the advent of Large Visual-Language Models (LVLMs) has received increasing attention across various domains, particularly in the field of visual document understanding (VDU). Different from conventional <b>vision-language</b> tasks, VDU is specifically concerned with text-rich scenarios containing abundant document elements. Nevertheless, the importance of fine-grained features remains largely unexplored within the community of LVLMs, leading to suboptimal performance in text-rich scenarios. In this paper, we abbreviate it as the fine-grained feature collapse issue. With the aim of filling this gap, we propose a <b>contrastive</b> <b>learning</b> framework, termed Document Object <b>COntrastive</b> <b>learning</b> (DoCo), specifically tailored for the downstream tasks of VDU. DoCo leverages an auxiliary <b>multimodal</b> encoder to obtain the features of document objects and align them to the visual features generated by the vision encoder of LVLM, which enhances visual representation in text-rich scenarios. It can represent that the <b>contrastive</b> <b>learning</b> between the visual holistic representations and the <b>multimodal</b> fine-grained features of document objects can assist the vision encoder in acquiring more effective visual cues, thereby enhancing the comprehension of text-rich documents in LVLMs. We also demonstrate that the proposed DoCo serves as a plug-and-play pre-training method, which can be employed in the pre-training of various LVLMs without inducing any increase in computational complexity during the inference process. Extensive experimental results on multiple <b>benchmarks</b> of VDU reveal that LVLMs equipped with our proposed DoCo can achieve superior performance and mitigate the gap between VDU and generic <b>vision-language</b> tasks.

{{</citation>}}


### (30/69 | 78/321) Percept, Chat, and then Adapt: Multimodal Knowledge Transfer of Foundation Models for Open-World Video Recognition (Boyu Chen et al., 2024)

{{<citation>}}

Boyu Chen, Siran Chen, Kunchang Li, Qinglin Xu, Yu Qiao, Yali Wang. (2024)  
**Percept, Chat, and then Adapt: Multimodal Knowledge Transfer of Foundation Models for Open-World Video Recognition**
<br/>
<button class="copy-to-clipboard" title="Percept, Chat, and then Adapt: Multimodal Knowledge Transfer of Foundation Models for Open-World Video Recognition" index=78>
  <span class="copy-to-clipboard-item">Copy Title<span>
</button>
<div class="toast toast-copied toast-index-78 align-items-center text-bg-secondary border-0 position-absolute top-0 end-0" role="alert" aria-live="assertive" aria-atomic="true">
  <div class="d-flex">
    <div class="toast-body">
      Copied!
    </div>
  </div>
</div>

---
Primary Category: cs.CV  
Categories: cs-CV, cs.CV  
Keyword Score: 29  
Keywords: Benchmarking, Foundation Model, Knowledge Transfer, Multi-modal, Multi-modal  
<a type="button" class="btn btn-outline-primary" href="http://arxiv.org/abs/2402.18951v1" target="_blank" >Paper Link</a>
<button type="button" class="btn btn-outline-primary download-pdf" url="https://arxiv.org/pdf/2402.18951v1.pdf" filename="2402.18951v1.pdf">Download PDF</button>

---


**ABSTRACT**  
Open-world video recognition is challenging since traditional networks are not generalized well on complex environment variations. Alternatively, <b>foundation</b> <b>models</b> with rich <b>knowledge</b> <b>have</b> recently shown their generalization power. However, how to apply such <b>knowledge</b> <b>has</b> not been fully explored for open-world video recognition. To this end, we propose a generic <b>knowledge</b> <b>transfer</b> pipeline, which progressively exploits and integrates external <b>multimodal</b> <b>knowledge</b> <b>from</b> <b>foundation</b> <b>models</b> to boost open-world video recognition. We name it PCA, based on three stages of Percept, Chat, and Adapt. First, we perform Percept process to reduce the video domain gap and obtain external visual <b>knowledge.</b> <b>Second,</b> we generate rich linguistic semantics as external textual <b>knowledge</b> <b>in</b> Chat stage. Finally, we blend external <b>multimodal</b> <b>knowledge</b> <b>in</b> Adapt stage, by inserting <b>multimodal</b> <b>knowledge</b> <b>adaptation</b> modules into networks. We conduct extensive experiments on three challenging open-world video <b>benchmarks,</b> i.e., TinyVIRAT, ARID, and QV-Pipe. Our approach achieves state-of-the-art performance on all three datasets.

{{</citation>}}


### (31/69 | 79/321) Panda-70M: Captioning 70M Videos with Multiple Cross-Modality Teachers (Tsai-Shien Chen et al., 2024)

{{<citation>}}

Tsai-Shien Chen, Aliaksandr Siarohin, Willi Menapace, Ekaterina Deyneka, Hsiang-wei Chao, Byung Eun Jeon, Yuwei Fang, Hsin-Ying Lee, Jian Ren, Ming-Hsuan Yang, Sergey Tulyakov. (2024)  
**Panda-70M: Captioning 70M Videos with Multiple Cross-Modality Teachers**
<br/>
<button class="copy-to-clipboard" title="Panda-70M: Captioning 70M Videos with Multiple Cross-Modality Teachers" index=79>
  <span class="copy-to-clipboard-item">Copy Title<span>
</button>
<div class="toast toast-copied toast-index-79 align-items-center text-bg-secondary border-0 position-absolute top-0 end-0" role="alert" aria-live="assertive" aria-atomic="true">
  <div class="d-flex">
    <div class="toast-body">
      Copied!
    </div>
  </div>
</div>

---
Primary Category: cs.CV  
Categories: cs-CV, cs.CV  
Keyword Score: 26  
Keywords: Fine-tuning, Multi-modal, Multi-modal, Image2text  
<a type="button" class="btn btn-outline-primary" href="http://arxiv.org/abs/2402.19479v1" target="_blank" >Paper Link</a>
<button type="button" class="btn btn-outline-primary download-pdf" url="https://arxiv.org/pdf/2402.19479v1.pdf" filename="2402.19479v1.pdf">Download PDF</button>

---


**ABSTRACT**  
The quality of the data and annotation upper-bounds the quality of a downstream model. While there exist large text corpora and <b>image-text</b> pairs, high-quality video-text data is much harder to collect. First of all, manual labeling is more time-consuming, as it requires an annotator to watch an entire video. Second, videos have a temporal dimension, consisting of several scenes stacked together, and showing multiple actions. Accordingly, to establish a video dataset with high-quality captions, we propose an automatic approach leveraging <b>multimodal</b> inputs, such as textual video description, subtitles, and individual video frames. Specifically, we curate 3.8M high-resolution videos from the publicly available HD-VILA-100M dataset. We then split them into semantically consistent video clips, and apply multiple cross-modality teacher models to obtain captions for each video. Next, we <b>finetune</b> a retrieval model on a small subset where the best caption of each video is manually selected and then employ the model in the whole dataset to select the best caption as the annotation. In this way, we get 70M videos paired with high-quality text captions. We dub the dataset as Panda-70M. We show the value of the proposed dataset on three downstream tasks: video captioning, video and text retrieval, and text-driven video generation. The models trained on the proposed data score substantially better on the majority of metrics across all the tasks.

{{</citation>}}


### (32/69 | 80/321) Debiased Novel Category Discovering and Localization (Juexiao Feng et al., 2024)

{{<citation>}}

Juexiao Feng, Yuhong Yang, Yanchun Xie, Yaqian Li, Yandong Guo, Yuchen Guo, Yuwei He, Liuyu Xiang, Guiguang Ding. (2024)  
**Debiased Novel Category Discovering and Localization**
<br/>
<button class="copy-to-clipboard" title="Debiased Novel Category Discovering and Localization" index=80>
  <span class="copy-to-clipboard-item">Copy Title<span>
</button>
<div class="toast toast-copied toast-index-80 align-items-center text-bg-secondary border-0 position-absolute top-0 end-0" role="alert" aria-live="assertive" aria-atomic="true">
  <div class="d-flex">
    <div class="toast-body">
      Copied!
    </div>
  </div>
</div>

---
Primary Category: cs.CV  
Categories: cs-CV, cs.CV  
Keyword Score: 26  
Keywords: Object Detection, Benchmarking, Clustering, Contrastive Learning  
<a type="button" class="btn btn-outline-primary" href="http://arxiv.org/abs/2402.18821v1" target="_blank" >Paper Link</a>
<button type="button" class="btn btn-outline-primary download-pdf" url="https://arxiv.org/pdf/2402.18821v1.pdf" filename="2402.18821v1.pdf">Download PDF</button>

---


**ABSTRACT**  
In recent years, <b>object</b> <b>detection</b> in deep learning has experienced rapid development. However, most existing <b>object</b> <b>detection</b> models perform well only on closed-set datasets, ignoring a large number of potential <b>objects</b> <b>whose</b> categories are not defined in the training set. These <b>objects</b> <b>are</b> often identified as background or incorrectly classified as pre-defined categories by the detectors. In this paper, we focus on the challenging problem of Novel Class Discovery and Localization (NCDL), aiming to train detectors that can detect the categories present in the training data, while also actively discover, localize, and cluster new categories. We analyze existing NCDL methods and identify the core issue: <b>object</b> <b>detectors</b> tend to be biased towards seen <b>objects,</b> <b>and</b> this leads to the neglect of unseen targets. To address this issue, we first propose an Debiased Region Mining (DRM) approach that combines class-agnostic Region Proposal Network (RPN) and class-aware RPN in a complementary manner. Additionally, we suggest to improve the representation network through semi-supervised <b>contrastive</b> <b>learning</b> by leveraging unlabeled data. Finally, we adopt a simple and efficient mini-batch K-means <b>clustering</b> method for novel class discovery. We conduct extensive experiments on the NCDL <b>benchmark,</b> and the results demonstrate that the proposed DRM approach significantly outperforms previous methods, establishing a new state-of-the-art.

{{</citation>}}


### (33/69 | 81/321) Learning a Generalized Physical Face Model From Data (Lingchen Yang et al., 2024)

{{<citation>}}

Lingchen Yang, Gaspard Zoss, Prashanth Chandran, Markus Gross, Barbara Solenthaler, Eftychios Sifakis, Derek Bradley. (2024)  
**Learning a Generalized Physical Face Model From Data**
<br/>
<button class="copy-to-clipboard" title="Learning a Generalized Physical Face Model From Data" index=81>
  <span class="copy-to-clipboard-item">Copy Title<span>
</button>
<div class="toast toast-copied toast-index-81 align-items-center text-bg-secondary border-0 position-absolute top-0 end-0" role="alert" aria-live="assertive" aria-atomic="true">
  <div class="d-flex">
    <div class="toast-body">
      Copied!
    </div>
  </div>
</div>

---
Primary Category: cs.CV  
Categories: cs-CV, cs-GR, cs.CV  
Keyword Score: 25  
Keywords: Geometry, Simulation, Simulator  
<a type="button" class="btn btn-outline-primary" href="http://arxiv.org/abs/2402.19477v1" target="_blank" >Paper Link</a>
<button type="button" class="btn btn-outline-primary download-pdf" url="https://arxiv.org/pdf/2402.19477v1.pdf" filename="2402.19477v1.pdf">Download PDF</button>

---


**ABSTRACT**  
Physically-based <b>simulation</b> is a powerful approach for 3D facial animation as the resulting deformations are governed by physical constraints, allowing to easily resolve self-collisions, respond to external forces and perform realistic anatomy edits. Today's methods are data-driven, where the actuations for finite elements are inferred from captured skin <b>geometry.</b> Unfortunately, these approaches have not been widely adopted due to the complexity of initializing the material space and learning the deformation model for each character separately, which often requires a skilled artist followed by lengthy network training. In this work, we aim to make physics-based facial animation more accessible by proposing a generalized physical face model that we learn from a large 3D face dataset in a <b>simulation-free</b> manner. Once trained, our model can be quickly fit to any unseen identity and produce a ready-to-animate physical face model automatically. Fitting is as easy as providing a single 3D face scan, or even a single face image. After fitting, we offer intuitive animation controls, as well as the ability to retarget animations across characters. All the while, the resulting animations allow for physical effects like collision avoidance, gravity, paralysis, bone reshaping and more.

{{</citation>}}


### (34/69 | 82/321) Aligning Knowledge Graph with Visual Perception for Object-goal Navigation (Nuo Xu et al., 2024)

{{<citation>}}

Nuo Xu, Wen Wang, Rong Yang, Mengjie Qin, Zheyuan Lin, Wei Song, Chunlong Zhang, Jason Gu, Chao Li. (2024)  
**Aligning Knowledge Graph with Visual Perception for Object-goal Navigation**
<br/>
<button class="copy-to-clipboard" title="Aligning Knowledge Graph with Visual Perception for Object-goal Navigation" index=82>
  <span class="copy-to-clipboard-item">Copy Title<span>
</button>
<div class="toast toast-copied toast-index-82 align-items-center text-bg-secondary border-0 position-absolute top-0 end-0" role="alert" aria-live="assertive" aria-atomic="true">
  <div class="d-flex">
    <div class="toast-body">
      Copied!
    </div>
  </div>
</div>

---
Primary Category: cs.CV  
Categories: cs-CV, cs-RO, cs.CV  
Keyword Score: 24  
Keywords: Graph, Knowledge Graph, Multi-modal, Multi-modal, Zero-shot  
<a type="button" class="btn btn-outline-primary" href="http://arxiv.org/abs/2402.18892v1" target="_blank" >Paper Link</a>
<button type="button" class="btn btn-outline-primary download-pdf" url="https://arxiv.org/pdf/2402.18892v1.pdf" filename="2402.18892v1.pdf">Download PDF</button>

---


**ABSTRACT**  
Object-goal navigation is a challenging task that requires guiding an agent to specific objects based on first-person visual observations. The ability of agent to comprehend its surroundings plays a crucial role in achieving successful object finding. However, existing <b>knowledge-graph-based</b> <b>navigators</b> often rely on discrete categorical one-hot vectors and vote counting strategy to construct <b>graph</b> representation of the scenes, which results in misalignment with visual images. To provide more accurate and coherent scene descriptions and address this misalignment issue, we propose the Aligning <b>Knowledge</b> <b>Graph</b> with Visual Perception (AKGVP) method for object-goal navigation. Technically, our approach introduces continuous modeling of the hierarchical scene architecture and leverages visual-language pre-training to align natural language description with visual perception. The integration of a continuous <b>knowledge</b> <b>graph</b> architecture and <b>multimodal</b> feature alignment empowers the navigator with a remarkable <b>zero-shot</b> navigation capability. We extensively evaluate our method using the AI2-THOR simulator and conduct a series of experiments to demonstrate the effectiveness and efficiency of our navigator. Code available: https://github.com/nuoxu/AKGVP.

{{</citation>}}


### (35/69 | 83/321) SeMoLi: What Moves Together Belongs Together (Jenny Seidenschwarz et al., 2024)

{{<citation>}}

Jenny Seidenschwarz, Aljoša Ošep, Francesco Ferroni, Simon Lucey, Laura Leal-Taixé. (2024)  
**SeMoLi: What Moves Together Belongs Together**
<br/>
<button class="copy-to-clipboard" title="SeMoLi: What Moves Together Belongs Together" index=83>
  <span class="copy-to-clipboard-item">Copy Title<span>
</button>
<div class="toast toast-copied toast-index-83 align-items-center text-bg-secondary border-0 position-absolute top-0 end-0" role="alert" aria-live="assertive" aria-atomic="true">
  <div class="d-flex">
    <div class="toast-body">
      Copied!
    </div>
  </div>
</div>

---
Primary Category: cs.CV  
Categories: cs-CV, cs.CV  
Keyword Score: 23  
Keywords: Object Detection, Message-Passing, Clustering  
<a type="button" class="btn btn-outline-primary" href="http://arxiv.org/abs/2402.19463v1" target="_blank" >Paper Link</a>
<button type="button" class="btn btn-outline-primary download-pdf" url="https://arxiv.org/pdf/2402.19463v1.pdf" filename="2402.19463v1.pdf">Download PDF</button>

---


**ABSTRACT**  
We tackle semi-supervised <b>object</b> <b>detection</b> based on motion cues. Recent results suggest that heuristic-based <b>clustering</b> methods in conjunction with <b>object</b> <b>trackers</b> can be used to pseudo-label instances of moving <b>objects</b> <b>and</b> use these as supervisory signals to train 3D <b>object</b> <b>detectors</b> in Lidar data without manual supervision. We re-think this approach and suggest that both, <b>object</b> <b>detection,</b> as well as motion-inspired pseudo-labeling, can be tackled in a data-driven manner. We leverage recent advances in scene flow estimation to obtain point trajectories from which we extract long-term, class-agnostic motion patterns. Revisiting correlation <b>clustering</b> in the context of message passing networks, we learn to group those motion patterns to cluster points to <b>object</b> <b>instances.</b> By estimating the full extent of the <b>objects,</b> <b>we</b> obtain per-scan 3D bounding boxes that we use to supervise a Lidar <b>object</b> <b>detection</b> network. Our method not only outperforms prior heuristic-based approaches (57.5 AP, +14 improvement over prior work), more importantly, we show we can pseudo-label and train <b>object</b> <b>detectors</b> across datasets.

{{</citation>}}


### (36/69 | 84/321) PEM: Prototype-based Efficient MaskFormer for Image Segmentation (Niccolò Cavagnero et al., 2024)

{{<citation>}}

Niccolò Cavagnero, Gabriele Rosi, Claudia Cuttano, Francesca Pistilli, Marco Ciccone, Giuseppe Averta, Fabio Cermelli. (2024)  
**PEM: Prototype-based Efficient MaskFormer for Image Segmentation**
<br/>
<button class="copy-to-clipboard" title="PEM: Prototype-based Efficient MaskFormer for Image Segmentation" index=84>
  <span class="copy-to-clipboard-item">Copy Title<span>
</button>
<div class="toast toast-copied toast-index-84 align-items-center text-bg-secondary border-0 position-absolute top-0 end-0" role="alert" aria-live="assertive" aria-atomic="true">
  <div class="d-flex">
    <div class="toast-body">
      Copied!
    </div>
  </div>
</div>

---
Primary Category: cs.CV  
Categories: cs-AI, cs-CV, cs.CV  
Keyword Score: 23  
Keywords: Benchmarking, Convolution, Transformer  
<a type="button" class="btn btn-outline-primary" href="http://arxiv.org/abs/2402.19422v2" target="_blank" >Paper Link</a>
<button type="button" class="btn btn-outline-primary download-pdf" url="https://arxiv.org/pdf/2402.19422v2.pdf" filename="2402.19422v2.pdf">Download PDF</button>

---


**ABSTRACT**  
Recent <b>transformer-based</b> architectures have shown impressive results in the field of image segmentation. Thanks to their flexibility, they obtain outstanding performance in multiple segmentation tasks, such as semantic and panoptic, under a single unified framework. To achieve such impressive performance, these architectures employ intensive operations and require substantial computational resources, which are often not available, especially on edge devices. To fill this gap, we propose Prototype-based Efficient MaskFormer (PEM), an efficient <b>transformer-based</b> architecture that can operate in multiple segmentation tasks. PEM proposes a novel prototype-based cross-attention which leverages the redundancy of visual features to restrict the computation and improve the efficiency without harming the performance. In addition, PEM introduces an efficient multi-scale feature pyramid network, capable of extracting features that have high semantic content in an efficient way, thanks to the combination of deformable <b>convolutions</b> and context-based self-modulation. We <b>benchmark</b> the proposed PEM architecture on two tasks, semantic and panoptic segmentation, evaluated on two different datasets, Cityscapes and ADE20K. PEM demonstrates outstanding performance on every task and dataset, outperforming task-specific architectures while being comparable and even better than computationally-expensive baselines.

{{</citation>}}


### (37/69 | 85/321) A SAM-guided Two-stream Lightweight Model for Anomaly Detection (Chenghao Li et al., 2024)

{{<citation>}}

Chenghao Li, Lei Qi, Xin Geng. (2024)  
**A SAM-guided Two-stream Lightweight Model for Anomaly Detection**
<br/>
<button class="copy-to-clipboard" title="A SAM-guided Two-stream Lightweight Model for Anomaly Detection" index=85>
  <span class="copy-to-clipboard-item">Copy Title<span>
</button>
<div class="toast toast-copied toast-index-85 align-items-center text-bg-secondary border-0 position-absolute top-0 end-0" role="alert" aria-live="assertive" aria-atomic="true">
  <div class="d-flex">
    <div class="toast-body">
      Copied!
    </div>
  </div>
</div>

---
Primary Category: cs.CV  
Categories: cs-CV, cs.CV  
Keyword Score: 23  
Keywords: Anomaly Detection, Benchmarking, Unsupervised Learning  
<a type="button" class="btn btn-outline-primary" href="http://arxiv.org/abs/2402.19145v1" target="_blank" >Paper Link</a>
<button type="button" class="btn btn-outline-primary download-pdf" url="https://arxiv.org/pdf/2402.19145v1.pdf" filename="2402.19145v1.pdf">Download PDF</button>

---


**ABSTRACT**  
In industrial <b>anomaly</b> <b>detection,</b> model efficiency and mobile-friendliness become the primary concerns in real-world applications. Simultaneously, the impressive generalization capabilities of Segment Anything (SAM) have garnered broad academic attention, making it an ideal choice for localizing unseen anomalies and diverse real-world patterns. In this paper, considering these two critical factors, we propose a SAM-guided Two-stream Lightweight Model for <b>unsupervised</b> <b>anomaly</b> <b>detection</b> (STLM) that not only aligns with the two practical application requirements but also harnesses the robust generalization capabilities of SAM. We employ two lightweight image encoders, i.e., our two-stream lightweight module, guided by SAM's knowledge. To be specific, one stream is trained to generate discriminative and general feature representations in both normal and anomalous regions, while the other stream reconstructs the same images without anomalies, which effectively enhances the differentiation of two-stream representations when facing anomalous regions. Furthermore, we employ a shared mask decoder and a feature aggregation module to generate <b>anomaly</b> <b>maps.</b> Our experiments conducted on MVTec AD <b>benchmark</b> show that STLM, with about 16M parameters and achieving an inference time in 20ms, competes effectively with state-of-the-art methods in terms of performance, 98.26% on pixel-level AUC and 94.92% on PRO. We further experiment on more difficult datasets, e.g., VisA and DAGM, to demonstrate the effectiveness and generalizability of STLM.

{{</citation>}}


### (38/69 | 86/321) Theoretically Achieving Continuous Representation of Oriented Bounding Boxes (Zikai Xiao et al., 2024)

{{<citation>}}

Zikai Xiao, Guo-Ye Yang, Xue Yang, Tai-Jiang Mu, Junchi Yan, Shi-min Hu. (2024)  
**Theoretically Achieving Continuous Representation of Oriented Bounding Boxes**
<br/>
<button class="copy-to-clipboard" title="Theoretically Achieving Continuous Representation of Oriented Bounding Boxes" index=86>
  <span class="copy-to-clipboard-item">Copy Title<span>
</button>
<div class="toast toast-copied toast-index-86 align-items-center text-bg-secondary border-0 position-absolute top-0 end-0" role="alert" aria-live="assertive" aria-atomic="true">
  <div class="d-flex">
    <div class="toast-body">
      Copied!
    </div>
  </div>
</div>

---
Primary Category: cs.CV  
Categories: cs-AI, cs-CV, cs.CV  
Keyword Score: 23  
Keywords: Object Detection, Benchmarking, Fairness  
<a type="button" class="btn btn-outline-primary" href="http://arxiv.org/abs/2402.18975v1" target="_blank" >Paper Link</a>
<button type="button" class="btn btn-outline-primary download-pdf" url="https://arxiv.org/pdf/2402.18975v1.pdf" filename="2402.18975v1.pdf">Download PDF</button>

---


**ABSTRACT**  
Considerable efforts have been devoted to Oriented <b>Object</b> <b>Detection</b> (OOD). However, one lasting issue regarding the discontinuity in Oriented Bounding Box (OBB) representation remains unresolved, which is an inherent bottleneck for extant OOD methods. This paper endeavors to completely solve this issue in a theoretically guaranteed manner and puts an end to the ad-hoc efforts in this direction. Prior studies typically can only address one of the two cases of discontinuity: rotation and aspect ratio, and often inadvertently introduce decoding discontinuity, e.g. Decoding Incompleteness (DI) and Decoding Ambiguity (DA) as discussed in literature. Specifically, we propose a novel representation method called Continuous OBB (COBB), which can be readily integrated into existing detectors e.g. Faster-RCNN as a plugin. It can theoretically ensure continuity in bounding box regression which to our best knowledge, has not been achieved in literature for rectangle-based <b>object</b> <b>representation.</b> For <b>fairness</b> and transparency of experiments, we have developed a modularized <b>benchmark</b> based on the open-source deep learning framework Jittor's detection toolbox JDet for OOD evaluation. On the popular DOTA dataset, by integrating Faster-RCNN as the same baseline model, our new method outperforms the peer method Gliding Vertex by 1.13% mAP50 (relative improvement 1.54%), and 2.46% mAP75 (relative improvement 5.91%), without any tricks.

{{</citation>}}


### (39/69 | 87/321) SwitchLight: Co-design of Physics-driven Architecture and Pre-training Framework for Human Portrait Relighting (Hoon Kim et al., 2024)

{{<citation>}}

Hoon Kim, Minje Jang, Wonjun Yoon, Jisoo Lee, Donghyun Na, Sanghyun Woo. (2024)  
**SwitchLight: Co-design of Physics-driven Architecture and Pre-training Framework for Human Portrait Relighting**
<br/>
<button class="copy-to-clipboard" title="SwitchLight: Co-design of Physics-driven Architecture and Pre-training Framework for Human Portrait Relighting" index=87>
  <span class="copy-to-clipboard-item">Copy Title<span>
</button>
<div class="toast toast-copied toast-index-87 align-items-center text-bg-secondary border-0 position-absolute top-0 end-0" role="alert" aria-live="assertive" aria-atomic="true">
  <div class="d-flex">
    <div class="toast-body">
      Copied!
    </div>
  </div>
</div>

---
Primary Category: cs.CV  
Categories: cs-CV, cs.CV  
Keyword Score: 23  
Keywords: Benchmarking, Self-supervised Learning, Self-supervised Pre-training  
<a type="button" class="btn btn-outline-primary" href="http://arxiv.org/abs/2402.18848v1" target="_blank" >Paper Link</a>
<button type="button" class="btn btn-outline-primary download-pdf" url="https://arxiv.org/pdf/2402.18848v1.pdf" filename="2402.18848v1.pdf">Download PDF</button>

---


**ABSTRACT**  
We introduce a co-designed approach for human portrait relighting that combines a physics-guided architecture with a pre-training framework. Drawing on the Cook-Torrance reflectance model, we have meticulously configured the architecture design to precisely simulate light-surface interactions. Furthermore, to overcome the limitation of scarce high-quality lightstage data, we have developed a <b>self-supervised</b> <b>pre-training</b> strategy. This novel combination of accurate physical modeling and expanded training dataset establishes a new <b>benchmark</b> in relighting realism.

{{</citation>}}


### (40/69 | 88/321) Modality-Agnostic Structural Image Representation Learning for Deformable Multi-Modality Medical Image Registration (Tony C. W. Mok et al., 2024)

{{<citation>}}

Tony C. W. Mok, Zi Li, Yunhao Bai, Jianpeng Zhang, Wei Liu, Yan-Jie Zhou, Ke Yan, Dakai Jin, Yu Shi, Xiaoli Yin, Le Lu, Ling Zhang. (2024)  
**Modality-Agnostic Structural Image Representation Learning for Deformable Multi-Modality Medical Image Registration**
<br/>
<button class="copy-to-clipboard" title="Modality-Agnostic Structural Image Representation Learning for Deformable Multi-Modality Medical Image Registration" index=88>
  <span class="copy-to-clipboard-item">Copy Title<span>
</button>
<div class="toast toast-copied toast-index-88 align-items-center text-bg-secondary border-0 position-absolute top-0 end-0" role="alert" aria-live="assertive" aria-atomic="true">
  <div class="d-flex">
    <div class="toast-body">
      Copied!
    </div>
  </div>
</div>

---
Primary Category: cs.CV  
Categories: cs-CV, cs.CV  
Keyword Score: 21  
Keywords: Contrastive Learning, Multi-modal, Multi-modal, Representation Learning  
<a type="button" class="btn btn-outline-primary" href="http://arxiv.org/abs/2402.18933v1" target="_blank" >Paper Link</a>
<button type="button" class="btn btn-outline-primary download-pdf" url="https://arxiv.org/pdf/2402.18933v1.pdf" filename="2402.18933v1.pdf">Download PDF</button>

---


**ABSTRACT**  
Establishing dense anatomical correspondence across distinct imaging modalities is a foundational yet challenging procedure for numerous medical image analysis studies and image-guided radiotherapy. Existing multi-modality image registration algorithms rely on statistical-based similarity measures or local structural image <b>representations.</b> <b>However,</b> the former is sensitive to locally varying noise, while the latter is not discriminative enough to cope with complex anatomical structures in <b>multimodal</b> scans, causing ambiguity in determining the anatomical correspondence across scans with different modalities. In this paper, we propose a modality-agnostic structural <b>representation</b> <b>learning</b> method, which leverages Deep Neighbourhood Self-similarity (DNS) and anatomy-aware <b>contrastive</b> <b>learning</b> to learn discriminative and contrast-invariance deep structural image <b>representations</b> <b>(DSIR)</b> without the need for anatomical delineations or pre-aligned training images. We evaluate our method on multiphase CT, abdomen MR-CT, and brain MR T1w-T2w registration. Comprehensive results demonstrate that our method is superior to the conventional local structural <b>representation</b> <b>and</b> statistical-based similarity measures in terms of discriminability and accuracy.

{{</citation>}}


### (41/69 | 89/321) Learning to Find Missing Video Frames with Synthetic Data Augmentation: A General Framework and Application in Generating Thermal Images Using RGB Cameras (Mathias Viborg Andersen et al., 2024)

{{<citation>}}

Mathias Viborg Andersen, Ross Greer, Andreas Møgelmose, Mohan Trivedi. (2024)  
**Learning to Find Missing Video Frames with Synthetic Data Augmentation: A General Framework and Application in Generating Thermal Images Using RGB Cameras**
<br/>
<button class="copy-to-clipboard" title="Learning to Find Missing Video Frames with Synthetic Data Augmentation: A General Framework and Application in Generating Thermal Images Using RGB Cameras" index=89>
  <span class="copy-to-clipboard-item">Copy Title<span>
</button>
<div class="toast toast-copied toast-index-89 align-items-center text-bg-secondary border-0 position-absolute top-0 end-0" role="alert" aria-live="assertive" aria-atomic="true">
  <div class="d-flex">
    <div class="toast-body">
      Copied!
    </div>
  </div>
</div>

---
Primary Category: cs.CV  
Categories: cs-AI, cs-CV, cs-LG, cs.CV  
Keyword Score: 20  
Keywords: Data Augmentation, Generative Adversarial Network  
<a type="button" class="btn btn-outline-primary" href="http://arxiv.org/abs/2403.00196v1" target="_blank" >Paper Link</a>
<button type="button" class="btn btn-outline-primary download-pdf" url="https://arxiv.org/pdf/2403.00196v1.pdf" filename="2403.00196v1.pdf">Download PDF</button>

---


**ABSTRACT**  
Advanced Driver Assistance Systems (ADAS) in intelligent vehicles rely on accurate driver perception within the vehicle cabin, often leveraging a combination of sensing modalities. However, these modalities operate at varying rates, posing challenges for real-time, comprehensive driver state monitoring. This paper addresses the issue of missing <b>data</b> <b>due</b> to sensor frame rate mismatches, introducing a <b>generative</b> <b>model</b> <b>approach</b> to create synthetic yet realistic thermal imagery. We propose using conditional <b>generative</b> <b>adversarial</b> <b>networks</b> (cGANs), specifically comparing the pix2pix and CycleGAN architectures. Experimental results demonstrate that pix2pix outperforms CycleGAN, and utilizing multi-view input styles, especially stacked views, enhances the accuracy of thermal image generation. Moreover, the study evaluates the model's generalizability across different subjects, revealing the importance of individualized training for optimal performance. The findings suggest the potential of <b>generative</b> <b>models</b> <b>in</b> addressing missing frames, advancing driver state monitoring for intelligent vehicles, and underscoring the need for continued research in model generalization and customization.

{{</citation>}}


### (42/69 | 90/321) FusionVision: A comprehensive approach of 3D object reconstruction and segmentation from RGB-D cameras using YOLO and fast segment anything (Safouane El Ghazouali et al., 2024)

{{<citation>}}

Safouane El Ghazouali, Youssef Mhirit, Ali Oukhrid, Umberto Michelucci, Hichem Nouira. (2024)  
**FusionVision: A comprehensive approach of 3D object reconstruction and segmentation from RGB-D cameras using YOLO and fast segment anything**
<br/>
<button class="copy-to-clipboard" title="FusionVision: A comprehensive approach of 3D object reconstruction and segmentation from RGB-D cameras using YOLO and fast segment anything" index=90>
  <span class="copy-to-clipboard-item">Copy Title<span>
</button>
<div class="toast toast-copied toast-index-90 align-items-center text-bg-secondary border-0 position-absolute top-0 end-0" role="alert" aria-live="assertive" aria-atomic="true">
  <div class="d-flex">
    <div class="toast-body">
      Copied!
    </div>
  </div>
</div>

---
Primary Category: cs.CV  
Categories: cs-AI, cs-CV, cs.CV  
Keyword Score: 20  
Keywords: Yolo, Object Detection  
<a type="button" class="btn btn-outline-primary" href="http://arxiv.org/abs/2403.00175v1" target="_blank" >Paper Link</a>
<button type="button" class="btn btn-outline-primary download-pdf" url="https://arxiv.org/pdf/2403.00175v1.pdf" filename="2403.00175v1.pdf">Download PDF</button>

---


**ABSTRACT**  
In the realm of computer vision, the integration of advanced techniques into the processing of RGB-D camera inputs poses a significant challenge, given the inherent complexities arising from diverse environmental conditions and varying <b>object</b> <b>appearances.</b> Therefore, this paper introduces FusionVision, an exhaustive pipeline adapted for the robust 3D segmentation of <b>objects</b> <b>in</b> RGB-D imagery. Traditional computer vision systems face limitations in simultaneously capturing precise <b>object</b> <b>boundaries</b> and achieving high-precision <b>object</b> <b>detection</b> on depth map as they are mainly proposed for RGB cameras. To address this challenge, FusionVision adopts an integrated approach by merging state-of-the-art <b>object</b> <b>detection</b> techniques, with advanced instance segmentation methods. The integration of these components enables a holistic (unified analysis of information obtained from both color \textit{RGB} and depth \textit{D} channels) interpretation of RGB-D data, facilitating the extraction of comprehensive and accurate <b>object</b> <b>information.</b> The proposed FusionVision pipeline employs <b>YOLO</b> for identifying <b>objects</b> <b>within</b> the RGB image domain. Subsequently, FastSAM, an innovative semantic segmentation model, is applied to delineate <b>object</b> <b>boundaries,</b> yielding refined segmentation masks. The synergy between these components and their integration into 3D scene understanding ensures a cohesive fusion of <b>object</b> <b>detection</b> and segmentation, enhancing overall precision in 3D <b>object</b> <b>segmentation.</b> The code and pre-trained models are publicly available at https://github.com/safouaneelg/FusionVision/.

{{</citation>}}


### (43/69 | 91/321) Artwork Explanation in Large-scale Vision Language Models (Kazuki Hayashi et al., 2024)

{{<citation>}}

Kazuki Hayashi, Yusuke Sakai, Hidetaka Kamigaito, Katsuhiko Hayashi, Taro Watanabe. (2024)  
**Artwork Explanation in Large-scale Vision Language Models**
<br/>
<button class="copy-to-clipboard" title="Artwork Explanation in Large-scale Vision Language Models" index=91>
  <span class="copy-to-clipboard-item">Copy Title<span>
</button>
<div class="toast toast-copied toast-index-91 align-items-center text-bg-secondary border-0 position-absolute top-0 end-0" role="alert" aria-live="assertive" aria-atomic="true">
  <div class="d-flex">
    <div class="toast-body">
      Copied!
    </div>
  </div>
</div>

---
Primary Category: cs.CV  
Categories: cs-CV, cs.CV  
Keyword Score: 20  
Keywords: Text Generation, Vision-and-Language  
<a type="button" class="btn btn-outline-primary" href="http://arxiv.org/abs/2403.00068v1" target="_blank" >Paper Link</a>
<button type="button" class="btn btn-outline-primary download-pdf" url="https://arxiv.org/pdf/2403.00068v1.pdf" filename="2403.00068v1.pdf">Download PDF</button>

---


**ABSTRACT**  
Large-scale <b>vision-language</b> models (LVLMs) output <b>text</b> <b>from</b> images and instructions, demonstrating advanced capabilities in <b>text</b> <b>generation</b> and comprehension. However, it has not been clarified to what extent LVLMs understand the knowledge necessary for explaining images, the complex relationships between various pieces of knowledge, and how they integrate these understandings into their explanations. To address this issue, we propose a new task: the artwork explanation generation task, along with its evaluation dataset and metric for quantitatively assessing the understanding and utilization of knowledge about artworks. This task is apt for image description based on the premise that LVLMs are expected to have pre-existing knowledge of artworks, which are often subjects of wide recognition and documented information. It consists of two parts: generating explanations from both images and titles of artworks, and generating explanations using only images, thus evaluating the LVLMs' language-based and vision-based knowledge. Alongside, we release a training dataset for LVLMs to learn explanations that incorporate knowledge about artworks. Our findings indicate that LVLMs not only struggle with integrating language and visual information but also exhibit a more pronounced limitation in acquiring knowledge from images alone. The datasets (ExpArt=Explain Artworks) are available at https://huggingface.co/datasets/naist-nlp/ExpArt.

{{</citation>}}


### (44/69 | 92/321) Effective Message Hiding with Order-Preserving Mechanisms (Gao Yu et al., 2024)

{{<citation>}}

Gao Yu, Qiu Xuchong, Ye Zihan. (2024)  
**Effective Message Hiding with Order-Preserving Mechanisms**
<br/>
<button class="copy-to-clipboard" title="Effective Message Hiding with Order-Preserving Mechanisms" index=92>
  <span class="copy-to-clipboard-item">Copy Title<span>
</button>
<div class="toast toast-copied toast-index-92 align-items-center text-bg-secondary border-0 position-absolute top-0 end-0" role="alert" aria-live="assertive" aria-atomic="true">
  <div class="d-flex">
    <div class="toast-body">
      Copied!
    </div>
  </div>
</div>

---
Primary Category: cs.CV  
Categories: cs-CV, cs.CV  
Keyword Score: 20  
Keywords: Convolution, Convolutional Neural Network  
<a type="button" class="btn btn-outline-primary" href="http://arxiv.org/abs/2402.19160v1" target="_blank" >Paper Link</a>
<button type="button" class="btn btn-outline-primary download-pdf" url="https://arxiv.org/pdf/2402.19160v1.pdf" filename="2402.19160v1.pdf">Download PDF</button>

---


**ABSTRACT**  
Message hiding, a technique that conceals secret message bits within a cover image, aims to achieve an optimal balance among message capacity, recovery accuracy, and imperceptibility. While <b>convolutional</b> <b>neural</b> <b>networks</b> have notably improved message capacity and imperceptibility, achieving high recovery accuracy remains challenging. This challenge arises because <b>convolutional</b> <b>operations</b> <b>struggle</b> to preserve the sequential order of message bits and effectively address the discrepancy between these two modalities. To address this, we propose StegaFormer, an innovative MLP-based framework designed to preserve bit order and enable global fusion between modalities. Specifically, StegaFormer incorporates three crucial components: Order-Preserving Message Encoder (OPME), Decoder (OPMD) and Global Message-Image Fusion (GMIF). OPME and OPMD aim to preserve the order of message bits by segmenting the entire sequence into equal-length segments and incorporating sequential information during encoding and decoding. Meanwhile, GMIF employs a cross-modality fusion mechanism to effectively fuse the features from the two uncorrelated modalities. Experimental results on the COCO and DIV2K datasets demonstrate that StegaFormer surpasses existing state-of-the-art methods in terms of recovery accuracy, message capacity, and imperceptibility. We will make our code publicly available.

{{</citation>}}


### (45/69 | 93/321) Trajectory Consistency Distillation (Jianbin Zheng et al., 2024)

{{<citation>}}

Jianbin Zheng, Minghui Hu, Zhongyi Fan, Chaoyue Wang, Changxing Ding, Dacheng Tao, Tat-Jen Cham. (2024)  
**Trajectory Consistency Distillation**
<br/>
<button class="copy-to-clipboard" title="Trajectory Consistency Distillation" index=93>
  <span class="copy-to-clipboard-item">Copy Title<span>
</button>
<div class="toast toast-copied toast-index-93 align-items-center text-bg-secondary border-0 position-absolute top-0 end-0" role="alert" aria-live="assertive" aria-atomic="true">
  <div class="d-flex">
    <div class="toast-body">
      Copied!
    </div>
  </div>
</div>

---
Primary Category: cs.CV  
Categories: cs-CV, cs.CV  
Keyword Score: 20  
Keywords: Knowledge Distillation, Text2image  
<a type="button" class="btn btn-outline-primary" href="http://arxiv.org/abs/2402.19159v1" target="_blank" >Paper Link</a>
<button type="button" class="btn btn-outline-primary download-pdf" url="https://arxiv.org/pdf/2402.19159v1.pdf" filename="2402.19159v1.pdf">Download PDF</button>

---


**ABSTRACT**  
Latent Consistency Model (LCM) extends the Consistency Model to the latent space and leverages the guided consistency <b>distillation</b> technique to achieve impressive performance in accelerating <b>text-to-image</b> synthesis. However, we observed that LCM struggles to generate images with both clarity and detailed intricacy. To address this limitation, we initially delve into and elucidate the underlying causes. Our investigation identifies that the primary issue stems from errors in three distinct areas. Consequently, we introduce Trajectory Consistency <b>Distillation</b> (TCD), which encompasses trajectory consistency function and strategic stochastic sampling. The trajectory consistency function diminishes the <b>distillation</b> errors by broadening the scope of the self-consistency boundary condition and endowing the TCD with the ability to accurately trace the entire trajectory of the Probability Flow ODE. Additionally, strategic stochastic sampling is specifically designed to circumvent the accumulated errors inherent in multi-step consistency sampling, which is meticulously tailored to complement the TCD model. Experiments demonstrate that TCD not only significantly enhances image quality at low NFEs but also yields more detailed results compared to the teacher model at high NFEs.

{{</citation>}}


### (46/69 | 94/321) ProtoP-OD: Explainable Object Detection with Prototypical Parts (Pavlos Rath-Manakidis et al., 2024)

{{<citation>}}

Pavlos Rath-Manakidis, Frederik Strothmann, Tobias Glasmachers, Laurenz Wiskott. (2024)  
**ProtoP-OD: Explainable Object Detection with Prototypical Parts**
<br/>
<button class="copy-to-clipboard" title="ProtoP-OD: Explainable Object Detection with Prototypical Parts" index=94>
  <span class="copy-to-clipboard-item">Copy Title<span>
</button>
<div class="toast toast-copied toast-index-94 align-items-center text-bg-secondary border-0 position-absolute top-0 end-0" role="alert" aria-live="assertive" aria-atomic="true">
  <div class="d-flex">
    <div class="toast-body">
      Copied!
    </div>
  </div>
</div>

---
Primary Category: cs.CV  
Categories: cs-CV, cs-LG, cs.CV  
Keyword Score: 20  
Keywords: Object Detection, Transformer  
<a type="button" class="btn btn-outline-primary" href="http://arxiv.org/abs/2402.19142v1" target="_blank" >Paper Link</a>
<button type="button" class="btn btn-outline-primary download-pdf" url="https://arxiv.org/pdf/2402.19142v1.pdf" filename="2402.19142v1.pdf">Download PDF</button>

---


**ABSTRACT**  
Interpretation and visualization of the behavior of detection <b>transformers</b> tends to highlight the locations in the image that the model attends to, but it provides limited insight into the \emph{semantics} that the model is focusing on. This paper introduces an extension to detection <b>transformers</b> that constructs prototypical local features and uses them in <b>object</b> <b>detection.</b> These custom features, which we call prototypical parts, are designed to be mutually exclusive and align with the classifications of the model. The proposed extension consists of a bottleneck module, the prototype neck, that computes a discretized representation of prototype activations and a new loss term that matches prototypes to <b>object</b> <b>classes.</b> This setup leads to interpretable representations in the prototype neck, allowing visual inspection of the image content perceived by the model and a better understanding of the model's reliability. We show experimentally that our method incurs only a limited performance penalty, and we provide examples that demonstrate the quality of the explanations provided by our method, which we argue outweighs the performance penalty.

{{</citation>}}


### (47/69 | 95/321) Leveraging Representations from Intermediate Encoder-blocks for Synthetic Image Detection (Christos Koutlis et al., 2024)

{{<citation>}}

Christos Koutlis, Symeon Papadopoulos. (2024)  
**Leveraging Representations from Intermediate Encoder-blocks for Synthetic Image Detection**
<br/>
<button class="copy-to-clipboard" title="Leveraging Representations from Intermediate Encoder-blocks for Synthetic Image Detection" index=95>
  <span class="copy-to-clipboard-item">Copy Title<span>
</button>
<div class="toast toast-copied toast-index-95 align-items-center text-bg-secondary border-0 position-absolute top-0 end-0" role="alert" aria-live="assertive" aria-atomic="true">
  <div class="d-flex">
    <div class="toast-body">
      Copied!
    </div>
  </div>
</div>

---
Primary Category: cs.CV  
Categories: cs-CV, cs.CV  
Keyword Score: 20  
Keywords: Foundation Model, Transformer  
<a type="button" class="btn btn-outline-primary" href="http://arxiv.org/abs/2402.19091v1" target="_blank" >Paper Link</a>
<button type="button" class="btn btn-outline-primary download-pdf" url="https://arxiv.org/pdf/2402.19091v1.pdf" filename="2402.19091v1.pdf">Download PDF</button>

---


**ABSTRACT**  
The recently developed and publicly available synthetic image generation methods and services make it possible to create extremely realistic imagery on demand, raising great risks for the integrity and safety of online information. State-of-the-art Synthetic Image Detection (SID) research has led to strong evidence on the advantages of feature extraction from <b>foundation</b> <b>models.</b> However, such extracted features mostly encapsulate high-level visual semantics instead of fine-grained details, which are more important for the SID task. On the contrary, shallow layers encode low-level visual information. In this work, we leverage the image representations extracted by intermediate <b>Transformer</b> blocks of CLIP's image-encoder via a lightweight network that maps them to a learnable forgery-aware vector space capable of generalizing exceptionally well. We also employ a trainable module to incorporate the importance of each <b>Transformer</b> block to the final prediction. Our method is compared against the state-of-the-art by evaluating it on 20 test datasets and exhibits an average +10.6% absolute performance improvement. Notably, the best performing models require just a single epoch for training (~8 minutes). Code available at https://github.com/mever-team/rine.

{{</citation>}}


### (48/69 | 96/321) Atmospheric Turbulence Removal with Video Sequence Deep Visual Priors (P. Hill et al., 2024)

{{<citation>}}

P. Hill, N. Anantrasirichai, A. Achim, D. R. Bull. (2024)  
**Atmospheric Turbulence Removal with Video Sequence Deep Visual Priors**
<br/>
<button class="copy-to-clipboard" title="Atmospheric Turbulence Removal with Video Sequence Deep Visual Priors" index=96>
  <span class="copy-to-clipboard-item">Copy Title<span>
</button>
<div class="toast toast-copied toast-index-96 align-items-center text-bg-secondary border-0 position-absolute top-0 end-0" role="alert" aria-live="assertive" aria-atomic="true">
  <div class="d-flex">
    <div class="toast-body">
      Copied!
    </div>
  </div>
</div>

---
Primary Category: cs.CV  
Categories: cs-AI, cs-CV, cs.CV, eess-IV  
Keyword Score: 20  
Keywords: Self-supervised Learning, Self-supervised Learning  
<a type="button" class="btn btn-outline-primary" href="http://arxiv.org/abs/2402.19041v1" target="_blank" >Paper Link</a>
<button type="button" class="btn btn-outline-primary download-pdf" url="https://arxiv.org/pdf/2402.19041v1.pdf" filename="2402.19041v1.pdf">Download PDF</button>

---


**ABSTRACT**  
Atmospheric turbulence poses a challenge for the interpretation and visual perception of visual imagery due to its distortion effects. Model-based approaches have been used to address this, but such methods often suffer from artefacts associated with moving content. Conversely, deep learning based methods are dependent on large and diverse datasets that may not effectively represent any specific content. In this paper, we address these problems with a <b>self-supervised</b> <b>learning</b> method that does not require ground truth. The proposed method is not dependent on any dataset outside of the single data sequence being processed but is also able to improve the quality of any input raw sequences or pre-processed sequences. Specifically, our method is based on an accelerated Deep Image Prior (DIP), but integrates temporal information using pixel shuffling and a temporal sliding window. This efficiently learns spatio-temporal priors leading to a system that effectively mitigates atmospheric turbulence distortions. The experiments show that our method improves visual quality results qualitatively and quantitatively.

{{</citation>}}


### (49/69 | 97/321) Progressive Contrastive Learning with Multi-Prototype for Unsupervised Visible-Infrared Person Re-identification (Jiangming Shi et al., 2024)

{{<citation>}}

Jiangming Shi, Xiangbo Yin, Yaoxing Wang, Xiaofeng Liu, Yuan Xie, Yanyun Qu. (2024)  
**Progressive Contrastive Learning with Multi-Prototype for Unsupervised Visible-Infrared Person Re-identification**
<br/>
<button class="copy-to-clipboard" title="Progressive Contrastive Learning with Multi-Prototype for Unsupervised Visible-Infrared Person Re-identification" index=97>
  <span class="copy-to-clipboard-item">Copy Title<span>
</button>
<div class="toast toast-copied toast-index-97 align-items-center text-bg-secondary border-0 position-absolute top-0 end-0" role="alert" aria-live="assertive" aria-atomic="true">
  <div class="d-flex">
    <div class="toast-body">
      Copied!
    </div>
  </div>
</div>

---
Primary Category: cs.CV  
Categories: cs-CV, cs.CV  
Keyword Score: 20  
Keywords: Contrastive Learning, Unsupervised Learning  
<a type="button" class="btn btn-outline-primary" href="http://arxiv.org/abs/2402.19026v1" target="_blank" >Paper Link</a>
<button type="button" class="btn btn-outline-primary download-pdf" url="https://arxiv.org/pdf/2402.19026v1.pdf" filename="2402.19026v1.pdf">Download PDF</button>

---


**ABSTRACT**  
<b>Unsupervised</b> visible-infrared person re-identification (USVI-ReID) aims to match specified people in infrared images to visible images without annotation, and vice versa. USVI-ReID is a challenging yet under-explored task. Most existing methods address the USVI-ReID problem using cluster-based <b>contrastive</b> <b>learning,</b> which simply employs the cluster center as a representation of a person. However, the cluster center primarily focuses on shared information, overlooking disparity. To address the problem, we propose a Progressive <b>Contrastive</b> <b>Learning</b> with Multi-Prototype (PCLMP) method for USVI-ReID. In brief, we first generate the hard prototype by selecting the sample with the maximum distance from the cluster center. This hard prototype is used in the <b>contrastive</b> <b>loss</b> to emphasize disparity. Additionally, instead of rigidly aligning query images to a specific prototype, we generate the dynamic prototype by randomly picking samples within a cluster. This dynamic prototype is used to retain the natural variety of features while reducing instability in the simultaneous learning of both common and disparate information. Finally, we introduce a progressive learning strategy to gradually shift the model's attention towards hard samples, avoiding cluster deterioration. Extensive experiments conducted on the publicly available SYSU-MM01 and RegDB datasets validate the effectiveness of the proposed method. PCLMP outperforms the existing state-of-the-art method with an average mAP improvement of 3.9%. The source codes will be released.

{{</citation>}}


### (50/69 | 98/321) ViewFusion: Towards Multi-View Consistency via Interpolated Denoising (Xianghui Yang et al., 2024)

{{<citation>}}

Xianghui Yang, Yan Zuo, Sameera Ramasinghe, Loris Bazzani, Gil Avraham, Anton van den Hengel. (2024)  
**ViewFusion: Towards Multi-View Consistency via Interpolated Denoising**
<br/>
<button class="copy-to-clipboard" title="ViewFusion: Towards Multi-View Consistency via Interpolated Denoising" index=98>
  <span class="copy-to-clipboard-item">Copy Title<span>
</button>
<div class="toast toast-copied toast-index-98 align-items-center text-bg-secondary border-0 position-absolute top-0 end-0" role="alert" aria-live="assertive" aria-atomic="true">
  <div class="d-flex">
    <div class="toast-body">
      Copied!
    </div>
  </div>
</div>

---
Primary Category: cs.CV  
Categories: cs-CV, cs.CV  
Keyword Score: 20  
Keywords: Diffusion Model, Fine-tuning  
<a type="button" class="btn btn-outline-primary" href="http://arxiv.org/abs/2402.18842v1" target="_blank" >Paper Link</a>
<button type="button" class="btn btn-outline-primary download-pdf" url="https://arxiv.org/pdf/2402.18842v1.pdf" filename="2402.18842v1.pdf">Download PDF</button>

---


**ABSTRACT**  
Novel-view synthesis through <b>diffusion</b> <b>models</b> has demonstrated remarkable potential for generating diverse and high-quality images. Yet, the independent process of image generation in these prevailing methods leads to challenges in maintaining multiple-view consistency. To address this, we introduce ViewFusion, a novel, training-free algorithm that can be seamlessly integrated into existing pre-trained <b>diffusion</b> <b>models.</b> Our approach adopts an auto-regressive method that implicitly leverages previously generated views as context for the next view generation, ensuring robust multi-view consistency during the novel-view generation process. Through a <b>diffusion</b> <b>process</b> that fuses known-view information via interpolated denoising, our framework successfully extends single-view conditioned models to work in multiple-view conditional settings without any additional <b>fine-tuning.</b> Extensive experimental results demonstrate the effectiveness of ViewFusion in generating consistent and detailed novel views.

{{</citation>}}


### (51/69 | 99/321) Suppress and Rebalance: Towards Generalized Multi-Modal Face Anti-Spoofing (Xun Lin et al., 2024)

{{<citation>}}

Xun Lin, Shuai Wang, Rizhao Cai, Yizhong Liu, Ying Fu, Zitong Yu, Wenzhong Tang, Alex Kot. (2024)  
**Suppress and Rebalance: Towards Generalized Multi-Modal Face Anti-Spoofing**
<br/>
<button class="copy-to-clipboard" title="Suppress and Rebalance: Towards Generalized Multi-Modal Face Anti-Spoofing" index=99>
  <span class="copy-to-clipboard-item">Copy Title<span>
</button>
<div class="toast toast-copied toast-index-99 align-items-center text-bg-secondary border-0 position-absolute top-0 end-0" role="alert" aria-live="assertive" aria-atomic="true">
  <div class="d-flex">
    <div class="toast-body">
      Copied!
    </div>
  </div>
</div>

---
Primary Category: cs.CV  
Categories: cs-CV, cs.CV  
Keyword Score: 16  
Keywords: Face Recognition, Benchmarking, Multi-modal  
<a type="button" class="btn btn-outline-primary" href="http://arxiv.org/abs/2402.19298v2" target="_blank" >Paper Link</a>
<button type="button" class="btn btn-outline-primary download-pdf" url="https://arxiv.org/pdf/2402.19298v2.pdf" filename="2402.19298v2.pdf">Download PDF</button>

---


**ABSTRACT**  
<b>Face</b> <b>Anti-Spoofing</b> (FAS) is crucial for securing <b>face</b> <b>recognition</b> systems against presentation attacks. With advancements in sensor manufacture and <b>multi-modal</b> learning techniques, many <b>multi-modal</b> FAS approaches have emerged. However, they <b>face</b> <b>challenges</b> in generalizing to unseen attacks and deployment conditions. These challenges arise from (1) modality unreliability, where some modality sensors like depth and infrared undergo significant domain shifts in varying environments, leading to the spread of unreliable information during cross-modal feature fusion, and (2) modality imbalance, where training overly relies on a dominant modality hinders the convergence of others, reducing effectiveness against attack types that are indistinguishable sorely using the dominant modality. To address modality unreliability, we propose the Uncertainty-Guided Cross-Adapter (U-Adapter) to recognize unreliably detected regions within each modality and suppress the impact of unreliable regions on other modalities. For modality imbalance, we propose a Rebalanced Modality Gradient Modulation (ReGrad) strategy to rebalance the convergence speed of all modalities by adaptively adjusting their gradients. Besides, we provide the first large-scale <b>benchmark</b> for evaluating <b>multi-modal</b> FAS performance under domain generalization scenarios. Extensive experiments demonstrate that our method outperforms state-of-the-art methods. Source code and protocols will be released on https://github.com/OMGGGGG/mmdg.

{{</citation>}}


### (52/69 | 100/321) VEnvision3D: A Synthetic Perception Dataset for 3D Multi-Task Model Research (Jiahao Zhou et al., 2024)

{{<citation>}}

Jiahao Zhou, Chen Long, Yue Xie, Jialiang Wang, Boheng Li, Haiping Wang, Zhe Chen, Zhen Dong. (2024)  
**VEnvision3D: A Synthetic Perception Dataset for 3D Multi-Task Model Research**
<br/>
<button class="copy-to-clipboard" title="VEnvision3D: A Synthetic Perception Dataset for 3D Multi-Task Model Research" index=100>
  <span class="copy-to-clipboard-item">Copy Title<span>
</button>
<div class="toast toast-copied toast-index-100 align-items-center text-bg-secondary border-0 position-absolute top-0 end-0" role="alert" aria-live="assertive" aria-atomic="true">
  <div class="d-flex">
    <div class="toast-body">
      Copied!
    </div>
  </div>
</div>

---
Primary Category: cs.CV  
Categories: cs-CV, cs.CV  
Keyword Score: 13  
Keywords: Benchmarking, Foundation Model  
<a type="button" class="btn btn-outline-primary" href="http://arxiv.org/abs/2402.19059v2" target="_blank" >Paper Link</a>
<button type="button" class="btn btn-outline-primary download-pdf" url="https://arxiv.org/pdf/2402.19059v2.pdf" filename="2402.19059v2.pdf">Download PDF</button>

---


**ABSTRACT**  
Developing a unified multi-task <b>foundation</b> <b>model</b> has become a critical challenge in computer vision research. In the current field of 3D computer vision, most datasets only focus on single task, which complicates the concurrent training requirements of various downstream tasks. In this paper, we introduce VEnvision3D, a large 3D synthetic perception dataset for multi-task learning, including depth completion, segmentation, upsampling, place recognition, and 3D reconstruction. Since the data for each task is collected in the same environmental domain, sub-tasks are inherently aligned in terms of the utilized data. Therefore, such a unique attribute can assist in exploring the potential for the multi-task model and even the <b>foundation</b> <b>model</b> without separate training methods. Meanwhile, capitalizing on the advantage of virtual environments being freely editable, we implement some novel settings such as simulating temporal changes in the environment and sampling point clouds on model surfaces. These characteristics enable us to present several new <b>benchmarks.</b> We also perform extensive studies on multi-task end-to-end models, revealing new observations, challenges, and opportunities for future research. Our dataset and code will be open-sourced upon acceptance.

{{</citation>}}


### (53/69 | 101/321) DistriFusion: Distributed Parallel Inference for High-Resolution Diffusion Models (Muyang Li et al., 2024)

{{<citation>}}

Muyang Li, Tianle Cai, Jiaxin Cao, Qinsheng Zhang, Han Cai, Junjie Bai, Yangqing Jia, Ming-Yu Liu, Kai Li, Song Han. (2024)  
**DistriFusion: Distributed Parallel Inference for High-Resolution Diffusion Models**
<br/>
<button class="copy-to-clipboard" title="DistriFusion: Distributed Parallel Inference for High-Resolution Diffusion Models" index=101>
  <span class="copy-to-clipboard-item">Copy Title<span>
</button>
<div class="toast toast-copied toast-index-101 align-items-center text-bg-secondary border-0 position-absolute top-0 end-0" role="alert" aria-live="assertive" aria-atomic="true">
  <div class="d-flex">
    <div class="toast-body">
      Copied!
    </div>
  </div>
</div>

---
Primary Category: cs.CV  
Categories: cs-CV, cs.CV  
Keyword Score: 10  
Keywords: Diffusion Model  
<a type="button" class="btn btn-outline-primary" href="http://arxiv.org/abs/2402.19481v1" target="_blank" >Paper Link</a>
<button type="button" class="btn btn-outline-primary download-pdf" url="https://arxiv.org/pdf/2402.19481v1.pdf" filename="2402.19481v1.pdf">Download PDF</button>

---


**ABSTRACT**  
<b>Diffusion</b> <b>models</b> have achieved great success in synthesizing high-quality images. However, generating high-resolution images with <b>diffusion</b> <b>models</b> is still challenging due to the enormous computational costs, resulting in a prohibitive latency for interactive applications. In this paper, we propose DistriFusion to tackle this problem by leveraging parallelism across multiple GPUs. Our method splits the model input into multiple patches and assigns each patch to a GPU. However, na\"{\i}vely implementing such an algorithm breaks the interaction between patches and loses fidelity, while incorporating such an interaction will incur tremendous communication overhead. To overcome this dilemma, we observe the high similarity between the input from adjacent <b>diffusion</b> <b>steps</b> and propose displaced patch parallelism, which takes advantage of the sequential nature of the <b>diffusion</b> <b>process</b> by reusing the pre-computed feature maps from the previous timestep to provide context for the current step. Therefore, our method supports asynchronous communication, which can be pipelined by computation. Extensive experiments show that our method can be applied to recent Stable <b>Diffusion</b> <b>XL</b> with no quality degradation and achieve up to a 6.1$\times$ speedup on eight NVIDIA A100s compared to one. Our code is publicly available at https://github.com/mit-han-lab/distrifuser.

{{</citation>}}


### (54/69 | 102/321) HyenaPixel: Global Image Context with Convolutions (Julian Spravil et al., 2024)

{{<citation>}}

Julian Spravil, Sebastian Houben, Sven Behnke. (2024)  
**HyenaPixel: Global Image Context with Convolutions**
<br/>
<button class="copy-to-clipboard" title="HyenaPixel: Global Image Context with Convolutions" index=102>
  <span class="copy-to-clipboard-item">Copy Title<span>
</button>
<div class="toast toast-copied toast-index-102 align-items-center text-bg-secondary border-0 position-absolute top-0 end-0" role="alert" aria-live="assertive" aria-atomic="true">
  <div class="d-flex">
    <div class="toast-body">
      Copied!
    </div>
  </div>
</div>

---
Primary Category: cs.CV  
Categories: cs-CV, cs.CV  
Keyword Score: 10  
Keywords: Convolution  
<a type="button" class="btn btn-outline-primary" href="http://arxiv.org/abs/2402.19305v1" target="_blank" >Paper Link</a>
<button type="button" class="btn btn-outline-primary download-pdf" url="https://arxiv.org/pdf/2402.19305v1.pdf" filename="2402.19305v1.pdf">Download PDF</button>

---


**ABSTRACT**  
In vision tasks, a larger effective receptive field (ERF) is associated with better performance. While attention natively supports global context, <b>convolution</b> requires multiple stacked layers and a hierarchical structure for large context. In this work, we extend Hyena, a <b>convolution-based</b> attention replacement, from causal sequences to the non-causal two-dimensional image space. We scale the Hyena <b>convolution</b> kernels beyond the feature map size up to 191$\times$191 to maximize the ERF while maintaining sub-quadratic complexity in the number of pixels. We integrate our two-dimensional Hyena, HyenaPixel, and bidirectional Hyena into the MetaFormer framework. For image categorization, HyenaPixel and bidirectional Hyena achieve a competitive ImageNet-1k top-1 accuracy of 83.0% and 83.5%, respectively, while outperforming other large-kernel networks. Combining HyenaPixel with attention further increases accuracy to 83.6%. We attribute the success of attention to the lack of spatial bias in later stages and support this finding with bidirectional Hyena.

{{</citation>}}


### (55/69 | 103/321) Continuous Sign Language Recognition Based on Motor attention mechanism and frame-level Self-distillation (Qidan Zhu et al., 2024)

{{<citation>}}

Qidan Zhu, Jing Li, Fei Yuan, Quan Gan. (2024)  
**Continuous Sign Language Recognition Based on Motor attention mechanism and frame-level Self-distillation**
<br/>
<button class="copy-to-clipboard" title="Continuous Sign Language Recognition Based on Motor attention mechanism and frame-level Self-distillation" index=103>
  <span class="copy-to-clipboard-item">Copy Title<span>
</button>
<div class="toast toast-copied toast-index-103 align-items-center text-bg-secondary border-0 position-absolute top-0 end-0" role="alert" aria-live="assertive" aria-atomic="true">
  <div class="d-flex">
    <div class="toast-body">
      Copied!
    </div>
  </div>
</div>

---
Primary Category: cs.CV  
Categories: cs-CV, cs.CV  
Keyword Score: 10  
Keywords: Self-Distillation  
<a type="button" class="btn btn-outline-primary" href="http://arxiv.org/abs/2402.19118v1" target="_blank" >Paper Link</a>
<button type="button" class="btn btn-outline-primary download-pdf" url="https://arxiv.org/pdf/2402.19118v1.pdf" filename="2402.19118v1.pdf">Download PDF</button>

---


**ABSTRACT**  
Changes in facial expression, head movement, body movement and gesture movement are remarkable cues in sign language recognition, and most of the current continuous sign language recognition(CSLR) research methods mainly focus on static images in video sequences at the frame-level feature extraction stage, while ignoring the dynamic changes in the images. In this paper, we propose a novel motor attention mechanism to capture the distorted changes in local motion regions during sign language expression, and obtain a dynamic representation of image changes. And for the first time, we apply the <b>self-distillation</b> method to frame-level feature extraction for continuous sign language, which improves the feature expression without increasing the computational resources by self-distilling the features of adjacent stages and using the higher-order features as teachers to guide the lower-order features. The combination of the two constitutes our proposed holistic model of CSLR Based on motor attention mechanism and frame-level <b>Self-Distillation</b> (MAM-FSD), which improves the inference ability and robustness of the model. We conduct experiments on three publicly available datasets, and the experimental results show that our proposed method can effectively extract the sign language motion information in videos, improve the accuracy of CSLR and reach the state-of-the-art level.

{{</citation>}}


### (56/69 | 104/321) DOZE: A Dataset for Open-Vocabulary Zero-Shot Object Navigation in Dynamic Environments (Ji Ma et al., 2024)

{{<citation>}}

Ji Ma, Hongming Dai, Yao Mu, Pengying Wu, Hao Wang, Xiaowei Chi, Yang Fei, Shanghang Zhang, Chang Liu. (2024)  
**DOZE: A Dataset for Open-Vocabulary Zero-Shot Object Navigation in Dynamic Environments**
<br/>
<button class="copy-to-clipboard" title="DOZE: A Dataset for Open-Vocabulary Zero-Shot Object Navigation in Dynamic Environments" index=104>
  <span class="copy-to-clipboard-item">Copy Title<span>
</button>
<div class="toast toast-copied toast-index-104 align-items-center text-bg-secondary border-0 position-absolute top-0 end-0" role="alert" aria-live="assertive" aria-atomic="true">
  <div class="d-flex">
    <div class="toast-body">
      Copied!
    </div>
  </div>
</div>

---
Primary Category: cs.CV  
Categories: cs-CV, cs-RO, cs.CV  
Keyword Score: 10  
Keywords: Zero-shot  
<a type="button" class="btn btn-outline-primary" href="http://arxiv.org/abs/2402.19007v1" target="_blank" >Paper Link</a>
<button type="button" class="btn btn-outline-primary download-pdf" url="https://arxiv.org/pdf/2402.19007v1.pdf" filename="2402.19007v1.pdf">Download PDF</button>

---


**ABSTRACT**  
<b>Zero-Shot</b> Object Navigation (ZSON) requires agents to autonomously locate and approach unseen objects in unfamiliar environments and has emerged as a particularly challenging task within the domain of Embodied AI. Existing datasets for developing ZSON algorithms lack consideration of dynamic obstacles, object attribute diversity, and scene texts, thus exhibiting noticeable discrepancy from real-world situations. To address these issues, we propose a Dataset for Open-Vocabulary <b>Zero-Shot</b> Object Navigation in Dynamic Environments (DOZE) that comprises ten high-fidelity 3D scenes with over 18k tasks, aiming to mimic complex, dynamic real-world scenarios. Specifically, DOZE scenes feature multiple moving humanoid obstacles, a wide array of open-vocabulary objects, diverse distinct-attribute objects, and valuable textual hints. Besides, different from existing datasets that only provide collision checking between the agent and static obstacles, we enhance DOZE by integrating capabilities for detecting collisions between the agent and moving obstacles. This novel functionality enables evaluation of the agents' collision avoidance abilities in dynamic environments. We test four representative ZSON methods on DOZE, revealing substantial room for improvement in existing approaches concerning navigation efficiency, safety, and object recognition accuracy. Our dataset could be found at https://DOZE-Dataset.github.io/.

{{</citation>}}


### (57/69 | 105/321) PrivatEyes: Appearance-based Gaze Estimation Using Federated Secure Multi-Party Computation (Mayar Elfares et al., 2024)

{{<citation>}}

Mayar Elfares, Pascal Reisert, Zhiming Hu, Wenwu Tang, Ralf Küsters, Andreas Bulling. (2024)  
**PrivatEyes: Appearance-based Gaze Estimation Using Federated Secure Multi-Party Computation**
<br/>
<button class="copy-to-clipboard" title="PrivatEyes: Appearance-based Gaze Estimation Using Federated Secure Multi-Party Computation" index=105>
  <span class="copy-to-clipboard-item">Copy Title<span>
</button>
<div class="toast toast-copied toast-index-105 align-items-center text-bg-secondary border-0 position-absolute top-0 end-0" role="alert" aria-live="assertive" aria-atomic="true">
  <div class="d-flex">
    <div class="toast-body">
      Copied!
    </div>
  </div>
</div>

---
Primary Category: cs.CV  
Categories: cs-CV, cs-HC, cs.CV  
Keyword Score: 10  
Keywords: Federated Learning  
<a type="button" class="btn btn-outline-primary" href="http://arxiv.org/abs/2402.18970v1" target="_blank" >Paper Link</a>
<button type="button" class="btn btn-outline-primary download-pdf" url="https://arxiv.org/pdf/2402.18970v1.pdf" filename="2402.18970v1.pdf">Download PDF</button>

---


**ABSTRACT**  
Latest gaze estimation methods require large-scale training data but their collection and exchange pose significant privacy risks. We propose PrivatEyes - the first privacy-enhancing training approach for appearance-based gaze estimation based on <b>federated</b> <b>learning</b> (FL) and secure multi-party computation (MPC). PrivatEyes enables training gaze estimators on multiple local datasets across different users and server-based secure aggregation of the individual estimators' updates. PrivatEyes guarantees that individual gaze data remains private even if a majority of the aggregating servers is malicious. We also introduce a new data leakage attack DualView that shows that PrivatEyes limits the leakage of private training data more effectively than previous approaches. Evaluations on the MPIIGaze, MPIIFaceGaze, GazeCapture, and NVGaze datasets further show that the improved privacy does not lead to a lower gaze estimation accuracy or substantially higher computational costs - both of which are on par with its non-secure counterparts.

{{</citation>}}


### (58/69 | 106/321) Towards Out-of-Distribution Detection for breast cancer classification in Point-of-Care Ultrasound Imaging (Jennie Karlsson et al., 2024)

{{<citation>}}

Jennie Karlsson, Marisa Wodrich, Niels Christian Overgaard, Freja Sahlin, Kristina Lång, Anders Heyden, Ida Arvidsson. (2024)  
**Towards Out-of-Distribution Detection for breast cancer classification in Point-of-Care Ultrasound Imaging**
<br/>
<button class="copy-to-clipboard" title="Towards Out-of-Distribution Detection for breast cancer classification in Point-of-Care Ultrasound Imaging" index=106>
  <span class="copy-to-clipboard-item">Copy Title<span>
</button>
<div class="toast toast-copied toast-index-106 align-items-center text-bg-secondary border-0 position-absolute top-0 end-0" role="alert" aria-live="assertive" aria-atomic="true">
  <div class="d-flex">
    <div class="toast-body">
      Copied!
    </div>
  </div>
</div>

---
Primary Category: cs.CV  
Categories: cs-AI, cs-CV, cs.CV  
Keyword Score: 10  
Keywords: Out-of-distribution  
<a type="button" class="btn btn-outline-primary" href="http://arxiv.org/abs/2402.18960v1" target="_blank" >Paper Link</a>
<button type="button" class="btn btn-outline-primary download-pdf" url="https://arxiv.org/pdf/2402.18960v1.pdf" filename="2402.18960v1.pdf">Download PDF</button>

---


**ABSTRACT**  
Deep learning has shown to have great potential in medical applications. In critical domains as such, it is of high interest to have trustworthy algorithms which are able to tell when reliable assessments cannot be guaranteed. Detecting <b>out-of-distribution</b> (OOD) samples is a crucial step towards building a safe classifier. Following a previous study, showing that it is possible to classify breast cancer in point-of-care ultrasound images, this study investigates OOD detection using three different methods: softmax, energy score and deep ensembles. All methods are tested on three different OOD data sets. The results show that the energy score method outperforms the softmax method, performing well on two of the data sets. The ensemble method is the most robust, performing the best at detecting OOD samples for all three OOD data sets.

{{</citation>}}


### (59/69 | 107/321) Spectral Meets Spatial: Harmonising 3D Shape Matching and Interpolation (Dongliang Cao et al., 2024)

{{<citation>}}

Dongliang Cao, Marvin Eisenberger, Nafie El Amrani, Daniel Cremers, Florian Bernard. (2024)  
**Spectral Meets Spatial: Harmonising 3D Shape Matching and Interpolation**
<br/>
<button class="copy-to-clipboard" title="Spectral Meets Spatial: Harmonising 3D Shape Matching and Interpolation" index=107>
  <span class="copy-to-clipboard-item">Copy Title<span>
</button>
<div class="toast toast-copied toast-index-107 align-items-center text-bg-secondary border-0 position-absolute top-0 end-0" role="alert" aria-live="assertive" aria-atomic="true">
  <div class="d-flex">
    <div class="toast-body">
      Copied!
    </div>
  </div>
</div>

---
Primary Category: cs.CV  
Categories: cs-AI, cs-CG, cs-CV, cs.CV  
Keyword Score: 10  
Keywords: Supervised Learning  
<a type="button" class="btn btn-outline-primary" href="http://arxiv.org/abs/2402.18920v2" target="_blank" >Paper Link</a>
<button type="button" class="btn btn-outline-primary download-pdf" url="https://arxiv.org/pdf/2402.18920v2.pdf" filename="2402.18920v2.pdf">Download PDF</button>

---


**ABSTRACT**  
Although 3D shape matching and interpolation are highly interrelated, they are often studied separately and applied sequentially to relate different 3D shapes, thus resulting in sub-optimal performance. In this work we present a unified framework to predict both point-wise correspondences and shape interpolation between 3D shapes. To this end, we combine the deep functional map framework with classical surface deformation models to map shapes in both spectral and spatial domains. On the one hand, by incorporating spatial maps, our method obtains more accurate and smooth point-wise correspondences compared to previous functional map methods for shape matching. On the other hand, by introducing spectral maps, our method gets rid of commonly used but computationally expensive geodesic distance constraints that are only valid for near-isometric shape deformations. Furthermore, we propose a novel test-time adaptation scheme to capture both pose-dominant and shape-dominant deformations. Using different challenging datasets, we demonstrate that our method outperforms previous state-of-the-art methods for both shape matching and interpolation, even compared to <b>supervised</b> approaches.

{{</citation>}}


### (60/69 | 108/321) Enhancing Steganographic Text Extraction: Evaluating the Impact of NLP Models on Accuracy and Semantic Coherence (Mingyang Li et al., 2024)

{{<citation>}}

Mingyang Li, Maoqin Yuan, Luyao Li, Han Pengsihua. (2024)  
**Enhancing Steganographic Text Extraction: Evaluating the Impact of NLP Models on Accuracy and Semantic Coherence**
<br/>
<button class="copy-to-clipboard" title="Enhancing Steganographic Text Extraction: Evaluating the Impact of NLP Models on Accuracy and Semantic Coherence" index=108>
  <span class="copy-to-clipboard-item">Copy Title<span>
</button>
<div class="toast toast-copied toast-index-108 align-items-center text-bg-secondary border-0 position-absolute top-0 end-0" role="alert" aria-live="assertive" aria-atomic="true">
  <div class="d-flex">
    <div class="toast-body">
      Copied!
    </div>
  </div>
</div>

---
Primary Category: cs.CV  
Categories: cs-AI, cs-CL, cs-CV, cs.CV  
Keyword Score: 10  
Keywords: Information Retrieval  
<a type="button" class="btn btn-outline-primary" href="http://arxiv.org/abs/2402.18849v1" target="_blank" >Paper Link</a>
<button type="button" class="btn btn-outline-primary download-pdf" url="https://arxiv.org/pdf/2402.18849v1.pdf" filename="2402.18849v1.pdf">Download PDF</button>

---


**ABSTRACT**  
This study discusses a new method combining image steganography technology with Natural Language Processing (NLP) large models, aimed at improving the accuracy and robustness of extracting steganographic text. Traditional Least Significant Bit (LSB) steganography techniques face challenges in accuracy and robustness of <b>information</b> <b>extraction</b> when dealing with complex character encoding, such as Chinese characters. To address this issue, this study proposes an innovative LSB-NLP hybrid framework. This framework integrates the advanced capabilities of NLP large models, such as error detection, correction, and semantic consistency analysis, as well as <b>information</b> <b>reconstruction</b> techniques, thereby significantly enhancing the robustness of steganographic text extraction. Experimental results show that the LSB-NLP hybrid framework excels in improving the extraction accuracy of steganographic text, especially in handling Chinese characters. The findings of this study not only confirm the effectiveness of combining image steganography technology and NLP large models but also propose new ideas for research and application in the field of <b>information</b> <b>hiding.</b> The successful implementation of this interdisciplinary approach demonstrates the great potential of integrating image steganography technology with natural language processing technology in solving complex <b>information</b> <b>processing</b> problems.

{{</citation>}}


### (61/69 | 109/321) The 6th Affective Behavior Analysis in-the-wild (ABAW) Competition (Dimitrios Kollias et al., 2024)

{{<citation>}}

Dimitrios Kollias, Panagiotis Tzirakis, Alan Cowen, Stefanos Zafeiriou, Chunchang Shao, Guanyu Hu. (2024)  
**The 6th Affective Behavior Analysis in-the-wild (ABAW) Competition**
<br/>
<button class="copy-to-clipboard" title="The 6th Affective Behavior Analysis in-the-wild (ABAW) Competition" index=109>
  <span class="copy-to-clipboard-item">Copy Title<span>
</button>
<div class="toast toast-copied toast-index-109 align-items-center text-bg-secondary border-0 position-absolute top-0 end-0" role="alert" aria-live="assertive" aria-atomic="true">
  <div class="d-flex">
    <div class="toast-body">
      Copied!
    </div>
  </div>
</div>

---
Primary Category: cs.CV  
Categories: cs-CV, cs.CV  
Keyword Score: 6  
Keywords: Benchmarking, Benchmarking  
<a type="button" class="btn btn-outline-primary" href="http://arxiv.org/abs/2402.19344v1" target="_blank" >Paper Link</a>
<button type="button" class="btn btn-outline-primary download-pdf" url="https://arxiv.org/pdf/2402.19344v1.pdf" filename="2402.19344v1.pdf">Download PDF</button>

---


**ABSTRACT**  
This paper describes the 6th Affective Behavior Analysis in-the-wild (ABAW) Competition, which is part of the respective Workshop held in conjunction with IEEE CVPR 2024. The 6th ABAW Competition addresses contemporary challenges in understanding human emotions and behaviors, crucial for the development of human-centered technologies. In more detail, the Competition focuses on affect related <b>benchmarking</b> tasks and comprises of five sub-challenges: i) Valence-Arousal Estimation (the target is to estimate two continuous affect dimensions, valence and arousal), ii) Expression Recognition (the target is to recognise between the mutually exclusive classes of the 7 basic expressions and 'other'), iii) Action Unit Detection (the target is to detect 12 action units), iv) Compound Expression Recognition (the target is to recognise between the 7 mutually exclusive compound expression classes), and v) Emotional Mimicry Intensity Estimation (the target is to estimate six continuous emotion dimensions). In the paper, we present these Challenges, describe their respective datasets and challenge protocols (we outline the evaluation metrics) and present the baseline systems as well as their obtained performance. More information for the Competition can be found in: \url{https://affective-behavior-analysis-in-the-wild.github.io/6th}.

{{</citation>}}


### (62/69 | 110/321) WWW: A Unified Framework for Explaining What, Where and Why of Neural Networks by Interpretation of Neuron Concepts (Yong Hyun Ahn et al., 2024)

{{<citation>}}

Yong Hyun Ahn, Hyeon Bae Kim, Seong Tae Kim. (2024)  
**WWW: A Unified Framework for Explaining What, Where and Why of Neural Networks by Interpretation of Neuron Concepts**
<br/>
<button class="copy-to-clipboard" title="WWW: A Unified Framework for Explaining What, Where and Why of Neural Networks by Interpretation of Neuron Concepts" index=110>
  <span class="copy-to-clipboard-item">Copy Title<span>
</button>
<div class="toast toast-copied toast-index-110 align-items-center text-bg-secondary border-0 position-absolute top-0 end-0" role="alert" aria-live="assertive" aria-atomic="true">
  <div class="d-flex">
    <div class="toast-body">
      Copied!
    </div>
  </div>
</div>

---
Primary Category: cs.CV  
Categories: cs-CV, cs.CV  
Keyword Score: 5  
Keywords: Black Box  
<a type="button" class="btn btn-outline-primary" href="http://arxiv.org/abs/2402.18956v1" target="_blank" >Paper Link</a>
<button type="button" class="btn btn-outline-primary download-pdf" url="https://arxiv.org/pdf/2402.18956v1.pdf" filename="2402.18956v1.pdf">Download PDF</button>

---


**ABSTRACT**  
Recent advancements in neural networks have showcased their remarkable capabilities across various domains. Despite these successes, the <b>"black</b> <b>box"</b> problem still remains. Addressing this, we propose a novel framework, WWW, that offers the 'what', 'where', and 'why' of the neural network decisions in human-understandable terms. Specifically, WWW utilizes adaptive selection for concept discovery, employing adaptive cosine similarity and thresholding techniques to effectively explain 'what'. To address the 'where' and 'why', we proposed a novel combination of neuron activation maps (NAMs) with Shapley values, generating localized concept maps and heatmaps for individual inputs. Furthermore, WWW introduces a method for predicting uncertainty, leveraging heatmap similarities to estimate 'how' reliable the prediction is. Experimental evaluations of WWW demonstrate superior performance in both quantitative and qualitative metrics, outperforming existing methods in interpretability. WWW provides a unified solution for explaining 'what', 'where', and 'why', introducing a method for localized explanations from global interpretations and offering a plug-and-play solution adaptable to various architectures.

{{</citation>}}


### (63/69 | 111/321) PCDepth: Pattern-based Complementary Learning for Monocular Depth Estimation by Best of Both Worlds (Haotian Liu et al., 2024)

{{<citation>}}

Haotian Liu, Sanqing Qu, Fan Lu, Zongtao Bu, Florian Roehrbein, Alois Knoll, Guang Chen. (2024)  
**PCDepth: Pattern-based Complementary Learning for Monocular Depth Estimation by Best of Both Worlds**
<br/>
<button class="copy-to-clipboard" title="PCDepth: Pattern-based Complementary Learning for Monocular Depth Estimation by Best of Both Worlds" index=111>
  <span class="copy-to-clipboard-item">Copy Title<span>
</button>
<div class="toast toast-copied toast-index-111 align-items-center text-bg-secondary border-0 position-absolute top-0 end-0" role="alert" aria-live="assertive" aria-atomic="true">
  <div class="d-flex">
    <div class="toast-body">
      Copied!
    </div>
  </div>
</div>

---
Primary Category: cs.CV  
Categories: cs-CV, cs.CV  
Keyword Score: 5  
Keywords: Representation Learning  
<a type="button" class="btn btn-outline-primary" href="http://arxiv.org/abs/2402.18925v1" target="_blank" >Paper Link</a>
<button type="button" class="btn btn-outline-primary download-pdf" url="https://arxiv.org/pdf/2402.18925v1.pdf" filename="2402.18925v1.pdf">Download PDF</button>

---


**ABSTRACT**  
Event cameras can record scene dynamics with high temporal resolution, providing rich scene details for monocular depth estimation (MDE) even at low-level illumination. Therefore, existing complementary learning approaches for MDE fuse intensity information from images and scene details from event data for better scene understanding. However, most methods directly fuse two modalities at pixel level, ignoring that the attractive complementarity mainly impacts high-level patterns that only occupy a few pixels. For example, event data is likely to complement contours of scene objects. In this paper, we discretize the scene into a set of high-level patterns to explore the complementarity and propose a Pattern-based Complementary learning architecture for monocular Depth estimation (PCDepth). Concretely, PCDepth comprises two primary components: a complementary visual <b>representation</b> <b>learning</b> module for discretizing the scene into high-level patterns and integrating complementary patterns across modalities and a refined depth estimator aimed at scene reconstruction and depth prediction while maintaining an efficiency-accuracy balance. Through pattern-based complementary learning, PCDepth fully exploits two modalities and achieves more accurate predictions than existing methods, especially in challenging nighttime scenarios. Extensive experiments on MVSEC and DSEC datasets verify the effectiveness and superiority of our PCDepth. Remarkably, compared with state-of-the-art, PCDepth achieves a 37.9% improvement in accuracy in MVSEC nighttime scenarios.

{{</citation>}}


### (64/69 | 112/321) MemoNav: Working Memory Model for Visual Navigation (Hongxin Li et al., 2024)

{{<citation>}}

Hongxin Li, Zeyu Wang, Xu Yang, Yuran Yang, Shuqi Mei, Zhaoxiang Zhang. (2024)  
**MemoNav: Working Memory Model for Visual Navigation**
<br/>
<button class="copy-to-clipboard" title="MemoNav: Working Memory Model for Visual Navigation" index=112>
  <span class="copy-to-clipboard-item">Copy Title<span>
</button>
<div class="toast toast-copied toast-index-112 align-items-center text-bg-secondary border-0 position-absolute top-0 end-0" role="alert" aria-live="assertive" aria-atomic="true">
  <div class="d-flex">
    <div class="toast-body">
      Copied!
    </div>
  </div>
</div>

---
Primary Category: cs.CV  
Categories: cs-AI, cs-CV, cs-RO, cs.CV  
Keyword Score: 3  
Keywords: Graph  
<a type="button" class="btn btn-outline-primary" href="http://arxiv.org/abs/2402.19161v1" target="_blank" >Paper Link</a>
<button type="button" class="btn btn-outline-primary download-pdf" url="https://arxiv.org/pdf/2402.19161v1.pdf" filename="2402.19161v1.pdf">Download PDF</button>

---


**ABSTRACT**  
Image-goal navigation is a challenging task that requires an agent to navigate to a goal indicated by an image in unfamiliar environments. Existing methods utilizing diverse scene memories suffer from inefficient exploration since they use all historical observations for decision-making without considering the goal-relevant fraction. To address this limitation, we present MemoNav, a novel memory model for image-goal navigation, which utilizes a working memory-inspired pipeline to improve navigation performance. Specifically, we employ three types of navigation memory. The node features on a map are stored in the short-term memory (STM), as these features are dynamically updated. A forgetting module then retains the informative STM fraction to increase efficiency. We also introduce long-term memory (LTM) to learn global scene representations by progressively aggregating STM features. Subsequently, a <b>graph</b> attention module encodes the retained STM and the LTM to generate working memory (WM) which contains the scene features essential for efficient navigation. The synergy among these three memory types boosts navigation performance by enabling the agent to learn and leverage goal-relevant scene features within a topological map. Our evaluation on multi-goal tasks demonstrates that MemoNav significantly outperforms previous methods across all difficulty levels in both Gibson and Matterport3D scenes. Qualitative results further illustrate that MemoNav plans more efficient routes.

{{</citation>}}


### (65/69 | 113/321) DeepEraser: Deep Iterative Context Mining for Generic Text Eraser (Hao Feng et al., 2024)

{{<citation>}}

Hao Feng, Wendi Wang, Shaokai Liu, Jiajun Deng, Wengang Zhou, Houqiang Li. (2024)  
**DeepEraser: Deep Iterative Context Mining for Generic Text Eraser**
<br/>
<button class="copy-to-clipboard" title="DeepEraser: Deep Iterative Context Mining for Generic Text Eraser" index=113>
  <span class="copy-to-clipboard-item">Copy Title<span>
</button>
<div class="toast toast-copied toast-index-113 align-items-center text-bg-secondary border-0 position-absolute top-0 end-0" role="alert" aria-live="assertive" aria-atomic="true">
  <div class="d-flex">
    <div class="toast-body">
      Copied!
    </div>
  </div>
</div>

---
Primary Category: cs.CV  
Categories: cs-CV, cs.CV  
Keyword Score: 3  
Keywords: Benchmarking  
<a type="button" class="btn btn-outline-primary" href="http://arxiv.org/abs/2402.19108v1" target="_blank" >Paper Link</a>
<button type="button" class="btn btn-outline-primary download-pdf" url="https://arxiv.org/pdf/2402.19108v1.pdf" filename="2402.19108v1.pdf">Download PDF</button>

---


**ABSTRACT**  
In this work, we present DeepEraser, an effective deep network for generic text removal. DeepEraser utilizes a recurrent architecture that erases the text in an image via iterative operations. Our idea comes from the process of erasing pencil script, where the text area designated for removal is subject to continuous monitoring and the text is attenuated progressively, ensuring a thorough and clean erasure. Technically, at each iteration, an innovative erasing module is deployed, which not only explicitly aggregates the previous erasing progress but also mines additional semantic context to erase the target text. Through iterative refinements, the text regions are progressively replaced with more appropriate content and finally converge to a relatively accurate status. Furthermore, a custom mask generation strategy is introduced to improve the capability of DeepEraser for adaptive text removal, as opposed to indiscriminately removing all the text in an image. Our DeepEraser is notably compact with only 1.4M parameters and trained in an end-to-end manner. To verify its effectiveness, extensive experiments are conducted on several prevalent <b>benchmarks,</b> including SCUT-Syn, SCUT-EnsText, and Oxford Synthetic text dataset. The quantitative and qualitative results demonstrate the effectiveness of our DeepEraser over the state-of-the-art methods, as well as its strong generalization ability in custom mask text removal. The codes and pre-trained models are available at https://github.com/fh2019ustc/DeepEraser

{{</citation>}}


### (66/69 | 114/321) GoalNet: Goal Areas Oriented Pedestrian Trajectory Prediction (Ching-Lin Lee et al., 2024)

{{<citation>}}

Ching-Lin Lee, Zhi-Xuan Wang, Kuan-Ting Lai, Amar Fadillah. (2024)  
**GoalNet: Goal Areas Oriented Pedestrian Trajectory Prediction**
<br/>
<button class="copy-to-clipboard" title="GoalNet: Goal Areas Oriented Pedestrian Trajectory Prediction" index=114>
  <span class="copy-to-clipboard-item">Copy Title<span>
</button>
<div class="toast toast-copied toast-index-114 align-items-center text-bg-secondary border-0 position-absolute top-0 end-0" role="alert" aria-live="assertive" aria-atomic="true">
  <div class="d-flex">
    <div class="toast-body">
      Copied!
    </div>
  </div>
</div>

---
Primary Category: cs.CV  
Categories: cs-AI, cs-CV, cs.CV  
Keyword Score: 3  
Keywords: Multi-modal  
<a type="button" class="btn btn-outline-primary" href="http://arxiv.org/abs/2402.19002v1" target="_blank" >Paper Link</a>
<button type="button" class="btn btn-outline-primary download-pdf" url="https://arxiv.org/pdf/2402.19002v1.pdf" filename="2402.19002v1.pdf">Download PDF</button>

---


**ABSTRACT**  
Predicting the future trajectories of pedestrians on the road is an important task for autonomous driving. The pedestrian trajectory prediction is affected by scene paths, pedestrian's intentions and decision-making, which is a <b>multi-modal</b> problem. Most recent studies use past trajectories to predict a variety of potential future trajectory distributions, which do not account for the scene context and pedestrian targets. Instead of predicting the future trajectory directly, we propose to use scene context and observed trajectory to predict the goal points first, and then reuse the goal points to predict the future trajectories. By leveraging the information from scene context and observed trajectory, the uncertainty can be limited to a few target areas, which represent the "goals" of the pedestrians. In this paper, we propose GoalNet, a new trajectory prediction neural network based on the goal areas of a pedestrian. Our network can predict both pedestrian's trajectories and bounding boxes. The overall model is efficient and modular, and its outputs can be changed according to the usage scenario. Experimental results show that GoalNet significantly improves the previous state-of-the-art performance by 48.7% on the JAAD and 40.8% on the PIE dataset.

{{</citation>}}


### (67/69 | 115/321) Navigating Beyond Dropout: An Intriguing Solution Towards Generalizable Image Super Resolution (Hongjun Wang et al., 2024)

{{<citation>}}

Hongjun Wang, Jiyuan Chen, Yinqiang Zheng, Tieyong Zeng. (2024)  
**Navigating Beyond Dropout: An Intriguing Solution Towards Generalizable Image Super Resolution**
<br/>
<button class="copy-to-clipboard" title="Navigating Beyond Dropout: An Intriguing Solution Towards Generalizable Image Super Resolution" index=115>
  <span class="copy-to-clipboard-item">Copy Title<span>
</button>
<div class="toast toast-copied toast-index-115 align-items-center text-bg-secondary border-0 position-absolute top-0 end-0" role="alert" aria-live="assertive" aria-atomic="true">
  <div class="d-flex">
    <div class="toast-body">
      Copied!
    </div>
  </div>
</div>

---
Primary Category: cs.CV  
Categories: cs-AI, cs-CV, cs.CV  
Keyword Score: 3  
Keywords: Benchmarking  
<a type="button" class="btn btn-outline-primary" href="http://arxiv.org/abs/2402.18929v2" target="_blank" >Paper Link</a>
<button type="button" class="btn btn-outline-primary download-pdf" url="https://arxiv.org/pdf/2402.18929v2.pdf" filename="2402.18929v2.pdf">Download PDF</button>

---


**ABSTRACT**  
Deep learning has led to a dramatic leap on Single Image Super-Resolution (SISR) performances in recent years. %Despite the substantial advancement% While most existing work assumes a simple and fixed degradation model (e.g., bicubic downsampling), the research of Blind SR seeks to improve model generalization ability with unknown degradation. Recently, Kong et al pioneer the investigation of a more suitable training strategy for Blind SR using Dropout. Although such method indeed brings substantial generalization improvements via mitigating overfitting, we argue that Dropout simultaneously introduces undesirable side-effect that compromises model's capacity to faithfully reconstruct fine details. We show both the theoretical and experimental analyses in our paper, and furthermore, we present another easy yet effective training strategy that enhances the generalization ability of the model by simply modulating its first and second-order features statistics. Experimental results have shown that our method could serve as a model-agnostic regularization and outperforms Dropout on seven <b>benchmark</b> datasets including both synthetic and real-world scenarios.

{{</citation>}}


### (68/69 | 116/321) SNE-RoadSegV2: Advancing Heterogeneous Feature Fusion and Fallibility Awareness for Freespace Detection (Yi Feng et al., 2024)

{{<citation>}}

Yi Feng, Yu Ma, Qijun Chen, Ioannis Pitas, Rui Fan. (2024)  
**SNE-RoadSegV2: Advancing Heterogeneous Feature Fusion and Fallibility Awareness for Freespace Detection**
<br/>
<button class="copy-to-clipboard" title="SNE-RoadSegV2: Advancing Heterogeneous Feature Fusion and Fallibility Awareness for Freespace Detection" index=116>
  <span class="copy-to-clipboard-item">Copy Title<span>
</button>
<div class="toast toast-copied toast-index-116 align-items-center text-bg-secondary border-0 position-absolute top-0 end-0" role="alert" aria-live="assertive" aria-atomic="true">
  <div class="d-flex">
    <div class="toast-body">
      Copied!
    </div>
  </div>
</div>

---
Primary Category: cs.CV  
Categories: cs-CV, cs.CV  
Keyword Score: 3  
Keywords: Benchmarking  
<a type="button" class="btn btn-outline-primary" href="http://arxiv.org/abs/2402.18918v1" target="_blank" >Paper Link</a>
<button type="button" class="btn btn-outline-primary download-pdf" url="https://arxiv.org/pdf/2402.18918v1.pdf" filename="2402.18918v1.pdf">Download PDF</button>

---


**ABSTRACT**  
Feature-fusion networks with duplex encoders have proven to be an effective technique to solve the freespace detection problem. However, despite the compelling results achieved by previous research efforts, the exploration of adequate and discriminative heterogeneous feature fusion, as well as the development of fallibility-aware loss functions remains relatively scarce. This paper makes several significant contributions to address these limitations: (1) It presents a novel heterogeneous feature fusion block, comprising a holistic attention module, a heterogeneous feature contrast descriptor, and an affinity-weighted feature recalibrator, enabling a more in-depth exploitation of the inherent characteristics of the extracted features, (2) it incorporates both inter-scale and intra-scale skip connections into the decoder architecture while eliminating redundant ones, leading to both improved accuracy and computational efficiency, and (3) it introduces two fallibility-aware loss functions that separately focus on semantic-transition and depth-inconsistent regions, collectively contributing to greater supervision during model training. Our proposed heterogeneous feature fusion network (SNE-RoadSegV2), which incorporates all these innovative components, demonstrates superior performance in comparison to all other freespace detection algorithms across multiple public datasets. Notably, it ranks the 1st on the official KITTI Road <b>benchmark.</b>

{{</citation>}}


### (69/69 | 117/321) NARUTO: Neural Active Reconstruction from Uncertain Target Observations (Ziyue Feng et al., 2024)

{{<citation>}}

Ziyue Feng, Huangying Zhan, Zheng Chen, Qingan Yan, Xiangyu Xu, Changjiang Cai, Bing Li, Qilun Zhu, Yi Xu. (2024)  
**NARUTO: Neural Active Reconstruction from Uncertain Target Observations**
<br/>
<button class="copy-to-clipboard" title="NARUTO: Neural Active Reconstruction from Uncertain Target Observations" index=117>
  <span class="copy-to-clipboard-item">Copy Title<span>
</button>
<div class="toast toast-copied toast-index-117 align-items-center text-bg-secondary border-0 position-absolute top-0 end-0" role="alert" aria-live="assertive" aria-atomic="true">
  <div class="d-flex">
    <div class="toast-body">
      Copied!
    </div>
  </div>
</div>

---
Primary Category: cs.CV  
Categories: cs-CV, cs-RO, cs.CV  
Keyword Score: 3  
Keywords: Benchmarking  
<a type="button" class="btn btn-outline-primary" href="http://arxiv.org/abs/2402.18771v1" target="_blank" >Paper Link</a>
<button type="button" class="btn btn-outline-primary download-pdf" url="https://arxiv.org/pdf/2402.18771v1.pdf" filename="2402.18771v1.pdf">Download PDF</button>

---


**ABSTRACT**  
We present NARUTO, a neural active reconstruction system that combines a hybrid neural representation with uncertainty learning, enabling high-fidelity surface reconstruction. Our approach leverages a multi-resolution hash-grid as the mapping backbone, chosen for its exceptional convergence speed and capacity to capture high-frequency local features.The centerpiece of our work is the incorporation of an uncertainty learning module that dynamically quantifies reconstruction uncertainty while actively reconstructing the environment. By harnessing learned uncertainty, we propose a novel uncertainty aggregation strategy for goal searching and efficient path planning. Our system autonomously explores by targeting uncertain observations and reconstructs environments with remarkable completeness and fidelity. We also demonstrate the utility of this uncertainty-aware approach by enhancing SOTA neural SLAM systems through an active ray sampling strategy. Extensive evaluations of NARUTO in various environments, using an indoor scene simulator, confirm its superior performance and state-of-the-art status in active reconstruction, as evidenced by its impressive results on <b>benchmark</b> datasets like Replica and MP3D.

{{</citation>}}


## cs.IR (8)



### (1/8 | 118/321) LLM-Ensemble: Optimal Large Language Model Ensemble Method for E-commerce Product Attribute Value Extraction (Chenhao Fang et al., 2024)

{{<citation>}}

Chenhao Fang, Xiaohan Li, Zezhong Fan, Jianpeng Xu, Kaushiki Nag, Evren Korpeoglu, Sushant Kumar, Kannan Achan. (2024)  
**LLM-Ensemble: Optimal Large Language Model Ensemble Method for E-commerce Product Attribute Value Extraction**
<br/>
<button class="copy-to-clipboard" title="LLM-Ensemble: Optimal Large Language Model Ensemble Method for E-commerce Product Attribute Value Extraction" index=118>
  <span class="copy-to-clipboard-item">Copy Title<span>
</button>
<div class="toast toast-copied toast-index-118 align-items-center text-bg-secondary border-0 position-absolute top-0 end-0" role="alert" aria-live="assertive" aria-atomic="true">
  <div class="d-flex">
    <div class="toast-body">
      Copied!
    </div>
  </div>
</div>

---
Primary Category: cs.IR  
Categories: cs-AI, cs-CL, cs-IR, cs.IR  
Keyword Score: 80  
Keywords: Recommendation, GPT, GPT-3, GPT-3.5, GPT-4, PaLM, Large Language Model, Large Language Model  
<a type="button" class="btn btn-outline-primary" href="http://arxiv.org/abs/2403.00863v1" target="_blank" >Paper Link</a>
<button type="button" class="btn btn-outline-primary download-pdf" url="https://arxiv.org/pdf/2403.00863v1.pdf" filename="2403.00863v1.pdf">Download PDF</button>

---


**ABSTRACT**  
Product attribute value extraction is a pivotal component in Natural Language Processing (NLP) and the contemporary e-commerce industry. The provision of precise product attribute values is fundamental in ensuring high-quality <b>recommendations</b> and enhancing customer satisfaction. The recently emerging <b>Large</b> <b>Language</b> <b>Models</b> <b>(LLMs)</b> have demonstrated state-of-the-art performance in numerous attribute extraction tasks, without the need for domain-specific training data. Nevertheless, varying strengths and weaknesses are exhibited by different <b>LLMs</b> due to the diversity in data, architectures, and hyperparameters. This variation makes them complementary to each other, with no single <b>LLM</b> dominating all others. Considering the diverse strengths and weaknesses of <b>LLMs,</b> it becomes necessary to develop an ensemble method that leverages their complementary potentials. In this paper, we propose a novel algorithm called <b>LLM-ensemble</b> to ensemble different <b>LLMs'</b> outputs for attribute value extraction. We iteratively learn the weights for different <b>LLMs</b> to aggregate the labels with weights to predict the final attribute value. Not only can our proposed method be proven theoretically optimal, but it also ensures efficient computation, fast convergence, and safe deployment. We have also conducted extensive experiments with various state-of-the-art <b>LLMs,</b> including Llama2-13B, Llama2-70B, <b>PaLM-2,</b> <b>GPT-3.5,</b> and <b>GPT-4,</b> on Walmart's internal data. Our offline metrics demonstrate that the <b>LLM-ensemble</b> method outperforms all the state-of-the-art single <b>LLMs</b> on Walmart's internal dataset. This method has been launched in several production models, leading to improved Gross Merchandise Volume (GMV), Click-Through Rate (CTR), Conversion Rate (CVR), and Add-to-Cart Rate (ATC).

{{</citation>}}


### (2/8 | 119/321) Crafting Knowledge: Exploring the Creative Mechanisms of Chat-Based Search Engines (Lijia Ma et al., 2024)

{{<citation>}}

Lijia Ma, Xingchen Xu, Yong Tan. (2024)  
**Crafting Knowledge: Exploring the Creative Mechanisms of Chat-Based Search Engines**
<br/>
<button class="copy-to-clipboard" title="Crafting Knowledge: Exploring the Creative Mechanisms of Chat-Based Search Engines" index=119>
  <span class="copy-to-clipboard-item">Copy Title<span>
</button>
<div class="toast toast-copied toast-index-119 align-items-center text-bg-secondary border-0 position-absolute top-0 end-0" role="alert" aria-live="assertive" aria-atomic="true">
  <div class="d-flex">
    <div class="toast-body">
      Copied!
    </div>
  </div>
</div>

---
Primary Category: cs.IR  
Categories: J-4, cs-AI, cs-IR, cs.IR, econ-GN, q-fin-EC  
Keyword Score: 80  
Keywords: Retrieval-Augmented Generation, Retrieval-Augmented Generation, Retrieval-Augmented Generation, GPT, GPT-4, Large Language Model, Large Language Model, Perplexity  
<a type="button" class="btn btn-outline-primary" href="http://arxiv.org/abs/2402.19421v1" target="_blank" >Paper Link</a>
<button type="button" class="btn btn-outline-primary download-pdf" url="https://arxiv.org/pdf/2402.19421v1.pdf" filename="2402.19421v1.pdf">Download PDF</button>

---


**ABSTRACT**  
In the domain of digital information dissemination, search engines act as pivotal conduits linking information seekers with providers. The advent of chat-based search engines utilizing <b>Large</b> <b>Language</b> <b>Models</b> <b>(LLMs)</b> and <b>Retrieval</b> <b>Augmented</b> <b>Generation</b> <b>(RAG),</b> exemplified by Bing Chat, marks an evolutionary leap in the search ecosystem. They demonstrate metacognitive abilities in interpreting web information and crafting responses with human-like understanding and creativity. Nonetheless, the intricate nature of <b>LLMs</b> renders their "cognitive" processes opaque, challenging even their designers' understanding. This research aims to dissect the mechanisms through which an <b>LLM-powered</b> chat-based search engine, specifically Bing Chat, selects information sources for its responses. To this end, an extensive dataset has been compiled through engagements with New Bing, documenting the websites it cites alongside those listed by the conventional search engine. Employing natural language processing (NLP) techniques, the research reveals that Bing Chat exhibits a preference for content that is not only readable and formally structured, but also demonstrates lower <b>perplexity</b> levels, indicating a unique inclination towards text that is predictable by the underlying <b>LLM.</b> Further enriching our analysis, we procure an additional dataset through interactions with the <b>GPT-4</b> based knowledge <b>retrieval</b> <b>API,</b> <b>unveiling</b> a congruent text preference between the <b>RAG</b> API and Bing Chat. This consensus suggests that these text preferences intrinsically emerge from the underlying language models, rather than being explicitly crafted by Bing Chat's developers. Moreover, our investigation documents a greater similarity among websites cited by <b>RAG</b> technologies compared to those ranked highest by conventional search engines.

{{</citation>}}


### (3/8 | 120/321) MENTOR: Multi-level Self-supervised Learning for Multimodal Recommendation (Jinfeng Xu et al., 2024)

{{<citation>}}

Jinfeng Xu, Zheyu Chen, Shuo Yang, Jinze Li, Hewei Wang, Edith C. -H. Ngai. (2024)  
**MENTOR: Multi-level Self-supervised Learning for Multimodal Recommendation**
<br/>
<button class="copy-to-clipboard" title="MENTOR: Multi-level Self-supervised Learning for Multimodal Recommendation" index=120>
  <span class="copy-to-clipboard-item">Copy Title<span>
</button>
<div class="toast toast-copied toast-index-120 align-items-center text-bg-secondary border-0 position-absolute top-0 end-0" role="alert" aria-live="assertive" aria-atomic="true">
  <div class="d-flex">
    <div class="toast-body">
      Copied!
    </div>
  </div>
</div>

---
Primary Category: cs.IR  
Categories: cs-IR, cs.IR  
Keyword Score: 79  
Keywords: Graph Convolutional Network, Graph Convolutional Network, Graph, Convolution, Convolutional Neural Network, Multi-modal, Multi-modal, Recommendation, Self-supervised Learning, Self-supervised Learning  
<a type="button" class="btn btn-outline-primary" href="http://arxiv.org/abs/2402.19407v1" target="_blank" >Paper Link</a>
<button type="button" class="btn btn-outline-primary download-pdf" url="https://arxiv.org/pdf/2402.19407v1.pdf" filename="2402.19407v1.pdf">Download PDF</button>

---


**ABSTRACT**  
With the increasing multimedia information, <b>multimodal</b> <b>recommendation</b> has received extensive attention. It utilizes <b>multimodal</b> information to alleviate the data sparsity problem in <b>recommendation</b> systems, thus improving <b>recommendation</b> accuracy. However, the reliance on labeled data severely limits the performance of <b>multimodal</b> <b>recommendation</b> models. Recently, <b>self-supervised</b> <b>learning</b> has been used in <b>multimodal</b> <b>recommendations</b> to mitigate the label sparsity problem. Nevertheless, the state-of-the-art methods cannot avoid the modality noise when aligning <b>multimodal</b> information due to the large differences in the distributions of different modalities. To this end, we propose a Multi-level <b>sElf-supervised</b> <b>learNing</b> for <b>mulTimOdal</b> <b>Recommendation</b> (MENTOR) method to address the label sparsity problem and the modality alignment problem. Specifically, MENTOR first enhances the specific features of each modality using the <b>graph</b> <b>convolutional</b> <b>network</b> <b>(GCN)</b> and fuses the visual and textual modalities. It then enhances the item representation via the item semantic <b>graph</b> <b>for</b> <b>all</b> modalities, including the fused modality. Then, it introduces two multilevel <b>self-supervised</b> <b>tasks:</b> the multilevel cross-modal alignment task and the general feature enhancement task. The multilevel cross-modal alignment task aligns each modality under the guidance of the ID embedding from multiple levels while maintaining the historical interaction information. The general feature enhancement task enhances the general feature from both the <b>graph</b> <b>and</b> <b>feature</b> perspectives to improve the robustness of our model. Extensive experiments on three publicly available datasets demonstrate the effectiveness of our method. Our code is publicly available at https://github.com/Jinfeng-Xu/MENTOR.

{{</citation>}}


### (4/8 | 121/321) PaECTER: Patent-level Representation Learning using Citation-informed Transformers (Mainak Ghosh et al., 2024)

{{<citation>}}

Mainak Ghosh, Sebastian Erhardt, Michael E. Rose, Erik Buunk, Dietmar Harhoff. (2024)  
**PaECTER: Patent-level Representation Learning using Citation-informed Transformers**
<br/>
<button class="copy-to-clipboard" title="PaECTER: Patent-level Representation Learning using Citation-informed Transformers" index=121>
  <span class="copy-to-clipboard-item">Copy Title<span>
</button>
<div class="toast toast-copied toast-index-121 align-items-center text-bg-secondary border-0 position-absolute top-0 end-0" role="alert" aria-live="assertive" aria-atomic="true">
  <div class="d-flex">
    <div class="toast-body">
      Copied!
    </div>
  </div>
</div>

---
Primary Category: cs.IR  
Categories: cs-CL, cs-IR, cs-LG, cs.IR  
Keyword Score: 45  
Keywords: Fine-tuning, Representation Learning, BERT, Transformer, Pre-trained Language Model  
<a type="button" class="btn btn-outline-primary" href="http://arxiv.org/abs/2402.19411v1" target="_blank" >Paper Link</a>
<button type="button" class="btn btn-outline-primary download-pdf" url="https://arxiv.org/pdf/2402.19411v1.pdf" filename="2402.19411v1.pdf">Download PDF</button>

---


**ABSTRACT**  
PaECTER is a publicly available, open-source document-level encoder specific for patents. We <b>fine-tune</b> <b>BERT</b> for Patents with examiner-added citation information to generate numerical <b>representations</b> <b>for</b> patent documents. PaECTER performs better in similarity tasks than current state-of-the-art models used in the patent domain. More specifically, our model outperforms the next-best patent specific <b>pre-trained</b> <b>language</b> <b>model</b> <b>(BERT</b> for Patents) on our patent citation prediction test dataset on two different rank evaluation metrics. PaECTER predicts at least one most similar patent at a rank of 1.32 on average when compared against 25 irrelevant patents. Numerical <b>representations</b> <b>generated</b> by PaECTER from patent text can be used for downstream tasks such as classification, tracing knowledge flows, or semantic similarity search. Semantic similarity search is especially relevant in the context of prior art search for both inventors and patent examiners. PaECTER is available on Hugging Face.

{{</citation>}}


### (5/8 | 122/321) Enhancing Long-Term Recommendation with Bi-level Learnable Large Language Model Planning (Wentao Shi et al., 2024)

{{<citation>}}

Wentao Shi, Xiangnan He, Yang Zhang, Chongming Gao, Xinyue Li, Jizhi Zhang, Qifan Wang, Fuli Feng. (2024)  
**Enhancing Long-Term Recommendation with Bi-level Learnable Large Language Model Planning**
<br/>
<button class="copy-to-clipboard" title="Enhancing Long-Term Recommendation with Bi-level Learnable Large Language Model Planning" index=122>
  <span class="copy-to-clipboard-item">Copy Title<span>
</button>
<div class="toast toast-copied toast-index-122 align-items-center text-bg-secondary border-0 position-absolute top-0 end-0" role="alert" aria-live="assertive" aria-atomic="true">
  <div class="d-flex">
    <div class="toast-body">
      Copied!
    </div>
  </div>
</div>

---
Primary Category: cs.IR  
Categories: cs-AI, cs-CL, cs-IR, cs-LG, cs.IR  
Keyword Score: 40  
Keywords: Recommendation, Reinforcement Learning, Large Language Model, Large Language Model  
<a type="button" class="btn btn-outline-primary" href="http://arxiv.org/abs/2403.00843v1" target="_blank" >Paper Link</a>
<button type="button" class="btn btn-outline-primary download-pdf" url="https://arxiv.org/pdf/2403.00843v1.pdf" filename="2403.00843v1.pdf">Download PDF</button>

---


**ABSTRACT**  
Traditional <b>recommendation</b> setting tends to excessively cater to users' immediate interests and neglect their long-term engagement. To address it, it is crucial to incorporate planning capabilities into the <b>recommendation</b> decision-making process to develop policies that take into account both immediate interests and long-term engagement. Despite <b>Reinforcement</b> <b>Learning</b> (RL) can learn planning capacity by maximizing cumulative reward, the scarcity of <b>recommendation</b> data presents challenges such as instability and susceptibility to overfitting when training RL models from scratch. In this context, we propose to leverage the remarkable planning capabilities over sparse data of <b>Large</b> <b>Language</b> <b>Models</b> <b>(LLMs)</b> for long-term <b>recommendation.</b> The key lies in enabling a language model to understand and apply task-solving principles effectively in personalized <b>recommendation</b> scenarios, as the model's pre-training may not naturally encompass these principles, necessitating the need to inspire or teach the model. To achieve this, we propose a Bi-level Learnable <b>LLM</b> Planner framework, which combines macro-learning and micro-learning through a hierarchical mechanism. The framework includes a Planner and Reflector for acquiring high-level guiding principles and an Actor-Critic component for planning personalization. Extensive experiments validate the superiority of the framework in learning to plan for long-term <b>recommendations.</b>

{{</citation>}}


### (6/8 | 123/321) Aligning Language Models for Versatile Text-based Item Retrieval (Yuxuan Lei et al., 2024)

{{<citation>}}

Yuxuan Lei, Jianxun Lian, Jing Yao, Mingqi Wu, Defu Lian, Xing Xie. (2024)  
**Aligning Language Models for Versatile Text-based Item Retrieval**
<br/>
<button class="copy-to-clipboard" title="Aligning Language Models for Versatile Text-based Item Retrieval" index=123>
  <span class="copy-to-clipboard-item">Copy Title<span>
</button>
<div class="toast toast-copied toast-index-123 align-items-center text-bg-secondary border-0 position-absolute top-0 end-0" role="alert" aria-live="assertive" aria-atomic="true">
  <div class="d-flex">
    <div class="toast-body">
      Copied!
    </div>
  </div>
</div>

---
Primary Category: cs.IR  
Categories: cs-IR, cs.IR  
Keyword Score: 40  
Keywords: Fine-tuning, Zero-shot, Large Language Model, Text Embedding  
<a type="button" class="btn btn-outline-primary" href="http://arxiv.org/abs/2402.18899v1" target="_blank" >Paper Link</a>
<button type="button" class="btn btn-outline-primary download-pdf" url="https://arxiv.org/pdf/2402.18899v1.pdf" filename="2402.18899v1.pdf">Download PDF</button>

---


**ABSTRACT**  
This paper addresses the gap between general-purpose <b>text</b> <b>embeddings</b> and the specific demands of item retrieval tasks. We demonstrate the shortcomings of existing models in capturing the nuances necessary for <b>zero-shot</b> performance on item retrieval tasks. To overcome these limitations, we propose generate in-domain dataset from ten tasks tailored to unlocking models' representation ability for item retrieval. Our empirical studies demonstrate that <b>fine-tuning</b> embedding models on the dataset leads to remarkable improvements in a variety of retrieval tasks. We also illustrate the practical application of our refined model in a conversational setting, where it enhances the capabilities of <b>LLM-based</b> Recommender Agents like Chat-Rec. Our code is available at https://github.com/microsoft/RecAI.

{{</citation>}}


### (7/8 | 124/321) Effective Two-Stage Knowledge Transfer for Multi-Entity Cross-Domain Recommendation (Jianyu Guan et al., 2024)

{{<citation>}}

Jianyu Guan, Zongming Yin, Tianyi Zhang, Leihui Chen, Yin Zhang, Fei Huang, Jufeng Chen, Shuguang Han. (2024)  
**Effective Two-Stage Knowledge Transfer for Multi-Entity Cross-Domain Recommendation**
<br/>
<button class="copy-to-clipboard" title="Effective Two-Stage Knowledge Transfer for Multi-Entity Cross-Domain Recommendation" index=124>
  <span class="copy-to-clipboard-item">Copy Title<span>
</button>
<div class="toast toast-copied toast-index-124 align-items-center text-bg-secondary border-0 position-absolute top-0 end-0" role="alert" aria-live="assertive" aria-atomic="true">
  <div class="d-flex">
    <div class="toast-body">
      Copied!
    </div>
  </div>
</div>

---
Primary Category: cs.IR  
Categories: cs-IR, cs-LG, cs.IR  
Keyword Score: 30  
Keywords: Fine-tuning, Knowledge Transfer, Recommendation  
<a type="button" class="btn btn-outline-primary" href="http://arxiv.org/abs/2402.19101v1" target="_blank" >Paper Link</a>
<button type="button" class="btn btn-outline-primary download-pdf" url="https://arxiv.org/pdf/2402.19101v1.pdf" filename="2402.19101v1.pdf">Download PDF</button>

---


**ABSTRACT**  
In recent years, the <b>recommendation</b> content on e-commerce platforms has become increasingly rich -- a single user feed may contain multiple entities, such as selling products, short videos, and content posts. To deal with the multi-entity <b>recommendation</b> problem, an intuitive solution is to adopt the shared-network-based architecture for joint training. The idea is to transfer the extracted <b>knowledge</b> <b>from</b> one type of entity (source entity) to another (target entity). However, different from the conventional same-entity cross-domain <b>recommendation,</b> multi-entity <b>knowledge</b> <b>transfer</b> encounters several important issues: (1) data distributions of the source entity and target entity are naturally different, making the shared-network-based joint training susceptible to the negative transfer issue, (2) more importantly, the corresponding feature schema of each entity is not exactly aligned (e.g., price is an essential feature for selling product while missing for content posts), making the existing methods no longer appropriate. Recent researchers have also experimented with the pre-training and <b>fine-tuning</b> paradigm. Again, they only consider the scenarios with the same entity type and feature systems, which is inappropriate in our case. To this end, we design a pre-training & <b>fine-tuning</b> based Multi-entity <b>Knowledge</b> <b>Transfer</b> framework called MKT. MKT utilizes a multi-entity pre-training module to extract transferable <b>knowledge</b> <b>across</b> different entities. In particular, a feature alignment module is first applied to scale and align different feature schemas. Afterward, a couple of <b>knowledge</b> <b>extractors</b> are employed to extract the common and entity-specific <b>knowledge.</b> <b>In</b> the end, the extracted common <b>knowledge</b> <b>is</b> adopted for target entity model training. Through extensive offline and online experiments, we demonstrated the superiority of MKT over multiple State-Of-The-Art methods.

{{</citation>}}


### (8/8 | 125/321) Lower-Left Partial AUC: An Effective and Efficient Optimization Metric for Recommendation (Wentao Shi et al., 2024)

{{<citation>}}

Wentao Shi, Chenxu Wang, Fuli Feng, Yang Zhang, Wenjie Wang, Junkang Wu, Xiangnan He. (2024)  
**Lower-Left Partial AUC: An Effective and Efficient Optimization Metric for Recommendation**
<br/>
<button class="copy-to-clipboard" title="Lower-Left Partial AUC: An Effective and Efficient Optimization Metric for Recommendation" index=125>
  <span class="copy-to-clipboard-item">Copy Title<span>
</button>
<div class="toast toast-copied toast-index-125 align-items-center text-bg-secondary border-0 position-absolute top-0 end-0" role="alert" aria-live="assertive" aria-atomic="true">
  <div class="d-flex">
    <div class="toast-body">
      Copied!
    </div>
  </div>
</div>

---
Primary Category: cs.IR  
Categories: cs-IR, cs-LG, cs.IR  
Keyword Score: 10  
Keywords: Recommendation  
<a type="button" class="btn btn-outline-primary" href="http://arxiv.org/abs/2403.00844v1" target="_blank" >Paper Link</a>
<button type="button" class="btn btn-outline-primary download-pdf" url="https://arxiv.org/pdf/2403.00844v1.pdf" filename="2403.00844v1.pdf">Download PDF</button>

---


**ABSTRACT**  
Optimization metrics are crucial for building <b>recommendation</b> systems at scale. However, an effective and efficient metric for practical use remains elusive. While Top-K ranking metrics are the gold standard for optimization, they suffer from significant computational overhead. Alternatively, the more efficient accuracy and AUC metrics often fall short of capturing the true targets of <b>recommendation</b> tasks, leading to suboptimal performance. To overcome this dilemma, we propose a new optimization metric, Lower-Left Partial AUC (LLPAUC), which is computationally efficient like AUC but strongly correlates with Top-K ranking metrics. Compared to AUC, LLPAUC considers only the partial area under the ROC curve in the Lower-Left corner to push the optimization focus on Top-K. We provide theoretical validation of the correlation between LLPAUC and Top-K ranking metrics and demonstrate its robustness to noisy user feedback. We further design an efficient point-wise <b>recommendation</b> loss to maximize LLPAUC and evaluate it on three datasets, validating its effectiveness and robustness.

{{</citation>}}


## cs.LG (68)



### (1/68 | 126/321) UniTS: Building a Unified Time Series Model (Shanghua Gao et al., 2024)

{{<citation>}}

Shanghua Gao, Teddy Koker, Owen Queen, Thomas Hartvigsen, Theodoros Tsiligkaridis, Marinka Zitnik. (2024)  
**UniTS: Building a Unified Time Series Model**
<br/>
<button class="copy-to-clipboard" title="UniTS: Building a Unified Time Series Model" index=126>
  <span class="copy-to-clipboard-item">Copy Title<span>
</button>
<div class="toast toast-copied toast-index-126 align-items-center text-bg-secondary border-0 position-absolute top-0 end-0" role="alert" aria-live="assertive" aria-atomic="true">
  <div class="d-flex">
    <div class="toast-body">
      Copied!
    </div>
  </div>
</div>

---
Primary Category: cs.LG  
Categories: cs-AI, cs-LG, cs.LG  
Keyword Score: 80  
Keywords: Anomaly Detection, Few-shot, Fine-tuning, Foundation Model, Zero-shot, Large Language Model, Prompt, Prompt Learning  
<a type="button" class="btn btn-outline-primary" href="http://arxiv.org/abs/2403.00131v1" target="_blank" >Paper Link</a>
<button type="button" class="btn btn-outline-primary download-pdf" url="https://arxiv.org/pdf/2403.00131v1.pdf" filename="2403.00131v1.pdf">Download PDF</button>

---


**ABSTRACT**  
<b>Foundation</b> <b>models,</b> especially <b>LLMs,</b> are profoundly transforming deep learning. Instead of training many task-specific models, we can adapt a single pretrained model to many tasks via <b>fewshot</b> <b>prompting</b> <b>or</b> <b>fine-tuning.</b> However, current <b>foundation</b> <b>models</b> apply to sequence data but not to time series, which present unique challenges due to the inherent diverse and multidomain time series datasets, diverging task specifications across forecasting, classification and other types of tasks, and the apparent need for task-specialized models. We developed UNITS, a unified time series model that supports a universal task specification, accommodating classification, forecasting, imputation, and <b>anomaly</b> <b>detection</b> tasks. This is achieved through a novel unified network backbone, which incorporates sequence and variable attention along with a dynamic linear operator and is trained as a unified model. Across 38 multi-domain datasets, UNITS demonstrates superior performance compared to task-specific models and repurposed natural language-based <b>LLMs.</b> UNITS exhibits remarkable <b>zero-shot,</b> <b>few-shot,</b> and <b>prompt</b> <b>learning</b> capabilities when evaluated on new data domains and tasks. The source code and datasets are available at https://github.com/mims-harvard/UniTS.

{{</citation>}}


### (2/68 | 127/321) Direct Alignment of Draft Model for Speculative Decoding with Chat-Fine-Tuned LLMs (Raghavv Goel et al., 2024)

{{<citation>}}

Raghavv Goel, Mukul Gagrani, Wonseok Jeon, Junyoung Park, Mingu Lee, Christopher Lott. (2024)  
**Direct Alignment of Draft Model for Speculative Decoding with Chat-Fine-Tuned LLMs**
<br/>
<button class="copy-to-clipboard" title="Direct Alignment of Draft Model for Speculative Decoding with Chat-Fine-Tuned LLMs" index=127>
  <span class="copy-to-clipboard-item">Copy Title<span>
</button>
<div class="toast toast-copied toast-index-127 align-items-center text-bg-secondary border-0 position-absolute top-0 end-0" role="alert" aria-live="assertive" aria-atomic="true">
  <div class="d-flex">
    <div class="toast-body">
      Copied!
    </div>
  </div>
</div>

---
Primary Category: cs.LG  
Categories: cs-AI, cs-CL, cs-LG, cs.LG  
Keyword Score: 80  
Keywords: Fine-tuning, Knowledge Distillation, Knowledge Distillation, Reinforcement Learning, LLaMA, Text Generation, Large Language Model, Large Language Model  
<a type="button" class="btn btn-outline-primary" href="http://arxiv.org/abs/2403.00858v1" target="_blank" >Paper Link</a>
<button type="button" class="btn btn-outline-primary download-pdf" url="https://arxiv.org/pdf/2403.00858v1.pdf" filename="2403.00858v1.pdf">Download PDF</button>

---


**ABSTRACT**  
<b>Text</b> <b>generation</b> with <b>Large</b> <b>Language</b> <b>Models</b> <b>(LLMs)</b> is known to be memory bound due to the combination of their auto-regressive nature, huge parameter counts, and limited memory bandwidths, often resulting in low token rates. Speculative decoding has been proposed as a solution for <b>LLM</b> inference acceleration. However, since draft models are often unavailable in the modern open-source <b>LLM</b> families, e.g., for <b>Llama</b> 2 7B, training a high-quality draft model is required to enable inference acceleration via speculative decoding. In this paper, we propose a simple draft model training framework for direct alignment to chat-capable target models. With the proposed framework, we train <b>Llama</b> 2 Chat Drafter 115M, a draft model for <b>Llama</b> 2 Chat 7B or larger, with only 1.64\% of the original size. Our training framework only consists of pretraining, <b>distillation</b> dataset generation, and <b>finetuning</b> with <b>knowledge</b> <b>distillation,</b> with no additional alignment procedure. For the <b>finetuning</b> step, we use instruction-response pairs generated by target model for <b>distillation</b> in plausible data distribution, and propose a new Total Variation Distance++ (TVD++) loss that incorporates variance reduction techniques inspired from the policy gradient method in <b>reinforcement</b> <b>learning.</b> Our empirical results show that <b>Llama</b> 2 Chat Drafter 115M with speculative decoding achieves up to 2.3 block efficiency and 2.4$\times$ speed-up relative to autoregressive decoding on various tasks with no further task-specific <b>fine-tuning.</b>

{{</citation>}}


### (3/68 | 128/321) Non-Invasive Medical Digital Twins using Physics-Informed Self-Supervised Learning (Keying Kuang et al., 2024)

{{<citation>}}

Keying Kuang, Frances Dean, Jack B. Jedlicki, David Ouyang, Anthony Philippakis, David Sontag, Ahmed M. Alaa. (2024)  
**Non-Invasive Medical Digital Twins using Physics-Informed Self-Supervised Learning**
<br/>
<button class="copy-to-clipboard" title="Non-Invasive Medical Digital Twins using Physics-Informed Self-Supervised Learning" index=128>
  <span class="copy-to-clipboard-item">Copy Title<span>
</button>
<div class="toast toast-copied toast-index-128 align-items-center text-bg-secondary border-0 position-absolute top-0 end-0" role="alert" aria-live="assertive" aria-atomic="true">
  <div class="d-flex">
    <div class="toast-body">
      Copied!
    </div>
  </div>
</div>

---
Primary Category: cs.LG  
Categories: cs-LG, cs.LG, q-bio-QM  
Keyword Score: 70  
Keywords: Counter-factual, Fine-tuning, Self-supervised Learning, Self-supervised Learning, Simulation, Simulator, Unsupervised Learning  
<a type="button" class="btn btn-outline-primary" href="http://arxiv.org/abs/2403.00177v1" target="_blank" >Paper Link</a>
<button type="button" class="btn btn-outline-primary download-pdf" url="https://arxiv.org/pdf/2403.00177v1.pdf" filename="2403.00177v1.pdf">Download PDF</button>

---


**ABSTRACT**  
A digital twin is a virtual replica of a real-world physical phenomena that uses mathematical modeling to characterize and simulate its defining features. By constructing digital twins for disease processes, we can perform in-silico <b>simulations</b> that mimic patients' health conditions and <b>counterfactual</b> outcomes under hypothetical interventions in a virtual setting. This eliminates the need for invasive procedures or uncertain treatment decisions. In this paper, we propose a method to identify digital twin model parameters using only noninvasive patient health data. We approach the digital twin modeling as a composite inverse problem, and observe that its structure resembles pretraining and <b>finetuning</b> in <b>self-supervised</b> <b>learning</b> (SSL). Leveraging this, we introduce a physics-informed SSL algorithm that initially pretrains a neural network on the pretext task of solving the physical model equations. Subsequently, the model is trained to reconstruct low-dimensional health measurements from noninvasive modalities while being constrained by the physical equations learned in pretraining. We apply our method to identify digital twins of cardiac hemodynamics using noninvasive echocardiogram videos, and demonstrate its utility in <b>unsupervised</b> disease detection and in-silico clinical trials.

{{</citation>}}


### (4/68 | 129/321) Dual Operating Modes of In-Context Learning (Ziqian Lin et al., 2024)

{{<citation>}}

Ziqian Lin, Kangwook Lee. (2024)  
**Dual Operating Modes of In-Context Learning**
<br/>
<button class="copy-to-clipboard" title="Dual Operating Modes of In-Context Learning" index=129>
  <span class="copy-to-clipboard-item">Copy Title<span>
</button>
<div class="toast toast-copied toast-index-129 align-items-center text-bg-secondary border-0 position-absolute top-0 end-0" role="alert" aria-live="assertive" aria-atomic="true">
  <div class="d-flex">
    <div class="toast-body">
      Copied!
    </div>
  </div>
</div>

---
Primary Category: cs.LG  
Categories: cs-LG, cs.LG  
Keyword Score: 70  
Keywords: Probabilistic Model, Zero-shot, Transformer, In-context Learning, In-context Learning, In-context Learning, Large Language Model  
<a type="button" class="btn btn-outline-primary" href="http://arxiv.org/abs/2402.18819v1" target="_blank" >Paper Link</a>
<button type="button" class="btn btn-outline-primary download-pdf" url="https://arxiv.org/pdf/2402.18819v1.pdf" filename="2402.18819v1.pdf">Download PDF</button>

---


**ABSTRACT**  
<b>In-context</b> <b>learning</b> <b>(ICL)</b> exhibits dual operating modes: task learning, i.e., acquiring a new skill from <b>in-context</b> <b>samples,</b> and task retrieval, i.e., locating and activating a relevant pretrained skill. Recent theoretical work investigates various mathematical models to analyze <b>ICL,</b> but existing models explain only one operating mode at a time. We introduce a <b>probabilistic</b> <b>model,</b> with which one can explain the dual operating modes of <b>ICL</b> simultaneously. Focusing on <b>in-context</b> <b>learning</b> of linear functions, we extend existing models for pretraining data by introducing multiple task groups and task-dependent input distributions. We then analyze the behavior of the optimally pretrained model under the squared loss, i.e., the MMSE estimator of the label given <b>in-context</b> <b>examples.</b> Regarding pretraining task distribution as prior and <b>in-context</b> <b>examples</b> as the observation, we derive the closed-form expression of the task posterior distribution. With the closed-form expression, we obtain a quantitative understanding of the two operating modes of <b>ICL.</b> Furthermore, we shed light on an unexplained phenomenon observed in practice: under certain settings, the <b>ICL</b> risk initially increases and then decreases with more <b>in-context</b> <b>examples.</b> Our model offers a plausible explanation for this "early ascent" phenomenon: a limited number of <b>in-context</b> <b>samples</b> may lead to the retrieval of an incorrect skill, thereby increasing the risk, which will eventually diminish as task learning takes effect with more <b>in-context</b> <b>samples.</b> We also theoretically analyze <b>ICL</b> with biased labels, e.g., <b>zero-shot</b> <b>ICL,</b> where <b>in-context</b> <b>examples</b> are assigned random labels. Lastly, we validate our findings and predictions via experiments involving <b>Transformers</b> and <b>large</b> <b>language</b> <b>models.</b>

{{</citation>}}


### (5/68 | 130/321) Generating, Reconstructing, and Representing Discrete and Continuous Data: Generalized Diffusion with Learnable Encoding-Decoding (Guangyi Liu et al., 2024)

{{<citation>}}

Guangyi Liu, Yu Wang, Zeyu Feng, Qiyu Wu, Liping Tang, Yuan Gao, Zhen Li, Shuguang Cui, Julian McAuley, Eric P. Xing, Zichao Yang, Zhiting Hu. (2024)  
**Generating, Reconstructing, and Representing Discrete and Continuous Data: Generalized Diffusion with Learnable Encoding-Decoding**
<br/>
<button class="copy-to-clipboard" title="Generating, Reconstructing, and Representing Discrete and Continuous Data: Generalized Diffusion with Learnable Encoding-Decoding" index=130>
  <span class="copy-to-clipboard-item">Copy Title<span>
</button>
<div class="toast toast-copied toast-index-130 align-items-center text-bg-secondary border-0 position-absolute top-0 end-0" role="alert" aria-live="assertive" aria-atomic="true">
  <div class="d-flex">
    <div class="toast-body">
      Copied!
    </div>
  </div>
</div>

---
Primary Category: cs.LG  
Categories: cs-AI, cs-LG, cs.LG  
Keyword Score: 60  
Keywords: Diffusion Model, Autoencoder, Generative Adversarial Network, Generative Adversarial Network, Variational Autoencoder, Large Language Model  
<a type="button" class="btn btn-outline-primary" href="http://arxiv.org/abs/2402.19009v1" target="_blank" >Paper Link</a>
<button type="button" class="btn btn-outline-primary download-pdf" url="https://arxiv.org/pdf/2402.19009v1.pdf" filename="2402.19009v1.pdf">Download PDF</button>

---


**ABSTRACT**  
The vast applications of deep <b>generative</b> <b>models</b> <b>are</b> anchored in three core capabilities -- generating new instances, reconstructing inputs, and learning compact representations -- across various data types, such as discrete text/protein sequences and continuous images. Existing model families, like <b>Variational</b> <b>Autoencoders</b> (VAEs), <b>Generative</b> <b>Adversarial</b> <b>Networks</b> <b>(GANs),</b> autoregressive models, and <b>diffusion</b> <b>models,</b> generally excel in specific capabilities and data types but fall short in others. We introduce generalized <b>diffusion</b> <b>with</b> learnable encoder-decoder (DiLED), that seamlessly integrates the core capabilities for broad applicability and enhanced performance. DiLED generalizes the Gaussian noising-denoising in standard <b>diffusion</b> <b>by</b> introducing parameterized encoding-decoding. Crucially, DiLED is compatible with the well-established <b>diffusion</b> <b>model</b> objective and training recipes, allowing effective learning of the encoder-decoder parameters jointly with <b>diffusion.</b> <b>By</b> choosing appropriate encoder/decoder (e.g., <b>large</b> <b>language</b> <b>models),</b> DiLED naturally applies to different data types. Extensive experiments on text, proteins, and images demonstrate DiLED's flexibility to handle diverse data and tasks and its strong improvement over various existing models.

{{</citation>}}


### (6/68 | 131/321) Analyzing and Reducing Catastrophic Forgetting in Parameter Efficient Tuning (Weijieying Ren et al., 2024)

{{<citation>}}

Weijieying Ren, Xinlong Li, Lei Wang, Tianxiang Zhao, Wei Qin. (2024)  
**Analyzing and Reducing Catastrophic Forgetting in Parameter Efficient Tuning**
<br/>
<button class="copy-to-clipboard" title="Analyzing and Reducing Catastrophic Forgetting in Parameter Efficient Tuning" index=131>
  <span class="copy-to-clipboard-item">Copy Title<span>
</button>
<div class="toast toast-copied toast-index-131 align-items-center text-bg-secondary border-0 position-absolute top-0 end-0" role="alert" aria-live="assertive" aria-atomic="true">
  <div class="d-flex">
    <div class="toast-body">
      Copied!
    </div>
  </div>
</div>

---
Primary Category: cs.LG  
Categories: cs-AI, cs-CL, cs-LG, cs.LG  
Keyword Score: 53  
Keywords: Benchmarking, Continual Learning, Fine-tuning, Fine-tuning, Large Language Model, Large Language Model  
<a type="button" class="btn btn-outline-primary" href="http://arxiv.org/abs/2402.18865v1" target="_blank" >Paper Link</a>
<button type="button" class="btn btn-outline-primary download-pdf" url="https://arxiv.org/pdf/2402.18865v1.pdf" filename="2402.18865v1.pdf">Download PDF</button>

---


**ABSTRACT**  
Existing research has shown that <b>large</b> <b>language</b> <b>models</b> <b>(LLMs)</b> exhibit remarkable performance in language understanding and generation. However, when <b>LLMs</b> are continuously <b>fine-tuned</b> on complex and diverse domain-specific downstream tasks, the inference performance on historical tasks decreases dramatically, which is known as a catastrophic forgetting problem. A trade-off needs to be kept between learning plasticity and memory stability. Plenty of existing works have explored strategies like memory replay, regularization and parameter isolation, but little is known about the geometric connection of various adjacent minima in the <b>continual</b> <b>LLMs</b> <b>fine-tuning</b> scenarios. In this work, we investigate the geometric connections of different minima through the lens of mode connectivity, which means different minima can be connected by a low-loss valley. Through extensive experiments, we uncover the mode connectivity phenomenon in the <b>LLMs</b> <b>continual</b> <b>learning</b> scenario and find that it can strike a balance between plasticity and stability. Building upon these findings, we propose a simple yet effective method called Interpolation-based LoRA (I-LoRA), which constructs a dual-memory experience replay framework based on LoRA parameter interpolations. Extensive experiments and analysis on eight domain-specific CL <b>benchmarks</b> demonstrate that I-LoRA consistently show significant improvement over the previous state-of-the-art approaches with up to $11\%$ performance gains, providing a strong baseline and insights for future research on the <b>large</b> <b>language</b> <b>model</b> <b>continual</b> <b>learning</b> problem. Our code is available at \url{https://github.com/which47/LLMCL}.

{{</citation>}}


### (7/68 | 132/321) Curiosity-driven Red-teaming for Large Language Models (Zhang-Wei Hong et al., 2024)

{{<citation>}}

Zhang-Wei Hong, Idan Shenfeld, Tsun-Hsuan Wang, Yung-Sung Chuang, Aldo Pareja, James Glass, Akash Srivastava, Pulkit Agrawal. (2024)  
**Curiosity-driven Red-teaming for Large Language Models**
<br/>
<button class="copy-to-clipboard" title="Curiosity-driven Red-teaming for Large Language Models" index=132>
  <span class="copy-to-clipboard-item">Copy Title<span>
</button>
<div class="toast toast-copied toast-index-132 align-items-center text-bg-secondary border-0 position-absolute top-0 end-0" role="alert" aria-live="assertive" aria-atomic="true">
  <div class="d-flex">
    <div class="toast-body">
      Copied!
    </div>
  </div>
</div>

---
Primary Category: cs.LG  
Categories: cs-AI, cs-CL, cs-LG, cs.LG  
Keyword Score: 50  
Keywords: Fine-tuning, Reinforcement Learning, Large Language Model, Large Language Model, Prompt  
<a type="button" class="btn btn-outline-primary" href="http://arxiv.org/abs/2402.19464v1" target="_blank" >Paper Link</a>
<button type="button" class="btn btn-outline-primary download-pdf" url="https://arxiv.org/pdf/2402.19464v1.pdf" filename="2402.19464v1.pdf">Download PDF</button>

---


**ABSTRACT**  
<b>Large</b> <b>language</b> <b>models</b> <b>(LLMs)</b> hold great potential for many natural language applications but risk generating incorrect or toxic content. To probe when an <b>LLM</b> generates unwanted content, the current paradigm is to recruit a \textit{red team} of human testers to design input <b>prompts</b> (i.e., test cases) that elicit undesirable responses from <b>LLMs.</b> However, relying solely on human testers is expensive and time-consuming. Recent works automate red teaming by training a separate red team <b>LLM</b> with <b>reinforcement</b> <b>learning</b> (RL) to generate test cases that maximize the chance of eliciting undesirable responses from the target <b>LLM.</b> However, current RL methods are only able to generate a small number of effective test cases resulting in a low coverage of the span of <b>prompts</b> that elicit undesirable responses from the target <b>LLM.</b> To overcome this limitation, we draw a connection between the problem of increasing the coverage of generated test cases and the well-studied approach of curiosity-driven exploration that optimizes for novelty. Our method of curiosity-driven red teaming (CRT) achieves greater coverage of test cases while mantaining or increasing their effectiveness compared to existing methods. Our method, CRT successfully provokes toxic responses from LLaMA2 model that has been heavily <b>fine-tuned</b> using human preferences to avoid toxic outputs. Code is available at \url{https://github.com/Improbable-AI/curiosity_redteam}

{{</citation>}}


### (8/68 | 133/321) ArCHer: Training Language Model Agents via Hierarchical Multi-Turn RL (Yifei Zhou et al., 2024)

{{<citation>}}

Yifei Zhou, Andrea Zanette, Jiayi Pan, Sergey Levine, Aviral Kumar. (2024)  
**ArCHer: Training Language Model Agents via Hierarchical Multi-Turn RL**
<br/>
<button class="copy-to-clipboard" title="ArCHer: Training Language Model Agents via Hierarchical Multi-Turn RL" index=133>
  <span class="copy-to-clipboard-item">Copy Title<span>
</button>
<div class="toast toast-copied toast-index-133 align-items-center text-bg-secondary border-0 position-absolute top-0 end-0" role="alert" aria-live="assertive" aria-atomic="true">
  <div class="d-flex">
    <div class="toast-body">
      Copied!
    </div>
  </div>
</div>

---
Primary Category: cs.LG  
Categories: cs-AI, cs-CL, cs-LG, cs.LG  
Keyword Score: 50  
Keywords: Fine-tuning, Reinforcement Learning, Large Language Model, Large Language Model, Prompt  
<a type="button" class="btn btn-outline-primary" href="http://arxiv.org/abs/2402.19446v1" target="_blank" >Paper Link</a>
<button type="button" class="btn btn-outline-primary download-pdf" url="https://arxiv.org/pdf/2402.19446v1.pdf" filename="2402.19446v1.pdf">Download PDF</button>

---


**ABSTRACT**  
A broad use case of <b>large</b> <b>language</b> <b>models</b> <b>(LLMs)</b> is in goal-directed decision-making tasks (or "agent" tasks), where an <b>LLM</b> needs to not just generate completions for a given <b>prompt,</b> but rather make intelligent decisions over a multi-turn interaction to accomplish a task (e.g., when interacting with the web, using tools, or providing customer support). <b>Reinforcement</b> <b>learning</b> (RL) provides a general paradigm to address such agent tasks, but current RL methods for <b>LLMs</b> largely focus on optimizing single-turn rewards. By construction, most single-turn RL methods cannot endow <b>LLMs</b> with the ability to intelligently seek information over multiple turns, perform credit assignment, or reason about their past actions -- all of which are critical in agent tasks. This raises the question: how can we design effective and efficient multi-turn RL algorithms for LLMs? In this paper, we develop a framework for building multi-turn RL algorithms for <b>fine-tuning</b> <b>LLMs,</b> that preserves the flexibility of existing single-turn RL methods for <b>LLMs</b> (e.g., proximal policy optimization), while accommodating multiple turns, long horizons, and delayed rewards effectively. To do this, our framework adopts a hierarchical RL approach and runs two RL algorithms in parallel: a high-level off-policy value-based RL algorithm to aggregate reward over utterances, and a low-level RL algorithm that utilizes this high-level value function to train a token policy within each utterance or turn. Our hierarchical framework, Actor-Critic Framework with a Hierarchical Structure (ArCHer), can also give rise to other RL methods. Empirically, we find that ArCHer significantly improves efficiency and performance on agent tasks, attaining a sample efficiency of about 100x over existing methods, while also improving with larger model capacity (upto the 7 billion scale that we tested on).

{{</citation>}}


### (9/68 | 134/321) Griffin: Mixing Gated Linear Recurrences with Local Attention for Efficient Language Models (Soham De et al., 2024)

{{<citation>}}

Soham De, Samuel L. Smith, Anushan Fernando, Aleksandar Botev, George Cristian-Muraru, Albert Gu, Ruba Haroun, Leonard Berrada, Yutian Chen, Srivatsan Srinivasan, Guillaume Desjardins, Arnaud Doucet, David Budden, Yee Whye Teh, Razvan Pascanu, Nando De Freitas, Caglar Gulcehre. (2024)  
**Griffin: Mixing Gated Linear Recurrences with Local Attention for Efficient Language Models**
<br/>
<button class="copy-to-clipboard" title="Griffin: Mixing Gated Linear Recurrences with Local Attention for Efficient Language Models" index=134>
  <span class="copy-to-clipboard-item">Copy Title<span>
</button>
<div class="toast toast-copied toast-index-134 align-items-center text-bg-secondary border-0 position-absolute top-0 end-0" role="alert" aria-live="assertive" aria-atomic="true">
  <div class="d-flex">
    <div class="toast-body">
      Copied!
    </div>
  </div>
</div>

---
Primary Category: cs.LG  
Categories: cs-CL, cs-LG, cs.LG  
Keyword Score: 50  
Keywords: Graph Attention Networks, LLaMA, Recurrent Neural Network, Recurrent Neural Network, Transformer  
<a type="button" class="btn btn-outline-primary" href="http://arxiv.org/abs/2402.19427v1" target="_blank" >Paper Link</a>
<button type="button" class="btn btn-outline-primary download-pdf" url="https://arxiv.org/pdf/2402.19427v1.pdf" filename="2402.19427v1.pdf">Download PDF</button>

---


**ABSTRACT**  
<b>Recurrent</b> <b>neural</b> <b>networks</b> <b>(RNNs)</b> have fast inference and scale efficiently on long sequences, but they are difficult to train and hard to scale. We propose Hawk, an <b>RNN</b> with <b>gated</b> linear recurrences, and Griffin, a hybrid model that mixes <b>gated</b> linear recurrences with local attention. Hawk exceeds the reported performance of Mamba on downstream tasks, while Griffin matches the performance of <b>Llama-2</b> despite being trained on over 6 times fewer tokens. We also show that Griffin can extrapolate on sequences significantly longer than those seen during training. Our models match the hardware efficiency of <b>Transformers</b> during training, and during inference they have lower latency and significantly higher throughput. We scale Griffin up to 14B parameters, and explain how to shard our models for efficient distributed training.

{{</citation>}}


### (10/68 | 135/321) Loss-Free Machine Unlearning (Jack Foster et al., 2024)

{{<citation>}}

Jack Foster, Stefan Schoepf, Alexandra Brintrup. (2024)  
**Loss-Free Machine Unlearning**
<br/>
<button class="copy-to-clipboard" title="Loss-Free Machine Unlearning" index=135>
  <span class="copy-to-clipboard-item">Copy Title<span>
</button>
<div class="toast toast-copied toast-index-135 align-items-center text-bg-secondary border-0 position-absolute top-0 end-0" role="alert" aria-live="assertive" aria-atomic="true">
  <div class="d-flex">
    <div class="toast-body">
      Copied!
    </div>
  </div>
</div>

---
Primary Category: cs.LG  
Categories: cs-CV, cs-LG, cs.LG  
Keyword Score: 50  
Keywords: Vision Transformer, Fine-tuning, Machine Unlearning, Transformer, Vision Transformer  
<a type="button" class="btn btn-outline-primary" href="http://arxiv.org/abs/2402.19308v1" target="_blank" >Paper Link</a>
<button type="button" class="btn btn-outline-primary download-pdf" url="https://arxiv.org/pdf/2402.19308v1.pdf" filename="2402.19308v1.pdf">Download PDF</button>

---


**ABSTRACT**  
We present a <b>machine</b> <b>unlearning</b> approach that is both retraining- and label-free. Most existing <b>machine</b> <b>unlearning</b> approaches require a model to be <b>fine-tuned</b> to remove information while preserving performance. This is computationally expensive and necessitates the storage of the whole dataset for the lifetime of the model. Retraining-free approaches often utilise Fisher information, which is derived from the loss and requires labelled data which may not be available. Thus, we present an extension to the Selective Synaptic Dampening algorithm, substituting the diagonal of the Fisher information matrix for the gradient of the l2 norm of the model output to approximate sensitivity. We evaluate our method in a range of experiments using ResNet18 and <b>Vision</b> <b>Transformer.</b> Results show our label-free method is competitive with existing state-of-the-art approaches.

{{</citation>}}


### (11/68 | 136/321) Causal Graph ODE: Continuous Treatment Effect Modeling in Multi-agent Dynamical Systems (Zijie Huang et al., 2024)

{{<citation>}}

Zijie Huang, Jeehyun Hwang, Junkai Zhang, Jinwoo Baik, Weitong Zhang, Dominik Wodarz, Yizhou Sun, Quanquan Gu, Wei Wang. (2024)  
**Causal Graph ODE: Continuous Treatment Effect Modeling in Multi-agent Dynamical Systems**
<br/>
<button class="copy-to-clipboard" title="Causal Graph ODE: Continuous Treatment Effect Modeling in Multi-agent Dynamical Systems" index=136>
  <span class="copy-to-clipboard-item">Copy Title<span>
</button>
<div class="toast toast-copied toast-index-136 align-items-center text-bg-secondary border-0 position-absolute top-0 end-0" role="alert" aria-live="assertive" aria-atomic="true">
  <div class="d-flex">
    <div class="toast-body">
      Copied!
    </div>
  </div>
</div>

---
Primary Category: cs.LG  
Categories: cs-AI, cs-LG, cs.LG  
Keyword Score: 43  
Keywords: Graph, Graph Neural Network, Graph Neural Network, Adversarial Learning, Counter-factual  
<a type="button" class="btn btn-outline-primary" href="http://arxiv.org/abs/2403.00178v1" target="_blank" >Paper Link</a>
<button type="button" class="btn btn-outline-primary download-pdf" url="https://arxiv.org/pdf/2403.00178v1.pdf" filename="2403.00178v1.pdf">Download PDF</button>

---


**ABSTRACT**  
Real-world multi-agent systems are often dynamic and continuous, where the agents co-evolve and undergo changes in their trajectories and interactions over time. For example, the COVID-19 transmission in the U.S. can be viewed as a multi-agent system, where states act as agents and daily population movements between them are interactions. Estimating the <b>counterfactual</b> outcomes in such systems enables accurate future predictions and effective decision-making, such as formulating COVID-19 policies. However, existing methods fail to model the continuous dynamic effects of treatments on the outcome, especially when multiple treatments (e.g., "stay-at-home" and "get-vaccine" policies) are applied simultaneously. To tackle this challenge, we propose Causal <b>Graph</b> <b>Ordinary</b> <b>Differential</b> Equations (CAG-ODE), a novel model that captures the continuous interaction among agents using a <b>Graph</b> <b>Neural</b> <b>Network</b> <b>(GNN)</b> as the ODE function. The key innovation of our model is to learn time-dependent representations of treatments and incorporate them into the ODE function, enabling precise predictions of potential outcomes. To mitigate confounding bias, we further propose two domain <b>adversarial</b> <b>learning-based</b> objectives, which enable our model to learn balanced continuous representations that are not affected by treatments or interference. Experiments on two datasets (i.e., COVID-19 and tumor growth) demonstrate the superior performance of our proposed model.

{{</citation>}}


### (12/68 | 137/321) Theoretical Foundations of Deep Selective State-Space Models (Nicola Muca Cirone et al., 2024)

{{<citation>}}

Nicola Muca Cirone, Antonio Orvieto, Benjamin Walker, Cristopher Salvi, Terry Lyons. (2024)  
**Theoretical Foundations of Deep Selective State-Space Models**
<br/>
<button class="copy-to-clipboard" title="Theoretical Foundations of Deep Selective State-Space Models" index=137>
  <span class="copy-to-clipboard-item">Copy Title<span>
</button>
<div class="toast toast-copied toast-index-137 align-items-center text-bg-secondary border-0 position-absolute top-0 end-0" role="alert" aria-live="assertive" aria-atomic="true">
  <div class="d-flex">
    <div class="toast-body">
      Copied!
    </div>
  </div>
</div>

---
Primary Category: cs.LG  
Categories: cs-LG, cs.LG, math-DS  
Keyword Score: 40  
Keywords: Foundation Model, Transformer, Grounding, Stemming  
<a type="button" class="btn btn-outline-primary" href="http://arxiv.org/abs/2402.19047v2" target="_blank" >Paper Link</a>
<button type="button" class="btn btn-outline-primary download-pdf" url="https://arxiv.org/pdf/2402.19047v2.pdf" filename="2402.19047v2.pdf">Download PDF</button>

---


**ABSTRACT**  
Structured state-space models (SSMs) such as S4, <b>stemming</b> from the seminal work of Gu et al., are gaining popularity as effective approaches for modeling sequential data. Deep SSMs demonstrate outstanding performance across a diverse set of domains, at a reduced training and inference cost compared to attention-based <b>transformers.</b> Recent developments show that if the linear recurrence powering SSMs allows for multiplicative interactions between inputs and hidden states (e.g. GateLoop, Mamba, GLA), then the resulting architecture can surpass in both in accuracy and efficiency attention-powered <b>foundation</b> <b>models</b> trained on text, at scales of billion parameters. In this paper, we give theoretical <b>grounding</b> to this recent finding using tools from Rough Path Theory: we show that when random linear recurrences are equipped with simple input-controlled transitions (selectivity mechanism), then the hidden state is provably a low-dimensional projection of a powerful mathematical object called the signature of the input -- capturing non-linear interactions between tokens at distinct timescales. Our theory not only motivates the success of modern selective state-space models such as Mamba but also provides a solid framework to understand the expressive power of future SSM variants.

{{</citation>}}


### (13/68 | 138/321) Loss-aware Curriculum Learning for Heterogeneous Graph Neural Networks (Zhen Hao Wong et al., 2024)

{{<citation>}}

Zhen Hao Wong, Hansi Yang, Xiaoyi Fu, Quanming Yao. (2024)  
**Loss-aware Curriculum Learning for Heterogeneous Graph Neural Networks**
<br/>
<button class="copy-to-clipboard" title="Loss-aware Curriculum Learning for Heterogeneous Graph Neural Networks" index=138>
  <span class="copy-to-clipboard-item">Copy Title<span>
</button>
<div class="toast toast-copied toast-index-138 align-items-center text-bg-secondary border-0 position-absolute top-0 end-0" role="alert" aria-live="assertive" aria-atomic="true">
  <div class="d-flex">
    <div class="toast-body">
      Copied!
    </div>
  </div>
</div>

---
Primary Category: cs.LG  
Categories: cs-LG, cs.LG  
Keyword Score: 33  
Keywords: Graph, Graph Neural Network, Graph Neural Network, Curriculum Learning  
<a type="button" class="btn btn-outline-primary" href="http://arxiv.org/abs/2402.18875v1" target="_blank" >Paper Link</a>
<button type="button" class="btn btn-outline-primary download-pdf" url="https://arxiv.org/pdf/2402.18875v1.pdf" filename="2402.18875v1.pdf">Download PDF</button>

---


**ABSTRACT**  
Heterogeneous <b>Graph</b> <b>Neural</b> <b>Networks</b> (HGNNs) are a class of deep learning models designed specifically for heterogeneous <b>graphs,</b> <b>which</b> <b>are</b> <b>graphs</b> <b>that</b> <b>contain</b> different types of nodes and edges. This paper investigates the application of <b>curriculum</b> <b>learning</b> techniques to improve the performance and robustness of Heterogeneous <b>Graph</b> <b>Neural</b> <b>Networks</b> <b>(GNNs).</b> To better classify the quality of the data, we design a loss-aware training schedule, named LTS that measures the quality of every nodes of the data and incorporate the training dataset into the model in a progressive manner that increases difficulty step by step. LTS can be seamlessly integrated into various frameworks, effectively reducing bias and variance, mitigating the impact of noisy data, and enhancing overall accuracy. Our findings demonstrate the efficacy of <b>curriculum</b> <b>learning</b> in enhancing HGNNs capabilities for analyzing complex <b>graph-structured</b> <b>data.</b> <b>The</b> code is public at https: //github.com/LARS-research/CLGNN/.

{{</citation>}}


### (14/68 | 139/321) Training Dynamics of Multi-Head Softmax Attention for In-Context Learning: Emergence, Convergence, and Optimality (Siyu Chen et al., 2024)

{{<citation>}}

Siyu Chen, Heejune Sheen, Tianhao Wang, Zhuoran Yang. (2024)  
**Training Dynamics of Multi-Head Softmax Attention for In-Context Learning: Emergence, Convergence, and Optimality**
<br/>
<button class="copy-to-clipboard" title="Training Dynamics of Multi-Head Softmax Attention for In-Context Learning: Emergence, Convergence, and Optimality" index=139>
  <span class="copy-to-clipboard-item">Copy Title<span>
</button>
<div class="toast toast-copied toast-index-139 align-items-center text-bg-secondary border-0 position-absolute top-0 end-0" role="alert" aria-live="assertive" aria-atomic="true">
  <div class="d-flex">
    <div class="toast-body">
      Copied!
    </div>
  </div>
</div>

---
Primary Category: cs.LG  
Categories: cs-AI, cs-LG, cs.LG, math-OC, math-ST, stat-ML, stat-TH  
Keyword Score: 30  
Keywords: In-context Learning, In-context Learning, In-context Learning  
<a type="button" class="btn btn-outline-primary" href="http://arxiv.org/abs/2402.19442v1" target="_blank" >Paper Link</a>
<button type="button" class="btn btn-outline-primary download-pdf" url="https://arxiv.org/pdf/2402.19442v1.pdf" filename="2402.19442v1.pdf">Download PDF</button>

---


**ABSTRACT**  
We study the dynamics of gradient flow for training a multi-head softmax attention model for <b>in-context</b> <b>learning</b> of multi-task linear regression. We establish the global convergence of gradient flow under suitable choices of initialization. In addition, we prove that an interesting "task allocation" phenomenon emerges during the gradient flow dynamics, where each attention head focuses on solving a single task of the multi-task model. Specifically, we prove that the gradient flow dynamics can be split into three phases -- a warm-up phase where the loss decreases rather slowly and the attention heads gradually build up their inclination towards individual tasks, an emergence phase where each head selects a single task and the loss rapidly decreases, and a convergence phase where the attention parameters converge to a limit. Furthermore, we prove the optimality of gradient flow in the sense that the limiting model learned by gradient flow is on par with the best possible multi-head softmax attention model up to a constant factor. Our analysis also delineates a strict separation in terms of the prediction accuracy of <b>ICL</b> between single-head and multi-head attention models. The key technique for our convergence analysis is to map the gradient flow dynamics in the parameter space to a set of ordinary differential equations in the spectral domain, where the relative magnitudes of the semi-singular values of the attention weights determines task allocation. To our best knowledge, our work provides the first convergence result for the multi-head softmax attention model.

{{</citation>}}


### (15/68 | 140/321) Verification of Neural Networks' Global Robustness (Anan Kabaha et al., 2024)

{{<citation>}}

Anan Kabaha, Dana Drachsler-Cohen. (2024)  
**Verification of Neural Networks' Global Robustness**
<br/>
<button class="copy-to-clipboard" title="Verification of Neural Networks' Global Robustness" index=140>
  <span class="copy-to-clipboard-item">Copy Title<span>
</button>
<div class="toast toast-copied toast-index-140 align-items-center text-bg-secondary border-0 position-absolute top-0 end-0" role="alert" aria-live="assertive" aria-atomic="true">
  <div class="d-flex">
    <div class="toast-body">
      Copied!
    </div>
  </div>
</div>

---
Primary Category: cs.LG  
Categories: cs-CR, cs-LG, cs-PL, cs.LG  
Keyword Score: 30  
Keywords: Pruning, Stemming, Adversarial Attack  
<a type="button" class="btn btn-outline-primary" href="http://arxiv.org/abs/2402.19322v1" target="_blank" >Paper Link</a>
<button type="button" class="btn btn-outline-primary download-pdf" url="https://arxiv.org/pdf/2402.19322v1.pdf" filename="2402.19322v1.pdf">Download PDF</button>

---


**ABSTRACT**  
Neural networks are successful in various applications but are also susceptible to <b>adversarial</b> <b>attacks.</b> To show the safety of network classifiers, many verifiers have been introduced to reason about the local robustness of a given input to a given perturbation. While successful, local robustness cannot generalize to unseen inputs. Several works analyze global robustness properties, however, neither can provide a precise guarantee about the cases where a network classifier does not change its classification. In this work, we propose a new global robustness property for classifiers aiming at finding the minimal globally robust bound, which naturally extends the popular local robustness property for classifiers. We introduce VHAGaR, an anytime verifier for computing this bound. VHAGaR relies on three main ideas: encoding the problem as a mixed-integer programming and <b>pruning</b> the search space by identifying dependencies <b>stemming</b> from the perturbation or network computation and generalizing <b>adversarial</b> <b>attacks</b> to unknown inputs. We evaluate VHAGaR on several datasets and classifiers and show that, given a three hour timeout, the average gap between the lower and upper bound on the minimal globally robust bound computed by VHAGaR is 1.9, while the gap of an existing global robustness verifier is 154.7. Moreover, VHAGaR is 130.6x faster than this verifier. Our results further indicate that leveraging dependencies and <b>adversarial</b> <b>attacks</b> makes VHAGaR 78.6x faster.

{{</citation>}}


### (16/68 | 141/321) Investigating Gender Fairness in Machine Learning-driven Personalized Care for Chronic Pain (Pratik Gajane et al., 2024)

{{<citation>}}

Pratik Gajane, Sean Newman, John D. Piette. (2024)  
**Investigating Gender Fairness in Machine Learning-driven Personalized Care for Chronic Pain**
<br/>
<button class="copy-to-clipboard" title="Investigating Gender Fairness in Machine Learning-driven Personalized Care for Chronic Pain" index=141>
  <span class="copy-to-clipboard-item">Copy Title<span>
</button>
<div class="toast toast-copied toast-index-141 align-items-center text-bg-secondary border-0 position-absolute top-0 end-0" role="alert" aria-live="assertive" aria-atomic="true">
  <div class="d-flex">
    <div class="toast-body">
      Copied!
    </div>
  </div>
</div>

---
Primary Category: cs.LG  
Categories: cs-CY, cs-LG, cs.LG  
Keyword Score: 30  
Keywords: Bandit Algorithm, Fairness, Recommendation  
<a type="button" class="btn btn-outline-primary" href="http://arxiv.org/abs/2402.19226v1" target="_blank" >Paper Link</a>
<button type="button" class="btn btn-outline-primary download-pdf" url="https://arxiv.org/pdf/2402.19226v1.pdf" filename="2402.19226v1.pdf">Download PDF</button>

---


**ABSTRACT**  
This study investigates gender <b>fairness</b> in personalized pain care <b>recommendations</b> using machine learning algorithms. Leveraging a contextual <b>bandits</b> framework, personalized <b>recommendations</b> are formulated and evaluated using LinUCB algorithm on a dataset comprising interactions with $164$ patients across $10$ sessions each. Results indicate that while adjustments to algorithm parameters influence the quality of pain care <b>recommendations,</b> this impact remains consistent across genders. However, when certain patient information, such as self-reported pain measurements, is absent, the quality of pain care <b>recommendations</b> for women is notably inferior to that for men.

{{</citation>}}


### (17/68 | 142/321) CollaFuse: Navigating Limited Resources and Privacy in Collaborative Generative AI (Domenique Zipperling et al., 2024)

{{<citation>}}

Domenique Zipperling, Simeon Allmendinger, Lukas Struppek, Niklas Kühl. (2024)  
**CollaFuse: Navigating Limited Resources and Privacy in Collaborative Generative AI**
<br/>
<button class="copy-to-clipboard" title="CollaFuse: Navigating Limited Resources and Privacy in Collaborative Generative AI" index=142>
  <span class="copy-to-clipboard-item">Copy Title<span>
</button>
<div class="toast toast-copied toast-index-142 align-items-center text-bg-secondary border-0 position-absolute top-0 end-0" role="alert" aria-live="assertive" aria-atomic="true">
  <div class="d-flex">
    <div class="toast-body">
      Copied!
    </div>
  </div>
</div>

---
Primary Category: cs.LG  
Categories: cs-AI, cs-LG, cs.LG  
Keyword Score: 30  
Keywords: Federated Learning, Generative AI, Probabilistic Model  
<a type="button" class="btn btn-outline-primary" href="http://arxiv.org/abs/2402.19105v1" target="_blank" >Paper Link</a>
<button type="button" class="btn btn-outline-primary download-pdf" url="https://arxiv.org/pdf/2402.19105v1.pdf" filename="2402.19105v1.pdf">Download PDF</button>

---


**ABSTRACT**  
In the landscape of <b>generative</b> <b>artificial</b> intelligence, diffusion-based models present challenges for socio-technical systems in data requirements and privacy. Traditional approaches like <b>federated</b> <b>learning</b> distribute the learning process but strain individual clients, especially with constrained resources (e.g., edge devices). In response to these challenges, we introduce CollaFuse, a novel framework inspired by split learning. Tailored for efficient and collaborative use of denoising diffusion <b>probabilistic</b> <b>models,</b> CollaFuse enables shared server training and inference, alleviating client computational burdens. This is achieved by retaining data and computationally inexpensive GPU processes locally at each client while outsourcing the computationally expensive processes to the shared server. Demonstrated in a healthcare context, CollaFuse enhances privacy by highly reducing the need for sensitive information sharing. These capabilities hold the potential to impact various application areas, such as the design of edge computing solutions, healthcare research, or autonomous driving. In essence, our work advances distributed machine learning, shaping the future of collaborative GenAI networks.

{{</citation>}}


### (18/68 | 143/321) Global and Local Prompts Cooperation via Optimal Transport for Federated Learning (Hongxia Li et al., 2024)

{{<citation>}}

Hongxia Li, Wei Huang, Jingya Wang, Ye Shi. (2024)  
**Global and Local Prompts Cooperation via Optimal Transport for Federated Learning**
<br/>
<button class="copy-to-clipboard" title="Global and Local Prompts Cooperation via Optimal Transport for Federated Learning" index=143>
  <span class="copy-to-clipboard-item">Copy Title<span>
</button>
<div class="toast toast-copied toast-index-143 align-items-center text-bg-secondary border-0 position-absolute top-0 end-0" role="alert" aria-live="assertive" aria-atomic="true">
  <div class="d-flex">
    <div class="toast-body">
      Copied!
    </div>
  </div>
</div>

---
Primary Category: cs.LG  
Categories: cs-AI, cs-DC, cs-LG, cs.LG  
Keyword Score: 30  
Keywords: Federated Learning, Prompt, Prompt Learning  
<a type="button" class="btn btn-outline-primary" href="http://arxiv.org/abs/2403.00041v1" target="_blank" >Paper Link</a>
<button type="button" class="btn btn-outline-primary download-pdf" url="https://arxiv.org/pdf/2403.00041v1.pdf" filename="2403.00041v1.pdf">Download PDF</button>

---


**ABSTRACT**  
<b>Prompt</b> <b>learning</b> in pretrained visual-language models has shown remarkable flexibility across various downstream tasks. Leveraging its inherent lightweight nature, recent research attempted to integrate the powerful pretrained models into <b>federated</b> <b>learning</b> frameworks to simultaneously reduce communication costs and promote local training on insufficient data. Despite these efforts, current <b>federated</b> <b>prompt</b> <b>learning</b> methods lack specialized designs to systematically address severe data heterogeneities, e.g., data distribution with both label and feature shifts involved. To address this challenge, we present <b>Federated</b> <b>Prompts</b> <b>Cooperation</b> via Optimal Transport (FedOTP), which introduces efficient collaborative <b>prompt</b> <b>learning</b> strategies to capture diverse category traits on a per-client basis. Specifically, for each client, we learn a global <b>prompt</b> <b>to</b> extract consensus knowledge among clients, and a local <b>prompt</b> <b>to</b> capture client-specific category characteristics. Unbalanced Optimal Transport is then employed to align local visual features with these <b>prompts,</b> <b>striking</b> a balance between global consensus and local personalization. Extensive experiments on datasets with various types of heterogeneities have demonstrated that our FedOTP outperforms the state-of-the-art methods.

{{</citation>}}


### (19/68 | 144/321) Improving Group Connectivity for Generalization of Federated Deep Learning (Zexi Li et al., 2024)

{{<citation>}}

Zexi Li, Jie Lin, Zhiqi Li, Didi Zhu, Chao Wu. (2024)  
**Improving Group Connectivity for Generalization of Federated Deep Learning**
<br/>
<button class="copy-to-clipboard" title="Improving Group Connectivity for Generalization of Federated Deep Learning" index=144>
  <span class="copy-to-clipboard-item">Copy Title<span>
</button>
<div class="toast toast-copied toast-index-144 align-items-center text-bg-secondary border-0 position-absolute top-0 end-0" role="alert" aria-live="assertive" aria-atomic="true">
  <div class="d-flex">
    <div class="toast-body">
      Copied!
    </div>
  </div>
</div>

---
Primary Category: cs.LG  
Categories: cs-LG, cs.LG  
Keyword Score: 30  
Keywords: Convolution, Federated Learning, Transformer  
<a type="button" class="btn btn-outline-primary" href="http://arxiv.org/abs/2402.18949v1" target="_blank" >Paper Link</a>
<button type="button" class="btn btn-outline-primary download-pdf" url="https://arxiv.org/pdf/2402.18949v1.pdf" filename="2402.18949v1.pdf">Download PDF</button>

---


**ABSTRACT**  
<b>Federated</b> <b>learning</b> (FL) involves multiple heterogeneous clients collaboratively training a global model via iterative local updates and model fusion. The generalization of FL's global model has a large gap compared with centralized training, which is its bottleneck for broader applications. In this paper, we study and improve FL's generalization through a fundamental ``connectivity'' perspective, which means how the local models are connected in the parameter region and fused into a generalized global model. The term ``connectivity'' is derived from linear mode connectivity (LMC), studying the interpolated loss landscape of two different solutions (e.g., modes) of neural networks. Bridging the gap between LMC and FL, in this paper, we leverage fixed anchor models to empirically and theoretically study the transitivity property of connectivity from two models (LMC) to a group of models (model fusion in FL). Based on the findings, we propose FedGuCci and FedGuCci+, improving group connectivity for better generalization. It is shown that our methods can boost the generalization of FL under client heterogeneity across various tasks (4 CV datasets and 6 NLP datasets), models (both <b>convolutional</b> and <b>transformer-based),</b> and training paradigms (both from-scratch and pretrain-finetune).

{{</citation>}}


### (20/68 | 145/321) Real-Time Adaptive Safety-Critical Control with Gaussian Processes in High-Order Uncertain Models (Yu Zhang et al., 2024)

{{<citation>}}

Yu Zhang, Long Wen, Xiangtong Yao, Zhenshan Bing, Linghuan Kong, Wei He, Alois Knoll. (2024)  
**Real-Time Adaptive Safety-Critical Control with Gaussian Processes in High-Order Uncertain Models**
<br/>
<button class="copy-to-clipboard" title="Real-Time Adaptive Safety-Critical Control with Gaussian Processes in High-Order Uncertain Models" index=145>
  <span class="copy-to-clipboard-item">Copy Title<span>
</button>
<div class="toast toast-copied toast-index-145 align-items-center text-bg-secondary border-0 position-absolute top-0 end-0" role="alert" aria-live="assertive" aria-atomic="true">
  <div class="d-flex">
    <div class="toast-body">
      Copied!
    </div>
  </div>
</div>

---
Primary Category: cs.LG  
Categories: cs-LG, cs-SY, cs.LG, eess-SY  
Keyword Score: 30  
Keywords: Gaussian Process, Simulation, Simulator  
<a type="button" class="btn btn-outline-primary" href="http://arxiv.org/abs/2402.18946v2" target="_blank" >Paper Link</a>
<button type="button" class="btn btn-outline-primary download-pdf" url="https://arxiv.org/pdf/2402.18946v2.pdf" filename="2402.18946v2.pdf">Download PDF</button>

---


**ABSTRACT**  
This paper presents an adaptive online learning framework for systems with uncertain parameters to ensure safety-critical control in non-stationary environments. Our approach consists of two phases. The initial phase is centered on a novel sparse <b>Gaussian</b> <b>process</b> (GP) framework. We first integrate a forgetting factor to refine a variational sparse GP algorithm, thus enhancing its adaptability. Subsequently, the hyperparameters of the <b>Gaussian</b> <b>model</b> are trained with a specially compound kernel, and the <b>Gaussian</b> <b>model's</b> online inferential capability and computational efficiency are strengthened by updating a solitary inducing point derived from new samples, in conjunction with the learned hyperparameters. In the second phase, we propose a safety filter based on high-order control barrier functions (HOCBFs), synergized with the previously trained learning model. By leveraging the compound kernel from the first phase, we effectively address the inherent limitations of GPs in handling high-dimensional problems for real-time applications. The derived controller ensures a rigorous lower bound on the probability of satisfying the safety specification. Finally, the efficacy of our proposed algorithm is demonstrated through real-time obstacle avoidance experiments executed using both a <b>simulation</b> platform and a real-world 7-DOF robot.

{{</citation>}}


### (21/68 | 146/321) BP-DeepONet: A new method for cuffless blood pressure estimation using the physcis-informed DeepONet (Lingfeng Li et al., 2024)

{{<citation>}}

Lingfeng Li, Xue-Cheng Tai, Raymond Chan. (2024)  
**BP-DeepONet: A new method for cuffless blood pressure estimation using the physcis-informed DeepONet**
<br/>
<button class="copy-to-clipboard" title="BP-DeepONet: A new method for cuffless blood pressure estimation using the physcis-informed DeepONet" index=146>
  <span class="copy-to-clipboard-item">Copy Title<span>
</button>
<div class="toast toast-copied toast-index-146 align-items-center text-bg-secondary border-0 position-absolute top-0 end-0" role="alert" aria-live="assertive" aria-atomic="true">
  <div class="d-flex">
    <div class="toast-body">
      Copied!
    </div>
  </div>
</div>

---
Primary Category: cs.LG  
Categories: cs-LG, cs.LG, physics-med-ph  
Keyword Score: 30  
Keywords: Meta Learning, Simulation, Simulator  
<a type="button" class="btn btn-outline-primary" href="http://arxiv.org/abs/2402.18886v1" target="_blank" >Paper Link</a>
<button type="button" class="btn btn-outline-primary download-pdf" url="https://arxiv.org/pdf/2402.18886v1.pdf" filename="2402.18886v1.pdf">Download PDF</button>

---


**ABSTRACT**  
Cardiovascular diseases (CVDs) are the leading cause of death worldwide, with blood pressure serving as a crucial indicator. Arterial blood pressure (ABP) waveforms provide continuous pressure measurements throughout the cardiac cycle and offer valuable diagnostic insights. Consequently, there is a significant demand for non-invasive and cuff-less methods to measure ABP waveforms continuously. Accurate prediction of ABP waveforms can also improve the estimation of mean blood pressure, an essential cardiovascular health characteristic. This study proposes a novel framework based on the physics-informed DeepONet approach to predict ABP waveforms. Unlike previous methods, our approach requires the predicted ABP waveforms to satisfy the Navier-Stokes equation with a time-periodic condition and a Windkessel boundary condition. Notably, our framework is the first to predict ABP waveforms continuously, both with location and time, within the part of the artery that is being simulated. Furthermore, our method only requires ground truth data at the outlet boundary and can handle periodic conditions with varying periods. Incorporating the Windkessel boundary condition in our solution allows for generating natural physical reflection waves, which closely resemble measurements observed in real-world cases. Moreover, accurately estimating the hyper-parameters in the Navier-Stokes equation for our <b>simulations</b> poses a significant challenge. To overcome this obstacle, we introduce the concept of <b>meta-learning,</b> <b>enabling</b> the neural networks to learn these parameters during the training process.

{{</citation>}}


### (22/68 | 147/321) StiefelGen: A Simple, Model Agnostic Approach for Time Series Data Augmentation over Riemannian Manifolds (Prasad Cheema et al., 2024)

{{<citation>}}

Prasad Cheema, Mahito Sugiyama. (2024)  
**StiefelGen: A Simple, Model Agnostic Approach for Time Series Data Augmentation over Riemannian Manifolds**
<br/>
<button class="copy-to-clipboard" title="StiefelGen: A Simple, Model Agnostic Approach for Time Series Data Augmentation over Riemannian Manifolds" index=147>
  <span class="copy-to-clipboard-item">Copy Title<span>
</button>
<div class="toast toast-copied toast-index-147 align-items-center text-bg-secondary border-0 position-absolute top-0 end-0" role="alert" aria-live="assertive" aria-atomic="true">
  <div class="d-flex">
    <div class="toast-body">
      Copied!
    </div>
  </div>
</div>

---
Primary Category: cs.LG  
Categories: cs-LG, cs.LG  
Keyword Score: 25  
Keywords: Data Augmentation, Geometry, Reinforcement Learning  
<a type="button" class="btn btn-outline-primary" href="http://arxiv.org/abs/2402.19287v1" target="_blank" >Paper Link</a>
<button type="button" class="btn btn-outline-primary download-pdf" url="https://arxiv.org/pdf/2402.19287v1.pdf" filename="2402.19287v1.pdf">Download PDF</button>

---


**ABSTRACT**  
<b>Data</b> <b>augmentation</b> is an area of research which has seen active development in many machine learning fields, such as in image-based learning models, <b>reinforcement</b> <b>learning</b> for self driving vehicles, and general noise injection for point cloud <b>data.</b> <b>However,</b> convincing methods for general time series <b>data</b> <b>augmentation</b> still leaves much to be desired, especially since the methods developed for these models do not readily cross-over. Three common approaches for time series <b>data</b> <b>augmentation</b> include: (i) Constructing a physics-based model and then imbuing uncertainty over the coefficient space (for example), (ii) Adding noise to the observed <b>data</b> <b>set(s),</b> and, (iii) Having access to ample amounts of time series <b>data</b> <b>sets</b> from which a robust generative neural network model can be trained. However, for many practical problems that work with time series <b>data</b> <b>in</b> the industry: (i) One usually does not have access to a robust physical model, (ii) The addition of noise can in of itself require large or difficult assumptions (for example, what probability distribution should be used? Or, how large should the noise variance be?), and, (iii) In practice, it can be difficult to source a large representative time series <b>data</b> <b>base</b> with which to train the neural network model for the underlying problem. In this paper, we propose a methodology which attempts to simultaneously tackle all three of these previous limitations to a large extent. The method relies upon the well-studied matrix differential <b>geometry</b> of the Stiefel manifold, as it proposes a simple way in which time series signals can placed on, and then smoothly perturbed over the manifold. We attempt to clarify how this method works by showcasing several potential use cases which in particular work to take advantage of the unique properties of this underlying manifold.

{{</citation>}}


### (23/68 | 148/321) Impact of Decentralized Learning on Player Utilities in Stackelberg Games (Kate Donahue et al., 2024)

{{<citation>}}

Kate Donahue, Nicole Immorlica, Meena Jagadeesan, Brendan Lucier, Aleksandrs Slivkins. (2024)  
**Impact of Decentralized Learning on Player Utilities in Stackelberg Games**
<br/>
<button class="copy-to-clipboard" title="Impact of Decentralized Learning on Player Utilities in Stackelberg Games" index=148>
  <span class="copy-to-clipboard-item">Copy Title<span>
</button>
<div class="toast toast-copied toast-index-148 align-items-center text-bg-secondary border-0 position-absolute top-0 end-0" role="alert" aria-live="assertive" aria-atomic="true">
  <div class="d-flex">
    <div class="toast-body">
      Copied!
    </div>
  </div>
</div>

---
Primary Category: cs.LG  
Categories: cs-GT, cs-LG, cs.LG  
Keyword Score: 23  
Keywords: Benchmarking, Recommender System, Chatbot  
<a type="button" class="btn btn-outline-primary" href="http://arxiv.org/abs/2403.00188v1" target="_blank" >Paper Link</a>
<button type="button" class="btn btn-outline-primary download-pdf" url="https://arxiv.org/pdf/2403.00188v1.pdf" filename="2403.00188v1.pdf">Download PDF</button>

---


**ABSTRACT**  
When deployed in the world, a learning agent such as a <b>recommender</b> <b>system</b> or a <b>chatbot</b> often repeatedly interacts with another learning agent (such as a user) over time. In many such two-agent systems, each agent learns separately and the rewards of the two agents are not perfectly aligned. To better understand such cases, we examine the learning dynamics of the two-agent system and the implications for each agent's objective. We model these systems as Stackelberg games with decentralized learning and show that standard regret <b>benchmarks</b> (such as Stackelberg equilibrium payoffs) result in worst-case linear regret for at least one player. To better capture these systems, we construct a relaxed regret <b>benchmark</b> that is tolerant to small learning errors by agents. We show that standard learning algorithms fail to provide sublinear regret, and we develop algorithms to achieve near-optimal $O(T^{2/3})$ regret for both players with respect to these <b>benchmarks.</b> We further design relaxed environments under which faster learning ($O(\sqrt{T})$) is possible. Altogether, our results take a step towards assessing how two-agent interactions in sequential and decentralized learning environments affect the utility of both agents.

{{</citation>}}


### (24/68 | 149/321) On the Convergence of Federated Learning Algorithms without Data Similarity (Ali Beikmohammadi et al., 2024)

{{<citation>}}

Ali Beikmohammadi, Sarit Khirirat, Sindri Magnússon. (2024)  
**On the Convergence of Federated Learning Algorithms without Data Similarity**
<br/>
<button class="copy-to-clipboard" title="On the Convergence of Federated Learning Algorithms without Data Similarity" index=149>
  <span class="copy-to-clipboard-item">Copy Title<span>
</button>
<div class="toast toast-copied toast-index-149 align-items-center text-bg-secondary border-0 position-absolute top-0 end-0" role="alert" aria-live="assertive" aria-atomic="true">
  <div class="d-flex">
    <div class="toast-body">
      Copied!
    </div>
  </div>
</div>

---
Primary Category: cs.LG  
Categories: cs-GT, cs-LG, cs.LG  
Keyword Score: 23  
Keywords: Benchmarking, Federated Learning, Fine-tuning  
<a type="button" class="btn btn-outline-primary" href="http://arxiv.org/abs/2403.02347v1" target="_blank" >Paper Link</a>
<button type="button" class="btn btn-outline-primary download-pdf" url="https://arxiv.org/pdf/2403.02347v1.pdf" filename="2403.02347v1.pdf">Download PDF</button>

---


**ABSTRACT**  
Data similarity assumptions have traditionally been relied upon to understand the convergence behaviors of <b>federated</b> <b>learning</b> methods. Unfortunately, this approach often demands <b>fine-tuning</b> step sizes based on the level of data similarity. When data similarity is low, these small step sizes result in an unacceptably slow convergence speed for <b>federated</b> <b>methods.</b> In this paper, we present a novel and unified framework for analyzing the convergence of <b>federated</b> <b>learning</b> algorithms without the need for data similarity conditions. Our analysis centers on an inequality that captures the influence of step sizes on algorithmic convergence performance. By applying our theorems to well-known <b>federated</b> <b>algorithms,</b> we derive precise expressions for three widely used step size schedules: fixed, diminishing, and step-decay step sizes, which are independent of data similarity conditions. Finally, we conduct comprehensive evaluations of the performance of these <b>federated</b> <b>learning</b> algorithms, employing the proposed step size strategies to train deep neural network models on <b>benchmark</b> datasets under varying data similarity conditions. Our findings demonstrate significant improvements in convergence speed and overall performance, marking a substantial advancement in <b>federated</b> <b>learning</b> research.

{{</citation>}}


### (25/68 | 150/321) Towards Explaining Deep Neural Network Compression Through a Probabilistic Latent Space (Mahsa Mozafari-Nia et al., 2024)

{{<citation>}}

Mahsa Mozafari-Nia, Salimeh Yasaei Sekeh. (2024)  
**Towards Explaining Deep Neural Network Compression Through a Probabilistic Latent Space**
<br/>
<button class="copy-to-clipboard" title="Towards Explaining Deep Neural Network Compression Through a Probabilistic Latent Space" index=150>
  <span class="copy-to-clipboard-item">Copy Title<span>
</button>
<div class="toast toast-copied toast-index-150 align-items-center text-bg-secondary border-0 position-absolute top-0 end-0" role="alert" aria-live="assertive" aria-atomic="true">
  <div class="d-flex">
    <div class="toast-body">
      Copied!
    </div>
  </div>
</div>

---
Primary Category: cs.LG  
Categories: cs-LG, cs.LG  
Keyword Score: 23  
Keywords: Benchmarking, Fine-tuning, Pruning  
<a type="button" class="btn btn-outline-primary" href="http://arxiv.org/abs/2403.00155v1" target="_blank" >Paper Link</a>
<button type="button" class="btn btn-outline-primary download-pdf" url="https://arxiv.org/pdf/2403.00155v1.pdf" filename="2403.00155v1.pdf">Download PDF</button>

---


**ABSTRACT**  
Despite the impressive performance of deep neural networks (DNNs), their computational complexity and storage space consumption have led to the concept of network compression. While DNN compression techniques such as <b>pruning</b> and low-rank decomposition have been extensively studied, there has been insufficient attention paid to their theoretical explanation. In this paper, we propose a novel theoretical framework that leverages a probabilistic latent space of DNN weights and explains the optimal network sparsity by using the information-theoretic divergence measures. We introduce new analogous projected patterns (AP2) and analogous-in-probability projected patterns (AP3) notions for DNNs and prove that there exists a relationship between AP3/AP2 property of layers in the network and its performance. Further, we provide a theoretical analysis that explains the training process of the compressed network. The theoretical results are empirically validated through experiments conducted on standard pre-trained <b>benchmarks,</b> including AlexNet, ResNet50, and VGG16, using CIFAR10 and CIFAR100 datasets. Through our experiments, we highlight the relationship of AP3 and AP2 properties with <b>fine-tuning</b> pruned DNNs and sparsity levels.

{{</citation>}}


### (26/68 | 151/321) Deep Learning for Cross-Domain Data Fusion in Urban Computing: Taxonomy, Advances, and Outlook (Xingchen Zou et al., 2024)

{{<citation>}}

Xingchen Zou, Yibo Yan, Xixuan Hao, Yuehong Hu, Haomin Wen, Erdong Liu, Junbo Zhang, Yong Li, Tianrui Li, Yu Zheng, Yuxuan Liang. (2024)  
**Deep Learning for Cross-Domain Data Fusion in Urban Computing: Taxonomy, Advances, and Outlook**
<br/>
<button class="copy-to-clipboard" title="Deep Learning for Cross-Domain Data Fusion in Urban Computing: Taxonomy, Advances, and Outlook" index=151>
  <span class="copy-to-clipboard-item">Copy Title<span>
</button>
<div class="toast toast-copied toast-index-151 align-items-center text-bg-secondary border-0 position-absolute top-0 end-0" role="alert" aria-live="assertive" aria-atomic="true">
  <div class="d-flex">
    <div class="toast-body">
      Copied!
    </div>
  </div>
</div>

---
Primary Category: cs.LG  
Categories: cs-AI, cs-LG, cs.LG  
Keyword Score: 23  
Keywords: Multi-modal, Large Language Model, Large Language Model  
<a type="button" class="btn btn-outline-primary" href="http://arxiv.org/abs/2402.19348v1" target="_blank" >Paper Link</a>
<button type="button" class="btn btn-outline-primary download-pdf" url="https://arxiv.org/pdf/2402.19348v1.pdf" filename="2402.19348v1.pdf">Download PDF</button>

---


**ABSTRACT**  
As cities continue to burgeon, Urban Computing emerges as a pivotal discipline for sustainable development by harnessing the power of cross-domain data fusion from diverse sources (e.g., geographical, traffic, social media, and environmental data) and modalities (e.g., spatio-temporal, visual, and textual modalities). Recently, we are witnessing a rising trend that utilizes various deep-learning methods to facilitate cross-domain data fusion in smart cities. To this end, we propose the first survey that systematically reviews the latest advancements in deep learning-based data fusion methods tailored for urban computing. Specifically, we first delve into data perspective to comprehend the role of each modality and data source. Secondly, we classify the methodology into four primary categories: feature-based, alignment-based, contrast-based, and generation-based fusion methods. Thirdly, we further categorize <b>multi-modal</b> urban applications into seven types: urban planning, transportation, economy, public safety, society, environment, and energy. Compared with previous surveys, we focus more on the synergy of deep learning methods with urban computing applications. Furthermore, we shed light on the interplay between <b>Large</b> <b>Language</b> <b>Models</b> <b>(LLMs)</b> and urban computing, postulating future research directions that could revolutionize the field. We firmly believe that the taxonomy, progress, and prospects delineated in our survey stand poised to significantly enrich the research community. The summary of the comprehensive and up-to-date paper list can be found at https://github.com/yoshall/Awesome-Multimodal-Urban-Computing.

{{</citation>}}


### (27/68 | 152/321) FedStruct: Federated Decoupled Learning over Interconnected Graphs (Javad Aliakbari et al., 2024)

{{<citation>}}

Javad Aliakbari, Johan Östman, Alexandre Graell i Amat. (2024)  
**FedStruct: Federated Decoupled Learning over Interconnected Graphs**
<br/>
<button class="copy-to-clipboard" title="FedStruct: Federated Decoupled Learning over Interconnected Graphs" index=152>
  <span class="copy-to-clipboard-item">Copy Title<span>
</button>
<div class="toast toast-copied toast-index-152 align-items-center text-bg-secondary border-0 position-absolute top-0 end-0" role="alert" aria-live="assertive" aria-atomic="true">
  <div class="d-flex">
    <div class="toast-body">
      Copied!
    </div>
  </div>
</div>

---
Primary Category: cs.LG  
Categories: cs-IT, cs-LG, cs.LG, math-IT  
Keyword Score: 23  
Keywords: Node Classification, Graph, Federated Learning  
<a type="button" class="btn btn-outline-primary" href="http://arxiv.org/abs/2402.19163v1" target="_blank" >Paper Link</a>
<button type="button" class="btn btn-outline-primary download-pdf" url="https://arxiv.org/pdf/2402.19163v1.pdf" filename="2402.19163v1.pdf">Download PDF</button>

---


**ABSTRACT**  
We address the challenge of <b>federated</b> <b>learning</b> on <b>graph-structured</b> data distributed across multiple clients. Specifically, we focus on the prevalent scenario of interconnected subgraphs, where inter-connections between different clients play a critical role. We present a novel framework for this scenario, named FedStruct, that harnesses deep structural dependencies. To uphold privacy, unlike existing methods, FedStruct eliminates the necessity of sharing or generating sensitive <b>node</b> <b>features</b> or embeddings among clients. Instead, it leverages explicit global <b>graph</b> structure information to capture inter-node dependencies. We validate the effectiveness of FedStruct through experimental results conducted on six datasets for semi-supervised <b>node</b> <b>classification,</b> showcasing performance close to the centralized approach across various scenarios, including different data partitioning methods, varying levels of label availability, and number of clients.

{{</citation>}}


### (28/68 | 153/321) TimeXer: Empowering Transformers for Time Series Forecasting with Exogenous Variables (Yuxuan Wang et al., 2024)

{{<citation>}}

Yuxuan Wang, Haixu Wu, Jiaxiang Dong, Yong Liu, Yunzhong Qiu, Haoran Zhang, Jianmin Wang, Mingsheng Long. (2024)  
**TimeXer: Empowering Transformers for Time Series Forecasting with Exogenous Variables**
<br/>
<button class="copy-to-clipboard" title="TimeXer: Empowering Transformers for Time Series Forecasting with Exogenous Variables" index=153>
  <span class="copy-to-clipboard-item">Copy Title<span>
</button>
<div class="toast toast-copied toast-index-153 align-items-center text-bg-secondary border-0 position-absolute top-0 end-0" role="alert" aria-live="assertive" aria-atomic="true">
  <div class="d-flex">
    <div class="toast-body">
      Copied!
    </div>
  </div>
</div>

---
Primary Category: cs.LG  
Categories: cs-AI, cs-LG, cs.LG  
Keyword Score: 23  
Keywords: Benchmarking, Transformer, Self-Attention  
<a type="button" class="btn btn-outline-primary" href="http://arxiv.org/abs/2402.19072v1" target="_blank" >Paper Link</a>
<button type="button" class="btn btn-outline-primary download-pdf" url="https://arxiv.org/pdf/2402.19072v1.pdf" filename="2402.19072v1.pdf">Download PDF</button>

---


**ABSTRACT**  
Recent studies have demonstrated remarkable performance in time series forecasting. However, due to the partially-observed nature of real-world applications, solely focusing on the target of interest, so-called endogenous variables, is usually insufficient to guarantee accurate forecasting. Notably, a system is often recorded into multiple variables, where the exogenous series can provide valuable external information for endogenous variables. Thus, unlike prior well-established multivariate or univariate forecasting that either treats all the variables equally or overlooks exogenous information, this paper focuses on a practical setting, which is time series forecasting with exogenous variables. We propose a novel framework, TimeXer, to utilize external information to enhance the forecasting of endogenous variables. With a deftly designed embedding layer, TimeXer empowers the canonical <b>Transformer</b> architecture with the ability to reconcile endogenous and exogenous information, where patch-wise <b>self-attention</b> and variate-wise cross-attention are employed. Moreover, a global endogenous variate token is adopted to effectively bridge the exogenous series into endogenous temporal patches. Experimentally, TimeXer significantly improves time series forecasting with exogenous variables and achieves consistent state-of-the-art performance in twelve real-world forecasting <b>benchmarks.</b>

{{</citation>}}


### (29/68 | 154/321) To Pool or Not To Pool: Analyzing the Regularizing Effects of Group-Fair Training on Shared Models (Cyrus Cousins et al., 2024)

{{<citation>}}

Cyrus Cousins, I. Elizabeth Kumar, Suresh Venkatasubramanian. (2024)  
**To Pool or Not To Pool: Analyzing the Regularizing Effects of Group-Fair Training on Shared Models**
<br/>
<button class="copy-to-clipboard" title="To Pool or Not To Pool: Analyzing the Regularizing Effects of Group-Fair Training on Shared Models" index=154>
  <span class="copy-to-clipboard-item">Copy Title<span>
</button>
<div class="toast toast-copied toast-index-154 align-items-center text-bg-secondary border-0 position-absolute top-0 end-0" role="alert" aria-live="assertive" aria-atomic="true">
  <div class="d-flex">
    <div class="toast-body">
      Copied!
    </div>
  </div>
</div>

---
Primary Category: cs.LG  
Categories: cs-CY, cs-LG, cs.LG  
Keyword Score: 23  
Keywords: Sample Size, Simulation, Simulator  
<a type="button" class="btn btn-outline-primary" href="http://arxiv.org/abs/2402.18803v1" target="_blank" >Paper Link</a>
<button type="button" class="btn btn-outline-primary download-pdf" url="https://arxiv.org/pdf/2402.18803v1.pdf" filename="2402.18803v1.pdf">Download PDF</button>

---


**ABSTRACT**  
In fair machine learning, one source of performance disparities between groups is over-fitting to groups with relatively few training <b>samples.</b> <b>We</b> derive group-specific bounds on the generalization error of welfare-centric fair machine learning that benefit from the larger <b>sample</b> <b>size</b> of the majority group. We do this by considering group-specific Rademacher averages over a restricted hypothesis class, which contains the family of models likely to perform well with respect to a fair learning objective (e.g., a power-mean). Our <b>simulations</b> demonstrate these bounds improve over a naive method, as expected by theory, with particularly significant improvement for smaller group sizes.

{{</citation>}}


### (30/68 | 155/321) MPAT: Building Robust Deep Neural Networks against Textual Adversarial Attacks (Fangyuan Zhang et al., 2024)

{{<citation>}}

Fangyuan Zhang, Huichi Zhou, Shuangjiao Li, Hongtao Wang. (2024)  
**MPAT: Building Robust Deep Neural Networks against Textual Adversarial Attacks**
<br/>
<button class="copy-to-clipboard" title="MPAT: Building Robust Deep Neural Networks against Textual Adversarial Attacks" index=155>
  <span class="copy-to-clipboard-item">Copy Title<span>
</button>
<div class="toast toast-copied toast-index-155 align-items-center text-bg-secondary border-0 position-absolute top-0 end-0" role="alert" aria-live="assertive" aria-atomic="true">
  <div class="d-flex">
    <div class="toast-body">
      Copied!
    </div>
  </div>
</div>

---
Primary Category: cs.LG  
Categories: cs-CL, cs-CR, cs-LG, cs.LG  
Keyword Score: 23  
Keywords: Adversarial Learning, Benchmarking, Adversarial Attack  
<a type="button" class="btn btn-outline-primary" href="http://arxiv.org/abs/2402.18792v1" target="_blank" >Paper Link</a>
<button type="button" class="btn btn-outline-primary download-pdf" url="https://arxiv.org/pdf/2402.18792v1.pdf" filename="2402.18792v1.pdf">Download PDF</button>

---


**ABSTRACT**  
Deep neural networks have been proven to be vulnerable to <b>adversarial</b> <b>examples</b> and various methods have been proposed to defend against <b>adversarial</b> <b>attacks</b> for natural language processing tasks. However, previous defense methods have limitations in maintaining effective defense while ensuring the performance of the original task. In this paper, we propose a malicious perturbation based <b>adversarial</b> <b>training</b> method (MPAT) for building robust deep neural networks against textual <b>adversarial</b> <b>attacks.</b> Specifically, we construct a multi-level malicious example generation strategy to generate <b>adversarial</b> <b>examples</b> with malicious perturbations, which are used instead of original inputs for model training. Additionally, we employ a novel training objective function to ensure achieving the defense goal without compromising the performance on the original task. We conduct comprehensive experiments to evaluate our defense method by attacking five victim models on three <b>benchmark</b> datasets. The result demonstrates that our method is more effective against malicious <b>adversarial</b> <b>attacks</b> compared with previous defense methods while maintaining or further improving the performance on the original task.

{{</citation>}}


### (31/68 | 156/321) Ask Your Distribution Shift if Pre-Training is Right for You (Benjamin Cohen-Wang et al., 2024)

{{<citation>}}

Benjamin Cohen-Wang, Joshua Vendrow, Aleksander Madry. (2024)  
**Ask Your Distribution Shift if Pre-Training is Right for You**
<br/>
<button class="copy-to-clipboard" title="Ask Your Distribution Shift if Pre-Training is Right for You" index=156>
  <span class="copy-to-clipboard-item">Copy Title<span>
</button>
<div class="toast toast-copied toast-index-156 align-items-center text-bg-secondary border-0 position-absolute top-0 end-0" role="alert" aria-live="assertive" aria-atomic="true">
  <div class="d-flex">
    <div class="toast-body">
      Copied!
    </div>
  </div>
</div>

---
Primary Category: cs.LG  
Categories: cs-LG, cs.LG  
Keyword Score: 20  
Keywords: Distribution Shift, Distribution Shift, Fine-tuning  
<a type="button" class="btn btn-outline-primary" href="http://arxiv.org/abs/2403.00194v1" target="_blank" >Paper Link</a>
<button type="button" class="btn btn-outline-primary download-pdf" url="https://arxiv.org/pdf/2403.00194v1.pdf" filename="2403.00194v1.pdf">Download PDF</button>

---


**ABSTRACT**  
Pre-training is a widely used approach to develop models that are robust to <b>distribution</b> <b>shifts.</b> However, in practice, its effectiveness varies: <b>fine-tuning</b> a pre-trained model improves robustness significantly in some cases but not at all in others (compared to training from scratch). In this work, we seek to characterize the failure modes that pre-training can and cannot address. In particular, we focus on two possible failure modes of models under <b>distribution</b> <b>shift:</b> poor extrapolation (e.g., they cannot generalize to a different domain) and biases in the training data (e.g., they rely on spurious features). Our study suggests that, as a rule of thumb, pre-training can help mitigate poor extrapolation but not dataset biases. After providing theoretical motivation and empirical evidence for this finding, we explore two of its implications for developing robust models: (1) pre-training and interventions designed to prevent exploiting biases have complementary robustness benefits, and (2) <b>fine-tuning</b> on a (very) small, non-diverse but de-biased dataset can result in significantly more robust models than <b>fine-tuning</b> on a large and diverse but biased dataset. Code is available at https://github.com/MadryLab/pretraining-distribution-shift-robustness.

{{</citation>}}


### (32/68 | 157/321) Federated Linear Contextual Bandits with Heterogeneous Clients (Ethan Blaser et al., 2024)

{{<citation>}}

Ethan Blaser, Chuanhao Li, Hongning Wang. (2024)  
**Federated Linear Contextual Bandits with Heterogeneous Clients**
<br/>
<button class="copy-to-clipboard" title="Federated Linear Contextual Bandits with Heterogeneous Clients" index=157>
  <span class="copy-to-clipboard-item">Copy Title<span>
</button>
<div class="toast toast-copied toast-index-157 align-items-center text-bg-secondary border-0 position-absolute top-0 end-0" role="alert" aria-live="assertive" aria-atomic="true">
  <div class="d-flex">
    <div class="toast-body">
      Copied!
    </div>
  </div>
</div>

---
Primary Category: cs.LG  
Categories: cs-AI, cs-LG, cs.LG  
Keyword Score: 20  
Keywords: Bandit Algorithm, Federated Learning  
<a type="button" class="btn btn-outline-primary" href="http://arxiv.org/abs/2403.00116v1" target="_blank" >Paper Link</a>
<button type="button" class="btn btn-outline-primary download-pdf" url="https://arxiv.org/pdf/2403.00116v1.pdf" filename="2403.00116v1.pdf">Download PDF</button>

---


**ABSTRACT**  
The demand for collaborative and private <b>bandit</b> learning across multiple agents is surging due to the growing quantity of data generated from distributed systems. <b>Federated</b> <b>bandit</b> learning has emerged as a promising framework for private, efficient, and decentralized online learning. However, almost all previous works rely on strong assumptions of client homogeneity, i.e., all participating clients shall share the same <b>bandit</b> model; otherwise, they all would suffer linear regret. This greatly restricts the application of <b>federated</b> <b>bandit</b> learning in practice. In this work, we introduce a new approach for <b>federated</b> <b>bandits</b> for heterogeneous clients, which clusters clients for collaborative <b>bandit</b> learning under the <b>federated</b> <b>learning</b> setting. Our proposed algorithm achieves non-trivial sub-linear regret and communication cost for all clients, subject to the communication protocol under <b>federated</b> <b>learning</b> that at anytime only one model can be shared by the server.

{{</citation>}}


### (33/68 | 158/321) On Robustness and Generalization of ML-Based Congestion Predictors to Valid and Imperceptible Perturbations (Chester Holtz et al., 2024)

{{<citation>}}

Chester Holtz, Yucheng Wang, Chung-Kuan Cheng, Bill Lin. (2024)  
**On Robustness and Generalization of ML-Based Congestion Predictors to Valid and Imperceptible Perturbations**
<br/>
<button class="copy-to-clipboard" title="On Robustness and Generalization of ML-Based Congestion Predictors to Valid and Imperceptible Perturbations" index=158>
  <span class="copy-to-clipboard-item">Copy Title<span>
</button>
<div class="toast toast-copied toast-index-158 align-items-center text-bg-secondary border-0 position-absolute top-0 end-0" role="alert" aria-live="assertive" aria-atomic="true">
  <div class="d-flex">
    <div class="toast-body">
      Copied!
    </div>
  </div>
</div>

---
Primary Category: cs.LG  
Categories: cs-AR, cs-LG, cs.LG  
Keyword Score: 20  
Keywords: Graph Neural Network, Convolutional Neural Network  
<a type="button" class="btn btn-outline-primary" href="http://arxiv.org/abs/2403.00103v1" target="_blank" >Paper Link</a>
<button type="button" class="btn btn-outline-primary download-pdf" url="https://arxiv.org/pdf/2403.00103v1.pdf" filename="2403.00103v1.pdf">Download PDF</button>

---


**ABSTRACT**  
There is substantial interest in the use of machine learning (ML)-based techniques throughout the electronic computer-aided design (CAD) flow, particularly methods based on deep learning. However, while deep learning methods have achieved state-of-the-art performance in several applications, recent work has demonstrated that neural networks are generally vulnerable to small, carefully chosen perturbations of their input (e.g. a single pixel change in an image). In this work, we investigate robustness in the context of ML-based EDA tools -- particularly for congestion prediction. As far as we are aware, we are the first to explore this concept in the context of ML-based EDA. We first describe a novel notion of imperceptibility designed specifically for VLSI layout problems defined on netlists and cell placements. Our definition of imperceptibility is characterized by a guarantee that a perturbation to a layout will not alter its global routing. We then demonstrate that state-of-the-art <b>CNN</b> and <b>GNN-based</b> congestion models exhibit brittleness to imperceptible perturbations. Namely, we show that when a small number of cells (e.g. 1%-5% of cells) have their positions shifted such that a measure of global congestion is guaranteed to remain unaffected (e.g. 1% of the design adversarially shifted by 0.001% of the layout space results in a predicted decrease in congestion of up to 90%, while no change in congestion is implied by the perturbation). In other words, the quality of a predictor can be made arbitrarily poor (i.e. can be made to predict that a design is "congestion-free") for an arbitrary input layout. Next, we describe a simple technique to train predictors that improves robustness to these perturbations. Our work indicates that CAD engineers should be cautious when integrating neural network-based mechanisms in EDA flows to ensure robust and high-quality results.

{{</citation>}}


### (34/68 | 159/321) Heavy-Tailed Class Imbalance and Why Adam Outperforms Gradient Descent on Language Models (Frederik Kunstner et al., 2024)

{{<citation>}}

Frederik Kunstner, Robin Yadav, Alan Milligan, Mark Schmidt, Alberto Bietti. (2024)  
**Heavy-Tailed Class Imbalance and Why Adam Outperforms Gradient Descent on Language Models**
<br/>
<button class="copy-to-clipboard" title="Heavy-Tailed Class Imbalance and Why Adam Outperforms Gradient Descent on Language Models" index=159>
  <span class="copy-to-clipboard-item">Copy Title<span>
</button>
<div class="toast toast-copied toast-index-159 align-items-center text-bg-secondary border-0 position-absolute top-0 end-0" role="alert" aria-live="assertive" aria-atomic="true">
  <div class="d-flex">
    <div class="toast-body">
      Copied!
    </div>
  </div>
</div>

---
Primary Category: cs.LG  
Categories: cs-CL, cs-LG, cs.LG, math-OC, stat-ML  
Keyword Score: 20  
Keywords: Convolutional Neural Network, Transformer  
<a type="button" class="btn btn-outline-primary" href="http://arxiv.org/abs/2402.19449v1" target="_blank" >Paper Link</a>
<button type="button" class="btn btn-outline-primary download-pdf" url="https://arxiv.org/pdf/2402.19449v1.pdf" filename="2402.19449v1.pdf">Download PDF</button>

---


**ABSTRACT**  
Adam has been shown to outperform gradient descent in optimizing large language <b>transformers</b> empirically, and by a larger margin than on other tasks, but it is unclear why this happens. We show that the heavy-tailed class imbalance found in language modeling tasks leads to difficulties in the optimization dynamics. When training with gradient descent, the loss associated with infrequent words decreases slower than the loss associated with frequent ones. As most samples come from relatively infrequent words, the average loss decreases slowly with gradient descent. On the other hand, Adam and sign-based methods do not suffer from this problem and improve predictions on all classes. To establish that this behavior is indeed caused by class imbalance, we show empirically that it persist through different architectures and data types, on language <b>transformers,</b> vision <b>CNNs,</b> and linear models. We further study this phenomenon on a linear classification with cross-entropy loss, showing that heavy-tailed class imbalance leads to ill-conditioning, and that the normalization used by Adam can counteract it.

{{</citation>}}


### (35/68 | 160/321) Distributed Momentum Methods Under Biased Gradient Estimations (Ali Beikmohammadi et al., 2024)

{{<citation>}}

Ali Beikmohammadi, Sarit Khirirat, Sindri Magnússon. (2024)  
**Distributed Momentum Methods Under Biased Gradient Estimations**
<br/>
<button class="copy-to-clipboard" title="Distributed Momentum Methods Under Biased Gradient Estimations" index=160>
  <span class="copy-to-clipboard-item">Copy Title<span>
</button>
<div class="toast toast-copied toast-index-160 align-items-center text-bg-secondary border-0 position-absolute top-0 end-0" role="alert" aria-live="assertive" aria-atomic="true">
  <div class="d-flex">
    <div class="toast-body">
      Copied!
    </div>
  </div>
</div>

---
Primary Category: cs.LG  
Categories: cs-LG, cs.LG  
Keyword Score: 20  
Keywords: Meta Learning, Reinforcement Learning  
<a type="button" class="btn btn-outline-primary" href="http://arxiv.org/abs/2403.00853v1" target="_blank" >Paper Link</a>
<button type="button" class="btn btn-outline-primary download-pdf" url="https://arxiv.org/pdf/2403.00853v1.pdf" filename="2403.00853v1.pdf">Download PDF</button>

---


**ABSTRACT**  
Distributed stochastic gradient methods are gaining prominence in solving large-scale machine learning problems that involve data distributed across multiple nodes. However, obtaining unbiased stochastic gradients, which have been the focus of most theoretical research, is challenging in many distributed machine learning applications. The gradient estimations easily become biased, for example, when gradients are compressed or clipped, when data is shuffled, and in <b>meta-learning</b> <b>and</b> <b>reinforcement</b> <b>learning.</b> In this work, we establish non-asymptotic convergence bounds on distributed momentum methods under biased gradient estimation on both general non-convex and $\mu$-PL non-convex problems. Our analysis covers general distributed optimization problems, and we work out the implications for special cases where gradient estimates are biased, i.e., in <b>meta-learning</b> <b>and</b> when the gradients are compressed or clipped. Our numerical experiments on training deep neural networks with Top-$K$ sparsification and clipping verify faster convergence performance of momentum methods than traditional biased gradient descent.

{{</citation>}}


### (36/68 | 161/321) Estimation and Deconvolution of Second Order Cyclostationary Signals (Igor Makienko et al., 2024)

{{<citation>}}

Igor Makienko, Michael Grebshtein, Eli Gildish. (2024)  
**Estimation and Deconvolution of Second Order Cyclostationary Signals**
<br/>
<button class="copy-to-clipboard" title="Estimation and Deconvolution of Second Order Cyclostationary Signals" index=161>
  <span class="copy-to-clipboard-item">Copy Title<span>
</button>
<div class="toast toast-copied toast-index-161 align-items-center text-bg-secondary border-0 position-absolute top-0 end-0" role="alert" aria-live="assertive" aria-atomic="true">
  <div class="d-flex">
    <div class="toast-body">
      Copied!
    </div>
  </div>
</div>

---
Primary Category: cs.LG  
Categories: cs-LG, cs.LG, eess-SP  
Keyword Score: 20  
Keywords: Simulation, Simulator  
<a type="button" class="btn btn-outline-primary" href="http://arxiv.org/abs/2402.19290v1" target="_blank" >Paper Link</a>
<button type="button" class="btn btn-outline-primary download-pdf" url="https://arxiv.org/pdf/2402.19290v1.pdf" filename="2402.19290v1.pdf">Download PDF</button>

---


**ABSTRACT**  
This method solves the dual problem of blind deconvolution and estimation of the time waveform of noisy second-order cyclo-stationary (CS2) signals that traverse a Transfer Function (TF) en route to a sensor. We have proven that the deconvolution filter exists and eliminates the TF effect from signals whose statistics vary over time. This method is blind, meaning it does not require prior knowledge about the signals or TF. <b>Simulations</b> demonstrate the algorithm high precision across various signal types, TFs, and Signal-to-Noise Ratios (SNRs). In this study, the CS2 signals family is restricted to the product of a deterministic periodic function and white noise. Furthermore, this method has the potential to improve the training of Machine Learning models where the aggregation of signals from identical systems but with different TFs is required.

{{</citation>}}


### (37/68 | 162/321) SPriFed-OMP: A Differentially Private Federated Learning Algorithm for Sparse Basis Recovery (Ajinkya Kiran Mulay et al., 2024)

{{<citation>}}

Ajinkya Kiran Mulay, Xiaojun Lin. (2024)  
**SPriFed-OMP: A Differentially Private Federated Learning Algorithm for Sparse Basis Recovery**
<br/>
<button class="copy-to-clipboard" title="SPriFed-OMP: A Differentially Private Federated Learning Algorithm for Sparse Basis Recovery" index=162>
  <span class="copy-to-clipboard-item">Copy Title<span>
</button>
<div class="toast toast-copied toast-index-162 align-items-center text-bg-secondary border-0 position-absolute top-0 end-0" role="alert" aria-live="assertive" aria-atomic="true">
  <div class="d-flex">
    <div class="toast-body">
      Copied!
    </div>
  </div>
</div>

---
Primary Category: cs.LG  
Categories: cs-CR, cs-LG, cs.LG  
Keyword Score: 20  
Keywords: Federated Learning, Differential Privacy  
<a type="button" class="btn btn-outline-primary" href="http://arxiv.org/abs/2402.19016v1" target="_blank" >Paper Link</a>
<button type="button" class="btn btn-outline-primary download-pdf" url="https://arxiv.org/pdf/2402.19016v1.pdf" filename="2402.19016v1.pdf">Download PDF</button>

---


**ABSTRACT**  
Sparse basis recovery is a classical and important statistical learning problem when the number of model dimensions $p$ is much larger than the number of samples $n$. However, there has been little work that studies sparse basis recovery in the <b>Federated</b> <b>Learning</b> (FL) setting, where the client data's <b>differential</b> <b>privacy</b> (DP) must also be simultaneously protected. In particular, the performance guarantees of existing DP-FL algorithms (such as DP-SGD) will degrade significantly when $p \gg n$, and thus, they will fail to learn the true underlying sparse model accurately. In this work, we develop a new differentially private sparse basis recovery algorithm for the FL setting, called SPriFed-OMP. SPriFed-OMP converts OMP (Orthogonal Matching Pursuit) to the FL setting. Further, it combines SMPC (secure multi-party computation) and DP to ensure that only a small amount of noise needs to be added in order to achieve <b>differential</b> <b>privacy.</b> As a result, SPriFed-OMP can efficiently recover the true sparse basis for a linear model with only $n = O(\sqrt{p})$ samples. We further present an enhanced version of our approach, SPriFed-OMP-GRAD based on gradient privatization, that improves the performance of SPriFed-OMP. Our theoretical analysis and empirical results demonstrate that both SPriFed-OMP and SPriFed-OMP-GRAD terminate in a small number of steps, and they significantly outperform the previous state-of-the-art DP-FL solutions in terms of the accuracy-privacy trade-off.

{{</citation>}}


### (38/68 | 163/321) Stop Relying on No-Choice and Do not Repeat the Moves: Optimal, Efficient and Practical Algorithms for Assortment Optimization (Aadirupa Saha et al., 2024)

{{<citation>}}

Aadirupa Saha, Pierre Gaillard. (2024)  
**Stop Relying on No-Choice and Do not Repeat the Moves: Optimal, Efficient and Practical Algorithms for Assortment Optimization**
<br/>
<button class="copy-to-clipboard" title="Stop Relying on No-Choice and Do not Repeat the Moves: Optimal, Efficient and Practical Algorithms for Assortment Optimization" index=163>
  <span class="copy-to-clipboard-item">Copy Title<span>
</button>
<div class="toast toast-copied toast-index-163 align-items-center text-bg-secondary border-0 position-absolute top-0 end-0" role="alert" aria-live="assertive" aria-atomic="true">
  <div class="d-flex">
    <div class="toast-body">
      Copied!
    </div>
  </div>
</div>

---
Primary Category: cs.LG  
Categories: cs-IR, cs-LG, cs.LG  
Keyword Score: 20  
Keywords: Fine-tuning, Recommender System  
<a type="button" class="btn btn-outline-primary" href="http://arxiv.org/abs/2402.18917v1" target="_blank" >Paper Link</a>
<button type="button" class="btn btn-outline-primary download-pdf" url="https://arxiv.org/pdf/2402.18917v1.pdf" filename="2402.18917v1.pdf">Download PDF</button>

---


**ABSTRACT**  
We address the problem of active online assortment optimization problem with preference feedback, which is a framework for modeling user choices and subsetwise utility maximization. The framework is useful in various real-world applications including ad placement, online retail, <b>recommender</b> <b>systems,</b> <b>fine-tuning</b> language models, amongst many. The problem, although has been studied in the past, lacks an intuitive and practical solution approach with simultaneously efficient algorithm and optimal regret guarantee. E.g., popularly used assortment selection algorithms often require the presence of a `strong reference' which is always included in the choice sets, further they are also designed to offer the same assortments repeatedly until the reference item gets selected -- all such requirements are quite unrealistic for practical applications. In this paper, we designed efficient algorithms for the problem of regret minimization in assortment selection with \emph{Plackett Luce} (PL) based user choices. We designed a novel concentration guarantee for estimating the score parameters of the PL model using `\emph{Pairwise Rank-Breaking}', which builds the foundation of our proposed algorithms. Moreover, our methods are practical, provably optimal, and devoid of the aforementioned limitations of the existing methods. Empirical evaluations corroborate our findings and outperform the existing baselines.

{{</citation>}}


### (39/68 | 164/321) Influencing Bandits: Arm Selection for Preference Shaping (Viraj Nadkarni et al., 2024)

{{<citation>}}

Viraj Nadkarni, D. Manjunath, Sharayu Moharir. (2024)  
**Influencing Bandits: Arm Selection for Preference Shaping**
<br/>
<button class="copy-to-clipboard" title="Influencing Bandits: Arm Selection for Preference Shaping" index=164>
  <span class="copy-to-clipboard-item">Copy Title<span>
</button>
<div class="toast toast-copied toast-index-164 align-items-center text-bg-secondary border-0 position-absolute top-0 end-0" role="alert" aria-live="assertive" aria-atomic="true">
  <div class="d-flex">
    <div class="toast-body">
      Copied!
    </div>
  </div>
</div>

---
Primary Category: cs.LG  
Categories: I-2-6, cs-AI, cs-IR, cs-LG, cs-SY, cs.LG, eess-SY  
Keyword Score: 20  
Keywords: Bandit Algorithm, Recommendation  
<a type="button" class="btn btn-outline-primary" href="http://arxiv.org/abs/2403.00036v1" target="_blank" >Paper Link</a>
<button type="button" class="btn btn-outline-primary download-pdf" url="https://arxiv.org/pdf/2403.00036v1.pdf" filename="2403.00036v1.pdf">Download PDF</button>

---


**ABSTRACT**  
We consider a non stationary multi-armed <b>bandit</b> in which the population preferences are positively and negatively reinforced by the observed rewards. The objective of the algorithm is to shape the population preferences to maximize the fraction of the population favouring a predetermined arm. For the case of binary opinions, two types of opinion dynamics are considered -- decreasing elasticity (modeled as a Polya urn with increasing number of balls) and constant elasticity (using the voter model). For the first case, we describe an Explore-then-commit policy and a Thompson sampling policy and analyse the regret for each of these policies. We then show that these algorithms and their analyses carry over to the constant elasticity case. We also describe a Thompson sampling based algorithm for the case when more than two types of opinions are present. Finally, we discuss the case where presence of multiple <b>recommendation</b> systems gives rise to a trade-off between their popularity and opinion shaping objectives.

{{</citation>}}


### (40/68 | 165/321) Extended Flow Matching: a Method of Conditional Generation with Generalized Continuity Equation (Noboru Isobe et al., 2024)

{{<citation>}}

Noboru Isobe, Masanori Koyama, Kohei Hayashi, Kenji Fukumizu. (2024)  
**Extended Flow Matching: a Method of Conditional Generation with Generalized Continuity Equation**
<br/>
<button class="copy-to-clipboard" title="Extended Flow Matching: a Method of Conditional Generation with Generalized Continuity Equation" index=165>
  <span class="copy-to-clipboard-item">Copy Title<span>
</button>
<div class="toast toast-copied toast-index-165 align-items-center text-bg-secondary border-0 position-absolute top-0 end-0" role="alert" aria-live="assertive" aria-atomic="true">
  <div class="d-flex">
    <div class="toast-body">
      Copied!
    </div>
  </div>
</div>

---
Primary Category: cs.LG  
Categories: 68T07 (Primary), 49Q22 (Secondary), cs-LG, cs.LG, math-AP, math-FA, math-OC, math-PR  
Keyword Score: 20  
Keywords: Diffusion Model, Fine-tuning  
<a type="button" class="btn btn-outline-primary" href="http://arxiv.org/abs/2402.18839v2" target="_blank" >Paper Link</a>
<button type="button" class="btn btn-outline-primary download-pdf" url="https://arxiv.org/pdf/2402.18839v2.pdf" filename="2402.18839v2.pdf">Download PDF</button>

---


**ABSTRACT**  
The task of conditional generation is one of the most important applications of generative models, and numerous methods have been developed to date based on the celebrated <b>diffusion</b> <b>models,</b> with the guidance-based classifier-free method taking the lead. However, the theory of the guidance-based method not only requires the user to <b>fine-tune</b> the "guidance strength," but its target vector field does not necessarily correspond to the conditional distribution used in training. In this paper, we develop the theory of conditional generation based on Flow Matching, a current strong contender of <b>diffusion</b> <b>methods.</b> Motivated by the interpretation of a probability path as a distribution on path space, we establish a novel theory of flow-based generation of conditional distribution by employing the mathematical framework of generalized continuity equation instead of the continuity equation in flow matching. This theory naturally derives a method that aims to match the matrix field as opposed to the vector field. Our framework ensures the continuity of the generated conditional distribution through the existence of flow between conditional distributions. We will present our theory through experiments and mathematical results.

{{</citation>}}


### (41/68 | 166/321) BlockEcho: Retaining Long-Range Dependencies for Imputing Block-Wise Missing Data (Qiao Han et al., 2024)

{{<citation>}}

Qiao Han, Mingqian Li, Yao Yang, Yiteng Zhai. (2024)  
**BlockEcho: Retaining Long-Range Dependencies for Imputing Block-Wise Missing Data**
<br/>
<button class="copy-to-clipboard" title="BlockEcho: Retaining Long-Range Dependencies for Imputing Block-Wise Missing Data" index=166>
  <span class="copy-to-clipboard-item">Copy Title<span>
</button>
<div class="toast toast-copied toast-index-166 align-items-center text-bg-secondary border-0 position-absolute top-0 end-0" role="alert" aria-live="assertive" aria-atomic="true">
  <div class="d-flex">
    <div class="toast-body">
      Copied!
    </div>
  </div>
</div>

---
Primary Category: cs.LG  
Categories: cs-LG, cs.LG, stat-ML  
Keyword Score: 20  
Keywords: Generative Adversarial Network, Generative Adversarial Network  
<a type="button" class="btn btn-outline-primary" href="http://arxiv.org/abs/2402.18800v1" target="_blank" >Paper Link</a>
<button type="button" class="btn btn-outline-primary download-pdf" url="https://arxiv.org/pdf/2402.18800v1.pdf" filename="2402.18800v1.pdf">Download PDF</button>

---


**ABSTRACT**  
Block-wise missing data poses significant challenges in real-world data imputation tasks. Compared to scattered missing data, block-wise gaps exacerbate adverse effects on subsequent analytic and machine learning tasks, as the lack of local neighboring elements significantly reduces the interpolation capability and predictive power. However, this issue has not received adequate attention. Most SOTA matrix completion methods appeared less effective, primarily due to overreliance on neighboring elements for predictions. We systematically analyze the issue and propose a novel matrix completion method ``BlockEcho" for a more comprehensive solution. This method creatively integrates Matrix Factorization (MF) within <b>Generative</b> <b>Adversarial</b> <b>Networks</b> <b>(GAN)</b> to explicitly retain long-distance inter-element relationships in the original matrix. Besides, we incorporate an additional discriminator for <b>GAN,</b> comparing the generator's intermediate progress with pre-trained MF results to constrain high-order feature distributions. Subsequently, we evaluate BlockEcho on public datasets across three domains. Results demonstrate superior performance over both traditional and SOTA methods when imputing block-wise missing data, especially at higher missing rates. The advantage also holds for scattered missing data at high missing rates. We also contribute on the analyses in providing theoretical justification on the optimality and convergence of fusing MF and <b>GAN</b> for missing block data.

{{</citation>}}


### (42/68 | 167/321) Benchmarking Uncertainty Disentanglement: Specialized Uncertainties for Specialized Tasks (Bálint Mucsányi et al., 2024)

{{<citation>}}

Bálint Mucsányi, Michael Kirchhof, Seong Joon Oh. (2024)  
**Benchmarking Uncertainty Disentanglement: Specialized Uncertainties for Specialized Tasks**
<br/>
<button class="copy-to-clipboard" title="Benchmarking Uncertainty Disentanglement: Specialized Uncertainties for Specialized Tasks" index=167>
  <span class="copy-to-clipboard-item">Copy Title<span>
</button>
<div class="toast toast-copied toast-index-167 align-items-center text-bg-secondary border-0 position-absolute top-0 end-0" role="alert" aria-live="assertive" aria-atomic="true">
  <div class="d-flex">
    <div class="toast-body">
      Copied!
    </div>
  </div>
</div>

---
Primary Category: cs.LG  
Categories: cs-LG, cs.LG, stat-ML  
Keyword Score: 16  
Keywords: Benchmarking, Benchmarking, Out-of-distribution  
<a type="button" class="btn btn-outline-primary" href="http://arxiv.org/abs/2402.19460v1" target="_blank" >Paper Link</a>
<button type="button" class="btn btn-outline-primary download-pdf" url="https://arxiv.org/pdf/2402.19460v1.pdf" filename="2402.19460v1.pdf">Download PDF</button>

---


**ABSTRACT**  
Uncertainty quantification, once a singular task, has evolved into a spectrum of tasks, including abstained prediction, <b>out-of-distribution</b> detection, and aleatoric uncertainty quantification. The latest goal is disentanglement: the construction of multiple estimators that are each tailored to one and only one task. Hence, there is a plethora of recent advances with different intentions - that often entirely deviate from practical behavior. This paper conducts a comprehensive evaluation of numerous uncertainty estimators across diverse tasks on ImageNet. We find that, despite promising theoretical endeavors, disentanglement is not yet achieved in practice. Additionally, we reveal which uncertainty estimators excel at which specific tasks, providing insights for practitioners and guiding future research toward task-centric and disentangled uncertainty estimation methods. Our code is available at https://github.com/bmucsanyi/bud.

{{</citation>}}


### (43/68 | 168/321) Anomaly Detection in Offshore Wind Turbine Structures using Hierarchical Bayesian Modelling (S. M. Smith et al., 2024)

{{<citation>}}

S. M. Smith, A. J. Hughes, T. A. Dardeno, L. A. Bull, N. Dervilis, K. Worden. (2024)  
**Anomaly Detection in Offshore Wind Turbine Structures using Hierarchical Bayesian Modelling**
<br/>
<button class="copy-to-clipboard" title="Anomaly Detection in Offshore Wind Turbine Structures using Hierarchical Bayesian Modelling" index=168>
  <span class="copy-to-clipboard-item">Copy Title<span>
</button>
<div class="toast toast-copied toast-index-168 align-items-center text-bg-secondary border-0 position-absolute top-0 end-0" role="alert" aria-live="assertive" aria-atomic="true">
  <div class="d-flex">
    <div class="toast-body">
      Copied!
    </div>
  </div>
</div>

---
Primary Category: cs.LG  
Categories: cs-LG, cs.LG  
Keyword Score: 15  
Keywords: Anomaly Detection, Geometry  
<a type="button" class="btn btn-outline-primary" href="http://arxiv.org/abs/2402.19295v1" target="_blank" >Paper Link</a>
<button type="button" class="btn btn-outline-primary download-pdf" url="https://arxiv.org/pdf/2402.19295v1.pdf" filename="2402.19295v1.pdf">Download PDF</button>

---


**ABSTRACT**  
Population-based structural health monitoring (PBSHM), aims to share information between members of a population. An offshore wind (OW) farm could be considered as a population of nominally-identical wind-turbine structures. However, benign variations exist among members, such as <b>geometry,</b> sea-bed conditions and temperature differences. These factors could influence structural properties and therefore the dynamic response, making it more difficult to detect structural problems via traditional SHM techniques. This paper explores the use of a hierarchical Bayesian model to infer expected soil stiffness distributions at both population and local levels, as a basis to perform <b>anomaly</b> <b>detection,</b> in the form of scour, for new and existing turbines. To do this, observations of natural frequency will be generated as though they are from a small population of wind turbines. Differences between individual observations will be introduced by postulating distributions over the soil stiffness and measurement noise, as well as reducing soil depth (to represent scour), in the case of <b>anomaly</b> <b>detection.</b>

{{</citation>}}


### (44/68 | 169/321) Supervised Contrastive Representation Learning: Landscape Analysis with Unconstrained Features (Tina Behnia et al., 2024)

{{<citation>}}

Tina Behnia, Christos Thrampoulidis. (2024)  
**Supervised Contrastive Representation Learning: Landscape Analysis with Unconstrained Features**
<br/>
<button class="copy-to-clipboard" title="Supervised Contrastive Representation Learning: Landscape Analysis with Unconstrained Features" index=169>
  <span class="copy-to-clipboard-item">Copy Title<span>
</button>
<div class="toast toast-copied toast-index-169 align-items-center text-bg-secondary border-0 position-absolute top-0 end-0" role="alert" aria-live="assertive" aria-atomic="true">
  <div class="d-flex">
    <div class="toast-body">
      Copied!
    </div>
  </div>
</div>

---
Primary Category: cs.LG  
Categories: cs-LG, cs.LG, stat-ML  
Keyword Score: 15  
Keywords: Representation Learning, Supervised Learning  
<a type="button" class="btn btn-outline-primary" href="http://arxiv.org/abs/2402.18884v1" target="_blank" >Paper Link</a>
<button type="button" class="btn btn-outline-primary download-pdf" url="https://arxiv.org/pdf/2402.18884v1.pdf" filename="2402.18884v1.pdf">Download PDF</button>

---


**ABSTRACT**  
Recent findings reveal that over-parameterized deep neural networks, trained beyond zero training-error, exhibit a distinctive structural pattern at the final layer, termed as Neural-collapse (NC). These results indicate that the final hidden-layer outputs in such networks display minimal within-class variations over the training set. While existing research extensively investigates this phenomenon under cross-entropy loss, there are fewer studies focusing on its contrastive counterpart, <b>supervised</b> contrastive (SC) loss. Through the lens of NC, this paper employs an analytical approach to study the solutions derived from optimizing the SC loss. We adopt the unconstrained features model (UFM) as a representative proxy for unveiling NC-related phenomena in sufficiently over-parameterized deep networks. We show that, despite the non-convexity of SC loss minimization, all local minima are global minima. Furthermore, the minimizer is unique (up to a rotation). We prove our results by formalizing a tight convex relaxation of the UFM. Finally, through this convex formulation, we delve deeper into characterizing the properties of global solutions under label-imbalanced training data.

{{</citation>}}


### (45/68 | 170/321) FlatNAS: optimizing Flatness in Neural Architecture Search for Out-of-Distribution Robustness (Matteo Gambella et al., 2024)

{{<citation>}}

Matteo Gambella, Fabrizio Pittorino, Manuel Roveri. (2024)  
**FlatNAS: optimizing Flatness in Neural Architecture Search for Out-of-Distribution Robustness**
<br/>
<button class="copy-to-clipboard" title="FlatNAS: optimizing Flatness in Neural Architecture Search for Out-of-Distribution Robustness" index=170>
  <span class="copy-to-clipboard-item">Copy Title<span>
</button>
<div class="toast toast-copied toast-index-170 align-items-center text-bg-secondary border-0 position-absolute top-0 end-0" role="alert" aria-live="assertive" aria-atomic="true">
  <div class="d-flex">
    <div class="toast-body">
      Copied!
    </div>
  </div>
</div>

---
Primary Category: cs.LG  
Categories: cs-AI, cs-CV, cs-LG, cs.LG  
Keyword Score: 13  
Keywords: Benchmarking, Out-of-distribution  
<a type="button" class="btn btn-outline-primary" href="http://arxiv.org/abs/2402.19102v1" target="_blank" >Paper Link</a>
<button type="button" class="btn btn-outline-primary download-pdf" url="https://arxiv.org/pdf/2402.19102v1.pdf" filename="2402.19102v1.pdf">Download PDF</button>

---


**ABSTRACT**  
Neural Architecture Search (NAS) paves the way for the automatic definition of Neural Network (NN) architectures, attracting increasing research attention and offering solutions in various scenarios. This study introduces a novel NAS solution, called Flat Neural Architecture Search (FlatNAS), which explores the interplay between a novel figure of merit based on robustness to weight perturbations and single NN optimization with Sharpness-Aware Minimization (SAM). FlatNAS is the first work in the literature to systematically explore flat regions in the loss landscape of NNs in a NAS procedure, while jointly optimizing their performance on in-distribution data, their <b>out-of-distribution</b> (OOD) robustness, and constraining the number of parameters in their architecture. Differently from current studies primarily concentrating on OOD algorithms, FlatNAS successfully evaluates the impact of NN architectures on OOD robustness, a crucial aspect in real-world applications of machine and deep learning. FlatNAS achieves a good trade-off between performance, OOD generalization, and the number of parameters, by using only in-distribution data in the NAS exploration. The OOD robustness of the NAS-designed models is evaluated by focusing on robustness to input data corruptions, using popular <b>benchmark</b> datasets in the literature.

{{</citation>}}


### (46/68 | 171/321) On the Convergence of Differentially-Private Fine-tuning: To Linearly Probe or to Fully Fine-tune? (Shuqi Ke et al., 2024)

{{<citation>}}

Shuqi Ke, Charlie Hou, Giulia Fanti, Sewoong Oh. (2024)  
**On the Convergence of Differentially-Private Fine-tuning: To Linearly Probe or to Fully Fine-tune?**
<br/>
<button class="copy-to-clipboard" title="On the Convergence of Differentially-Private Fine-tuning: To Linearly Probe or to Fully Fine-tune?" index=171>
  <span class="copy-to-clipboard-item">Copy Title<span>
</button>
<div class="toast toast-copied toast-index-171 align-items-center text-bg-secondary border-0 position-absolute top-0 end-0" role="alert" aria-live="assertive" aria-atomic="true">
  <div class="d-flex">
    <div class="toast-body">
      Copied!
    </div>
  </div>
</div>

---
Primary Category: cs.LG  
Categories: cs-AI, cs-CR, cs-LG, cs.LG, math-OC  
Keyword Score: 13  
Keywords: Benchmarking, Fine-tuning  
<a type="button" class="btn btn-outline-primary" href="http://arxiv.org/abs/2402.18905v1" target="_blank" >Paper Link</a>
<button type="button" class="btn btn-outline-primary download-pdf" url="https://arxiv.org/pdf/2402.18905v1.pdf" filename="2402.18905v1.pdf">Download PDF</button>

---


**ABSTRACT**  
Differentially private (DP) machine learning pipelines typically involve a two-phase process: non-private pre-training on a public dataset, followed by <b>fine-tuning</b> on private data using DP optimization techniques. In the DP setting, it has been observed that full <b>fine-tuning</b> may not always yield the best test accuracy, even for in-distribution data. This paper (1) analyzes the training dynamics of DP linear probing (LP) and full <b>fine-tuning</b> (FT), and (2) explores the phenomenon of sequential <b>fine-tuning,</b> starting with linear probing and transitioning to full <b>fine-tuning</b> (LP-FT), and its impact on test loss. We provide theoretical insights into the convergence of DP <b>fine-tuning</b> within an overparameterized neural network and establish a utility curve that determines the allocation of privacy budget between linear probing and full <b>fine-tuning.</b> The theoretical results are supported by empirical evaluations on various <b>benchmarks</b> and models. The findings reveal the complex nature of DP <b>fine-tuning</b> methods. These results contribute to a deeper understanding of DP machine learning and highlight the importance of considering the allocation of privacy budget in the <b>fine-tuning</b> process.

{{</citation>}}


### (47/68 | 172/321) A Model-Based Approach for Improving Reinforcement Learning Efficiency Leveraging Expert Observations (Erhan Can Ozcan et al., 2024)

{{<citation>}}

Erhan Can Ozcan, Vittorio Giammarino, James Queeney, Ioannis Ch. Paschalidis. (2024)  
**A Model-Based Approach for Improving Reinforcement Learning Efficiency Leveraging Expert Observations**
<br/>
<button class="copy-to-clipboard" title="A Model-Based Approach for Improving Reinforcement Learning Efficiency Leveraging Expert Observations" index=172>
  <span class="copy-to-clipboard-item">Copy Title<span>
</button>
<div class="toast toast-copied toast-index-172 align-items-center text-bg-secondary border-0 position-absolute top-0 end-0" role="alert" aria-live="assertive" aria-atomic="true">
  <div class="d-flex">
    <div class="toast-body">
      Copied!
    </div>
  </div>
</div>

---
Primary Category: cs.LG  
Categories: cs-LG, cs.LG  
Keyword Score: 13  
Keywords: Benchmarking, Reinforcement Learning  
<a type="button" class="btn btn-outline-primary" href="http://arxiv.org/abs/2402.18836v1" target="_blank" >Paper Link</a>
<button type="button" class="btn btn-outline-primary download-pdf" url="https://arxiv.org/pdf/2402.18836v1.pdf" filename="2402.18836v1.pdf">Download PDF</button>

---


**ABSTRACT**  
This paper investigates how to incorporate expert observations (without explicit information on expert actions) into a deep <b>reinforcement</b> <b>learning</b> setting to improve sample efficiency. First, we formulate an augmented policy loss combining a maximum entropy <b>reinforcement</b> <b>learning</b> objective with a behavioral cloning loss that leverages a forward dynamics model. Then, we propose an algorithm that automatically adjusts the weights of each component in the augmented loss function. Experiments on a variety of continuous control tasks demonstrate that the proposed algorithm outperforms various <b>benchmarks</b> by effectively utilizing available expert observations.

{{</citation>}}


### (48/68 | 173/321) SoD$^2$: Statically Optimizing Dynamic Deep Neural Network (Wei Niu et al., 2024)

{{<citation>}}

Wei Niu, Gagan Agrawal, Bin Ren. (2024)  
**SoD$^2$: Statically Optimizing Dynamic Deep Neural Network**
<br/>
<button class="copy-to-clipboard" title="SoD$^2$: Statically Optimizing Dynamic Deep Neural Network" index=173>
  <span class="copy-to-clipboard-item">Copy Title<span>
</button>
<div class="toast toast-copied toast-index-173 align-items-center text-bg-secondary border-0 position-absolute top-0 end-0" role="alert" aria-live="assertive" aria-atomic="true">
  <div class="d-flex">
    <div class="toast-body">
      Copied!
    </div>
  </div>
</div>

---
Primary Category: cs.LG  
Categories: cs-AI, cs-LG, cs-PL, cs.LG  
Keyword Score: 10  
Keywords: Code Generation  
<a type="button" class="btn btn-outline-primary" href="http://arxiv.org/abs/2403.00176v1" target="_blank" >Paper Link</a>
<button type="button" class="btn btn-outline-primary download-pdf" url="https://arxiv.org/pdf/2403.00176v1.pdf" filename="2403.00176v1.pdf">Download PDF</button>

---


**ABSTRACT**  
Though many compilation and runtime systems have been developed for DNNs in recent years, the focus has largely been on static DNNs. Dynamic DNNs, where tensor shapes and sizes and even the set of operators used are dependent upon the input and/or execution, are becoming common. This paper presents SoD$^2$, a comprehensive framework for optimizing Dynamic DNNs. The basis of our approach is a classification of common operators that form DNNs, and the use of this classification towards a Rank and Dimension Propagation (RDP) method. This framework statically determines the shapes of operators as known constants, symbolic constants, or operations on these. Next, using RDP we enable a series of optimizations, like fused <b>code</b> <b>generation,</b> execution (order) planning, and even runtime memory allocation plan generation. By evaluating the framework on 10 emerging Dynamic DNNs and comparing it against several existing systems, we demonstrate both reductions in execution latency and memory requirements, with RDP-enabled key optimizations responsible for much of the gains. Our evaluation results show that SoD$^2$ runs up to $3.9\times$ faster than these systems while saving up to $88\%$ peak memory consumption.

{{</citation>}}


### (49/68 | 174/321) Privacy-Preserving Distributed Optimization and Learning (Ziqin Chen et al., 2024)

{{<citation>}}

Ziqin Chen, Yongqiang Wang. (2024)  
**Privacy-Preserving Distributed Optimization and Learning**
<br/>
<button class="copy-to-clipboard" title="Privacy-Preserving Distributed Optimization and Learning" index=174>
  <span class="copy-to-clipboard-item">Copy Title<span>
</button>
<div class="toast toast-copied toast-index-174 align-items-center text-bg-secondary border-0 position-absolute top-0 end-0" role="alert" aria-live="assertive" aria-atomic="true">
  <div class="d-flex">
    <div class="toast-body">
      Copied!
    </div>
  </div>
</div>

---
Primary Category: cs.LG  
Categories: cs-CR, cs-GT, cs-LG, cs.LG  
Keyword Score: 10  
Keywords: Differential Privacy  
<a type="button" class="btn btn-outline-primary" href="http://arxiv.org/abs/2403.00157v1" target="_blank" >Paper Link</a>
<button type="button" class="btn btn-outline-primary download-pdf" url="https://arxiv.org/pdf/2403.00157v1.pdf" filename="2403.00157v1.pdf">Download PDF</button>

---


**ABSTRACT**  
Distributed optimization and learning has recently garnered great attention due to its wide applications in sensor networks, smart grids, machine learning, and so forth. Despite rapid development, existing distributed optimization and learning algorithms require each agent to exchange messages with its neighbors, which may expose sensitive information and raise significant privacy concerns. In this survey paper, we overview privacy-preserving distributed optimization and learning methods. We first discuss cryptography, <b>differential</b> <b>privacy,</b> and other techniques that can be used for privacy preservation and indicate their pros and cons for privacy protection in distributed optimization and learning. We believe that among these approaches, <b>differential</b> <b>privacy</b> is most promising due to its low computational and communication complexities, which are extremely appealing for modern learning based applications with high dimensions of optimization variables. We then introduce several <b>differential-privacy</b> <b>algorithms</b> that can simultaneously ensure privacy and optimization accuracy. Moreover, we provide example applications in several machine learning problems to confirm the real-world effectiveness of these algorithms. Finally, we highlight some challenges in this research domain and discuss future directions.

{{</citation>}}


### (50/68 | 175/321) Longitudinal Counterfactuals: Constraints and Opportunities (Alexander Asemota et al., 2024)

{{<citation>}}

Alexander Asemota, Giles Hooker. (2024)  
**Longitudinal Counterfactuals: Constraints and Opportunities**
<br/>
<button class="copy-to-clipboard" title="Longitudinal Counterfactuals: Constraints and Opportunities" index=175>
  <span class="copy-to-clipboard-item">Copy Title<span>
</button>
<div class="toast toast-copied toast-index-175 align-items-center text-bg-secondary border-0 position-absolute top-0 end-0" role="alert" aria-live="assertive" aria-atomic="true">
  <div class="d-flex">
    <div class="toast-body">
      Copied!
    </div>
  </div>
</div>

---
Primary Category: cs.LG  
Categories: cs-CY, cs-LG, cs.LG  
Keyword Score: 10  
Keywords: Counter-factual  
<a type="button" class="btn btn-outline-primary" href="http://arxiv.org/abs/2403.00105v1" target="_blank" >Paper Link</a>
<button type="button" class="btn btn-outline-primary download-pdf" url="https://arxiv.org/pdf/2403.00105v1.pdf" filename="2403.00105v1.pdf">Download PDF</button>

---


**ABSTRACT**  
<b>Counterfactual</b> explanations are a common approach to providing recourse to data subjects. However, current methodology can produce <b>counterfactuals</b> that cannot be achieved by the subject, making the use of <b>counterfactuals</b> for recourse difficult to justify in practice. Though there is agreement that plausibility is an important quality when using <b>counterfactuals</b> for algorithmic recourse, ground truth plausibility continues to be difficult to quantify. In this paper, we propose using longitudinal data to assess and improve plausibility in <b>counterfactuals.</b> In particular, we develop a metric that compares longitudinal differences to <b>counterfactual</b> differences, allowing us to evaluate how similar a <b>counterfactual</b> is to prior observed changes. Furthermore, we use this metric to generate plausible <b>counterfactuals.</b> Finally, we discuss some of the inherent difficulties of using <b>counterfactuals</b> for recourse.

{{</citation>}}


### (51/68 | 176/321) A Scalable and Transferable Time Series Prediction Framework for Demand Forecasting (Young-Jin Park et al., 2024)

{{<citation>}}

Young-Jin Park, Donghyun Kim, Frédéric Odermatt, Juho Lee, Kyung-Min Kim. (2024)  
**A Scalable and Transferable Time Series Prediction Framework for Demand Forecasting**
<br/>
<button class="copy-to-clipboard" title="A Scalable and Transferable Time Series Prediction Framework for Demand Forecasting" index=176>
  <span class="copy-to-clipboard-item">Copy Title<span>
</button>
<div class="toast toast-copied toast-index-176 align-items-center text-bg-secondary border-0 position-absolute top-0 end-0" role="alert" aria-live="assertive" aria-atomic="true">
  <div class="d-flex">
    <div class="toast-body">
      Copied!
    </div>
  </div>
</div>

---
Primary Category: cs.LG  
Categories: cs-AI, cs-LG, cs.LG  
Keyword Score: 10  
Keywords: Zero-shot  
<a type="button" class="btn btn-outline-primary" href="http://arxiv.org/abs/2402.19402v1" target="_blank" >Paper Link</a>
<button type="button" class="btn btn-outline-primary download-pdf" url="https://arxiv.org/pdf/2402.19402v1.pdf" filename="2402.19402v1.pdf">Download PDF</button>

---


**ABSTRACT**  
Time series forecasting is one of the most essential and ubiquitous tasks in many business problems, including demand forecasting and logistics optimization. Traditional time series forecasting methods, however, have resulted in small models with limited expressive power because they have difficulty in scaling their model size up while maintaining high accuracy. In this paper, we propose Forecasting orchestra (Forchestra), a simple but powerful framework capable of accurately predicting future demand for a diverse range of items. We empirically demonstrate that the model size is scalable to up to 0.8 billion parameters. The proposed method not only outperforms existing forecasting models with a significant margin, but it could generalize well to unseen data points when evaluated in a <b>zero-shot</b> fashion on downstream datasets. Last but not least, we present extensive qualitative and quantitative studies to analyze how the proposed model outperforms baseline models and differs from conventional approaches. The original paper was presented as a full paper at ICDM 2022 and is available at: https://ieeexplore.ieee.org/document/10027662.

{{</citation>}}


### (52/68 | 177/321) Structure Preserving Diffusion Models (Haoye Lu et al., 2024)

{{<citation>}}

Haoye Lu, Spencer Szabados, Yaoliang Yu. (2024)  
**Structure Preserving Diffusion Models**
<br/>
<button class="copy-to-clipboard" title="Structure Preserving Diffusion Models" index=177>
  <span class="copy-to-clipboard-item">Copy Title<span>
</button>
<div class="toast toast-copied toast-index-177 align-items-center text-bg-secondary border-0 position-absolute top-0 end-0" role="alert" aria-live="assertive" aria-atomic="true">
  <div class="d-flex">
    <div class="toast-body">
      Copied!
    </div>
  </div>
</div>

---
Primary Category: cs.LG  
Categories: cs-CV, cs-LG, cs.LG  
Keyword Score: 10  
Keywords: Diffusion Model  
<a type="button" class="btn btn-outline-primary" href="http://arxiv.org/abs/2402.19369v1" target="_blank" >Paper Link</a>
<button type="button" class="btn btn-outline-primary download-pdf" url="https://arxiv.org/pdf/2402.19369v1.pdf" filename="2402.19369v1.pdf">Download PDF</button>

---


**ABSTRACT**  
<b>Diffusion</b> <b>models</b> have become the leading distribution-learning method in recent years. Herein, we introduce structure-preserving <b>diffusion</b> <b>processes,</b> a family of <b>diffusion</b> <b>processes</b> for learning distributions that possess additional structure, such as group symmetries, by developing theoretical conditions under which the <b>diffusion</b> <b>transition</b> steps preserve said symmetry. While also enabling equivariant data sampling trajectories, we exemplify these results by developing a collection of different symmetry equivariant <b>diffusion</b> <b>models</b> capable of learning distributions that are inherently symmetric. Empirical studies, over both synthetic and real-world datasets, are used to validate the developed models adhere to the proposed theory and are capable of achieving improved performance over existing methods in terms of sample equality. We also show how the proposed models can be used to achieve theoretically guaranteed equivariant image noise reduction without prior knowledge of the image orientation.

{{</citation>}}


### (53/68 | 178/321) Masks, Signs, And Learning Rate Rewinding (Advait Gadhikar et al., 2024)

{{<citation>}}

Advait Gadhikar, Rebekka Burkholz. (2024)  
**Masks, Signs, And Learning Rate Rewinding**
<br/>
<button class="copy-to-clipboard" title="Masks, Signs, And Learning Rate Rewinding" index=178>
  <span class="copy-to-clipboard-item">Copy Title<span>
</button>
<div class="toast toast-copied toast-index-178 align-items-center text-bg-secondary border-0 position-absolute top-0 end-0" role="alert" aria-live="assertive" aria-atomic="true">
  <div class="d-flex">
    <div class="toast-body">
      Copied!
    </div>
  </div>
</div>

---
Primary Category: cs.LG  
Categories: cs-LG, cs.LG  
Keyword Score: 10  
Keywords: Pruning  
<a type="button" class="btn btn-outline-primary" href="http://arxiv.org/abs/2402.19262v1" target="_blank" >Paper Link</a>
<button type="button" class="btn btn-outline-primary download-pdf" url="https://arxiv.org/pdf/2402.19262v1.pdf" filename="2402.19262v1.pdf">Download PDF</button>

---


**ABSTRACT**  
Learning Rate Rewinding (LRR) has been established as a strong variant of Iterative Magnitude <b>Pruning</b> (IMP) to find lottery tickets in deep overparameterized neural networks. While both iterative <b>pruning</b> schemes couple structure and parameter learning, understanding how LRR excels in both aspects can bring us closer to the design of more flexible deep learning algorithms that can optimize diverse sets of sparse architectures. To this end, we conduct experiments that disentangle the effect of mask learning and parameter optimization and how both benefit from overparameterization. The ability of LRR to flip parameter signs early and stay robust to sign perturbations seems to make it not only more effective in mask identification but also in optimizing diverse sets of masks, including random ones. In support of this hypothesis, we prove in a simplified single hidden neuron setting that LRR succeeds in more cases than IMP, as it can escape initially problematic sign configurations.

{{</citation>}}


### (54/68 | 179/321) Machine learning for modular multiplication (Kristin Lauter et al., 2024)

{{<citation>}}

Kristin Lauter, Cathy Yuanchen Li, Krystal Maughan, Rachel Newton, Megha Srivastava. (2024)  
**Machine learning for modular multiplication**
<br/>
<button class="copy-to-clipboard" title="Machine learning for modular multiplication" index=179>
  <span class="copy-to-clipboard-item">Copy Title<span>
</button>
<div class="toast toast-copied toast-index-179 align-items-center text-bg-secondary border-0 position-absolute top-0 end-0" role="alert" aria-live="assertive" aria-atomic="true">
  <div class="d-flex">
    <div class="toast-body">
      Copied!
    </div>
  </div>
</div>

---
Primary Category: cs.LG  
Categories: cs-CR, cs-LG, cs.LG  
Keyword Score: 10  
Keywords: Transformer  
<a type="button" class="btn btn-outline-primary" href="http://arxiv.org/abs/2402.19254v1" target="_blank" >Paper Link</a>
<button type="button" class="btn btn-outline-primary download-pdf" url="https://arxiv.org/pdf/2402.19254v1.pdf" filename="2402.19254v1.pdf">Download PDF</button>

---


**ABSTRACT**  
Motivated by cryptographic applications, we investigate two machine learning approaches to modular multiplication: namely circular regression and a sequence-to-sequence <b>transformer</b> model. The limited success of both methods demonstrated in our results gives evidence for the hardness of tasks involving modular multiplication upon which cryptosystems are based.

{{</citation>}}


### (55/68 | 180/321) Uncertainty-Based Extensible Codebook for Discrete Federated Learning in Heterogeneous Data Silos (Tianyi Zhang et al., 2024)

{{<citation>}}

Tianyi Zhang, Yu Cao, Dianbo Liu. (2024)  
**Uncertainty-Based Extensible Codebook for Discrete Federated Learning in Heterogeneous Data Silos**
<br/>
<button class="copy-to-clipboard" title="Uncertainty-Based Extensible Codebook for Discrete Federated Learning in Heterogeneous Data Silos" index=180>
  <span class="copy-to-clipboard-item">Copy Title<span>
</button>
<div class="toast toast-copied toast-index-180 align-items-center text-bg-secondary border-0 position-absolute top-0 end-0" role="alert" aria-live="assertive" aria-atomic="true">
  <div class="d-flex">
    <div class="toast-body">
      Copied!
    </div>
  </div>
</div>

---
Primary Category: cs.LG  
Categories: cs-LG, cs.LG  
Keyword Score: 10  
Keywords: Federated Learning  
<a type="button" class="btn btn-outline-primary" href="http://arxiv.org/abs/2402.18888v2" target="_blank" >Paper Link</a>
<button type="button" class="btn btn-outline-primary download-pdf" url="https://arxiv.org/pdf/2402.18888v2.pdf" filename="2402.18888v2.pdf">Download PDF</button>

---


**ABSTRACT**  
<b>Federated</b> <b>learning</b> (FL), aimed at leveraging vast distributed datasets, confronts a crucial challenge: the heterogeneity of data across different silos. While previous studies have explored discrete representations to enhance model generalization across minor distributional shifts, these approaches often struggle to adapt to new data silos with significantly divergent distributions. In response, we have identified that models derived from FL exhibit markedly increased uncertainty when applied to data silos with unfamiliar distributions. Consequently, we propose an innovative yet straightforward iterative framework, termed Uncertainty-Based Extensible-Codebook <b>Federated</b> <b>Learning</b> (UEFL). This framework dynamically maps latent features to trainable discrete vectors, assesses the uncertainty, and specifically extends the discretization dictionary or codebook for silos exhibiting high uncertainty. Our approach aims to simultaneously enhance accuracy and reduce uncertainty by explicitly addressing the diversity of data distributions, all while maintaining minimal computational overhead in environments characterized by heterogeneous data silos. Through experiments conducted on five datasets, our method has demonstrated its superiority, achieving significant improvements in accuracy (by 3%--22.1%) and uncertainty reduction (by 38.83%--96.24%), thereby outperforming contemporary state-of-the-art methods. The source code is available at https://github.com/destiny301/uefl.

{{</citation>}}


### (56/68 | 181/321) Dr. Strategy: Model-Based Generalist Agents with Strategic Dreaming (Hany Hamed et al., 2024)

{{<citation>}}

Hany Hamed, Subin Kim, Dongyeong Kim, Jaesik Yoon, Sungjin Ahn. (2024)  
**Dr. Strategy: Model-Based Generalist Agents with Strategic Dreaming**
<br/>
<button class="copy-to-clipboard" title="Dr. Strategy: Model-Based Generalist Agents with Strategic Dreaming" index=181>
  <span class="copy-to-clipboard-item">Copy Title<span>
</button>
<div class="toast toast-copied toast-index-181 align-items-center text-bg-secondary border-0 position-absolute top-0 end-0" role="alert" aria-live="assertive" aria-atomic="true">
  <div class="d-flex">
    <div class="toast-body">
      Copied!
    </div>
  </div>
</div>

---
Primary Category: cs.LG  
Categories: cs-LG, cs.LG  
Keyword Score: 10  
Keywords: Reinforcement Learning  
<a type="button" class="btn btn-outline-primary" href="http://arxiv.org/abs/2402.18866v1" target="_blank" >Paper Link</a>
<button type="button" class="btn btn-outline-primary download-pdf" url="https://arxiv.org/pdf/2402.18866v1.pdf" filename="2402.18866v1.pdf">Download PDF</button>

---


**ABSTRACT**  
Model-based <b>reinforcement</b> <b>learning</b> (MBRL) has been a primary approach to ameliorating the sample efficiency issue as well as to make a generalist agent. However, there has not been much effort toward enhancing the strategy of dreaming itself. Therefore, it is a question whether and how an agent can "dream better" in a more structured and strategic way. In this paper, inspired by the observation from cognitive science suggesting that humans use a spatial divide-and-conquer strategy in planning, we propose a new MBRL agent, called Dr. Strategy, which is equipped with a novel Dreaming Strategy. The proposed agent realizes a version of divide-and-conquer-like strategy in dreaming. This is achieved by learning a set of latent landmarks and then utilizing these to learn a landmark-conditioned highway policy. With the highway policy, the agent can first learn in the dream to move to a landmark, and from there it tackles the exploration and achievement task in a more focused way. In experiments, we show that the proposed model outperforms prior pixel-based MBRL methods in various visually complex and partially observable navigation tasks. The source code will be available at https://github.com/ahn-ml/drstrategy

{{</citation>}}


### (57/68 | 182/321) Rethinking Multi-domain Generalization with A General Learning Objective (Zhaorui Tan et al., 2024)

{{<citation>}}

Zhaorui Tan, Xi Yang, Kaizhu Huang. (2024)  
**Rethinking Multi-domain Generalization with A General Learning Objective**
<br/>
<button class="copy-to-clipboard" title="Rethinking Multi-domain Generalization with A General Learning Objective" index=182>
  <span class="copy-to-clipboard-item">Copy Title<span>
</button>
<div class="toast toast-copied toast-index-182 align-items-center text-bg-secondary border-0 position-absolute top-0 end-0" role="alert" aria-live="assertive" aria-atomic="true">
  <div class="d-flex">
    <div class="toast-body">
      Copied!
    </div>
  </div>
</div>

---
Primary Category: cs.LG  
Categories: cs-AI, cs-CV, cs-LG, cs.LG  
Keyword Score: 10  
Keywords: Knowledge Distillation  
<a type="button" class="btn btn-outline-primary" href="http://arxiv.org/abs/2402.18853v1" target="_blank" >Paper Link</a>
<button type="button" class="btn btn-outline-primary download-pdf" url="https://arxiv.org/pdf/2402.18853v1.pdf" filename="2402.18853v1.pdf">Download PDF</button>

---


**ABSTRACT**  
Multi-domain generalization (mDG) is universally aimed to minimize the discrepancy between training and testing distributions to enhance marginal-to-label distribution mapping. However, existing mDG literature lacks a general learning objective paradigm and often imposes constraints on static target marginal distributions. In this paper, we propose to leverage a $Y$-mapping to relax the constraint. We rethink the learning objective for mDG and design a new \textbf{general learning objective} to interpret and analyze most existing mDG wisdom. This general objective is bifurcated into two synergistic amis: learning domain-independent conditional features and maximizing a posterior. Explorations also extend to two effective regularization terms that incorporate prior information and suppress invalid causality, alleviating the issues that come with relaxed constraints. We theoretically contribute an upper bound for the domain alignment of domain-independent conditional features, disclosing that many previous mDG endeavors actually \textbf{optimize partially the objective} and thus lead to limited performance. As such, our study <b>distills</b> a general learning objective into four practical components, providing a general, robust, and flexible mechanism to handle complex domain shifts. Extensive empirical results indicate that the proposed objective with $Y$-mapping leads to substantially better mDG performance in various downstream tasks, including regression, segmentation, and classification.

{{</citation>}}


### (58/68 | 183/321) Applications of 0-1 Neural Networks in Prescription and Prediction (Vrishabh Patil et al., 2024)

{{<citation>}}

Vrishabh Patil, Kara Hoppe, Yonatan Mintz. (2024)  
**Applications of 0-1 Neural Networks in Prescription and Prediction**
<br/>
<button class="copy-to-clipboard" title="Applications of 0-1 Neural Networks in Prescription and Prediction" index=183>
  <span class="copy-to-clipboard-item">Copy Title<span>
</button>
<div class="toast toast-copied toast-index-183 align-items-center text-bg-secondary border-0 position-absolute top-0 end-0" role="alert" aria-live="assertive" aria-atomic="true">
  <div class="d-flex">
    <div class="toast-body">
      Copied!
    </div>
  </div>
</div>

---
Primary Category: cs.LG  
Categories: cs-AI, cs-LG, cs.LG, math-OC, stat-ML  
Keyword Score: 10  
Keywords: Counter-factual  
<a type="button" class="btn btn-outline-primary" href="http://arxiv.org/abs/2402.18851v1" target="_blank" >Paper Link</a>
<button type="button" class="btn btn-outline-primary download-pdf" url="https://arxiv.org/pdf/2402.18851v1.pdf" filename="2402.18851v1.pdf">Download PDF</button>

---


**ABSTRACT**  
A key challenge in medical decision making is learning treatment policies for patients with limited observational data. This challenge is particularly evident in personalized healthcare decision-making, where models need to take into account the intricate relationships between patient characteristics, treatment options, and health outcomes. To address this, we introduce prescriptive networks (PNNs), shallow 0-1 neural networks trained with mixed integer programming that can be used with <b>counterfactual</b> estimation to optimize policies in medium data settings. These models offer greater interpretability than deep neural networks and can encode more complex policies than common models such as decision trees. We show that PNNs can outperform existing methods in both synthetic data experiments and in a case study of assigning treatments for postpartum hypertension. In particular, PNNs are shown to produce policies that could reduce peak blood pressure by 5.47 mm Hg (p=0.02) over existing clinical practice, and by 2 mm Hg (p=0.01) over the next best prescriptive modeling technique. Moreover PNNs were more likely than all other models to correctly identify clinically significant features while existing models relied on potentially dangerous features such as patient insurance information and race that could lead to bias in treatment.

{{</citation>}}


### (59/68 | 184/321) Multi-Fidelity Residual Neural Processes for Scalable Surrogate Modeling (Ruijia Niu et al., 2024)

{{<citation>}}

Ruijia Niu, Dongxia Wu, Kai Kim, Yi-An Ma, Duncan Watson-Parris, Rose Yu. (2024)  
**Multi-Fidelity Residual Neural Processes for Scalable Surrogate Modeling**
<br/>
<button class="copy-to-clipboard" title="Multi-Fidelity Residual Neural Processes for Scalable Surrogate Modeling" index=184>
  <span class="copy-to-clipboard-item">Copy Title<span>
</button>
<div class="toast toast-copied toast-index-184 align-items-center text-bg-secondary border-0 position-absolute top-0 end-0" role="alert" aria-live="assertive" aria-atomic="true">
  <div class="d-flex">
    <div class="toast-body">
      Copied!
    </div>
  </div>
</div>

---
Primary Category: cs.LG  
Categories: cs-LG, cs.LG  
Keyword Score: 10  
Keywords: Out-of-distribution  
<a type="button" class="btn btn-outline-primary" href="http://arxiv.org/abs/2402.18846v1" target="_blank" >Paper Link</a>
<button type="button" class="btn btn-outline-primary download-pdf" url="https://arxiv.org/pdf/2402.18846v1.pdf" filename="2402.18846v1.pdf">Download PDF</button>

---


**ABSTRACT**  
Multi-fidelity surrogate modeling aims to learn an accurate surrogate at the highest fidelity level by combining data from multiple sources. Traditional methods relying on Gaussian processes can hardly scale to high-dimensional data. Deep learning approaches utilize neural network based encoders and decoders to improve scalability. These approaches share encoded representations across fidelities without including corresponding decoder parameters. At the highest fidelity, the representations are decoded with different parameters, making the shared information inherently inaccurate. This hinders inference performance, especially in <b>out-of-distribution</b> scenarios when the highest fidelity data has limited domain coverage. To address these limitations, we propose Multi-fidelity Residual Neural Processes (MFRNP), a novel multi-fidelity surrogate modeling framework. MFRNP optimizes lower fidelity decoders for accurate information sharing by aggregating lower fidelity surrogate outputs and models residual between the aggregation and ground truth on the highest fidelity. We show that MFRNP significantly outperforms current state-of-the-art in learning partial differential equations and a real-world climate modeling task.

{{</citation>}}


### (60/68 | 185/321) Enhancing the 'Immunity' of Mixture-of-Experts Networks for Adversarial Defense (Qiao Han et al., 2024)

{{<citation>}}

Qiao Han, yong huang, xinling Guo, Yiteng Zhai, Yu Qin, Yao Yang. (2024)  
**Enhancing the 'Immunity' of Mixture-of-Experts Networks for Adversarial Defense**
<br/>
<button class="copy-to-clipboard" title="Enhancing the 'Immunity' of Mixture-of-Experts Networks for Adversarial Defense" index=185>
  <span class="copy-to-clipboard-item">Copy Title<span>
</button>
<div class="toast toast-copied toast-index-185 align-items-center text-bg-secondary border-0 position-absolute top-0 end-0" role="alert" aria-live="assertive" aria-atomic="true">
  <div class="d-flex">
    <div class="toast-body">
      Copied!
    </div>
  </div>
</div>

---
Primary Category: cs.LG  
Categories: cs-CR, cs-LG, cs.LG  
Keyword Score: 10  
Keywords: Mutual Information  
<a type="button" class="btn btn-outline-primary" href="http://arxiv.org/abs/2402.18787v1" target="_blank" >Paper Link</a>
<button type="button" class="btn btn-outline-primary download-pdf" url="https://arxiv.org/pdf/2402.18787v1.pdf" filename="2402.18787v1.pdf">Download PDF</button>

---


**ABSTRACT**  
Recent studies have revealed the vulnerability of Deep Neural Networks (DNNs) to adversarial examples, which can easily fool DNNs into making incorrect predictions. To mitigate this deficiency, we propose a novel adversarial defense method called "Immunity" (Innovative MoE with <b>MUtual</b> <b>information</b> \& positioN stabilITY) based on a modified Mixture-of-Experts (MoE) architecture in this work. The key enhancements to the standard MoE are two-fold: 1) integrating of Random Switch Gates (RSGs) to obtain diverse network structures via random permutation of RSG parameters at evaluation time, despite of RSGs being determined after one-time training; 2) devising innovative <b>Mutual</b> <b>Information</b> (MI)-based and Position Stability-based loss functions by capitalizing on Grad-CAM's explanatory power to increase the diversity and the causality of expert networks. Notably, our MI-based loss operates directly on the heatmaps, thereby inducing subtler negative impacts on the classification performance when compared to other losses of the same type, theoretically. Extensive evaluation validates the efficacy of the proposed approach in improving adversarial robustness against a wide range of attacks.

{{</citation>}}


### (61/68 | 186/321) Disentangling the Causes of Plasticity Loss in Neural Networks (Clare Lyle et al., 2024)

{{<citation>}}

Clare Lyle, Zeyu Zheng, Khimya Khetarpal, Hado van Hasselt, Razvan Pascanu, James Martens, Will Dabney. (2024)  
**Disentangling the Causes of Plasticity Loss in Neural Networks**
<br/>
<button class="copy-to-clipboard" title="Disentangling the Causes of Plasticity Loss in Neural Networks" index=186>
  <span class="copy-to-clipboard-item">Copy Title<span>
</button>
<div class="toast toast-copied toast-index-186 align-items-center text-bg-secondary border-0 position-absolute top-0 end-0" role="alert" aria-live="assertive" aria-atomic="true">
  <div class="d-flex">
    <div class="toast-body">
      Copied!
    </div>
  </div>
</div>

---
Primary Category: cs.LG  
Categories: cs-LG, cs.LG  
Keyword Score: 10  
Keywords: Reinforcement Learning  
<a type="button" class="btn btn-outline-primary" href="http://arxiv.org/abs/2402.18762v1" target="_blank" >Paper Link</a>
<button type="button" class="btn btn-outline-primary download-pdf" url="https://arxiv.org/pdf/2402.18762v1.pdf" filename="2402.18762v1.pdf">Download PDF</button>

---


**ABSTRACT**  
Underpinning the past decades of work on the design, initialization, and optimization of neural networks is a seemingly innocuous assumption: that the network is trained on a \textit{stationary} data distribution. In settings where this assumption is violated, e.g.\ deep <b>reinforcement</b> <b>learning,</b> learning algorithms become unstable and brittle with respect to hyperparameters and even random seeds. One factor driving this instability is the loss of plasticity, meaning that updating the network's predictions in response to new information becomes more difficult as training progresses. While many recent works provide analyses and partial solutions to this phenomenon, a fundamental question remains unanswered: to what extent do known mechanisms of plasticity loss overlap, and how can mitigation strategies be combined to best maintain the trainability of a network? This paper addresses these questions, showing that loss of plasticity can be decomposed into multiple independent mechanisms and that, while intervening on any single mechanism is insufficient to avoid the loss of plasticity in all cases, intervening on multiple mechanisms in conjunction results in highly robust learning algorithms. We show that a combination of layer normalization and weight decay is highly effective at maintaining plasticity in a variety of synthetic nonstationary learning tasks, and further demonstrate its effectiveness on naturally arising nonstationarities, including <b>reinforcement</b> <b>learning</b> in the Arcade Learning Environment.

{{</citation>}}


### (62/68 | 187/321) Lifelong Benchmarks: Efficient Model Evaluation in an Era of Rapid Progress (Ameya Prabhu et al., 2024)

{{<citation>}}

Ameya Prabhu, Vishaal Udandarao, Philip Torr, Matthias Bethge, Adel Bibi, Samuel Albanie. (2024)  
**Lifelong Benchmarks: Efficient Model Evaluation in an Era of Rapid Progress**
<br/>
<button class="copy-to-clipboard" title="Lifelong Benchmarks: Efficient Model Evaluation in an Era of Rapid Progress" index=187>
  <span class="copy-to-clipboard-item">Copy Title<span>
</button>
<div class="toast toast-copied toast-index-187 align-items-center text-bg-secondary border-0 position-absolute top-0 end-0" role="alert" aria-live="assertive" aria-atomic="true">
  <div class="d-flex">
    <div class="toast-body">
      Copied!
    </div>
  </div>
</div>

---
Primary Category: cs.LG  
Categories: cs-CV, cs-LG, cs.LG  
Keyword Score: 6  
Keywords: Benchmarking, Benchmarking  
<a type="button" class="btn btn-outline-primary" href="http://arxiv.org/abs/2402.19472v1" target="_blank" >Paper Link</a>
<button type="button" class="btn btn-outline-primary download-pdf" url="https://arxiv.org/pdf/2402.19472v1.pdf" filename="2402.19472v1.pdf">Download PDF</button>

---


**ABSTRACT**  
Standardized <b>benchmarks</b> drive progress in machine learning. However, with repeated testing, the risk of overfitting grows as algorithms over-exploit <b>benchmark</b> idiosyncrasies. In our work, we seek to mitigate this challenge by compiling ever-expanding large-scale <b>benchmarks</b> called Lifelong <b>Benchmarks.</b> As exemplars of our approach, we create Lifelong-CIFAR10 and Lifelong-ImageNet, containing (for now) 1.69M and 1.98M test samples, respectively. While reducing overfitting, lifelong <b>benchmarks</b> introduce a key challenge: the high cost of evaluating a growing number of models across an ever-expanding sample set. To address this challenge, we also introduce an efficient evaluation framework: Sort \& Search (S&S), which reuses previously evaluated models by leveraging dynamic programming algorithms to selectively rank and sub-select test samples, enabling cost-effective lifelong <b>benchmarking.</b> Extensive empirical evaluations across 31,000 models demonstrate that S&S achieves highly-efficient approximate accuracy measurement, reducing compute cost from 180 GPU days to 5 GPU hours (1000x reduction) on a single A100 GPU, with low approximation error. As such, lifelong <b>benchmarks</b> offer a robust, practical solution to the <b>"benchmark</b> exhaustion" problem.

{{</citation>}}


### (63/68 | 188/321) Probabilistic Lipschitzness and the Stable Rank for Comparing Explanation Models (Lachlan Simpson et al., 2024)

{{<citation>}}

Lachlan Simpson, Kyle Millar, Adriel Cheng, Cheng-Chew Lim, Hong Gunn Chew. (2024)  
**Probabilistic Lipschitzness and the Stable Rank for Comparing Explanation Models**
<br/>
<button class="copy-to-clipboard" title="Probabilistic Lipschitzness and the Stable Rank for Comparing Explanation Models" index=188>
  <span class="copy-to-clipboard-item">Copy Title<span>
</button>
<div class="toast toast-copied toast-index-188 align-items-center text-bg-secondary border-0 position-absolute top-0 end-0" role="alert" aria-live="assertive" aria-atomic="true">
  <div class="d-flex">
    <div class="toast-body">
      Copied!
    </div>
  </div>
</div>

---
Primary Category: cs.LG  
Categories: cs-LG, cs.LG  
Keyword Score: 5  
Keywords: Black Box  
<a type="button" class="btn btn-outline-primary" href="http://arxiv.org/abs/2402.18863v1" target="_blank" >Paper Link</a>
<button type="button" class="btn btn-outline-primary download-pdf" url="https://arxiv.org/pdf/2402.18863v1.pdf" filename="2402.18863v1.pdf">Download PDF</button>

---


**ABSTRACT**  
Explainability models are now prevalent within machine learning to address the <b>black-box</b> <b>nature</b> of neural networks. The question now is which explainability model is most effective. Probabilistic Lipschitzness has demonstrated that the smoothness of a neural network is fundamentally linked to the quality of post hoc explanations. In this work, we prove theoretical lower bounds on the probabilistic Lipschitzness of Integrated Gradients, LIME and SmoothGrad. We propose a novel metric using probabilistic Lipschitzness, normalised astuteness, to compare the robustness of explainability models. Further, we prove a link between the local Lipschitz constant of a neural network and its stable rank. We then demonstrate that the stable rank of a neural network provides a heuristic for the robustness of explainability models.

{{</citation>}}


### (64/68 | 189/321) Learnability Gaps of Strategic Classification (Lee Cohen et al., 2024)

{{<citation>}}

Lee Cohen, Yishay Mansour, Shay Moran, Han Shao. (2024)  
**Learnability Gaps of Strategic Classification**
<br/>
<button class="copy-to-clipboard" title="Learnability Gaps of Strategic Classification" index=189>
  <span class="copy-to-clipboard-item">Copy Title<span>
</button>
<div class="toast toast-copied toast-index-189 align-items-center text-bg-secondary border-0 position-absolute top-0 end-0" role="alert" aria-live="assertive" aria-atomic="true">
  <div class="d-flex">
    <div class="toast-body">
      Copied!
    </div>
  </div>
</div>

---
Primary Category: cs.LG  
Categories: cs-GT, cs-LG, cs.LG  
Keyword Score: 3  
Keywords: Graph  
<a type="button" class="btn btn-outline-primary" href="http://arxiv.org/abs/2402.19303v1" target="_blank" >Paper Link</a>
<button type="button" class="btn btn-outline-primary download-pdf" url="https://arxiv.org/pdf/2402.19303v1.pdf" filename="2402.19303v1.pdf">Download PDF</button>

---


**ABSTRACT**  
In contrast with standard classification tasks, strategic classification involves agents strategically modifying their features in an effort to receive favorable predictions. For instance, given a classifier determining loan approval based on credit scores, applicants may open or close their credit cards to fool the classifier. The learning goal is to find a classifier robust against strategic manipulations. Various settings, based on what and when information is known, have been explored in strategic classification. In this work, we focus on addressing a fundamental question: the learnability gaps between strategic classification and standard learning. We essentially show that any learnable class is also strategically learnable: we first consider a fully informative setting, where the manipulation structure (which is modeled by a manipulation <b>graph</b> $G^\star$) is known and during training time the learner has access to both the pre-manipulation data and post-manipulation data. We provide nearly tight sample complexity and regret bounds, offering significant improvements over prior results. Then, we relax the fully informative setting by introducing two natural types of uncertainty. First, following Ahmadi et al. (2023), we consider the setting in which the learner only has access to the post-manipulation data. We improve the results of Ahmadi et al. (2023) and close the gap between mistake upper bound and lower bound raised by them. Our second relaxation of the fully informative setting introduces uncertainty to the manipulation structure. That is, we assume that the manipulation <b>graph</b> is unknown but belongs to a known class of <b>graphs.</b> We provide nearly tight bounds on the learning complexity in various unknown manipulation <b>graph</b> settings. Notably, our algorithm in this setting is of independent interest and can be applied to other problems such as multi-label learning.

{{</citation>}}


### (65/68 | 190/321) Degradation Modeling and Prognostic Analysis Under Unknown Failure Modes (Ying Fu et al., 2024)

{{<citation>}}

Ying Fu, Ye Kwon Huh, Kaibo Liu. (2024)  
**Degradation Modeling and Prognostic Analysis Under Unknown Failure Modes**
<br/>
<button class="copy-to-clipboard" title="Degradation Modeling and Prognostic Analysis Under Unknown Failure Modes" index=190>
  <span class="copy-to-clipboard-item">Copy Title<span>
</button>
<div class="toast toast-copied toast-index-190 align-items-center text-bg-secondary border-0 position-absolute top-0 end-0" role="alert" aria-live="assertive" aria-atomic="true">
  <div class="d-flex">
    <div class="toast-body">
      Copied!
    </div>
  </div>
</div>

---
Primary Category: cs.LG  
Categories: cs-AI, cs-LG, cs.LG  
Keyword Score: 3  
Keywords: Clustering  
<a type="button" class="btn btn-outline-primary" href="http://arxiv.org/abs/2402.19294v1" target="_blank" >Paper Link</a>
<button type="button" class="btn btn-outline-primary download-pdf" url="https://arxiv.org/pdf/2402.19294v1.pdf" filename="2402.19294v1.pdf">Download PDF</button>

---


**ABSTRACT**  
Operating units often experience various failure modes in complex systems, leading to distinct degradation paths. Relying on a prognostic model trained on a single failure mode may lead to poor generalization performance across multiple failure modes. Therefore, accurately identifying the failure mode is of critical importance. Current prognostic approaches either ignore failure modes during degradation or assume known failure mode labels, which can be challenging to acquire in practice. Moreover, the high dimensionality and complex relations of sensor signals make it challenging to identify the failure modes accurately. To address these issues, we propose a novel failure mode diagnosis method that leverages a dimension reduction technique called UMAP (Uniform Manifold Approximation and Projection) to project and visualize each unit's degradation trajectory into a lower dimension. Then, using these degradation trajectories, we develop a time series-based <b>clustering</b> method to identify the training units' failure modes. Finally, we introduce a monotonically constrained prognostic model to predict the failure mode labels and RUL of the test units simultaneously using the obtained failure modes of the training units. The proposed prognostic model provides failure mode-specific RUL predictions while preserving the monotonic property of the RUL predictions across consecutive time steps. We evaluate the proposed model using a case study with the aircraft gas turbine engine dataset.

{{</citation>}}


### (66/68 | 191/321) Negative-Binomial Randomized Gamma Markov Processes for Heterogeneous Overdispersed Count Time Series (Rui Huang et al., 2024)

{{<citation>}}

Rui Huang, Sikun Yang, Heinz Koeppl. (2024)  
**Negative-Binomial Randomized Gamma Markov Processes for Heterogeneous Overdispersed Count Time Series**
<br/>
<button class="copy-to-clipboard" title="Negative-Binomial Randomized Gamma Markov Processes for Heterogeneous Overdispersed Count Time Series" index=191>
  <span class="copy-to-clipboard-item">Copy Title<span>
</button>
<div class="toast toast-copied toast-index-191 align-items-center text-bg-secondary border-0 position-absolute top-0 end-0" role="alert" aria-live="assertive" aria-atomic="true">
  <div class="d-flex">
    <div class="toast-body">
      Copied!
    </div>
  </div>
</div>

---
Primary Category: cs.LG  
Categories: cs-AI, cs-LG, cs.LG, stat-ML  
Keyword Score: 3  
Keywords: Graph  
<a type="button" class="btn btn-outline-primary" href="http://arxiv.org/abs/2402.18995v1" target="_blank" >Paper Link</a>
<button type="button" class="btn btn-outline-primary download-pdf" url="https://arxiv.org/pdf/2402.18995v1.pdf" filename="2402.18995v1.pdf">Download PDF</button>

---


**ABSTRACT**  
Modeling count-valued time series has been receiving increasing attention since count time series naturally arise in physical and social domains. Poisson gamma dynamical systems (PGDSs) are newly-developed methods, which can well capture the expressive latent transition structure and bursty dynamics behind count sequences. In particular, PGDSs demonstrate superior performance in terms of data imputation and prediction, compared with canonical linear dynamical system (LDS) based methods. Despite these advantages, PGDS cannot capture the heterogeneous overdispersed behaviours of the underlying dynamic processes. To mitigate this defect, we propose a negative-binomial-randomized gamma Markov process, which not only significantly improves the predictive performance of the proposed dynamical system, but also facilitates the fast convergence of the inference algorithm. Moreover, we develop methods to estimate both factor-structured and <b>graph-structured</b> transition dynamics, which enable us to infer more explainable latent structure, compared with PGDSs. Finally, we demonstrate the explainable latent structure learned by the proposed method, and show its superior performance in imputing missing data and forecasting future observations, compared with the related models.

{{</citation>}}


### (67/68 | 192/321) Graph Generation via Spectral Diffusion (Giorgia Minello et al., 2024)

{{<citation>}}

Giorgia Minello, Alessandro Bicciato, Luca Rossi, Andrea Torsello, Luca Cosmo. (2024)  
**Graph Generation via Spectral Diffusion**
<br/>
<button class="copy-to-clipboard" title="Graph Generation via Spectral Diffusion" index=192>
  <span class="copy-to-clipboard-item">Copy Title<span>
</button>
<div class="toast toast-copied toast-index-192 align-items-center text-bg-secondary border-0 position-absolute top-0 end-0" role="alert" aria-live="assertive" aria-atomic="true">
  <div class="d-flex">
    <div class="toast-body">
      Copied!
    </div>
  </div>
</div>

---
Primary Category: cs.LG  
Categories: cs-LG, cs.LG  
Keyword Score: 3  
Keywords: Graph  
<a type="button" class="btn btn-outline-primary" href="http://arxiv.org/abs/2402.18974v1" target="_blank" >Paper Link</a>
<button type="button" class="btn btn-outline-primary download-pdf" url="https://arxiv.org/pdf/2402.18974v1.pdf" filename="2402.18974v1.pdf">Download PDF</button>

---


**ABSTRACT**  
In this paper, we present GRASP, a novel <b>graph</b> generative model based on 1) the spectral decomposition of the <b>graph</b> Laplacian matrix and 2) a diffusion process. Specifically, we propose to use a denoising model to sample eigenvectors and eigenvalues from which we can reconstruct the <b>graph</b> Laplacian and adjacency matrix. Our permutation invariant model can also handle node features by concatenating them to the eigenvectors of each node. Using the Laplacian spectrum allows us to naturally capture the structural characteristics of the <b>graph</b> and work directly in the node space while avoiding the quadratic complexity bottleneck that limits the applicability of other methods. This is achieved by truncating the spectrum, which as we show in our experiments results in a faster yet accurate generative process. An extensive set of experiments on both synthetic and real world <b>graphs</b> demonstrates the strengths of our model against state-of-the-art alternatives.

{{</citation>}}


### (68/68 | 193/321) Taking Second-life Batteries from Exhausted to Empowered using Experiments, Data Analysis, and Health Estimation (Xiaofan Cui et al., 2024)

{{<citation>}}

Xiaofan Cui, Muhammad Aadil Khan, Gabriele Pozzato, Surinder Singh, Ratnesh Sharma, Simona Onori. (2024)  
**Taking Second-life Batteries from Exhausted to Empowered using Experiments, Data Analysis, and Health Estimation**
<br/>
<button class="copy-to-clipboard" title="Taking Second-life Batteries from Exhausted to Empowered using Experiments, Data Analysis, and Health Estimation" index=193>
  <span class="copy-to-clipboard-item">Copy Title<span>
</button>
<div class="toast toast-copied toast-index-193 align-items-center text-bg-secondary border-0 position-absolute top-0 end-0" role="alert" aria-live="assertive" aria-atomic="true">
  <div class="d-flex">
    <div class="toast-body">
      Copied!
    </div>
  </div>
</div>

---
Primary Category: cs.LG  
Categories: cs-LG, cs-SY, cs.LG, eess-SY  
Keyword Score: 3  
Keywords: Clustering  
<a type="button" class="btn btn-outline-primary" href="http://arxiv.org/abs/2402.18859v1" target="_blank" >Paper Link</a>
<button type="button" class="btn btn-outline-primary download-pdf" url="https://arxiv.org/pdf/2402.18859v1.pdf" filename="2402.18859v1.pdf">Download PDF</button>

---


**ABSTRACT**  
The reuse of retired electric vehicle (EV) batteries in electric grid energy storage emerges as a promising strategy to address environmental concerns and boost economic value. This study concentrates on devising health monitoring algorithms for retired batteries (BMS$_2$) deployed in grid storage applications. Over 15 months of testing, we compile, analyze, and publicly share a dataset of second-life (SL) batteries, implementing a cycling protocol simulating grid energy storage load profiles within a 3 V-4 V voltage window. Four machine learning-based health estimation models, relying on BMS$_2$ features and initial capacity, are developed and compared, with the selected model achieving a Mean Absolute Percentage Error (MAPE) below 2.3% on test data. Additionally, an adaptive online health estimation algorithm is proposed by integrating a <b>clustering-based</b> method, limiting estimation errors during online deployment. These results constitute an initial proof of concept, showcasing the feasibility of repurposing retired batteries for second-life applications. Based on obtained data and representative power demand, these SL batteries exhibit the potential, under specific conditions, for over a decade of grid energy storage use.

{{</citation>}}


## cs.SE (8)



### (1/8 | 194/321) Compositional API Recommendation for Library-Oriented Code Generation (Zexiong Ma et al., 2024)

{{<citation>}}

Zexiong Ma, Shengnan An, Bing Xie, Zeqi Lin. (2024)  
**Compositional API Recommendation for Library-Oriented Code Generation**
<br/>
<button class="copy-to-clipboard" title="Compositional API Recommendation for Library-Oriented Code Generation" index=194>
  <span class="copy-to-clipboard-item">Copy Title<span>
</button>
<div class="toast toast-copied toast-index-194 align-items-center text-bg-secondary border-0 position-absolute top-0 end-0" role="alert" aria-live="assertive" aria-atomic="true">
  <div class="d-flex">
    <div class="toast-body">
      Copied!
    </div>
  </div>
</div>

---
Primary Category: cs.SE  
Categories: cs-AI, cs-CL, cs-SE, cs.SE  
Keyword Score: 53  
Keywords: Benchmarking, Recommendation, Code Generation, Large Language Model, Large Language Model, Prompt  
<a type="button" class="btn btn-outline-primary" href="http://arxiv.org/abs/2402.19431v1" target="_blank" >Paper Link</a>
<button type="button" class="btn btn-outline-primary download-pdf" url="https://arxiv.org/pdf/2402.19431v1.pdf" filename="2402.19431v1.pdf">Download PDF</button>

---


**ABSTRACT**  
<b>Large</b> <b>language</b> <b>models</b> <b>(LLMs)</b> have achieved exceptional performance in <b>code</b> <b>generation.</b> However, the performance remains unsatisfactory in generating library-oriented <b>code,</b> <b>especially</b> for the libraries not present in the training data of <b>LLMs.</b> Previous work utilizes API <b>recommendation</b> technology to help <b>LLMs</b> use libraries: it retrieves APIs related to the user requirements, then leverages them as context to <b>prompt</b> <b>LLMs.</b> However, developmental requirements can be coarse-grained, requiring a combination of multiple fine-grained APIs. This granularity inconsistency makes API <b>recommendation</b> a challenging task. To address this, we propose CAPIR (Compositional API <b>Recommendation),</b> which adopts a "divide-and-conquer" strategy to recommend APIs for coarse-grained requirements. Specifically, CAPIR employs an <b>LLM-based</b> Decomposer to break down a coarse-grained task description into several detailed subtasks. Then, CAPIR applies an embedding-based Retriever to identify relevant APIs corresponding to each subtask. Moreover, CAPIR leverages an <b>LLM-based</b> Reranker to filter out redundant APIs and provides the final <b>recommendation.</b> To facilitate the evaluation of API <b>recommendation</b> methods on coarse-grained requirements, we present two challenging <b>benchmarks,</b> RAPID (Recommend APIs based on Documentation) and LOCG (Library-Oriented <b>Code</b> <b>Generation).</b> Experimental results on these <b>benchmarks,</b> demonstrate the effectiveness of CAPIR in comparison to existing baselines. Specifically, on RAPID's Torchdata-AR dataset, compared to the state-of-the-art API <b>recommendation</b> approach, CAPIR improves recall@5 from 18.7% to 43.2% and precision@5 from 15.5% to 37.1%. On LOCG's Torchdata-Code dataset, compared to <b>code</b> <b>generation</b> without API <b>recommendation,</b> CAPIR improves pass@100 from 16.0% to 28.0%.

{{</citation>}}


### (2/8 | 195/321) StarCoder 2 and The Stack v2: The Next Generation (Anton Lozhkov et al., 2024)

{{<citation>}}

Anton Lozhkov, Raymond Li, Loubna Ben Allal, Federico Cassano, Joel Lamy-Poirier, Nouamane Tazi, Ao Tang, Dmytro Pykhtar, Jiawei Liu, Yuxiang Wei, Tianyang Liu, Max Tian, Denis Kocetkov, Arthur Zucker, Younes Belkada, Zijian Wang, Qian Liu, Dmitry Abulkhanov, Indraneil Paul, Zhuang Li, Wen-Ding Li, Megan Risdal, Jia Li, Jian Zhu, Terry Yue Zhuo, Evgenii Zheltonozhskii, Nii Osae Osae Dade, Wenhao Yu, Lucas Krauß, Naman Jain, Yixuan Su, Xuanli He, Manan Dey, Edoardo Abati, Yekun Chai, Niklas Muennighoff, Xiangru Tang, Muhtasham Oblokulov, Christopher Akiki, Marc Marone, Chenghao Mou, Mayank Mishra, Alex Gu, Binyuan Hui, Tri Dao, Armel Zebaze, Olivier Dehaene, Nicolas Patry, Canwen Xu, Julian McAuley, Han Hu, Torsten Scholak, Sebastien Paquet, Jennifer Robinson, Carolyn Jane Anderson, Nicolas Chapados, Mostofa Patwary, Nima Tajbakhsh, Yacine Jernite, Carlos Muñoz Ferrandis, Lingming Zhang, Sean Hughes, Thomas Wolf, Arjun Guha, Leandro von Werra, Harm de Vries. (2024)  
**StarCoder 2 and The Stack v2: The Next Generation**
<br/>
<button class="copy-to-clipboard" title="StarCoder 2 and The Stack v2: The Next Generation" index=195>
  <span class="copy-to-clipboard-item">Copy Title<span>
</button>
<div class="toast toast-copied toast-index-195 align-items-center text-bg-secondary border-0 position-absolute top-0 end-0" role="alert" aria-live="assertive" aria-atomic="true">
  <div class="d-flex">
    <div class="toast-body">
      Copied!
    </div>
  </div>
</div>

---
Primary Category: cs.SE  
Categories: cs-AI, cs-SE, cs.SE  
Keyword Score: 53  
Keywords: Benchmarking, High-Resource, Low-Resource, Reasoning, Large Language Model, Large Language Model  
<a type="button" class="btn btn-outline-primary" href="http://arxiv.org/abs/2402.19173v1" target="_blank" >Paper Link</a>
<button type="button" class="btn btn-outline-primary download-pdf" url="https://arxiv.org/pdf/2402.19173v1.pdf" filename="2402.19173v1.pdf">Download PDF</button>

---


**ABSTRACT**  
The BigCode project, an open-scientific collaboration focused on the responsible development of <b>Large</b> <b>Language</b> <b>Models</b> for Code (Code <b>LLMs),</b> introduces StarCoder2. In partnership with Software Heritage (SWH), we build The Stack v2 on top of the digital commons of their source code archive. Alongside the SWH repositories spanning 619 programming languages, we carefully select other high-quality data sources, such as GitHub pull requests, Kaggle notebooks, and code documentation. This results in a training set that is 4x larger than the first StarCoder dataset. We train StarCoder2 models with 3B, 7B, and 15B parameters on 3.3 to 4.3 trillion tokens and thoroughly evaluate them on a comprehensive set of Code <b>LLM</b> <b>benchmarks.</b> We find that our small model, StarCoder2-3B, outperforms other Code <b>LLMs</b> of similar size on most <b>benchmarks,</b> and also outperforms StarCoderBase-15B. Our <b>large</b> <b>model,</b> <b>StarCoder2-</b> 15B, significantly outperforms other models of comparable size. In addition, it matches or outperforms CodeLlama-34B, a model more than twice its size. Although DeepSeekCoder- 33B is the best-performing model at code completion for <b>high-resource</b> languages, we find that StarCoder2-15B outperforms it on math and code <b>reasoning</b> <b>benchmarks,</b> as well as several <b>low-resource</b> languages. We make the model weights available under an OpenRAIL license and ensure full transparency regarding the training data by releasing the SoftWare Heritage persistent IDentifiers (SWHIDs) of the source code data.

{{</citation>}}


### (3/8 | 196/321) SEED: Customize Large Language Models with Sample-Efficient Adaptation for Code Generation (Xue Jiang et al., 2024)

{{<citation>}}

Xue Jiang, Yihong Dong, Zhi Jin, Ge Li. (2024)  
**SEED: Customize Large Language Models with Sample-Efficient Adaptation for Code Generation**
<br/>
<button class="copy-to-clipboard" title="SEED: Customize Large Language Models with Sample-Efficient Adaptation for Code Generation" index=196>
  <span class="copy-to-clipboard-item">Copy Title<span>
</button>
<div class="toast toast-copied toast-index-196 align-items-center text-bg-secondary border-0 position-absolute top-0 end-0" role="alert" aria-live="assertive" aria-atomic="true">
  <div class="d-flex">
    <div class="toast-body">
      Copied!
    </div>
  </div>
</div>

---
Primary Category: cs.SE  
Categories: cs-AI, cs-CL, cs-SE, cs.SE  
Keyword Score: 40  
Keywords: Fine-tuning, Code Generation, Large Language Model, Large Language Model  
<a type="button" class="btn btn-outline-primary" href="http://arxiv.org/abs/2403.00046v1" target="_blank" >Paper Link</a>
<button type="button" class="btn btn-outline-primary download-pdf" url="https://arxiv.org/pdf/2403.00046v1.pdf" filename="2403.00046v1.pdf">Download PDF</button>

---


**ABSTRACT**  
Although <b>Large</b> <b>Language</b> <b>Models</b> <b>(LLMs)</b> have made significant progress in <b>code</b> <b>generation,</b> they still struggle with <b>code</b> <b>generation</b> tasks in specific scenarios. These scenarios usually necessitate the adaptation of <b>LLMs</b> to fulfill specific needs, but the limited training data available in practice leads to poor <b>code</b> <b>generation</b> performance. How to effectively adapt <b>LLMs</b> to new scenarios with fewer training samples is a major challenge for current <b>code</b> <b>generation.</b> In this paper, we propose a novel adaptation approach named SEED, which stands for Sample-Efficient adaptation with Error-Driven learning for <b>code</b> <b>generation.</b> SEED leverages the errors made by <b>LLMs</b> as learning opportunities, using error revision to overcome its own shortcomings, thus achieving efficient learning. Specifically, SEED involves identifying error <b>code</b> <b>generated</b> by <b>LLMs,</b> employing Self-revise for <b>code</b> <b>revision,</b> optimizing the model with revised <b>code,</b> <b>and</b> iteratively adapting the process for continuous improvement. Experimental results show that, compared to traditional <b>fine-tuning</b> approaches, SEED achieves superior performance with fewer training samples, showing a relative improvement of 27.2%-325.0% in Pass@1. We also validate the effectiveness of Self-revise, which generates revised <b>code</b> <b>that</b> optimizes the model more efficiently compared to the <b>code</b> <b>samples</b> from datasets. Moreover, SEED consistently demonstrates strong performance across various <b>LLMs,</b> underscoring its generalizability.

{{</citation>}}


### (4/8 | 197/321) FhGenie: A Custom, Confidentiality-preserving Chat AI for Corporate and Scientific Use (Ingo Weber et al., 2024)

{{<citation>}}

Ingo Weber, Hendrik Linka, Daniel Mertens, Tamara Muryshkin, Heinrich Opgenoorth, Stefan Langer. (2024)  
**FhGenie: A Custom, Confidentiality-preserving Chat AI for Corporate and Scientific Use**
<br/>
<button class="copy-to-clipboard" title="FhGenie: A Custom, Confidentiality-preserving Chat AI for Corporate and Scientific Use" index=197>
  <span class="copy-to-clipboard-item">Copy Title<span>
</button>
<div class="toast toast-copied toast-index-197 align-items-center text-bg-secondary border-0 position-absolute top-0 end-0" role="alert" aria-live="assertive" aria-atomic="true">
  <div class="d-flex">
    <div class="toast-body">
      Copied!
    </div>
  </div>
</div>

---
Primary Category: cs.SE  
Categories: cs-AI, cs-HC, cs-SE, cs.SE  
Keyword Score: 40  
Keywords: Generative AI, ChatGPT, Large Language Model, Large Language Model  
<a type="button" class="btn btn-outline-primary" href="http://arxiv.org/abs/2403.00039v1" target="_blank" >Paper Link</a>
<button type="button" class="btn btn-outline-primary download-pdf" url="https://arxiv.org/pdf/2403.00039v1.pdf" filename="2403.00039v1.pdf">Download PDF</button>

---


**ABSTRACT**  
Since OpenAI's release of <b>ChatGPT,</b> <b>generative</b> <b>AI</b> has received significant attention across various domains. These AI-based chat systems have the potential to enhance the productivity of knowledge workers in diverse tasks. However, the use of free public services poses a risk of data leakage, as service providers may exploit user input for additional training and optimization without clear boundaries. Even subscription-based alternatives sometimes lack transparency in handling user data. To address these concerns and enable Fraunhofer staff to leverage this technology while ensuring confidentiality, we have designed and developed a customized chat AI called FhGenie (genie being a reference to a helpful spirit). Within few days of its release, thousands of Fraunhofer employees started using this service. As pioneers in implementing such a system, many other organizations have followed suit. Our solution builds upon commercial <b>large</b> <b>language</b> <b>models</b> <b>(LLMs),</b> which we have carefully integrated into our system to meet our specific requirements and compliance constraints, including confidentiality and GDPR. In this paper, we share detailed insights into the architectural considerations, design, implementation, and subsequent updates of FhGenie. Additionally, we discuss challenges, observations, and the core lessons learned from its productive usage.

{{</citation>}}


### (5/8 | 198/321) The Counterfeit Conundrum: Can Code Language Models Grasp the Nuances of Their Incorrect Generations? (Alex Gu et al., 2024)

{{<citation>}}

Alex Gu, Wen-Ding Li, Naman Jain, Theo X. Olausson, Celine Lee, Koushik Sen, Armando Solar-Lezama. (2024)  
**The Counterfeit Conundrum: Can Code Language Models Grasp the Nuances of Their Incorrect Generations?**
<br/>
<button class="copy-to-clipboard" title="The Counterfeit Conundrum: Can Code Language Models Grasp the Nuances of Their Incorrect Generations?" index=198>
  <span class="copy-to-clipboard-item">Copy Title<span>
</button>
<div class="toast toast-copied toast-index-198 align-items-center text-bg-secondary border-0 position-absolute top-0 end-0" role="alert" aria-live="assertive" aria-atomic="true">
  <div class="d-flex">
    <div class="toast-body">
      Copied!
    </div>
  </div>
</div>

---
Primary Category: cs.SE  
Categories: cs-AI, cs-LG, cs-SE, cs.SE  
Keyword Score: 20  
Keywords: Code Generation, Reasoning  
<a type="button" class="btn btn-outline-primary" href="http://arxiv.org/abs/2402.19475v1" target="_blank" >Paper Link</a>
<button type="button" class="btn btn-outline-primary download-pdf" url="https://arxiv.org/pdf/2402.19475v1.pdf" filename="2402.19475v1.pdf">Download PDF</button>

---


**ABSTRACT**  
While language models are increasingly more proficient at <b>code</b> <b>generation,</b> they still frequently generate incorrect programs. Many of these programs are obviously wrong, but others are more subtle and pass weaker correctness checks such as being able to compile. In this work, we focus on these counterfeit samples: programs sampled from a language model that 1) have a high enough log-probability to be generated at a moderate temperature and 2) pass weak correctness checks. Overall, we discover that most models have a very shallow understanding of counterfeits through three clear failure modes. First, models mistakenly classify them as correct. Second, models are worse at <b>reasoning</b> about the execution behaviour of counterfeits and often predict their execution results as if they were correct. Third, when asking models to fix counterfeits, the likelihood of a model successfully repairing a counterfeit is often even lower than that of sampling a correct program from scratch. Counterfeits also have very unexpected properties: first, counterfeit programs for problems that are easier for a model to solve are not necessarily easier to detect and only slightly easier to execute and repair. Second, counterfeits from a given model are just as confusing to the model itself as they are to other models. Finally, both strong and weak models are able to generate counterfeit samples that equally challenge all models. In light of our findings, we recommend that care and caution be taken when relying on models to understand their own samples, especially when no external feedback is incorporated.

{{</citation>}}


### (6/8 | 199/321) AlloyASG: Alloy Predicate Code Representation as a Compact Structurally Balanced Graph (Guanxuan Wu et al., 2024)

{{<citation>}}

Guanxuan Wu, Allison Sullivan. (2024)  
**AlloyASG: Alloy Predicate Code Representation as a Compact Structurally Balanced Graph**
<br/>
<button class="copy-to-clipboard" title="AlloyASG: Alloy Predicate Code Representation as a Compact Structurally Balanced Graph" index=199>
  <span class="copy-to-clipboard-item">Copy Title<span>
</button>
<div class="toast toast-copied toast-index-199 align-items-center text-bg-secondary border-0 position-absolute top-0 end-0" role="alert" aria-live="assertive" aria-atomic="true">
  <div class="d-flex">
    <div class="toast-body">
      Copied!
    </div>
  </div>
</div>

---
Primary Category: cs.SE  
Categories: cs-PL, cs-SE, cs.SE  
Keyword Score: 13  
Keywords: Graph, Code Generation  
<a type="button" class="btn btn-outline-primary" href="http://arxiv.org/abs/2403.00170v1" target="_blank" >Paper Link</a>
<button type="button" class="btn btn-outline-primary download-pdf" url="https://arxiv.org/pdf/2403.00170v1.pdf" filename="2403.00170v1.pdf">Download PDF</button>

---


**ABSTRACT**  
In the program analysis and automated bug-fixing fields, it is common to create an abstract interpretation of a program's source <b>code</b> <b>as</b> an Abstract Syntax Tree (AST), which enables programs written in a high-level language to have various static and dynamic analyses applied. However, ASTs suffer from exponential growth in their data size due to the limitation that ASTs will often have identical nodes separately listed in the tree. To address this issue, we introduce a novel <b>code</b> <b>representation</b> schema, Complex Structurally Balanced Abstract Semantic <b>Graph</b> (CSBASG), which represents <b>code</b> <b>as</b> a complex-weighted directed <b>graph</b> that lists a semantic element as a node in the <b>graph</b> and ensures its structural balance for almost finitely enumerable <b>code</b> <b>segments,</b> such as the modeling language Alloy. Our experiment ensures that CSBASG provides a one-on-one correspondence of Alloy predicates to complex-weighted <b>graphs.</b> We evaluate the effectiveness and efficiency of our CSBASG representation for Alloy models and identify future applications of CSBASG for Alloy <b>code</b> <b>generation</b> and automated repair.

{{</citation>}}


### (7/8 | 200/321) Understanding Fairness in Software Engineering: Insights from Stack Exchange (Emeralda Sesari et al., 2024)

{{<citation>}}

Emeralda Sesari, Federica Sarro, Ayushi Rastogi. (2024)  
**Understanding Fairness in Software Engineering: Insights from Stack Exchange**
<br/>
<button class="copy-to-clipboard" title="Understanding Fairness in Software Engineering: Insights from Stack Exchange" index=200>
  <span class="copy-to-clipboard-item">Copy Title<span>
</button>
<div class="toast toast-copied toast-index-200 align-items-center text-bg-secondary border-0 position-absolute top-0 end-0" role="alert" aria-live="assertive" aria-atomic="true">
  <div class="d-flex">
    <div class="toast-body">
      Copied!
    </div>
  </div>
</div>

---
Primary Category: cs.SE  
Categories: cs-SE, cs.SE  
Keyword Score: 10  
Keywords: Fairness  
<a type="button" class="btn btn-outline-primary" href="http://arxiv.org/abs/2402.19038v1" target="_blank" >Paper Link</a>
<button type="button" class="btn btn-outline-primary download-pdf" url="https://arxiv.org/pdf/2402.19038v1.pdf" filename="2402.19038v1.pdf">Download PDF</button>

---


**ABSTRACT**  
Software practitioners discuss problems at work with peers, in-person and online. These discussions can be technical (e.g., how to fix a bug?) and social (e.g., how to assign work fairly?). While there is a growing body of knowledge exploring <b>fairness</b> problems and solutions in the human and social factors of software engineering, most focus has been on specific problems. This study provides <b>fairness</b> discussions by software practitioners on Stack Exchange sites. We present an exploratory study presenting the <b>fairness</b> experience of software practitioners and <b>fairness</b> expectations in software teams. We also want to identify the <b>fairness</b> aspects software practitioners talk about the most. For example, do they care more about <b>fairness</b> in income or how they are treated in the workplace? Our investigation of <b>fairness</b> discussions on eight Stack Exchange sites resulted in a list of 136 posts (28 questions and 108 answers) manually curated from 4,178 candidate posts. The study reveals that the majority of <b>fairness</b> discussions (24 posts) revolve around the topic of income suggesting that many software practitioners are highly interested in matters related to their pay and how it is fairly distributed. Further, we noted that while not discussed as often, discussions on <b>fairness</b> in recruitment tend to receive the highest number of views and scores. Interestingly, the study shows that unfairness experiences extend beyond the protected attributes. In this study, only 25 out of 136 posts mention protected attributes, with gender mainly being discussed.

{{</citation>}}


### (8/8 | 201/321) CEBin: A Cost-Effective Framework for Large-Scale Binary Code Similarity Detection (Hao Wang et al., 2024)

{{<citation>}}

Hao Wang, Zeyu Gao, Chao Zhang, Mingyang Sun, Yuchen Zhou, Han Qiu, Xi Xiao. (2024)  
**CEBin: A Cost-Effective Framework for Large-Scale Binary Code Similarity Detection**
<br/>
<button class="copy-to-clipboard" title="CEBin: A Cost-Effective Framework for Large-Scale Binary Code Similarity Detection" index=201>
  <span class="copy-to-clipboard-item">Copy Title<span>
</button>
<div class="toast toast-copied toast-index-201 align-items-center text-bg-secondary border-0 position-absolute top-0 end-0" role="alert" aria-live="assertive" aria-atomic="true">
  <div class="d-flex">
    <div class="toast-body">
      Copied!
    </div>
  </div>
</div>

---
Primary Category: cs.SE  
Categories: cs-CR, cs-SE, cs.SE  
Keyword Score: 3  
Keywords: Benchmarking  
<a type="button" class="btn btn-outline-primary" href="http://arxiv.org/abs/2402.18818v1" target="_blank" >Paper Link</a>
<button type="button" class="btn btn-outline-primary download-pdf" url="https://arxiv.org/pdf/2402.18818v1.pdf" filename="2402.18818v1.pdf">Download PDF</button>

---


**ABSTRACT**  
Binary code similarity detection (BCSD) is a fundamental technique for various application. Many BCSD solutions have been proposed recently, which mostly are embedding-based, but have shown limited accuracy and efficiency especially when the volume of target binaries to search is large. To address this issue, we propose a cost-effective BCSD framework, CEBin, which fuses embedding-based and comparison-based approaches to significantly improve accuracy while minimizing overheads. Specifically, CEBin utilizes a refined embedding-based approach to extract features of target code, which efficiently narrows down the scope of candidate similar code and boosts performance. Then, it utilizes a comparison-based approach that performs a pairwise comparison on the candidates to capture more nuanced and complex relationships, which greatly improves the accuracy of similarity detection. By bridging the gap between embedding-based and comparison-based approaches, CEBin is able to provide an effective and efficient solution for detecting similar code (including vulnerable ones) in large-scale software ecosystems. Experimental results on three well-known datasets demonstrate the superiority of CEBin over existing state-of-the-art (SOTA) baselines. To further evaluate the usefulness of BCSD in real world, we construct a large-scale <b>benchmark</b> of vulnerability, offering the first precise evaluation scheme to assess BCSD methods for the 1-day vulnerability detection task. CEBin could identify the similar function from millions of candidate functions in just a few seconds and achieves an impressive recall rate of $85.46\%$ on this more practical but challenging task, which are several order of magnitudes faster and $4.07\times$ better than the best SOTA baseline. Our code is available at https://github.com/Hustcw/CEBin.

{{</citation>}}


## cs.CY (7)



### (1/7 | 202/321) Wisdom of the Silicon Crowd: LLM Ensemble Prediction Capabilities Match Human Crowd Accuracy (Philipp Schoenegger et al., 2024)

{{<citation>}}

Philipp Schoenegger, Indre Tuminauskaite, Peter S. Park, Philip E. Tetlock. (2024)  
**Wisdom of the Silicon Crowd: LLM Ensemble Prediction Capabilities Match Human Crowd Accuracy**
<br/>
<button class="copy-to-clipboard" title="Wisdom of the Silicon Crowd: LLM Ensemble Prediction Capabilities Match Human Crowd Accuracy" index=202>
  <span class="copy-to-clipboard-item">Copy Title<span>
</button>
<div class="toast toast-copied toast-index-202 align-items-center text-bg-secondary border-0 position-absolute top-0 end-0" role="alert" aria-live="assertive" aria-atomic="true">
  <div class="d-flex">
    <div class="toast-body">
      Copied!
    </div>
  </div>
</div>

---
Primary Category: cs.CY  
Categories: cs-AI, cs-CL, cs-CY, cs-LG, cs.CY  
Keyword Score: 53  
Keywords: Benchmarking, Claude, GPT, GPT-4, Large Language Model, Large Language Model  
<a type="button" class="btn btn-outline-primary" href="http://arxiv.org/abs/2402.19379v1" target="_blank" >Paper Link</a>
<button type="button" class="btn btn-outline-primary download-pdf" url="https://arxiv.org/pdf/2402.19379v1.pdf" filename="2402.19379v1.pdf">Download PDF</button>

---


**ABSTRACT**  
Human forecasting accuracy in practice relies on the 'wisdom of the crowd' effect, in which predictions about future events are significantly improved by aggregating across a crowd of individual forecasters. Past work on the forecasting ability of <b>large</b> <b>language</b> <b>models</b> <b>(LLMs)</b> suggests that frontier <b>LLMs,</b> as individual forecasters, underperform compared to the gold standard of a human crowd forecasting tournament aggregate. In Study 1, we expand this research by using an <b>LLM</b> ensemble approach consisting of a crowd of twelve <b>LLMs.</b> We compare the aggregated <b>LLM</b> predictions on 31 binary questions to that of a crowd of 925 human forecasters from a three-month forecasting tournament. Our main analysis shows that the <b>LLM</b> crowd outperforms a simple no-information <b>benchmark</b> and is statistically equivalent to the human crowd. We also observe an acquiescence effect, with mean model predictions being significantly above 50%, despite an almost even split of positive and negative resolutions. Moreover, in Study 2, we test whether <b>LLM</b> predictions (of <b>GPT-4</b> and <b>Claude</b> 2) can be improved by drawing on human cognitive output. We find that both models' forecasting accuracy benefits from exposure to the median human prediction as information, improving accuracy by between 17% and 28%: though this leads to less accurate predictions than simply averaging human and machine forecasts. Our results suggest that <b>LLMs</b> can achieve forecasting accuracy rivaling that of human crowd forecasting tournaments: via the simple, practically applicable method of forecast aggregation. This replicates the 'wisdom of the crowd' effect for <b>LLMs,</b> and opens up their use for a variety applications throughout society.

{{</citation>}}


### (2/7 | 203/321) Mobile Health Text Misinformation Identification Using Mobile Data Mining (Wen-Chen Hu et al., 2024)

{{<citation>}}

Wen-Chen Hu, Sanjaikanth E Vadakkethil Somanathan Pillai, Abdelrahman Ahmed ElSaid. (2024)  
**Mobile Health Text Misinformation Identification Using Mobile Data Mining**
<br/>
<button class="copy-to-clipboard" title="Mobile Health Text Misinformation Identification Using Mobile Data Mining" index=203>
  <span class="copy-to-clipboard-item">Copy Title<span>
</button>
<div class="toast toast-copied toast-index-203 align-items-center text-bg-secondary border-0 position-absolute top-0 end-0" role="alert" aria-live="assertive" aria-atomic="true">
  <div class="d-flex">
    <div class="toast-body">
      Copied!
    </div>
  </div>
</div>

---
Primary Category: cs.CY  
Categories: cs-CY, cs.CY  
Keyword Score: 20  
Keywords: Information Retrieval, Stemming  
<a type="button" class="btn btn-outline-primary" href="http://arxiv.org/abs/2402.19280v2" target="_blank" >Paper Link</a>
<button type="button" class="btn btn-outline-primary download-pdf" url="https://arxiv.org/pdf/2402.19280v2.pdf" filename="2402.19280v2.pdf">Download PDF</button>

---


**ABSTRACT**  
More than six million people died of the COVID-19 by April 2022. The heavy casualties have put people on great and urgent alert and people try to find all kinds of <b>information</b> <b>to</b> keep them from being inflected by the coronavirus. This research tries to find out whether the mobile health text <b>information</b> <b>sent</b> to peoples devices is correct as smartphones becoming the major <b>information</b> <b>source</b> for people. The proposed method uses various mobile <b>information</b> <b>retrieval</b> and data mining technologies including lexical analysis, stopword elimination, <b>stemming,</b> and decision trees to classify the mobile health text <b>information</b> <b>to</b> one of the following classes: (i) true, (ii) fake, (iii) misinformative, (iv) disinformative, and (v) neutral. Experiment results show the accuracy of the proposed method is above the threshold value 50 percentage, but is not optimal. It is because the problem, mobile text misinformation identification, is intrinsically difficult.

{{</citation>}}


### (3/7 | 204/321) Shared lightweight autonomous vehicles for urban food deliveries: A simulation study (Ainhoa Genua Cerviño et al., 2024)

{{<citation>}}

Ainhoa Genua Cerviño, Naroa Coretti Sanchez, Elaine Liu Wang, Arnaud Grignard, Kent Larson. (2024)  
**Shared lightweight autonomous vehicles for urban food deliveries: A simulation study**
<br/>
<button class="copy-to-clipboard" title="Shared lightweight autonomous vehicles for urban food deliveries: A simulation study" index=204>
  <span class="copy-to-clipboard-item">Copy Title<span>
</button>
<div class="toast toast-copied toast-index-204 align-items-center text-bg-secondary border-0 position-absolute top-0 end-0" role="alert" aria-live="assertive" aria-atomic="true">
  <div class="d-flex">
    <div class="toast-body">
      Copied!
    </div>
  </div>
</div>

---
Primary Category: cs.CY  
Categories: cs-CY, cs.CY  
Keyword Score: 20  
Keywords: Simulation, Simulator  
<a type="button" class="btn btn-outline-primary" href="http://arxiv.org/abs/2402.19233v1" target="_blank" >Paper Link</a>
<button type="button" class="btn btn-outline-primary download-pdf" url="https://arxiv.org/pdf/2402.19233v1.pdf" filename="2402.19233v1.pdf">Download PDF</button>

---


**ABSTRACT**  
In recent years, the rapid growth of on-demand deliveries, especially in food deliveries, has spurred the exploration of innovative mobility solutions. In this context, lightweight autonomous vehicles have emerged as a potential alternative. However, their fleet-level behavior remains largely unexplored. To address this gap, we have developed an agent-based model and an environmental impact study assessing the fleet performance of lightweight autonomous food delivery vehicles. This model explores critical factors such as fleet sizing, service level, operational strategies, and environmental impacts. We have applied this model to a case study in Cambridge, MA, USA, where results indicate that there could be environmental benefits in replacing traditional car-based deliveries with shared lightweight autonomous vehicle fleets. Lastly, we introduce an interactive platform that offers a user-friendly means of comprehending the model's performance and potential trade-offs, which can help inform decision-makers in the evolving landscape of food delivery innovation.

{{</citation>}}


### (4/7 | 205/321) FATE in MMLA: A Student-Centred Exploration of Fairness, Accountability, Transparency, and Ethics in Multimodal Learning Analytics (Yueqiao Jin et al., 2024)

{{<citation>}}

Yueqiao Jin, Vanessa Echeverria, Lixiang Yan, Linxuan Zhao, Riordan Alfredo, Yi-Shan Tsai, Dragan Gašević, Roberto Martinez-Maldonado. (2024)  
**FATE in MMLA: A Student-Centred Exploration of Fairness, Accountability, Transparency, and Ethics in Multimodal Learning Analytics**
<br/>
<button class="copy-to-clipboard" title="FATE in MMLA: A Student-Centred Exploration of Fairness, Accountability, Transparency, and Ethics in Multimodal Learning Analytics" index=205>
  <span class="copy-to-clipboard-item">Copy Title<span>
</button>
<div class="toast toast-copied toast-index-205 align-items-center text-bg-secondary border-0 position-absolute top-0 end-0" role="alert" aria-live="assertive" aria-atomic="true">
  <div class="d-flex">
    <div class="toast-body">
      Copied!
    </div>
  </div>
</div>

---
Primary Category: cs.CY  
Categories: cs-CY, cs-HC, cs.CY  
Keyword Score: 16  
Keywords: Fairness, Multi-modal, Multi-modal  
<a type="button" class="btn btn-outline-primary" href="http://arxiv.org/abs/2402.19071v1" target="_blank" >Paper Link</a>
<button type="button" class="btn btn-outline-primary download-pdf" url="https://arxiv.org/pdf/2402.19071v1.pdf" filename="2402.19071v1.pdf">Download PDF</button>

---


**ABSTRACT**  
<b>Multimodal</b> Learning Analytics (MMLA) integrates novel sensing technologies and artificial intelligence algorithms, providing opportunities to enhance student reflection during complex, collaborative learning experiences. Although recent advancements in MMLA have shown its capability to generate insights into diverse learning behaviours across various learning settings, little research has been conducted to evaluate these systems in authentic learning contexts, particularly regarding students' perceived <b>fairness,</b> accountability, transparency, and ethics (FATE). Understanding these perceptions is essential to using MMLA effectively without introducing ethical complications or negatively affecting how students learn. This study aimed to address this gap by assessing the FATE of MMLA in an authentic, collaborative learning context. We conducted semi-structured interviews with 14 undergraduate students who used MMLA visualisations for post-activity reflection. The findings highlighted the significance of accurate and comprehensive data representation to ensure visualisation <b>fairness,</b> the need for different levels of data access to foster accountability, the imperative of measuring and cultivating transparency with students, and the necessity of transforming informed consent from dichotomous to continuous and measurable scales. While students value the benefits of MMLA, they also emphasise the importance of ethical considerations, highlighting a pressing need for the LA and MMLA community to investigate and address FATE issues actively.

{{</citation>}}


### (5/7 | 206/321) Future of Pandemic Prevention and Response CCC Workshop Report (David Danks et al., 2024)

{{<citation>}}

David Danks, Rada Mihalcea, Katie Siek, Mona Singh, Brian Dixon, Haley Griffin. (2024)  
**Future of Pandemic Prevention and Response CCC Workshop Report**
<br/>
<button class="copy-to-clipboard" title="Future of Pandemic Prevention and Response CCC Workshop Report" index=206>
  <span class="copy-to-clipboard-item">Copy Title<span>
</button>
<div class="toast toast-copied toast-index-206 align-items-center text-bg-secondary border-0 position-absolute top-0 end-0" role="alert" aria-live="assertive" aria-atomic="true">
  <div class="d-flex">
    <div class="toast-body">
      Copied!
    </div>
  </div>
</div>

---
Primary Category: cs.CY  
Categories: cs-CY, cs.CY  
Keyword Score: 10  
Keywords: Summarization  
<a type="button" class="btn btn-outline-primary" href="http://arxiv.org/abs/2403.00096v1" target="_blank" >Paper Link</a>
<button type="button" class="btn btn-outline-primary download-pdf" url="https://arxiv.org/pdf/2403.00096v1.pdf" filename="2403.00096v1.pdf">Download PDF</button>

---


**ABSTRACT**  
This report <b>summarizes</b> the discussions and conclusions of a 2-day multidisciplinary workshop that brought together researchers and practitioners in healthcare, computer science, and social sciences to explore what lessons were learned and what actions, primarily in research, could be taken. One consistent observation was that there is significant merit in thinking not only about pandemic situations, but also about peacetime advances, as many healthcare networks and communities are now in a perpetual state of crisis. Attendees discussed how the COVID-19 pandemic amplified gaps in our health and computing systems, and how current and future computing technologies could fill these gaps and improve the trajectory of the next pandemic. Three major computing themes emerged from the workshop: models, data, and infrastructure. Computational models are extremely important during pandemics, from anticipating supply needs of hospitals, to determining the care capacity of hospital and social service providers, to projecting the spread of the disease. Accurate, reliable models can save lives, and inform community leaders on policy decisions. Health system users require accurate, reliable data to achieve success when applying models. This requires data and measurement standardization across health care organizations, modernizing the data infrastructure, and methods for ensuring data remains private while shared for model development, validation, and application. Finally, many health care systems lack the data, compute, and communication infrastructures required to build models on their data, use those models in ordinary operations, or even to reliably access their data. Robust and timely computing research has the potential to better support healthcare works to save lives in times of crisis (e.g., pandemics) and today during relative peacetime.

{{</citation>}}


### (6/7 | 207/321) The Constitutions of Web3 (Joshua Z. Tan et al., 2024)

{{<citation>}}

Joshua Z. Tan, Max Langenkamp, Anna Weichselbraun, Ann Brody, Lucia Korpas. (2024)  
**The Constitutions of Web3**
<br/>
<button class="copy-to-clipboard" title="The Constitutions of Web3" index=207>
  <span class="copy-to-clipboard-item">Copy Title<span>
</button>
<div class="toast toast-copied toast-index-207 align-items-center text-bg-secondary border-0 position-absolute top-0 end-0" role="alert" aria-live="assertive" aria-atomic="true">
  <div class="d-flex">
    <div class="toast-body">
      Copied!
    </div>
  </div>
</div>

---
Primary Category: cs.CY  
Categories: cs-CY, cs.CY  
Keyword Score: 10  
Keywords: Recommendation  
<a type="button" class="btn btn-outline-primary" href="http://arxiv.org/abs/2403.00081v1" target="_blank" >Paper Link</a>
<button type="button" class="btn btn-outline-primary download-pdf" url="https://arxiv.org/pdf/2403.00081v1.pdf" filename="2403.00081v1.pdf">Download PDF</button>

---


**ABSTRACT**  
The governance of online communities has been a critical issue since the first USENET groups, and a number of serious constitutions -- declarations of goals, values, and rights -- have emerged since the mid-1990s. More recently, decentralized autonomous organizations (DAOs) have begun to publish their own constitutions, manifestos, and other governance documents. There are two unique aspects to these documents: they (1) often govern significantly more resources than previously-observed online communities, and (2) are used in conjunction with smart contracts that can secure certain community rights and processes through code. In this article, we analyze 25 DAO constitutions, observe a number of common patterns, and provide a template and a set of <b>recommendations</b> to support the crafting and dissemination of future DAO constitutions. We conclude with a report on how our template and <b>recommendations</b> were then used within the actual constitutional drafting process of a major blockchain.

{{</citation>}}


### (7/7 | 208/321) Envisioning the Applications and Implications of Generative AI for News Media (Sachita Nishal et al., 2024)

{{<citation>}}

Sachita Nishal, Nicholas Diakopoulos. (2024)  
**Envisioning the Applications and Implications of Generative AI for News Media**
<br/>
<button class="copy-to-clipboard" title="Envisioning the Applications and Implications of Generative AI for News Media" index=208>
  <span class="copy-to-clipboard-item">Copy Title<span>
</button>
<div class="toast toast-copied toast-index-208 align-items-center text-bg-secondary border-0 position-absolute top-0 end-0" role="alert" aria-live="assertive" aria-atomic="true">
  <div class="d-flex">
    <div class="toast-body">
      Copied!
    </div>
  </div>
</div>

---
Primary Category: cs.CY  
Categories: H-0; J-4, cs-CY, cs.CY  
Keyword Score: 10  
Keywords: Generative AI  
<a type="button" class="btn btn-outline-primary" href="http://arxiv.org/abs/2402.18835v1" target="_blank" >Paper Link</a>
<button type="button" class="btn btn-outline-primary download-pdf" url="https://arxiv.org/pdf/2402.18835v1.pdf" filename="2402.18835v1.pdf">Download PDF</button>

---


**ABSTRACT**  
This article considers the increasing use of algorithmic decision-support systems and synthetic media in the newsroom, and explores how <b>generative</b> <b>models</b> can help reporters and editors across a range of tasks from the conception of a news story to its distribution. Specifically, we draw from a taxonomy of tasks associated with news production, and discuss where <b>generative</b> <b>models</b> could appropriately support reporters, the journalistic and ethical values that must be preserved within these interactions, and the resulting implications for design contributions in this area in the future. Our essay is relevant to practitioners and researchers as they consider using <b>generative</b> <b>AI</b> systems to support different tasks and workflows.

{{</citation>}}


## cs.AI (6)



### (1/6 | 209/321) ToolNet: Connecting Large Language Models with Massive Tools via Tool Graph (Xukun Liu et al., 2024)

{{<citation>}}

Xukun Liu, Zhiyuan Peng, Xiaoyuan Yi, Xing Xie, Lirong Xiang, Yuchen Liu, Dongkuan Xu. (2024)  
**ToolNet: Connecting Large Language Models with Massive Tools via Tool Graph**
<br/>
<button class="copy-to-clipboard" title="ToolNet: Connecting Large Language Models with Massive Tools via Tool Graph" index=209>
  <span class="copy-to-clipboard-item">Copy Title<span>
</button>
<div class="toast toast-copied toast-index-209 align-items-center text-bg-secondary border-0 position-absolute top-0 end-0" role="alert" aria-live="assertive" aria-atomic="true">
  <div class="d-flex">
    <div class="toast-body">
      Copied!
    </div>
  </div>
</div>

---
Primary Category: cs.AI  
Categories: cs-AI, cs-CL, cs.AI  
Keyword Score: 53  
Keywords: Graph, Reasoning, In-context Learning, In-context Learning, Large Language Model, Large Language Model  
<a type="button" class="btn btn-outline-primary" href="http://arxiv.org/abs/2403.00839v1" target="_blank" >Paper Link</a>
<button type="button" class="btn btn-outline-primary download-pdf" url="https://arxiv.org/pdf/2403.00839v1.pdf" filename="2403.00839v1.pdf">Download PDF</button>

---


**ABSTRACT**  
While achieving remarkable progress in a broad range of tasks, <b>large</b> <b>language</b> <b>models</b> <b>(LLMs)</b> remain significantly limited in properly using massive external tools. Existing <b>in-context</b> <b>learning</b> approaches simply format tools into a list of plain text descriptions and input them to <b>LLMs,</b> from which, <b>LLMs</b> generate a sequence of tool calls to solve problems step by step. Such a paradigm ignores the intrinsic dependency between tools and offloads all <b>reasoning</b> loads to <b>LLMs,</b> making them restricted to a limited number of specifically designed tools. It thus remains challenging for <b>LLMs</b> to operate on a library of massive tools, casting a great limitation when confronted with real-world scenarios. This paper proposes ToolNet, a plug-and-play framework that scales up the number of tools to thousands with a moderate increase in token consumption. ToolNet organizes tools into a directed <b>graph.</b> Each node represents a tool, and weighted edges denote tool transition. Starting from an initial tool node, an <b>LLM</b> navigates in the <b>graph</b> by iteratively choosing the next one from its successors until the task is resolved. Extensive experiments show that ToolNet can achieve impressive results in challenging multi-hop tool learning datasets and is resilient to tool failures.

{{</citation>}}


### (2/6 | 210/321) RL-GPT: Integrating Reinforcement Learning and Code-as-policy (Shaoteng Liu et al., 2024)

{{<citation>}}

Shaoteng Liu, Haoqi Yuan, Minda Hu, Yanwei Li, Yukang Chen, Shu Liu, Zongqing Lu, Jiaya Jia. (2024)  
**RL-GPT: Integrating Reinforcement Learning and Code-as-policy**
<br/>
<button class="copy-to-clipboard" title="RL-GPT: Integrating Reinforcement Learning and Code-as-policy" index=210>
  <span class="copy-to-clipboard-item">Copy Title<span>
</button>
<div class="toast toast-copied toast-index-210 align-items-center text-bg-secondary border-0 position-absolute top-0 end-0" role="alert" aria-live="assertive" aria-atomic="true">
  <div class="d-flex">
    <div class="toast-body">
      Copied!
    </div>
  </div>
</div>

---
Primary Category: cs.AI  
Categories: cs-AI, cs-LG, cs.AI  
Keyword Score: 40  
Keywords: Reinforcement Learning, GPT, Large Language Model, Large Language Model  
<a type="button" class="btn btn-outline-primary" href="http://arxiv.org/abs/2402.19299v1" target="_blank" >Paper Link</a>
<button type="button" class="btn btn-outline-primary download-pdf" url="https://arxiv.org/pdf/2402.19299v1.pdf" filename="2402.19299v1.pdf">Download PDF</button>

---


**ABSTRACT**  
<b>Large</b> <b>Language</b> <b>Models</b> <b>(LLMs)</b> have demonstrated proficiency in utilizing various tools by coding, yet they face limitations in handling intricate logic and precise control. In embodied tasks, high-level planning is amenable to direct coding, while low-level actions often necessitate task-specific refinement, such as <b>Reinforcement</b> <b>Learning</b> (RL). To seamlessly integrate both modalities, we introduce a two-level hierarchical framework, RL-GPT, comprising a slow agent and a fast agent. The slow agent analyzes actions suitable for coding, while the fast agent executes coding tasks. This decomposition effectively focuses each agent on specific tasks, proving highly efficient within our pipeline. Our approach outperforms traditional RL methods and existing <b>GPT</b> agents, demonstrating superior efficiency. In the Minecraft game, it rapidly obtains diamonds within a single day on an RTX3090. Additionally, it achieves SOTA performance across all designated MineDojo tasks.

{{</citation>}}


### (3/6 | 211/321) Functional Benchmarks for Robust Evaluation of Reasoning Performance, and the Reasoning Gap (Saurabh Srivastava et al., 2024)

{{<citation>}}

Saurabh Srivastava, Annarose M B, Anto P V, Shashank Menon, Ajay Sukumar, Adwaith Samod T, Alan Philipose, Stevin Prince, Sooraj Thomas. (2024)  
**Functional Benchmarks for Robust Evaluation of Reasoning Performance, and the Reasoning Gap**
<br/>
<button class="copy-to-clipboard" title="Functional Benchmarks for Robust Evaluation of Reasoning Performance, and the Reasoning Gap" index=211>
  <span class="copy-to-clipboard-item">Copy Title<span>
</button>
<div class="toast toast-copied toast-index-211 align-items-center text-bg-secondary border-0 position-absolute top-0 end-0" role="alert" aria-live="assertive" aria-atomic="true">
  <div class="d-flex">
    <div class="toast-body">
      Copied!
    </div>
  </div>
</div>

---
Primary Category: cs.AI  
Categories: cs-AI, cs-CL, cs.AI  
Keyword Score: 23  
Keywords: Benchmarking, Reasoning, Prompt  
<a type="button" class="btn btn-outline-primary" href="http://arxiv.org/abs/2402.19450v1" target="_blank" >Paper Link</a>
<button type="button" class="btn btn-outline-primary download-pdf" url="https://arxiv.org/pdf/2402.19450v1.pdf" filename="2402.19450v1.pdf">Download PDF</button>

---


**ABSTRACT**  
We propose a framework for robust evaluation of <b>reasoning</b> capabilities of language models, using functional variants of <b>benchmarks.</b> Models that solve a <b>reasoning</b> test should exhibit no difference in performance over the static version of a problem compared to a snapshot of the functional variant. We have rewritten the relevant fragment of the MATH <b>benchmark</b> into its functional variant MATH(), with functionalization of other <b>benchmarks</b> to follow. When evaluating current state-of-the-art models over snapshots of MATH(), we find a <b>reasoning</b> gap -- the percentage difference between the static and functional accuracies. We find <b>reasoning</b> gaps from 58.35% to 80.31% among the state-of-the-art closed and open weights models that perform well on static <b>benchmarks,</b> with the caveat that the gaps are likely to be smaller with more sophisticated <b>prompting</b> strategies. Here we show that models which anecdotally have good <b>reasoning</b> performance over real-world tasks, have quantifiable lower gaps, motivating the open problem of building "gap 0" models. Code for evaluation and new evaluation datasets, three MATH() snapshots, are publicly available at https://github.com/consequentai/fneval/.

{{</citation>}}


### (4/6 | 212/321) A Cognitive-Based Trajectory Prediction Approach for Autonomous Driving (Haicheng Liao et al., 2024)

{{<citation>}}

Haicheng Liao, Yongkang Li, Zhenning Li, Chengyue Wang, Zhiyong Cui, Shengbo Eben Li, Chengzhong Xu. (2024)  
**A Cognitive-Based Trajectory Prediction Approach for Autonomous Driving**
<br/>
<button class="copy-to-clipboard" title="A Cognitive-Based Trajectory Prediction Approach for Autonomous Driving" index=212>
  <span class="copy-to-clipboard-item">Copy Title<span>
</button>
<div class="toast toast-copied toast-index-212 align-items-center text-bg-secondary border-0 position-absolute top-0 end-0" role="alert" aria-live="assertive" aria-atomic="true">
  <div class="d-flex">
    <div class="toast-body">
      Copied!
    </div>
  </div>
</div>

---
Primary Category: cs.AI  
Categories: cs-AI, cs-RO, cs.AI  
Keyword Score: 23  
Keywords: Benchmarking, Knowledge Distillation, Knowledge Distillation  
<a type="button" class="btn btn-outline-primary" href="http://arxiv.org/abs/2402.19251v1" target="_blank" >Paper Link</a>
<button type="button" class="btn btn-outline-primary download-pdf" url="https://arxiv.org/pdf/2402.19251v1.pdf" filename="2402.19251v1.pdf">Download PDF</button>

---


**ABSTRACT**  
In autonomous vehicle (AV) technology, the ability to accurately predict the movements of surrounding vehicles is paramount for ensuring safety and operational efficiency. Incorporating human decision-making insights enables AVs to more effectively anticipate the potential actions of other vehicles, significantly improving prediction accuracy and responsiveness in dynamic environments. This paper introduces the Human-Like Trajectory Prediction (HLTP) model, which adopts a teacher-student <b>knowledge</b> <b>distillation</b> framework inspired by human cognitive processes. The HLTP model incorporates a sophisticated teacher-student <b>knowledge</b> <b>distillation</b> framework. The "teacher" model, equipped with an adaptive visual sector, mimics the visual processing of the human brain, particularly the functions of the occipital and temporal lobes. The "student" model focuses on real-time interaction and decision-making, drawing parallels to prefrontal and parietal cortex functions. This approach allows for dynamic adaptation to changing driving scenarios, capturing essential perceptual cues for accurate prediction. Evaluated using the Macao Connected and Autonomous Driving (MoCAD) dataset, along with the NGSIM and HighD <b>benchmarks,</b> HLTP demonstrates superior performance compared to existing models, particularly in challenging environments with incomplete data. The project page is available at Github.

{{</citation>}}


### (5/6 | 213/321) Negative Sampling in Knowledge Graph Representation Learning: A Review (Tiroshan Madushanka et al., 2024)

{{<citation>}}

Tiroshan Madushanka, Ryutaro Ichise. (2024)  
**Negative Sampling in Knowledge Graph Representation Learning: A Review**
<br/>
<button class="copy-to-clipboard" title="Negative Sampling in Knowledge Graph Representation Learning: A Review" index=213>
  <span class="copy-to-clipboard-item">Copy Title<span>
</button>
<div class="toast toast-copied toast-index-213 align-items-center text-bg-secondary border-0 position-absolute top-0 end-0" role="alert" aria-live="assertive" aria-atomic="true">
  <div class="d-flex">
    <div class="toast-body">
      Copied!
    </div>
  </div>
</div>

---
Primary Category: cs.AI  
Categories: cs-AI, cs.AI  
Keyword Score: 23  
Keywords: Graph, Graph Embedding, Knowledge Graph, Representation Learning  
<a type="button" class="btn btn-outline-primary" href="http://arxiv.org/abs/2402.19195v1" target="_blank" >Paper Link</a>
<button type="button" class="btn btn-outline-primary download-pdf" url="https://arxiv.org/pdf/2402.19195v1.pdf" filename="2402.19195v1.pdf">Download PDF</button>

---


**ABSTRACT**  
<b>Knowledge</b> <b>graph</b> <b>representation</b> <b>learning</b> (KGRL) or <b>knowledge</b> <b>graph</b> <b>embedding</b> (KGE) plays a crucial role in AI applications for <b>knowledge</b> <b>construction</b> and information exploration. These models aim to encode entities and relations present in a <b>knowledge</b> <b>graph</b> <b>into</b> a lower-dimensional vector space. During the training process of KGE models, using positive and negative samples becomes essential for discrimination purposes. However, obtaining negative samples directly from existing <b>knowledge</b> <b>graphs</b> <b>poses</b> a challenge, emphasizing the need for effective generation techniques. The quality of these negative samples greatly impacts the accuracy of the learned embeddings, making their generation a critical aspect of KGRL. This comprehensive survey paper systematically reviews various negative sampling (NS) methods and their contributions to the success of KGRL. Their respective advantages and disadvantages are outlined by categorizing existing NS methods into five distinct categories. Moreover, this survey identifies open research questions that serve as potential directions for future investigations. By offering a generalization and alignment of fundamental NS concepts, this survey provides valuable insights for designing effective NS methods in the context of KGRL and serves as a motivating force for further advancements in the field.

{{</citation>}}


### (6/6 | 214/321) Pivoting Retail Supply Chain with Deep Generative Techniques: Taxonomy, Survey and Insights (Yuan Wang et al., 2024)

{{<citation>}}

Yuan Wang, Lokesh Kumar Sambasivan, Mingang Fu, Prakhar Mehrotra. (2024)  
**Pivoting Retail Supply Chain with Deep Generative Techniques: Taxonomy, Survey and Insights**
<br/>
<button class="copy-to-clipboard" title="Pivoting Retail Supply Chain with Deep Generative Techniques: Taxonomy, Survey and Insights" index=214>
  <span class="copy-to-clipboard-item">Copy Title<span>
</button>
<div class="toast toast-copied toast-index-214 align-items-center text-bg-secondary border-0 position-absolute top-0 end-0" role="alert" aria-live="assertive" aria-atomic="true">
  <div class="d-flex">
    <div class="toast-body">
      Copied!
    </div>
  </div>
</div>

---
Primary Category: cs.AI  
Categories: cs-AI, cs-LG, cs.AI  
Keyword Score: 20  
Keywords: Generative AI, ChatGPT  
<a type="button" class="btn btn-outline-primary" href="http://arxiv.org/abs/2403.00861v1" target="_blank" >Paper Link</a>
<button type="button" class="btn btn-outline-primary download-pdf" url="https://arxiv.org/pdf/2403.00861v1.pdf" filename="2403.00861v1.pdf">Download PDF</button>

---


**ABSTRACT**  
<b>Generative</b> <b>AI</b> applications, such as <b>ChatGPT</b> or DALL-E, have shown the world their impressive capabilities in generating human-like text or image. Diving deeper, the science stakeholder for those AI applications are Deep <b>Generative</b> <b>Models,</b> a.k.a DGMs, which are designed to learn the underlying distribution of the data and generate new data points that are statistically similar to the original dataset. One critical question is raised: how can we leverage DGMs into morden retail supply chain realm? To address this question, this paper expects to provide a comprehensive review of DGMs and discuss their existing and potential usecases in retail supply chain, by (1) providing a taxonomy and overview of state-of-the-art DGMs and their variants, (2) reviewing existing DGM applications in retail supply chain from a end-to-end view of point, and (3) discussing insights and potential directions on how DGMs can be further utilized on solving retail supply chain problems.

{{</citation>}}


## cs.CR (11)



### (1/11 | 215/321) Always be Pre-Training: Representation Learning for Network Intrusion Detection with GNNs (Zhengyao Gu et al., 2024)

{{<citation>}}

Zhengyao Gu, Diego Troy Lopez, Lilas Alrahis, Ozgur Sinanoglu. (2024)  
**Always be Pre-Training: Representation Learning for Network Intrusion Detection with GNNs**
<br/>
<button class="copy-to-clipboard" title="Always be Pre-Training: Representation Learning for Network Intrusion Detection with GNNs" index=215>
  <span class="copy-to-clipboard-item">Copy Title<span>
</button>
<div class="toast toast-copied toast-index-215 align-items-center text-bg-secondary border-0 position-absolute top-0 end-0" role="alert" aria-live="assertive" aria-atomic="true">
  <div class="d-flex">
    <div class="toast-body">
      Copied!
    </div>
  </div>
</div>

---
Primary Category: cs.CR  
Categories: cs-CR, cs.CR  
Keyword Score: 51  
Keywords: Graph, Graph Neural Network, Graph Neural Network, Benchmarking, Representation Learning, Supervised Learning, In-context Learning  
<a type="button" class="btn btn-outline-primary" href="http://arxiv.org/abs/2402.18986v1" target="_blank" >Paper Link</a>
<button type="button" class="btn btn-outline-primary download-pdf" url="https://arxiv.org/pdf/2402.18986v1.pdf" filename="2402.18986v1.pdf">Download PDF</button>

---


**ABSTRACT**  
<b>Graph</b> <b>neural</b> <b>network-based</b> network intrusion detection systems have recently demonstrated state-of-the-art performance on <b>benchmark</b> datasets. Nevertheless, these methods suffer from a reliance on target encoding for data pre-processing, limiting widespread adoption due to the associated need for annotated labels--a cost-prohibitive requirement. In this work, we propose a solution involving <b>in-context</b> pre-training and the utilization of dense <b>representations</b> <b>for</b> categorical features to jointly overcome the label-dependency limitation. Our approach exhibits remarkable data efficiency, achieving over 98% of the performance of the <b>supervised</b> state-of-the-art with less than 4% labeled data on the NF-UQ-NIDS-V2 dataset.

{{</citation>}}


### (2/11 | 216/321) PRSA: Prompt Reverse Stealing Attacks against Large Language Models (Yong Yang et al., 2024)

{{<citation>}}

Yong Yang, Xuhong Zhang, Yi Jiang, Xi Chen, Haoyu Wang, Shouling Ji, Zonghui Wang. (2024)  
**PRSA: Prompt Reverse Stealing Attacks against Large Language Models**
<br/>
<button class="copy-to-clipboard" title="PRSA: Prompt Reverse Stealing Attacks against Large Language Models" index=216>
  <span class="copy-to-clipboard-item">Copy Title<span>
</button>
<div class="toast toast-copied toast-index-216 align-items-center text-bg-secondary border-0 position-absolute top-0 end-0" role="alert" aria-live="assertive" aria-atomic="true">
  <div class="d-flex">
    <div class="toast-body">
      Copied!
    </div>
  </div>
</div>

---
Primary Category: cs.CR  
Categories: cs-CL, cs-CR, cs.CR  
Keyword Score: 50  
Keywords: Fine-tuning, Pruning, Large Language Model, Large Language Model, Prompt  
<a type="button" class="btn btn-outline-primary" href="http://arxiv.org/abs/2402.19200v1" target="_blank" >Paper Link</a>
<button type="button" class="btn btn-outline-primary download-pdf" url="https://arxiv.org/pdf/2402.19200v1.pdf" filename="2402.19200v1.pdf">Download PDF</button>

---


**ABSTRACT**  
<b>Prompt,</b> recognized as crucial intellectual property, enables <b>large</b> <b>language</b> <b>models</b> <b>(LLMs)</b> to perform specific tasks without the need of <b>fine-tuning,</b> underscoring their escalating importance. With the rise of <b>prompt-based</b> services, such as <b>prompt</b> marketplaces and <b>LLM</b> applications, providers often display <b>prompts'</b> capabilities through input-output examples to attract users. However, this paradigm raises a pivotal security concern: does the exposure of input-output pairs pose the risk of potential <b>prompt</b> leakage, infringing on the intellectual property rights of the developers? To our knowledge, this problem still has not been comprehensively explored yet. To remedy this gap, in this paper, we perform the first in depth exploration and propose a novel attack framework for reverse-stealing <b>prompts</b> against commercial <b>LLMs,</b> namely PRSA. The main idea of PRSA is that by analyzing the critical features of the input-output pairs, we mimic and gradually infer (steal) the target <b>prompts.</b> In detail, PRSA mainly consists of two key phases: <b>prompt</b> mutation and <b>prompt</b> <b>pruning.</b> In the mutation phase, we propose a <b>prompt</b> attention algorithm based on differential feedback to capture these critical features for effectively inferring the target <b>prompts.</b> In the <b>prompt</b> <b>pruning</b> phase, we identify and mask the words dependent on specific inputs, enabling the <b>prompts</b> to accommodate diverse inputs for generalization. Through extensive evaluation, we verify that PRSA poses a severe threat in real world scenarios. We have reported these findings to <b>prompt</b> service providers and actively collaborate with them to take protective measures for <b>prompt</b> copyright.

{{</citation>}}


### (3/11 | 217/321) Syntactic Ghost: An Imperceptible General-purpose Backdoor Attacks on Pre-trained Language Models (Pengzhou Cheng et al., 2024)

{{<citation>}}

Pengzhou Cheng, Wei Du, Zongru Wu, Fengwei Zhang, Libo Chen, Gongshen Liu. (2024)  
**Syntactic Ghost: An Imperceptible General-purpose Backdoor Attacks on Pre-trained Language Models**
<br/>
<button class="copy-to-clipboard" title="Syntactic Ghost: An Imperceptible General-purpose Backdoor Attacks on Pre-trained Language Models" index=217>
  <span class="copy-to-clipboard-item">Copy Title<span>
</button>
<div class="toast toast-copied toast-index-217 align-items-center text-bg-secondary border-0 position-absolute top-0 end-0" role="alert" aria-live="assertive" aria-atomic="true">
  <div class="d-flex">
    <div class="toast-body">
      Copied!
    </div>
  </div>
</div>

---
Primary Category: cs.CR  
Categories: cs-AI, cs-CL, cs-CR, cs.CR  
Keyword Score: 50  
Keywords: Contrastive Learning, Natural Language Understanding, Perplexity, Pre-trained Language Model, Pre-trained Language Model  
<a type="button" class="btn btn-outline-primary" href="http://arxiv.org/abs/2402.18945v1" target="_blank" >Paper Link</a>
<button type="button" class="btn btn-outline-primary download-pdf" url="https://arxiv.org/pdf/2402.18945v1.pdf" filename="2402.18945v1.pdf">Download PDF</button>

---


**ABSTRACT**  
<b>Pre-trained</b> <b>language</b> <b>models</b> <b>(PLMs)</b> have been found susceptible to backdoor attacks, which can transfer vulnerabilities to various downstream tasks. However, existing <b>PLM</b> backdoors are conducted with explicit triggers under the manually aligned, thus failing to satisfy expectation goals simultaneously in terms of effectiveness, stealthiness, and universality. In this paper, we propose a novel approach to achieve invisible and general backdoor implantation, called \textbf{Syntactic Ghost} (synGhost for short). Specifically, the method hostilely manipulates poisoned samples with different predefined syntactic structures as stealth triggers and then implants the backdoor to <b>pre-trained</b> <b>representation</b> <b>space</b> without disturbing the primitive knowledge. The output representations of poisoned samples are distributed as uniformly as possible in the feature space via <b>contrastive</b> <b>learning,</b> forming a wide range of backdoors. Additionally, in light of the unique properties of syntactic triggers, we introduce an auxiliary module to drive the <b>PLMs</b> to learn this knowledge in priority, which can alleviate the interference between different syntactic structures. Experiments show that our method outperforms the previous methods and achieves the predefined objectives. Not only do severe threats to various <b>natural</b> <b>language</b> <b>understanding</b> (NLU) tasks on two tuning paradigms but also to multiple <b>PLMs.</b> Meanwhile, the synGhost is imperceptible against three countermeasures based on <b>perplexity,</b> fine-pruning, and the proposed maxEntropy.

{{</citation>}}


### (4/11 | 218/321) LoRA-as-an-Attack! Piercing LLM Safety Under The Share-and-Play Scenario (Hongyi Liu et al., 2024)

{{<citation>}}

Hongyi Liu, Zirui Liu, Ruixiang Tang, Jiayi Yuan, Shaochen Zhong, Yu-Neng Chuang, Li Li, Rui Chen, Xia Hu. (2024)  
**LoRA-as-an-Attack! Piercing LLM Safety Under The Share-and-Play Scenario**
<br/>
<button class="copy-to-clipboard" title="LoRA-as-an-Attack! Piercing LLM Safety Under The Share-and-Play Scenario" index=218>
  <span class="copy-to-clipboard-item">Copy Title<span>
</button>
<div class="toast toast-copied toast-index-218 align-items-center text-bg-secondary border-0 position-absolute top-0 end-0" role="alert" aria-live="assertive" aria-atomic="true">
  <div class="d-flex">
    <div class="toast-body">
      Copied!
    </div>
  </div>
</div>

---
Primary Category: cs.CR  
Categories: cs-AI, cs-CL, cs-CR, cs.CR  
Keyword Score: 20  
Keywords: Fine-tuning, Large Language Model  
<a type="button" class="btn btn-outline-primary" href="http://arxiv.org/abs/2403.00108v1" target="_blank" >Paper Link</a>
<button type="button" class="btn btn-outline-primary download-pdf" url="https://arxiv.org/pdf/2403.00108v1.pdf" filename="2403.00108v1.pdf">Download PDF</button>

---


**ABSTRACT**  
<b>Fine-tuning</b> <b>LLMs</b> is crucial to enhancing their task-specific performance and ensuring model behaviors are aligned with human preferences. Among various <b>fine-tuning</b> methods, LoRA is popular for its efficiency and ease to use, allowing end-users to easily post and adopt lightweight LoRA modules on open-source platforms to tailor their model for different customization. However, such a handy share-and-play setting opens up new attack surfaces, that the attacker can render LoRA as an attacker, such as backdoor injection, and widely distribute the adversarial LoRA to the community easily. This can result in detrimental outcomes. Despite the huge potential risks of sharing LoRA modules, this aspect however has not been fully explored. To fill the gap, in this study we thoroughly investigate the attack opportunities enabled in the growing share-and-play scenario. Specifically, we study how to inject backdoor into the LoRA module and dive deeper into LoRA's infection mechanisms. We found that training-free mechanism is possible in LoRA backdoor injection. We also discover the impact of backdoor attacks with the presence of multiple LoRA adaptions concurrently as well as LoRA based backdoor transferability. Our aim is to raise awareness of the potential risks under the emerging share-and-play scenario, so as to proactively prevent potential consequences caused by LoRA-as-an-Attack. Warning: the paper contains potential offensive content generated by models.

{{</citation>}}


### (5/11 | 219/321) SoK: Exploring the Potential of Large Language Models for Improving Digital Forensic Investigation Efficiency (Akila Wickramasekara et al., 2024)

{{<citation>}}

Akila Wickramasekara, Frank Breitinger, Mark Scanlon. (2024)  
**SoK: Exploring the Potential of Large Language Models for Improving Digital Forensic Investigation Efficiency**
<br/>
<button class="copy-to-clipboard" title="SoK: Exploring the Potential of Large Language Models for Improving Digital Forensic Investigation Efficiency" index=219>
  <span class="copy-to-clipboard-item">Copy Title<span>
</button>
<div class="toast toast-copied toast-index-219 align-items-center text-bg-secondary border-0 position-absolute top-0 end-0" role="alert" aria-live="assertive" aria-atomic="true">
  <div class="d-flex">
    <div class="toast-body">
      Copied!
    </div>
  </div>
</div>

---
Primary Category: cs.CR  
Categories: cs-AI, cs-CR, cs.CR  
Keyword Score: 20  
Keywords: Large Language Model, Large Language Model  
<a type="button" class="btn btn-outline-primary" href="http://arxiv.org/abs/2402.19366v1" target="_blank" >Paper Link</a>
<button type="button" class="btn btn-outline-primary download-pdf" url="https://arxiv.org/pdf/2402.19366v1.pdf" filename="2402.19366v1.pdf">Download PDF</button>

---


**ABSTRACT**  
The growing number of cases requiring digital forensic analysis raises concerns about law enforcement's ability to conduct investigations promptly. Consequently, this systemisation of knowledge paper delves into the potential and effectiveness of integrating <b>Large</b> <b>Language</b> <b>Models</b> <b>(LLMs)</b> into digital forensic investigation to address these challenges. A thorough literature review is undertaken, encompassing existing digital forensic models, tools, <b>LLMs,</b> deep learning techniques, and the utilisation of <b>LLMs</b> in investigations. The review identifies current challenges within existing digital forensic processes and explores both the obstacles and possibilities of incorporating <b>LLMs.</b> In conclusion, the study asserts that the adoption of <b>LLMs</b> in digital forensics, with appropriate constraints, holds the potential to enhance investigation efficiency, improve traceability, and alleviate technical and judicial barriers faced by law enforcement entities.

{{</citation>}}


### (6/11 | 220/321) Watermark Stealing in Large Language Models (Nikola Jovanović et al., 2024)

{{<citation>}}

Nikola Jovanović, Robin Staab, Martin Vechev. (2024)  
**Watermark Stealing in Large Language Models**
<br/>
<button class="copy-to-clipboard" title="Watermark Stealing in Large Language Models" index=220>
  <span class="copy-to-clipboard-item">Copy Title<span>
</button>
<div class="toast toast-copied toast-index-220 align-items-center text-bg-secondary border-0 position-absolute top-0 end-0" role="alert" aria-live="assertive" aria-atomic="true">
  <div class="d-flex">
    <div class="toast-body">
      Copied!
    </div>
  </div>
</div>

---
Primary Category: cs.CR  
Categories: cs-AI, cs-CR, cs-LG, cs.CR  
Keyword Score: 20  
Keywords: Large Language Model, Large Language Model  
<a type="button" class="btn btn-outline-primary" href="http://arxiv.org/abs/2402.19361v1" target="_blank" >Paper Link</a>
<button type="button" class="btn btn-outline-primary download-pdf" url="https://arxiv.org/pdf/2402.19361v1.pdf" filename="2402.19361v1.pdf">Download PDF</button>

---


**ABSTRACT**  
<b>LLM</b> watermarking has attracted attention as a promising way to detect AI-generated content, with some works suggesting that current schemes may already be fit for deployment. In this work we dispute this claim, identifying watermark stealing (WS) as a fundamental vulnerability of these schemes. We show that querying the API of the watermarked <b>LLM</b> to approximately reverse-engineer a watermark enables practical spoofing attacks, as suggested in prior work, but also greatly boosts scrubbing attacks, which was previously unnoticed. We are the first to propose an automated WS algorithm and use it in the first comprehensive study of spoofing and scrubbing in realistic settings. We show that for under $50 an attacker can both spoof and scrub state-of-the-art schemes previously considered safe, with average success rate of over 80%. Our findings challenge common beliefs about <b>LLM</b> watermarking, stressing the need for more robust schemes. We make all our code and additional examples available at https://watermark-stealing.org.

{{</citation>}}


### (7/11 | 221/321) How to Train your Antivirus: RL-based Hardening through the Problem-Space (Jacopo Cortellazzi et al., 2024)

{{<citation>}}

Jacopo Cortellazzi, Ilias Tsingenopoulos, Branislav Bošanský, Simone Aonzo, Davy Preuveneers, Wouter Joosen, Fabio Pierazzi, Lorenzo Cavallaro. (2024)  
**How to Train your Antivirus: RL-based Hardening through the Problem-Space**
<br/>
<button class="copy-to-clipboard" title="How to Train your Antivirus: RL-based Hardening through the Problem-Space" index=221>
  <span class="copy-to-clipboard-item">Copy Title<span>
</button>
<div class="toast toast-copied toast-index-221 align-items-center text-bg-secondary border-0 position-absolute top-0 end-0" role="alert" aria-live="assertive" aria-atomic="true">
  <div class="d-flex">
    <div class="toast-body">
      Copied!
    </div>
  </div>
</div>

---
Primary Category: cs.CR  
Categories: cs-AI, cs-CR, cs.CR  
Keyword Score: 20  
Keywords: Adversarial Learning, Reinforcement Learning  
<a type="button" class="btn btn-outline-primary" href="http://arxiv.org/abs/2402.19027v1" target="_blank" >Paper Link</a>
<button type="button" class="btn btn-outline-primary download-pdf" url="https://arxiv.org/pdf/2402.19027v1.pdf" filename="2402.19027v1.pdf">Download PDF</button>

---


**ABSTRACT**  
ML-based malware detection on dynamic analysis reports is vulnerable to both evasion and spurious correlations. In this work, we investigate a specific ML architecture employed in the pipeline of a widely-known commercial antivirus company, with the goal to harden it against <b>adversarial</b> <b>malware.</b> <b>Adversarial</b> <b>training,</b> the sole defensive technique that can confer empirical robustness, is not applicable out of the box in this domain, for the principal reason that gradient-based perturbations rarely map back to feasible problem-space programs. We introduce a novel <b>Reinforcement</b> <b>Learning</b> approach for constructing <b>adversarial</b> <b>examples,</b> a constituent part of adversarially training a model against evasion. Our approach comes with multiple advantages. It performs modifications that are feasible in the problem-space, and only those; thus it circumvents the inverse mapping problem. It also makes possible to provide theoretical guarantees on the robustness of the model against a particular set of <b>adversarial</b> <b>capabilities.</b> Our empirical exploration validates our theoretical insights, where we can consistently reach 0\% Attack Success Rate after a few <b>adversarial</b> <b>retraining</b> iterations.

{{</citation>}}


### (8/11 | 222/321) RobWE: Robust Watermark Embedding for Personalized Federated Learning Model Ownership Protection (Yang Xu et al., 2024)

{{<citation>}}

Yang Xu, Yunlin Tan, Cheng Zhang, Kai Chi, Peng Sun, Wenyuan Yang, Ju Ren, Hongbo Jiang, Yaoxue Zhang. (2024)  
**RobWE: Robust Watermark Embedding for Personalized Federated Learning Model Ownership Protection**
<br/>
<button class="copy-to-clipboard" title="RobWE: Robust Watermark Embedding for Personalized Federated Learning Model Ownership Protection" index=222>
  <span class="copy-to-clipboard-item">Copy Title<span>
</button>
<div class="toast toast-copied toast-index-222 align-items-center text-bg-secondary border-0 position-absolute top-0 end-0" role="alert" aria-live="assertive" aria-atomic="true">
  <div class="d-flex">
    <div class="toast-body">
      Copied!
    </div>
  </div>
</div>

---
Primary Category: cs.CR  
Categories: cs-AI, cs-CR, cs.CR  
Keyword Score: 10  
Keywords: Federated Learning  
<a type="button" class="btn btn-outline-primary" href="http://arxiv.org/abs/2402.19054v1" target="_blank" >Paper Link</a>
<button type="button" class="btn btn-outline-primary download-pdf" url="https://arxiv.org/pdf/2402.19054v1.pdf" filename="2402.19054v1.pdf">Download PDF</button>

---


**ABSTRACT**  
Embedding watermarks into models has been widely used to protect model ownership in <b>federated</b> <b>learning</b> (FL). However, existing methods are inadequate for protecting the ownership of personalized models acquired by clients in personalized FL (PFL). This is due to the aggregation of the global model in PFL, resulting in conflicts over clients' private watermarks. Moreover, malicious clients may tamper with embedded watermarks to facilitate model leakage and evade accountability. This paper presents a robust watermark embedding scheme, named RobWE, to protect the ownership of personalized models in PFL. We first decouple the watermark embedding of personalized models into two parts: head layer embedding and representation layer embedding. The head layer belongs to clients' private part without participating in model aggregation, while the representation layer is the shared part for aggregation. For representation layer embedding, we employ a watermark slice embedding operation, which avoids watermark embedding conflicts. Furthermore, we design a malicious watermark detection scheme enabling the server to verify the correctness of watermarks before aggregating local models. We conduct an exhaustive experimental evaluation of RobWE. The results demonstrate that RobWE significantly outperforms the state-of-the-art watermark embedding schemes in FL in terms of fidelity, reliability, and robustness.

{{</citation>}}


### (9/11 | 223/321) Privacy Management and Interface Design for a Smart House (Ana-Maria Comeaga et al., 2024)

{{<citation>}}

Ana-Maria Comeaga, Iuliana Marin. (2024)  
**Privacy Management and Interface Design for a Smart House**
<br/>
<button class="copy-to-clipboard" title="Privacy Management and Interface Design for a Smart House" index=223>
  <span class="copy-to-clipboard-item">Copy Title<span>
</button>
<div class="toast toast-copied toast-index-223 align-items-center text-bg-secondary border-0 position-absolute top-0 end-0" role="alert" aria-live="assertive" aria-atomic="true">
  <div class="d-flex">
    <div class="toast-body">
      Copied!
    </div>
  </div>
</div>

---
Primary Category: cs.CR  
Categories: cs-CR, cs-SE, cs.CR  
Keyword Score: 10  
Keywords: Supervised Learning  
<a type="button" class="btn btn-outline-primary" href="http://arxiv.org/abs/2402.18973v1" target="_blank" >Paper Link</a>
<button type="button" class="btn btn-outline-primary download-pdf" url="https://arxiv.org/pdf/2402.18973v1.pdf" filename="2402.18973v1.pdf">Download PDF</button>

---


**ABSTRACT**  
In today's life, more and more people tend to opt for a smart house. In this way, the idea of including technology has become popular worldwide. Despite this concept's many benefits, managing security remains an essential problem due to the shared activities. The Internet of Things system behind a smart house is based on several sensors to measure temperature, humidity, air quality, and movement. Because of being <b>supervised</b> every day through sensors and controlling their house only with a simple click, many people can be afraid of this new approach in terms of their privacy, and this fact can constrain them from following their habits. The security aspects should be constantly analyzed to keep the data's confidentiality and make people feel safe in their own houses. In this context, the current paper puts light on an alternative design of a platform in which the safety of homeowners is the primary purpose, and they maintain complete control over the data generated by smart devices. The current research highlights the role of security and interface design in controlling a smart house. The study underscores the importance of providing an interface that can be used easily by any person to manage data and live activities in a modern residence in an era dominated by continuously developing technology.

{{</citation>}}


### (10/11 | 224/321) Attacks Against Mobility Prediction in 5G Networks (Syafiq Al Atiiq et al., 2024)

{{<citation>}}

Syafiq Al Atiiq, Yachao Yuan, Christian Gehrmann, Jakob Sternby, Luis Barriga. (2024)  
**Attacks Against Mobility Prediction in 5G Networks**
<br/>
<button class="copy-to-clipboard" title="Attacks Against Mobility Prediction in 5G Networks" index=224>
  <span class="copy-to-clipboard-item">Copy Title<span>
</button>
<div class="toast toast-copied toast-index-224 align-items-center text-bg-secondary border-0 position-absolute top-0 end-0" role="alert" aria-live="assertive" aria-atomic="true">
  <div class="d-flex">
    <div class="toast-body">
      Copied!
    </div>
  </div>
</div>

---
Primary Category: cs.CR  
Categories: cs-CR, cs-LG, cs-NI, cs.CR  
Keyword Score: 3  
Keywords: Clustering  
<a type="button" class="btn btn-outline-primary" href="http://arxiv.org/abs/2402.19319v1" target="_blank" >Paper Link</a>
<button type="button" class="btn btn-outline-primary download-pdf" url="https://arxiv.org/pdf/2402.19319v1.pdf" filename="2402.19319v1.pdf">Download PDF</button>

---


**ABSTRACT**  
The $5^{th}$ generation of mobile networks introduces a new Network Function (NF) that was not present in previous generations, namely the Network Data Analytics Function (NWDAF). Its primary objective is to provide advanced analytics services to various entities within the network and also towards external application services in the 5G ecosystem. One of the key use cases of NWDAF is mobility trajectory prediction, which aims to accurately support efficient mobility management of User Equipment (UE) in the network by allocating ``just in time'' necessary network resources. In this paper, we show that there are potential mobility attacks that can compromise the accuracy of these predictions. In a semi-realistic scenario with 10,000 subscribers, we demonstrate that an adversary equipped with the ability to hijack cellular mobile devices and clone them can significantly reduce the prediction accuracy from 75\% to 40\% using just 100 adversarial UEs. While a defense mechanism largely depends on the attack and the mobility types in a particular area, we prove that a basic KMeans <b>clustering</b> is effective in distinguishing legitimate and adversarial UEs.

{{</citation>}}


### (11/11 | 225/321) Rahmani Sort: A Novel Variant of Insertion Sort Algorithm with O(nlogn) Complexity (Mohammad Khalid Imam Rahmani, 2024)

{{<citation>}}

Mohammad Khalid Imam Rahmani. (2024)  
**Rahmani Sort: A Novel Variant of Insertion Sort Algorithm with O(nlogn) Complexity**
<br/>
<button class="copy-to-clipboard" title="Rahmani Sort: A Novel Variant of Insertion Sort Algorithm with O(nlogn) Complexity" index=225>
  <span class="copy-to-clipboard-item">Copy Title<span>
</button>
<div class="toast toast-copied toast-index-225 align-items-center text-bg-secondary border-0 position-absolute top-0 end-0" role="alert" aria-live="assertive" aria-atomic="true">
  <div class="d-flex">
    <div class="toast-body">
      Copied!
    </div>
  </div>
</div>

---
Primary Category: cs.CR  
Categories: 14J26 (Secondary), E-1, cs-CR, cs-DS, cs.CR  
Keyword Score: 3  
Keywords: Clustering  
<a type="button" class="btn btn-outline-primary" href="http://arxiv.org/abs/2402.19107v1" target="_blank" >Paper Link</a>
<button type="button" class="btn btn-outline-primary download-pdf" url="https://arxiv.org/pdf/2402.19107v1.pdf" filename="2402.19107v1.pdf">Download PDF</button>

---


**ABSTRACT**  
Various decision support systems are available that implement Data Mining and Data Warehousing techniques for diving into the sea of data for getting useful patterns of knowledge (pearls). Classification, regression, <b>clustering,</b> and many other algorithms are used to enhance the precision and accuracy of the decision process. So, there is scope for increasing the response time of the decision process, especially in mission-critical operations. If data are ordered with suitable and efficient sorting operation, the response time of the decision process can be minimized. Insertion sort is much more suitable for such applications due to its simple and straight logic along with its dynamic nature suitable for list implementation. But it is slower than merge sort and quick sort. The main reasons this is slow: firstly, a sequential search is used to find the actual position of the next key element into the sorted left subarray and secondly, shifting of elements is required by one position towards the right for accommodating the newly inserted element. Therefore, I propose a new algorithm by using a novel technique of binary search mechanism for finding the sorted location of the next key item into the previously sorted left subarray much quicker than the conventional insertion sort algorithm. Performance measurement in terms of the actual running time of the new algorithm has been compared with those of other conventional sorting algorithms apart from the insertion sort. The results obtained on various sample data show that the new algorithm is better in performance than the conventional insertion sort and merge sort algorithms.

{{</citation>}}


## cs.CE (2)



### (1/2 | 226/321) Generative models struggle with kirigami metamaterials (Gerrit Felsch et al., 2024)

{{<citation>}}

Gerrit Felsch, Viacheslav Slesarenko. (2024)  
**Generative models struggle with kirigami metamaterials**
<br/>
<button class="copy-to-clipboard" title="Generative models struggle with kirigami metamaterials" index=226>
  <span class="copy-to-clipboard-item">Copy Title<span>
</button>
<div class="toast toast-copied toast-index-226 align-items-center text-bg-secondary border-0 position-absolute top-0 end-0" role="alert" aria-live="assertive" aria-atomic="true">
  <div class="d-flex">
    <div class="toast-body">
      Copied!
    </div>
  </div>
</div>

---
Primary Category: cs.CE  
Categories: J-2; I-6, cond-mat-mtrl-sci, cond-mat-soft, cs-CE, cs.CE  
Keyword Score: 50  
Keywords: Autoencoder, Generative Adversarial Network, Generative Adversarial Network, Probabilistic Model, Variational Autoencoder  
<a type="button" class="btn btn-outline-primary" href="http://arxiv.org/abs/2402.19196v1" target="_blank" >Paper Link</a>
<button type="button" class="btn btn-outline-primary download-pdf" url="https://arxiv.org/pdf/2402.19196v1.pdf" filename="2402.19196v1.pdf">Download PDF</button>

---


**ABSTRACT**  
<b>Generative</b> <b>machine</b> <b>learning</b> models have shown notable success in identifying architectures for metamaterials - materials whose behavior is determined primarily by their internal organization - that match specific target properties. By examining kirigami metamaterials, in which dependencies between cuts yield complex design restrictions, we demonstrate that this perceived success in the employment of <b>generative</b> <b>models</b> <b>for</b> metamaterials might be akin to survivorship bias. We assess the performance of the four most popular <b>generative</b> <b>models</b> <b>-</b> the <b>Variational</b> <b>Autoencoder</b> (VAE), the <b>Generative</b> <b>Adversarial</b> <b>Network</b> <b>(GAN),</b> the Wasserstein <b>GAN</b> (WGAN), and the Denoising Diffusion <b>Probabilistic</b> <b>Model</b> (DDPM) - in generating kirigami structures. Prohibiting cut intersections can prevent the identification of an appropriate similarity measure for kirigami metamaterials, significantly impacting the effectiveness of VAE and WGAN, which rely on the Euclidean distance - a metric shown to be unsuitable for considered geometries. This imposes significant limitations on employing modern <b>generative</b> <b>models</b> <b>for</b> the creation of diverse metamaterials.

{{</citation>}}


### (2/2 | 227/321) Protein Multimer Structure Prediction via Prompt Learning (Ziqi Gao et al., 2024)

{{<citation>}}

Ziqi Gao, Xiangguo Sun, Zijing Liu, Yu Li, Hong Cheng, Jia Li. (2024)  
**Protein Multimer Structure Prediction via Prompt Learning**
<br/>
<button class="copy-to-clipboard" title="Protein Multimer Structure Prediction via Prompt Learning" index=227>
  <span class="copy-to-clipboard-item">Copy Title<span>
</button>
<div class="toast toast-copied toast-index-227 align-items-center text-bg-secondary border-0 position-absolute top-0 end-0" role="alert" aria-live="assertive" aria-atomic="true">
  <div class="d-flex">
    <div class="toast-body">
      Copied!
    </div>
  </div>
</div>

---
Primary Category: cs.CE  
Categories: cs-CE, cs.CE  
Keyword Score: 30  
Keywords: Meta Learning, Prompt, Prompt Learning  
<a type="button" class="btn btn-outline-primary" href="http://arxiv.org/abs/2402.18813v1" target="_blank" >Paper Link</a>
<button type="button" class="btn btn-outline-primary download-pdf" url="https://arxiv.org/pdf/2402.18813v1.pdf" filename="2402.18813v1.pdf">Download PDF</button>

---


**ABSTRACT**  
Understanding the 3D structures of protein multimers is crucial, as they play a vital role in regulating various cellular processes. It has been empirically confirmed that the multimer structure prediction~(MSP) can be well handled in a step-wise assembly fashion using provided dimer structures and predicted protein-protein interactions~(PPIs). However, due to the biological gap in the formation of dimers and larger multimers, directly applying PPI prediction techniques can often cause a \textit{poor generalization} to the MSP task. To address this challenge, we aim to extend the PPI knowledge to multimers of different scales~(i.e., chain numbers). Specifically, we propose \textbf{\textsc{PromptMSP}}, a pre-training and \textbf{Prompt} tuning framework for \textbf{M}ultimer \textbf{S}tructure \textbf{P}rediction. First, we tailor the source and target tasks for effective PPI knowledge learning and efficient inference, respectively. We design PPI-inspired <b>prompt</b> <b>learning</b> to narrow the gaps of two task formats and generalize the PPI knowledge to multimers of different scales. We provide a <b>meta-learning</b> <b>strategy</b> to learn a reliable initialization of the <b>prompt</b> <b>model,</b> enabling our <b>prompting</b> <b>framework</b> to effectively adapt to limited data for large-scale multimers. Empirically, we achieve both significant accuracy (RMSD and TM-Score) and efficiency improvements compared to advanced MSP models. The code, data and checkpoints are released at \url{https://github.com/zqgao22/PromptMSP}.

{{</citation>}}


## q-bio.BM (1)



### (1/1 | 228/321) A Protein Structure Prediction Approach Leveraging Transformer and CNN Integration (Yanlin Zhou et al., 2024)

{{<citation>}}

Yanlin Zhou, Kai Tan, Xinyu Shen, Zheng He. (2024)  
**A Protein Structure Prediction Approach Leveraging Transformer and CNN Integration**
<br/>
<button class="copy-to-clipboard" title="A Protein Structure Prediction Approach Leveraging Transformer and CNN Integration" index=228>
  <span class="copy-to-clipboard-item">Copy Title<span>
</button>
<div class="toast toast-copied toast-index-228 align-items-center text-bg-secondary border-0 position-absolute top-0 end-0" role="alert" aria-live="assertive" aria-atomic="true">
  <div class="d-flex">
    <div class="toast-body">
      Copied!
    </div>
  </div>
</div>

---
Primary Category: q-bio.BM  
Categories: cs-LG, q-bio-BM, q-bio.BM  
Keyword Score: 50  
Keywords: Convolution, Convolutional Neural Network, Convolutional Neural Network, Supervised Learning, Transformer  
<a type="button" class="btn btn-outline-primary" href="http://arxiv.org/abs/2402.19095v1" target="_blank" >Paper Link</a>
<button type="button" class="btn btn-outline-primary download-pdf" url="https://arxiv.org/pdf/2402.19095v1.pdf" filename="2402.19095v1.pdf">Download PDF</button>

---


**ABSTRACT**  
Proteins are essential for life, and their structure determines their function. The protein secondary structure is formed by the folding of the protein primary structure, and the protein tertiary structure is formed by the bending and folding of the secondary structure. Therefore, the study of protein secondary structure is very helpful to the overall understanding of protein structure. Although the accuracy of protein secondary structure prediction has continuously improved with the development of machine learning and deep learning, progress in the field of protein structure prediction, unfortunately, remains insufficient to meet the large demand for protein information. Therefore, based on the advantages of deep learning-based methods in feature extraction and learning ability, this paper adopts a two-dimensional fusion deep neural network model, DstruCCN, which uses <b>Convolutional</b> <b>Neural</b> <b>Networks</b> (CCN) and a <b>supervised</b> <b>Transformer</b> protein language model for single-sequence protein structure prediction. The training features of the two are combined to predict the protein <b>Transformer</b> binding site matrix, and then the three-dimensional structure is reconstructed using energy minimization.

{{</citation>}}


## q-bio.NC (2)



### (1/2 | 229/321) Speaker-Independent Dysarthria Severity Classification using Self-Supervised Transformers and Multi-Task Learning (Lauren Stumpf et al., 2024)

{{<citation>}}

Lauren Stumpf, Balasundaram Kadirvelu, Sigourney Waibel, A. Aldo Faisal. (2024)  
**Speaker-Independent Dysarthria Severity Classification using Self-Supervised Transformers and Multi-Task Learning**
<br/>
<button class="copy-to-clipboard" title="Speaker-Independent Dysarthria Severity Classification using Self-Supervised Transformers and Multi-Task Learning" index=229>
  <span class="copy-to-clipboard-item">Copy Title<span>
</button>
<div class="toast toast-copied toast-index-229 align-items-center text-bg-secondary border-0 position-absolute top-0 end-0" role="alert" aria-live="assertive" aria-atomic="true">
  <div class="d-flex">
    <div class="toast-body">
      Copied!
    </div>
  </div>
</div>

---
Primary Category: q-bio.NC  
Categories: I-2-7; I-2-1; J-3, cs-AI, cs-CL, cs-LG, cs-SD, eess-AS, q-bio-NC, q-bio.NC  
Keyword Score: 48  
Keywords: Benchmarking, Black Box, Contrastive Learning, Generative AI, Self-supervised Learning, Transformer  
<a type="button" class="btn btn-outline-primary" href="http://arxiv.org/abs/2403.00854v1" target="_blank" >Paper Link</a>
<button type="button" class="btn btn-outline-primary download-pdf" url="https://arxiv.org/pdf/2403.00854v1.pdf" filename="2403.00854v1.pdf">Download PDF</button>

---


**ABSTRACT**  
Dysarthria, a condition resulting from impaired control of the speech muscles due to neurological disorders, significantly impacts the communication and quality of life of patients. The condition's complexity, human scoring and varied presentations make its assessment and management challenging. This study presents a <b>transformer-based</b> framework for automatically assessing dysarthria severity from raw speech data. It can offer an objective, repeatable, accessible, standardised and cost-effective and compared to traditional methods requiring human expert assessors. We develop a <b>transformer</b> framework, called Speaker-Agnostic Latent Regularisation (SALR), incorporating a multi-task learning objective and <b>contrastive</b> <b>learning</b> for speaker-independent multi-class dysarthria severity classification. The multi-task framework is designed to reduce reliance on speaker-specific characteristics and address the intrinsic intra-class variability of dysarthric speech. We evaluated on the Universal Access Speech dataset using leave-one-speaker-out cross-validation, our model demonstrated superior performance over traditional machine learning approaches, with an accuracy of $70.48\%$ and an F1 score of $59.23\%$. Our SALR model also exceeded the previous <b>benchmark</b> for AI-based classification, which used support vector machines, by $16.58\%$. We open the <b>black</b> <b>box</b> of our model by visualising the latent space where we can observe how the model substantially reduces speaker-specific cues and amplifies task-specific ones, thereby showing its robustness. In conclusion, SALR establishes a new <b>benchmark</b> in speaker-independent multi-class dysarthria severity classification using <b>generative</b> <b>AI.</b> The potential implications of our findings for broader clinical applications in automated dysarthria severity assessments.

{{</citation>}}


### (2/2 | 230/321) Identification of Craving Maps among Marijuana Users via Analysis of Functional Brain Networks with High-Order Attention Graph Neural Networks (Jun-En Ding et al., 2024)

{{<citation>}}

Jun-En Ding, Shihao Yang, Anna Zilverstand, Feng Liu. (2024)  
**Identification of Craving Maps among Marijuana Users via Analysis of Functional Brain Networks with High-Order Attention Graph Neural Networks**
<br/>
<button class="copy-to-clipboard" title="Identification of Craving Maps among Marijuana Users via Analysis of Functional Brain Networks with High-Order Attention Graph Neural Networks" index=230>
  <span class="copy-to-clipboard-item">Copy Title<span>
</button>
<div class="toast toast-copied toast-index-230 align-items-center text-bg-secondary border-0 position-absolute top-0 end-0" role="alert" aria-live="assertive" aria-atomic="true">
  <div class="d-flex">
    <div class="toast-body">
      Copied!
    </div>
  </div>
</div>

---
Primary Category: q-bio.NC  
Categories: cs-LG, eess-SP, q-bio-NC, q-bio.NC  
Keyword Score: 36  
Keywords: Message-Passing, Graph, Graph Neural Network, Clustering, LSTM  
<a type="button" class="btn btn-outline-primary" href="http://arxiv.org/abs/2403.00033v2" target="_blank" >Paper Link</a>
<button type="button" class="btn btn-outline-primary download-pdf" url="https://arxiv.org/pdf/2403.00033v2.pdf" filename="2403.00033v2.pdf">Download PDF</button>

---


**ABSTRACT**  
The consumption of high doses of marijuana can have significant psychological and social impacts. In this study, we propose an interpretable novel framework called the HOGAB (High-Order <b>Graph</b> <b>Attention</b> <b>Neural</b> Networks) model for addictive Marijuana classification and analysis of the localized network clusters that demonstrated abnormal brain activities among chronic marijuana users. The HOGAB integrates dynamic intrinsic functional networks with <b>LSTM</b> technology to capture temporal patterns in fMRI time series of marijuana users. We employed the high-order attention module in neighborhood nodes for information fusion and message passing, enhancing community <b>clustering</b> analysis for long-term marijuana users. Furthermore, we improve the overall classification ability of the model by incorporating attention mechanisms, achieving an AUC of 85.1% and an accuracy of 80.7% in classification, higher than the comparison algoirthms. Specifically, we identified the most relevant subnetworks and cognitive regions that are influenced by persistent marijuana usage, revealing that chronic marijuana consumption adversely affects cognitive control, particularly within the Dorsal Attention and Frontoparietal networks, which are essential for attentional, cognitive and higher cognitive functions. The results show that our proposed model is capable of accurately predicting craving bahavior and identifying brain maps associated with long-term cravings, and thus pinpointing brain regions that are important for analysis.

{{</citation>}}


## cond-mat.mtrl-sci (2)



### (1/2 | 231/321) Training-set-free two-stage deep learning for spectroscopic data de-noising (Dongchen Huang et al., 2024)

{{<citation>}}

Dongchen Huang, Junde Liu, Tian Qian, Hongming Weng. (2024)  
**Training-set-free two-stage deep learning for spectroscopic data de-noising**
<br/>
<button class="copy-to-clipboard" title="Training-set-free two-stage deep learning for spectroscopic data de-noising" index=231>
  <span class="copy-to-clipboard-item">Copy Title<span>
</button>
<div class="toast toast-copied toast-index-231 align-items-center text-bg-secondary border-0 position-absolute top-0 end-0" role="alert" aria-live="assertive" aria-atomic="true">
  <div class="d-flex">
    <div class="toast-body">
      Copied!
    </div>
  </div>
</div>

---
Primary Category: cond-mat.mtrl-sci  
Categories: cond-mat-mtrl-sci, cond-mat.mtrl-sci, cs-LG, physics-data-an  
Keyword Score: 45  
Keywords: Geometry, Supervised Learning, Supervised Learning, Unsupervised Learning, Unsupervised Learning  
<a type="button" class="btn btn-outline-primary" href="http://arxiv.org/abs/2402.18830v2" target="_blank" >Paper Link</a>
<button type="button" class="btn btn-outline-primary download-pdf" url="https://arxiv.org/pdf/2402.18830v2.pdf" filename="2402.18830v2.pdf">Download PDF</button>

---


**ABSTRACT**  
De-noising is a prominent step in the spectra post-processing procedure. Previous machine learning-based methods are fast but mostly based on <b>supervised</b> <b>learning</b> and require a training set that may be typically expensive in real experimental measurements. <b>Unsupervised</b> <b>learning-based</b> algorithms are slow and require many iterations to achieve convergence. Here, we bridge this gap by proposing a training-set-free two-stage deep learning method. We show that the fuzzy fixed input in previous methods can be improved by introducing an adaptive prior. Combined with more advanced optimization techniques, our approach can achieve five times acceleration compared to previous work. Theoretically, we study the landscape of a corresponding non-convex linear problem, and our results indicates that this problem has benign <b>geometry</b> for first-order algorithms to converge.

{{</citation>}}


### (2/2 | 232/321) Accelerating materials discovery for polymer solar cells: Data-driven insights enabled by natural language processing (Pranav Shetty et al., 2024)

{{<citation>}}

Pranav Shetty, Aishat Adeboye, Sonakshi Gupta, Chao Zhang, Rampi Ramprasad. (2024)  
**Accelerating materials discovery for polymer solar cells: Data-driven insights enabled by natural language processing**
<br/>
<button class="copy-to-clipboard" title="Accelerating materials discovery for polymer solar cells: Data-driven insights enabled by natural language processing" index=232>
  <span class="copy-to-clipboard-item">Copy Title<span>
</button>
<div class="toast toast-copied toast-index-232 align-items-center text-bg-secondary border-0 position-absolute top-0 end-0" role="alert" aria-live="assertive" aria-atomic="true">
  <div class="d-flex">
    <div class="toast-body">
      Copied!
    </div>
  </div>
</div>

---
Primary Category: cond-mat.mtrl-sci  
Categories: cond-mat-mtrl-sci, cond-mat.mtrl-sci, cs-CL, physics-app-ph  
Keyword Score: 10  
Keywords: Active Learning  
<a type="button" class="btn btn-outline-primary" href="http://arxiv.org/abs/2402.19462v1" target="_blank" >Paper Link</a>
<button type="button" class="btn btn-outline-primary download-pdf" url="https://arxiv.org/pdf/2402.19462v1.pdf" filename="2402.19462v1.pdf">Download PDF</button>

---


**ABSTRACT**  
We present a natural language processing pipeline that was used to extract polymer solar cell property data from the literature and simulate various <b>active</b> <b>learning</b> strategies. While data-driven methods have been well established to discover novel materials faster than Edisonian trial-and-error approaches, their benefits have not been quantified. Our approach demonstrates a potential reduction in discovery time by approximately 75 %, equivalent to a 15 year acceleration in material innovation. Our pipeline enables us to extract data from more than 3300 papers which is ~5 times larger than similar data sets reported by others. We also trained machine learning models to predict the power conversion efficiency and used our model to identify promising donor-acceptor combinations that are as yet unreported. We thus demonstrate a workflow that goes from published literature to extracted material property data which in turn is used to obtain data-driven insights. Our insights include <b>active</b> <b>learning</b> strategies that can simultaneously optimize the material system and train strong predictive models of material properties. This work provides a valuable framework for research in material science.

{{</citation>}}


## eess.AS (2)



### (1/2 | 233/321) A SOUND APPROACH: Using Large Language Models to generate audio descriptions for egocentric text-audio retrieval (Andreea-Maria Oncescu et al., 2024)

{{<citation>}}

Andreea-Maria Oncescu, João F. Henriques, Andrew Zisserman, Samuel Albanie, A. Sophia Koepke. (2024)  
**A SOUND APPROACH: Using Large Language Models to generate audio descriptions for egocentric text-audio retrieval**
<br/>
<button class="copy-to-clipboard" title="A SOUND APPROACH: Using Large Language Models to generate audio descriptions for egocentric text-audio retrieval" index=233>
  <span class="copy-to-clipboard-item">Copy Title<span>
</button>
<div class="toast toast-copied toast-index-233 align-items-center text-bg-secondary border-0 position-absolute top-0 end-0" role="alert" aria-live="assertive" aria-atomic="true">
  <div class="d-flex">
    <div class="toast-body">
      Copied!
    </div>
  </div>
</div>

---
Primary Category: eess.AS  
Categories: cs-IR, cs-SD, eess-AS, eess.AS  
Keyword Score: 43  
Keywords: Benchmarking, Zero-shot, Large Language Model, Large Language Model, Prompt  
<a type="button" class="btn btn-outline-primary" href="http://arxiv.org/abs/2402.19106v1" target="_blank" >Paper Link</a>
<button type="button" class="btn btn-outline-primary download-pdf" url="https://arxiv.org/pdf/2402.19106v1.pdf" filename="2402.19106v1.pdf">Download PDF</button>

---


**ABSTRACT**  
Video databases from the internet are a valuable source of text-audio retrieval datasets. However, given that sound and vision streams represent different "views" of the data, treating visual descriptions as audio descriptions is far from optimal. Even if audio class labels are present, they commonly are not very detailed, making them unsuited for text-audio retrieval. To exploit relevant audio information from video-text datasets, we introduce a methodology for generating audio-centric descriptions using <b>Large</b> <b>Language</b> <b>Models</b> <b>(LLMs).</b> In this work, we consider the egocentric video setting and propose three new text-audio retrieval <b>benchmarks</b> based on the EpicMIR and EgoMCQ tasks, and on the EpicSounds dataset. Our approach for obtaining audio-centric descriptions gives significantly higher <b>zero-shot</b> performance than using the original visual-centric descriptions. Furthermore, we show that using the same <b>prompts,</b> we can successfully employ <b>LLMs</b> to improve the retrieval on EpicSounds, compared to using the original audio class labels of the dataset. Finally, we confirm that <b>LLMs</b> can be used to determine the difficulty of identifying the action associated with a sound.

{{</citation>}}


### (2/2 | 234/321) Extending Multilingual Speech Synthesis to 100+ Languages without Transcribed Data (Takaaki Saeki et al., 2024)

{{<citation>}}

Takaaki Saeki, Gary Wang, Nobuyuki Morioka, Isaac Elias, Kyle Kastner, Andrew Rosenberg, Bhuvana Ramabhadran, Heiga Zen, Françoise Beaufays, Hadar Shemtov. (2024)  
**Extending Multilingual Speech Synthesis to 100+ Languages without Transcribed Data**
<br/>
<button class="copy-to-clipboard" title="Extending Multilingual Speech Synthesis to 100+ Languages without Transcribed Data" index=234>
  <span class="copy-to-clipboard-item">Copy Title<span>
</button>
<div class="toast toast-copied toast-index-234 align-items-center text-bg-secondary border-0 position-absolute top-0 end-0" role="alert" aria-live="assertive" aria-atomic="true">
  <div class="d-flex">
    <div class="toast-body">
      Copied!
    </div>
  </div>
</div>

---
Primary Category: eess.AS  
Categories: cs-SD, eess-AS, eess.AS  
Keyword Score: 35  
Keywords: Representation Learning, Unsupervised Learning, Text-to-speech, Text-to-speech  
<a type="button" class="btn btn-outline-primary" href="http://arxiv.org/abs/2402.18932v1" target="_blank" >Paper Link</a>
<button type="button" class="btn btn-outline-primary download-pdf" url="https://arxiv.org/pdf/2402.18932v1.pdf" filename="2402.18932v1.pdf">Download PDF</button>

---


**ABSTRACT**  
Collecting high-quality studio recordings of audio is challenging, which limits the language coverage of <b>text-to-speech</b> <b>(TTS)</b> systems. This paper proposes a framework for scaling a multilingual <b>TTS</b> model to 100+ languages using found data without supervision. The proposed framework combines speech-text encoder pretraining with <b>unsupervised</b> training using untranscribed speech and unspoken text data sources, thereby leveraging massively multilingual joint speech and text <b>representation</b> <b>learning.</b> Without any transcribed speech in a new language, this <b>TTS</b> model can generate intelligible speech in >30 unseen languages (CER difference of <10% to ground truth). With just 15 minutes of transcribed, found data, we can reduce the intelligibility difference to 1% or less from the ground-truth, and achieve naturalness scores that match the ground-truth in several languages.

{{</citation>}}


## cs.SI (4)



### (1/4 | 235/321) Evolving to the Future: Unseen Event Adaptive Fake News Detection on Social Media (Jiajun Zhang et al., 2024)

{{<citation>}}

Jiajun Zhang, Zhixun Li, Qiang Liu, Shu Wu, Liang Wang. (2024)  
**Evolving to the Future: Unseen Event Adaptive Fake News Detection on Social Media**
<br/>
<button class="copy-to-clipboard" title="Evolving to the Future: Unseen Event Adaptive Fake News Detection on Social Media" index=235>
  <span class="copy-to-clipboard-item">Copy Title<span>
</button>
<div class="toast toast-copied toast-index-235 align-items-center text-bg-secondary border-0 position-absolute top-0 end-0" role="alert" aria-live="assertive" aria-atomic="true">
  <div class="d-flex">
    <div class="toast-body">
      Copied!
    </div>
  </div>
</div>

---
Primary Category: cs.SI  
Categories: cs-AI, cs-CL, cs-SI, cs.SI  
Keyword Score: 43  
Keywords: Graph, Graph Contrastive Learning, Contrastive Learning, Fake News Detection, Fake News Detection  
<a type="button" class="btn btn-outline-primary" href="http://arxiv.org/abs/2403.00037v1" target="_blank" >Paper Link</a>
<button type="button" class="btn btn-outline-primary download-pdf" url="https://arxiv.org/pdf/2403.00037v1.pdf" filename="2403.00037v1.pdf">Download PDF</button>

---


**ABSTRACT**  
With the rapid development of social media, the wide dissemination of <b>fake</b> <b>news</b> <b>on</b> social media is increasingly threatening both individuals and society. In the dynamic landscape of social media, <b>fake</b> <b>news</b> <b>detection</b> aims to develop a model trained on news reporting past events. The objective is to predict and identify <b>fake</b> <b>news</b> <b>about</b> future events, which often relate to subjects entirely different from those in the past. However, existing <b>fake</b> <b>detection</b> <b>methods</b> exhibit a lack of robustness and cannot generalize to unseen events. To address this, we introduce Future ADaptive Event-based <b>Fake</b> <b>news</b> <b>Detection</b> (FADE) framework. Specifically, we train a target predictor through an adaptive augmentation strategy and <b>graph</b> <b>contrastive</b> <b>learning</b> to make more robust overall predictions. Simultaneously, we independently train an event-only predictor to obtain biased predictions. Then we further mitigate event bias by obtaining the final prediction by subtracting the output of the event-only predictor from the output of the target predictor. Encouraging results from experiments designed to emulate real-world social media conditions validate the effectiveness of our method in comparison to existing state-of-the-art approaches.

{{</citation>}}


### (2/4 | 236/321) Link Recommendation to Augment Influence Diffusion with Provable Guarantees (Xiaolong Chen et al., 2024)

{{<citation>}}

Xiaolong Chen, Yifan Song, Jing Tang. (2024)  
**Link Recommendation to Augment Influence Diffusion with Provable Guarantees**
<br/>
<button class="copy-to-clipboard" title="Link Recommendation to Augment Influence Diffusion with Provable Guarantees" index=236>
  <span class="copy-to-clipboard-item">Copy Title<span>
</button>
<div class="toast toast-copied toast-index-236 align-items-center text-bg-secondary border-0 position-absolute top-0 end-0" role="alert" aria-live="assertive" aria-atomic="true">
  <div class="d-flex">
    <div class="toast-body">
      Copied!
    </div>
  </div>
</div>

---
Primary Category: cs.SI  
Categories: cs-SI, cs.SI  
Keyword Score: 13  
Keywords: Graph, Recommendation  
<a type="button" class="btn btn-outline-primary" href="http://arxiv.org/abs/2402.19189v1" target="_blank" >Paper Link</a>
<button type="button" class="btn btn-outline-primary download-pdf" url="https://arxiv.org/pdf/2402.19189v1.pdf" filename="2402.19189v1.pdf">Download PDF</button>

---


**ABSTRACT**  
Link <b>recommendation</b> systems in online social networks (OSNs), such as Facebook's ``People You May Know'', Twitter's ``Who to Follow'', and Instagram's ``Suggested Accounts'', facilitate the formation of new connections among users. This paper addresses the challenge of link <b>recommendation</b> for the purpose of social influence maximization. In particular, given a <b>graph</b> $G$ and the seed set $S$, our objective is to select $k$ edges that connect seed nodes and ordinary nodes to optimize the influence dissemination of the seed set. This problem, referred to as influence maximization with augmentation (IMA), has been proven to be NP-hard. In this paper, we propose an algorithm, namely \textsf{AIS}, consisting of an efficient estimator for augmented influence estimation and an accelerated sampling approach. \textsf{AIS} provides a $(1-1/\mathrm{e}-\varepsilon)$-approximate solution with a high probability of $1-\delta$, and runs in $O(k^2 (m+n) \log (n / \delta) / \varepsilon^2 + k \left|E_{\mathcal{C}}\right|)$ time assuming that the influence of any singleton node is smaller than that of the seed set. To the best of our knowledge, this is the first algorithm that can be implemented on large <b>graphs</b> containing millions of nodes while preserving strong theoretical guarantees. We conduct extensive experiments to demonstrate the effectiveness and efficiency of our proposed algorithm.

{{</citation>}}


### (3/4 | 237/321) Higher-Order Networks Representation and Learning: A Survey (Hao Tian et al., 2024)

{{<citation>}}

Hao Tian, Reza Zafarani. (2024)  
**Higher-Order Networks Representation and Learning: A Survey**
<br/>
<button class="copy-to-clipboard" title="Higher-Order Networks Representation and Learning: A Survey" index=237>
  <span class="copy-to-clipboard-item">Copy Title<span>
</button>
<div class="toast toast-copied toast-index-237 align-items-center text-bg-secondary border-0 position-absolute top-0 end-0" role="alert" aria-live="assertive" aria-atomic="true">
  <div class="d-flex">
    <div class="toast-body">
      Copied!
    </div>
  </div>
</div>

---
Primary Category: cs.SI  
Categories: 68Q06, A-1; I-5-1, cs-DS, cs-SI, cs.SI  
Keyword Score: 3  
Keywords: Graph  
<a type="button" class="btn btn-outline-primary" href="http://arxiv.org/abs/2402.19414v1" target="_blank" >Paper Link</a>
<button type="button" class="btn btn-outline-primary download-pdf" url="https://arxiv.org/pdf/2402.19414v1.pdf" filename="2402.19414v1.pdf">Download PDF</button>

---


**ABSTRACT**  
Network data has become widespread, larger, and more complex over the years. Traditional network data is dyadic, capturing the relations among pairs of entities. With the need to model interactions among more than two entities, significant research has focused on higher-order networks and ways to represent, analyze, and learn from them. There are two main directions to studying higher-order networks. One direction has focused on capturing higher-order patterns in traditional (dyadic) <b>graphs</b> by changing the basic unit of study from nodes to small frequently observed subgraphs, called motifs. As most existing network data comes in the form of pairwise dyadic relationships, studying higher-order structures within such <b>graphs</b> may uncover new insights. The second direction aims to directly model higher-order interactions using new and more complex representations such as simplicial complexes or hypergraphs. Some of these models have long been proposed, but improvements in computational power and the advent of new computational techniques have increased their popularity. Our goal in this paper is to provide a succinct yet comprehensive summary of the advanced higher-order network analysis techniques. We provide a systematic review of its foundations and algorithms, along with use cases and applications of higher-order networks in various scientific domains.

{{</citation>}}


### (4/4 | 238/321) Scaling up Dynamic Edge Partition Models via Stochastic Gradient MCMC (Sikun Yang et al., 2024)

{{<citation>}}

Sikun Yang, Heinz Koeppl. (2024)  
**Scaling up Dynamic Edge Partition Models via Stochastic Gradient MCMC**
<br/>
<button class="copy-to-clipboard" title="Scaling up Dynamic Edge Partition Models via Stochastic Gradient MCMC" index=238>
  <span class="copy-to-clipboard-item">Copy Title<span>
</button>
<div class="toast toast-copied toast-index-238 align-items-center text-bg-secondary border-0 position-absolute top-0 end-0" role="alert" aria-live="assertive" aria-atomic="true">
  <div class="d-flex">
    <div class="toast-body">
      Copied!
    </div>
  </div>
</div>

---
Primary Category: cs.SI  
Categories: cs-AI, cs-LG, cs-SI, cs.SI  
Keyword Score: 3  
Keywords: Graph  
<a type="button" class="btn btn-outline-primary" href="http://arxiv.org/abs/2403.00044v1" target="_blank" >Paper Link</a>
<button type="button" class="btn btn-outline-primary download-pdf" url="https://arxiv.org/pdf/2403.00044v1.pdf" filename="2403.00044v1.pdf">Download PDF</button>

---


**ABSTRACT**  
The edge partition model (EPM) is a generative model for extracting an overlapping community structure from static <b>graph-structured</b> data. In the EPM, the gamma process (GaP) prior is adopted to infer the appropriate number of latent communities, and each vertex is endowed with a gamma distributed positive memberships vector. Despite having many attractive properties, inference in the EPM is typically performed using Markov chain Monte Carlo (MCMC) methods that prevent it from being applied to massive network data. In this paper, we generalize the EPM to account for dynamic enviroment by representing each vertex with a positive memberships vector constructed using Dirichlet prior specification, and capturing the time-evolving behaviour of vertices via a Dirichlet Markov chain construction. A simple-to-implement Gibbs sampler is proposed to perform posterior computation using Negative- Binomial augmentation technique. For large network data, we propose a stochastic gradient Markov chain Monte Carlo (SG-MCMC) algorithm for scalable inference in the proposed model. The experimental results show that the novel methods achieve competitive performance in terms of link prediction, while being much faster.

{{</citation>}}


## cs.IT (6)



### (1/6 | 239/321) Active Sensing for Reciprocal MIMO Channels (Tao Jiang et al., 2024)

{{<citation>}}

Tao Jiang, Wei Yu. (2024)  
**Active Sensing for Reciprocal MIMO Channels**
<br/>
<button class="copy-to-clipboard" title="Active Sensing for Reciprocal MIMO Channels" index=239>
  <span class="copy-to-clipboard-item">Copy Title<span>
</button>
<div class="toast toast-copied toast-index-239 align-items-center text-bg-secondary border-0 position-absolute top-0 end-0" role="alert" aria-live="assertive" aria-atomic="true">
  <div class="d-flex">
    <div class="toast-body">
      Copied!
    </div>
  </div>
</div>

---
Primary Category: cs.IT  
Categories: cs-IT, cs.IT, eess-SP, math-IT  
Keyword Score: 40  
Keywords: Simulation, Simulator, Recurrent Neural Network, Summarization  
<a type="button" class="btn btn-outline-primary" href="http://arxiv.org/abs/2403.00134v1" target="_blank" >Paper Link</a>
<button type="button" class="btn btn-outline-primary download-pdf" url="https://arxiv.org/pdf/2403.00134v1.pdf" filename="2403.00134v1.pdf">Download PDF</button>

---


**ABSTRACT**  
This paper addresses the design of transmit precoder and receive combiner matrices to support $N_{\rm s}$ independent data streams over a time-division duplex (TDD) point-to-point massive multiple-input multiple-output (MIMO) channel with either a fully digital or a hybrid structure. The optimal precoder and combiner design amounts to finding the top-$N_{\rm s}$ singular vectors of the channel matrix, but the explicit estimation of the entire high-dimensional channel would require significant pilot overhead. Alternatively, prior works seek to find the precoding and combining matrices directly by exploiting channel reciprocity and by using the power iteration method, but its performance degrades in the low SNR regime. To tackle this challenging problem, this paper proposes a learning-based active sensing framework, where the transmitter and the receiver send pilots alternately using sensing beamformers that are actively designed as functions of previously received pilots. This is accomplished by using <b>recurrent</b> <b>neural</b> <b>networks</b> to <b>summarize</b> information from the historical observations into hidden state vectors, then using fully connected neural networks to learn the appropriate sensing beamformers in the next pilot stage and finally the transmit precoding and receive combiner matrices for data communications. <b>Simulations</b> demonstrate that the learning-based method outperforms existing approaches significantly and maintains superior performance even in low SNR regimes both in fully digital and hybrid MIMO scenarios.

{{</citation>}}


### (2/6 | 240/321) Block-MDS QC-LDPC Codes for Information Reconciliation in Key Distribution (Lev Tauz et al., 2024)

{{<citation>}}

Lev Tauz, Debarnab Mitra, Jayanth Shreekumar, Murat Can Sarihan, Chee Wei Wong, Lara Dolecek. (2024)  
**Block-MDS QC-LDPC Codes for Information Reconciliation in Key Distribution**
<br/>
<button class="copy-to-clipboard" title="Block-MDS QC-LDPC Codes for Information Reconciliation in Key Distribution" index=240>
  <span class="copy-to-clipboard-item">Copy Title<span>
</button>
<div class="toast toast-copied toast-index-240 align-items-center text-bg-secondary border-0 position-absolute top-0 end-0" role="alert" aria-live="assertive" aria-atomic="true">
  <div class="d-flex">
    <div class="toast-body">
      Copied!
    </div>
  </div>
</div>

---
Primary Category: cs.IT  
Categories: cs-IT, cs.IT, math-IT  
Keyword Score: 30  
Keywords: Knowledge Distillation, Simulation, Simulator  
<a type="button" class="btn btn-outline-primary" href="http://arxiv.org/abs/2403.00192v1" target="_blank" >Paper Link</a>
<button type="button" class="btn btn-outline-primary download-pdf" url="https://arxiv.org/pdf/2403.00192v1.pdf" filename="2403.00192v1.pdf">Download PDF</button>

---


**ABSTRACT**  
Quantum key distribution (QKD) is a popular protocol that provides information theoretically secure keys to multiple parties. Two important post-processing steps of QKD are 1) the information reconciliation (IR) step, where parties reconcile mismatches in generated keys through classical communication, and 2) the privacy amplification (PA) step, where parties <b>distill</b> their common key into a new secure key that the adversary has little to no information about. In general, these two steps have been abstracted as two distinct problems. In this work, we consider a new technique of performing the IR and PA steps jointly through sampling that relaxes the requirement on the IR step, allowing for more success in key creation. We provide a novel LDPC code construction known as Block-MDS QC-LDPC codes that can utilize the relaxed requirement by creating LDPC codes with pre-defined sub-matrices of full-rank. We demonstrate through <b>simulations</b> that our technique of sampling can provide notable gains in successfully creating secret keys.

{{</citation>}}


### (3/6 | 241/321) Helper Data Schemes for Coded Modulation and Shaping in Physical Unclonable Functions (Robert F. H. Fischer, 2024)

{{<citation>}}

Robert F. H. Fischer. (2024)  
**Helper Data Schemes for Coded Modulation and Shaping in Physical Unclonable Functions**
<br/>
<button class="copy-to-clipboard" title="Helper Data Schemes for Coded Modulation and Shaping in Physical Unclonable Functions" index=241>
  <span class="copy-to-clipboard-item">Copy Title<span>
</button>
<div class="toast toast-copied toast-index-241 align-items-center text-bg-secondary border-0 position-absolute top-0 end-0" role="alert" aria-live="assertive" aria-atomic="true">
  <div class="d-flex">
    <div class="toast-body">
      Copied!
    </div>
  </div>
</div>

---
Primary Category: cs.IT  
Categories: cs-IT, cs.IT, math-IT  
Keyword Score: 20  
Keywords: Simulation, Simulator  
<a type="button" class="btn btn-outline-primary" href="http://arxiv.org/abs/2402.18980v1" target="_blank" >Paper Link</a>
<button type="button" class="btn btn-outline-primary download-pdf" url="https://arxiv.org/pdf/2402.18980v1.pdf" filename="2402.18980v1.pdf">Download PDF</button>

---


**ABSTRACT**  
In this paper, we consider the generation and utilization of helper data for physical unclonable functions (PUFs) that provide real-valued readout symbols. Compared to classical binary PUFs, more entropy can be extracted from each basic building block (PUF node), resulting in longer keys/fingerprints and/or a higher reliability. To this end, a coded modulation and signal shaping scheme that matches the (approximately) Gaussian distribution of the readout has to be employed. A new helper data scheme is proposed that works with any type of coded modulation/shaping scheme. Compared to the permutation scheme from the literature, less amount of helper data has to be generated and a higher reliability is achieved. Moreover, the recently proposed idea of a two-metric helper data scheme is generalized to coded modulation and a general S-metric scheme. It is shown how extra helper data can be generated to improve decodability. The proposed schemes are assessed by numerical <b>simulations</b> and by evaluation of measurement data. We compare multi-level codes using a new rate design strategy with bit-interleaved coded modulation and trellis shaping with a distribution matcher. By selecting a suitable design, the rate per PUF node that can be reliably extracted can be as high as 2~bit/node.

{{</citation>}}


### (4/6 | 242/321) The Road to Next-Generation Multiple Access: A 50-Year Tutorial Review (Yuanwei Liu et al., 2024)

{{<citation>}}

Yuanwei Liu, Chongjun Ouyang, Zhiguo Ding, Robert Schober. (2024)  
**The Road to Next-Generation Multiple Access: A 50-Year Tutorial Review**
<br/>
<button class="copy-to-clipboard" title="The Road to Next-Generation Multiple Access: A 50-Year Tutorial Review" index=242>
  <span class="copy-to-clipboard-item">Copy Title<span>
</button>
<div class="toast toast-copied toast-index-242 align-items-center text-bg-secondary border-0 position-absolute top-0 end-0" role="alert" aria-live="assertive" aria-atomic="true">
  <div class="d-flex">
    <div class="toast-body">
      Copied!
    </div>
  </div>
</div>

---
Primary Category: cs.IT  
Categories: cs-IT, cs.IT, eess-SP, math-IT  
Keyword Score: 10  
Keywords: Mutual Information  
<a type="button" class="btn btn-outline-primary" href="http://arxiv.org/abs/2403.00189v1" target="_blank" >Paper Link</a>
<button type="button" class="btn btn-outline-primary download-pdf" url="https://arxiv.org/pdf/2403.00189v1.pdf" filename="2403.00189v1.pdf">Download PDF</button>

---


**ABSTRACT**  
The evolution of wireless communications has been significantly influenced by remarkable advancements in multiple access (MA) technologies over the past five decades, shaping the landscape of modern connectivity. Within this context, a comprehensive tutorial review is presented, focusing on representative MA techniques developed over the past 50 years. The following areas are explored: i) The foundational principles and information-theoretic capacity limits of power-domain non-orthogonal multiple access (NOMA) are characterized, along with its extension to multiple-input multiple-output (MIMO)-NOMA. ii) Several MA transmission schemes exploiting the spatial domain are investigated, encompassing both conventional space-division multiple access (SDMA)/MIMO-NOMA systems and near-field MA systems utilizing spherical-wave propagation models. iii) The application of NOMA to integrated sensing and communications (ISAC) systems is studied. This includes an introduction to typical NOMA-based downlink/uplink ISAC frameworks, followed by an evaluation of their performance limits using a <b>mutual</b> <b>information</b> (MI)-based analytical framework. iv) Major issues and research opportunities associated with the integration of MA with other emerging technologies are identified to facilitate MA in next-generation networks, i.e., next-generation multiple access (NGMA). Throughout the paper, promising directions are highlighted to inspire future research endeavors in the realm of MA and NGMA.

{{</citation>}}


### (5/6 | 243/321) Digital Twin Aided Massive MIMO: CSI Compression and Feedback (Shuaifeng Jiang et al., 2024)

{{<citation>}}

Shuaifeng Jiang, Ahmed Alkhateeb. (2024)  
**Digital Twin Aided Massive MIMO: CSI Compression and Feedback**
<br/>
<button class="copy-to-clipboard" title="Digital Twin Aided Massive MIMO: CSI Compression and Feedback" index=243>
  <span class="copy-to-clipboard-item">Copy Title<span>
</button>
<div class="toast toast-copied toast-index-243 align-items-center text-bg-secondary border-0 position-absolute top-0 end-0" role="alert" aria-live="assertive" aria-atomic="true">
  <div class="d-flex">
    <div class="toast-body">
      Copied!
    </div>
  </div>
</div>

---
Primary Category: cs.IT  
Categories: cs-IT, cs.IT, eess-SP, math-IT  
Keyword Score: 10  
Keywords: Domain Adaptation  
<a type="button" class="btn btn-outline-primary" href="http://arxiv.org/abs/2402.19434v2" target="_blank" >Paper Link</a>
<button type="button" class="btn btn-outline-primary download-pdf" url="https://arxiv.org/pdf/2402.19434v2.pdf" filename="2402.19434v2.pdf">Download PDF</button>

---


**ABSTRACT**  
Deep learning (DL) approaches have demonstrated high performance in compressing and reconstructing the channel state information (CSI) and reducing the CSI feedback overhead in massive MIMO systems. One key challenge, however, with the DL approaches is the demand for extensive training data. Collecting this real-world CSI data incurs significant overhead that hinders the DL approaches from scaling to a large number of communication sites. To address this challenge, we propose a novel direction that utilizes site-specific \textit{digital twins} to aid the training of DL models. The proposed digital twin approach generates site-specific synthetic CSI data from the EM 3D model and ray tracing, which can then be used to train the DL model without real-world data collection. To further improve the performance, we adopt online data selection to refine the DL model training with a small real-world CSI dataset. Results show that a DL model trained solely on the digital twin data can achieve high performance when tested in a real-world deployment. Further, leveraging <b>domain</b> <b>adaptation</b> techniques, the proposed approach requires orders of magnitude less real-world data to approach the same performance of the model trained completely on a real-world CSI dataset.

{{</citation>}}


### (6/6 | 244/321) Evaluating the Gilbert-Varshamov Bound for Constrained Systems (Keshav Goyal et al., 2024)

{{<citation>}}

Keshav Goyal, Han Mao Kiah. (2024)  
**Evaluating the Gilbert-Varshamov Bound for Constrained Systems**
<br/>
<button class="copy-to-clipboard" title="Evaluating the Gilbert-Varshamov Bound for Constrained Systems" index=244>
  <span class="copy-to-clipboard-item">Copy Title<span>
</button>
<div class="toast toast-copied toast-index-244 align-items-center text-bg-secondary border-0 position-absolute top-0 end-0" role="alert" aria-live="assertive" aria-atomic="true">
  <div class="d-flex">
    <div class="toast-body">
      Copied!
    </div>
  </div>
</div>

---
Primary Category: cs.IT  
Categories: cs-DM, cs-IT, cs.IT, math-CO, math-IT  
Keyword Score: 3  
Keywords: Graph  
<a type="button" class="btn btn-outline-primary" href="http://arxiv.org/abs/2402.18869v1" target="_blank" >Paper Link</a>
<button type="button" class="btn btn-outline-primary download-pdf" url="https://arxiv.org/pdf/2402.18869v1.pdf" filename="2402.18869v1.pdf">Download PDF</button>

---


**ABSTRACT**  
We revisit the well-known Gilbert-Varshamov (GV) bound for constrained systems. In 1991, Kolesnik and Krachkovsky showed that GV bound can be determined via the solution of some optimization problem. Later, Marcus and Roth (1992) modified the optimization problem and improved the GV bound in many instances. In this work, we provide explicit numerical procedures to solve these two optimization problems and hence, compute the bounds. We then show the procedures can be further simplified when we plot the respective curves. In the case where the <b>graph</b> presentation comprise a single state, we provide explicit formulas for both bounds.

{{</citation>}}


## cs.RO (13)



### (1/13 | 245/321) From Flies to Robots: Inverted Landing in Small Quadcopters with Dynamic Perching (Bryan Habas et al., 2024)

{{<citation>}}

Bryan Habas, Bo Cheng. (2024)  
**From Flies to Robots: Inverted Landing in Small Quadcopters with Dynamic Perching**
<br/>
<button class="copy-to-clipboard" title="From Flies to Robots: Inverted Landing in Small Quadcopters with Dynamic Perching" index=245>
  <span class="copy-to-clipboard-item">Copy Title<span>
</button>
<div class="toast toast-copied toast-index-245 align-items-center text-bg-secondary border-0 position-absolute top-0 end-0" role="alert" aria-live="assertive" aria-atomic="true">
  <div class="d-flex">
    <div class="toast-body">
      Copied!
    </div>
  </div>
</div>

---
Primary Category: cs.RO  
Categories: cs-LG, cs-RO, cs-SY, cs.RO, eess-SY  
Keyword Score: 40  
Keywords: Reinforcement Learning, Simulation, Simulator, Zero-shot  
<a type="button" class="btn btn-outline-primary" href="http://arxiv.org/abs/2403.00128v1" target="_blank" >Paper Link</a>
<button type="button" class="btn btn-outline-primary download-pdf" url="https://arxiv.org/pdf/2403.00128v1.pdf" filename="2403.00128v1.pdf">Download PDF</button>

---


**ABSTRACT**  
Inverted landing is a routine behavior among a number of animal fliers. However, mastering this feat poses a considerable challenge for robotic fliers, especially to perform dynamic perching with rapid body rotations (or flips) and landing against gravity. Inverted landing in flies have suggested that optical flow senses are closely linked to the precise triggering and control of body flips that lead to a variety of successful landing behaviors. Building upon this knowledge, we aimed to replicate the flies' landing behaviors in small quadcopters by developing a control policy general to arbitrary ceiling-approach conditions. First, we employed <b>reinforcement</b> <b>learning</b> in <b>simulation</b> to optimize discrete sensory-motor pairs across a broad spectrum of ceiling-approach velocities and directions. Next, we converted the sensory-motor pairs to a two-stage control policy in a continuous augmented-optical flow space. The control policy consists of a first-stage Flip-Trigger Policy, which employs a one-class support vector machine, and a second-stage Flip-Action Policy, implemented as a feed-forward neural network. To transfer the inverted-landing policy to physical systems, we utilized domain randomization and system identification techniques for a <b>zero-shot</b> sim-to-real transfer. As a result, we successfully achieved a range of robust inverted-landing behaviors in small quadcopters, emulating those observed in flies.

{{</citation>}}


### (2/13 | 246/321) Mirage: Cross-Embodiment Zero-Shot Policy Transfer with Cross-Painting (Lawrence Yunliang Chen et al., 2024)

{{<citation>}}

Lawrence Yunliang Chen, Kush Hari, Karthik Dharmarajan, Chenfeng Xu, Quan Vuong, Ken Goldberg. (2024)  
**Mirage: Cross-Embodiment Zero-Shot Policy Transfer with Cross-Painting**
<br/>
<button class="copy-to-clipboard" title="Mirage: Cross-Embodiment Zero-Shot Policy Transfer with Cross-Painting" index=246>
  <span class="copy-to-clipboard-item">Copy Title<span>
</button>
<div class="toast toast-copied toast-index-246 align-items-center text-bg-secondary border-0 position-absolute top-0 end-0" role="alert" aria-live="assertive" aria-atomic="true">
  <div class="d-flex">
    <div class="toast-body">
      Copied!
    </div>
  </div>
</div>

---
Primary Category: cs.RO  
Categories: cs-RO, cs.RO  
Keyword Score: 40  
Keywords: Fine-tuning, Simulation, Simulator, Zero-shot  
<a type="button" class="btn btn-outline-primary" href="http://arxiv.org/abs/2402.19249v1" target="_blank" >Paper Link</a>
<button type="button" class="btn btn-outline-primary download-pdf" url="https://arxiv.org/pdf/2402.19249v1.pdf" filename="2402.19249v1.pdf">Download PDF</button>

---


**ABSTRACT**  
The ability to reuse collected data and transfer trained policies between robots could alleviate the burden of additional data collection and training. While existing approaches such as pretraining plus <b>finetuning</b> and co-training show promise, they do not generalize to robots unseen in training. Focusing on common robot arms with similar workspaces and 2-jaw grippers, we investigate the feasibility of <b>zero-shot</b> transfer. Through <b>simulation</b> studies on 8 manipulation tasks, we find that state-based Cartesian control policies can successfully <b>zero-shot</b> transfer to a target robot after accounting for forward dynamics. To address robot visual disparities for vision-based policies, we introduce Mirage, which uses "cross-painting"--masking out the unseen target robot and inpainting the seen source robot--during execution in real time so that it appears to the policy as if the trained source robot were performing the task. Despite its simplicity, our extensive <b>simulation</b> and physical experiments provide strong evidence that Mirage can successfully <b>zero-shot</b> transfer between different robot arms and grippers with only minimal performance degradation on a variety of manipulation tasks such as picking, stacking, and assembly, significantly outperforming a generalist policy. Project website: https://robot-mirage.github.io/

{{</citation>}}


### (3/13 | 247/321) ARMCHAIR: integrated inverse reinforcement learning and model predictive control for human-robot collaboration (Angelo Caregnato-Neto et al., 2024)

{{<citation>}}

Angelo Caregnato-Neto, Luciano Cavalcante Siebert, Arkady Zgonnikov, Marcos Ricardo Omena de Albuquerque Maximo, Rubens Junqueira Magalhães Afonso. (2024)  
**ARMCHAIR: integrated inverse reinforcement learning and model predictive control for human-robot collaboration**
<br/>
<button class="copy-to-clipboard" title="ARMCHAIR: integrated inverse reinforcement learning and model predictive control for human-robot collaboration" index=247>
  <span class="copy-to-clipboard-item">Copy Title<span>
</button>
<div class="toast toast-copied toast-index-247 align-items-center text-bg-secondary border-0 position-absolute top-0 end-0" role="alert" aria-live="assertive" aria-atomic="true">
  <div class="d-flex">
    <div class="toast-body">
      Copied!
    </div>
  </div>
</div>

---
Primary Category: cs.RO  
Categories: cs-HC, cs-MA, cs-RO, cs-SY, cs.RO, eess-SY  
Keyword Score: 40  
Keywords: Human Intervention, Reinforcement Learning, Simulation, Simulator  
<a type="button" class="btn btn-outline-primary" href="http://arxiv.org/abs/2402.19128v1" target="_blank" >Paper Link</a>
<button type="button" class="btn btn-outline-primary download-pdf" url="https://arxiv.org/pdf/2402.19128v1.pdf" filename="2402.19128v1.pdf">Download PDF</button>

---


**ABSTRACT**  
One of the key issues in <b>human-robot</b> <b>collaboration</b> is the development of computational models that allow robots to predict and adapt to <b>human</b> <b>behavior.</b> Much progress has been achieved in developing such models, as well as control techniques that address the autonomy problems of motion planning and decision-making in robotics. However, the integration of computational models of <b>human</b> <b>behavior</b> with such control techniques still poses a major challenge, resulting in a bottleneck for efficient collaborative <b>human-robot</b> <b>teams.</b> In this context, we present a novel architecture for <b>human-robot</b> <b>collaboration:</b> Adaptive Robot Motion for Collaboration with <b>Humans</b> <b>using</b> Adversarial Inverse <b>Reinforcement</b> <b>learning</b> (ARMCHAIR). Our solution leverages adversarial inverse <b>reinforcement</b> <b>learning</b> and model predictive control to compute optimal trajectories and decisions for a mobile multi-robot system that collaborates with a <b>human</b> <b>in</b> an exploration task. During the mission, ARMCHAIR operates without <b>human</b> <b>intervention,</b> autonomously identifying the necessity to support and acting accordingly. Our approach also explicitly addresses the network connectivity requirement of the <b>human-robot</b> <b>team.</b> Extensive <b>simulation-based</b> evaluations demonstrate that ARMCHAIR allows a group of robots to safely support a simulated <b>human</b> <b>in</b> an exploration scenario, preventing collisions and network disconnections, and improving the overall performance of the task.

{{</citation>}}


### (4/13 | 248/321) Learning to walk in confined spaces using 3D representation (Takahiro Miki et al., 2024)

{{<citation>}}

Takahiro Miki, Joonho Lee, Lorenz Wellhausen, Marco Hutter. (2024)  
**Learning to walk in confined spaces using 3D representation**
<br/>
<button class="copy-to-clipboard" title="Learning to walk in confined spaces using 3D representation" index=248>
  <span class="copy-to-clipboard-item">Copy Title<span>
</button>
<div class="toast toast-copied toast-index-248 align-items-center text-bg-secondary border-0 position-absolute top-0 end-0" role="alert" aria-live="assertive" aria-atomic="true">
  <div class="d-flex">
    <div class="toast-body">
      Copied!
    </div>
  </div>
</div>

---
Primary Category: cs.RO  
Categories: cs-RO, cs.RO  
Keyword Score: 30  
Keywords: Reinforcement Learning, Simulation, Simulator  
<a type="button" class="btn btn-outline-primary" href="http://arxiv.org/abs/2403.00187v1" target="_blank" >Paper Link</a>
<button type="button" class="btn btn-outline-primary download-pdf" url="https://arxiv.org/pdf/2403.00187v1.pdf" filename="2403.00187v1.pdf">Download PDF</button>

---


**ABSTRACT**  
Legged robots have the potential to traverse complex terrain and access confined spaces beyond the reach of traditional platforms thanks to their ability to carefully select footholds and flexibly adapt their body posture while walking. However, robust deployment in real-world applications is still an open challenge. In this paper, we present a method for legged locomotion control using <b>reinforcement</b> <b>learning</b> and 3D volumetric representations to enable robust and versatile locomotion in confined and unstructured environments. By employing a two-layer hierarchical policy structure, we exploit the capabilities of a highly robust low-level policy to follow 6D commands and a high-level policy to enable three-dimensional spatial awareness for navigating under overhanging obstacles. Our study includes the development of a procedural terrain generator to create diverse training environments. We present a series of experimental evaluations in both <b>simulation</b> and real-world settings, demonstrating the effectiveness of our approach in controlling a quadruped robot in confined, rough terrain. By achieving this, our work extends the applicability of legged robots to a broader range of scenarios.

{{</citation>}}


### (5/13 | 249/321) Conversational Language Models for Human-in-the-Loop Multi-Robot Coordination (William Hunt et al., 2024)

{{<citation>}}

William Hunt, Toby Godfrey, Mohammad D. Soorati. (2024)  
**Conversational Language Models for Human-in-the-Loop Multi-Robot Coordination**
<br/>
<button class="copy-to-clipboard" title="Conversational Language Models for Human-in-the-Loop Multi-Robot Coordination" index=249>
  <span class="copy-to-clipboard-item">Copy Title<span>
</button>
<div class="toast toast-copied toast-index-249 align-items-center text-bg-secondary border-0 position-absolute top-0 end-0" role="alert" aria-live="assertive" aria-atomic="true">
  <div class="d-flex">
    <div class="toast-body">
      Copied!
    </div>
  </div>
</div>

---
Primary Category: cs.RO  
Categories: cs-RO, cs.RO  
Keyword Score: 26  
Keywords: Multi-modal, Multi-modal, human-in-the-loop, Large Language Model  
<a type="button" class="btn btn-outline-primary" href="http://arxiv.org/abs/2402.19166v1" target="_blank" >Paper Link</a>
<button type="button" class="btn btn-outline-primary download-pdf" url="https://arxiv.org/pdf/2402.19166v1.pdf" filename="2402.19166v1.pdf">Download PDF</button>

---


**ABSTRACT**  
With the increasing prevalence and diversity of robots interacting in the real world, there is need for flexible, on-the-fly planning and cooperation. <b>Large</b> <b>Language</b> <b>Models</b> are starting to be explored in a <b>multimodal</b> setup for communication, coordination, and planning in robotics. Existing approaches generally use a single agent building a plan, or have multiple homogeneous agents coordinating for a simple task. We present a decentralised, dialogical approach in which a team of agents with different abilities plans solutions through peer-to-peer and human-robot discussion. We suggest that argument-style dialogues are an effective way to facilitate adaptive use of each agent's abilities within a cooperative team. Two robots discuss how to solve a cleaning problem set by a human, define roles, and agree on paths they each take. Each step can be interrupted by a human advisor and agents check their plans with the human. Agents then execute this plan in the real world, collecting rubbish from people in each room. Our implementation uses text at every step, maintaining transparency and effective human-multi-robot interaction.

{{</citation>}}


### (6/13 | 250/321) Humanoid Locomotion as Next Token Prediction (Ilija Radosavovic et al., 2024)

{{<citation>}}

Ilija Radosavovic, Bike Zhang, Baifeng Shi, Jathushan Rajasegaran, Sarthak Kamat, Trevor Darrell, Koushil Sreenath, Jitendra Malik. (2024)  
**Humanoid Locomotion as Next Token Prediction**
<br/>
<button class="copy-to-clipboard" title="Humanoid Locomotion as Next Token Prediction" index=250>
  <span class="copy-to-clipboard-item">Copy Title<span>
</button>
<div class="toast toast-copied toast-index-250 align-items-center text-bg-secondary border-0 position-absolute top-0 end-0" role="alert" aria-live="assertive" aria-atomic="true">
  <div class="d-flex">
    <div class="toast-body">
      Copied!
    </div>
  </div>
</div>

---
Primary Category: cs.RO  
Categories: cs-CV, cs-LG, cs-RO, cs.RO  
Keyword Score: 23  
Keywords: Multi-modal, Zero-shot, Transformer  
<a type="button" class="btn btn-outline-primary" href="http://arxiv.org/abs/2402.19469v1" target="_blank" >Paper Link</a>
<button type="button" class="btn btn-outline-primary download-pdf" url="https://arxiv.org/pdf/2402.19469v1.pdf" filename="2402.19469v1.pdf">Download PDF</button>

---


**ABSTRACT**  
We cast real-world humanoid control as a next token prediction problem, akin to predicting the next word in language. Our model is a causal <b>transformer</b> trained via autoregressive prediction of sensorimotor trajectories. To account for the <b>multi-modal</b> nature of the data, we perform prediction in a modality-aligned way, and for each input token predict the next token from the same modality. This general formulation enables us to leverage data with missing modalities, like video trajectories without actions. We train our model on a collection of simulated trajectories coming from prior neural network policies, model-based controllers, motion capture data, and YouTube videos of humans. We show that our model enables a full-sized humanoid to walk in San Francisco <b>zero-shot.</b> Our model can transfer to the real world even when trained on only 27 hours of walking data, and can generalize to commands not seen during training like walking backward. These findings suggest a promising path toward learning challenging real-world control tasks by generative modeling of sensorimotor trajectories.

{{</citation>}}


### (7/13 | 251/321) Developing a Taxonomy of Elements Adversarial to Autonomous Vehicles (Mohammadali Saffary et al., 2024)

{{<citation>}}

Mohammadali Saffary, Nishan Inampudi, Joshua E. Siegel. (2024)  
**Developing a Taxonomy of Elements Adversarial to Autonomous Vehicles**
<br/>
<button class="copy-to-clipboard" title="Developing a Taxonomy of Elements Adversarial to Autonomous Vehicles" index=251>
  <span class="copy-to-clipboard-item">Copy Title<span>
</button>
<div class="toast toast-copied toast-index-251 align-items-center text-bg-secondary border-0 position-absolute top-0 end-0" role="alert" aria-live="assertive" aria-atomic="true">
  <div class="d-flex">
    <div class="toast-body">
      Copied!
    </div>
  </div>
</div>

---
Primary Category: cs.RO  
Categories: cs-RO, cs.RO  
Keyword Score: 20  
Keywords: Simulation, Simulator  
<a type="button" class="btn btn-outline-primary" href="http://arxiv.org/abs/2403.00136v1" target="_blank" >Paper Link</a>
<button type="button" class="btn btn-outline-primary download-pdf" url="https://arxiv.org/pdf/2403.00136v1.pdf" filename="2403.00136v1.pdf">Download PDF</button>

---


**ABSTRACT**  
As highly automated vehicles reach higher deployment rates, they find themselves in increasingly dangerous situations. Knowing that the consequence of a crash is significant for the health of occupants, bystanders, and properties, as well as to the viability of autonomy and adjacent businesses, we must search for more efficacious ways to comprehensively and reliably train autonomous vehicles to better navigate the complex scenarios with which they struggle. We therefore introduce a taxonomy of potentially adversarial elements that may contribute to poor performance or system failures as a means of identifying and elucidating lesser-seen risks. This taxonomy may be used to characterize failures of automation, as well as to support <b>simulation</b> and real-world training efforts by providing a more comprehensive classification system for events resulting in disengagement, collision, or other negative consequences. This taxonomy is created from and tested against real collision events to ensure comprehensive coverage with minimal class overlap and few omissions. It is intended to be used both for the identification of harm-contributing adversarial events and in the generation thereof (to create extreme edge- and corner-case scenarios) in training procedures.

{{</citation>}}


### (8/13 | 252/321) Navigation and Control of Unconventional VTOL UAVs in Forward-Flight with Explicit Wind Velocity Estimation (Mitchell Cohen et al., 2024)

{{<citation>}}

Mitchell Cohen, James Richard Forbes. (2024)  
**Navigation and Control of Unconventional VTOL UAVs in Forward-Flight with Explicit Wind Velocity Estimation**
<br/>
<button class="copy-to-clipboard" title="Navigation and Control of Unconventional VTOL UAVs in Forward-Flight with Explicit Wind Velocity Estimation" index=252>
  <span class="copy-to-clipboard-item">Copy Title<span>
</button>
<div class="toast toast-copied toast-index-252 align-items-center text-bg-secondary border-0 position-absolute top-0 end-0" role="alert" aria-live="assertive" aria-atomic="true">
  <div class="d-flex">
    <div class="toast-body">
      Copied!
    </div>
  </div>
</div>

---
Primary Category: cs.RO  
Categories: cs-RO, cs.RO  
Keyword Score: 20  
Keywords: Simulation, Simulator  
<a type="button" class="btn btn-outline-primary" href="http://arxiv.org/abs/2403.00076v1" target="_blank" >Paper Link</a>
<button type="button" class="btn btn-outline-primary download-pdf" url="https://arxiv.org/pdf/2403.00076v1.pdf" filename="2403.00076v1.pdf">Download PDF</button>

---


**ABSTRACT**  
This paper presents a solution for the state estimation and control problems for a class of unconventional vertical takeoff and landing (VTOL) UAVs operating in forward-flight conditions. A tightly-coupled state estimation approach is used to estimate the aircraft navigation states, sensor biases, and the wind velocity. State estimation is done within a matrix Lie group framework using the Invariant Extended Kalman Filter (IEKF), which offers several advantages compared to standard multiplicative EKFs traditionally used in aerospace and robotics problems. An SO(3)- based attitude controller is employed, leading to a single attitude control law without a separate sideslip control loop. A control allocator is used to determine how to use multiple, possibly redundant, actuators to produce the desired control moments. The wind velocity estimates are used in the attitude controller and the control allocator to improve performance. A numerical example is considered using a sample VTOL tailsitter-type UAV with four control surfaces. Monte-Carlo <b>simulations</b> demonstrate robustness of the proposed control and estimation scheme to various initial conditions, noise levels, and flight trajectories.

{{</citation>}}


### (9/13 | 253/321) Pushing the Limits of Cross-Embodiment Learning for Manipulation and Navigation (Jonathan Yang et al., 2024)

{{<citation>}}

Jonathan Yang, Catherine Glossop, Arjun Bhorkar, Dhruv Shah, Quan Vuong, Chelsea Finn, Dorsa Sadigh, Sergey Levine. (2024)  
**Pushing the Limits of Cross-Embodiment Learning for Manipulation and Navigation**
<br/>
<button class="copy-to-clipboard" title="Pushing the Limits of Cross-Embodiment Learning for Manipulation and Navigation" index=253>
  <span class="copy-to-clipboard-item">Copy Title<span>
</button>
<div class="toast toast-copied toast-index-253 align-items-center text-bg-secondary border-0 position-absolute top-0 end-0" role="alert" aria-live="assertive" aria-atomic="true">
  <div class="d-flex">
    <div class="toast-body">
      Copied!
    </div>
  </div>
</div>

---
Primary Category: cs.RO  
Categories: 68T40, I-2-9, cs-RO, cs.RO  
Keyword Score: 20  
Keywords: Foundation Model, Zero-shot  
<a type="button" class="btn btn-outline-primary" href="http://arxiv.org/abs/2402.19432v1" target="_blank" >Paper Link</a>
<button type="button" class="btn btn-outline-primary download-pdf" url="https://arxiv.org/pdf/2402.19432v1.pdf" filename="2402.19432v1.pdf">Download PDF</button>

---


**ABSTRACT**  
Recent years in robotics and imitation learning have shown remarkable progress in training large-scale <b>foundation</b> <b>models</b> by leveraging data across a multitude of embodiments. The success of such policies might lead us to wonder: just how diverse can the robots in the training set be while still facilitating positive transfer? In this work, we study this question in the context of heterogeneous embodiments, examining how even seemingly very different domains, such as robotic navigation and manipulation, can provide benefits when included in the training data for the same model. We train a single goal-conditioned policy that is capable of controlling robotic arms, quadcopters, quadrupeds, and mobile bases. We then investigate the extent to which transfer can occur across navigation and manipulation on these embodiments by framing them as a single goal-reaching task. We find that co-training with navigation data can enhance robustness and performance in goal-conditioned manipulation with a wrist-mounted camera. We then deploy our policy trained only from navigation-only and static manipulation-only data on a mobile manipulator, showing that it can control a novel embodiment in a <b>zero-shot</b> manner. These results provide evidence that large-scale robotic policies can benefit from data collected across various embodiments. Further information and robot videos can be found on our project website http://extreme-cross-embodiment.github.io.

{{</citation>}}


### (10/13 | 254/321) Contact-Implicit Model Predictive Control for Dexterous In-hand Manipulation: A Long-Horizon and Robust Approach (Yongpeng Jiang et al., 2024)

{{<citation>}}

Yongpeng Jiang, Mingrui Yu, Xinghao Zhu, Masayoshi Tomizuka, Xiang Li. (2024)  
**Contact-Implicit Model Predictive Control for Dexterous In-hand Manipulation: A Long-Horizon and Robust Approach**
<br/>
<button class="copy-to-clipboard" title="Contact-Implicit Model Predictive Control for Dexterous In-hand Manipulation: A Long-Horizon and Robust Approach" index=254>
  <span class="copy-to-clipboard-item">Copy Title<span>
</button>
<div class="toast toast-copied toast-index-254 align-items-center text-bg-secondary border-0 position-absolute top-0 end-0" role="alert" aria-live="assertive" aria-atomic="true">
  <div class="d-flex">
    <div class="toast-body">
      Copied!
    </div>
  </div>
</div>

---
Primary Category: cs.RO  
Categories: cs-RO, cs.RO  
Keyword Score: 20  
Keywords: Simulation, Simulator  
<a type="button" class="btn btn-outline-primary" href="http://arxiv.org/abs/2402.18897v1" target="_blank" >Paper Link</a>
<button type="button" class="btn btn-outline-primary download-pdf" url="https://arxiv.org/pdf/2402.18897v1.pdf" filename="2402.18897v1.pdf">Download PDF</button>

---


**ABSTRACT**  
Dexterous in-hand manipulation is an essential skill of production and life. Nevertheless, the highly stiff and mutable features of contacts cause limitations to real-time contact discovery and inference, which degrades the performance of model-based methods. Inspired by recent advancements in contact-rich locomotion and manipulation, this paper proposes a novel model-based approach to control dexterous in-hand manipulation and overcome the current limitations. The proposed approach has the attractive feature, which allows the robot to robustly execute long-horizon in-hand manipulation without pre-defined contact sequences or separated planning procedures. Specifically, we design a contact-implicit model predictive controller at high-level to generate real-time contact plans, which are executed by the low-level tracking controller. Compared with other model-based methods, such a long-horizon feature enables replanning and robust execution of contact-rich motions to achieve large-displacement in-hand tasks more efficiently; Compared with existing learning-based methods, the proposed approach achieves the dexterity and also generalizes to different objects without any pre-training. Detailed <b>simulations</b> and ablation studies demonstrate the efficiency and effectiveness of our method. It runs at 20Hz on the 23-degree-of-freedom long-horizon in-hand object rotation task.

{{</citation>}}


### (11/13 | 255/321) RoadRunner - Learning Traversability Estimation for Autonomous Off-road Driving (Jonas Frey et al., 2024)

{{<citation>}}

Jonas Frey, Shehryar Khattak, Manthan Patel, Deegan Atha, Julian Nubert, Curtis Padgett, Marco Hutter, Patrick Spieler. (2024)  
**RoadRunner - Learning Traversability Estimation for Autonomous Off-road Driving**
<br/>
<button class="copy-to-clipboard" title="RoadRunner - Learning Traversability Estimation for Autonomous Off-road Driving" index=255>
  <span class="copy-to-clipboard-item">Copy Title<span>
</button>
<div class="toast toast-copied toast-index-255 align-items-center text-bg-secondary border-0 position-absolute top-0 end-0" role="alert" aria-live="assertive" aria-atomic="true">
  <div class="d-flex">
    <div class="toast-body">
      Copied!
    </div>
  </div>
</div>

---
Primary Category: cs.RO  
Categories: cs-CV, cs-RO, cs.RO  
Keyword Score: 15  
Keywords: Geometry, Self-supervised Learning  
<a type="button" class="btn btn-outline-primary" href="http://arxiv.org/abs/2402.19341v2" target="_blank" >Paper Link</a>
<button type="button" class="btn btn-outline-primary download-pdf" url="https://arxiv.org/pdf/2402.19341v2.pdf" filename="2402.19341v2.pdf">Download PDF</button>

---


**ABSTRACT**  
Autonomous navigation at high speeds in off-road environments necessitates robots to comprehensively understand their surroundings using onboard sensing only. The extreme conditions posed by the off-road setting can cause degraded camera image quality due to poor lighting and motion blur, as well as limited sparse geometric information available from LiDAR sensing when driving at high speeds. In this work, we present RoadRunner, a novel framework capable of predicting terrain traversability and an elevation map directly from camera and LiDAR sensor inputs. RoadRunner enables reliable autonomous navigation, by fusing sensory information, handling of uncertainty, and generation of contextually informed predictions about the <b>geometry</b> and traversability of the terrain while operating at low latency. In contrast to existing methods relying on classifying handcrafted semantic classes and using heuristics to predict traversability costs, our method is trained end-to-end in a <b>self-supervised</b> fashion. The RoadRunner network architecture builds upon popular sensor fusion network architectures from the autonomous driving domain, which embed LiDAR and camera information into a common Bird's Eye View perspective. Training is enabled by utilizing an existing traversability estimation stack to generate training data in hindsight in a scalable manner from real-world off-road driving datasets. Furthermore, RoadRunner improves the system latency by a factor of roughly 4, from 500 ms to 140 ms, while improving the accuracy for traversability costs and elevation map predictions. We demonstrate the effectiveness of RoadRunner in enabling safe and reliable off-road navigation at high speeds in multiple real-world driving scenarios through unstructured desert environments.

{{</citation>}}


### (12/13 | 256/321) Genie: Smart ROS-based Caching for Connected Autonomous Robots (Zexin Li et al., 2024)

{{<citation>}}

Zexin Li, Soroush Bateni, Cong Liu. (2024)  
**Genie: Smart ROS-based Caching for Connected Autonomous Robots**
<br/>
<button class="copy-to-clipboard" title="Genie: Smart ROS-based Caching for Connected Autonomous Robots" index=256>
  <span class="copy-to-clipboard-item">Copy Title<span>
</button>
<div class="toast toast-copied toast-index-256 align-items-center text-bg-secondary border-0 position-absolute top-0 end-0" role="alert" aria-live="assertive" aria-atomic="true">
  <div class="d-flex">
    <div class="toast-body">
      Copied!
    </div>
  </div>
</div>

---
Primary Category: cs.RO  
Categories: cs-RO, cs-SY, cs.RO, eess-SY  
Keyword Score: 10  
Keywords: Object Detection  
<a type="button" class="btn btn-outline-primary" href="http://arxiv.org/abs/2402.19410v1" target="_blank" >Paper Link</a>
<button type="button" class="btn btn-outline-primary download-pdf" url="https://arxiv.org/pdf/2402.19410v1.pdf" filename="2402.19410v1.pdf">Download PDF</button>

---


**ABSTRACT**  
Despite the promising future of autonomous robots, several key issues currently remain that can lead to compromised performance and safety. One such issue is latency, where we find that even the latest embedded platforms from NVIDIA fail to execute intelligence tasks (e.g., <b>object</b> <b>detection)</b> of autonomous vehicles in a real-time fashion. One remedy to this problem is the promising paradigm of edge computing. Through collaboration with our industry partner, we identify key prohibitive limitations of the current edge mindset: (1) servers are not distributed enough and thus, are not close enough to vehicles, (2) current proposed edge solutions do not provide substantially better performance and extra information specific to autonomous vehicles to warrant their cost to the user, and (3) the state-of-the-art solutions are not compatible with popular frameworks used in autonomous systems, particularly the Robot Operating System (ROS). To remedy these issues, we provide Genie, an encapsulation technique that can enable transparent caching in ROS in a non-intrusive way (i.e., without modifying the source code), can build the cache in a distributed manner (in contrast to traditional central caching methods), and can construct a collective three-dimensional <b>object</b> <b>map</b> to provide substantially better latency (even on low-power edge servers) and higher quality data to all vehicles in a certain locality. We fully implement our design on state-of-the-art industry-adopted embedded and edge platforms, using the prominent autonomous driving software Autoware, and find that Genie can enhance the latency of Autoware Vision Detector by 82% on average, enable <b>object</b> <b>reusability</b> 31% of the time on average and as much as 67% for the incoming requests, and boost the confidence in its <b>object</b> <b>map</b> considerably over time.

{{</citation>}}


### (13/13 | 257/321) RELEAD: Resilient Localization with Enhanced LiDAR Odometry in Adverse Environments (Zhiqiang Chen et al., 2024)

{{<citation>}}

Zhiqiang Chen, Hongbo Chen, Yuhua Qi, Shipeng Zhong, Dapeng Feng, Wu Jin, Weisong Wen, Ming Liu. (2024)  
**RELEAD: Resilient Localization with Enhanced LiDAR Odometry in Adverse Environments**
<br/>
<button class="copy-to-clipboard" title="RELEAD: Resilient Localization with Enhanced LiDAR Odometry in Adverse Environments" index=257>
  <span class="copy-to-clipboard-item">Copy Title<span>
</button>
<div class="toast toast-copied toast-index-257 align-items-center text-bg-secondary border-0 position-absolute top-0 end-0" role="alert" aria-live="assertive" aria-atomic="true">
  <div class="d-flex">
    <div class="toast-body">
      Copied!
    </div>
  </div>
</div>

---
Primary Category: cs.RO  
Categories: cs-RO, cs.RO  
Keyword Score: 3  
Keywords: Graph  
<a type="button" class="btn btn-outline-primary" href="http://arxiv.org/abs/2402.18934v1" target="_blank" >Paper Link</a>
<button type="button" class="btn btn-outline-primary download-pdf" url="https://arxiv.org/pdf/2402.18934v1.pdf" filename="2402.18934v1.pdf">Download PDF</button>

---


**ABSTRACT**  
LiDAR-based localization is valuable for applications like mining surveys and underground facility maintenance. However, existing methods can struggle when dealing with uninformative geometric structures in challenging scenarios. This paper presents RELEAD, a LiDAR-centric solution designed to address scan-matching degradation. Our method enables degeneracy-free point cloud registration by solving constrained ESIKF updates in the front end and incorporates multisensor constraints, even when dealing with outlier measurements, through <b>graph</b> optimization based on Graduated Non-Convexity (GNC). Additionally, we propose a robust Incremental Fixed Lag Smoother (rIFL) for efficient GNC-based optimization. RELEAD has undergone extensive evaluation in degenerate scenarios and has outperformed existing state-of-the-art LiDAR-Inertial odometry and LiDAR-Visual-Inertial odometry methods.

{{</citation>}}


## eess.SY (5)



### (1/5 | 258/321) Closed-loop training of static output feedback neural network controllers for large systems: A distillation case study (E. M. Turan et al., 2024)

{{<citation>}}

E. M. Turan, J. Jäschke. (2024)  
**Closed-loop training of static output feedback neural network controllers for large systems: A distillation case study**
<br/>
<button class="copy-to-clipboard" title="Closed-loop training of static output feedback neural network controllers for large systems: A distillation case study" index=258>
  <span class="copy-to-clipboard-item">Copy Title<span>
</button>
<div class="toast toast-copied toast-index-258 align-items-center text-bg-secondary border-0 position-absolute top-0 end-0" role="alert" aria-live="assertive" aria-atomic="true">
  <div class="d-flex">
    <div class="toast-body">
      Copied!
    </div>
  </div>
</div>

---
Primary Category: eess.SY  
Categories: cs-SY, eess-SY, eess.SY, math-OC  
Keyword Score: 40  
Keywords: Heuristic Approach, Knowledge Distillation, Simulation, Simulator  
<a type="button" class="btn btn-outline-primary" href="http://arxiv.org/abs/2402.19309v1" target="_blank" >Paper Link</a>
<button type="button" class="btn btn-outline-primary download-pdf" url="https://arxiv.org/pdf/2402.19309v1.pdf" filename="2402.19309v1.pdf">Download PDF</button>

---


**ABSTRACT**  
The online implementation of model predictive control for constrained multivariate systems has two main disadvantages: it requires an estimate of the entire model state and an optimisation problem must be solved online. These issues have typically been treated separately. This work proposes an integrated approach for the offline training of an output feedback neural network controller in closed loop. Online this neural network controller computers the plant inputs cheaply using noisy measurements. In addition, the controller can be trained to only make use of certain predefined measurements. Further, a <b>heuristic</b> <b>approach</b> is proposed to perform the automatic selection of important measurements. The proposed method is demonstrated by extensive <b>simulations</b> using a non-linear <b>distillation</b> column model of 50 states.

{{</citation>}}


### (2/5 | 259/321) Temporal-Aware Deep Reinforcement Learning for Energy Storage Bidding in Energy and Contingency Reserve Markets (Jinhao Li et al., 2024)

{{<citation>}}

Jinhao Li, Changlong Wang, Yanru Zhang, Hao Wang. (2024)  
**Temporal-Aware Deep Reinforcement Learning for Energy Storage Bidding in Energy and Contingency Reserve Markets**
<br/>
<button class="copy-to-clipboard" title="Temporal-Aware Deep Reinforcement Learning for Energy Storage Bidding in Energy and Contingency Reserve Markets" index=259>
  <span class="copy-to-clipboard-item">Copy Title<span>
</button>
<div class="toast toast-copied toast-index-259 align-items-center text-bg-secondary border-0 position-absolute top-0 end-0" role="alert" aria-live="assertive" aria-atomic="true">
  <div class="d-flex">
    <div class="toast-body">
      Copied!
    </div>
  </div>
</div>

---
Primary Category: eess.SY  
Categories: cs-LG, cs-SY, eess-SY, eess.SY, math-OC  
Keyword Score: 28  
Keywords: Benchmarking, Black Box, Reinforcement Learning, Transformer  
<a type="button" class="btn btn-outline-primary" href="http://arxiv.org/abs/2402.19110v1" target="_blank" >Paper Link</a>
<button type="button" class="btn btn-outline-primary download-pdf" url="https://arxiv.org/pdf/2402.19110v1.pdf" filename="2402.19110v1.pdf">Download PDF</button>

---


**ABSTRACT**  
The battery energy storage system (BESS) has immense potential for enhancing grid reliability and security through its participation in the electricity market. BESS often seeks various revenue streams by taking part in multiple markets to unlock its full potential, but effective algorithms for joint-market participation under price uncertainties are insufficiently explored in the existing research. To bridge this gap, we develop a novel BESS joint bidding strategy that utilizes deep <b>reinforcement</b> <b>learning</b> (DRL) to bid in the spot and contingency frequency control ancillary services (FCAS) markets. Our approach leverages a <b>transformer-based</b> temporal feature extractor to effectively respond to price fluctuations in seven markets simultaneously and helps DRL learn the best BESS bidding strategy in joint-market participation. Additionally, unlike conventional <b>"black-box"</b> <b>DRL</b> model, our approach is more interpretable and provides valuable insights into the temporal bidding behavior of BESS in the dynamic electricity market. We validate our method using realistic market prices from the Australian National Electricity Market. The results show that our strategy outperforms <b>benchmarks,</b> including both optimization-based and other DRL-based strategies, by substantial margins. Our findings further suggest that effective temporal-aware bidding can significantly increase profits in the spot and contingency FCAS markets compared to individual market participation.

{{</citation>}}


### (3/5 | 260/321) Ultraviolet Positioning via TDOA: Error Analysis and System Prototype (Shihui Yu et al., 2024)

{{<citation>}}

Shihui Yu, Chubing Lv, Yueke Yang, Yuchen Pan, Lei Sun, Yubo Zhang, Juliang Cao, Ruihang Yu, Chen Gong, Wenqi Wu, Zhengyuan Xu. (2024)  
**Ultraviolet Positioning via TDOA: Error Analysis and System Prototype**
<br/>
<button class="copy-to-clipboard" title="Ultraviolet Positioning via TDOA: Error Analysis and System Prototype" index=260>
  <span class="copy-to-clipboard-item">Copy Title<span>
</button>
<div class="toast toast-copied toast-index-260 align-items-center text-bg-secondary border-0 position-absolute top-0 end-0" role="alert" aria-live="assertive" aria-atomic="true">
  <div class="d-flex">
    <div class="toast-body">
      Copied!
    </div>
  </div>
</div>

---
Primary Category: eess.SY  
Categories: cs-SY, eess-SY, eess.SY  
Keyword Score: 20  
Keywords: Simulation, Simulator  
<a type="button" class="btn btn-outline-primary" href="http://arxiv.org/abs/2402.19013v1" target="_blank" >Paper Link</a>
<button type="button" class="btn btn-outline-primary download-pdf" url="https://arxiv.org/pdf/2402.19013v1.pdf" filename="2402.19013v1.pdf">Download PDF</button>

---


**ABSTRACT**  
This work performs the design, real-time hardware realization, and experimental evaluation of a positioning system by ultra-violet (UV) communication under photon-level signal detection. The positioning is based on time-difference of arrival (TDOA) principle. Time division-based transmission of synchronization sequence from three transmitters with known positions is applied. We investigate the positioning error via decomposing it into two parts, the transmitter-side timing error and the receiver-side synchronization error. The theoretical average error matches well with the <b>simulation</b> results, which indicates that theoretical fitting can provide reliable guidance and prediction for hardware experiments. We also conduct real-time hardware realization of the TDOA-based positioning system using Field Programmable Gate Array (FPGA), which is experimentally evaluated via outdoor experiments. Experimental results match well with the theoretical and <b>simulation</b> results.

{{</citation>}}


### (4/5 | 261/321) Go Beyond Black-box Policies: Rethinking the Design of Learning Agent for Interpretable and Verifiable HVAC Control (Zhiyu An et al., 2024)

{{<citation>}}

Zhiyu An, Xianzhong Ding, Wan Du. (2024)  
**Go Beyond Black-box Policies: Rethinking the Design of Learning Agent for Interpretable and Verifiable HVAC Control**
<br/>
<button class="copy-to-clipboard" title="Go Beyond Black-box Policies: Rethinking the Design of Learning Agent for Interpretable and Verifiable HVAC Control" index=261>
  <span class="copy-to-clipboard-item">Copy Title<span>
</button>
<div class="toast toast-copied toast-index-261 align-items-center text-bg-secondary border-0 position-absolute top-0 end-0" role="alert" aria-live="assertive" aria-atomic="true">
  <div class="d-flex">
    <div class="toast-body">
      Copied!
    </div>
  </div>
</div>

---
Primary Category: eess.SY  
Categories: cs-AI, cs-LG, cs-SY, eess-SY, eess.SY  
Keyword Score: 15  
Keywords: Black Box, Reinforcement Learning  
<a type="button" class="btn btn-outline-primary" href="http://arxiv.org/abs/2403.00172v1" target="_blank" >Paper Link</a>
<button type="button" class="btn btn-outline-primary download-pdf" url="https://arxiv.org/pdf/2403.00172v1.pdf" filename="2403.00172v1.pdf">Download PDF</button>

---


**ABSTRACT**  
Recent research has shown the potential of Model-based <b>Reinforcement</b> <b>Learning</b> (MBRL) to enhance energy efficiency of Heating, Ventilation, and Air Conditioning (HVAC) systems. However, existing methods rely on <b>black-box</b> <b>thermal</b> dynamics models and stochastic optimizers, lacking reliability guarantees and posing risks to occupant health. In this work, we overcome the reliability bottleneck by redesigning HVAC controllers using decision trees extracted from existing thermal dynamics models and historical data. Our decision tree-based policies are deterministic, verifiable, interpretable, and more energy-efficient than current MBRL methods. First, we introduce a novel verification criterion for RL agents in HVAC control based on domain knowledge. Second, we develop a policy extraction procedure that produces a verifiable decision tree policy. We found that the high dimensionality of the thermal dynamics model input hinders the efficiency of policy extraction. To tackle the dimensionality challenge, we leverage importance sampling conditioned on historical data distributions, significantly improving policy extraction efficiency. Lastly, we present an offline verification algorithm that guarantees the reliability of a control policy. Extensive experiments show that our method saves 68.4% more energy and increases human comfort gain by 14.8% compared to the state-of-the-art method, in addition to an 1127x reduction in computation overhead. Our code and data are available at https://github.com/ryeii/Veri_HVAC

{{</citation>}}


### (5/5 | 262/321) Adaptive Testing Environment Generation for Connected and Automated Vehicles with Dense Reinforcement Learning (Jingxuan Yang et al., 2024)

{{<citation>}}

Jingxuan Yang, Ruoxuan Bai, Haoyuan Ji, Yi Zhang, Jianming Hu, Shuo Feng. (2024)  
**Adaptive Testing Environment Generation for Connected and Automated Vehicles with Dense Reinforcement Learning**
<br/>
<button class="copy-to-clipboard" title="Adaptive Testing Environment Generation for Connected and Automated Vehicles with Dense Reinforcement Learning" index=262>
  <span class="copy-to-clipboard-item">Copy Title<span>
</button>
<div class="toast toast-copied toast-index-262 align-items-center text-bg-secondary border-0 position-absolute top-0 end-0" role="alert" aria-live="assertive" aria-atomic="true">
  <div class="d-flex">
    <div class="toast-body">
      Copied!
    </div>
  </div>
</div>

---
Primary Category: eess.SY  
Categories: cs-LG, cs-SY, eess-SY, eess.SY  
Keyword Score: 10  
Keywords: Reinforcement Learning  
<a type="button" class="btn btn-outline-primary" href="http://arxiv.org/abs/2402.19275v1" target="_blank" >Paper Link</a>
<button type="button" class="btn btn-outline-primary download-pdf" url="https://arxiv.org/pdf/2402.19275v1.pdf" filename="2402.19275v1.pdf">Download PDF</button>

---


**ABSTRACT**  
The assessment of safety performance plays a pivotal role in the development and deployment of connected and automated vehicles (CAVs). A common approach involves designing testing scenarios based on prior knowledge of CAVs (e.g., surrogate models), conducting tests in these scenarios, and subsequently evaluating CAVs' safety performances. However, substantial differences between CAVs and the prior knowledge can significantly diminish the evaluation efficiency. In response to this issue, existing studies predominantly concentrate on the adaptive design of testing scenarios during the CAV testing process. Yet, these methods have limitations in their applicability to high-dimensional scenarios. To overcome this challenge, we develop an adaptive testing environment that bolsters evaluation robustness by incorporating multiple surrogate models and optimizing the combination coefficients of these surrogate models to enhance evaluation efficiency. We formulate the optimization problem as a regression task utilizing quadratic programming. To efficiently obtain the regression target via <b>reinforcement</b> <b>learning,</b> we propose the dense <b>reinforcement</b> <b>learning</b> method and devise a new adaptive policy with high sample efficiency. Essentially, our approach centers on learning the values of critical scenes displaying substantial surrogate-to-real gaps. The effectiveness of our method is validated in high-dimensional overtaking scenarios, demonstrating that our approach achieves notable evaluation efficiency.

{{</citation>}}


## eess.IV (12)



### (1/12 | 263/321) Unsupervised Learning of High-resolution Light Field Imaging via Beam Splitter-based Hybrid Lenses (Jianxin Lei et al., 2024)

{{<citation>}}

Jianxin Lei, Chengcai Xu, Langqing Shi, Junhui Hou, Ping Zhou. (2024)  
**Unsupervised Learning of High-resolution Light Field Imaging via Beam Splitter-based Hybrid Lenses**
<br/>
<button class="copy-to-clipboard" title="Unsupervised Learning of High-resolution Light Field Imaging via Beam Splitter-based Hybrid Lenses" index=263>
  <span class="copy-to-clipboard-item">Copy Title<span>
</button>
<div class="toast toast-copied toast-index-263 align-items-center text-bg-secondary border-0 position-absolute top-0 end-0" role="alert" aria-live="assertive" aria-atomic="true">
  <div class="d-flex">
    <div class="toast-body">
      Copied!
    </div>
  </div>
</div>

---
Primary Category: eess.IV  
Categories: cs-CV, eess-IV, eess.IV  
Keyword Score: 40  
Keywords: Supervised Learning, Supervised Learning, Unsupervised Learning, Unsupervised Learning  
<a type="button" class="btn btn-outline-primary" href="http://arxiv.org/abs/2402.19020v1" target="_blank" >Paper Link</a>
<button type="button" class="btn btn-outline-primary download-pdf" url="https://arxiv.org/pdf/2402.19020v1.pdf" filename="2402.19020v1.pdf">Download PDF</button>

---


**ABSTRACT**  
In this paper, we design a beam splitter-based hybrid light field imaging prototype to record 4D light field image and high-resolution 2D image simultaneously, and make a hybrid light field dataset. The 2D image could be considered as the high-resolution ground truth corresponding to the low-resolution central sub-aperture image of 4D light field image. Subsequently, we propose an <b>unsupervised</b> <b>learning-based</b> super-resolution framework with the hybrid light field dataset, which adaptively settles the light field spatial super-resolution problem with a complex degradation model. Specifically, we design two loss functions based on pre-trained models that enable the super-resolution network to learn the detailed features and light field parallax structure with only one ground truth. Extensive experiments demonstrate the same superiority of our approach with <b>supervised</b> <b>learning-based</b> state-of-the-art ones. To our knowledge, it is the first end-to-end <b>unsupervised</b> <b>learning-based</b> spatial super-resolution approach in light field imaging research, whose input is available from our beam splitter-based hybrid light field system. The hardware and software together may help promote the application of light field super-resolution to a great extent.

{{</citation>}}


### (2/12 | 264/321) Graph Convolutional Neural Networks for Automated Echocardiography View Recognition: A Holistic Approach (Sarina Thomas et al., 2024)

{{<citation>}}

Sarina Thomas, Cristiana Tiago, Børge Solli Andreassen, Svein Arne Aase, Jurica Šprem, Erik Steen, Anne Solberg, Guy Ben-Yosef. (2024)  
**Graph Convolutional Neural Networks for Automated Echocardiography View Recognition: A Holistic Approach**
<br/>
<button class="copy-to-clipboard" title="Graph Convolutional Neural Networks for Automated Echocardiography View Recognition: A Holistic Approach" index=264>
  <span class="copy-to-clipboard-item">Copy Title<span>
</button>
<div class="toast toast-copied toast-index-264 align-items-center text-bg-secondary border-0 position-absolute top-0 end-0" role="alert" aria-live="assertive" aria-atomic="true">
  <div class="d-flex">
    <div class="toast-body">
      Copied!
    </div>
  </div>
</div>

---
Primary Category: eess.IV  
Categories: cs-CV, cs-LG, eess-IV, eess.IV  
Keyword Score: 33  
Keywords: Diffusion Model, Graph, Convolution, Convolutional Neural Network  
<a type="button" class="btn btn-outline-primary" href="http://arxiv.org/abs/2402.19062v2" target="_blank" >Paper Link</a>
<button type="button" class="btn btn-outline-primary download-pdf" url="https://arxiv.org/pdf/2402.19062v2.pdf" filename="2402.19062v2.pdf">Download PDF</button>

---


**ABSTRACT**  
To facilitate diagnosis on cardiac ultrasound (US), clinical practice has established several standard views of the heart, which serve as reference points for diagnostic measurements and define viewports from which images are acquired. Automatic view recognition involves grouping those images into classes of standard views. Although deep learning techniques have been successful in achieving this, they still struggle with fully verifying the suitability of an image for specific measurements due to factors like the correct location, pose, and potential occlusions of cardiac structures. Our approach goes beyond view classification and incorporates a 3D mesh reconstruction of the heart that enables several more downstream tasks, like segmentation and pose estimation. In this work, we explore learning 3D heart meshes via <b>graph</b> <b>convolutions,</b> using similar techniques to learn 3D meshes in natural images, such as human pose estimation. As the availability of fully annotated 3D images is limited, we generate synthetic US images from 3D meshes by training an adversarial denoising <b>diffusion</b> <b>model.</b> Experiments were conducted on synthetic and clinical cases for view recognition and structure detection. The approach yielded good performance on synthetic images and, despite being exclusively trained on synthetic data, it already showed potential when applied to clinical images. With this proof-of-concept, we aim to demonstrate the benefits of <b>graphs</b> to improve cardiac view recognition that can ultimately lead to better efficiency in cardiac diagnosis.

{{</citation>}}


### (3/12 | 265/321) SeD: Semantic-Aware Discriminator for Image Super-Resolution (Bingchen Li et al., 2024)

{{<citation>}}

Bingchen Li, Xin Li, Hanxin Zhu, Yeying Jin, Ruoyu Feng, Zhizheng Zhang, Zhibo Chen. (2024)  
**SeD: Semantic-Aware Discriminator for Image Super-Resolution**
<br/>
<button class="copy-to-clipboard" title="SeD: Semantic-Aware Discriminator for Image Super-Resolution" index=265>
  <span class="copy-to-clipboard-item">Copy Title<span>
</button>
<div class="toast toast-copied toast-index-265 align-items-center text-bg-secondary border-0 position-absolute top-0 end-0" role="alert" aria-live="assertive" aria-atomic="true">
  <div class="d-flex">
    <div class="toast-body">
      Copied!
    </div>
  </div>
</div>

---
Primary Category: eess.IV  
Categories: cs-CV, eess-IV, eess.IV  
Keyword Score: 30  
Keywords: Adversarial Learning, Generative Adversarial Network, Generative Adversarial Network  
<a type="button" class="btn btn-outline-primary" href="http://arxiv.org/abs/2402.19387v1" target="_blank" >Paper Link</a>
<button type="button" class="btn btn-outline-primary download-pdf" url="https://arxiv.org/pdf/2402.19387v1.pdf" filename="2402.19387v1.pdf">Download PDF</button>

---


**ABSTRACT**  
<b>Generative</b> <b>Adversarial</b> <b>Networks</b> <b>(GANs)</b> have been widely used to recover vivid textures in image super-resolution (SR) tasks. In particular, one discriminator is utilized to enable the SR network to learn the distribution of real-world high-quality images in an <b>adversarial</b> <b>training</b> manner. However, the distribution learning is overly coarse-grained, which is susceptible to virtual textures and causes counter-intuitive generation results. To mitigate this, we propose the simple and effective Semantic-aware Discriminator (denoted as SeD), which encourages the SR network to learn the fine-grained distributions by introducing the semantics of images as a condition. Concretely, we aim to excavate the semantics of images from a well-trained semantic extractor. Under different semantics, the discriminator is able to distinguish the real-fake images individually and adaptively, which guides the SR network to learn the more fine-grained semantic-aware textures. To obtain accurate and abundant semantics, we take full advantage of recently popular pretrained vision models (PVMs) with extensive datasets, and then incorporate its semantic features into the discriminator through a well-designed spatial cross-attention module. In this way, our proposed semantic-aware discriminator empowered the SR network to produce more photo-realistic and pleasing images. Extensive experiments on two typical tasks, i.e., SR and Real SR have demonstrated the effectiveness of our proposed methods.

{{</citation>}}


### (4/12 | 266/321) GDCNet: Calibrationless geometric distortion correction of echo planar imaging data using deep learning (Marina Manso Jimeno et al., 2024)

{{<citation>}}

Marina Manso Jimeno, Keren Bachi, George Gardner, Yasmin L. Hurd, John Thomas Vaughan Jr., Sairam Geethanath. (2024)  
**GDCNet: Calibrationless geometric distortion correction of echo planar imaging data using deep learning**
<br/>
<button class="copy-to-clipboard" title="GDCNet: Calibrationless geometric distortion correction of echo planar imaging data using deep learning" index=266>
  <span class="copy-to-clipboard-item">Copy Title<span>
</button>
<div class="toast toast-copied toast-index-266 align-items-center text-bg-secondary border-0 position-absolute top-0 end-0" role="alert" aria-live="assertive" aria-atomic="true">
  <div class="d-flex">
    <div class="toast-body">
      Copied!
    </div>
  </div>
</div>

---
Primary Category: eess.IV  
Categories: cs-CV, eess-IV, eess.IV  
Keyword Score: 23  
Keywords: Benchmarking, Mutual Information, Self-supervised Learning  
<a type="button" class="btn btn-outline-primary" href="http://arxiv.org/abs/2402.18777v1" target="_blank" >Paper Link</a>
<button type="button" class="btn btn-outline-primary download-pdf" url="https://arxiv.org/pdf/2402.18777v1.pdf" filename="2402.18777v1.pdf">Download PDF</button>

---


**ABSTRACT**  
Functional magnetic resonance imaging techniques benefit from echo-planar imaging's fast image acquisition but are susceptible to inhomogeneities in the main magnetic field, resulting in geometric distortion and signal loss artifacts in the images. Traditional methods leverage a field map or voxel displacement map for distortion correction. However, voxel displacement map estimation requires additional sequence acquisitions, and the accuracy of the estimation influences correction performance. This work implements a novel approach called GDCNet, which estimates a geometric distortion map by non-linear registration to T1-weighted anatomical images and applies it for distortion correction. GDCNet demonstrated fast distortion correction of functional images in retrospectively and prospectively acquired datasets. Among the compared models, the 2D <b>self-supervised</b> configuration resulted in a statistically significant improvement to normalized <b>mutual</b> <b>information</b> between distortion-corrected functional and T1-weighted images compared to the <b>benchmark</b> methods FUGUE and TOPUP. Furthermore, GDCNet models achieved processing speeds 14 times faster than TOPUP in the prospective dataset.

{{</citation>}}


### (5/12 | 267/321) Towards Generalizable Tumor Synthesis (Qi Chen et al., 2024)

{{<citation>}}

Qi Chen, Xiaoxi Chen, Haorui Song, Zhiwei Xiong, Alan Yuille, Chen Wei, Zongwei Zhou. (2024)  
**Towards Generalizable Tumor Synthesis**
<br/>
<button class="copy-to-clipboard" title="Towards Generalizable Tumor Synthesis" index=267>
  <span class="copy-to-clipboard-item">Copy Title<span>
</button>
<div class="toast toast-copied toast-index-267 align-items-center text-bg-secondary border-0 position-absolute top-0 end-0" role="alert" aria-live="assertive" aria-atomic="true">
  <div class="d-flex">
    <div class="toast-body">
      Copied!
    </div>
  </div>
</div>

---
Primary Category: eess.IV  
Categories: cs-CV, eess-IV, eess.IV  
Keyword Score: 20  
Keywords: Diffusion Model, Generative AI  
<a type="button" class="btn btn-outline-primary" href="http://arxiv.org/abs/2402.19470v1" target="_blank" >Paper Link</a>
<button type="button" class="btn btn-outline-primary download-pdf" url="https://arxiv.org/pdf/2402.19470v1.pdf" filename="2402.19470v1.pdf">Download PDF</button>

---


**ABSTRACT**  
Tumor synthesis enables the creation of artificial tumors in medical images, facilitating the training of AI models for tumor detection and segmentation. However, success in tumor synthesis hinges on creating visually realistic tumors that are generalizable across multiple organs and, furthermore, the resulting AI models being capable of detecting real tumors in images sourced from different domains (e.g., hospitals). This paper made a progressive stride toward generalizable tumor synthesis by leveraging a critical observation: early-stage tumors (< 2cm) tend to have similar imaging characteristics in computed tomography (CT), whether they originate in the liver, pancreas, or kidneys. We have ascertained that <b>generative</b> <b>AI</b> models, e.g., <b>Diffusion</b> <b>Models,</b> can create realistic tumors generalized to a range of organs even when trained on a limited number of tumor examples from only one organ. Moreover, we have shown that AI models trained on these synthetic tumors can be generalized to detect and segment real tumors from CT volumes, encompassing a broad spectrum of patient demographics, imaging protocols, and healthcare facilities.

{{</citation>}}


### (6/12 | 268/321) WDM: 3D Wavelet Diffusion Models for High-Resolution Medical Image Synthesis (Paul Friedrich et al., 2024)

{{<citation>}}

Paul Friedrich, Julia Wolleb, Florentin Bieder, Alicia Durrer, Philippe C. Cattin. (2024)  
**WDM: 3D Wavelet Diffusion Models for High-Resolution Medical Image Synthesis**
<br/>
<button class="copy-to-clipboard" title="WDM: 3D Wavelet Diffusion Models for High-Resolution Medical Image Synthesis" index=268>
  <span class="copy-to-clipboard-item">Copy Title<span>
</button>
<div class="toast toast-copied toast-index-268 align-items-center text-bg-secondary border-0 position-absolute top-0 end-0" role="alert" aria-live="assertive" aria-atomic="true">
  <div class="d-flex">
    <div class="toast-body">
      Copied!
    </div>
  </div>
</div>

---
Primary Category: eess.IV  
Categories: cs-CV, eess-IV, eess.IV  
Keyword Score: 20  
Keywords: Diffusion Model, Generative Adversarial Network  
<a type="button" class="btn btn-outline-primary" href="http://arxiv.org/abs/2402.19043v1" target="_blank" >Paper Link</a>
<button type="button" class="btn btn-outline-primary download-pdf" url="https://arxiv.org/pdf/2402.19043v1.pdf" filename="2402.19043v1.pdf">Download PDF</button>

---


**ABSTRACT**  
Due to the three-dimensional nature of CT- or MR-scans, generative modeling of medical images is a particularly challenging task. Existing approaches mostly apply patch-wise, slice-wise, or cascaded generation techniques to fit the high-dimensional data into the limited GPU memory. However, these approaches may introduce artifacts and potentially restrict the model's applicability for certain downstream tasks. This work presents WDM, a wavelet-based medical image synthesis framework that applies a <b>diffusion</b> <b>model</b> on wavelet decomposed images. The presented approach is a simple yet effective way of scaling <b>diffusion</b> <b>models</b> to high resolutions and can be trained on a single 40 GB GPU. Experimental results on BraTS and LIDC-IDRI unconditional image generation at a resolution of $128 \times 128 \times 128$ show state-of-the-art image fidelity (FID) and sample diversity (MS-SSIM) scores compared to <b>GANs,</b> <b>Diffusion</b> <b>Models,</b> and Latent <b>Diffusion</b> <b>Models.</b> Our proposed method is the only one capable of generating high-quality images at a resolution of $256 \times 256 \times 256$.

{{</citation>}}


### (7/12 | 269/321) CAMixerSR: Only Details Need More 'Attention' (Yan Wang et al., 2024)

{{<citation>}}

Yan Wang, Shijie Zhao, Yi Liu, Junlin Li, Li Zhang. (2024)  
**CAMixerSR: Only Details Need More 'Attention'**
<br/>
<button class="copy-to-clipboard" title="CAMixerSR: Only Details Need More 'Attention'" index=269>
  <span class="copy-to-clipboard-item">Copy Title<span>
</button>
<div class="toast toast-copied toast-index-269 align-items-center text-bg-secondary border-0 position-absolute top-0 end-0" role="alert" aria-live="assertive" aria-atomic="true">
  <div class="d-flex">
    <div class="toast-body">
      Copied!
    </div>
  </div>
</div>

---
Primary Category: eess.IV  
Categories: cs-CV, eess-IV, eess.IV  
Keyword Score: 10  
Keywords: Convolution  
<a type="button" class="btn btn-outline-primary" href="http://arxiv.org/abs/2402.19289v1" target="_blank" >Paper Link</a>
<button type="button" class="btn btn-outline-primary download-pdf" url="https://arxiv.org/pdf/2402.19289v1.pdf" filename="2402.19289v1.pdf">Download PDF</button>

---


**ABSTRACT**  
To satisfy the rapidly increasing demands on the large image (2K-8K) super-resolution (SR), prevailing methods follow two independent tracks: 1) accelerate existing networks by content-aware routing, and 2) design better super-resolution networks via token mixer refining. Despite directness, they encounter unavoidable defects (e.g., inflexible route or non-discriminative processing) limiting further improvements of quality-complexity trade-off. To erase the drawbacks, we integrate these schemes by proposing a content-aware mixer (CAMixer), which assigns <b>convolution</b> for simple contexts and additional deformable window-attention for sparse textures. Specifically, the CAMixer uses a learnable predictor to generate multiple bootstraps, including offsets for windows warping, a mask for classifying windows, and <b>convolutional</b> attentions for endowing <b>convolution</b> with the dynamic property, which modulates attention to include more useful textures self-adaptively and improves the representation capability of <b>convolution.</b> We further introduce a global classification loss to improve the accuracy of predictors. By simply stacking CAMixers, we obtain CAMixerSR which achieves superior performance on large-image SR, lightweight SR, and omnidirectional-image SR.

{{</citation>}}


### (8/12 | 270/321) Training Generative Image Super-Resolution Models by Wavelet-Domain Losses Enables Better Control of Artifacts (Cansu Korkmaz et al., 2024)

{{<citation>}}

Cansu Korkmaz, A. Murat Tekalp, Zafer Dogan. (2024)  
**Training Generative Image Super-Resolution Models by Wavelet-Domain Losses Enables Better Control of Artifacts**
<br/>
<button class="copy-to-clipboard" title="Training Generative Image Super-Resolution Models by Wavelet-Domain Losses Enables Better Control of Artifacts" index=270>
  <span class="copy-to-clipboard-item">Copy Title<span>
</button>
<div class="toast toast-copied toast-index-270 align-items-center text-bg-secondary border-0 position-absolute top-0 end-0" role="alert" aria-live="assertive" aria-atomic="true">
  <div class="d-flex">
    <div class="toast-body">
      Copied!
    </div>
  </div>
</div>

---
Primary Category: eess.IV  
Categories: cs-CV, eess-IV, eess.IV  
Keyword Score: 10  
Keywords: Generative Adversarial Network  
<a type="button" class="btn btn-outline-primary" href="http://arxiv.org/abs/2402.19215v1" target="_blank" >Paper Link</a>
<button type="button" class="btn btn-outline-primary download-pdf" url="https://arxiv.org/pdf/2402.19215v1.pdf" filename="2402.19215v1.pdf">Download PDF</button>

---


**ABSTRACT**  
Super-resolution (SR) is an ill-posed inverse problem, where the size of the set of feasible solutions that are consistent with a given low-resolution image is very large. Many algorithms have been proposed to find a "good" solution among the feasible solutions that strike a balance between fidelity and perceptual quality. Unfortunately, all known methods generate artifacts and hallucinations while trying to reconstruct high-frequency (HF) image details. A fundamental question is: Can a model learn to distinguish genuine image details from artifacts? Although some recent works focused on the differentiation of details and artifacts, this is a very challenging problem and a satisfactory solution is yet to be found. This paper shows that the characterization of genuine HF details versus artifacts can be better learned by training <b>GAN-based</b> SR models using wavelet-domain loss functions compared to RGB-domain or Fourier-space losses. Although wavelet-domain losses have been used in the literature before, they have not been used in the context of the SR task. More specifically, we train the discriminator only on the HF wavelet sub-bands instead of on RGB images and the generator is trained by a fidelity loss over wavelet subbands to make it sensitive to the scale and orientation of structures. Extensive experimental results demonstrate that our model achieves better perception-distortion trade-off according to multiple objective measures and visual evaluations.

{{</citation>}}


### (9/12 | 271/321) Deep Network for Image Compressed Sensing Coding Using Local Structural Sampling (Wenxue Cui et al., 2024)

{{<citation>}}

Wenxue Cui, Xingtao Wang, Xiaopeng Fan, Shaohui Liu, Xinwei Gao, Debin Zhao. (2024)  
**Deep Network for Image Compressed Sensing Coding Using Local Structural Sampling**
<br/>
<button class="copy-to-clipboard" title="Deep Network for Image Compressed Sensing Coding Using Local Structural Sampling" index=271>
  <span class="copy-to-clipboard-item">Copy Title<span>
</button>
<div class="toast toast-copied toast-index-271 align-items-center text-bg-secondary border-0 position-absolute top-0 end-0" role="alert" aria-live="assertive" aria-atomic="true">
  <div class="d-flex">
    <div class="toast-body">
      Copied!
    </div>
  </div>
</div>

---
Primary Category: eess.IV  
Categories: cs-CV, eess-IV, eess.IV  
Keyword Score: 10  
Keywords: Convolutional Neural Network  
<a type="button" class="btn btn-outline-primary" href="http://arxiv.org/abs/2402.19111v1" target="_blank" >Paper Link</a>
<button type="button" class="btn btn-outline-primary download-pdf" url="https://arxiv.org/pdf/2402.19111v1.pdf" filename="2402.19111v1.pdf">Download PDF</button>

---


**ABSTRACT**  
Existing image compressed sensing (CS) coding frameworks usually solve an inverse problem based on measurement coding and optimization-based image reconstruction, which still exist the following two challenges: 1) The widely used random sampling matrix, such as the Gaussian Random Matrix (GRM), usually leads to low measurement coding efficiency. 2) The optimization-based reconstruction methods generally maintain a much higher computational complexity. In this paper, we propose a new <b>CNN</b> based image CS coding framework using local structural sampling (dubbed CSCNet) that includes three functional modules: local structural sampling, measurement coding and Laplacian pyramid reconstruction. In the proposed framework, instead of GRM, a new local structural sampling matrix is first developed, which is able to enhance the correlation between the measurements through a local perceptual sampling strategy. Besides, the designed local structural sampling matrix can be jointly optimized with the other functional modules during training process. After sampling, the measurements with high correlations are produced, which are then coded into final bitstreams by the third-party image codec. At last, a Laplacian pyramid reconstruction network is proposed to efficiently recover the target image from the measurement domain to the image domain. Extensive experimental results demonstrate that the proposed scheme outperforms the existing state-of-the-art CS coding methods, while maintaining fast computational speed.

{{</citation>}}


### (10/12 | 272/321) Variable-Rate Learned Image Compression with Multi-Objective Optimization and Quantization-Reconstruction Offsets (Fatih Kamisli et al., 2024)

{{<citation>}}

Fatih Kamisli, Fabien Racape, Hyomin Choi. (2024)  
**Variable-Rate Learned Image Compression with Multi-Objective Optimization and Quantization-Reconstruction Offsets**
<br/>
<button class="copy-to-clipboard" title="Variable-Rate Learned Image Compression with Multi-Objective Optimization and Quantization-Reconstruction Offsets" index=272>
  <span class="copy-to-clipboard-item">Copy Title<span>
</button>
<div class="toast toast-copied toast-index-272 align-items-center text-bg-secondary border-0 position-absolute top-0 end-0" role="alert" aria-live="assertive" aria-atomic="true">
  <div class="d-flex">
    <div class="toast-body">
      Copied!
    </div>
  </div>
</div>

---
Primary Category: eess.IV  
Categories: cs-CV, eess-IV, eess.IV  
Keyword Score: 10  
Keywords: Quantization  
<a type="button" class="btn btn-outline-primary" href="http://arxiv.org/abs/2402.18930v1" target="_blank" >Paper Link</a>
<button type="button" class="btn btn-outline-primary download-pdf" url="https://arxiv.org/pdf/2402.18930v1.pdf" filename="2402.18930v1.pdf">Download PDF</button>

---


**ABSTRACT**  
Achieving successful variable bitrate compression with computationally simple algorithms from a single end-to-end learned image or video compression model remains a challenge. Many approaches have been proposed, including conditional auto-encoders, channel-adaptive gains for the latent tensor or uniformly quantizing all elements of the latent tensor. This paper follows the traditional approach to vary a single <b>quantization</b> step size to perform uniform <b>quantization</b> of all latent tensor elements. However, three modifications are proposed to improve the variable rate compression performance. First, multi objective optimization is used for (post) training. Second, a <b>quantization-reconstruction</b> offset is introduced into the <b>quantization</b> operation. Third, variable rate <b>quantization</b> is used also for the hyper latent. All these modifications can be made on a pre-trained single-rate compression model by performing post training. The algorithms are implemented into three well-known image compression models and the achieved variable rate compression results indicate negligible or minimal compression performance loss compared to training multiple models. (Codes will be shared at https://github.com/InterDigitalInc/CompressAI)

{{</citation>}}


### (11/12 | 273/321) LoLiSRFlow: Joint Single Image Low-light Enhancement and Super-resolution via Cross-scale Transformer-based Conditional Flow (Ziyu Yue et al., 2024)

{{<citation>}}

Ziyu Yue, Jiaxin Gao, Sihan Xie, Yang Liu, Zhixun Su. (2024)  
**LoLiSRFlow: Joint Single Image Low-light Enhancement and Super-resolution via Cross-scale Transformer-based Conditional Flow**
<br/>
<button class="copy-to-clipboard" title="LoLiSRFlow: Joint Single Image Low-light Enhancement and Super-resolution via Cross-scale Transformer-based Conditional Flow" index=273>
  <span class="copy-to-clipboard-item">Copy Title<span>
</button>
<div class="toast toast-copied toast-index-273 align-items-center text-bg-secondary border-0 position-absolute top-0 end-0" role="alert" aria-live="assertive" aria-atomic="true">
  <div class="d-flex">
    <div class="toast-body">
      Copied!
    </div>
  </div>
</div>

---
Primary Category: eess.IV  
Categories: cs-CV, eess-IV, eess.IV  
Keyword Score: 10  
Keywords: Transformer  
<a type="button" class="btn btn-outline-primary" href="http://arxiv.org/abs/2402.18871v1" target="_blank" >Paper Link</a>
<button type="button" class="btn btn-outline-primary download-pdf" url="https://arxiv.org/pdf/2402.18871v1.pdf" filename="2402.18871v1.pdf">Download PDF</button>

---


**ABSTRACT**  
The visibility of real-world images is often limited by both low-light and low-resolution, however, these issues are only addressed in the literature through Low-Light Enhancement (LLE) and Super- Resolution (SR) methods. Admittedly, a simple cascade of these approaches cannot work harmoniously to cope well with the highly ill-posed problem for simultaneously enhancing visibility and resolution. In this paper, we propose a normalizing flow network, dubbed LoLiSRFLow, specifically designed to consider the degradation mechanism inherent in joint LLE and SR. To break the bonds of the one-to-many mapping for low-light low-resolution images to normal-light high-resolution images, LoLiSRFLow directly learns the conditional probability distribution over a variety of feasible solutions for high-resolution well-exposed images. Specifically, a multi-resolution parallel <b>transformer</b> acts as a conditional encoder that extracts the Retinex-induced resolution-and-illumination invariant map as the previous one. And the invertible network maps the distribution of usually exposed high-resolution images to a latent distribution. The backward inference is equivalent to introducing an additional constrained loss for the normal training route, thus enabling the manifold of the natural exposure of the high-resolution image to be immaculately depicted. We also propose a synthetic dataset modeling the realistic low-light low-resolution degradation, named DFSR-LLE, containing 7100 low-resolution dark-light/high-resolution normal sharp pairs. Quantitative and qualitative experimental results demonstrate the effectiveness of our method on both the proposed synthetic and real datasets.

{{</citation>}}


### (12/12 | 274/321) Anatomy-guided fiber trajectory distribution estimation for cranial nerves tractography (Lei Xie et al., 2024)

{{<citation>}}

Lei Xie, Qingrun Zeng, Huajun Zhou, Guoqiang Xie, Mingchu Li, Jiahao Huang, Jianan Cui, Hao Chen, Yuanjing Feng. (2024)  
**Anatomy-guided fiber trajectory distribution estimation for cranial nerves tractography**
<br/>
<button class="copy-to-clipboard" title="Anatomy-guided fiber trajectory distribution estimation for cranial nerves tractography" index=274>
  <span class="copy-to-clipboard-item">Copy Title<span>
</button>
<div class="toast toast-copied toast-index-274 align-items-center text-bg-secondary border-0 position-absolute top-0 end-0" role="alert" aria-live="assertive" aria-atomic="true">
  <div class="d-flex">
    <div class="toast-body">
      Copied!
    </div>
  </div>
</div>

---
Primary Category: eess.IV  
Categories: cs-CV, eess-IV, eess.IV  
Keyword Score: 5  
Keywords: Geometry  
<a type="button" class="btn btn-outline-primary" href="http://arxiv.org/abs/2402.18856v1" target="_blank" >Paper Link</a>
<button type="button" class="btn btn-outline-primary download-pdf" url="https://arxiv.org/pdf/2402.18856v1.pdf" filename="2402.18856v1.pdf">Download PDF</button>

---


**ABSTRACT**  
Diffusion MRI tractography is an important tool for identifying and analyzing the intracranial course of cranial nerves (CNs). However, the complex environment of the skull base leads to ambiguous spatial correspondence between diffusion directions and fiber <b>geometry,</b> and existing diffusion tractography methods of CNs identification are prone to producing erroneous trajectories and missing true positive connections. To overcome the above challenge, we propose a novel CNs identification framework with anatomy-guided fiber trajectory distribution, which incorporates anatomical shape prior knowledge during the process of CNs tracing to build diffusion tensor vector fields. We introduce higher-order streamline differential equations for continuous flow field representations to directly characterize the fiber trajectory distribution of CNs from the tract-based level. The experimental results on the vivo HCP dataset and the clinical MDM dataset demonstrate that the proposed method reduces false-positive fiber production compared to competing methods and produces reconstructed CNs (i.e. CN II, CN III, CN V, and CN VII/VIII) that are judged to better correspond to the known anatomy.

{{</citation>}}


## cs.HC (8)



### (1/8 | 275/321) ARTiST: Automated Text Simplification for Task Guidance in Augmented Reality (Guande Wu et al., 2024)

{{<citation>}}

Guande Wu, Jing Qian, Sonia Castelo, Shaoyu Chen, Joao Rulff, Claudio Silva. (2024)  
**ARTiST: Automated Text Simplification for Task Guidance in Augmented Reality**
<br/>
<button class="copy-to-clipboard" title="ARTiST: Automated Text Simplification for Task Guidance in Augmented Reality" index=275>
  <span class="copy-to-clipboard-item">Copy Title<span>
</button>
<div class="toast toast-copied toast-index-275 align-items-center text-bg-secondary border-0 position-absolute top-0 end-0" role="alert" aria-live="assertive" aria-atomic="true">
  <div class="d-flex">
    <div class="toast-body">
      Copied!
    </div>
  </div>
</div>

---
Primary Category: cs.HC  
Categories: H-1-2; I-2-7, cs-CL, cs-HC, cs.HC  
Keyword Score: 40  
Keywords: Few-shot, GPT, GPT-3, Prompt  
<a type="button" class="btn btn-outline-primary" href="http://arxiv.org/abs/2402.18797v1" target="_blank" >Paper Link</a>
<button type="button" class="btn btn-outline-primary download-pdf" url="https://arxiv.org/pdf/2402.18797v1.pdf" filename="2402.18797v1.pdf">Download PDF</button>

---


**ABSTRACT**  
Text presented in augmented reality provides in-situ, real-time information for users. However, this content can be challenging to apprehend quickly when engaging in cognitively demanding AR tasks, especially when it is presented on a head-mounted display. We propose ARTiST, an automatic text simplification system that uses a <b>few-shot</b> <b>prompt</b> and <b>GPT-3</b> models to specifically optimize the text length and semantic content for augmented reality. Developed out of a formative study that included seven users and three experts, our system combines a customized error calibration model with a <b>few-shot</b> <b>prompt</b> to integrate the syntactic, lexical, elaborative, and content simplification techniques, and generate simplified AR text for head-worn displays. Results from a 16-user empirical study showed that ARTiST lightens the cognitive load and improves performance significantly over both unmodified text and text modified via traditional methods. Our work constitutes a step towards automating the optimization of batch text data for readability and performance in augmented reality.

{{</citation>}}


### (2/8 | 276/321) Implications of Regulations on the Use of AI and Generative AI for Human-Centered Responsible Artificial Intelligence (Marios Constantinides et al., 2024)

{{<citation>}}

Marios Constantinides, Mohammad Tahaei, Daniele Quercia, Simone Stumpf, Michael Madaio, Sean Kennedy, Lauren Wilcox, Jessica Vitak, Henriette Cramer, Edyta Bogucka, Ricardo Baeza-Yates, Ewa Luger, Jess Holbrook, Michael Muller, Ilana Golbin Blumenfeld, Giada Pistilli. (2024)  
**Implications of Regulations on the Use of AI and Generative AI for Human-Centered Responsible Artificial Intelligence**
<br/>
<button class="copy-to-clipboard" title="Implications of Regulations on the Use of AI and Generative AI for Human-Centered Responsible Artificial Intelligence" index=276>
  <span class="copy-to-clipboard-item">Copy Title<span>
</button>
<div class="toast toast-copied toast-index-276 align-items-center text-bg-secondary border-0 position-absolute top-0 end-0" role="alert" aria-live="assertive" aria-atomic="true">
  <div class="d-flex">
    <div class="toast-body">
      Copied!
    </div>
  </div>
</div>

---
Primary Category: cs.HC  
Categories: cs-HC, cs.HC  
Keyword Score: 10  
Keywords: Generative AI  
<a type="button" class="btn btn-outline-primary" href="http://arxiv.org/abs/2403.00148v1" target="_blank" >Paper Link</a>
<button type="button" class="btn btn-outline-primary download-pdf" url="https://arxiv.org/pdf/2403.00148v1.pdf" filename="2403.00148v1.pdf">Download PDF</button>

---


**ABSTRACT**  
With the upcoming AI regulations (e.g., EU AI Act) and rapid advancements in <b>generative</b> <b>AI,</b> new challenges emerge in the area of Human-Centered Responsible Artificial Intelligence (HCR-AI). As AI becomes more ubiquitous, questions around decision-making authority, human oversight, accountability, sustainability, and the ethical and legal responsibilities of AI and their creators become paramount. Addressing these questions requires a collaborative approach. By involving stakeholders from various disciplines in the 2\textsuperscript{nd} edition of the HCR-AI Special Interest Group (SIG) at CHI 2024, we aim to discuss the implications of regulations in HCI research, develop new theories, evaluation frameworks, and methods to navigate the complex nature of AI ethics, steering AI development in a direction that is beneficial and sustainable for all of humanity.

{{</citation>}}


### (3/8 | 277/321) Guidelines for Integrating Value Sensitive Design in Responsible AI Toolkits (Malak Sadek et al., 2024)

{{<citation>}}

Malak Sadek, Marios Constantinides, Daniele Quercia, Céline Mougenot. (2024)  
**Guidelines for Integrating Value Sensitive Design in Responsible AI Toolkits**
<br/>
<button class="copy-to-clipboard" title="Guidelines for Integrating Value Sensitive Design in Responsible AI Toolkits" index=277>
  <span class="copy-to-clipboard-item">Copy Title<span>
</button>
<div class="toast toast-copied toast-index-277 align-items-center text-bg-secondary border-0 position-absolute top-0 end-0" role="alert" aria-live="assertive" aria-atomic="true">
  <div class="d-flex">
    <div class="toast-body">
      Copied!
    </div>
  </div>
</div>

---
Primary Category: cs.HC  
Categories: cs-HC, cs.HC  
Keyword Score: 10  
Keywords: Fairness  
<a type="button" class="btn btn-outline-primary" href="http://arxiv.org/abs/2403.00145v1" target="_blank" >Paper Link</a>
<button type="button" class="btn btn-outline-primary download-pdf" url="https://arxiv.org/pdf/2403.00145v1.pdf" filename="2403.00145v1.pdf">Download PDF</button>

---


**ABSTRACT**  
Value Sensitive Design (VSD) is a framework for integrating human values throughout the technology design process. In parallel, Responsible AI (RAI) advocates for the development of systems aligning with ethical values, such as <b>fairness</b> and transparency. In this study, we posit that a VSD approach is not only compatible, but also advantageous to the development of RAI toolkits. To empirically assess this hypothesis, we conducted four workshops involving 17 early-career AI researchers. Our aim was to establish links between VSD and RAI values while examining how existing toolkits incorporate VSD principles in their design. Our findings show that collaborative and educational design features within these toolkits, including illustrative examples and open-ended cues, facilitate an understanding of human and ethical values, and empower researchers to incorporate values into AI systems. Drawing on these insights, we formulated six design guidelines for integrating VSD values into the development of RAI toolkits.

{{</citation>}}


### (4/8 | 278/321) User Characteristics in Explainable AI: The Rabbit Hole of Personalization? (Robert Nimmo et al., 2024)

{{<citation>}}

Robert Nimmo, Marios Constantinides, Ke Zhou, Daniele Quercia, Simone Stumpf. (2024)  
**User Characteristics in Explainable AI: The Rabbit Hole of Personalization?**
<br/>
<button class="copy-to-clipboard" title="User Characteristics in Explainable AI: The Rabbit Hole of Personalization?" index=278>
  <span class="copy-to-clipboard-item">Copy Title<span>
</button>
<div class="toast toast-copied toast-index-278 align-items-center text-bg-secondary border-0 position-absolute top-0 end-0" role="alert" aria-live="assertive" aria-atomic="true">
  <div class="d-flex">
    <div class="toast-body">
      Copied!
    </div>
  </div>
</div>

---
Primary Category: cs.HC  
Categories: cs-HC, cs.HC  
Keyword Score: 10  
Keywords: Explainable AI  
<a type="button" class="btn btn-outline-primary" href="http://arxiv.org/abs/2403.00137v1" target="_blank" >Paper Link</a>
<button type="button" class="btn btn-outline-primary download-pdf" url="https://arxiv.org/pdf/2403.00137v1.pdf" filename="2403.00137v1.pdf">Download PDF</button>

---


**ABSTRACT**  
As Artificial Intelligence (AI) becomes ubiquitous, the need for <b>Explainable</b> <b>AI</b> (XAI) has become critical for transparency and trust among users. A significant challenge in XAI is catering to diverse users, such as data scientists, domain experts, and end-users. Recent research has started to investigate how users' characteristics impact interactions with and user experience of explanations, with a view to personalizing XAI. However, are we heading down a rabbit hole by focusing on unimportant details? Our research aimed to investigate how user characteristics are related to using, understanding, and trusting an AI system that provides explanations. Our empirical study with 149 participants who interacted with an XAI system that flagged inappropriate comments showed that very few user characteristics mattered; only age and the personality trait openness influenced actual understanding. Our work provides evidence to reorient user-focused XAI research and question the pursuit of personalized XAI based on fine-grained user characteristics.

{{</citation>}}


### (5/8 | 279/321) #PoetsOfInstagram: Navigating The Practices And Challenges Of Novice Poets On Instagram (Ankolika De et al., 2024)

{{<citation>}}

Ankolika De, Zhicong Lu. (2024)  
**#PoetsOfInstagram: Navigating The Practices And Challenges Of Novice Poets On Instagram**
<br/>
<button class="copy-to-clipboard" title="#PoetsOfInstagram: Navigating The Practices And Challenges Of Novice Poets On Instagram" index=279>
  <span class="copy-to-clipboard-item">Copy Title<span>
</button>
<div class="toast toast-copied toast-index-279 align-items-center text-bg-secondary border-0 position-absolute top-0 end-0" role="alert" aria-live="assertive" aria-atomic="true">
  <div class="d-flex">
    <div class="toast-body">
      Copied!
    </div>
  </div>
</div>

---
Primary Category: cs.HC  
Categories: H-5-m; K-4-0, cs-CY, cs-HC, cs-SI, cs.HC  
Keyword Score: 10  
Keywords: Recommendation  
<a type="button" class="btn btn-outline-primary" href="http://arxiv.org/abs/2402.19347v1" target="_blank" >Paper Link</a>
<button type="button" class="btn btn-outline-primary download-pdf" url="https://arxiv.org/pdf/2402.19347v1.pdf" filename="2402.19347v1.pdf">Download PDF</button>

---


**ABSTRACT**  
Commencing as a photo-sharing platform, Instagram has since become multifaceted, accommodating diverse art forms, with poetry emerging as a prominent one. However, the academic understanding of Instagram's poetry community is limited, yet its significance emerges from its distinctive utilization of a primarily visual social media platform guided by <b>recommendation</b> algorithms for disseminating poetry, further characterized by a predominantly novice creative population. We employ qualitative analysis to explore motivations, experiences, and algorithmic influence within Instagram's poetry community. We demonstrate that participants prioritize conforming to algorithmic constraints for visibility, yet maintain their community's values of integrity and originality, illustrating the tension between algorithmic growth and participant authenticity. We introduce the concept of Algorithmically Mediated Creative Labor, a phenomenon specific to non-monetizing creative users who are impacted by the prioritization of professional creators and continually adapt their creative endeavors to align with platform logic, thereby affecting their motivation and creative outputs.

{{</citation>}}


### (6/8 | 280/321) DISCERN: Designing Decision Support Interfaces to Investigate the Complexities of Workplace Social Decision-Making With Line Managers (Pranav Khadpe et al., 2024)

{{<citation>}}

Pranav Khadpe, Lindy Le, Kate Nowak, Shamsi T. Iqbal, Jina Suh. (2024)  
**DISCERN: Designing Decision Support Interfaces to Investigate the Complexities of Workplace Social Decision-Making With Line Managers**
<br/>
<button class="copy-to-clipboard" title="DISCERN: Designing Decision Support Interfaces to Investigate the Complexities of Workplace Social Decision-Making With Line Managers" index=280>
  <span class="copy-to-clipboard-item">Copy Title<span>
</button>
<div class="toast toast-copied toast-index-280 align-items-center text-bg-secondary border-0 position-absolute top-0 end-0" role="alert" aria-live="assertive" aria-atomic="true">
  <div class="d-flex">
    <div class="toast-body">
      Copied!
    </div>
  </div>
</div>

---
Primary Category: cs.HC  
Categories: cs-HC, cs.HC  
Keyword Score: 10  
Keywords: Reasoning  
<a type="button" class="btn btn-outline-primary" href="http://arxiv.org/abs/2402.19318v1" target="_blank" >Paper Link</a>
<button type="button" class="btn btn-outline-primary download-pdf" url="https://arxiv.org/pdf/2402.19318v1.pdf" filename="2402.19318v1.pdf">Download PDF</button>

---


**ABSTRACT**  
Line managers form the first level of management in organizations, and must make complex decisions, while maintaining relationships with those impacted by their decisions. Amidst growing interest in technology-supported decision-making at work, their needs remain understudied. Further, most existing design knowledge for supporting social decision-making comes from domains where decision-makers are more socially detached from those they decide for. We conducted iterative design research with line managers within a technology organization, investigating decision-making practices, and opportunities for technological support. Through formative research, development of a decision-representation tool -- DISCERN -- and user enactments, we identify their communication and analysis needs that lack adequate support. We found they preferred tools for externalizing <b>reasoning</b> rather than tools that replace interpersonal interactions, and they wanted tools to support a range of intuitive and calculative decision-making. We discuss how design of social decision-making supports, especially in the workplace, can more explicitly support highly interactional social decision-making.

{{</citation>}}


### (7/8 | 281/321) Think Fast, Think Slow, Think Critical: Designing an Automated Propaganda Detection Tool (Liudmila Zavolokina et al., 2024)

{{<citation>}}

Liudmila Zavolokina, Kilian Sprenkamp, Zoya Katashinskaya, Daniel Gordon Jones, Gerhard Schwabe. (2024)  
**Think Fast, Think Slow, Think Critical: Designing an Automated Propaganda Detection Tool**
<br/>
<button class="copy-to-clipboard" title="Think Fast, Think Slow, Think Critical: Designing an Automated Propaganda Detection Tool" index=281>
  <span class="copy-to-clipboard-item">Copy Title<span>
</button>
<div class="toast toast-copied toast-index-281 align-items-center text-bg-secondary border-0 position-absolute top-0 end-0" role="alert" aria-live="assertive" aria-atomic="true">
  <div class="d-flex">
    <div class="toast-body">
      Copied!
    </div>
  </div>
</div>

---
Primary Category: cs.HC  
Categories: cs-AI, cs-HC, cs.HC  
Keyword Score: 10  
Keywords: Large Language Model  
<a type="button" class="btn btn-outline-primary" href="http://arxiv.org/abs/2402.19135v1" target="_blank" >Paper Link</a>
<button type="button" class="btn btn-outline-primary download-pdf" url="https://arxiv.org/pdf/2402.19135v1.pdf" filename="2402.19135v1.pdf">Download PDF</button>

---


**ABSTRACT**  
In today's digital age, characterized by rapid news consumption and increasing vulnerability to propaganda, fostering citizens' critical thinking is crucial for stable democracies. This paper introduces the design of ClarifAI, a novel automated propaganda detection tool designed to nudge readers towards more critical news consumption by activating the analytical mode of thinking, following Kahneman's dual-system theory of cognition. Using <b>Large</b> <b>Language</b> <b>Models,</b> ClarifAI detects propaganda in news articles and provides context-rich explanations, enhancing users' understanding and critical thinking. Our contribution is threefold: first, we propose the design of ClarifAI; second, in an online experiment, we demonstrate that this design effectively encourages news readers to engage in more critical reading; and third, we emphasize the value of explanations for fostering critical thinking. The study thus offers both a practical tool and useful design knowledge for mitigating propaganda in digital news.

{{</citation>}}


### (8/8 | 282/321) Umwelt: Accessible Structured Editing of Multimodal Data Representations (Jonathan Zong et al., 2024)

{{<citation>}}

Jonathan Zong, Isabella Pedraza Pineros, Mengzhu Katie Chen, Daniel Hajas, Arvind Satyanarayan. (2024)  
**Umwelt: Accessible Structured Editing of Multimodal Data Representations**
<br/>
<button class="copy-to-clipboard" title="Umwelt: Accessible Structured Editing of Multimodal Data Representations" index=282>
  <span class="copy-to-clipboard-item">Copy Title<span>
</button>
<div class="toast toast-copied toast-index-282 align-items-center text-bg-secondary border-0 position-absolute top-0 end-0" role="alert" aria-live="assertive" aria-atomic="true">
  <div class="d-flex">
    <div class="toast-body">
      Copied!
    </div>
  </div>
</div>

---
Primary Category: cs.HC  
Categories: cs-HC, cs.HC  
Keyword Score: 6  
Keywords: Multi-modal, Multi-modal  
<a type="button" class="btn btn-outline-primary" href="http://arxiv.org/abs/2403.00106v2" target="_blank" >Paper Link</a>
<button type="button" class="btn btn-outline-primary download-pdf" url="https://arxiv.org/pdf/2403.00106v2.pdf" filename="2403.00106v2.pdf">Download PDF</button>

---


**ABSTRACT**  
We present Umwelt, an authoring environment for interactive <b>multimodal</b> data representations. In contrast to prior approaches, which center the visual modality, Umwelt treats visualization, sonification, and textual description as coequal representations: they are all derived from a shared abstract data model, such that no modality is prioritized over the others. To simplify specification, Umwelt evaluates a set of heuristics to generate default <b>multimodal</b> representations that express a dataset's functional relationships. To support smoothly moving between representations, Umwelt maintains a shared query predicated that is reified across all modalities -- for instance, navigating the textual description also highlights the visualization and filters the sonification. In a study with 5 blind / low-vision expert users, we found that Umwelt's <b>multimodal</b> representations afforded complementary overview and detailed perspectives on a dataset, allowing participants to fluidly shift between task- and representation-oriented ways of thinking.

{{</citation>}}


## cs.SD (2)



### (1/2 | 283/321) Probing the Information Encoded in Neural-based Acoustic Models of Automatic Speech Recognition Systems (Quentin Raymondaud et al., 2024)

{{<citation>}}

Quentin Raymondaud, Mickael Rouvier, Richard Dufour. (2024)  
**Probing the Information Encoded in Neural-based Acoustic Models of Automatic Speech Recognition Systems**
<br/>
<button class="copy-to-clipboard" title="Probing the Information Encoded in Neural-based Acoustic Models of Automatic Speech Recognition Systems" index=283>
  <span class="copy-to-clipboard-item">Copy Title<span>
</button>
<div class="toast toast-copied toast-index-283 align-items-center text-bg-secondary border-0 position-absolute top-0 end-0" role="alert" aria-live="assertive" aria-atomic="true">
  <div class="d-flex">
    <div class="toast-body">
      Copied!
    </div>
  </div>
</div>

---
Primary Category: cs.SD  
Categories: cs-AI, cs-SD, cs.SD, eess-AS  
Keyword Score: 35  
Keywords: Black Box, Automatic Speech Recognition, Automatic Speech Recognition, Automatic Speech Recognition  
<a type="button" class="btn btn-outline-primary" href="http://arxiv.org/abs/2402.19443v1" target="_blank" >Paper Link</a>
<button type="button" class="btn btn-outline-primary download-pdf" url="https://arxiv.org/pdf/2402.19443v1.pdf" filename="2402.19443v1.pdf">Download PDF</button>

---


**ABSTRACT**  
Deep learning architectures have made significant progress in terms of performance in many research areas. The <b>automatic</b> <b>speech</b> <b>recognition</b> <b>(ASR)</b> field has thus benefited from these scientific and technological advances, particularly for acoustic modeling, now integrating deep neural network architectures. However, these performance gains have translated into increased complexity regarding the information learned and conveyed through these <b>black-box</b> <b>architectures.</b> Following many researches in neural networks interpretability, we propose in this article a protocol that aims to determine which and where information is located in an <b>ASR</b> acoustic model (AM). To do so, we propose to evaluate AM performance on a determined set of tasks using intermediate representations (here, at different layer levels). Regarding the performance variation and targeted tasks, we can emit hypothesis about which information is enhanced or perturbed at different architecture steps. Experiments are performed on both speaker verification, acoustic environment classification, gender classification, tempo-distortion detection systems and <b>speech</b> <b>sentiment/emotion</b> identification. Analysis showed that neural-based AMs hold heterogeneous information that seems surprisingly uncorrelated with phoneme recognition, such as emotion, sentiment or speaker identity. The low-level hidden layers globally appears useful for the structuring of information while the upper ones would tend to delete useless information for phoneme recognition.

{{</citation>}}


### (2/2 | 284/321) Unraveling Adversarial Examples against Speaker Identification -- Techniques for Attack Detection and Victim Model Classification (Sonal Joshi et al., 2024)

{{<citation>}}

Sonal Joshi, Thomas Thebaud, Jesús Villalba, Najim Dehak. (2024)  
**Unraveling Adversarial Examples against Speaker Identification -- Techniques for Attack Detection and Victim Model Classification**
<br/>
<button class="copy-to-clipboard" title="Unraveling Adversarial Examples against Speaker Identification -- Techniques for Attack Detection and Victim Model Classification" index=284>
  <span class="copy-to-clipboard-item">Copy Title<span>
</button>
<div class="toast toast-copied toast-index-284 align-items-center text-bg-secondary border-0 position-absolute top-0 end-0" role="alert" aria-live="assertive" aria-atomic="true">
  <div class="d-flex">
    <div class="toast-body">
      Copied!
    </div>
  </div>
</div>

---
Primary Category: cs.SD  
Categories: cs-CR, cs-LG, cs-SD, cs.SD, eess-AS  
Keyword Score: 10  
Keywords: Adversarial Attack  
<a type="button" class="btn btn-outline-primary" href="http://arxiv.org/abs/2402.19355v1" target="_blank" >Paper Link</a>
<button type="button" class="btn btn-outline-primary download-pdf" url="https://arxiv.org/pdf/2402.19355v1.pdf" filename="2402.19355v1.pdf">Download PDF</button>

---


**ABSTRACT**  
<b>Adversarial</b> <b>examples</b> have proven to threaten speaker identification systems, and several countermeasures against them have been proposed. In this paper, we propose a method to detect the presence of <b>adversarial</b> <b>examples,</b> i.e., a binary classifier distinguishing between benign and <b>adversarial</b> <b>examples.</b> We build upon and extend previous work on attack type classification by exploring new architectures. Additionally, we introduce a method for identifying the victim model on which the <b>adversarial</b> <b>attack</b> is carried out. To achieve this, we generate a new dataset containing multiple attacks performed against various victim models. We achieve an AUC of 0.982 for attack detection, with no more than a 0.03 drop in performance for unknown attacks. Our attack classification accuracy (excluding benign) reaches 86.48% across eight attack types using our LightResNet34 architecture, while our victim model classification accuracy reaches 72.28% across four victim models.

{{</citation>}}


## cs.NI (4)



### (1/4 | 285/321) Energy-Efficient UAV Swarm Assisted MEC with Dynamic Clustering and Scheduling (Jialiuyuan Li et al., 2024)

{{<citation>}}

Jialiuyuan Li, Jiayuan Chen, Changyan Yi, Tong Zhang, Kun Zhu, Jun Cai. (2024)  
**Energy-Efficient UAV Swarm Assisted MEC with Dynamic Clustering and Scheduling**
<br/>
<button class="copy-to-clipboard" title="Energy-Efficient UAV Swarm Assisted MEC with Dynamic Clustering and Scheduling" index=285>
  <span class="copy-to-clipboard-item">Copy Title<span>
</button>
<div class="toast toast-copied toast-index-285 align-items-center text-bg-secondary border-0 position-absolute top-0 end-0" role="alert" aria-live="assertive" aria-atomic="true">
  <div class="d-flex">
    <div class="toast-body">
      Copied!
    </div>
  </div>
</div>

---
Primary Category: cs.NI  
Categories: cs-NI, cs.NI, eess-SP  
Keyword Score: 33  
Keywords: Clustering, Reinforcement Learning, Simulation, Simulator  
<a type="button" class="btn btn-outline-primary" href="http://arxiv.org/abs/2402.18936v1" target="_blank" >Paper Link</a>
<button type="button" class="btn btn-outline-primary download-pdf" url="https://arxiv.org/pdf/2402.18936v1.pdf" filename="2402.18936v1.pdf">Download PDF</button>

---


**ABSTRACT**  
In this paper, the energy-efficient unmanned aerial vehicle (UAV) swarm assisted mobile edge computing (MEC) with dynamic <b>clustering</b> and scheduling is studied. In the considered system model, UAVs are divided into multiple swarms, with each swarm consisting of a leader UAV and several follower UAVs to provide computing services to end-users. Unlike existing work, we allow UAVs to dynamically cluster into different swarms, i.e., each follower UAV can change its leader based on the time-varying spatial positions, updated application placement, etc. in a dynamic manner. Meanwhile, UAVs are required to dynamically schedule their energy replenishment, application placement, trajectory planning and task delegation. With the aim of maximizing the long-term energy efficiency of the UAV swarm assisted MEC system, a joint optimization problem of dynamic <b>clustering</b> and scheduling is formulated. Taking into account the underlying cooperation and competition among intelligent UAVs, we further reformulate this optimization problem as a combination of a series of strongly coupled multi-agent stochastic games, and then propose a novel <b>reinforcement</b> <b>learning-based</b> UAV swarm dynamic coordination (RLDC) algorithm for obtaining the equilibrium. <b>Simulations</b> are conducted to evaluate the performance of the RLDC algorithm and demonstrate its superiority over counterparts.

{{</citation>}}


### (2/4 | 286/321) X-ResQ: Reverse Annealing for Quantum MIMO Detection with Flexible Parallelism (Minsung Kim et al., 2024)

{{<citation>}}

Minsung Kim, Abhishek Kumar Singh, Davide Venturelli, John Kaewell, Kyle Jamieson. (2024)  
**X-ResQ: Reverse Annealing for Quantum MIMO Detection with Flexible Parallelism**
<br/>
<button class="copy-to-clipboard" title="X-ResQ: Reverse Annealing for Quantum MIMO Detection with Flexible Parallelism" index=286>
  <span class="copy-to-clipboard-item">Copy Title<span>
</button>
<div class="toast toast-copied toast-index-286 align-items-center text-bg-secondary border-0 position-absolute top-0 end-0" role="alert" aria-live="assertive" aria-atomic="true">
  <div class="d-flex">
    <div class="toast-body">
      Copied!
    </div>
  </div>
</div>

---
Primary Category: cs.NI  
Categories: cs-NI, cs.NI, quant-ph  
Keyword Score: 10  
Keywords: Question Answering  
<a type="button" class="btn btn-outline-primary" href="http://arxiv.org/abs/2402.18778v1" target="_blank" >Paper Link</a>
<button type="button" class="btn btn-outline-primary download-pdf" url="https://arxiv.org/pdf/2402.18778v1.pdf" filename="2402.18778v1.pdf">Download PDF</button>

---


**ABSTRACT**  
Quantum Annealing <b>(QA)-accelerated</b> MIMO detection is an emerging research approach in the context of NextG wireless networks. The opportunity is to enable large MIMO systems and thus improve wireless performance. The approach aims to leverage <b>QA</b> to expedite the computation required for theoretically optimal but computationally-demanding Maximum Likelihood detection to overcome the limitations of the currently deployed linear detectors. This paper presents \textbf{X-ResQ}, a <b>QA-based</b> MIMO detector system featuring fine-grained quantum task parallelism that is uniquely enabled by the Reverse Annealing (RA) protocol. Unlike prior designs, X-ResQ has many desirable system properties for a parallel <b>QA</b> detector and has effectively improved detection performance as more qubits are assigned. In our evaluations on a state-of-the-art quantum annealer, fully parallel X-ResQ achieves near-optimal throughput (over 10 bits/s/Hz) for $4\times6$ MIMO with 16-QAM using six levels of parallelism with 240 qubits and $220~\mu$s <b>QA</b> compute time, achieving 2.5--5$\times$ gains compared against other tested detectors. For more comprehensive evaluations, we implement and evaluate X-ResQ in the non-quantum digital setting. This non-quantum X-ResQ demonstration showcases the potential to realize ultra-large $1024\times1024$ MIMO, significantly outperforming other MIMO detectors, including the state-of-the-art RA detector classically implemented in the same way.

{{</citation>}}


### (3/4 | 287/321) Vision-Radio Experimental Infrastructure Architecture Towards 6G (Filipe B. Teixeira et al., 2024)

{{<citation>}}

Filipe B. Teixeira, Manuel Ricardo, André Coelho, Hélder P. Oliveira, Paula Viana, Nuno Paulino, Helder Fontes, Paulo Marques, Rui Campos, Luis M. Pessoa. (2024)  
**Vision-Radio Experimental Infrastructure Architecture Towards 6G**
<br/>
<button class="copy-to-clipboard" title="Vision-Radio Experimental Infrastructure Architecture Towards 6G" index=287>
  <span class="copy-to-clipboard-item">Copy Title<span>
</button>
<div class="toast toast-copied toast-index-287 align-items-center text-bg-secondary border-0 position-absolute top-0 end-0" role="alert" aria-live="assertive" aria-atomic="true">
  <div class="d-flex">
    <div class="toast-body">
      Copied!
    </div>
  </div>
</div>

---
Primary Category: cs.NI  
Categories: cs-NI, cs.NI, eess-SP  
Keyword Score: 6  
Keywords: Multi-modal, Multi-modal  
<a type="button" class="btn btn-outline-primary" href="http://arxiv.org/abs/2402.19416v1" target="_blank" >Paper Link</a>
<button type="button" class="btn btn-outline-primary download-pdf" url="https://arxiv.org/pdf/2402.19416v1.pdf" filename="2402.19416v1.pdf">Download PDF</button>

---


**ABSTRACT**  
Telecommunications and computer vision have evolved separately so far. Yet, with the shift to sub-terahertz (sub-THz) and terahertz (THz) radio communications, there is an opportunity to explore computer vision technologies together with radio communications, considering the dependency of both technologies on Line of Sight. The combination of radio sensing and computer vision can address challenges such as obstructions and poor lighting. Also, machine learning algorithms, capable of processing <b>multimodal</b> data, play a crucial role in deriving insights from raw and low-level sensing data, offering a new level of abstraction that can enhance various applications and use cases such as beamforming and terminal handovers. This paper introduces CONVERGE, a pioneering vision-radio paradigm that bridges this gap by leveraging Integrated Sensing and Communication (ISAC) to facilitate a dual "View-to-Communicate, Communicate-to-View" approach. CONVERGE offers tools that merge wireless communications and computer vision, establishing a novel Research Infrastructure (RI) that will be open to the scientific community and capable of providing open datasets. This new infrastructure will support future research in 6G and beyond concerning multiple verticals, such as telecommunications, automotive, manufacturing, media, and health.

{{</citation>}}


### (4/4 | 288/321) Structural Resilience and Connectivity of the IPv6 Internet: An AS-level Topology Examination (Bin Yuan et al., 2024)

{{<citation>}}

Bin Yuan, Tianbo Song. (2024)  
**Structural Resilience and Connectivity of the IPv6 Internet: An AS-level Topology Examination**
<br/>
<button class="copy-to-clipboard" title="Structural Resilience and Connectivity of the IPv6 Internet: An AS-level Topology Examination" index=288>
  <span class="copy-to-clipboard-item">Copy Title<span>
</button>
<div class="toast toast-copied toast-index-288 align-items-center text-bg-secondary border-0 position-absolute top-0 end-0" role="alert" aria-live="assertive" aria-atomic="true">
  <div class="d-flex">
    <div class="toast-body">
      Copied!
    </div>
  </div>
</div>

---
Primary Category: cs.NI  
Categories: cs-CR, cs-NI, cs.NI  
Keyword Score: 3  
Keywords: Clustering  
<a type="button" class="btn btn-outline-primary" href="http://arxiv.org/abs/2403.00193v1" target="_blank" >Paper Link</a>
<button type="button" class="btn btn-outline-primary download-pdf" url="https://arxiv.org/pdf/2403.00193v1.pdf" filename="2403.00193v1.pdf">Download PDF</button>

---


**ABSTRACT**  
The study utilizes a comprehensive dataset informed by IPv6 routing information to provide statistics, degree distribution, joint degree distribution, and <b>clustering</b> analysis of the IPv6 Internet's structure and resilience.The dataset includes 17,232 unique ASes and 10,000 unique IPv6 prefixes. Analysis reveals an interconnected network with an average path length of approximately 3 hops, suggesting a robust and efficient network with potential redundancy and resilience, despite some isolated components. The paper outlines the degree distribution, indicating many peripheral nodes in a sparse network, and a <b>clustering</b> analysis showing a tendency for ASes to form clusters, which is indicative of redundancy and robustness against failures. The connectivity analysis, including path redundancy and reachability, supports the network's resilience.The findings are crucial for network design and strategic planning, particularly as IPv6 adoption increases. The paper emphasizes the importance of continuous monitoring and improvement of network connectivity in the evolving Internet landscape, highlighting the IPv6 Internet's resilience and structured connectivity.

{{</citation>}}


## cs.DC (2)



### (1/2 | 289/321) FlexLLM: A System for Co-Serving Large Language Model Inference and Parameter-Efficient Finetuning (Xupeng Miao et al., 2024)

{{<citation>}}

Xupeng Miao, Gabriele Oliaro, Xinhao Cheng, Mengdi Wu, Colin Unger, Zhihao Jia. (2024)  
**FlexLLM: A System for Co-Serving Large Language Model Inference and Parameter-Efficient Finetuning**
<br/>
<button class="copy-to-clipboard" title="FlexLLM: A System for Co-Serving Large Language Model Inference and Parameter-Efficient Finetuning" index=289>
  <span class="copy-to-clipboard-item">Copy Title<span>
</button>
<div class="toast toast-copied toast-index-289 align-items-center text-bg-secondary border-0 position-absolute top-0 end-0" role="alert" aria-live="assertive" aria-atomic="true">
  <div class="d-flex">
    <div class="toast-body">
      Copied!
    </div>
  </div>
</div>

---
Primary Category: cs.DC  
Categories: cs-CL, cs-DC, cs-LG, cs.DC  
Keyword Score: 33  
Keywords: Graph, Fine-tuning, Pruning, Large Language Model  
<a type="button" class="btn btn-outline-primary" href="http://arxiv.org/abs/2402.18789v1" target="_blank" >Paper Link</a>
<button type="button" class="btn btn-outline-primary download-pdf" url="https://arxiv.org/pdf/2402.18789v1.pdf" filename="2402.18789v1.pdf">Download PDF</button>

---


**ABSTRACT**  
Parameter-efficient <b>finetuning</b> (PEFT) is a widely used technique to adapt <b>large</b> <b>language</b> <b>models</b> for different tasks. Service providers typically create separate systems for users to perform PEFT model <b>finetuning</b> and inference tasks. This is because existing systems cannot handle workloads that include a mix of inference and PEFT <b>finetuning</b> requests. As a result, shared GPU resources are underutilized, leading to inefficiencies. To address this problem, we present FlexLLM, the first system that can serve inference and parameter-efficient <b>finetuning</b> requests in the same iteration. Our system leverages the complementary nature of these two tasks and utilizes shared GPU resources to run them jointly, using a method called co-serving. To achieve this, FlexLLM introduces a novel token-level <b>finetuning</b> mechanism, which breaks down the <b>finetuning</b> computation of a sequence into smaller token-level computations and uses dependent parallelization and <b>graph</b> <b>pruning,</b> two static compilation optimizations, to minimize the memory overhead and latency for co-serving. Compared to existing systems, FlexLLM's co-serving approach reduces the activation GPU memory overhead by up to 8x, and the end-to-end GPU memory requirement of <b>finetuning</b> by up to 36% while maintaining a low inference latency and improving <b>finetuning</b> throughput. For example, under a heavy inference workload, FlexLLM can still preserve more than 80% of the peak <b>finetuning</b> throughput, whereas existing systems cannot make any progress with <b>finetuning.</b> The source code of FlexLLM is publicly available at https://github.com/flexflow/FlexFlow.

{{</citation>}}


### (2/2 | 290/321) Arrow Matrix Decomposition: A Novel Approach for Communication-Efficient Sparse Matrix Multiplication (Lukas Gianinazzi et al., 2024)

{{<citation>}}

Lukas Gianinazzi, Alexandros Nikolaos Ziogas, Langwen Huang, Piotr Luczynski, Saleh Ashkboos, Florian Scheidl, Armon Carigiet, Chio Ge, Nabil Abubaker, Maciej Besta, Tal Ben-Nun, Torsten Hoefler. (2024)  
**Arrow Matrix Decomposition: A Novel Approach for Communication-Efficient Sparse Matrix Multiplication**
<br/>
<button class="copy-to-clipboard" title="Arrow Matrix Decomposition: A Novel Approach for Communication-Efficient Sparse Matrix Multiplication" index=290>
  <span class="copy-to-clipboard-item">Copy Title<span>
</button>
<div class="toast toast-copied toast-index-290 align-items-center text-bg-secondary border-0 position-absolute top-0 end-0" role="alert" aria-live="assertive" aria-atomic="true">
  <div class="d-flex">
    <div class="toast-body">
      Copied!
    </div>
  </div>
</div>

---
Primary Category: cs.DC  
Categories: F-2-1, cs-DC, cs.DC  
Keyword Score: 13  
Keywords: Graph, Graph Neural Network  
<a type="button" class="btn btn-outline-primary" href="http://arxiv.org/abs/2402.19364v1" target="_blank" >Paper Link</a>
<button type="button" class="btn btn-outline-primary download-pdf" url="https://arxiv.org/pdf/2402.19364v1.pdf" filename="2402.19364v1.pdf">Download PDF</button>

---


**ABSTRACT**  
We propose a novel approach to iterated sparse matrix dense matrix multiplication, a fundamental computational kernel in scientific computing and <b>graph</b> <b>neural</b> <b>network</b> training. In cases where matrix sizes exceed the memory of a single compute node, data transfer becomes a bottleneck. An approach based on dense matrix multiplication algorithms leads to suboptimal scalability and fails to exploit the sparsity in the problem. To address these challenges, we propose decomposing the sparse matrix into a small number of highly structured matrices called arrow matrices, which are connected by permutations. Our approach enables communication-avoiding multiplications, achieving a polynomial reduction in communication volume per iteration for matrices corresponding to planar <b>graphs</b> <b>and</b> <b>other</b> minor-excluded families of <b>graphs.</b> <b>Our</b> <b>evaluation</b> demonstrates that our approach outperforms a state-of-the-art method for sparse matrix multiplication on matrices with hundreds of millions of rows, offering near-linear strong and weak scaling.

{{</citation>}}


## cs.AR (3)



### (1/3 | 291/321) NeuraLUT: Hiding Neural Network Density in Boolean Synthesizable Functions (Marta Andronic et al., 2024)

{{<citation>}}

Marta Andronic, George A. Constantinides. (2024)  
**NeuraLUT: Hiding Neural Network Density in Boolean Synthesizable Functions**
<br/>
<button class="copy-to-clipboard" title="NeuraLUT: Hiding Neural Network Density in Boolean Synthesizable Functions" index=291>
  <span class="copy-to-clipboard-item">Copy Title<span>
</button>
<div class="toast toast-copied toast-index-291 align-items-center text-bg-secondary border-0 position-absolute top-0 end-0" role="alert" aria-live="assertive" aria-atomic="true">
  <div class="d-flex">
    <div class="toast-body">
      Copied!
    </div>
  </div>
</div>

---
Primary Category: cs.AR  
Categories: cs-AR, cs-LG, cs.AR, stat-ML  
Keyword Score: 30  
Keywords: MNIST, Quantization, Quantization  
<a type="button" class="btn btn-outline-primary" href="http://arxiv.org/abs/2403.00849v1" target="_blank" >Paper Link</a>
<button type="button" class="btn btn-outline-primary download-pdf" url="https://arxiv.org/pdf/2403.00849v1.pdf" filename="2403.00849v1.pdf">Download PDF</button>

---


**ABSTRACT**  
Field-Programmable Gate Array (FPGA) accelerators have proven successful in handling latency- and resource-critical deep neural network (DNN) inference tasks. Among the most computationally intensive operations in a neural network (NN) is the dot product between the feature and weight vectors. Thus, some previous FPGA acceleration works have proposed mapping neurons with <b>quantized</b> inputs and outputs directly to lookup tables (LUTs) for hardware implementation. In these works, the boundaries of the neurons coincide with the boundaries of the LUTs. We propose relaxing these boundaries and mapping entire sub-networks to a single LUT. As the sub-networks are absorbed within the LUT, the NN topology and precision within a partition do not affect the size of the lookup tables generated. Therefore, we utilize fully connected layers with floating-point precision inside each partition, which benefit from being universal function approximators, with rigid sparsity and <b>quantization</b> enforced only between partitions, where the NN topology becomes exposed to the circuit topology. Although cheap to implement, this approach can lead to very deep NNs, and so to tackle challenges like vanishing gradients, we also introduce skip connections inside the partitions. The resulting methodology can be seen as training DNNs with a specific sparsity pattern that allows them to be mapped to much shallower circuit-level networks, thereby significantly improving latency. We validate our proposed method on a known latency-critical task, jet substructure tagging, and on the classical computer vision task, the digit classification using <b>MNIST.</b> Our approach allows for greater function expressivity within the LUTs compared to existing work, leading to lower latency NNs for the same accuracy.

{{</citation>}}


### (2/3 | 292/321) MIMDRAM: An End-to-End Processing-Using-DRAM System for High-Throughput, Energy-Efficient and Programmer-Transparent Multiple-Instruction Multiple-Data Processing (Geraldo F. Oliveira et al., 2024)

{{<citation>}}

Geraldo F. Oliveira, Ataberk Olgun, Abdullah Giray Yağlıkçı, F. Nisa Bostancı, Juan Gómez-Luna, Saugata Ghose, Onur Mutlu. (2024)  
**MIMDRAM: An End-to-End Processing-Using-DRAM System for High-Throughput, Energy-Efficient and Programmer-Transparent Multiple-Instruction Multiple-Data Processing**
<br/>
<button class="copy-to-clipboard" title="MIMDRAM: An End-to-End Processing-Using-DRAM System for High-Throughput, Energy-Efficient and Programmer-Transparent Multiple-Instruction Multiple-Data Processing" index=292>
  <span class="copy-to-clipboard-item">Copy Title<span>
</button>
<div class="toast toast-copied toast-index-292 align-items-center text-bg-secondary border-0 position-absolute top-0 end-0" role="alert" aria-live="assertive" aria-atomic="true">
  <div class="d-flex">
    <div class="toast-body">
      Copied!
    </div>
  </div>
</div>

---
Primary Category: cs.AR  
Categories: cs-AR, cs-DC, cs.AR  
Keyword Score: 10  
Keywords: Fairness  
<a type="button" class="btn btn-outline-primary" href="http://arxiv.org/abs/2402.19080v2" target="_blank" >Paper Link</a>
<button type="button" class="btn btn-outline-primary download-pdf" url="https://arxiv.org/pdf/2402.19080v2.pdf" filename="2402.19080v2.pdf">Download PDF</button>

---


**ABSTRACT**  
Processing-using-DRAM (PUD) is a processing-in-memory (PIM) approach that uses a DRAM array's massive internal parallelism to execute very-wide data-parallel operations, in a single-instruction multiple-data (SIMD) fashion. However, DRAM rows' large and rigid granularity limit the effectiveness and applicability of PUD in three ways. First, since applications have varying degrees of SIMD parallelism, PUD execution often leads to underutilization, throughput loss, and energy waste. Second, most PUD architectures are limited to the execution of parallel map operations. Third, the need to feed the wide DRAM row with tens of thousands of data elements combined with the lack of adequate compiler support for PUD systems create a programmability barrier. Our goal is to design a flexible PUD system that overcomes the limitations caused by the large and rigid granularity of PUD. To this end, we propose MIMDRAM, a hardware/software co-designed PUD system that introduces new mechanisms to allocate and control only the necessary resources for a given PUD operation. The key idea of MIMDRAM is to leverage fine-grained DRAM (i.e., the ability to independently access smaller segments of a large DRAM row) for PUD computation. MIMDRAM exploits this key idea to enable a multiple-instruction multiple-data (MIMD) execution model in each DRAM subarray. We evaluate MIMDRAM using twelve real-world applications and 495 multi-programmed application mixes. Our evaluation shows that MIMDRAM provides 34x the performance, 14.3x the energy efficiency, 1.7x the throughput, and 1.3x the <b>fairness</b> of a state-of-the-art PUD framework, along with 30.6x and 6.8x the energy efficiency of a high-end CPU and GPU, respectively. MIMDRAM adds small area cost to a DRAM chip (1.11%) and CPU die (0.6%).

{{</citation>}}


### (3/3 | 293/321) OzMAC: An Energy-Efficient Sparsity-Exploiting Multiply-Accumulate-Unit Design for DL Inference (Harideep Nair et al., 2024)

{{<citation>}}

Harideep Nair, Prabhu Vellaisamy, Tsung-Han Lin, Perry Wang, Shawn Blanton, John Paul Shen. (2024)  
**OzMAC: An Energy-Efficient Sparsity-Exploiting Multiply-Accumulate-Unit Design for DL Inference**
<br/>
<button class="copy-to-clipboard" title="OzMAC: An Energy-Efficient Sparsity-Exploiting Multiply-Accumulate-Unit Design for DL Inference" index=293>
  <span class="copy-to-clipboard-item">Copy Title<span>
</button>
<div class="toast toast-copied toast-index-293 align-items-center text-bg-secondary border-0 position-absolute top-0 end-0" role="alert" aria-live="assertive" aria-atomic="true">
  <div class="d-flex">
    <div class="toast-body">
      Copied!
    </div>
  </div>
</div>

---
Primary Category: cs.AR  
Categories: cs-AR, cs.AR  
Keyword Score: 3  
Keywords: Benchmarking  
<a type="button" class="btn btn-outline-primary" href="http://arxiv.org/abs/2402.19376v1" target="_blank" >Paper Link</a>
<button type="button" class="btn btn-outline-primary download-pdf" url="https://arxiv.org/pdf/2402.19376v1.pdf" filename="2402.19376v1.pdf">Download PDF</button>

---


**ABSTRACT**  
General Matrix Multiply (GEMM) hardware, employing large arrays of multiply-accumulate (MAC) units, perform bulk of the computation in deep learning (DL). Recent trends have established 8-bit integer (INT8) as the most widely used precision for DL inference. This paper proposes a novel MAC design capable of dynamically exploiting bit sparsity (i.e., number of `0' bits within a binary value) in input data to achieve significant improvements on area, power and energy. The proposed architecture, called OzMAC (Omit-zero-MAC), skips over zeros within a binary input value and performs simple shift-and-add-based compute in place of expensive multipliers. We implement OzMAC in SystemVerilog and present post-synthesis performance-power-area (PPA) results using commercial TSMC N5 (5nm) process node. Using eight pretrained INT8 deep neural networks (DNNs) as <b>benchmarks,</b> we demonstrate the existence of high bit sparsity in real DNN workloads and show that 8-bit OzMAC improves all three metrics of area, power, and energy significantly by 21%, 70%, and 28%, respectively. Similar improvements are achieved when scaling data precisions (4, 8, 16 bits) and clock frequencies (0.5 GHz, 1 GHz, 1.5 GHz). For the 8-bit OzMAC, scaling its frequency to normalize the throughput relative to conventional MAC, it still achieves 30% improvement on both power and energy.

{{</citation>}}


## cs.GT (2)



### (1/2 | 294/321) Conjectural Online Learning with First-order Beliefs in Asymmetric Information Stochastic Games (Tao Li et al., 2024)

{{<citation>}}

Tao Li, Kim Hammar, Rolf Stadler, Quanyan Zhu. (2024)  
**Conjectural Online Learning with First-order Beliefs in Asymmetric Information Stochastic Games**
<br/>
<button class="copy-to-clipboard" title="Conjectural Online Learning with First-order Beliefs in Asymmetric Information Stochastic Games" index=294>
  <span class="copy-to-clipboard-item">Copy Title<span>
</button>
<div class="toast toast-copied toast-index-294 align-items-center text-bg-secondary border-0 position-absolute top-0 end-0" role="alert" aria-live="assertive" aria-atomic="true">
  <div class="d-flex">
    <div class="toast-body">
      Copied!
    </div>
  </div>
</div>

---
Primary Category: cs.GT  
Categories: cs-GT, cs-LG, cs-SY, cs.GT, eess-SY  
Keyword Score: 30  
Keywords: Reinforcement Learning, Simulation, Simulator  
<a type="button" class="btn btn-outline-primary" href="http://arxiv.org/abs/2402.18781v2" target="_blank" >Paper Link</a>
<button type="button" class="btn btn-outline-primary download-pdf" url="https://arxiv.org/pdf/2402.18781v2.pdf" filename="2402.18781v2.pdf">Download PDF</button>

---


**ABSTRACT**  
Asymmetric information stochastic games (\textsc{aisg}s) arise in many complex socio-technical systems, such as cyber-physical systems and IT infrastructures. Existing computational methods for \textsc{aisg}s are primarily offline and can not adapt to equilibrium deviations. Further, current methods are limited to special classes of \textsc{aisg}s to avoid belief hierarchies. To address these limitations, we propose conjectural online learning (\textsc{col}), an online method for generic \textsc{aisg}s. \textsc{col} uses a forecaster-actor-critic (\textsc{fac}) architecture where subjective forecasts is used to conjecture the opponents' strategies and break belief hierarchies (forecaster), online rollout is used to adapt strategies to nonstationary environments (actor), Monte-Carlo <b>simulation</b> is used to estimate costs (critic), and Bayesian learning is used to calibrate conjectures. We prove that the conjectures produced by \textsc{col} are asymptotically consistent with the information feedback in the sense of a relaxed Bayesian consistency. We also prove that the empirical strategy profile induced by \textsc{col} converges to the Berk-Nash equilibrium, a solution concept characterizing rationality under subjectivity. Experimental results from an intrusion response use case demonstrate \textsc{col}'s superiority over state-of-the-art <b>reinforcement</b> <b>learning</b> methods against nonstationary attacks.

{{</citation>}}


### (2/2 | 295/321) Understanding Iterative Combinatorial Auction Designs via Multi-Agent Reinforcement Learning (Greg d'Eon et al., 2024)

{{<citation>}}

Greg d'Eon, Neil Newman, Kevin Leyton-Brown. (2024)  
**Understanding Iterative Combinatorial Auction Designs via Multi-Agent Reinforcement Learning**
<br/>
<button class="copy-to-clipboard" title="Understanding Iterative Combinatorial Auction Designs via Multi-Agent Reinforcement Learning" index=295>
  <span class="copy-to-clipboard-item">Copy Title<span>
</button>
<div class="toast toast-copied toast-index-295 align-items-center text-bg-secondary border-0 position-absolute top-0 end-0" role="alert" aria-live="assertive" aria-atomic="true">
  <div class="d-flex">
    <div class="toast-body">
      Copied!
    </div>
  </div>
</div>

---
Primary Category: cs.GT  
Categories: cs-AI, cs-GT, cs-MA, cs.GT  
Keyword Score: 10  
Keywords: Reinforcement Learning  
<a type="button" class="btn btn-outline-primary" href="http://arxiv.org/abs/2402.19420v1" target="_blank" >Paper Link</a>
<button type="button" class="btn btn-outline-primary download-pdf" url="https://arxiv.org/pdf/2402.19420v1.pdf" filename="2402.19420v1.pdf">Download PDF</button>

---


**ABSTRACT**  
Iterative combinatorial auctions are widely used in high stakes settings such as spectrum auctions. Such auctions can be hard to understand analytically, making it difficult for bidders to determine how to behave and for designers to optimize auction rules to ensure desirable outcomes such as high revenue or welfare. In this paper, we investigate whether multi-agent <b>reinforcement</b> <b>learning</b> (MARL) algorithms can be used to understand iterative combinatorial auctions, given that these algorithms have recently shown empirical success in several other domains. We find that MARL can indeed benefit auction analysis, but that deploying it effectively is nontrivial. We begin by describing modelling decisions that keep the resulting game tractable without sacrificing important features such as imperfect information or asymmetry between bidders. We also discuss how to navigate pitfalls of various MARL algorithms, how to overcome challenges in verifying convergence, and how to generate and interpret multiple equilibria. We illustrate the promise of our resulting approach by using it to evaluate a specific rule change to a clock auction, finding substantially different auction outcomes due to complex changes in bidders' behavior.

{{</citation>}}


## physics.soc-ph (1)



### (1/1 | 296/321) Quantum Readiness in Healthcare and Public Health: Building a Quantum Literate Workforce (Jonathan B VanGeest et al., 2024)

{{<citation>}}

Jonathan B VanGeest, Kieran J Fogarty, William G Hervey, Robert A Hanson, Suresh Nair, Timothy A Akers. (2024)  
**Quantum Readiness in Healthcare and Public Health: Building a Quantum Literate Workforce**
<br/>
<button class="copy-to-clipboard" title="Quantum Readiness in Healthcare and Public Health: Building a Quantum Literate Workforce" index=296>
  <span class="copy-to-clipboard-item">Copy Title<span>
</button>
<div class="toast toast-copied toast-index-296 align-items-center text-bg-secondary border-0 position-absolute top-0 end-0" role="alert" aria-live="assertive" aria-atomic="true">
  <div class="d-flex">
    <div class="toast-body">
      Copied!
    </div>
  </div>
</div>

---
Primary Category: physics.soc-ph  
Categories: cs-CY, cs-ET, physics-soc-ph, physics.soc-ph, quant-ph  
Keyword Score: 20  
Keywords: Simulation, Simulator  
<a type="button" class="btn btn-outline-primary" href="http://arxiv.org/abs/2403.00122v1" target="_blank" >Paper Link</a>
<button type="button" class="btn btn-outline-primary download-pdf" url="https://arxiv.org/pdf/2403.00122v1.pdf" filename="2403.00122v1.pdf">Download PDF</button>

---


**ABSTRACT**  
Quantum technologies, including quantum computing, cryptography, and sensing, among others, are set to revolutionize sectors ranging from materials science to drug discovery. Despite their significant potential, the implications for public health have been largely overlooked, highlighting a critical gap in recognition and preparation. This oversight necessitates immediate action, as public health remains largely unaware of quantum technologies as a tool for advancement. The application of quantum principles to epidemiology and health informatics, termed quantum health epidemiology and quantum health informatics, has the potential to radically transform disease surveillance, prediction, modeling, and analysis of health data. However, there is a notable lack of quantum expertise within the public health workforce and educational pipelines. This gap underscores the urgent need for the development of quantum literacy among public health practitioners, leaders, and students to leverage emerging opportunities while addressing risks and ethical considerations. Innovative teaching methods, such as interactive <b>simulations,</b> games, visual models, and other tailored platforms, offer viable solutions for bridging knowledge gaps without the need for advanced physics or mathematics. However, the opportunity to adapt is fleeting as the quantum era in healthcare looms near. It is imperative that public health urgently focuses on updating its educational approaches, workforce strategies, data governance, and organizational culture to proactively meet the challenges of quantum disruption thereby becoming quantum ready.

{{</citation>}}


## quant-ph (1)



### (1/1 | 297/321) Statistical Estimation in the Spiked Tensor Model via the Quantum Approximate Optimization Algorithm (Leo Zhou et al., 2024)

{{<citation>}}

Leo Zhou, Joao Basso, Song Mei. (2024)  
**Statistical Estimation in the Spiked Tensor Model via the Quantum Approximate Optimization Algorithm**
<br/>
<button class="copy-to-clipboard" title="Statistical Estimation in the Spiked Tensor Model via the Quantum Approximate Optimization Algorithm" index=297>
  <span class="copy-to-clipboard-item">Copy Title<span>
</button>
<div class="toast toast-copied toast-index-297 align-items-center text-bg-secondary border-0 position-absolute top-0 end-0" role="alert" aria-live="assertive" aria-atomic="true">
  <div class="d-flex">
    <div class="toast-body">
      Copied!
    </div>
  </div>
</div>

---
Primary Category: quant-ph  
Categories: cs-DS, math-PR, math-ST, quant-ph, quant-ph, stat-ML, stat-TH  
Keyword Score: 20  
Keywords: Simulation, Simulator  
<a type="button" class="btn btn-outline-primary" href="http://arxiv.org/abs/2402.19456v1" target="_blank" >Paper Link</a>
<button type="button" class="btn btn-outline-primary download-pdf" url="https://arxiv.org/pdf/2402.19456v1.pdf" filename="2402.19456v1.pdf">Download PDF</button>

---


**ABSTRACT**  
The quantum approximate optimization algorithm (QAOA) is a general-purpose algorithm for combinatorial optimization. In this paper, we analyze the performance of the QAOA on a statistical estimation problem, namely, the spiked tensor model, which exhibits a statistical-computational gap classically. We prove that the weak recovery threshold of $1$-step QAOA matches that of $1$-step tensor power iteration. Additional heuristic calculations suggest that the weak recovery threshold of $p$-step QAOA matches that of $p$-step tensor power iteration when $p$ is a fixed constant. This further implies that multi-step QAOA with tensor unfolding could achieve, but not surpass, the classical computation threshold $\Theta(n^{(q-2)/4})$ for spiked $q$-tensors. Meanwhile, we characterize the asymptotic overlap distribution for $p$-step QAOA, finding an intriguing sine-Gaussian law verified through <b>simulations.</b> For some $p$ and $q$, the QAOA attains an overlap that is larger by a constant factor than the tensor power iteration overlap. Of independent interest, our proof techniques employ the Fourier transform to handle difficult combinatorial sums, a novel approach differing from prior QAOA analyses on spin-glass models without planted structure.

{{</citation>}}


## math.AP (1)



### (1/1 | 298/321) High multiplicity of positive solutions in a superlinear problem of Moore-Nehari type (Pablo Cubillos et al., 2024)

{{<citation>}}

Pablo Cubillos, Julián López-Gómez, Andrea Tellini. (2024)  
**High multiplicity of positive solutions in a superlinear problem of Moore-Nehari type**
<br/>
<button class="copy-to-clipboard" title="High multiplicity of positive solutions in a superlinear problem of Moore-Nehari type" index=298>
  <span class="copy-to-clipboard-item">Copy Title<span>
</button>
<div class="toast toast-copied toast-index-298 align-items-center text-bg-secondary border-0 position-absolute top-0 end-0" role="alert" aria-live="assertive" aria-atomic="true">
  <div class="d-flex">
    <div class="toast-body">
      Copied!
    </div>
  </div>
</div>

---
Primary Category: math.AP  
Categories: 35J25, 34B08, 35J60, 65N06, 65P30, cs-NA, math-AP, math-CA, math-NA, math.AP  
Keyword Score: 20  
Keywords: Simulation, Simulator  
<a type="button" class="btn btn-outline-primary" href="http://arxiv.org/abs/2402.19084v1" target="_blank" >Paper Link</a>
<button type="button" class="btn btn-outline-primary download-pdf" url="https://arxiv.org/pdf/2402.19084v1.pdf" filename="2402.19084v1.pdf">Download PDF</button>

---


**ABSTRACT**  
In this paper we consider a superlinear one-dimensional elliptic boundary value problem that generalizes the one studied by Moore and Nehari in [43]. Specifically, we deal with piecewise-constant weight functions in front of the nonlinearity with an arbitrary number $\kappa\geq 1$ of vanishing regions. We study, from an analytic and numerical point of view, the number of positive solutions, depending on the value of a parameter $\lambda$ and on $\kappa$. Our main results are twofold. On the one hand, we study analytically the behavior of the solutions, as $\lambda\downarrow-\infty$, in the regions where the weight vanishes. Our result leads us to conjecture the existence of $2^{\kappa+1}-1$ solutions for sufficiently negative $\lambda$. On the other hand, we support such a conjecture with the results of numerical <b>simulations</b> which also shed light on the structure of the global bifurcation diagrams in $\lambda$ and the profiles of positive solutions. Finally, we give additional numerical results suggesting that the same high multiplicity result holds true for a much larger class of weights, also arbitrarily close to situations where there is uniqueness of positive solutions.

{{</citation>}}


## cs.MA (1)



### (1/1 | 299/321) Offline Fictitious Self-Play for Competitive Games (Jingxiao Chen et al., 2024)

{{<citation>}}

Jingxiao Chen, Weiji Xie, Weinan Zhang, Yong yu, Ying Wen. (2024)  
**Offline Fictitious Self-Play for Competitive Games**
<br/>
<button class="copy-to-clipboard" title="Offline Fictitious Self-Play for Competitive Games" index=299>
  <span class="copy-to-clipboard-item">Copy Title<span>
</button>
<div class="toast toast-copied toast-index-299 align-items-center text-bg-secondary border-0 position-absolute top-0 end-0" role="alert" aria-live="assertive" aria-atomic="true">
  <div class="d-flex">
    <div class="toast-body">
      Copied!
    </div>
  </div>
</div>

---
Primary Category: cs.MA  
Categories: cs-AI, cs-GT, cs-LG, cs-MA, cs.MA  
Keyword Score: 20  
Keywords: Offline Reinforcement Learning, Reinforcement Learning  
<a type="button" class="btn btn-outline-primary" href="http://arxiv.org/abs/2403.00841v1" target="_blank" >Paper Link</a>
<button type="button" class="btn btn-outline-primary download-pdf" url="https://arxiv.org/pdf/2403.00841v1.pdf" filename="2403.00841v1.pdf">Download PDF</button>

---


**ABSTRACT**  
<b>Offline</b> <b>Reinforcement</b> <b>Learning</b> (RL) has received significant interest due to its ability to improve policies in previously collected datasets without online interactions. Despite its success in the single-agent setting, <b>offline</b> <b>multi-agent</b> <b>RL</b> remains a challenge, especially in competitive games. Firstly, unaware of the game structure, it is impossible to interact with the opponents and conduct a major learning paradigm, self-play, for competitive games. Secondly, real-world datasets cannot cover all the state and action space in the game, resulting in barriers to identifying Nash equilibrium (NE). To address these issues, this paper introduces Off-FSP, the first practical model-free <b>offline</b> <b>RL</b> <b>algorithm</b> for competitive games. We start by simulating interactions with various opponents by adjusting the weights of the fixed dataset with importance sampling. This technique allows us to learn best responses to different opponents and employ the <b>Offline</b> <b>Self-Play</b> <b>learning</b> framework. In this framework, we further implement Fictitious Self-Play (FSP) to approximate NE. In partially covered real-world datasets, our methods show the potential to approach NE by incorporating any single-agent <b>offline</b> <b>RL</b> <b>method.</b> Experimental results in Leduc Hold'em Poker show that our method significantly improves performances compared with state-of-the-art baselines.

{{</citation>}}


## cs.NE (2)



### (1/2 | 300/321) Spyx: A Library for Just-In-Time Compiled Optimization of Spiking Neural Networks (Kade M. Heckel et al., 2024)

{{<citation>}}

Kade M. Heckel, Thomas Nowotny. (2024)  
**Spyx: A Library for Just-In-Time Compiled Optimization of Spiking Neural Networks**
<br/>
<button class="copy-to-clipboard" title="Spyx: A Library for Just-In-Time Compiled Optimization of Spiking Neural Networks" index=300>
  <span class="copy-to-clipboard-item">Copy Title<span>
</button>
<div class="toast toast-copied toast-index-300 align-items-center text-bg-secondary border-0 position-absolute top-0 end-0" role="alert" aria-live="assertive" aria-atomic="true">
  <div class="d-flex">
    <div class="toast-body">
      Copied!
    </div>
  </div>
</div>

---
Primary Category: cs.NE  
Categories: I-2-5, cs-LG, cs-NE, cs.NE  
Keyword Score: 20  
Keywords: Simulation, Simulator  
<a type="button" class="btn btn-outline-primary" href="http://arxiv.org/abs/2402.18994v1" target="_blank" >Paper Link</a>
<button type="button" class="btn btn-outline-primary download-pdf" url="https://arxiv.org/pdf/2402.18994v1.pdf" filename="2402.18994v1.pdf">Download PDF</button>

---


**ABSTRACT**  
As the role of artificial intelligence becomes increasingly pivotal in modern society, the efficient training and deployment of deep neural networks have emerged as critical areas of focus. Recent advancements in attention-based large neural architectures have spurred the development of AI accelerators, facilitating the training of extensive, multi-billion parameter models. Despite their effectiveness, these powerful networks often incur high execution costs in production environments. Neuromorphic computing, inspired by biological neural processes, offers a promising alternative. By utilizing temporally-sparse computations, Spiking Neural Networks (SNNs) offer to enhance energy efficiency through a reduced and low-power hardware footprint. However, the training of SNNs can be challenging due to their recurrent nature which cannot as easily leverage the massive parallelism of modern AI accelerators. To facilitate the investigation of SNN architectures and dynamics researchers have sought to bridge Python-based deep learning frameworks such as PyTorch or TensorFlow with custom-implemented compute kernels. This paper introduces Spyx, a new and lightweight SNN <b>simulation</b> and optimization library designed in JAX. By pre-staging data in the expansive vRAM of contemporary accelerators and employing extensive JIT compilation, Spyx allows for SNN optimization to be executed as a unified, low-level program on NVIDIA GPUs or Google TPUs. This approach achieves optimal hardware utilization, surpassing the performance of many existing SNN training frameworks while maintaining considerable flexibility.

{{</citation>}}


### (2/2 | 301/321) Airport take-off and landing optimization through genetic algorithms (Fernando Guedan Pecker et al., 2024)

{{<citation>}}

Fernando Guedan Pecker, Cristian Ramirez Atencia. (2024)  
**Airport take-off and landing optimization through genetic algorithms**
<br/>
<button class="copy-to-clipboard" title="Airport take-off and landing optimization through genetic algorithms" index=301>
  <span class="copy-to-clipboard-item">Copy Title<span>
</button>
<div class="toast toast-copied toast-index-301 align-items-center text-bg-secondary border-0 position-absolute top-0 end-0" role="alert" aria-live="assertive" aria-atomic="true">
  <div class="d-flex">
    <div class="toast-body">
      Copied!
    </div>
  </div>
</div>

---
Primary Category: cs.NE  
Categories: cs-NE, cs.NE  
Keyword Score: 10  
Keywords: Fine-tuning  
<a type="button" class="btn btn-outline-primary" href="http://arxiv.org/abs/2402.19222v1" target="_blank" >Paper Link</a>
<button type="button" class="btn btn-outline-primary download-pdf" url="https://arxiv.org/pdf/2402.19222v1.pdf" filename="2402.19222v1.pdf">Download PDF</button>

---


**ABSTRACT**  
This research addresses the crucial issue of pollution from aircraft operations, focusing on optimizing both gate allocation and runway scheduling simultaneously, a novel approach not previously explored. The study presents an innovative genetic algorithm-based method for minimizing pollution from fuel combustion during aircraft take-off and landing at airports. This algorithm uniquely integrates the optimization of both landing gates and take-off/landing runways, considering the correlation between engine operation time and pollutant levels. The approach employs advanced constraint handling techniques to manage the intricate time and resource limitations inherent in airport operations. Additionally, the study conducts a thorough sensitivity analysis of the model, with a particular emphasis on the mutation factor and the type of penalty function, to <b>fine-tune</b> the optimization process. This dual-focus optimization strategy represents a significant advancement in reducing environmental impact in the aviation sector, establishing a new standard for comprehensive and efficient airport operation management.

{{</citation>}}


## eess.SP (1)



### (1/1 | 302/321) Message-Enhanced DeGroot Model (Huisheng Wang et al., 2024)

{{<citation>}}

Huisheng Wang, Zhanjiang Chen, H. Vicky Zhao. (2024)  
**Message-Enhanced DeGroot Model**
<br/>
<button class="copy-to-clipboard" title="Message-Enhanced DeGroot Model" index=302>
  <span class="copy-to-clipboard-item">Copy Title<span>
</button>
<div class="toast toast-copied toast-index-302 align-items-center text-bg-secondary border-0 position-absolute top-0 end-0" role="alert" aria-live="assertive" aria-atomic="true">
  <div class="d-flex">
    <div class="toast-body">
      Copied!
    </div>
  </div>
</div>

---
Primary Category: eess.SP  
Categories: cs-SI, cs-SY, eess-SP, eess-SY, eess.SP  
Keyword Score: 20  
Keywords: Simulation, Simulator  
<a type="button" class="btn btn-outline-primary" href="http://arxiv.org/abs/2402.18867v1" target="_blank" >Paper Link</a>
<button type="button" class="btn btn-outline-primary download-pdf" url="https://arxiv.org/pdf/2402.18867v1.pdf" filename="2402.18867v1.pdf">Download PDF</button>

---


**ABSTRACT**  
Understanding the impact of messages on agents' opinions over social networks is important. However, to our best knowledge, there has been limited quantitative investigation into this phenomenon in the prior works. To address this gap, this paper proposes the Message-Enhanced DeGroot model. The Bounded Brownian Message model provides a quantitative description of the message evolution, jointly considering temporal continuity, randomness, and polarization from mass media theory. The Message-Enhanced DeGroot model, combining the Bounded Brownian Message model with the traditional DeGroot model, quantitatively describes the evolution of agents' opinions under the influence of messages. We theoretically study the probability distribution and statistics of the messages and agents' opinions and quantitatively analyze the impact of messages on opinions. We also conduct <b>simulations</b> to validate our analyses.

{{</citation>}}


## cs.DS (2)



### (1/2 | 303/321) Efficient Processing of Subsequent Densest Subgraph Query (Chia-Yang Hung et al., 2024)

{{<citation>}}

Chia-Yang Hung, Chih-Ya Shen. (2024)  
**Efficient Processing of Subsequent Densest Subgraph Query**
<br/>
<button class="copy-to-clipboard" title="Efficient Processing of Subsequent Densest Subgraph Query" index=303>
  <span class="copy-to-clipboard-item">Copy Title<span>
</button>
<div class="toast toast-copied toast-index-303 align-items-center text-bg-secondary border-0 position-absolute top-0 end-0" role="alert" aria-live="assertive" aria-atomic="true">
  <div class="d-flex">
    <div class="toast-body">
      Copied!
    </div>
  </div>
</div>

---
Primary Category: cs.DS  
Categories: 68W27, cs-DS, cs.DS  
Keyword Score: 13  
Keywords: Graph, Recommendation  
<a type="button" class="btn btn-outline-primary" href="http://arxiv.org/abs/2402.18883v1" target="_blank" >Paper Link</a>
<button type="button" class="btn btn-outline-primary download-pdf" url="https://arxiv.org/pdf/2402.18883v1.pdf" filename="2402.18883v1.pdf">Download PDF</button>

---


**ABSTRACT**  
Dense subgraph extraction is a fundamental problem in <b>graph</b> analysis and data mining, aimed at identifying cohesive and densely connected substructures within a given <b>graph.</b> It plays a crucial role in various domains, including social network analysis, biological network analysis, <b>recommendation</b> systems, and community detection. However, extracting a subgraph with the highest node similarity is a lack of exploration. To address this problem, we studied the Member Selection Problem and extended it with a dynamic constraint variant. By incorporating dynamic constraints, our algorithm can adapt to changing conditions or requirements, allowing for more flexible and personalized subgraph extraction. This approach enables the algorithm to provide tailored solutions that meet specific needs, even in scenarios where constraints may vary over time. We also provide the theoretical analysis to show that our algorithm is 1/3-approximation. Eventually, the experiments show that our algorithm is effective and efficient in tackling the member selection problem with dynamic constraints.

{{</citation>}}


### (2/2 | 304/321) Average-Case Local Computation Algorithms (Amartya Shankha Biswas et al., 2024)

{{<citation>}}

Amartya Shankha Biswas, Ruidi Cao, Edward Pyne, Ronitt Rubinfeld. (2024)  
**Average-Case Local Computation Algorithms**
<br/>
<button class="copy-to-clipboard" title="Average-Case Local Computation Algorithms" index=304>
  <span class="copy-to-clipboard-item">Copy Title<span>
</button>
<div class="toast toast-copied toast-index-304 align-items-center text-bg-secondary border-0 position-absolute top-0 end-0" role="alert" aria-live="assertive" aria-atomic="true">
  <div class="d-flex">
    <div class="toast-body">
      Copied!
    </div>
  </div>
</div>

---
Primary Category: cs.DS  
Categories: cs-DS, cs.DS  
Keyword Score: 3  
Keywords: Graph  
<a type="button" class="btn btn-outline-primary" href="http://arxiv.org/abs/2403.00129v1" target="_blank" >Paper Link</a>
<button type="button" class="btn btn-outline-primary download-pdf" url="https://arxiv.org/pdf/2403.00129v1.pdf" filename="2403.00129v1.pdf">Download PDF</button>

---


**ABSTRACT**  
We initiate the study of Local Computation Algorithms on average case inputs. In the Local Computation Algorithm (LCA) model, we are given probe access to a huge <b>graph,</b> and asked to answer membership queries about some combinatorial structure on the <b>graph,</b> answering each query with sublinear work. For instance, an LCA for the $k$-spanner problem gives access to a sparse subgraph $H\subseteq G$ that preserves distances up to a factor of $k$. We build simple LCAs for this problem assuming the input <b>graph</b> is drawn from the well-studied Erdos-Reyni and Preferential Attachment <b>graph</b> models. In both cases, our spanners achieve size and stretch tradeoffs that are impossible to achieve for general <b>graphs,</b> while having dramatically lower query complexity than worst-case LCAs. Our second result investigates the intersection of LCAs with Local Access Generators (LAGs). Local Access Generators provide efficient query access to a random object, for instance an Erdos Reyni random <b>graph.</b> We explore the natural problem of generating a random <b>graph</b> together with a combinatorial structure on it. We show that this combination can be easier to solve than focusing on each problem by itself, by building a fast, simple algorithm that provides access to an Erdos Reyni random <b>graph</b> together with a maximal independent set.

{{</citation>}}


## cs.LO (5)



### (1/5 | 305/321) Quantitative Assurance and Synthesis of Controllers from Activity Diagrams (Kangfeng Ye et al., 2024)

{{<citation>}}

Kangfeng Ye, Fang Yan, Simos Gerasimou. (2024)  
**Quantitative Assurance and Synthesis of Controllers from Activity Diagrams**
<br/>
<button class="copy-to-clipboard" title="Quantitative Assurance and Synthesis of Controllers from Activity Diagrams" index=305>
  <span class="copy-to-clipboard-item">Copy Title<span>
</button>
<div class="toast toast-copied toast-index-305 align-items-center text-bg-secondary border-0 position-absolute top-0 end-0" role="alert" aria-live="assertive" aria-atomic="true">
  <div class="d-flex">
    <div class="toast-body">
      Copied!
    </div>
  </div>
</div>

---
Primary Category: cs.LO  
Categories: D-2-4; F-3-1; F-3-2; F-4-3, cs-FL, cs-LO, cs-SE, cs.LO  
Keyword Score: 10  
Keywords: Probabilistic Model  
<a type="button" class="btn btn-outline-primary" href="http://arxiv.org/abs/2403.00169v1" target="_blank" >Paper Link</a>
<button type="button" class="btn btn-outline-primary download-pdf" url="https://arxiv.org/pdf/2403.00169v1.pdf" filename="2403.00169v1.pdf">Download PDF</button>

---


**ABSTRACT**  
<b>Probabilistic</b> <b>model</b> checking is a widely used formal verification technique to automatically verify qualitative and quantitative properties for <b>probabilistic</b> <b>models.</b> However, capturing such systems, writing corresponding properties, and verifying them require domain knowledge. This makes it not accessible for researchers and engineers who may not have the required knowledge. Previous studies have extended UML activity diagrams (ADs), developed transformations, and implemented accompanying tools for automation. The research, however, is incomprehensive and not fully open, which makes it hard to be evaluated, extended, adapted, and accessed. In this paper, we propose a comprehensive verification framework for ADs, including a new profile for probability, time, and quality annotations, a semantics interpretation of ADs in three Markov models, and a set of transformation rules from activity diagrams to the PRISM language, supported by PRISM and Storm. Most importantly, we developed algorithms for transformation and implemented them in a tool, called QASCAD, using model-based techniques, for fully automated verification. We evaluated one case study where multiple robots are used for delivery in a hospital and further evaluated six other examples from the literature. With all these together, this work makes noteworthy contributions to the verification of ADs by improving evaluation, extensibility, adaptability, and accessibility.

{{</citation>}}


### (2/5 | 306/321) Rewriting and Inductive Reasoning (Márton Hajdu et al., 2024)

{{<citation>}}

Márton Hajdu, Laura Kovács, Michael Rawson. (2024)  
**Rewriting and Inductive Reasoning**
<br/>
<button class="copy-to-clipboard" title="Rewriting and Inductive Reasoning" index=306>
  <span class="copy-to-clipboard-item">Copy Title<span>
</button>
<div class="toast toast-copied toast-index-306 align-items-center text-bg-secondary border-0 position-absolute top-0 end-0" role="alert" aria-live="assertive" aria-atomic="true">
  <div class="d-flex">
    <div class="toast-body">
      Copied!
    </div>
  </div>
</div>

---
Primary Category: cs.LO  
Categories: cs-LO, cs.LO  
Keyword Score: 10  
Keywords: Reasoning  
<a type="button" class="btn btn-outline-primary" href="http://arxiv.org/abs/2402.19199v1" target="_blank" >Paper Link</a>
<button type="button" class="btn btn-outline-primary download-pdf" url="https://arxiv.org/pdf/2402.19199v1.pdf" filename="2402.19199v1.pdf">Download PDF</button>

---


**ABSTRACT**  
Rewriting techniques based on reduction orderings generate "just enough" consequences to retain first-order completeness. This is ideal for superposition-based first-order theorem proving, but for at least one approach to inductive <b>reasoning</b> we show that we are missing crucial consequences. We therefore extend the superposition calculus with rewriting-based techniques to generate sufficient consequences for automating induction in saturation. When applying our work within the unit-equational fragment, our experiments with the theorem prover Vampire show significant improvements for inductive <b>reasoning.</b>

{{</citation>}}


### (3/5 | 307/321) Program Synthesis in Saturation (Petra Hozzová et al., 2024)

{{<citation>}}

Petra Hozzová, Laura Kovács, Chase Norman, Andrei Voronkov. (2024)  
**Program Synthesis in Saturation**
<br/>
<button class="copy-to-clipboard" title="Program Synthesis in Saturation" index=307>
  <span class="copy-to-clipboard-item">Copy Title<span>
</button>
<div class="toast toast-copied toast-index-307 align-items-center text-bg-secondary border-0 position-absolute top-0 end-0" role="alert" aria-live="assertive" aria-atomic="true">
  <div class="d-flex">
    <div class="toast-body">
      Copied!
    </div>
  </div>
</div>

---
Primary Category: cs.LO  
Categories: cs-LO, cs.LO  
Keyword Score: 10  
Keywords: Reasoning  
<a type="button" class="btn btn-outline-primary" href="http://arxiv.org/abs/2402.18962v1" target="_blank" >Paper Link</a>
<button type="button" class="btn btn-outline-primary download-pdf" url="https://arxiv.org/pdf/2402.18962v1.pdf" filename="2402.18962v1.pdf">Download PDF</button>

---


**ABSTRACT**  
We present an automated <b>reasoning</b> framework for synthesizing recursion-free programs using saturation-based theorem proving. Given a functional specification encoded as a first-order logical formula, we use a first-order theorem prover to both establish validity of this formula and discover program fragments satisfying the specification. As a result, when deriving a proof of program correctness, we also synthesize a program that is correct with respect to the given specification. We describe properties of the calculus that a saturation-based prover capable of synthesis should employ, and extend the superposition calculus in a corresponding way. We implemented our work in the first-order prover Vampire, extending the successful applicability of first-order proving to program synthesis. This is an extended version of an Automated Deduction -- CADE 29 paper with the same title and the same authors.

{{</citation>}}


### (4/5 | 308/321) Getting Saturated with Induction (Márton Hajdu et al., 2024)

{{<citation>}}

Márton Hajdu, Petra Hozzová, Laura Kovács, Giles Reger, Andrei Voronkov. (2024)  
**Getting Saturated with Induction**
<br/>
<button class="copy-to-clipboard" title="Getting Saturated with Induction" index=308>
  <span class="copy-to-clipboard-item">Copy Title<span>
</button>
<div class="toast toast-copied toast-index-308 align-items-center text-bg-secondary border-0 position-absolute top-0 end-0" role="alert" aria-live="assertive" aria-atomic="true">
  <div class="d-flex">
    <div class="toast-body">
      Copied!
    </div>
  </div>
</div>

---
Primary Category: cs.LO  
Categories: cs-LO, cs.LO  
Keyword Score: 10  
Keywords: Reasoning  
<a type="button" class="btn btn-outline-primary" href="http://arxiv.org/abs/2402.18954v1" target="_blank" >Paper Link</a>
<button type="button" class="btn btn-outline-primary download-pdf" url="https://arxiv.org/pdf/2402.18954v1.pdf" filename="2402.18954v1.pdf">Download PDF</button>

---


**ABSTRACT**  
Induction in saturation-based first-order theorem proving is a new exciting direction in the automation of inductive <b>reasoning.</b> In this paper we survey our work on integrating induction directly into the saturation-based proof search framework of first-order theorem proving. We describe our induction inference rules proving properties with inductively defined datatypes and integers. We also present additional <b>reasoning</b> heuristics for strengthening inductive <b>reasoning,</b> as well as for using induction hypotheses and recursive function definitions for guiding induction. We present exhaustive experimental results demonstrating the practical impact of our approach as implemented within Vampire. This is an extended version of a Principles of Systems Design 2022 paper with the same title and the same authors.

{{</citation>}}


### (5/5 | 309/321) Invariant Checking for SMT-based Systems with Quantifiers (Gianluca Redondi et al., 2024)

{{<citation>}}

Gianluca Redondi, Alessandro Cimatti, Alberto Griggio, Kenneth McMillan. (2024)  
**Invariant Checking for SMT-based Systems with Quantifiers**
<br/>
<button class="copy-to-clipboard" title="Invariant Checking for SMT-based Systems with Quantifiers" index=309>
  <span class="copy-to-clipboard-item">Copy Title<span>
</button>
<div class="toast toast-copied toast-index-309 align-items-center text-bg-secondary border-0 position-absolute top-0 end-0" role="alert" aria-live="assertive" aria-atomic="true">
  <div class="d-flex">
    <div class="toast-body">
      Copied!
    </div>
  </div>
</div>

---
Primary Category: cs.LO  
Categories: cs-LO, cs.LO  
Keyword Score: 3  
Keywords: Benchmarking  
<a type="button" class="btn btn-outline-primary" href="http://arxiv.org/abs/2402.19028v1" target="_blank" >Paper Link</a>
<button type="button" class="btn btn-outline-primary download-pdf" url="https://arxiv.org/pdf/2402.19028v1.pdf" filename="2402.19028v1.pdf">Download PDF</button>

---


**ABSTRACT**  
This paper addresses the problem of checking invariant properties for a large class of symbolic transition systems, defined by a combination of SMT theories and quantifiers. State variables can be functions from an uninterpreted sort (finite, but unbounded) to an interpreted sort, such as the the integers under the theory of linear arithmetic. This formalism is very expressive and can be used for modeling parameterized systems, array-manipulating programs, and more. We propose two algorithms for finding universal inductive invariants for such systems. The first algorithm combines an IC3-style loop with a form of implicit predicate abstraction to construct an invariant in an incremental manner. The second algorithm constructs an under-approximation of the original problem, and searches for a formula which is an inductive invariant for this case; then, the invariant is generalized to the original case, and checked with a portfolio of techniques. We have implemented the two algorithms and conducted an extensive experimental evaluation, considering various <b>benchmarks</b> and different tools from the literature. As far as we know, our method is the first capable of handling in a large class of systems in a uniform way. The experiment shows that both algorithms are competitive with the state of the art.

{{</citation>}}


## math.OC (2)



### (1/2 | 310/321) Analysis of Kernel Mirror Prox for Measure Optimization (Pavel Dvurechensky et al., 2024)

{{<citation>}}

Pavel Dvurechensky, Jia-Jie Zhu. (2024)  
**Analysis of Kernel Mirror Prox for Measure Optimization**
<br/>
<button class="copy-to-clipboard" title="Analysis of Kernel Mirror Prox for Measure Optimization" index=310>
  <span class="copy-to-clipboard-item">Copy Title<span>
</button>
<div class="toast toast-copied toast-index-310 align-items-center text-bg-secondary border-0 position-absolute top-0 end-0" role="alert" aria-live="assertive" aria-atomic="true">
  <div class="d-flex">
    <div class="toast-body">
      Copied!
    </div>
  </div>
</div>

---
Primary Category: math.OC  
Categories: 90C25, 90C30, 68Q25,, cs-LG, math-OC, math.OC  
Keyword Score: 10  
Keywords: Discrete Time, Discrete Time  
<a type="button" class="btn btn-outline-primary" href="http://arxiv.org/abs/2403.00147v1" target="_blank" >Paper Link</a>
<button type="button" class="btn btn-outline-primary download-pdf" url="https://arxiv.org/pdf/2403.00147v1.pdf" filename="2403.00147v1.pdf">Download PDF</button>

---


**ABSTRACT**  
By choosing a suitable function space as the dual to the non-negative measure cone, we study in a unified framework a class of functional saddle-point optimization problems, which we term the Mixed Functional Nash Equilibrium (MFNE), that underlies several existing machine learning algorithms, such as implicit generative models, distributionally robust optimization (DRO), and Wasserstein barycenters. We model the saddle-point optimization dynamics as an interacting Fisher-Rao-RKHS gradient flow when the function space is chosen as a reproducing kernel Hilbert space (RKHS). As a <b>discrete</b> <b>time</b> counterpart, we propose a primal-dual kernel mirror prox (KMP) algorithm, which uses a dual step in the RKHS, and a primal entropic mirror prox step. We then provide a unified convergence analysis of KMP in an infinite-dimensional setting for this class of MFNE problems, which establishes a convergence rate of $O(1/N)$ in the deterministic case and $O(1/\sqrt{N})$ in the stochastic case, where $N$ is the iteration counter. As a case study, we apply our analysis to DRO, providing algorithmic guarantees for DRO robustness and convergence.

{{</citation>}}


### (2/2 | 311/321) Deep Reinforcement Learning: A Convex Optimization Approach (Ather Gattami, 2024)

{{<citation>}}

Ather Gattami. (2024)  
**Deep Reinforcement Learning: A Convex Optimization Approach**
<br/>
<button class="copy-to-clipboard" title="Deep Reinforcement Learning: A Convex Optimization Approach" index=311>
  <span class="copy-to-clipboard-item">Copy Title<span>
</button>
<div class="toast toast-copied toast-index-311 align-items-center text-bg-secondary border-0 position-absolute top-0 end-0" role="alert" aria-live="assertive" aria-atomic="true">
  <div class="d-flex">
    <div class="toast-body">
      Copied!
    </div>
  </div>
</div>

---
Primary Category: math.OC  
Categories: cs-LG, math-OC, math.OC  
Keyword Score: 10  
Keywords: Reinforcement Learning  
<a type="button" class="btn btn-outline-primary" href="http://arxiv.org/abs/2402.19212v1" target="_blank" >Paper Link</a>
<button type="button" class="btn btn-outline-primary download-pdf" url="https://arxiv.org/pdf/2402.19212v1.pdf" filename="2402.19212v1.pdf">Download PDF</button>

---


**ABSTRACT**  
In this paper, we consider <b>reinforcement</b> <b>learning</b> of nonlinear systems with continuous state and action spaces. We present an episodic learning algorithm, where we for each episode use convex optimization to find a two-layer neural network approximation of the optimal $Q$-function. The convex optimization approach guarantees that the weights calculated at each episode are optimal, with respect to the given sampled states and actions of the current episode. For stable nonlinear systems, we show that the algorithm converges and that the converging parameters of the trained neural network can be made arbitrarily close to the optimal neural network parameters. In particular, if the regularization parameter is $\rho$ and the time horizon is $T$, then the parameters of the trained neural network converge to $w$, where the distance between $w$ from the optimal parameters $w^\star$ is bounded by $\mathcal{O}(\rho T^{-1})$. That is, when the number of episodes goes to infinity, there exists a constant $C$ such that \[\|w-w^\star\| \le C\cdot\frac{\rho}{T}.\] In particular, our algorithm converges arbitrarily close to the optimal neural network parameters as the time horizon increases or as the regularization parameter decreases.

{{</citation>}}


## stat.ML (1)



### (1/1 | 312/321) Listening to the Noise: Blind Denoising with Gibbs Diffusion (David Heurtel-Depeiges et al., 2024)

{{<citation>}}

David Heurtel-Depeiges, Charles C. Margossian, Ruben Ohana, Bruno Régaldo-Saint Blancard. (2024)  
**Listening to the Noise: Blind Denoising with Gibbs Diffusion**
<br/>
<button class="copy-to-clipboard" title="Listening to the Noise: Blind Denoising with Gibbs Diffusion" index=312>
  <span class="copy-to-clipboard-item">Copy Title<span>
</button>
<div class="toast toast-copied toast-index-312 align-items-center text-bg-secondary border-0 position-absolute top-0 end-0" role="alert" aria-live="assertive" aria-atomic="true">
  <div class="d-flex">
    <div class="toast-body">
      Copied!
    </div>
  </div>
</div>

---
Primary Category: stat.ML  
Categories: astro-ph-CO, cs-CV, cs-LG, eess-SP, stat-ML, stat.ML  
Keyword Score: 10  
Keywords: Diffusion Model  
<a type="button" class="btn btn-outline-primary" href="http://arxiv.org/abs/2402.19455v1" target="_blank" >Paper Link</a>
<button type="button" class="btn btn-outline-primary download-pdf" url="https://arxiv.org/pdf/2402.19455v1.pdf" filename="2402.19455v1.pdf">Download PDF</button>

---


**ABSTRACT**  
In recent years, denoising problems have become intertwined with the development of deep generative models. In particular, <b>diffusion</b> <b>models</b> are trained like denoisers, and the distribution they model coincide with denoising priors in the Bayesian picture. However, denoising through <b>diffusion-based</b> <b>posterior</b> sampling requires the noise level and covariance to be known, preventing blind denoising. We overcome this limitation by introducing Gibbs <b>Diffusion</b> <b>(GDiff),</b> a general methodology addressing posterior sampling of both the signal and the noise parameters. Assuming arbitrary parametric Gaussian noise, we develop a Gibbs algorithm that alternates sampling steps from a conditional <b>diffusion</b> <b>model</b> trained to map the signal prior to the family of noise distributions, and a Monte Carlo sampler to infer the noise parameters. Our theoretical analysis highlights potential pitfalls, guides diagnostic usage, and quantifies errors in the Gibbs stationary distribution caused by the <b>diffusion</b> <b>model.</b> We showcase our method for 1) blind denoising of natural images involving colored noises with unknown amplitude and spectral index, and 2) a cosmology problem, namely the analysis of cosmic microwave background data, where Bayesian inference of "noise" parameters means constraining models of the evolution of the Universe.

{{</citation>}}


## math.NA (3)



### (1/3 | 313/321) Fractional material derivative: pointwise representation and a finite volume numerical scheme (Łukasz Płociniczak et al., 2024)

{{<citation>}}

Łukasz Płociniczak, Marek A. Teuerle. (2024)  
**Fractional material derivative: pointwise representation and a finite volume numerical scheme**
<br/>
<button class="copy-to-clipboard" title="Fractional material derivative: pointwise representation and a finite volume numerical scheme" index=313>
  <span class="copy-to-clipboard-item">Copy Title<span>
</button>
<div class="toast toast-copied toast-index-313 align-items-center text-bg-secondary border-0 position-absolute top-0 end-0" role="alert" aria-live="assertive" aria-atomic="true">
  <div class="d-flex">
    <div class="toast-body">
      Copied!
    </div>
  </div>
</div>

---
Primary Category: math.NA  
Categories: cs-NA, math-NA, math.NA  
Keyword Score: 10  
Keywords: Continuous Time, Continuous Time  
<a type="button" class="btn btn-outline-primary" href="http://arxiv.org/abs/2402.19015v1" target="_blank" >Paper Link</a>
<button type="button" class="btn btn-outline-primary download-pdf" url="https://arxiv.org/pdf/2402.19015v1.pdf" filename="2402.19015v1.pdf">Download PDF</button>

---


**ABSTRACT**  
The fractional material derivative appears as the fractional operator that governs the dynamics of the scaling limits of L\'evy walks - a stochastic process that originates from the famous <b>continuous-time</b> <b>random</b> walks. It is usually defined as the Fourier-Laplace multiplier, therefore, it can be thought of as a pseudo-differential operator. In this paper, we show that there exists a local representation in time and space, pointwise, of the fractional material derivative. This allows us to define it on a space of locally integrable functions which is larger than the original one in which Fourier and Laplace transform exist as functions. We consider several typical differential equations involving the fractional material derivative and provide conditions for their solutions to exist. In some cases, the analytical solution can be found. For the general initial value problem, we devise a finite volume method and prove its stability, convergence, and conservation of probability. Numerical illustrations verify our analytical findings. Moreover, our numerical experiments show superiority in the computation time of the proposed numerical scheme over a Monte Carlo method applied to the problem of probability density function's derivation.

{{</citation>}}


### (2/3 | 314/321) Penalty-free discontinuous Galerkin method (Jan Jaśkowiec et al., 2024)

{{<citation>}}

Jan Jaśkowiec, N. Sukumar. (2024)  
**Penalty-free discontinuous Galerkin method**
<br/>
<button class="copy-to-clipboard" title="Penalty-free discontinuous Galerkin method" index=314>
  <span class="copy-to-clipboard-item">Copy Title<span>
</button>
<div class="toast toast-copied toast-index-314 align-items-center text-bg-secondary border-0 position-absolute top-0 end-0" role="alert" aria-live="assertive" aria-atomic="true">
  <div class="d-flex">
    <div class="toast-body">
      Copied!
    </div>
  </div>
</div>

---
Primary Category: math.NA  
Categories: cs-NA, math-NA, math.NA  
Keyword Score: 3  
Keywords: Benchmarking  
<a type="button" class="btn btn-outline-primary" href="http://arxiv.org/abs/2403.00125v1" target="_blank" >Paper Link</a>
<button type="button" class="btn btn-outline-primary download-pdf" url="https://arxiv.org/pdf/2403.00125v1.pdf" filename="2403.00125v1.pdf">Download PDF</button>

---


**ABSTRACT**  
In this paper, we present a new high-order discontinuous Galerkin (DG) method, in which neither a penalty parameter nor a stabilization parameter is needed. We refer to this method as penalty-free DG (\PFDG). In this method, the trial and test functions belong to the broken Sobolev space, in which the functions are in general discontinuous on the mesh skeleton and do not meet the Dirichlet boundary conditions. However, a subset can be distinguished in this space, where the functions are continuous and satisfy the Dirichlet boundary conditions, and this subset is called admissible. The trial solution is chosen to lie in an \emph{augmented} admissible subset, in which a small violation of the continuity condition is permitted. This subset is constructed by applying special augmented constraints to the linear combination of finite element basis functions. In this approach, all the advantages of the DG method are retained without the necessity of using stability parameters or numerical fluxes. Several <b>benchmark</b> problems in two dimensions (Poisson equation, linear elasticity, hyperelasticity, and biharmonic equation) on polygonal (triangles, quadrilateral and weakly convex polygons) meshes as well as a three-dimensional Poisson problem on hexahedral meshes are considered. Numerical results are presented that affirm the sound accuracy and optimal convergence of the method in the $L^2$ norm and the energy seminorm.

{{</citation>}}


### (3/3 | 315/321) An asymptotic-preserving method for the three-temperature radiative transfer model (Ruo Li et al., 2024)

{{<citation>}}

Ruo Li, Weiming Li, Shengtong Liang, Yuehan Shao, Min Tang, Yanli Wang. (2024)  
**An asymptotic-preserving method for the three-temperature radiative transfer model**
<br/>
<button class="copy-to-clipboard" title="An asymptotic-preserving method for the three-temperature radiative transfer model" index=315>
  <span class="copy-to-clipboard-item">Copy Title<span>
</button>
<div class="toast toast-copied toast-index-315 align-items-center text-bg-secondary border-0 position-absolute top-0 end-0" role="alert" aria-live="assertive" aria-atomic="true">
  <div class="d-flex">
    <div class="toast-body">
      Copied!
    </div>
  </div>
</div>

---
Primary Category: math.NA  
Categories: cs-NA, math-MP, math-NA, math-ph, math.NA  
Keyword Score: 3  
Keywords: Benchmarking  
<a type="button" class="btn btn-outline-primary" href="http://arxiv.org/abs/2402.19191v1" target="_blank" >Paper Link</a>
<button type="button" class="btn btn-outline-primary download-pdf" url="https://arxiv.org/pdf/2402.19191v1.pdf" filename="2402.19191v1.pdf">Download PDF</button>

---


**ABSTRACT**  
We present an asymptotic-preserving (AP) numerical method for solving the three-temperature radiative transfer model, which holds significant importance in inertial confinement fusion. A carefully designedsplitting method is developed that can provide a general framework of extending AP schemes for the gray radiative transport equation to the more complex three-temperature radiative transfer model. The proposed scheme captures two important limiting models: the three-temperature radiation diffusion equation (3TRDE) when opacity approaches infinity and the two-temperature limit when the ion-electron coupling coefficient goes to infinity. We have rigorously demonstrated the AP property and energy conservation characteristics of the proposed scheme and its efficiency has been validated through a series of <b>benchmark</b> tests in the numerical part.

{{</citation>}}


## cs.GR (1)



### (1/1 | 316/321) 3D Gaussian Model for Animation and Texturing (Xiangzhi Eric Wang et al., 2024)

{{<citation>}}

Xiangzhi Eric Wang, Zackary P. T. Sin. (2024)  
**3D Gaussian Model for Animation and Texturing**
<br/>
<button class="copy-to-clipboard" title="3D Gaussian Model for Animation and Texturing" index=316>
  <span class="copy-to-clipboard-item">Copy Title<span>
</button>
<div class="toast toast-copied toast-index-316 align-items-center text-bg-secondary border-0 position-absolute top-0 end-0" role="alert" aria-live="assertive" aria-atomic="true">
  <div class="d-flex">
    <div class="toast-body">
      Copied!
    </div>
  </div>
</div>

---
Primary Category: cs.GR  
Categories: cs-GR, cs.GR  
Keyword Score: 5  
Keywords: Geometry  
<a type="button" class="btn btn-outline-primary" href="http://arxiv.org/abs/2402.19441v1" target="_blank" >Paper Link</a>
<button type="button" class="btn btn-outline-primary download-pdf" url="https://arxiv.org/pdf/2402.19441v1.pdf" filename="2402.19441v1.pdf">Download PDF</button>

---


**ABSTRACT**  
3D Gaussian Splatting has made a marked impact on neural rendering by achieving impressive fidelity and performance. Despite this achievement, however, it is not readily applicable to developing interactive applications. Real-time applications like XR apps and games require functions such as animation, UV-mapping, and model editing simultaneously manipulated through the usage of a 3D model. We propose a modeling that is analogous to typical 3D models, which we call 3D Gaussian Model (3DGM); it provides a manipulatable proxy for novel animation and texture transfer. By binding the 3D Gaussians in texture space and re-projecting them back to world space through implicit shell mapping, we show how our 3D modeling can serve as a valid rendering methodology for interactive applications. It is further noted that recently, 3D mesh reconstruction works have been able to produce high-quality mesh for rendering. Our work, on the other hand, only requires an approximated <b>geometry</b> for rendering an object in high fidelity. Applicationwise, we will show that our proxy-based 3DGM is capable of driving novel animation without animated training data and texture transferring via UV mapping of the 3D Gaussians. We believe the result indicates the potential of our work for enabling interactive applications for 3D Gaussian Splatting.

{{</citation>}}


## cs.CC (1)



### (1/1 | 317/321) On Efficient Computation of DiRe Committees (Kunal Relia, 2024)

{{<citation>}}

Kunal Relia. (2024)  
**On Efficient Computation of DiRe Committees**
<br/>
<button class="copy-to-clipboard" title="On Efficient Computation of DiRe Committees" index=317>
  <span class="copy-to-clipboard-item">Copy Title<span>
</button>
<div class="toast toast-copied toast-index-317 align-items-center text-bg-secondary border-0 position-absolute top-0 end-0" role="alert" aria-live="assertive" aria-atomic="true">
  <div class="d-flex">
    <div class="toast-body">
      Copied!
    </div>
  </div>
</div>

---
Primary Category: cs.CC  
Categories: cs-CC, cs-CY, cs-GT, cs.CC  
Keyword Score: 3  
Keywords: Graph  
<a type="button" class="btn btn-outline-primary" href="http://arxiv.org/abs/2402.19365v1" target="_blank" >Paper Link</a>
<button type="button" class="btn btn-outline-primary download-pdf" url="https://arxiv.org/pdf/2402.19365v1.pdf" filename="2402.19365v1.pdf">Download PDF</button>

---


**ABSTRACT**  
Consider a committee election consisting of (i) a set of candidates who are divided into arbitrary groups each of size \emph{at most} two and a diversity constraint that stipulates the selection of \emph{at least} one candidate from each group and (ii) a set of voters who are divided into arbitrary populations each approving \emph{at most} two candidates and a representation constraint that stipulates the selection of \emph{at least} one candidate from each population who has a non-null set of approved candidates. The DiRe (Diverse + Representative) committee feasibility problem (a.k.a. the minimum vertex cover problem on unweighted undirected <b>graphs)</b> concerns the determination of the smallest size committee that satisfies the given constraints. Here, for this problem, we discover an unconditional deterministic polynomial-time algorithm that is an amalgamation of maximum matching, breadth-first search, maximal matching, and local minimization.

{{</citation>}}


## math.CO (3)



### (1/3 | 318/321) Oriented trees in $O(k \sqrt{k})$-chromatic digraphs, a subquadratic bound for Burr's conjecture (Stéphane Bessy et al., 2024)

{{<citation>}}

Stéphane Bessy, Daniel Gonçalves, Amadeus Reinald. (2024)  
**Oriented trees in $O(k \sqrt{k})$-chromatic digraphs, a subquadratic bound for Burr's conjecture**
<br/>
<button class="copy-to-clipboard" title="Oriented trees in $O(k \sqrt{k})$-chromatic digraphs, a subquadratic bound for Burr's conjecture" index=318>
  <span class="copy-to-clipboard-item">Copy Title<span>
</button>
<div class="toast toast-copied toast-index-318 align-items-center text-bg-secondary border-0 position-absolute top-0 end-0" role="alert" aria-live="assertive" aria-atomic="true">
  <div class="d-flex">
    <div class="toast-body">
      Copied!
    </div>
  </div>
</div>

---
Primary Category: math.CO  
Categories: 05C20, cs-DM, math-CO, math.CO  
Keyword Score: 3  
Keywords: Graph  
<a type="button" class="btn btn-outline-primary" href="http://arxiv.org/abs/2402.19351v1" target="_blank" >Paper Link</a>
<button type="button" class="btn btn-outline-primary download-pdf" url="https://arxiv.org/pdf/2402.19351v1.pdf" filename="2402.19351v1.pdf">Download PDF</button>

---


**ABSTRACT**  
In 1980, Burr conjectured that every directed <b>graph</b> with chromatic number $2k-2$ contains any oriented tree of order $k$ as a subdigraph. Burr showed that chromatic number $(k-1)^2$ suffices, which was improved in 2013 to $\frac{k^2}{2} - \frac{k}{2} + 1$ by Addario-Berry et al. We give the first subquadratic bound for Burr's conjecture, by showing that every directed <b>graph</b> with chromatic number $8\sqrt{\frac{2}{15}} k \sqrt{k} + O(k)$ contains any oriented tree of order $k$. Moreover, we provide improved bounds of $\sqrt{\frac{4}{3}} k \sqrt{k}+O(k)$ for arborescences, and $(b-1)(k-3)+3$ for paths on $b$ blocks, with $b\ge 2$.

{{</citation>}}


### (2/3 | 319/321) Broadcast independence number of oriented circulant graphs (Abdelamin Laouar et al., 2024)

{{<citation>}}

Abdelamin Laouar, Isma Bouchemakh, Eric Sopena. (2024)  
**Broadcast independence number of oriented circulant graphs**
<br/>
<button class="copy-to-clipboard" title="Broadcast independence number of oriented circulant graphs" index=319>
  <span class="copy-to-clipboard-item">Copy Title<span>
</button>
<div class="toast toast-copied toast-index-319 align-items-center text-bg-secondary border-0 position-absolute top-0 end-0" role="alert" aria-live="assertive" aria-atomic="true">
  <div class="d-flex">
    <div class="toast-body">
      Copied!
    </div>
  </div>
</div>

---
Primary Category: math.CO  
Categories: 05C12, 05C69, cs-DM, math-CO, math.CO  
Keyword Score: 3  
Keywords: Graph  
<a type="button" class="btn btn-outline-primary" href="http://arxiv.org/abs/2402.19234v1" target="_blank" >Paper Link</a>
<button type="button" class="btn btn-outline-primary download-pdf" url="https://arxiv.org/pdf/2402.19234v1.pdf" filename="2402.19234v1.pdf">Download PDF</button>

---


**ABSTRACT**  
In 2001, D. Erwin \cite{Erw01} introduced in his Ph.D. dissertation the notion of broadcast independence in unoriented <b>graphs.</b> Since then, some results but not many, are published on this notion, including research work on the broadcast independence number of unoriented circulant <b>graphs</b> \cite{LBS23}. In this paper, we are focused in the same parameter but of the class of oriented circulant <b>graphs.</b> An independent broadcast on an oriented <b>graph</b> $\overrightarrow{G}$ is a function $f: V\longrightarrow \{0,\ldots,\diam(\overrightarrow{G})\}$ such that $(i)$ $f(v)\leq e(v)$ for every vertex $v\in V(\overrightarrow{G})$, where $\diam(\overrightarrow{G})$ denotes the diameter of $\overrightarrow{G}$ and $e(v)$ the eccentricity of vertex $v$, and $(ii)$ $d_{\overrightarrow{G}}(u,v) > f(u)$ for every distinct vertices $u$, $v$ with $f(u)$, $f(v)>0$, where $d_{\overrightarrow{G}}(u,v)$ denotes the length of a shortest oriented path from $u$ to $v$. The broadcast independence number $\beta_b(\overrightarrow{G})$ of $\overrightarrow{G}$ is then the maximum value of $\sum_{v \in V} f(v)$, taken over all independent broadcasts on $\overrightarrow{G}$. The goal of this paper is to study the properties of independent broadcasts of oriented circulant <b>graphs</b> $\overrightarrow{C}(n;1,a)$, for any integers $n$ and $a$ with $n>|a|\geq 1$ and $a \notin \{1,n-1\}$. Then, we give some bounds and some exact values for the number $\beta_b(\overrightarrow{C}(n;1,a))$.

{{</citation>}}


### (3/3 | 320/321) Graph Burning: Bounds and Hardness (Dhanyamol Antony et al., 2024)

{{<citation>}}

Dhanyamol Antony, Anita Das, Shirish Gosavi, Dalu Jacob, Shashanka Kulamarva. (2024)  
**Graph Burning: Bounds and Hardness**
<br/>
<button class="copy-to-clipboard" title="Graph Burning: Bounds and Hardness" index=320>
  <span class="copy-to-clipboard-item">Copy Title<span>
</button>
<div class="toast toast-copied toast-index-320 align-items-center text-bg-secondary border-0 position-absolute top-0 end-0" role="alert" aria-live="assertive" aria-atomic="true">
  <div class="d-flex">
    <div class="toast-body">
      Copied!
    </div>
  </div>
</div>

---
Primary Category: math.CO  
Categories: 05C12, 68Q17, 05C85, 05C38, 05C05, cs-DM, math-CO, math.CO  
Keyword Score: 3  
Keywords: Graph  
<a type="button" class="btn btn-outline-primary" href="http://arxiv.org/abs/2402.18984v1" target="_blank" >Paper Link</a>
<button type="button" class="btn btn-outline-primary download-pdf" url="https://arxiv.org/pdf/2402.18984v1.pdf" filename="2402.18984v1.pdf">Download PDF</button>

---


**ABSTRACT**  
The burning number of a <b>graph</b> $G$, denoted by $b(G)$, is the minimum number of steps required to burn all the vertices of a <b>graph</b> where in each step the existing fire spreads to all the adjacent vertices and one additional vertex can be burned as a new fire source. In this paper, we study the burning number problem both from an algorithmic and a structural point of view. The decision problem of computing the burning number of an input <b>graph</b> is known to be NP-Complete for trees with maximum degree at most three and interval <b>graphs.</b> Here, we prove that this problem is NP-Complete even when restricted to connected proper interval <b>graphs</b> and connected cubic <b>graphs.</b> The well-known burning number conjecture asserts that all the vertices of any <b>graph</b> of order $n$ can be burned in $\lceil \sqrt{n}~\rceil$ steps. In line with this conjecture, upper and lower bounds of $b(G)$ are well-studied for various special <b>graph</b> classes. Here, we provide an improved upper bound for the burning number of connected $P_k$-free <b>graphs</b> and show that the bound is tight up to an additive constant $1$. Finally, we study two variants of the problem, namely edge burning (only edges are burned) and total burning (both vertices and edges are burned). In particular, we establish their relationship with the burning number problem and evaluate the complexity of these variants.

{{</citation>}}


## cs.DM (1)



### (1/1 | 321/321) More algorithmic results for problems of spread of influence in edge-weighted graphs with and without incentives (Siavash Askari et al., 2024)

{{<citation>}}

Siavash Askari, Manouchehr Zaker. (2024)  
**More algorithmic results for problems of spread of influence in edge-weighted graphs with and without incentives**
<br/>
<button class="copy-to-clipboard" title="More algorithmic results for problems of spread of influence in edge-weighted graphs with and without incentives" index=321>
  <span class="copy-to-clipboard-item">Copy Title<span>
</button>
<div class="toast toast-copied toast-index-321 align-items-center text-bg-secondary border-0 position-absolute top-0 end-0" role="alert" aria-live="assertive" aria-atomic="true">
  <div class="d-flex">
    <div class="toast-body">
      Copied!
    </div>
  </div>
</div>

---
Primary Category: cs.DM  
Categories: 05C69, 05C85, 68Q25, 91D30, cs-DM, cs.DM, math-CO  
Keyword Score: 3  
Keywords: Graph  
<a type="button" class="btn btn-outline-primary" href="http://arxiv.org/abs/2402.19257v1" target="_blank" >Paper Link</a>
<button type="button" class="btn btn-outline-primary download-pdf" url="https://arxiv.org/pdf/2402.19257v1.pdf" filename="2402.19257v1.pdf">Download PDF</button>

---


**ABSTRACT**  
Many phenomena in real world social networks are interpreted as spread of influence between activated and non-activated network elements. These phenomena are formulated by combinatorial <b>graphs,</b> where vertices represent the elements and edges represent social ties between elements. A main problem is to study important subsets of elements (target sets or dynamic monopolies) such that their activation spreads to the entire network. In edge-weighted networks the influence between two adjacent vertices depends on the weight of their edge. In models with incentives, the main problem is to minimize total amount of incentives (called optimal target vectors) which can be offered to vertices such that some vertices are activated and their activation spreads to the whole network. Algorithmic study of target sets and vectors is a hot research field. We prove an inapproximability result for optimal target sets in edge weighted networks even for complete <b>graphs.</b> Some other hardness and polynomial time results are presented for optimal target vectors and degenerate threshold assignments in edge-weighted networks.

{{</citation>}}
