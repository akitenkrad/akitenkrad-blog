---
draft: false
title: "arXiv @ 2023.11.10"
date: 2023-11-10
author: "akitenkrad"
description: ""
tags: ["arXiv", "Published:2023"]
menu:
  sidebar:
    name: "arXiv @ 2023.11.10"
    identifier: arxiv_20231110
    parent: 202311_arxiv
    weight: 10
math: true
---

<figure style="border:none; width:100%; display:flex; justify-content: center">
    <iframe src="pie.html" width=900 height=620 style="border:none"></iframe>
</figure>


## Primary Categories

- [cs.CR (4)](#cscr-4)
- [cs.IT (2)](#csit-2)
- [cs.CL (32)](#cscl-32)
- [cs.HC (2)](#cshc-2)
- [cs.LG (21)](#cslg-21)
- [cs.CV (13)](#cscv-13)
- [cs.IR (5)](#csir-5)
- [cs.AR (3)](#csar-3)
- [cs.RO (2)](#csro-2)
- [eess.SY (1)](#eesssy-1)
- [eess.AS (1)](#eessas-1)
- [cs.AI (7)](#csai-7)
- [eess.IV (3)](#eessiv-3)
- [cs.DB (2)](#csdb-2)
- [cs.MA (1)](#csma-1)
- [cs.NI (1)](#csni-1)
- [cs.SE (4)](#csse-4)
- [cs.CY (1)](#cscy-1)
- [physics.optics (1)](#physicsoptics-1)
- [q-fin.PM (1)](#q-finpm-1)
- [cond-mat.mtrl-sci (1)](#cond-matmtrl-sci-1)

## cs.CR (4)



### (1/108) Rust for Embedded Systems: Current State, Challenges and Open Problems (Ayushi Sharma et al., 2023)

{{<citation>}}

Ayushi Sharma, Shashank Sharma, Santiago Torres-Arias, Aravind Machiry. (2023)  
**Rust for Embedded Systems: Current State, Challenges and Open Problems**  

---
Primary Category: cs.CR  
Categories: cs-CR, cs-SE, cs.CR  
Keywords: Security  
[Paper Link](http://arxiv.org/abs/2311.05063v1)  

---


**ABSTRACT**  
Embedded software is used in safety-critical systems such as medical devices and autonomous vehicles, where software defects, including security vulnerabilities, have severe consequences. Most embedded codebases are developed in unsafe languages, specifically C/C++, and are riddled with memory safety vulnerabilities. To prevent such vulnerabilities, RUST, a performant memory-safe systems language, provides an optimal choice for developing embedded software. RUST interoperability enables developing RUST applications on top of existing C codebases. Despite this, even the most resourceful organizations continue to develop embedded software in C/C++. This paper performs the first systematic study to holistically understand the current state and challenges of using RUST for embedded systems. Our study is organized across three research questions. We collected a dataset of 2,836 RUST embedded software spanning various categories and 5 Static Application Security Testing ( SAST) tools. We performed a systematic analysis of our dataset and surveys with 225 developers to investigate our research questions. We found that existing RUST software support is inadequate, SAST tools cannot handle certain features of RUST embedded software, resulting in failures, and the prevalence of advanced types in existing RUST software makes it challenging to engineer interoperable code. In addition, we found various challenges faced by developers in using RUST for embedded systems development.

{{</citation>}}


### (2/108) DEMASQ: Unmasking the ChatGPT Wordsmith (Kavita Kumari et al., 2023)

{{<citation>}}

Kavita Kumari, Alessandro Pegoraro, Hossein Fereidooni, Ahmad-Reza Sadeghi. (2023)  
**DEMASQ: Unmasking the ChatGPT Wordsmith**  

---
Primary Category: cs.CR  
Categories: cs-CR, cs-LG, cs.CR  
Keywords: AI, ChatGPT, GPT, Language Model  
[Paper Link](http://arxiv.org/abs/2311.05019v1)  

---


**ABSTRACT**  
The potential misuse of ChatGPT and other Large Language Models (LLMs) has raised concerns regarding the dissemination of false information, plagiarism, academic dishonesty, and fraudulent activities. Consequently, distinguishing between AI-generated and human-generated content has emerged as an intriguing research topic. However, current text detection methods lack precision and are often restricted to specific tasks or domains, making them inadequate for identifying content generated by ChatGPT. In this paper, we propose an effective ChatGPT detector named DEMASQ, which accurately identifies ChatGPT-generated content. Our method addresses two critical factors: (i) the distinct biases in text composition observed in human- and machine-generated content and (ii) the alterations made by humans to evade previous detection methods. DEMASQ is an energy-based detection model that incorporates novel aspects, such as (i) optimization inspired by the Doppler effect to capture the interdependence between input text embeddings and output labels, and (ii) the use of explainable AI techniques to generate diverse perturbations. To evaluate our detector, we create a benchmark dataset comprising a mixture of prompts from both ChatGPT and humans, encompassing domains such as medical, open Q&A, finance, wiki, and Reddit. Our evaluation demonstrates that DEMASQ achieves high accuracy in identifying content generated by ChatGPT.

{{</citation>}}


### (3/108) Sandi: A System for Accountability and Applications in Direct Communication (Extended Abstract) (F. Betül Durak et al., 2023)

{{<citation>}}

F. Betül Durak, Kim Laine, Simon Langowski, Radames Cruz Moreno, Robert Sim, Shrey Jain. (2023)  
**Sandi: A System for Accountability and Applications in Direct Communication (Extended Abstract)**  

---
Primary Category: cs.CR  
Categories: cs-CR, cs.CR  
Keywords: AI, Generative AI  
[Paper Link](http://arxiv.org/abs/2311.04861v1)  

---


**ABSTRACT**  
Reputation systems guide our decision making both in life and work: which restaurant to eat at, which vendor to buy from, which software dependencies to use, and who or what to trust. These systems are often based on old ideas and are failing in the face of modern threats. Fraudsters have found ways to manipulate them, undermining their integrity and utility. Generative AI adds to the problem by enabling the creation of real-looking fake narratives at scale, creating a false sense of consensus. Meanwhile, the need for reliable reputation concepts is more important than ever, as wrong decisions lead to increasingly severe outcomes: wasted time, poor service, and a feeling of injustice at best, fraud, identity theft, and ransomware at worst.   In this extended abstract we introduce Sandi, a new kind of reputation system with a single well-defined purpose: to create trust through accountability in one-to-one transactions. Examples of such transactions include sending an email or making a purchase online. Sandi has strong security and privacy properties that make it suitable for use also in sensitive contexts. Furthermore, Sandi can guarantee reputation integrity and transparency for its registered users.   As a primary application, we envision how Sandi could counter fraud and abuse in direct communication. Concretely, message senders request a cryptographic tag from Sandi that they send along with their message. If the receiver finds the message inappropriate, they can report the sender using this tag. Notably, only senders need registered accounts and do not need to manage long-term keys. The design of Sandi ensures compatibility with any communication system that allows for small binary data transmission.

{{</citation>}}


### (4/108) CompactTag: Minimizing Computation Overheads in Actively-Secure MPC for Deep Neural Networks (Yongqin Wang et al., 2023)

{{<citation>}}

Yongqin Wang, Pratik Sarkar, Nishat Koti, Arpita Patra, Murali Annavaram. (2023)  
**CompactTag: Minimizing Computation Overheads in Actively-Secure MPC for Deep Neural Networks**  

---
Primary Category: cs.CR  
Categories: cs-CR, cs.CR  
Keywords: Transformer  
[Paper Link](http://arxiv.org/abs/2311.04406v1)  

---


**ABSTRACT**  
Secure Multiparty Computation (MPC) protocols enable secure evaluation of a circuit by several parties, even in the presence of an adversary who maliciously corrupts all but one of the parties. These MPC protocols are constructed using the well-known secret-sharing-based paradigm (SPDZ and SPDZ2k), where the protocols ensure security against a malicious adversary by computing Message Authentication Code (MAC) tags on the input shares and then evaluating the circuit with these input shares and tags. However, this tag computation adds a significant runtime overhead, particularly for machine learning (ML) applications with numerous linear computation layers such as convolutions and fully connected layers.   To alleviate the tag computation overhead, we introduce CompactTag, a lightweight algorithm for generating MAC tags specifically tailored for linear layers in ML. Linear layer operations in ML, including convolutions, can be transformed into Toeplitz matrix multiplications. For the multiplication of two matrices with dimensions T1 x T2 and T2 x T3 respectively, SPDZ2k required O(T1 x T2 x T3) local multiplications for the tag computation. In contrast, CompactTag only requires O(T1 x T2 + T1 x T3 + T2 x T3) local multiplications, resulting in a substantial performance boost for various ML models.   We empirically compared our protocol to the SPDZ2k protocol for various ML circuits, including ResNet Training-Inference, Transformer Training-Inference, and VGG16 Training-Inference. SPDZ2k dedicated around 30% of its online runtime for tag computation. CompactTag speeds up this tag computation bottleneck by up to 23x, resulting in up to 1.47x total online phase runtime speedups for various ML workloads.

{{</citation>}}


## cs.IT (2)



### (5/108) Matrix Completion via Memoryless Scalar Quantization (Arian Eamaz et al., 2023)

{{<citation>}}

Arian Eamaz, Farhang Yeganegi, Mojtaba Soltanalian. (2023)  
**Matrix Completion via Memoryless Scalar Quantization**  

---
Primary Category: cs.IT  
Categories: cs-IT, cs.IT, math-IT  
Keywords: Quantization  
[Paper Link](http://arxiv.org/abs/2311.05052v1)  

---


**ABSTRACT**  
We delve into the impact of memoryless scalar quantization on matrix completion. We broaden our theoretical discussion to encompass the coarse quantization scenario with a dithering scheme, where the only available information for low-rank matrix recovery is few-bit low-resolution data. Our primary motivation for this research is to evaluate the recovery performance of nuclear norm minimization in handling quantized matrix problems without the use of any regularization terms such as those stemming from maximum likelihood estimation. We furnish theoretical guarantees for both scenarios: when access to dithers is available during the reconstruction process, and when we have access solely to the statistical properties of the dithers. Additionally, we conduct a comprehensive analysis of the effects of sign flips and prequantization noise on the recovery performance, particularly when the impact of sign flips is quantified using the well-known Hamming distance in the upper bound of recovery error.

{{</citation>}}


### (6/108) Single Server Private Information Retrieval Protocols With Codes Over Rings (Şeyma Bodur et al., 2023)

{{<citation>}}

Şeyma Bodur, Edgar Martínez-Moro, Diego Ruano. (2023)  
**Single Server Private Information Retrieval Protocols With Codes Over Rings**  

---
Primary Category: cs.IT  
Categories: cs-IT, cs.IT, math-IT  
Keywords: Information Retrieval  
[Paper Link](http://arxiv.org/abs/2311.04688v2)  

---


**ABSTRACT**  
A Private Information Retrieval (PIR) protocol based on coding theory for a single server is proposed. It provides computational security against linear algebra attacks, addressing the main drawback of previous PIR proposals based on coding theory. The approach involves two types of codes each one over a different ring, an inner non-free linear code that will be used as a distinguisher of some elements added to the query matrix, and an outer code that will be used for generating the query matrix. Moreover, it only uses modular arithmetic at the server level and the recovering stage if the base ring chosen for the inner code is $\mathbb Z_m$.

{{</citation>}}


## cs.CL (32)



### (7/108) Deep Learning Brasil at ABSAPT 2022: Portuguese Transformer Ensemble Approaches (Juliana Resplande Santanna Gomes et al., 2023)

{{<citation>}}

Juliana Resplande Santanna Gomes, Eduardo Augusto Santos Garcia, Adalberto Ferreira Barbosa Junior, Ruan Chaves Rodrigues, Diogo Fernandes Costa Silva, Dyonnatan Ferreira Maia, Nádia Félix Felipe da Silva, Arlindo Rodrigues Galvão Filho, Anderson da Silva Soares. (2023)  
**Deep Learning Brasil at ABSAPT 2022: Portuguese Transformer Ensemble Approaches**  

---
Primary Category: cs.CL  
Categories: cs-CL, cs.CL  
Keywords: Sentiment Analysis, Transformer  
[Paper Link](http://arxiv.org/abs/2311.05051v1)  

---


**ABSTRACT**  
Aspect-based Sentiment Analysis (ABSA) is a task whose objective is to classify the individual sentiment polarity of all entities, called aspects, in a sentence. The task is composed of two subtasks: Aspect Term Extraction (ATE), identify all aspect terms in a sentence; and Sentiment Orientation Extraction (SOE), given a sentence and its aspect terms, the task is to determine the sentiment polarity of each aspect term (positive, negative or neutral). This article presents we present our participation in Aspect-Based Sentiment Analysis in Portuguese (ABSAPT) 2022 at IberLEF 2022. We submitted the best performing systems, achieving new state-of-the-art results on both subtasks.

{{</citation>}}


### (8/108) DeepLearningBrasil@LT-EDI-2023: Exploring Deep Learning Techniques for Detecting Depression in Social Media Text (Eduardo Garcia et al., 2023)

{{<citation>}}

Eduardo Garcia, Juliana Gomes, Adalberto Barbosa Júnior, Cardeque Borges, Nádia da Silva. (2023)  
**DeepLearningBrasil@LT-EDI-2023: Exploring Deep Learning Techniques for Detecting Depression in Social Media Text**  

---
Primary Category: cs.CL  
Categories: cs-AI, cs-CL, cs.CL  
Keywords: BERT, NLP, Social Media  
[Paper Link](http://arxiv.org/abs/2311.05047v1)  

---


**ABSTRACT**  
In this paper, we delineate the strategy employed by our team, DeepLearningBrasil, which secured us the first place in the shared task DepSign-LT-EDI@RANLP-2023, achieving a 47.0% Macro F1-Score and a notable 2.4% advantage. The task was to classify social media texts into three distinct levels of depression - "not depressed," "moderately depressed," and "severely depressed." Leveraging the power of the RoBERTa and DeBERTa models, we further pre-trained them on a collected Reddit dataset, specifically curated from mental health-related Reddit's communities (Subreddits), leading to an enhanced understanding of nuanced mental health discourse. To address lengthy textual data, we used truncation techniques that retained the essence of the content by focusing on its beginnings and endings. Our model was robust against unbalanced data by incorporating sample weights into the loss. Cross-validation and ensemble techniques were then employed to combine our k-fold trained models, delivering an optimal solution. The accompanying code is made available for transparency and further development.

{{</citation>}}


### (9/108) First Tragedy, then Parse: History Repeats Itself in the New Era of Large Language Models (Naomi Saphra et al., 2023)

{{<citation>}}

Naomi Saphra, Eve Fleisig, Kyunghyun Cho, Adam Lopez. (2023)  
**First Tragedy, then Parse: History Repeats Itself in the New Era of Large Language Models**  

---
Primary Category: cs.CL  
Categories: cs-CL, cs.CL  
Keywords: ChatGPT, GPT, Language Model, NLP  
[Paper Link](http://arxiv.org/abs/2311.05020v1)  

---


**ABSTRACT**  
Many NLP researchers are experiencing an existential crisis triggered by the astonishing success of ChatGPT and other systems based on large language models (LLMs). After such a disruptive change to our understanding of the field, what is left to do? Taking a historical lens, we look for guidance from the first era of LLMs, which began in 2005 with large $n$-gram models for machine translation. We identify durable lessons from the first era, and more importantly, we identify evergreen problems where NLP researchers can continue to make meaningful contributions in areas where LLMs are ascendant. Among these lessons, we discuss the primacy of hardware advancement in shaping the availability and importance of scale, as well as the urgent challenge of quality evaluation, both automated and human. We argue that disparities in scale are transient and that researchers can work to reduce them; that data, rather than hardware, is still a bottleneck for many meaningful applications; that meaningful evaluation informed by actual use is still an open problem; and that there is still room for speculative approaches.

{{</citation>}}


### (10/108) Interpreting Pretrained Language Models via Concept Bottlenecks (Zhen Tan et al., 2023)

{{<citation>}}

Zhen Tan, Lu Cheng, Song Wang, Yuan Bo, Jundong Li, Huan Liu. (2023)  
**Interpreting Pretrained Language Models via Concept Bottlenecks**  

---
Primary Category: cs.CL  
Categories: cs-AI, cs-CL, cs.CL  
Keywords: Language Model, Pretrained Language Models  
[Paper Link](http://arxiv.org/abs/2311.05014v1)  

---


**ABSTRACT**  
Pretrained language models (PLMs) have made significant strides in various natural language processing tasks. However, the lack of interpretability due to their ``black-box'' nature poses challenges for responsible implementation. Although previous studies have attempted to improve interpretability by using, e.g., attention weights in self-attention layers, these weights often lack clarity, readability, and intuitiveness. In this research, we propose a novel approach to interpreting PLMs by employing high-level, meaningful concepts that are easily understandable for humans. For example, we learn the concept of ``Food'' and investigate how it influences the prediction of a model's sentiment towards a restaurant review. We introduce C$^3$M, which combines human-annotated and machine-generated concepts to extract hidden neurons designed to encapsulate semantically meaningful and task-specific concepts. Through empirical evaluations on real-world datasets, we manifest that our approach offers valuable insights to interpret PLM behavior, helps diagnose model failures, and enhances model robustness amidst noisy concept labels.

{{</citation>}}


### (11/108) On the steerability of large language models toward data-driven personas (Junyi Li et al., 2023)

{{<citation>}}

Junyi Li, Ninareh Mehrabi, Charith Peris, Palash Goyal, Kai-Wei Chang, Aram Galstyan, Richard Zemel, Rahul Gupta. (2023)  
**On the steerability of large language models toward data-driven personas**  

---
Primary Category: cs.CL  
Categories: cs-CL, cs.CL  
Keywords: Language Model  
[Paper Link](http://arxiv.org/abs/2311.04978v1)  

---


**ABSTRACT**  
The recent surge in Large Language Model (LLM) related applications has led to a concurrent escalation in expectations for LLMs to accommodate a myriad of personas and encompass a broad spectrum of perspectives. An important first step towards addressing this demand is to align language models with specific personas, be it groups of users or individuals. Towards this goal, we first present a new conceptualization of a persona. Moving beyond the traditional reliance on demographics like age, gender, or political party affiliation, we introduce a data-driven persona definition methodology built on collaborative-filtering. In this methodology, users are embedded into a continuous vector space based on their opinions and clustered into cohorts that manifest coherent views across specific inquiries. This methodology allows for a more nuanced understanding of different latent social groups present in the overall population (as opposed to simply using demographic groups) and enhances the applicability of model steerability. Finally, we present an efficient method to steer LLMs towards a particular persona. We learn a soft-prompting model to map the continuous representation of users into sequences of virtual tokens which, when prepended to the LLM input, enables the LLM to produce responses aligned with a given user. Our results show that our steerability algorithm is superior in performance compared to a collection of baselines.

{{</citation>}}


### (12/108) Beyond Size: How Gradients Shape Pruning Decisions in Large Language Models (Rocktim Jyoti Das et al., 2023)

{{<citation>}}

Rocktim Jyoti Das, Liqun Ma, Zhiqiang Shen. (2023)  
**Beyond Size: How Gradients Shape Pruning Decisions in Large Language Models**  

---
Primary Category: cs.CL  
Categories: cs-AI, cs-CL, cs-LG, cs.CL  
Keywords: GPT, LLaMA, Language Model, Pruning  
[Paper Link](http://arxiv.org/abs/2311.04902v1)  

---


**ABSTRACT**  
Large Language Models (LLMs) with a billion or more parameters are prime targets for network pruning, which aims to reduce a portion of the network weights without compromising performance. Prior approaches such as Weights Magnitude, SparseGPT, and Wanda, either concentrated solely on weights or integrated weights with activations for sparsity. However, they overlooked the informative gradients derived from pretrained large language models. In this paper, we present a novel sparsity-centric pruning method for pretrained LLMs, termed Gradient-based Language Model Pruner (GBLM-Pruner). GBLM-Pruner leverages the first-order term of the Taylor expansion, operating in a training-free manner by harnessing properly normalized gradients from a few calibration samples to determine the importance pruning score, and substantially outperforms competitive counterparts like SparseGPT and Wanda in multiple benchmarks. Intriguing, after incorporating gradients, the unstructured pruning method tends to reveal some structural patterns post-pruning, which mirrors the geometric interdependence inherent in the LLMs' parameter structure. Additionally, GBLM-Pruner functions without any subsequent retraining or weight updates to maintain its simplicity as other counterparts. Extensive evaluations on LLaMA-1 and LLaMA-2 across various language benchmarks and perplexity show that GBLM-Pruner surpasses magnitude pruning, Wanda (weights+activations) and SparseGPT (weights+activations+weight update) by significant margins. Our code and models are available at https://github.com/RocktimJyotiDas/GBLM-Pruner.

{{</citation>}}


### (13/108) How Abstract Is Linguistic Generalization in Large Language Models? Experiments with Argument Structure (Michael Wilson et al., 2023)

{{<citation>}}

Michael Wilson, Jackson Petty, Robert Frank. (2023)  
**How Abstract Is Linguistic Generalization in Large Language Models? Experiments with Argument Structure**  

---
Primary Category: cs.CL  
Categories: cs-CL, cs.CL  
Keywords: Language Model, Transformer  
[Paper Link](http://arxiv.org/abs/2311.04900v1)  

---


**ABSTRACT**  
Language models are typically evaluated on their success at predicting the distribution of specific words in specific contexts. Yet linguistic knowledge also encodes relationships between contexts, allowing inferences between word distributions. We investigate the degree to which pre-trained Transformer-based large language models (LLMs) represent such relationships, focusing on the domain of argument structure. We find that LLMs perform well in generalizing the distribution of a novel noun argument between related contexts that were seen during pre-training (e.g., the active object and passive subject of the verb spray), succeeding by making use of the semantically-organized structure of the embedding space for word embeddings. However, LLMs fail at generalizations between related contexts that have not been observed during pre-training, but which instantiate more abstract, but well-attested structural generalizations (e.g., between the active object and passive subject of an arbitrary verb). Instead, in this case, LLMs show a bias to generalize based on linear order. This finding points to a limitation with current models and points to a reason for which their training is data-intensive.s reported here are available at https://github.com/clay-lab/structural-alternations.

{{</citation>}}


### (14/108) Prompt Sketching for Large Language Models (Luca Beurer-Kellner et al., 2023)

{{<citation>}}

Luca Beurer-Kellner, Mark Niklas Müller, Marc Fischer, Martin Vechev. (2023)  
**Prompt Sketching for Large Language Models**  

---
Primary Category: cs.CL  
Categories: cs-AI, cs-CL, cs.CL  
Keywords: Language Model, Sketch  
[Paper Link](http://arxiv.org/abs/2311.04954v1)  

---


**ABSTRACT**  
Many recent prompting strategies for large language models (LLMs) query the model multiple times sequentially -- first to produce intermediate results and then the final answer. However, using these methods, both decoder and model are unaware of potential follow-up prompts, leading to disconnected and undesirably wordy intermediate responses. In this work, we address this issue by proposing prompt sketching, a new prompting paradigm in which an LLM does not only respond by completing a prompt, but by predicting values for multiple variables in a template. This way, sketching grants users more control over the generation process, e.g., by providing a reasoning framework via intermediate instructions, leading to better overall results. The key idea enabling sketching with existing, autoregressive models is to adapt the decoding procedure to also score follow-up instructions during text generation, thus optimizing overall template likelihood in inference. Our experiments show that in a zero-shot setting, prompt sketching outperforms existing, sequential prompting schemes such as direct asking or chain-of-thought on 7 out of 8 LLM benchmarking tasks, including state tracking, arithmetic reasoning, and general question answering. To facilitate future use, we release a number of generic, yet effective sketches applicable to many tasks, and an open source library called dclib, powering our sketch-aware decoders.

{{</citation>}}


### (15/108) Future Lens: Anticipating Subsequent Tokens from a Single Hidden State (Koyena Pal et al., 2023)

{{<citation>}}

Koyena Pal, Jiuding Sun, Andrew Yuan, Byron C. Wallace, David Bau. (2023)  
**Future Lens: Anticipating Subsequent Tokens from a Single Hidden State**  

---
Primary Category: cs.CL  
Categories: cs-CL, cs-LG, cs.CL  
Keywords: GPT  
[Paper Link](http://arxiv.org/abs/2311.04897v1)  

---


**ABSTRACT**  
We conjecture that hidden state vectors corresponding to individual input tokens encode information sufficient to accurately predict several tokens ahead. More concretely, in this paper we ask: Given a hidden (internal) representation of a single token at position $t$ in an input, can we reliably anticipate the tokens that will appear at positions $\geq t + 2$? To test this, we measure linear approximation and causal intervention methods in GPT-J-6B to evaluate the degree to which individual hidden states in the network contain signal rich enough to predict future hidden states and, ultimately, token outputs. We find that, at some layers, we can approximate a model's output with more than 48% accuracy with respect to its prediction of subsequent tokens through a single hidden state. Finally we present a "Future Lens" visualization that uses these methods to create a new view of transformer states.

{{</citation>}}


### (16/108) Bias Runs Deep: Implicit Reasoning Biases in Persona-Assigned LLMs (Shashank Gupta et al., 2023)

{{<citation>}}

Shashank Gupta, Vaishnavi Shrivastava, Ameet Deshpande, Ashwin Kalyan, Peter Clark, Ashish Sabharwal, Tushar Khot. (2023)  
**Bias Runs Deep: Implicit Reasoning Biases in Persona-Assigned LLMs**  

---
Primary Category: cs.CL  
Categories: cs-CL, cs.CL  
Keywords: Bias, ChatGPT, GPT, Reasoning  
[Paper Link](http://arxiv.org/abs/2311.04892v1)  

---


**ABSTRACT**  
Recent works have showcased the ability of large-scale language models (LLMs) to embody diverse personas in their responses, exemplified by prompts like 'You are Yoda. Explain the Theory of Relativity.' While this ability allows personalization of LLMs and enables human behavior simulation, its effect on LLMs' capabilities remain unclear. To fill this gap, we present the first extensive study of the unintended side-effects of persona assignment on the ability of LLMs, specifically ChatGPT, to perform basic reasoning tasks. Our study covers 24 reasoning datasets and 16 diverse personas spanning 5 socio-demographic groups: race, gender, religion, disability, and political affiliation. Our experiments unveil that ChatGPT carries deep rooted bias against various socio-demographics underneath a veneer of fairness. While it overtly rejects stereotypes when explicitly asked ('Are Black people less skilled at mathematics?'), it manifests stereotypical and often erroneous presumptions when prompted to answer questions while taking on a persona. These can be observed as abstentions in the model responses, e.g., 'As a Black person, I am unable to answer this question as it requires math knowledge', and generally result in a substantial drop in performance on reasoning tasks. We find that this inherent deep bias is ubiquitous - 80% of our personas demonstrated bias; it is significant - certain datasets had relative drops in performance of 70%+; and can be especially harmful for certain groups - certain personas had stat. sign. drops on more than 80% of the datasets. Further analysis shows that these persona-induced errors can be hard-to-discern and hard-to-avoid. Our findings serve as a cautionary tale that the practice of assigning personas to LLMs - a trend on the rise - can surface their deep-rooted biases and have unforeseeable and detrimental side-effects.

{{</citation>}}


### (17/108) SEMQA: Semi-Extractive Multi-Source Question Answering (Tal Schuster et al., 2023)

{{<citation>}}

Tal Schuster, Adam D. Lelkes, Haitian Sun, Jai Gupta, Jonathan Berant, William W. Cohen, Donald Metzler. (2023)  
**SEMQA: Semi-Extractive Multi-Source Question Answering**  

---
Primary Category: cs.CL  
Categories: cs-AI, cs-CL, cs-LG, cs.CL  
Keywords: QA, Question Answering  
[Paper Link](http://arxiv.org/abs/2311.04886v1)  

---


**ABSTRACT**  
Recently proposed long-form question answering (QA) systems, supported by large language models (LLMs), have shown promising capabilities. Yet, attributing and verifying their generated abstractive answers can be difficult, and automatically evaluating their accuracy remains an ongoing challenge.   In this work, we introduce a new QA task for answering multi-answer questions by summarizing multiple diverse sources in a semi-extractive fashion. Specifically, Semi-extractive Multi-source QA (SEMQA) requires models to output a comprehensive answer, while mixing factual quoted spans -- copied verbatim from given input sources -- and non-factual free-text connectors that glue these spans together into a single cohesive passage. This setting bridges the gap between the outputs of well-grounded but constrained extractive QA systems and more fluent but harder to attribute fully abstractive answers. Particularly, it enables a new mode for language models that leverages their advanced language generation capabilities, while also producing fine in-line attributions by-design that are easy to verify, interpret, and evaluate.   To study this task, we create the first dataset of this kind, QuoteSum, with human-written semi-extractive answers to natural and generated questions, and define text-based evaluation metrics. Experimenting with several LLMs in various settings, we find this task to be surprisingly challenging, demonstrating the importance of QuoteSum for developing and studying such consolidation capabilities.

{{</citation>}}


### (18/108) Profiling Irony & Stereotype: Exploring Sentiment, Topic, and Lexical Features (Tibor L. R. Krols et al., 2023)

{{<citation>}}

Tibor L. R. Krols, Marie Mortensen, Ninell Oldenburg. (2023)  
**Profiling Irony & Stereotype: Exploring Sentiment, Topic, and Lexical Features**  

---
Primary Category: cs.CL  
Categories: cs-CL, cs.CL  
Keywords: Twitter  
[Paper Link](http://arxiv.org/abs/2311.04885v1)  

---


**ABSTRACT**  
Social media has become a very popular source of information. With this popularity comes an interest in systems that can classify the information produced. This study tries to create such a system detecting irony in Twitter users. Recent work emphasize the importance of lexical features, sentiment features and the contrast herein along with TF-IDF and topic models. Based on a thorough feature selection process, the resulting model contains specific sub-features from these areas. Our model reaches an F1-score of 0.84, which is above the baseline. We find that lexical features, especially TF-IDF, contribute the most to our models while sentiment and topic modeling features contribute less to overall performance. Lastly, we highlight multiple interesting and important paths for further exploration.

{{</citation>}}


### (19/108) LongQLoRA: Efficient and Effective Method to Extend Context Length of Large Language Models (Jianxin Yang, 2023)

{{<citation>}}

Jianxin Yang. (2023)  
**LongQLoRA: Efficient and Effective Method to Extend Context Length of Large Language Models**  

---
Primary Category: cs.CL  
Categories: cs-AI, cs-CL, cs.CL  
Keywords: Attention, LLaMA, Language Model  
[Paper Link](http://arxiv.org/abs/2311.04879v2)  

---


**ABSTRACT**  
We present LongQLoRA, an efficient and effective method to extend context length of large language models with less training resources. LongQLoRA combines the advantages of Position Interpolation, QLoRA and Shift Short Attention of LongLoRA. With a single 32GB V100 GPU, LongQLoRA can extend the context length of LLaMA2 7B and 13B from 4096 to 8192 and even to 12k within 1000 finetuning steps. LongQLoRA achieves competitive perplexity performance on PG19 and Proof-pile datasets, our model outperforms LongLoRA and is very close to MPT-7B-8K within the evaluation context length of 8192. We collect and build 39k long instruction data to extend context length of Vicuna-13B from 4096 to 8192 and achieve good performance both in long and short context generation task. We also do some ablation experiments to study the effect of LoRA rank, finetuning steps and attention patterns in inference.The model weights, training data and code are avaliable at https://github.com/yangjianxin1/LongQLoRA.

{{</citation>}}


### (20/108) Rethinking Benchmark and Contamination for Language Models with Rephrased Samples (Shuo Yang et al., 2023)

{{<citation>}}

Shuo Yang, Wei-Lin Chiang, Lianmin Zheng, Joseph E. Gonzalez, Ion Stoica. (2023)  
**Rethinking Benchmark and Contamination for Language Models with Rephrased Samples**  

---
Primary Category: cs.CL  
Categories: cs-AI, cs-CL, cs.CL  
Keywords: GPT, GPT-3.5, GPT-4, Language Model  
[Paper Link](http://arxiv.org/abs/2311.04850v2)  

---


**ABSTRACT**  
Large language models are increasingly trained on all the data ever produced by humans. Many have raised concerns about the trustworthiness of public benchmarks due to potential contamination in pre-training or fine-tuning datasets. While most data decontamination efforts apply string matching (e.g., n-gram overlap) to remove benchmark data, we show that these methods are insufficient, and simple variations of test data (e.g., paraphrasing, translation) can easily bypass these decontamination measures. Furthermore, we demonstrate that if such variation of test data is not eliminated, a 13B model can easily overfit a test benchmark and achieve drastically high performance, on par with GPT-4. We validate such observations in widely used benchmarks such as MMLU, GSK8k, and HumanEval. To address this growing risk, we propose a stronger LLM-based decontamination method and apply it to widely used pre-training and fine-tuning datasets, revealing significant previously unknown test overlap. For example, in pre-training sets such as RedPajama-Data-1T and StarCoder-Data, we identified that 8-18\% of the HumanEval benchmark overlaps. Interestingly, we also find such contamination in synthetic dataset generated by GPT-3.5/4, suggesting a potential risk of unintentional contamination. We urge the community to adopt stronger decontamination approaches when using public benchmarks. Moreover, we call for the community to actively develop fresh one-time exams to evaluate models accurately. Our decontamination tool is publicly available at https://github.com/lm-sys/llm-decontaminator.

{{</citation>}}


### (21/108) Hierarchically Gated Recurrent Neural Network for Sequence Modeling (Zhen Qin et al., 2023)

{{<citation>}}

Zhen Qin, Songlin Yang, Yiran Zhong. (2023)  
**Hierarchically Gated Recurrent Neural Network for Sequence Modeling**  

---
Primary Category: cs.CL  
Categories: cs-CL, cs-LG, cs.CL  
Keywords: NLP, Transformer, Transformers  
[Paper Link](http://arxiv.org/abs/2311.04823v1)  

---


**ABSTRACT**  
Transformers have surpassed RNNs in popularity due to their superior abilities in parallel training and long-term dependency modeling. Recently, there has been a renewed interest in using linear RNNs for efficient sequence modeling. These linear RNNs often employ gating mechanisms in the output of the linear recurrence layer while ignoring the significance of using forget gates within the recurrence. In this paper, we propose a gated linear RNN model dubbed Hierarchically Gated Recurrent Neural Network (HGRN), which includes forget gates that are lower bounded by a learnable value. The lower bound increases monotonically when moving up layers. This allows the upper layers to model long-term dependencies and the lower layers to model more local, short-term dependencies. Experiments on language modeling, image classification, and long-range arena benchmarks showcase the efficiency and effectiveness of our proposed model. The source code is available at https://github.com/OpenNLPLab/HGRN.

{{</citation>}}


### (22/108) MTGER: Multi-view Temporal Graph Enhanced Temporal Reasoning over Time-Involved Document (Zheng Chu et al., 2023)

{{<citation>}}

Zheng Chu, Zekun Wang, Jiafeng Liang, Ming Liu, Bing Qin. (2023)  
**MTGER: Multi-view Temporal Graph Enhanced Temporal Reasoning over Time-Involved Document**  

---
Primary Category: cs.CL  
Categories: cs-AI, cs-CL, cs.CL  
Keywords: QA, Reasoning  
[Paper Link](http://arxiv.org/abs/2311.04816v1)  

---


**ABSTRACT**  
The facts and time in the document are intricately intertwined, making temporal reasoning over documents challenging. Previous work models time implicitly, making it difficult to handle such complex relationships. To address this issue, we propose MTGER, a novel Multi-view Temporal Graph Enhanced Temporal Reasoning framework for temporal reasoning over time-involved documents. Concretely, MTGER explicitly models the temporal relationships among facts by multi-view temporal graphs. On the one hand, the heterogeneous temporal graphs explicitly model the temporal and discourse relationships among facts; on the other hand, the multi-view mechanism captures both time-focused and fact-focused information, allowing the two views to complement each other through adaptive fusion. To further improve the implicit reasoning capability of the model, we design a self-supervised time-comparing objective. Extensive experimental results demonstrate the effectiveness of our method on the TimeQA and SituatedQA datasets. Furthermore, MTGER gives more consistent answers under question perturbations.

{{</citation>}}


### (23/108) DACBERT: Leveraging Dependency Agreement for Cost-Efficient Bert Pretraining (Martin Kuo et al., 2023)

{{<citation>}}

Martin Kuo, Jianyi Zhang, Yiran Chen. (2023)  
**DACBERT: Leveraging Dependency Agreement for Cost-Efficient Bert Pretraining**  

---
Primary Category: cs.CL  
Categories: cs-AI, cs-CL, cs.CL  
Keywords: BERT, GLUE  
[Paper Link](http://arxiv.org/abs/2311.04799v1)  

---


**ABSTRACT**  
Building on the cost-efficient pretraining advancements brought about by Crammed BERT, we enhance its performance and interpretability further by introducing a novel pretrained model Dependency Agreement Crammed BERT (DACBERT) and its two-stage pretraining framework - Dependency Agreement Pretraining. This framework, grounded by linguistic theories, seamlessly weaves syntax and semantic information into the pretraining process. The first stage employs four dedicated submodels to capture representative dependency agreements at the chunk level, effectively converting these agreements into embeddings. The second stage uses these refined embeddings, in tandem with conventional BERT embeddings, to guide the pretraining of the rest of the model. Evaluated on the GLUE benchmark, our DACBERT demonstrates notable improvement across various tasks, surpassing Crammed BERT by 3.13% in the RTE task and by 2.26% in the MRPC task. Furthermore, our method boosts the average GLUE score by 0.83%, underscoring its significant potential. The pretraining process can be efficiently executed on a single GPU within a 24-hour cycle, necessitating no supplementary computational resources or extending the pretraining duration compared with the Crammed BERT. Extensive studies further illuminate our approach's instrumental role in bolstering the interpretability of pretrained language models for natural language understanding tasks.

{{</citation>}}


### (24/108) Using large language models to study human memory for meaningful narratives (Antonios Georgiou Tankut Can et al., 2023)

{{<citation>}}

Antonios Georgiou Tankut Can, Mikhail Katkov, Misha Tsodyks. (2023)  
**Using large language models to study human memory for meaningful narratives**  

---
Primary Category: cs.CL  
Categories: cs-CL, cs.CL, q-bio-NC  
Keywords: AI  
[Paper Link](http://arxiv.org/abs/2311.04742v1)  

---


**ABSTRACT**  
One of the most impressive achievements of the AI revolution is the development of large language models that can generate meaningful text and respond to instructions in plain English with no additional training necessary. Here we show that language models can be used as a scientific instrument for studying human memory for meaningful material. We developed a pipeline for designing large scale memory experiments and analyzing the obtained results. We performed online memory experiments with a large number of participants and collected recognition and recall data for narratives of different lengths. We found that both recall and recognition performance scale linearly with narrative length. Furthermore, in order to investigate the role of narrative comprehension in memory, we repeated these experiments using scrambled versions of the presented stories. We found that even though recall performance declined significantly, recognition remained largely unaffected. Interestingly, recalls in this condition seem to follow the original narrative order rather than the scrambled presentation, pointing to a contextual reconstruction of the story in memory.

{{</citation>}}


### (25/108) Pre-training LLMs using human-like development data corpus (Khushi Bhardwaj et al., 2023)

{{<citation>}}

Khushi Bhardwaj, Raj Sanjay Shah, Sashank Varma. (2023)  
**Pre-training LLMs using human-like development data corpus**  

---
Primary Category: cs.CL  
Categories: cs-AI, cs-CL, cs.CL  
Keywords: BERT, Language Model  
[Paper Link](http://arxiv.org/abs/2311.04666v1)  

---


**ABSTRACT**  
Pre-trained Large Language Models (LLMs) have shown success in a diverse set of language inference and understanding tasks. The pre-training stage of LLMs looks at a large corpus of raw textual data. The BabyLM shared task compares LLM pre-training to human language acquisition, where the number of tokens seen by 13-year-old kids is magnitudes smaller than the number of tokens seen by LLMs. In this work, we pre-train and evaluate LLMs on their ability to learn contextual word representations using roughly the same number of tokens as seen by children. We provide a strong set of baselines; with different architectures, evaluation of changes in performance across epochs, and reported pre-training metrics for the strict small and strict tracks of the task. We also try to loosely replicate the RoBERTa baseline given by the task organizers to observe the training robustness to hyperparameter selection and replicability. We provide the submission details to the strict and strict-small tracks in this report.

{{</citation>}}


### (26/108) Massive Editing for Large Language Models via Meta Learning (Chenmien Tan et al., 2023)

{{<citation>}}

Chenmien Tan, Ge Zhang, Jie Fu. (2023)  
**Massive Editing for Large Language Models via Meta Learning**  

---
Primary Category: cs.CL  
Categories: cs-CL, cs-LG, cs.CL  
Keywords: BERT, GPT, Language Model, NLP, T5  
[Paper Link](http://arxiv.org/abs/2311.04661v2)  

---


**ABSTRACT**  
While large language models (LLMs) have enabled learning knowledge from the pre-training corpora, the acquired knowledge may be fundamentally incorrect or outdated over time, which necessitates rectifying the knowledge of the language model (LM) after the training. A promising approach involves employing a hyper-network to generate parameter shift, whereas existing hyper-networks suffer from inferior scalability in synchronous editing operation amount. To mitigate the problem, we propose the MAssive Language Model Editing Network (MALMEN), which formulates the parameter shift aggregation as the least square problem, subsequently updating the LM parameters using the normal equation. To accommodate editing multiple facts simultaneously with limited memory budgets, we separate the computation on the hyper-network and LM, enabling arbitrary batch size on both neural networks. Our method is evaluated by editing up to thousands of facts on LMs with different architectures, i.e., BERT-base, GPT-2, T5-XL (2.8B), and GPT-J (6B), across various knowledge-intensive NLP tasks, i.e., closed book fact-checking and question answering. Remarkably, MALMEN is capable of editing hundreds of times more facts than strong baselines with the identical hyper-network architecture and outperforms editor specifically designed for GPT. Our code is available at https://github.com/ChenmienTan/malmen.

{{</citation>}}


### (27/108) Explained anomaly detection in text reviews: Can subjective scenarios be correctly evaluated? (David Novoa-Paradela et al., 2023)

{{<citation>}}

David Novoa-Paradela, Oscar Fontenla-Romero, Bertha Guijarro-Berdiñas. (2023)  
**Explained anomaly detection in text reviews: Can subjective scenarios be correctly evaluated?**  

---
Primary Category: cs.CL  
Categories: cs-AI, cs-CL, cs-LG, cs.CL  
Keywords: Amazon  
[Paper Link](http://arxiv.org/abs/2311.04948v1)  

---


**ABSTRACT**  
This paper presents a pipeline to detect and explain anomalous reviews in online platforms. The pipeline is made up of three modules and allows the detection of reviews that do not generate value for users due to either worthless or malicious composition. The classifications are accompanied by a normality score and an explanation that justifies the decision made. The pipeline's ability to solve the anomaly detection task was evaluated using different datasets created from a large Amazon database. Additionally, a study comparing three explainability techniques involving 241 participants was conducted to assess the explainability module. The study aimed to measure the impact of explanations on the respondents' ability to reproduce the classification model and their perceived usefulness. This work can be useful to automate tasks in review online platforms, such as those for electronic commerce, and offers inspiration for addressing similar problems in the field of anomaly detection in textual data. We also consider it interesting to have carried out a human evaluation of the capacity of different explainability techniques in a real and infrequent scenario such as the detection of anomalous reviews, as well as to reflect on whether it is possible to explain tasks as humanly subjective as this one.

{{</citation>}}


### (28/108) TEAL: Tokenize and Embed ALL for Multi-modal Large Language Models (Zhen Yang et al., 2023)

{{<citation>}}

Zhen Yang, Yingxue Zhang, Fandong Meng, Jie Zhou. (2023)  
**TEAL: Tokenize and Embed ALL for Multi-modal Large Language Models**  

---
Primary Category: cs.CL  
Categories: cs-AI, cs-CL, cs.CL  
Keywords: Language Model  
[Paper Link](http://arxiv.org/abs/2311.04589v1)  

---


**ABSTRACT**  
Despite Multi-modal Large Language Models (MM-LLMs) have made exciting strides recently, they are still struggling to efficiently model the interactions among multi-modal inputs and the generation in non-textual modalities. In this work, we propose TEAL (Tokenize and Embed ALl)}, an approach to treat the input from any modality as a token sequence and learn a joint embedding space for all modalities. Specifically, for the input from any modality, TEAL first discretizes it into a token sequence with the off-the-shelf tokenizer and embeds the token sequence into a joint embedding space with a learnable embedding matrix. MM-LLMs just need to predict the multi-modal tokens autoregressively as the textual LLMs do. Finally, the corresponding de-tokenizer is applied to generate the output in each modality based on the predicted token sequence. With the joint embedding space, TEAL enables the frozen LLMs to perform both understanding and generation tasks involving non-textual modalities, such as image and audio. Thus, the textual LLM can just work as an interface and maintain its high performance in textual understanding and generation. Experiments show that TEAL achieves substantial improvements in multi-modal understanding, and implements a simple scheme for multi-modal generations.

{{</citation>}}


### (29/108) Assessing Distractors in Multiple-Choice Tests (Vatsal Raina et al., 2023)

{{<citation>}}

Vatsal Raina, Adian Liusie, Mark Gales. (2023)  
**Assessing Distractors in Multiple-Choice Tests**  

---
Primary Category: cs.CL  
Categories: cs-CL, cs.CL  
Keywords: ChatGPT, GPT  
[Paper Link](http://arxiv.org/abs/2311.04554v1)  

---


**ABSTRACT**  
Multiple-choice tests are a common approach for assessing candidates' comprehension skills. Standard multiple-choice reading comprehension exams require candidates to select the correct answer option from a discrete set based on a question in relation to a contextual passage. For appropriate assessment, the distractor answer options must by definition be incorrect but plausible and diverse. However, generating good quality distractors satisfying these criteria is a challenging task for content creators. We propose automated assessment metrics for the quality of distractors in multiple-choice reading comprehension tests. Specifically, we define quality in terms of the incorrectness, plausibility and diversity of the distractor options. We assess incorrectness using the classification ability of a binary multiple-choice reading comprehension system. Plausibility is assessed by considering the distractor confidence - the probability mass associated with the distractor options for a standard multi-class multiple-choice reading comprehension system. Diversity is assessed by pairwise comparison of an embedding-based equivalence metric between the distractors of a question. To further validate the plausibility metric we compare against candidate distributions over multiple-choice questions and agreement with a ChatGPT model's interpretation of distractor plausibility and diversity.

{{</citation>}}


### (30/108) Large GPT-like Models are Bad Babies: A Closer Look at the Relationship between Linguistic Competence and Psycholinguistic Measures (Julius Steuer et al., 2023)

{{<citation>}}

Julius Steuer, Marius Mosbach, Dietrich Klakow. (2023)  
**Large GPT-like Models are Bad Babies: A Closer Look at the Relationship between Linguistic Competence and Psycholinguistic Measures**  

---
Primary Category: cs.CL  
Categories: cs-CL, cs.CL  
Keywords: GLUE, GPT  
[Paper Link](http://arxiv.org/abs/2311.04547v1)  

---


**ABSTRACT**  
Research on the cognitive plausibility of language models (LMs) has so far mostly concentrated on modelling psycholinguistic response variables such as reading times, gaze durations and N400/P600 EEG signals, while mostly leaving out the dimension of what Mahowald et al. (2023) described as formal and functional linguistic competence, and developmental plausibility. We address this gap by training a series of GPT-like language models of different sizes on the strict version of the BabyLM pretraining corpus, evaluating on the challenge tasks (BLiMP, GLUE, MSGS) and an additional reading time prediction task. We find a positive correlation between LM size and performance on all three challenge tasks, with different preferences for model width and depth in each of the tasks. In contrast, a negative correlation was found between LM size and reading time fit of linear mixed-effects models using LM surprisal as a predictor, with the second-smallest LM achieving the largest log-likelihood reduction over a baseline model without surprisal. This suggests that modelling processing effort and linguistic competence may require an approach different from training GPT-like LMs on a developmentally plausible corpus.

{{</citation>}}


### (31/108) RankAug: Augmented data ranking for text classification (Tiasa Singha Roy et al., 2023)

{{<citation>}}

Tiasa Singha Roy, Priyam Basu. (2023)  
**RankAug: Augmented data ranking for text classification**  

---
Primary Category: cs.CL  
Categories: cs-AI, cs-CL, cs-LG, cs.CL  
Keywords: NLU, Natural Language Understanding  
[Paper Link](http://arxiv.org/abs/2311.04535v1)  

---


**ABSTRACT**  
Research on data generation and augmentation has been focused majorly on enhancing generation models, leaving a notable gap in the exploration and refinement of methods for evaluating synthetic data. There are several text similarity metrics within the context of generated data filtering which can impact the performance of specific Natural Language Understanding (NLU) tasks, specifically focusing on intent and sentiment classification. In this study, we propose RankAug, a text-ranking approach that detects and filters out the top augmented texts in terms of being most similar in meaning with lexical and syntactical diversity. Through experiments conducted on multiple datasets, we demonstrate that the judicious selection of filtering techniques can yield a substantial improvement of up to 35% in classification accuracy for under-represented classes.

{{</citation>}}


### (32/108) Loss Masking Is Not Needed in Decoder-only Transformer for Discrete-token Based ASR (Qian Chen et al., 2023)

{{<citation>}}

Qian Chen, Wen Wang, Qinglin Zhang, Siqi Zheng, Shiliang Zhang, Chong Deng, Yukun Ma, Hai Yu, Jiaqing Liu, Chong Zhang. (2023)  
**Loss Masking Is Not Needed in Decoder-only Transformer for Discrete-token Based ASR**  

---
Primary Category: cs.CL  
Categories: cs-CL, cs-SD, cs.CL, eess-AS  
Keywords: GPT, PaLM, Transformer  
[Paper Link](http://arxiv.org/abs/2311.04534v1)  

---


**ABSTRACT**  
Recently, unified speech-text models, such as SpeechGPT, VioLA, and AudioPaLM, have achieved remarkable performance on speech tasks. These models convert continuous speech signals into discrete tokens (speech discretization) and merge text and speech tokens into a shared vocabulary. Then they train a single decoder-only Transformer on a mixture of speech tasks. Specifically, all these models utilize Loss Masking on the input speech tokens for the ASR task, which means that these models do not explicitly model the dependency between the speech tokens. In this paper, we attempt to model the sequence of speech tokens in an autoregressive manner like text. However, we find that applying the conventional cross-entropy loss on input speech tokens does not consistently improve the ASR performance over Loss Masking. Therefore, we propose a novel approach denoted Smoothed Label Distillation (SLD), which introduces a KL divergence loss with smoothed labels on the input speech tokens to effectively model speech tokens. Experiments demonstrate that our SLD approach alleviates the limitations of the cross-entropy loss and consistently outperforms Loss Masking for decoder-only Transformer based ASR using different speech discretization methods.

{{</citation>}}


### (33/108) Conversation Understanding using Relational Temporal Graph Neural Networks with Auxiliary Cross-Modality Interaction (Cam-Van Thi Nguyen et al., 2023)

{{<citation>}}

Cam-Van Thi Nguyen, Anh-Tuan Mai, The-Son Le, Hai-Dang Kieu, Duc-Trong Le. (2023)  
**Conversation Understanding using Relational Temporal Graph Neural Networks with Auxiliary Cross-Modality Interaction**  

---
Primary Category: cs.CL  
Categories: cs-CL, cs-MM, cs.CL  
Keywords: Graph Neural Network, Graph Neural Networks  
[Paper Link](http://arxiv.org/abs/2311.04507v1)  

---


**ABSTRACT**  
Emotion recognition is a crucial task for human conversation understanding. It becomes more challenging with the notion of multimodal data, e.g., language, voice, and facial expressions. As a typical solution, the global- and the local context information are exploited to predict the emotional label for every single sentence, i.e., utterance, in the dialogue. Specifically, the global representation could be captured via modeling of cross-modal interactions at the conversation level. The local one is often inferred using the temporal information of speakers or emotional shifts, which neglects vital factors at the utterance level. Additionally, most existing approaches take fused features of multiple modalities in an unified input without leveraging modality-specific representations. Motivating from these problems, we propose the Relational Temporal Graph Neural Network with Auxiliary Cross-Modality Interaction (CORECT), an novel neural network framework that effectively captures conversation-level cross-modality interactions and utterance-level temporal dependencies with the modality-specific manner for conversation understanding. Extensive experiments demonstrate the effectiveness of CORECT via its state-of-the-art results on the IEMOCAP and CMU-MOSEI datasets for the multimodal ERC task.

{{</citation>}}


### (34/108) Multi-label and Multi-target Sampling of Machine Annotation for Computational Stance Detection (Zhengyuan Liu et al., 2023)

{{<citation>}}

Zhengyuan Liu, Hai Leong Chieu, Nancy F. Chen. (2023)  
**Multi-label and Multi-target Sampling of Machine Annotation for Computational Stance Detection**  

---
Primary Category: cs.CL  
Categories: cs-CL, cs.CL  
Keywords: Stance Detection  
[Paper Link](http://arxiv.org/abs/2311.04495v1)  

---


**ABSTRACT**  
Data collection from manual labeling provides domain-specific and task-aligned supervision for data-driven approaches, and a critical mass of well-annotated resources is required to achieve reasonable performance in natural language processing tasks. However, manual annotations are often challenging to scale up in terms of time and budget, especially when domain knowledge, capturing subtle semantic features, and reasoning steps are needed. In this paper, we investigate the efficacy of leveraging large language models on automated labeling for computational stance detection. We empirically observe that while large language models show strong potential as an alternative to human annotators, their sensitivity to task-specific instructions and their intrinsic biases pose intriguing yet unique challenges in machine annotation. We introduce a multi-label and multi-target sampling strategy to optimize the annotation quality. Experimental results on the benchmark stance detection corpora show that our method can significantly improve performance and learning efficacy.

{{</citation>}}


### (35/108) Twitter Sentiment Analysis of Covid Vacciness (Wenbo Zhu et al., 2023)

{{<citation>}}

Wenbo Zhu, Tiechuan Hu. (2023)  
**Twitter Sentiment Analysis of Covid Vacciness**  

---
Primary Category: cs.CL  
Categories: cs-CL, cs-IR, cs-LG, cs-SI, cs.CL  
Keywords: Sentiment Analysis, Twitter  
[Paper Link](http://arxiv.org/abs/2311.04479v1)  

---


**ABSTRACT**  
In this paper, we look at a database of tweets sorted by various keywords that could indicate the users sentiment towards covid vaccines. With social media becoming such a prevalent source of opinion, sorting and ranking tweets that hold important information such as opinions on covid vaccines is of utmost importance. Two different ranking scales were used, and ranking a tweet in this way could represent the difference between an opinion being lost and an opinion being featured on the site, which affects the decisions and behavior of people, and why researchers were interested in it. Using natural language processing techniques, our aim is to determine and categorize opinions about covid vaccines with the highest accuracy possible.

{{</citation>}}


### (36/108) RDGCN: Reinforced Dependency Graph Convolutional Network for Aspect-based Sentiment Analysis (Xusheng Zhao et al., 2023)

{{<citation>}}

Xusheng Zhao, Hao Peng, Qiong Dai, Xu Bai, Huailiang Peng, Yanbing Liu, Qinglang Guo, Philip S. Yu. (2023)  
**RDGCN: Reinforced Dependency Graph Convolutional Network for Aspect-based Sentiment Analysis**  

---
Primary Category: cs.CL  
Categories: cs-AI, cs-CL, cs.CL  
Keywords: GNN, Graph Convolutional Network, Sentiment Analysis  
[Paper Link](http://arxiv.org/abs/2311.04467v1)  

---


**ABSTRACT**  
Aspect-based sentiment analysis (ABSA) is dedicated to forecasting the sentiment polarity of aspect terms within sentences. Employing graph neural networks to capture structural patterns from syntactic dependency parsing has been confirmed as an effective approach for boosting ABSA. In most works, the topology of dependency trees or dependency-based attention coefficients is often loosely regarded as edges between aspects and opinions, which can result in insufficient and ambiguous syntactic utilization. To address these problems, we propose a new reinforced dependency graph convolutional network (RDGCN) that improves the importance calculation of dependencies in both distance and type views. Initially, we propose an importance calculation criterion for the minimum distances over dependency trees. Under the criterion, we design a distance-importance function that leverages reinforcement learning for weight distribution search and dissimilarity control. Since dependency types often do not have explicit syntax like tree distances, we use global attention and mask mechanisms to design type-importance functions. Finally, we merge these weights and implement feature aggregation and classification. Comprehensive experiments on three popular datasets demonstrate the effectiveness of the criterion and importance functions. RDGCN outperforms state-of-the-art GNN-based baselines in all validations.

{{</citation>}}


### (37/108) LooGLE: Can Long-Context Language Models Understand Long Contexts? (Jiaqi Li et al., 2023)

{{<citation>}}

Jiaqi Li, Mengmeng Wang, Zilong Zheng, Muhan Zhang. (2023)  
**LooGLE: Can Long-Context Language Models Understand Long Contexts?**  

---
Primary Category: cs.CL  
Categories: cs-AI, cs-CL, cs.CL  
Keywords: Language Model  
[Paper Link](http://arxiv.org/abs/2311.04939v1)  

---


**ABSTRACT**  
Large language models (LLMs), despite their impressive performance in various language tasks, are typically limited to processing texts within context-window size. This limitation has spurred significant research efforts to enhance LLMs' long-context understanding with high-quality long-sequence benchmarks. However, prior datasets in this regard suffer from shortcomings, such as short context length compared to the context window of modern LLMs; outdated documents that have data leakage problems; and an emphasis on short dependency tasks rather than long dependency tasks. In this paper, we present LooGLE, a Long Context Generic Language Evaluation benchmark for LLMs' long context understanding. LooGLE features relatively new documents post-2022, with over 24,000 tokens per document and 6,000 newly generated questions spanning diverse domains. Human annotators meticulously crafted more than 1,100 high-quality question-answer pairs to meet the long dependency requirements. These pairs underwent thorough cross-validation, yielding the most precise assessment of LLMs' long dependency capabilities. The evaluation of eight state-of-the-art LLMs on LooGLE revealed key findings: (i) commercial models outperformed open-sourced models; (ii) LLMs excelled in short dependency tasks like short question-answering and cloze tasks but struggled with more intricate long dependency tasks; (iii) in-context learning and chaining thoughts offered only marginal improvements; (iv) retrieval-based techniques demonstrated substantial benefits for short question-answering, while strategies for extending context window length had limited impact on long context understanding. As such, LooGLE not only provides a systematic and comprehensive evaluation schema on long-context LLMs, but also sheds light on future development of enhanced models towards "true long-context understanding".

{{</citation>}}


### (38/108) Data Factors for Better Compositional Generalization (Xiang Zhou et al., 2023)

{{<citation>}}

Xiang Zhou, Yichen Jiang, Mohit Bansal. (2023)  
**Data Factors for Better Compositional Generalization**  

---
Primary Category: cs.CL  
Categories: cs-AI, cs-CL, cs-LG, cs.CL  
Keywords: Transformer  
[Paper Link](http://arxiv.org/abs/2311.04420v1)  

---


**ABSTRACT**  
Recent diagnostic datasets on compositional generalization, such as SCAN (Lake and Baroni, 2018) and COGS (Kim and Linzen, 2020), expose severe problems in models trained from scratch on these datasets. However, in contrast to this poor performance, state-of-the-art models trained on larger and more general datasets show better generalization ability. In this work, to reconcile this inconsistency, we conduct an empirical analysis by training Transformer models on a variety of training sets with different data factors, including dataset scale, pattern complexity, example difficulty, etc. First, we show that increased dataset complexity can lead to better generalization behavior on multiple different generalization challenges. To further understand this improvement, we show two axes of the benefit from more complex datasets: they provide more diverse examples so compositional understanding becomes more effective, and they also prevent ungeneralizable memorization of the examples due to reduced example repetition frequency. Finally, we explore how training examples of different difficulty levels influence generalization differently. On synthetic datasets, simple examples invoke stronger compositionality than hard examples do. On larger-scale real language datasets, while hard examples become more important potentially to ensure decent data coverage, a balanced mixture of simple and hard examples manages to induce the strongest generalizability. The code and data for this work are available at https://github.com/owenzx/data4comp

{{</citation>}}


## cs.HC (2)



### (39/108) Synthetic Speaking Children -- Why We Need Them and How to Make Them (Muhammad Ali Farooq et al., 2023)

{{<citation>}}

Muhammad Ali Farooq, Dan Bigioi, Rishabh Jain, Wang Yao, Mariam Yiwere, Peter Corcoran. (2023)  
**Synthetic Speaking Children -- Why We Need Them and How to Make Them**  

---
Primary Category: cs.HC  
Categories: cs-AI, cs-HC, cs-SD, cs.HC, eess-AS  
Keywords: AI  
[Paper Link](http://arxiv.org/abs/2311.06307v1)  

---


**ABSTRACT**  
Contemporary Human Computer Interaction (HCI) research relies primarily on neural network models for machine vision and speech understanding of a system user. Such models require extensively annotated training datasets for optimal performance and when building interfaces for users from a vulnerable population such as young children, GDPR introduces significant complexities in data collection, management, and processing. Motivated by the training needs of an Edge AI smart toy platform this research explores the latest advances in generative neural technologies and provides a working proof of concept of a controllable data generation pipeline for speech driven facial training data at scale. In this context, we demonstrate how StyleGAN2 can be finetuned to create a gender balanced dataset of children's faces. This dataset includes a variety of controllable factors such as facial expressions, age variations, facial poses, and even speech-driven animations with realistic lip synchronization. By combining generative text to speech models for child voice synthesis and a 3D landmark based talking heads pipeline, we can generate highly realistic, entirely synthetic, talking child video clips. These video clips can provide valuable, and controllable, synthetic training data for neural network models, bridging the gap when real data is scarce or restricted due to privacy regulations.

{{</citation>}}


### (40/108) A Systematic Review on Fostering Appropriate Trust in Human-AI Interaction (Siddharth Mehrotra et al., 2023)

{{<citation>}}

Siddharth Mehrotra, Chadha Degachi, Oleksandra Vereschak, Catholijn M. Jonker, Myrthe L. Tielman. (2023)  
**A Systematic Review on Fostering Appropriate Trust in Human-AI Interaction**  

---
Primary Category: cs.HC  
Categories: cs-AI, cs-HC, cs.HC  
Keywords: AI  
[Paper Link](http://arxiv.org/abs/2311.06305v1)  

---


**ABSTRACT**  
Appropriate Trust in Artificial Intelligence (AI) systems has rapidly become an important area of focus for both researchers and practitioners. Various approaches have been used to achieve it, such as confidence scores, explanations, trustworthiness cues, or uncertainty communication. However, a comprehensive understanding of the field is lacking due to the diversity of perspectives arising from various backgrounds that influence it and the lack of a single definition for appropriate trust. To investigate this topic, this paper presents a systematic review to identify current practices in building appropriate trust, different ways to measure it, types of tasks used, and potential challenges associated with it. We also propose a Belief, Intentions, and Actions (BIA) mapping to study commonalities and differences in the concepts related to appropriate trust by (a) describing the existing disagreements on defining appropriate trust, and (b) providing an overview of the concepts and definitions related to appropriate trust in AI from the existing literature. Finally, the challenges identified in studying appropriate trust are discussed, and observations are summarized as current trends, potential gaps, and research opportunities for future work. Overall, the paper provides insights into the complex concept of appropriate trust in human-AI interaction and presents research opportunities to advance our understanding on this topic.

{{</citation>}}


## cs.LG (21)



### (41/108) Quantum Generative Modeling of Sequential Data with Trainable Token Embedding (Wanda Hou et al., 2023)

{{<citation>}}

Wanda Hou, Miao Li, Yi-Zhuang You. (2023)  
**Quantum Generative Modeling of Sequential Data with Trainable Token Embedding**  

---
Primary Category: cs.LG  
Categories: cs-LG, cs.LG, quant-ph  
Keywords: Embedding  
[Paper Link](http://arxiv.org/abs/2311.05050v1)  

---


**ABSTRACT**  
Generative models are a class of machine learning models that aim to learn the underlying probability distribution of data. Unlike discriminative models, generative models focus on capturing the data's inherent structure, allowing them to generate new samples that resemble the original data. To fully exploit the potential of modeling probability distributions using quantum physics, a quantum-inspired generative model known as the Born machines have shown great advancements in learning classical and quantum data over matrix product state(MPS) framework. The Born machines support tractable log-likelihood, autoregressive and mask sampling, and have shown outstanding performance in various unsupervised learning tasks. However, much of the current research has been centered on improving the expressive power of MPS, predominantly embedding each token directly by a corresponding tensor index. In this study, we generalize the embedding method into trainable quantum measurement operators that can be simultaneously honed with MPS. Our study indicated that combined with trainable embedding, Born machines can exhibit better performance and learn deeper correlations from the dataset.

{{</citation>}}


### (42/108) Bridging Dimensions: Confident Reachability for High-Dimensional Controllers (Yuang Geng et al., 2023)

{{<citation>}}

Yuang Geng, Souradeep Dutta, Ivan Ruchkin. (2023)  
**Bridging Dimensions: Confident Reachability for High-Dimensional Controllers**  

---
Primary Category: cs.LG  
Categories: cs-LG, cs.LG  
Keywords: AI  
[Paper Link](http://arxiv.org/abs/2311.04843v1)  

---


**ABSTRACT**  
Autonomous systems are increasingly implemented using end-end-end trained controllers. Such controllers make decisions that are executed on the real system with images as one of the primary sensing modalities. Deep neural networks form a fundamental building block of such controllers. Unfortunately, the existing neural-network verification tools do not scale to inputs with thousands of dimensions. Especially when the individual inputs (such as pixels) are devoid of clear physical meaning. This paper takes a step towards connecting exhaustive closed-loop verification with high-dimensional controllers. Our key insight is that the behavior of a high-dimensional controller can be approximated with several low-dimensional controllers in different regions of the state space. To balance approximation and verifiability, we leverage the latest verification-aware knowledge distillation. Then, if low-dimensional reachability results are inflated with statistical approximation errors, they yield a high-confidence reachability guarantee for the high-dimensional controller. We investigate two inflation techniques -- based on trajectories and actions -- both of which show convincing performance in two OpenAI gym benchmarks.

{{</citation>}}


### (43/108) Real-Time Recurrent Reinforcement Learning (Julian Lemmel et al., 2023)

{{<citation>}}

Julian Lemmel, Radu Grosu. (2023)  
**Real-Time Recurrent Reinforcement Learning**  

---
Primary Category: cs.LG  
Categories: cs-LG, cs-NE, cs-SY, cs.LG, eess-SY  
Keywords: Reinforcement Learning  
[Paper Link](http://arxiv.org/abs/2311.04830v1)  

---


**ABSTRACT**  
Recent advances in reinforcement learning, for partially-observable Markov decision processes (POMDPs), rely on the biologically implausible backpropagation through time algorithm (BPTT) to perform gradient-descent optimisation. In this paper we propose a novel reinforcement learning algorithm that makes use of random feedback local online learning (RFLO), a biologically plausible approximation of realtime recurrent learning (RTRL) to compute the gradients of the parameters of a recurrent neural network in an online manner. By combining it with TD($\lambda$), a variant of temporaldifference reinforcement learning with eligibility traces, we create a biologically plausible, recurrent actor-critic algorithm, capable of solving discrete and continuous control tasks in POMDPs. We compare BPTT, RTRL and RFLO as well as different network architectures, and find that RFLO can perform just as well as RTRL while exceeding even BPTT in terms of complexity. The proposed method, called real-time recurrent reinforcement learning (RTRRL), serves as a model of learning in biological neural networks mimicking reward pathways in the mammalian brain.

{{</citation>}}


### (44/108) Determination of toxic comments and unintended model bias minimization using Deep learning approach (Md Azim Khan, 2023)

{{<citation>}}

Md Azim Khan. (2023)  
**Determination of toxic comments and unintended model bias minimization using Deep learning approach**  

---
Primary Category: cs.LG  
Categories: cs-CL, cs-CY, cs-LG, cs.LG  
Keywords: BERT, Transformer, Transformers  
[Paper Link](http://arxiv.org/abs/2311.04789v1)  

---


**ABSTRACT**  
Online conversations can be toxic and subjected to threats, abuse, or harassment. To identify toxic text comments, several deep learning and machine learning models have been proposed throughout the years. However, recent studies demonstrate that because of the imbalances in the training data, some models are more likely to show unintended biases including gender bias and identity bias. In this research, our aim is to detect toxic comment and reduce the unintended bias concerning identity features such as race, gender, sex, religion by fine-tuning an attention based model called BERT(Bidirectional Encoder Representation from Transformers). We apply weighted loss to address the issue of unbalanced data and compare the performance of a fine-tuned BERT model with a traditional Logistic Regression model in terms of classification and bias minimization. The Logistic Regression model with the TFIDF vectorizer achieve 57.1% accuracy, and fine-tuned BERT model's accuracy is 89%. Code is available at https://github.com/zim10/Determine_Toxic_comment_and_identity_bias.git

{{</citation>}}


### (45/108) Why Do Clinical Probabilistic Models Fail To Transport Between Sites? (Thomas A. Lasko et al., 2023)

{{<citation>}}

Thomas A. Lasko, Eric V. Strobl, William W. Stead. (2023)  
**Why Do Clinical Probabilistic Models Fail To Transport Between Sites?**  

---
Primary Category: cs.LG  
Categories: cs-LG, cs-PF, cs.LG, stat-ML  
Keywords: Clinical  
[Paper Link](http://arxiv.org/abs/2311.04787v1)  

---


**ABSTRACT**  
The rising popularity of artificial intelligence in healthcare is highlighting the problem that a computational model achieving super-human clinical performance at its training sites may perform substantially worse at new sites. In this perspective, we present common sources for this failure to transport, which we divide into sources under the control of the experimenter and sources inherent to the clinical data-generating process. Of the inherent sources we look a little deeper into site-specific clinical practices that can affect the data distribution, and propose a potential solution intended to isolate the imprint of those practices on the data from the patterns of disease cause and effect that are the usual target of clinical models.

{{</citation>}}


### (46/108) Towards a Unified Framework of Contrastive Learning for Disentangled Representations (Stefan Matthes et al., 2023)

{{<citation>}}

Stefan Matthes, Zhiwei Han, Hao Shen. (2023)  
**Towards a Unified Framework of Contrastive Learning for Disentangled Representations**  

---
Primary Category: cs.LG  
Categories: cs-LG, cs.LG, stat-ML  
Keywords: Contrastive Learning  
[Paper Link](http://arxiv.org/abs/2311.04774v1)  

---


**ABSTRACT**  
Contrastive learning has recently emerged as a promising approach for learning data representations that discover and disentangle the explanatory factors of the data. Previous analyses of such approaches have largely focused on individual contrastive losses, such as noise-contrastive estimation (NCE) and InfoNCE, and rely on specific assumptions about the data generating process. This paper extends the theoretical guarantees for disentanglement to a broader family of contrastive methods, while also relaxing the assumptions about the data distribution. Specifically, we prove identifiability of the true latents for four contrastive losses studied in this paper, without imposing common independence assumptions. The theoretical findings are validated on several benchmark datasets. Finally, practical limitations of these methods are also investigated.

{{</citation>}}


### (47/108) Vital Sign Forecasting for Sepsis Patients in ICUs (Anubhav Bhatti et al., 2023)

{{<citation>}}

Anubhav Bhatti, Yuwei Liu, Chen Dan, Bingjie Shen, San Lee, Yonghwan Kim, Jang Yong Kim. (2023)  
**Vital Sign Forecasting for Sepsis Patients in ICUs**  

---
Primary Category: cs.LG  
Categories: cs-AI, cs-LG, cs.LG  
Keywords: Transformer  
[Paper Link](http://arxiv.org/abs/2311.04770v1)  

---


**ABSTRACT**  
Sepsis and septic shock are a critical medical condition affecting millions globally, with a substantial mortality rate. This paper uses state-of-the-art deep learning (DL) architectures to introduce a multi-step forecasting system to predict vital signs indicative of septic shock progression in Intensive Care Units (ICUs). Our approach utilizes a short window of historical vital sign data to forecast future physiological conditions. We introduce a DL-based vital sign forecasting system that predicts up to 3 hours of future vital signs from 6 hours of past data. We further adopt the DILATE loss function to capture better the shape and temporal dynamics of vital signs, which are critical for clinical decision-making. We compare three DL models, N-BEATS, N-HiTS, and Temporal Fusion Transformer (TFT), using the publicly available eICU Collaborative Research Database (eICU-CRD), highlighting their forecasting capabilities in a critical care setting. We evaluate the performance of our models using mean squared error (MSE) and dynamic time warping (DTW) metrics. Our findings show that while TFT excels in capturing overall trends, N-HiTS is superior in retaining short-term fluctuations within a predefined range. This paper demonstrates the potential of deep learning in transforming the monitoring systems in ICUs, potentially leading to significant improvements in patient care and outcomes by accurately forecasting vital signs to assist healthcare providers in detecting early signs of physiological instability and anticipating septic shock.

{{</citation>}}


### (48/108) Euclidean, Projective, Conformal: Choosing a Geometric Algebra for Equivariant Transformers (Pim de Haan et al., 2023)

{{<citation>}}

Pim de Haan, Taco Cohen, Johann Brehmer. (2023)  
**Euclidean, Projective, Conformal: Choosing a Geometric Algebra for Equivariant Transformers**  

---
Primary Category: cs.LG  
Categories: cs-AI, cs-LG, cs.LG  
Keywords: Transformer, Transformers  
[Paper Link](http://arxiv.org/abs/2311.04744v1)  

---


**ABSTRACT**  
The Geometric Algebra Transformer (GATr) is a versatile architecture for geometric deep learning based on projective geometric algebra. We generalize this architecture into a blueprint that allows one to construct a scalable transformer architecture given any geometric (or Clifford) algebra. We study versions of this architecture for Euclidean, projective, and conformal algebras, all of which are suited to represent 3D data, and evaluate them in theory and practice. The simplest Euclidean architecture is computationally cheap, but has a smaller symmetry group and is not as sample-efficient, while the projective model is not sufficiently expressive. Both the conformal algebra and an improved version of the projective algebra define powerful, performant architectures.

{{</citation>}}


### (49/108) Robust Best-arm Identification in Linear Bandits (Wei Wang et al., 2023)

{{<citation>}}

Wei Wang, Sattar Vakili, Ilija Bogunovic. (2023)  
**Robust Best-arm Identification in Linear Bandits**  

---
Primary Category: cs.LG  
Categories: cs-LG, cs.LG, stat-ML  
Keywords: AI  
[Paper Link](http://arxiv.org/abs/2311.04731v1)  

---


**ABSTRACT**  
We study the robust best-arm identification problem (RBAI) in the case of linear rewards. The primary objective is to identify a near-optimal robust arm, which involves selecting arms at every round and assessing their robustness by exploring potential adversarial actions. This approach is particularly relevant when utilizing a simulator and seeking to identify a robust solution for real-world transfer. To this end, we present an instance-dependent lower bound for the robust best-arm identification problem with linear rewards. Furthermore, we propose both static and adaptive bandit algorithms that achieve sample complexity that matches the lower bound. In synthetic experiments, our algorithms effectively identify the best robust arm and perform similarly to the oracle strategy. As an application, we examine diabetes care and the process of learning insulin dose recommendations that are robust with respect to inaccuracies in standard calculators. Our algorithms prove to be effective in identifying robust dosage values across various age ranges of patients.

{{</citation>}}


### (50/108) Leveraging Speculative Sampling and KV-Cache Optimizations Together for Generative AI using OpenVINO (Haim Barad et al., 2023)

{{<citation>}}

Haim Barad, Ekaterina Aidova, Yury Gorbachev. (2023)  
**Leveraging Speculative Sampling and KV-Cache Optimizations Together for Generative AI using OpenVINO**  

---
Primary Category: cs.LG  
Categories: cs-AI, cs-LG, cs-PF, cs.LG  
Keywords: AI, Generative AI  
[Paper Link](http://arxiv.org/abs/2311.04951v1)  

---


**ABSTRACT**  
Inference optimizations are critical for improving user experience and reducing infrastructure costs and power consumption. In this article, we illustrate a form of dynamic execution known as speculative sampling to reduce the overall latency of text generation and compare it with standard autoregressive sampling. This can be used together with model-based optimizations (e.g. quantization) to provide an optimized solution. Both sampling methods make use of KV caching. A Jupyter notebook and some sample executions are provided.

{{</citation>}}


### (51/108) Hybrid Focal and Full-Range Attention Based Graph Transformers (Minhong Zhu et al., 2023)

{{<citation>}}

Minhong Zhu, Zhenhao Zhao, Weiran Cai. (2023)  
**Hybrid Focal and Full-Range Attention Based Graph Transformers**  

---
Primary Category: cs.LG  
Categories: cs-AI, cs-LG, cs.LG  
Keywords: Attention, Transformer, Transformers  
[Paper Link](http://arxiv.org/abs/2311.04653v1)  

---


**ABSTRACT**  
The paradigm of Transformers using the self-attention mechanism has manifested its advantage in learning graph-structured data. Yet, Graph Transformers are capable of modeling full range dependencies but are often deficient in extracting information from locality. A common practice is to utilize Message Passing Neural Networks (MPNNs) as an auxiliary to capture local information, which however are still inadequate for comprehending substructures. In this paper, we present a purely attention-based architecture, namely Focal and Full-Range Graph Transformer (FFGT), which can mitigate the loss of local information in learning global correlations. The core component of FFGT is a new mechanism of compound attention, which combines the conventional full-range attention with K-hop focal attention on ego-nets to aggregate both global and local information. Beyond the scope of canonical Transformers, the FFGT has the merit of being more substructure-aware. Our approach enhances the performance of existing Graph Transformers on various open datasets, while achieves compatible SOTA performance on several Long-Range Graph Benchmark (LRGB) datasets even with a vanilla transformer. We further examine influential factors on the optimal focal length of attention via introducing a novel synthetic dataset based on SBM-PATTERN.

{{</citation>}}


### (52/108) Object-Centric Learning with Slot Mixture Module (Daniil Kirilenko et al., 2023)

{{<citation>}}

Daniil Kirilenko, Vitaliy Vorobyov, Alexey K. Kovalev, Aleksandr I. Panov. (2023)  
**Object-Centric Learning with Slot Mixture Module**  

---
Primary Category: cs.LG  
Categories: cs-AI, cs-CV, cs-LG, cs.LG  
Keywords: Attention  
[Paper Link](http://arxiv.org/abs/2311.04640v1)  

---


**ABSTRACT**  
Object-centric architectures usually apply a differentiable module to the entire feature map to decompose it into sets of entity representations called slots. Some of these methods structurally resemble clustering algorithms, where the cluster's center in latent space serves as a slot representation. Slot Attention is an example of such a method, acting as a learnable analog of the soft k-means algorithm. Our work employs a learnable clustering method based on the Gaussian Mixture Model. Unlike other approaches, we represent slots not only as centers of clusters but also incorporate information about the distance between clusters and assigned vectors, leading to more expressive slot representations. Our experiments demonstrate that using this approach instead of Slot Attention improves performance in object-centric scenarios, achieving state-of-the-art results in the set property prediction task.

{{</citation>}}


### (53/108) Accurate Autism Spectrum Disorder prediction using Support Vector Classifier based on Federated Learning (SVCFL) (Ali Mohammadifar et al., 2023)

{{<citation>}}

Ali Mohammadifar, Hasan Samadbin, Arman Daliri. (2023)  
**Accurate Autism Spectrum Disorder prediction using Support Vector Classifier based on Federated Learning (SVCFL)**  

---
Primary Category: cs.LG  
Categories: cs-LG, cs.LG  
Keywords: AI  
[Paper Link](http://arxiv.org/abs/2311.04606v1)  

---


**ABSTRACT**  
The path to an autism diagnosis can be long and difficult, and delays can have serious consequences. Artificial intelligence can completely change the way autism is diagnosed, especially when it comes to situations where it is difficult to see the first signs of the disease. AI-based diagnostic tools may help confirm a diagnosis or highlight the need for further testing by analyzing large volumes of data and uncovering patterns that may not be immediately apparent to human evaluators. After a successful and timely diagnosis, autism can be treated through artificial intelligence using various methods. In this article, by using four datasets and gathering them with the federated learning method and diagnosing them with the support vector classifier method, the early diagnosis of this disorder has been discussed. In this method, we have achieved 99% accuracy for predicting autism spectrum disorder and we have achieved 13% improvement in the results.

{{</citation>}}


### (54/108) On Characterizing the Evolution of Embedding Space of Neural Networks using Algebraic Topology (Suryaka Suresh et al., 2023)

{{<citation>}}

Suryaka Suresh, Bishshoy Das, Vinayak Abrol, Sumantra Dutta Roy. (2023)  
**On Characterizing the Evolution of Embedding Space of Neural Networks using Algebraic Topology**  

---
Primary Category: cs.LG  
Categories: cs-CV, cs-LG, cs.LG  
Keywords: Embedding  
[Paper Link](http://arxiv.org/abs/2311.04592v2)  

---


**ABSTRACT**  
We study how the topology of feature embedding space changes as it passes through the layers of a well-trained deep neural network (DNN) through Betti numbers. Motivated by existing studies using simplicial complexes on shallow fully connected networks (FCN), we present an extended analysis using Cubical homology instead, with a variety of popular deep architectures and real image datasets. We demonstrate that as depth increases, a topologically complicated dataset is transformed into a simple one, resulting in Betti numbers attaining their lowest possible value. The rate of decay in topological complexity (as a metric) helps quantify the impact of architectural choices on the generalization ability. Interestingly from a representation learning perspective, we highlight several invariances such as topological invariance of (1) an architecture on similar datasets; (2) embedding space of a dataset for architectures of variable depth; (3) embedding space to input resolution/size, and (4) data sub-sampling. In order to further demonstrate the link between expressivity \& the generalization capability of a network, we consider the task of ranking pre-trained models for downstream classification task (transfer learning). Compared to existing approaches, the proposed metric has a better correlation to the actually achievable accuracy via fine-tuning the pre-trained model.

{{</citation>}}


### (55/108) Army of Thieves: Enhancing Black-Box Model Extraction via Ensemble based sample selection (Akshit Jindal et al., 2023)

{{<citation>}}

Akshit Jindal, Vikram Goyal, Saket Anand, Chetan Arora. (2023)  
**Army of Thieves: Enhancing Black-Box Model Extraction via Ensemble based sample selection**  

---
Primary Category: cs.LG  
Categories: cs-AI, cs-CR, cs-CV, cs-LG, cs.LG  
Keywords: Active Learning, Semi-Supervised  
[Paper Link](http://arxiv.org/abs/2311.04588v1)  

---


**ABSTRACT**  
Machine Learning (ML) models become vulnerable to Model Stealing Attacks (MSA) when they are deployed as a service. In such attacks, the deployed model is queried repeatedly to build a labelled dataset. This dataset allows the attacker to train a thief model that mimics the original model. To maximize query efficiency, the attacker has to select the most informative subset of data points from the pool of available data. Existing attack strategies utilize approaches like Active Learning and Semi-Supervised learning to minimize costs. However, in the black-box setting, these approaches may select sub-optimal samples as they train only one thief model. Depending on the thief model's capacity and the data it was pretrained on, the model might even select noisy samples that harm the learning process. In this work, we explore the usage of an ensemble of deep learning models as our thief model. We call our attack Army of Thieves(AOT) as we train multiple models with varying complexities to leverage the crowd's wisdom. Based on the ensemble's collective decision, uncertain samples are selected for querying, while the most confident samples are directly included in the training data. Our approach is the first one to utilize an ensemble of thief models to perform model extraction. We outperform the base approaches of existing state-of-the-art methods by at least 3% and achieve a 21% higher adversarial sample transferability than previous work for models trained on the CIFAR-10 dataset.

{{</citation>}}


### (56/108) Long-term Time Series Forecasting based on Decomposition and Neural Ordinary Differential Equations (Seonkyu Lim et al., 2023)

{{<citation>}}

Seonkyu Lim, Jaehyeon Park, Seojin Kim, Hyowon Wi, Haksoo Lim, Jinsung Jeon, Jeongwhan Choi, Noseong Park. (2023)  
**Long-term Time Series Forecasting based on Decomposition and Neural Ordinary Differential Equations**  

---
Primary Category: cs.LG  
Categories: cs-LG, cs.LG  
Keywords: Time Series, Transformer  
[Paper Link](http://arxiv.org/abs/2311.04522v2)  

---


**ABSTRACT**  
Long-term time series forecasting (LTSF) is a challenging task that has been investigated in various domains such as finance investment, health care, traffic, and weather forecasting. In recent years, Linear-based LTSF models showed better performance, pointing out the problem of Transformer-based approaches causing temporal information loss. However, Linear-based approach has also limitations that the model is too simple to comprehensively exploit the characteristics of the dataset. To solve these limitations, we propose LTSF-DNODE, which applies a model based on linear ordinary differential equations (ODEs) and a time series decomposition method according to data statistical characteristics. We show that LTSF-DNODE outperforms the baselines on various real-world datasets. In addition, for each dataset, we explore the impacts of regularization in the neural ordinary differential equation (NODE) framework.

{{</citation>}}


### (57/108) Towards Democratizing AI: A Comparative Analysis of AI as a Service Platforms and the Open Space for Machine Learning Approach (Dennis Rall et al., 2023)

{{<citation>}}

Dennis Rall, Bernhard Bauer, Thomas Fraunholz. (2023)  
**Towards Democratizing AI: A Comparative Analysis of AI as a Service Platforms and the Open Space for Machine Learning Approach**  

---
Primary Category: cs.LG  
Categories: I-2-1, cs-LG, cs.LG  
Keywords: AI  
[Paper Link](http://arxiv.org/abs/2311.04518v1)  

---


**ABSTRACT**  
Recent AI research has significantly reduced the barriers to apply AI, but the process of setting up the necessary tools and frameworks can still be a challenge. While AI-as-a-Service platforms have emerged to simplify the training and deployment of AI models, they still fall short of achieving true democratization of AI. In this paper, we aim to address this gap by comparing several popular AI-as-a-Service platforms and identifying the key requirements for a platform that can achieve true democratization of AI. Our analysis highlights the need for self-hosting options, high scalability, and openness. To address these requirements, we propose our approach: the "Open Space for Machine Learning" platform. Our platform is built on cutting-edge technologies such as Kubernetes, Kubeflow Pipelines, and Ludwig, enabling us to overcome the challenges of democratizing AI. We argue that our approach is more comprehensive and effective in meeting the requirements of democratizing AI than existing AI-as-a-Service platforms.

{{</citation>}}


### (58/108) Retro-BLEU: Quantifying Chemical Plausibility of Retrosynthesis Routes through Reaction Template Sequence Analysis (Junren Li et al., 2023)

{{<citation>}}

Junren Li, Lei Fang, Jian-Guang Lou. (2023)  
**Retro-BLEU: Quantifying Chemical Plausibility of Retrosynthesis Routes through Reaction Template Sequence Analysis**  

---
Primary Category: cs.LG  
Categories: cs-AI, cs-LG, cs.LG, q-bio-BM  
Keywords: BLEU  
[Paper Link](http://arxiv.org/abs/2311.06304v1)  

---


**ABSTRACT**  
Computer-assisted methods have emerged as valuable tools for retrosynthesis analysis. However, quantifying the plausibility of generated retrosynthesis routes remains a challenging task. We introduce Retro-BLEU, a statistical metric adapted from the well-established BLEU score in machine translation, to evaluate the plausibility of retrosynthesis routes based on reaction template sequences analysis. We demonstrate the effectiveness of Retro-BLEU by applying it to a diverse set of retrosynthesis routes generated by state-of-the-art algorithms and compare the performance with other evaluation metrics. The results show that Retro-BLEU is capable of differentiating between plausible and implausible routes. Furthermore, we provide insights into the strengths and weaknesses of Retro-BLEU, paving the way for future developments and improvements in this field.

{{</citation>}}


### (59/108) Recursion in Recursion: Two-Level Nested Recursion for Length Generalization with Scalability (Jishnu Ray Chowdhury et al., 2023)

{{<citation>}}

Jishnu Ray Chowdhury, Cornelia Caragea. (2023)  
**Recursion in Recursion: Two-Level Nested Recursion for Length Generalization with Scalability**  

---
Primary Category: cs.LG  
Categories: cs-CL, cs-LG, cs.LG  
Keywords: Transformer, Transformers  
[Paper Link](http://arxiv.org/abs/2311.04449v1)  

---


**ABSTRACT**  
Binary Balanced Tree RvNNs (BBT-RvNNs) enforce sequence composition according to a preset balanced binary tree structure. Thus, their non-linear recursion depth is just $\log_2 n$ ($n$ being the sequence length). Such logarithmic scaling makes BBT-RvNNs efficient and scalable on long sequence tasks such as Long Range Arena (LRA). However, such computational efficiency comes at a cost because BBT-RvNNs cannot solve simple arithmetic tasks like ListOps. On the flip side, RvNNs (e.g., Beam Tree RvNN) that do succeed on ListOps (and other structure-sensitive tasks like formal logical inference) are generally several times more expensive than even RNNs. In this paper, we introduce a novel framework -- Recursion in Recursion (RIR) to strike a balance between the two sides - getting some of the benefits from both worlds. In RIR, we use a form of two-level nested recursion - where the outer recursion is a $k$-ary balanced tree model with another recursive model (inner recursion) implementing its cell function. For the inner recursion, we choose Beam Tree RvNNs (BT-RvNN). To adjust BT-RvNNs within RIR we also propose a novel strategy of beam alignment. Overall, this entails that the total recursive depth in RIR is upper-bounded by $k \log_k n$. Our best RIR-based model is the first model that demonstrates high ($\geq 90\%$) length-generalization performance on ListOps while at the same time being scalable enough to be trainable on long sequence inputs from LRA. Moreover, in terms of accuracy in the LRA language tasks, it performs competitively with Structured State Space Models (SSMs) without any special initialization - outperforming Transformers by a large margin. On the other hand, while SSMs can marginally outperform RIR on LRA, they (SSMs) fail to length-generalize on ListOps. Our code is available at: \url{https://github.com/JRC1995/BeamRecursionFamily/}.

{{</citation>}}


### (60/108) MixTEA: Semi-supervised Entity Alignment with Mixture Teaching (Feng Xie et al., 2023)

{{<citation>}}

Feng Xie, Xin Song, Xiang Zeng, Xuechen Zhao, Lei Tian, Bin Zhou, Yusong Tan. (2023)  
**MixTEA: Semi-supervised Entity Alignment with Mixture Teaching**  

---
Primary Category: cs.LG  
Categories: cs-AI, cs-LG, cs-SI, cs.LG  
Keywords: Entity Alignment  
[Paper Link](http://arxiv.org/abs/2311.04441v1)  

---


**ABSTRACT**  
Semi-supervised entity alignment (EA) is a practical and challenging task because of the lack of adequate labeled mappings as training data. Most works address this problem by generating pseudo mappings for unlabeled entities. However, they either suffer from the erroneous (noisy) pseudo mappings or largely ignore the uncertainty of pseudo mappings. In this paper, we propose a novel semi-supervised EA method, termed as MixTEA, which guides the model learning with an end-to-end mixture teaching of manually labeled mappings and probabilistic pseudo mappings. We firstly train a student model using few labeled mappings as standard. More importantly, in pseudo mapping learning, we propose a bi-directional voting (BDV) strategy that fuses the alignment decisions in different directions to estimate the uncertainty via the joint matching confidence score. Meanwhile, we also design a matching diversity-based rectification (MDR) module to adjust the pseudo mapping learning, thus reducing the negative influence of noisy mappings. Extensive results on benchmark datasets as well as further analyses demonstrate the superiority and the effectiveness of our proposed method.

{{</citation>}}


### (61/108) A Hierarchical Spatial Transformer for Massive Point Samples in Continuous Space (Wenchong He et al., 2023)

{{<citation>}}

Wenchong He, Zhe Jiang, Tingsong Xiao, Zelin Xu, Shigang Chen, Ronald Fick, Miles Medina, Christine Angelini. (2023)  
**A Hierarchical Spatial Transformer for Massive Point Samples in Continuous Space**  

---
Primary Category: cs.LG  
Categories: cs-LG, cs.LG  
Keywords: Transformer, Transformers  
[Paper Link](http://arxiv.org/abs/2311.04434v1)  

---


**ABSTRACT**  
Transformers are widely used deep learning architectures. Existing transformers are mostly designed for sequences (texts or time series), images or videos, and graphs. This paper proposes a novel transformer model for massive (up to a million) point samples in continuous space. Such data are ubiquitous in environment sciences (e.g., sensor observations), numerical simulations (e.g., particle-laden flow, astrophysics), and location-based services (e.g., POIs and trajectories). However, designing a transformer for massive spatial points is non-trivial due to several challenges, including implicit long-range and multi-scale dependency on irregular points in continuous space, a non-uniform point distribution, the potential high computational costs of calculating all-pair attention across massive points, and the risks of over-confident predictions due to varying point density. To address these challenges, we propose a new hierarchical spatial transformer model, which includes multi-resolution representation learning within a quad-tree hierarchy and efficient spatial attention via coarse approximation. We also design an uncertainty quantification branch to estimate prediction confidence related to input feature noise and point sparsity. We provide a theoretical analysis of computational time complexity and memory costs. Extensive experiments on both real-world and synthetic datasets show that our method outperforms multiple baselines in prediction accuracy and our model can scale up to one million points on one NVIDIA A100 GPU. The code is available at \url{https://github.com/spatialdatasciencegroup/HST}.

{{</citation>}}


## cs.CV (13)



### (62/108) Zero-shot Translation of Attention Patterns in VQA Models to Natural Language (Leonard Salewski et al., 2023)

{{<citation>}}

Leonard Salewski, A. Sophia Koepke, Hendrik P. A. Lensch, Zeynep Akata. (2023)  
**Zero-shot Translation of Attention Patterns in VQA Models to Natural Language**  

---
Primary Category: cs.CV  
Categories: cs-AI, cs-CL, cs-CV, cs.CV  
Keywords: Attention, QA, Question Answering  
[Paper Link](http://arxiv.org/abs/2311.05043v1)  

---


**ABSTRACT**  
Converting a model's internals to text can yield human-understandable insights about the model. Inspired by the recent success of training-free approaches for image captioning, we propose ZS-A2T, a zero-shot framework that translates the transformer attention of a given model into natural language without requiring any training. We consider this in the context of Visual Question Answering (VQA). ZS-A2T builds on a pre-trained large language model (LLM), which receives a task prompt, question, and predicted answer, as inputs. The LLM is guided to select tokens which describe the regions in the input image that the VQA model attended to. Crucially, we determine this similarity by exploiting the text-image matching capabilities of the underlying VQA model. Our framework does not require any training and allows the drop-in replacement of different guiding sources (e.g. attribution instead of attention maps), or language models. We evaluate this novel task on textual explanation datasets for VQA, giving state-of-the-art performances for the zero-shot setting on GQA-REX and VQA-X. Our code is available at: https://github.com/ExplainableML/ZS-A2T.

{{</citation>}}


### (63/108) Active Transfer Learning for Efficient Video-Specific Human Pose Estimation (Hiromu Taketsugu et al., 2023)

{{<citation>}}

Hiromu Taketsugu, Norimichi Ukita. (2023)  
**Active Transfer Learning for Efficient Video-Specific Human Pose Estimation**  

---
Primary Category: cs.CV  
Categories: I-2-10; I-4-8, cs-CV, cs-LG, cs.CV  
Keywords: Active Learning  
[Paper Link](http://arxiv.org/abs/2311.05041v1)  

---


**ABSTRACT**  
Human Pose (HP) estimation is actively researched because of its wide range of applications. However, even estimators pre-trained on large datasets may not perform satisfactorily due to a domain gap between the training and test data. To address this issue, we present our approach combining Active Learning (AL) and Transfer Learning (TL) to adapt HP estimators to individual video domains efficiently. For efficient learning, our approach quantifies (i) the estimation uncertainty based on the temporal changes in the estimated heatmaps and (ii) the unnaturalness in the estimated full-body HPs. These quantified criteria are then effectively combined with the state-of-the-art representativeness criterion to select uncertain and diverse samples for efficient HP estimator learning. Furthermore, we reconsider the existing Active Transfer Learning (ATL) method to introduce novel ideas related to the retraining methods and Stopping Criteria (SC). Experimental results demonstrate that our method enhances learning efficiency and outperforms comparative methods. Our code is publicly available at: https://github.com/ImIntheMiddle/VATL4Pose-WACV2024

{{</citation>}}


### (64/108) S$^3$AD: Semi-supervised Small Apple Detection in Orchard Environments (Robert Johanson et al., 2023)

{{<citation>}}

Robert Johanson, Christian Wilms, Ole Johannsen, Simone Frintrop. (2023)  
**S$^3$AD: Semi-supervised Small Apple Detection in Orchard Environments**  

---
Primary Category: cs.CV  
Categories: cs-CV, cs.CV  
Keywords: Semi-Supervised  
[Paper Link](http://arxiv.org/abs/2311.05029v1)  

---


**ABSTRACT**  
Crop detection is integral for precision agriculture applications such as automated yield estimation or fruit picking. However, crop detection, e.g., apple detection in orchard environments remains challenging due to a lack of large-scale datasets and the small relative size of the crops in the image. In this work, we address these challenges by reformulating the apple detection task in a semi-supervised manner. To this end, we provide the large, high-resolution dataset MAD comprising 105 labeled images with 14,667 annotated apple instances and 4,440 unlabeled images. Utilizing this dataset, we also propose a novel Semi-Supervised Small Apple Detection system S$^3$AD based on contextual attention and selective tiling to improve the challenging detection of small apples, while limiting the computational overhead. We conduct an extensive evaluation on MAD and the MSU dataset, showing that S$^3$AD substantially outperforms strong fully-supervised baselines, including several small object detection systems, by up to $14.9\%$. Additionally, we exploit the detailed annotations of our dataset w.r.t. apple properties to analyze the influence of relative size or level of occlusion on the results of various systems, quantifying current challenges.

{{</citation>}}


### (65/108) Familiarity-Based Open-Set Recognition Under Adversarial Attacks (Philip Enevoldsen et al., 2023)

{{<citation>}}

Philip Enevoldsen, Christian Gundersen, Nico Lang, Serge Belongie, Christian Igel. (2023)  
**Familiarity-Based Open-Set Recognition Under Adversarial Attacks**  

---
Primary Category: cs.CV  
Categories: cs-CV, cs-LG, cs.CV  
Keywords: Adversarial Attack, ImageNet  
[Paper Link](http://arxiv.org/abs/2311.05006v1)  

---


**ABSTRACT**  
Open-set recognition (OSR), the identification of novel categories, can be a critical component when deploying classification models in real-world applications. Recent work has shown that familiarity-based scoring rules such as the Maximum Softmax Probability (MSP) or the Maximum Logit Score (MLS) are strong baselines when the closed-set accuracy is high. However, one of the potential weaknesses of familiarity-based OSR are adversarial attacks. Here, we present gradient-based adversarial attacks on familiarity scores for both types of attacks, False Familiarity and False Novelty attacks, and evaluate their effectiveness in informed and uninformed settings on TinyImageNet.

{{</citation>}}


### (66/108) Exploiting Inductive Biases in Video Modeling through Neural CDEs (Johnathan Chiu et al., 2023)

{{<citation>}}

Johnathan Chiu, Samuel Duffield, Max Hunter-Gordon, Kaelan Donatella, Max Aifer, Andi Gu. (2023)  
**Exploiting Inductive Biases in Video Modeling through Neural CDEs**  

---
Primary Category: cs.CV  
Categories: cs-CV, cs.CV  
Keywords: Bias  
[Paper Link](http://arxiv.org/abs/2311.04986v1)  

---


**ABSTRACT**  
We introduce a novel approach to video modeling that leverages controlled differential equations (CDEs) to address key challenges in video tasks, notably video interpolation and mask propagation. We apply CDEs at varying resolutions leading to a continuous-time U-Net architecture. Unlike traditional methods, our approach does not require explicit optical flow learning, and instead makes use of the inherent continuous-time features of CDEs to produce a highly expressive video model. We demonstrate competitive performance against state-of-the-art models for video interpolation and mask propagation tasks.

{{</citation>}}


### (67/108) GENOME: GenerativE Neuro-symbOlic visual reasoning by growing and reusing ModulEs (Zhenfang Chen et al., 2023)

{{<citation>}}

Zhenfang Chen, Rui Sun, Wenjun Liu, Yining Hong, Chuang Gan. (2023)  
**GENOME: GenerativE Neuro-symbOlic visual reasoning by growing and reusing ModulEs**  

---
Primary Category: cs.CV  
Categories: cs-CV, cs.CV  
Keywords: Language Model  
[Paper Link](http://arxiv.org/abs/2311.04901v1)  

---


**ABSTRACT**  
Recent works have shown that Large Language Models (LLMs) could empower traditional neuro-symbolic models via programming capabilities to translate language into module descriptions, thus achieving strong visual reasoning results while maintaining the model's transparency and efficiency. However, these models usually exhaustively generate the entire code snippet given each new instance of a task, which is extremely ineffective. We propose generative neuro-symbolic visual reasoning by growing and reusing modules. Specifically, our model consists of three unique stages, module initialization, module generation, and module execution. First, given a vision-language task, we adopt LLMs to examine whether we could reuse and grow over established modules to handle this new task. If not, we initialize a new module needed by the task and specify the inputs and outputs of this new module. After that, the new module is created by querying LLMs to generate corresponding code snippets that match the requirements. In order to get a better sense of the new module's ability, we treat few-shot training examples as test cases to see if our new module could pass these cases. If yes, the new module is added to the module library for future reuse. Finally, we evaluate the performance of our model on the testing set by executing the parsed programs with the newly made visual modules to get the results. We find the proposed model possesses several advantages. First, it performs competitively on standard tasks like visual question answering and referring expression comprehension; Second, the modules learned from one task can be seamlessly transferred to new tasks; Last but not least, it is able to adapt to new visual reasoning tasks by observing a few training examples and reusing modules.

{{</citation>}}


### (68/108) Towards Few-Annotation Learning in Computer Vision: Application to Image Classification and Object Detection tasks (Quentin Bouniot, 2023)

{{<citation>}}

Quentin Bouniot. (2023)  
**Towards Few-Annotation Learning in Computer Vision: Application to Image Classification and Object Detection tasks**  

---
Primary Category: cs.CV  
Categories: cs-AI, cs-CV, cs-LG, cs.CV, stat-ML  
Keywords: Computer Vision, Contrastive Learning, Few-Shot, Image Classification, Object Detection, Representation Learning, Transformer  
[Paper Link](http://arxiv.org/abs/2311.04888v1)  

---


**ABSTRACT**  
In this thesis, we develop theoretical, algorithmic and experimental contributions for Machine Learning with limited labels, and more specifically for the tasks of Image Classification and Object Detection in Computer Vision. In a first contribution, we are interested in bridging the gap between theory and practice for popular Meta-Learning algorithms used in Few-Shot Classification. We make connections to Multi-Task Representation Learning, which benefits from solid theoretical foundations, to verify the best conditions for a more efficient meta-learning. Then, to leverage unlabeled data when training object detectors based on the Transformer architecture, we propose both an unsupervised pretraining and a semi-supervised learning method in two other separate contributions. For pretraining, we improve Contrastive Learning for object detectors by introducing the localization information. Finally, our semi-supervised method is the first tailored to transformer-based detectors.

{{</citation>}}


### (69/108) Self-Supervised Learning for Visual Relationship Detection through Masked Bounding Box Reconstruction (Zacharias Anastasakis et al., 2023)

{{<citation>}}

Zacharias Anastasakis, Dimitrios Mallis, Markos Diomataris, George Alexandridis, Stefanos Kollias, Vassilis Pitsikalis. (2023)  
**Self-Supervised Learning for Visual Relationship Detection through Masked Bounding Box Reconstruction**  

---
Primary Category: cs.CV  
Categories: cs-CV, cs.CV  
Keywords: Self-Supervised  
[Paper Link](http://arxiv.org/abs/2311.04834v1)  

---


**ABSTRACT**  
We present a novel self-supervised approach for representation learning, particularly for the task of Visual Relationship Detection (VRD). Motivated by the effectiveness of Masked Image Modeling (MIM), we propose Masked Bounding Box Reconstruction (MBBR), a variation of MIM where a percentage of the entities/objects within a scene are masked and subsequently reconstructed based on the unmasked objects. The core idea is that, through object-level masked modeling, the network learns context-aware representations that capture the interaction of objects within a scene and thus are highly predictive of visual object relationships. We extensively evaluate learned representations, both qualitatively and quantitatively, in a few-shot setting and demonstrate the efficacy of MBBR for learning robust visual representations, particularly tailored for VRD. The proposed method is able to surpass state-of-the-art VRD methods on the Predicate Detection (PredDet) evaluation setting, using only a few annotated samples. We make our code available at https://github.com/deeplab-ai/SelfSupervisedVRD.

{{</citation>}}


### (70/108) SODAWideNet -- Salient Object Detection with an Attention augmented Wide Encoder Decoder network without ImageNet pre-training (Rohit Venkata Sai Dulam et al., 2023)

{{<citation>}}

Rohit Venkata Sai Dulam, Chandra Kambhamettu. (2023)  
**SODAWideNet -- Salient Object Detection with an Attention augmented Wide Encoder Decoder network without ImageNet pre-training**  

---
Primary Category: cs.CV  
Categories: cs-CV, cs.CV  
Keywords: Attention, ImageNet, Object Detection  
[Paper Link](http://arxiv.org/abs/2311.04828v2)  

---


**ABSTRACT**  
Developing a new Salient Object Detection (SOD) model involves selecting an ImageNet pre-trained backbone and creating novel feature refinement modules to use backbone features. However, adding new components to a pre-trained backbone needs retraining the whole network on the ImageNet dataset, which requires significant time. Hence, we explore developing a neural network from scratch directly trained on SOD without ImageNet pre-training. Such a formulation offers full autonomy to design task-specific components. To that end, we propose SODAWideNet, an encoder-decoder-style network for Salient Object Detection. We deviate from the commonly practiced paradigm of narrow and deep convolutional models to a wide and shallow architecture, resulting in a parameter-efficient deep neural network. To achieve a shallower network, we increase the receptive field from the beginning of the network using a combination of dilated convolutions and self-attention. Therefore, we propose Multi Receptive Field Feature Aggregation Module (MRFFAM) that efficiently obtains discriminative features from farther regions at higher resolutions using dilated convolutions. Next, we propose Multi-Scale Attention (MSA), which creates a feature pyramid and efficiently computes attention across multiple resolutions to extract global features from larger feature maps. Finally, we propose two variants, SODAWideNet-S (3.03M) and SODAWideNet (9.03M), that achieve competitive performance against state-of-the-art models on five datasets.

{{</citation>}}


### (71/108) Domain Adaptive Object Detection via Balancing Between Self-Training and Adversarial Learning (Muhammad Akhtar Munir et al., 2023)

{{<citation>}}

Muhammad Akhtar Munir, Muhammad Haris Khan, M. Saquib Sarfraz, Mohsen Ali. (2023)  
**Domain Adaptive Object Detection via Balancing Between Self-Training and Adversarial Learning**  

---
Primary Category: cs.CV  
Categories: cs-CV, cs.CV  
Keywords: Object Detection  
[Paper Link](http://arxiv.org/abs/2311.04815v1)  

---


**ABSTRACT**  
Deep learning based object detectors struggle generalizing to a new target domain bearing significant variations in object and background. Most current methods align domains by using image or instance-level adversarial feature alignment. This often suffers due to unwanted background and lacks class-specific alignment. A straightforward approach to promote class-level alignment is to use high confidence predictions on unlabeled domain as pseudo-labels. These predictions are often noisy since model is poorly calibrated under domain shift. In this paper, we propose to leverage model's predictive uncertainty to strike the right balance between adversarial feature alignment and class-level alignment. We develop a technique to quantify predictive uncertainty on class assignments and bounding-box predictions. Model predictions with low uncertainty are used to generate pseudo-labels for self-training, whereas the ones with higher uncertainty are used to generate tiles for adversarial feature alignment. This synergy between tiling around uncertain object regions and generating pseudo-labels from highly certain object regions allows capturing both image and instance-level context during the model adaptation. We report thorough ablation study to reveal the impact of different components in our approach. Results on five diverse and challenging adaptation scenarios show that our approach outperforms existing state-of-the-art methods with noticeable margins.

{{</citation>}}


### (72/108) Be Careful When Evaluating Explanations Regarding Ground Truth (Hubert Baniecki et al., 2023)

{{<citation>}}

Hubert Baniecki, Maciej Chrabaszcz, Andreas Holzinger, Bastian Pfeifer, Anna Saranti, Przemyslaw Biecek. (2023)  
**Be Careful When Evaluating Explanations Regarding Ground Truth**  

---
Primary Category: cs.CV  
Categories: cs-CV, cs-LG, cs.CV  
Keywords: AI  
[Paper Link](http://arxiv.org/abs/2311.04813v1)  

---


**ABSTRACT**  
Evaluating explanations of image classifiers regarding ground truth, e.g. segmentation masks defined by human perception, primarily evaluates the quality of the models under consideration rather than the explanation methods themselves. Driven by this observation, we propose a framework for $\textit{jointly}$ evaluating the robustness of safety-critical systems that $\textit{combine}$ a deep neural network with an explanation method. These are increasingly used in real-world applications like medical image analysis or robotics. We introduce a fine-tuning procedure to (mis)align model$\unicode{x2013}$explanation pipelines with ground truth and use it to quantify the potential discrepancy between worst and best-case scenarios of human alignment. Experiments across various model architectures and post-hoc local interpretation methods provide insights into the robustness of vision transformers and the overall vulnerability of such AI systems to potential adversarial attacks.

{{</citation>}}


### (73/108) Interpretable Geoscience Artificial Intelligence (XGeoS-AI): Application to Demystify Image Recognition (Jin-Jian Xu et al., 2023)

{{<citation>}}

Jin-Jian Xu, Hao Zhang, Chao-Sheng Tang, Lin Li, Bin Shi. (2023)  
**Interpretable Geoscience Artificial Intelligence (XGeoS-AI): Application to Demystify Image Recognition**  

---
Primary Category: cs.CV  
Categories: cs-AI, cs-CV, cs.CV, eess-IV  
Keywords: AI  
[Paper Link](http://arxiv.org/abs/2311.04940v1)  

---


**ABSTRACT**  
As Earth science enters the era of big data, artificial intelligence (AI) not only offers great potential for solving geoscience problems, but also plays a critical role in accelerating the understanding of the complex, interactive, and multiscale processes of Earth's behavior. As geoscience AI models are progressively utilized for significant predictions in crucial situations, geoscience researchers are increasingly demanding their interpretability and versatility. This study proposes an interpretable geoscience artificial intelligence (XGeoS-AI) framework to unravel the mystery of image recognition in the Earth sciences, and its effectiveness and versatility is demonstrated by taking computed tomography (CT) image recognition as an example. Inspired by the mechanism of human vision, the proposed XGeoS-AI framework generates a threshold value from a local region within the whole image to complete the recognition. Different kinds of artificial intelligence (AI) methods, such as Support Vector Regression (SVR), Multilayer Perceptron (MLP), Convolutional Neural Network (CNN), can be adopted as the AI engines of the proposed XGeoS-AI framework to efficiently complete geoscience image recognition tasks. Experimental results demonstrate that the effectiveness, versatility, and heuristics of the proposed framework have great potential in solving geoscience image recognition problems. Interpretable AI should receive more and more attention in the field of the Earth sciences, which is the key to promoting more rational and wider applications of AI in the field of Earth sciences. In addition, the proposed interpretable framework may be the forerunner of technological innovation in the Earth sciences.

{{</citation>}}


### (74/108) Improved DDIM Sampling with Moment Matching Gaussian Mixtures (Prasad Gabbur, 2023)

{{<citation>}}

Prasad Gabbur. (2023)  
**Improved DDIM Sampling with Moment Matching Gaussian Mixtures**  

---
Primary Category: cs.CV  
Categories: I-2, I-4, cs-AI, cs-CV, cs-LG, cs.CV  
Keywords: ImageNet  
[Paper Link](http://arxiv.org/abs/2311.04938v1)  

---


**ABSTRACT**  
We propose using a Gaussian Mixture Model (GMM) as reverse transition operator (kernel) within the Denoising Diffusion Implicit Models (DDIM) framework, which is one of the most widely used approaches for accelerated sampling from pre-trained Denoising Diffusion Probabilistic Models (DDPM). Specifically we match the first and second order central moments of the DDPM forward marginals by constraining the parameters of the GMM. We see that moment matching is sufficient to obtain samples with equal or better quality than the original DDIM with Gaussian kernels. We provide experimental results with unconditional models trained on CelebAHQ and FFHQ and class-conditional models trained on ImageNet datasets respectively. Our results suggest that using the GMM kernel leads to significant improvements in the quality of the generated samples when the number of sampling steps is small, as measured by FID and IS metrics. For example on ImageNet 256x256, using 10 sampling steps, we achieve a FID of 6.94 and IS of 207.85 with a GMM kernel compared to 10.15 and 196.73 respectively with a Gaussian kernel.

{{</citation>}}


## cs.IR (5)



### (75/108) Automated Annotation of Scientific Texts for ML-based Keyphrase Extraction and Validation (Oluwamayowa O. Amusat et al., 2023)

{{<citation>}}

Oluwamayowa O. Amusat, Harshad Hegde, Christopher J. Mungall, Anna Giannakou, Neil P. Byers, Dan Gunter, Kjiersten Fagnan, Lavanya Ramakrishnan. (2023)  
**Automated Annotation of Scientific Texts for ML-based Keyphrase Extraction and Validation**  

---
Primary Category: cs.IR  
Categories: cs-AI, cs-IR, cs-LG, cs.IR, q-bio-GN  
Keywords: Keyphrase Extraction  
[Paper Link](http://arxiv.org/abs/2311.05042v1)  

---


**ABSTRACT**  
Advanced omics technologies and facilities generate a wealth of valuable data daily; however, the data often lacks the essential metadata required for researchers to find and search them effectively. The lack of metadata poses a significant challenge in the utilization of these datasets. Machine learning-based metadata extraction techniques have emerged as a potentially viable approach to automatically annotating scientific datasets with the metadata necessary for enabling effective search. Text labeling, usually performed manually, plays a crucial role in validating machine-extracted metadata. However, manual labeling is time-consuming; thus, there is an need to develop automated text labeling techniques in order to accelerate the process of scientific innovation. This need is particularly urgent in fields such as environmental genomics and microbiome science, which have historically received less attention in terms of metadata curation and creation of gold-standard text mining datasets.   In this paper, we present two novel automated text labeling approaches for the validation of ML-generated metadata for unlabeled texts, with specific applications in environmental genomics. Our techniques show the potential of two new ways to leverage existing information about the unlabeled texts and the scientific domain. The first technique exploits relationships between different types of data sources related to the same research study, such as publications and proposals. The second technique takes advantage of domain-specific controlled vocabularies or ontologies. In this paper, we detail applying these approaches for ML-generated metadata validation. Our results show that the proposed label assignment approaches can generate both generic and highly-specific text labels for the unlabeled texts, with up to 44% of the labels matching with those suggested by a ML keyword extraction algorithm.

{{</citation>}}


### (76/108) Towards Effective Paraphrasing for Information Disguise (Anmol Agarwal et al., 2023)

{{<citation>}}

Anmol Agarwal, Shrey Gupta, Vamshi Bonagiri, Manas Gaur, Joseph Reagle, Ponnurangam Kumaraguru. (2023)  
**Towards Effective Paraphrasing for Information Disguise**  

---
Primary Category: cs.IR  
Categories: cs-AI, cs-IR, cs.IR  
Keywords: AI, NLP, Natural Language Processing  
[Paper Link](http://arxiv.org/abs/2311.05018v1)  

---


**ABSTRACT**  
Information Disguise (ID), a part of computational ethics in Natural Language Processing (NLP), is concerned with best practices of textual paraphrasing to prevent the non-consensual use of authors' posts on the Internet. Research on ID becomes important when authors' written online communication pertains to sensitive domains, e.g., mental health. Over time, researchers have utilized AI-based automated word spinners (e.g., SpinRewriter, WordAI) for paraphrasing content. However, these tools fail to satisfy the purpose of ID as their paraphrased content still leads to the source when queried on search engines. There is limited prior work on judging the effectiveness of paraphrasing methods for ID on search engines or their proxies, neural retriever (NeurIR) models. We propose a framework where, for a given sentence from an author's post, we perform iterative perturbation on the sentence in the direction of paraphrasing with an attempt to confuse the search mechanism of a NeurIR system when the sentence is queried on it. Our experiments involve the subreddit 'r/AmItheAsshole' as the source of public content and Dense Passage Retriever as a NeurIR system-based proxy for search engines. Our work introduces a novel method of phrase-importance rankings using perplexity scores and involves multi-level phrase substitutions via beam search. Our multi-phrase substitution scheme succeeds in disguising sentences 82% of the time and hence takes an essential step towards enabling researchers to disguise sensitive content effectively before making it public. We also release the code of our approach.

{{</citation>}}


### (77/108) Evaluating Generative Ad Hoc Information Retrieval (Lukas Gienapp et al., 2023)

{{<citation>}}

Lukas Gienapp, Harrisen Scells, Niklas Deckers, Janek Bevendorff, Shuai Wang, Johannes Kiesel, Shahbaz Syed, Maik Fröbe, Guido Zucoon, Benno Stein, Matthias Hagen, Martin Potthast. (2023)  
**Evaluating Generative Ad Hoc Information Retrieval**  

---
Primary Category: cs.IR  
Categories: cs-CL, cs-IR, cs.IR  
Keywords: Information Retrieval  
[Paper Link](http://arxiv.org/abs/2311.04694v1)  

---


**ABSTRACT**  
Recent advances in large language models have enabled the development of viable generative information retrieval systems. A generative retrieval system returns a grounded generated text in response to an information need instead of the traditional document ranking. Quantifying the utility of these types of responses is essential for evaluating generative retrieval systems. As the established evaluation methodology for ranking-based ad hoc retrieval may seem unsuitable for generative retrieval, new approaches for reliable, repeatable, and reproducible experimentation are required. In this paper, we survey the relevant information retrieval and natural language processing literature, identify search tasks and system architectures in generative retrieval, develop a corresponding user model, and study its operationalization. This theoretical analysis provides a foundation and new insights for the evaluation of generative ad hoc retrieval systems.

{{</citation>}}


### (78/108) A Comprehensive Summarization and Evaluation of Feature Refinement Modules for CTR Prediction (Fangye Wang et al., 2023)

{{<citation>}}

Fangye Wang, Yingxu Wang, Hansu Gu, Dongsheng Li, Tun Lu, Peng Zhang, Li Shang, Ning Gu. (2023)  
**A Comprehensive Summarization and Evaluation of Feature Refinement Modules for CTR Prediction**  

---
Primary Category: cs.IR  
Categories: cs-IR, cs.IR  
Keywords: Summarization  
[Paper Link](http://arxiv.org/abs/2311.04625v1)  

---


**ABSTRACT**  
Click-through rate (CTR) prediction is widely used in academia and industry. Most CTR tasks fall into a feature embedding \& feature interaction paradigm, where the accuracy of CTR prediction is mainly improved by designing practical feature interaction structures. However, recent studies have argued that the fixed feature embedding learned only through the embedding layer limits the performance of existing CTR models. Some works apply extra modules on top of the embedding layer to dynamically refine feature representations in different instances, making it effective and easy to integrate with existing CTR methods. Despite the promising results, there is a lack of a systematic review and summarization of this new promising direction on the CTR task. To fill this gap, we comprehensively summarize and define a new module, namely \textbf{feature refinement} (FR) module, that can be applied between feature embedding and interaction layers. We extract 14 FR modules from previous works, including instances where the FR module was proposed but not clearly defined or explained. We fully assess the effectiveness and compatibility of existing FR modules through comprehensive and extensive experiments with over 200 augmented models and over 4,000 runs for more than 15,000 GPU hours. The results offer insightful guidelines for researchers, and all benchmarking code and experimental results are open-sourced. In addition, we present a new architecture of assigning independent FR modules to separate sub-networks for parallel CTR models, as opposed to the conventional method of inserting a shared FR module on top of the embedding layer. Our approach is also supported by comprehensive experiments demonstrating its effectiveness.

{{</citation>}}


### (79/108) From Input to Output: A Multi-layer Knowledge Distillation Framework for Compressing Recommendation Models (Zhangchi Zhu et al., 2023)

{{<citation>}}

Zhangchi Zhu, Wei Zhang. (2023)  
**From Input to Output: A Multi-layer Knowledge Distillation Framework for Compressing Recommendation Models**  

---
Primary Category: cs.IR  
Categories: cs-IR, cs.IR  
Keywords: Knowledge Distillation  
[Paper Link](http://arxiv.org/abs/2311.04549v1)  

---


**ABSTRACT**  
To reduce the size of recommendation models, there have been many studies on compressing recommendation models using knowledge distillation. In this paper, we decompose recommendation models into three layers, i.e., the input layer, the intermediate layer, and the output layer, and address deficiencies layer by layer. First, previous methods focus only on two layers, neglecting the input layer. Second, in the intermediate layer, existing methods ignore the inconsistency of user preferences induced by the projectors. Third, in the output layer, existing methods use only hard labels rather than soft labels from the teacher. To address these deficiencies, we propose \textbf{M}ulti-layer \textbf{K}nowledge \textbf{D}istillation (MKD), which consists of three components: 1) Distillation with Neighbor-based Knowledge (NKD) utilizes the teacher's knowledge about entities with similar characteristics in the input layer to enable the student to learn robust representations. 2) Distillation with Consistent Preference (CPD) reduces the inconsistency of user preferences caused by projectors in the intermediate layer by two regularization terms. 3) Distillation with Soft Labels (SLD) constructs soft labels in the output layer by considering the predictions of both the teacher and the student. Our extensive experiments show that MKD even outperforms the teacher with one-tenth of the model size.

{{</citation>}}


## cs.AR (3)



### (80/108) Just-in-time Quantization with Processing-In-Memory for Efficient ML Training (Mohamed Assem Ibrahim et al., 2023)

{{<citation>}}

Mohamed Assem Ibrahim, Shaizeen Aga, Ada Li, Suchita Pati, Mahzabeen Islam. (2023)  
**Just-in-time Quantization with Processing-In-Memory for Efficient ML Training**  

---
Primary Category: cs.AR  
Categories: cs-AR, cs-DC, cs.AR  
Keywords: Quantization  
[Paper Link](http://arxiv.org/abs/2311.05034v1)  

---


**ABSTRACT**  
Data format innovations have been critical for machine learning (ML) scaling, which in turn fuels ground-breaking ML capabilities. However, even in the presence of low-precision formats, model weights are often stored in both high-precision and low-precision during training. Furthermore, with emerging directional data formats (e.g., MX9, MX6, etc.) multiple low-precision weight copies can be required. To lower memory capacity needs of weights, we explore just-in-time quantization (JIT-Q) where we only store high-precision weights in memory and generate low-precision weights only when needed. To perform JIT-Q efficiently, in this work, we evaluate emerging processing-in-memory (PIM) technology to execute quantization. With PIM, we can offload quantization to in-memory compute units enabling quantization to be performed without incurring costly data movement while allowing quantization to be concurrent with accelerator computation. Our proposed PIM-offloaded quantization keeps up with GPU compute and delivers considerable capacity savings (up to 24\%) at marginal throughput loss (up to 2.4\%). Said memory capacity savings can unlock several benefits such as fitting larger model in the same system, reducing model parallelism requirement, and improving overall ML training efficiency.

{{</citation>}}


### (81/108) MaxEVA: Maximizing the Efficiency of Matrix Multiplication on Versal AI Engine (Endri Taka et al., 2023)

{{<citation>}}

Endri Taka, Aman Arora, Kai-Chiang Wu, Diana Marculescu. (2023)  
**MaxEVA: Maximizing the Efficiency of Matrix Multiplication on Versal AI Engine**  

---
Primary Category: cs.AR  
Categories: cs-AR, cs.AR  
Keywords: AI  
[Paper Link](http://arxiv.org/abs/2311.04980v1)  

---


**ABSTRACT**  
The increasing computational and memory requirements of Deep Learning (DL) workloads has led to outstanding innovations in hardware architectures. An archetype of such architectures is the novel Versal AI Engine (AIE) by AMD/Xilinx. The AIE comprises multiple programmable processors optimized for vector-based algorithms. An AIE array consisting of 400 processor cores, operating at 1.25 GHz is able to deliver a peak throughput of 8 TFLOPs for 32-bit floating-point (fp32), and 128 TOPs for 8-bit integer (int8) precision. In this work, we propose MaxEVA: a novel framework to efficiently map Matrix Multiplication (MatMul) workloads on Versal AIE devices. Our framework maximizes the performance and energy efficiency of MatMul applications by efficiently exploiting features of the AIE architecture and resolving performance bottlenecks from multiple angles. When demonstrating on the VC1902 device of the VCK190 board, MaxEVA accomplishes up to 5.44 TFLOPs and 77.01 TOPs throughput for fp32 and int8 precisions, respectively. In terms of energy efficiency, MaxEVA attains up to 85.11 GFLOPs/W for fp32, and 1.73 TOPs/W for int8. Our proposed method substantially outperforms the state-of-the-art approach by exhibiting up to 2.19x throughput gain and 29.4% higher energy efficiency. The MaxEVA framework provides notable insights to fill the knowledge gap in effectively designing MatMul-based DL workloads on the new Versal AIE devices.

{{</citation>}}


### (82/108) Evaluating Emerging AI/ML Accelerators: IPU, RDU, and NVIDIA/AMD GPUs (Hongwu Peng et al., 2023)

{{<citation>}}

Hongwu Peng, Caiwen Ding, Tong Geng, Sutanay Choudhury, Kevin Barker, Ang Li. (2023)  
**Evaluating Emerging AI/ML Accelerators: IPU, RDU, and NVIDIA/AMD GPUs**  

---
Primary Category: cs.AR  
Categories: C-4, cs-AR, cs-DC, cs-LG, cs-PF, cs.AR  
Keywords: AI  
[Paper Link](http://arxiv.org/abs/2311.04417v1)  

---


**ABSTRACT**  
The relentless advancement of artificial intelligence (AI) and machine learning (ML) applications necessitates the development of specialized hardware accelerators capable of handling the increasing complexity and computational demands. Traditional computing architectures, based on the von Neumann model, are being outstripped by the requirements of contemporary AI/ML algorithms, leading to a surge in the creation of accelerators like the Graphcore Intelligence Processing Unit (IPU), Sambanova Reconfigurable Dataflow Unit (RDU), and enhanced GPU platforms. These hardware accelerators are characterized by their innovative data-flow architectures and other design optimizations that promise to deliver superior performance and energy efficiency for AI/ML tasks.   This research provides a preliminary evaluation and comparison of these commercial AI/ML accelerators, delving into their hardware and software design features to discern their strengths and unique capabilities. By conducting a series of benchmark evaluations on common DNN operators and other AI/ML workloads, we aim to illuminate the advantages of data-flow architectures over conventional processor designs and offer insights into the performance trade-offs of each platform. The findings from our study will serve as a valuable reference for the design and performance expectations of research prototypes, thereby facilitating the development of next-generation hardware accelerators tailored for the ever-evolving landscape of AI/ML applications. Through this analysis, we aspire to contribute to the broader understanding of current accelerator technologies and to provide guidance for future innovations in the field.

{{</citation>}}


## cs.RO (2)



### (83/108) Fuzzy Ensembles of Reinforcement Learning Policies for Robotic Systems with Varied Parameters (Abdel Gafoor Haddad et al., 2023)

{{<citation>}}

Abdel Gafoor Haddad, Mohammed B. Mohiuddin, Igor Boiko, Yahya Zweiri. (2023)  
**Fuzzy Ensembles of Reinforcement Learning Policies for Robotic Systems with Varied Parameters**  

---
Primary Category: cs.RO  
Categories: cs-RO, cs-SY, cs.RO, eess-SY  
Keywords: Reinforcement Learning  
[Paper Link](http://arxiv.org/abs/2311.05655v1)  

---


**ABSTRACT**  
Reinforcement Learning (RL) is an emerging approach to control many dynamical systems for which classical control approaches are not applicable or insufficient. However, the resultant policies may not generalize to variations in the parameters that the system may exhibit. This paper presents a powerful yet simple algorithm in which collaboration is facilitated between RL agents that are trained independently to perform the same task but with different system parameters. The independency among agents allows the exploitation of multi-core processing to perform parallel training. Two examples are provided to demonstrate the effectiveness of the proposed technique. The main demonstration is performed on a quadrotor with slung load tracking problem in a real-time experimental setup. It is shown that integrating the developed algorithm outperforms individual policies by reducing the RMSE tracking error. The robustness of the ensemble is also verified against wind disturbance.

{{</citation>}}


### (84/108) The voraus-AD Dataset for Anomaly Detection in Robot Applications (Jan Thieß Brockmann et al., 2023)

{{<citation>}}

Jan Thieß Brockmann, Marco Rudolph, Bodo Rosenhahn, Bastian Wandt. (2023)  
**The voraus-AD Dataset for Anomaly Detection in Robot Applications**  

---
Primary Category: cs.RO  
Categories: cs-AI, cs-LG, cs-RO, cs.RO  
Keywords: Anomaly Detection  
[Paper Link](http://arxiv.org/abs/2311.04765v1)  

---


**ABSTRACT**  
During the operation of industrial robots, unusual events may endanger the safety of humans and the quality of production. When collecting data to detect such cases, it is not ensured that data from all potentially occurring errors is included as unforeseeable events may happen over time. Therefore, anomaly detection (AD) delivers a practical solution, using only normal data to learn to detect unusual events. We introduce a dataset that allows training and benchmarking of anomaly detection methods for robotic applications based on machine data which will be made publicly available to the research community. As a typical robot task the dataset includes a pick-and-place application which involves movement, actions of the end effector and interactions with the objects of the environment. Since several of the contained anomalies are not task-specific but general, evaluations on our dataset are transferable to other robotics applications as well. Additionally, we present MVT-Flow (multivariate time-series flow) as a new baseline method for anomaly detection: It relies on deep-learning-based density estimation with normalizing flows, tailored to the data domain by taking its structure into account for the architecture. Our evaluation shows that MVT-Flow outperforms baselines from previous work by a large margin of 6.2% in area under ROC.

{{</citation>}}


## eess.SY (1)



### (85/108) Reinforcement Learning Generalization for Nonlinear Systems Through Dual-Scale Homogeneity Transformations (Abdel Gafoor Haddad et al., 2023)

{{<citation>}}

Abdel Gafoor Haddad, Igor Boiko, Yahya Zweiri. (2023)  
**Reinforcement Learning Generalization for Nonlinear Systems Through Dual-Scale Homogeneity Transformations**  

---
Primary Category: eess.SY  
Categories: cs-SY, eess-SY, eess.SY  
Keywords: Reinforcement Learning  
[Paper Link](http://arxiv.org/abs/2311.05013v1)  

---


**ABSTRACT**  
Reinforcement learning is an emerging approach to control dynamical systems for which classical approaches are difficult to apply. However, trained agents may not generalize against the variations of system parameters. This paper presents the concept of dual-scale homogeneity, an important property in understating the scaling behavior of nonlinear systems. Furthermore, it also presents an effective yet simple approach to designing a parameter-dependent control law that homogenizes a nonlinear system. The presented approach is applied to two systems, demonstrating its ability to provide a consistent performance irrespective of parameters variations. To demonstrate the practicality of the proposed approach, the control policy is generated by a deep deterministic policy gradient to control the load position of a quadrotor with a slung load. The proposed synergy between the homogeneity transformations and reinforcement learning yields superior performance compared to other recent learning-based control techniques. It achieves a success rate of 96% in bringing the load to its designated target with a 3D RMSE of 0.0253 m. The video that shows the experimental results along with a summary of the paper is available at this link.

{{</citation>}}


## eess.AS (1)



### (86/108) GPU-Accelerated WFST Beam Search Decoder for CTC-based Speech Recognition (Daniel Galvez et al., 2023)

{{<citation>}}

Daniel Galvez, Tim Kaldewey. (2023)  
**GPU-Accelerated WFST Beam Search Decoder for CTC-based Speech Recognition**  

---
Primary Category: eess.AS  
Categories: cs-LG, eess-AS, eess.AS  
Keywords: Speech Recognition  
[Paper Link](http://arxiv.org/abs/2311.04996v1)  

---


**ABSTRACT**  
While Connectionist Temporal Classification (CTC) models deliver state-of-the-art accuracy in automated speech recognition (ASR) pipelines, their performance has been limited by CPU-based beam search decoding. We introduce a GPU-accelerated Weighted Finite State Transducer (WFST) beam search decoder compatible with current CTC models. It increases pipeline throughput and decreases latency, supports streaming inference, and also supports advanced features like utterance-specific word boosting via on-the-fly composition. We provide pre-built DLPack-based python bindings for ease of use with Python-based machine learning frameworks at https://github.com/nvidia-riva/riva-asrlib-decoder. We evaluated our decoder for offline and online scenarios, demonstrating that it is the fastest beam search decoder for CTC models. In the offline scenario it achieves up to 7 times more throughput than the current state-of-the-art CPU decoder and in the online streaming scenario, it achieves nearly 8 times lower latency, with same or better word error rate.

{{</citation>}}


## cs.AI (7)



### (87/108) ADaPT: As-Needed Decomposition and Planning with Language Models (Archiki Prasad et al., 2023)

{{<citation>}}

Archiki Prasad, Alexander Koller, Mareike Hartmann, Peter Clark, Ashish Sabharwal, Mohit Bansal, Tushar Khot. (2023)  
**ADaPT: As-Needed Decomposition and Planning with Language Models**  

---
Primary Category: cs.AI  
Categories: cs-AI, cs-CL, cs-LG, cs.AI  
Keywords: Language Model  
[Paper Link](http://arxiv.org/abs/2311.05772v1)  

---


**ABSTRACT**  
Large Language Models (LLMs) are increasingly being used for interactive decision-making tasks requiring planning and adapting to the environment. Recent works employ LLMs-as-agents in broadly two ways: iteratively determining the next action (iterative executors) or generating plans and executing sub-tasks using LLMs (plan-and-execute). However, these methods struggle with task complexity, as the inability to execute any sub-task may lead to task failure. To address these shortcomings, we introduce As-Needed Decomposition and Planning for complex Tasks (ADaPT), an approach that explicitly plans and decomposes complex sub-tasks as-needed, i.e., when the LLM is unable to execute them. ADaPT recursively decomposes sub-tasks to adapt to both task complexity and LLM capability. Our results demonstrate that ADaPT substantially outperforms established strong baselines, achieving success rates up to 28.3% higher in ALFWorld, 27% in WebShop, and 33% in TextCraft -- a novel compositional dataset that we introduce. Through extensive analysis, we illustrate the importance of multilevel decomposition and establish that ADaPT dynamically adjusts to the capabilities of the executor LLM as well as to task complexity.

{{</citation>}}


### (88/108) On the Multiple Roles of Ontologies in Explainable AI (Roberto Confalonieri et al., 2023)

{{<citation>}}

Roberto Confalonieri, Giancarlo Guizzardi. (2023)  
**On the Multiple Roles of Ontologies in Explainable AI**  

---
Primary Category: cs.AI  
Categories: I-2-6, cs-AI, cs.AI  
Keywords: AI  
[Paper Link](http://arxiv.org/abs/2311.04778v1)  

---


**ABSTRACT**  
This paper discusses the different roles that explicit knowledge, in particular ontologies, can play in Explainable AI and in the development of human-centric explainable systems and intelligible explanations. We consider three main perspectives in which ontologies can contribute significantly, namely reference modelling, common-sense reasoning, and knowledge refinement and complexity management. We overview some of the existing approaches in the literature, and we position them according to these three proposed perspectives. The paper concludes by discussing what challenges still need to be addressed to enable ontology-based approaches to explanation and to evaluate their human-understandability and effectiveness.

{{</citation>}}


### (89/108) Pragmatic Reasoning Unlocks Quantifier Semantics for Foundation Models (Yiyuan Li et al., 2023)

{{<citation>}}

Yiyuan Li, Rakesh R. Menon, Sayan Ghosh, Shashank Srivastava. (2023)  
**Pragmatic Reasoning Unlocks Quantifier Semantics for Foundation Models**  

---
Primary Category: cs.AI  
Categories: cs-AI, cs.AI  
Keywords: Reasoning  
[Paper Link](http://arxiv.org/abs/2311.04659v1)  

---


**ABSTRACT**  
Generalized quantifiers (e.g., few, most) are used to indicate the proportions predicates are satisfied (for example, some apples are red). One way to interpret quantifier semantics is to explicitly bind these satisfactions with percentage scopes (e.g., 30%-40% of apples are red). This approach can be helpful for tasks like logic formalization and surface-form quantitative reasoning (Gordon and Schubert, 2010; Roy et al., 2015). However, it remains unclear if recent foundation models possess this ability, as they lack direct training signals. To explore this, we introduce QuRe, a crowd-sourced dataset of human-annotated generalized quantifiers in Wikipedia sentences featuring percentage-equipped predicates. We explore quantifier comprehension in language models using PRESQUE, a framework that combines natural language inference and the Rational Speech Acts framework. Experimental results on the HVD dataset and QuRe illustrate that PRESQUE, employing pragmatic reasoning, performs 20% better than a literal reasoning baseline when predicting quantifier percentage scopes, with no additional training required.

{{</citation>}}


### (90/108) Explainable AI for Earth Observation: Current Methods, Open Challenges, and Opportunities (Gulsen Taskin et al., 2023)

{{<citation>}}

Gulsen Taskin, Erchan Aptoula, Alp Ertürk. (2023)  
**Explainable AI for Earth Observation: Current Methods, Open Challenges, and Opportunities**  

---
Primary Category: cs.AI  
Categories: cs-AI, cs-LG, cs.AI  
Keywords: AI  
[Paper Link](http://arxiv.org/abs/2311.04491v1)  

---


**ABSTRACT**  
Deep learning has taken by storm all fields involved in data analysis, including remote sensing for Earth observation. However, despite significant advances in terms of performance, its lack of explainability and interpretability, inherent to neural networks in general since their inception, remains a major source of criticism. Hence it comes as no surprise that the expansion of deep learning methods in remote sensing is being accompanied by increasingly intensive efforts oriented towards addressing this drawback through the exploration of a wide spectrum of Explainable Artificial Intelligence techniques. This chapter, organized according to prominent Earth observation application fields, presents a panorama of the state-of-the-art in explainable remote sensing image analysis.

{{</citation>}}


### (91/108) Emergent Communication for Rules Reasoning (Yuxuan Guo et al., 2023)

{{<citation>}}

Yuxuan Guo, Yifan Hao, Rui Zhang, Enshuai Zhou, Zidong Du, Xishan Zhang, Xinkai Song, Yuanbo Wen, Yongwei Zhao, Xuehai Zhou, Jiaming Guo, Qi Yi, Shaohui Peng, Di Huang, Ruizhi Chen, Qi Guo, Yunji Chen. (2023)  
**Emergent Communication for Rules Reasoning**  

---
Primary Category: cs.AI  
Categories: cs-AI, cs.AI  
Keywords: Reasoning  
[Paper Link](http://arxiv.org/abs/2311.04474v1)  

---


**ABSTRACT**  
Research on emergent communication between deep-learning-based agents has received extensive attention due to its inspiration for linguistics and artificial intelligence. However, previous attempts have hovered around emerging communication under perception-oriented environmental settings, that forces agents to describe low-level perceptual features intra image or symbol contexts. In this work, inspired by the classic human reasoning test (namely Raven's Progressive Matrix), we propose the Reasoning Game, a cognition-oriented environment that encourages agents to reason and communicate high-level rules, rather than perceived low-level contexts. Moreover, we propose 1) an unbiased dataset (namely rule-RAVEN) as a benchmark to avoid overfitting, 2) and a two-stage curriculum agent training method as a baseline for more stable convergence in the Reasoning Game, where contexts and semantics are bilaterally drifting. Experimental results show that, in the Reasoning Game, a semantically stable and compositional language emerges to solve reasoning problems. The emerged language helps agents apply the extracted rules to the generalization of unseen context attributes, and to the transfer between different context attributes or even tasks.

{{</citation>}}


### (92/108) Human Conditional Reasoning in Answer Set Programming (Chiaki Sakama, 2023)

{{<citation>}}

Chiaki Sakama. (2023)  
**Human Conditional Reasoning in Answer Set Programming**  

---
Primary Category: cs.AI  
Categories: cs-AI, cs-LO, cs.AI  
Keywords: AI, Reasoning  
[Paper Link](http://arxiv.org/abs/2311.04412v1)  

---


**ABSTRACT**  
Given a conditional sentence P=>Q (if P then Q) and respective facts, four different types of inferences are observed in human reasoning. Affirming the antecedent (AA) (or modus ponens) reasons Q from P; affirming the consequent (AC) reasons P from Q; denying the antecedent (DA) reasons -Q from -P; and denying the consequent (DC) (or modus tollens) reasons -P from -Q. Among them, AA and DC are logically valid, while AC and DA are logically invalid and often called logical fallacies. Nevertheless, humans often perform AC or DA as pragmatic inference in daily life. In this paper, we realize AC, DA and DC inferences in answer set programming. Eight different types of completion are introduced and their semantics are given by answer sets. We investigate formal properties and characterize human reasoning tasks in cognitive psychology. Those completions are also applied to commonsense reasoning in AI.

{{</citation>}}


### (93/108) Human-Centered Planning (Yuliang Li et al., 2023)

{{<citation>}}

Yuliang Li, Nitin Kamra, Ruta Desai, Alon Halevy. (2023)  
**Human-Centered Planning**  

---
Primary Category: cs.AI  
Categories: cs-AI, cs.AI  
Keywords: AI  
[Paper Link](http://arxiv.org/abs/2311.04403v1)  

---


**ABSTRACT**  
LLMs have recently made impressive inroads on tasks whose output is structured, such as coding, robotic planning and querying databases. The vision of creating AI-powered personal assistants also involves creating structured outputs, such as a plan for one's day, or for an overseas trip. Here, since the plan is executed by a human, the output doesn't have to satisfy strict syntactic constraints. A useful assistant should also be able to incorporate vague constraints specified by the user in natural language. This makes LLMs an attractive option for planning.   We consider the problem of planning one's day. We develop an LLM-based planner (LLMPlan) extended with the ability to self-reflect on its output and a symbolic planner (SymPlan) with the ability to translate text constraints into a symbolic representation. Despite no formal specification of constraints, we find that LLMPlan performs explicit constraint satisfaction akin to the traditional symbolic planners on average (2% performance difference), while retaining the reasoning of implicit requirements. Consequently, LLM-based planners outperform their symbolic counterparts in user satisfaction (70.5% vs. 40.4%) during interactive evaluation with 40 users.

{{</citation>}}


## eess.IV (3)



### (94/108) GCS-ICHNet: Assessment of Intracerebral Hemorrhage Prognosis using Self-Attention with Domain Knowledge Integration (Xuhao Shan et al., 2023)

{{<citation>}}

Xuhao Shan, Xinyang Li, Ruiquan Ge, Shibin Wu, Ahmed Elazab, Jichao Zhu, Lingyan Zhang, Gangyong Jia, Qingying Xiao, Xiang Wan, Changmiao Wang. (2023)  
**GCS-ICHNet: Assessment of Intracerebral Hemorrhage Prognosis using Self-Attention with Domain Knowledge Integration**  

---
Primary Category: eess.IV  
Categories: cs-CV, eess-IV, eess.IV  
Keywords: AI, Attention, Self-Attention  
[Paper Link](http://arxiv.org/abs/2311.04772v1)  

---


**ABSTRACT**  
Intracerebral Hemorrhage (ICH) is a severe condition resulting from damaged brain blood vessel ruptures, often leading to complications and fatalities. Timely and accurate prognosis and management are essential due to its high mortality rate. However, conventional methods heavily rely on subjective clinician expertise, which can lead to inaccurate diagnoses and delays in treatment. Artificial intelligence (AI) models have been explored to assist clinicians, but many prior studies focused on model modification without considering domain knowledge. This paper introduces a novel deep learning algorithm, GCS-ICHNet, which integrates multimodal brain CT image data and the Glasgow Coma Scale (GCS) score to improve ICH prognosis. The algorithm utilizes a transformer-based fusion module for assessment. GCS-ICHNet demonstrates high sensitivity 81.03% and specificity 91.59%, outperforming average clinicians and other state-of-the-art methods.

{{</citation>}}


### (95/108) SS-MAE: Spatial-Spectral Masked Auto-Encoder for Multi-Source Remote Sensing Image Classification (Junyan Lin et al., 2023)

{{<citation>}}

Junyan Lin, Feng Gao, Xiaocheng Shi, Junyu Dong, Qian Du. (2023)  
**SS-MAE: Spatial-Spectral Masked Auto-Encoder for Multi-Source Remote Sensing Image Classification**  

---
Primary Category: eess.IV  
Categories: cs-CV, eess-IV, eess.IV  
Keywords: Image Classification, Transformer  
[Paper Link](http://arxiv.org/abs/2311.04442v1)  

---


**ABSTRACT**  
Masked image modeling (MIM) is a highly popular and effective self-supervised learning method for image understanding. Existing MIM-based methods mostly focus on spatial feature modeling, neglecting spectral feature modeling. Meanwhile, existing MIM-based methods use Transformer for feature extraction, some local or high-frequency information may get lost. To this end, we propose a spatial-spectral masked auto-encoder (SS-MAE) for HSI and LiDAR/SAR data joint classification. Specifically, SS-MAE consists of a spatial-wise branch and a spectral-wise branch. The spatial-wise branch masks random patches and reconstructs missing pixels, while the spectral-wise branch masks random spectral channels and reconstructs missing channels. Our SS-MAE fully exploits the spatial and spectral representations of the input data. Furthermore, to complement local features in the training stage, we add two lightweight CNNs for feature extraction. Both global and local features are taken into account for feature modeling. To demonstrate the effectiveness of the proposed SS-MAE, we conduct extensive experiments on three publicly available datasets. Extensive experiments on three multi-source datasets verify the superiority of our SS-MAE compared with several state-of-the-art baselines. The source codes are available at \url{https://github.com/summitgao/SS-MAE}.

{{</citation>}}


### (96/108) CSAM: A 2.5D Cross-Slice Attention Module for Anisotropic Volumetric Medical Image Segmentation (Alex Ling Yu Hung et al., 2023)

{{<citation>}}

Alex Ling Yu Hung, Haoxin Zheng, Kai Zhao, Xiaoxi Du, Kaifeng Pang, Qi Miao, Steven S. Raman, Demetri Terzopoulos, Kyunghyun Sung. (2023)  
**CSAM: A 2.5D Cross-Slice Attention Module for Anisotropic Volumetric Medical Image Segmentation**  

---
Primary Category: eess.IV  
Categories: cs-CV, eess-IV, eess.IV  
Keywords: Attention  
[Paper Link](http://arxiv.org/abs/2311.04942v1)  

---


**ABSTRACT**  
A large portion of volumetric medical data, especially magnetic resonance imaging (MRI) data, is anisotropic, as the through-plane resolution is typically much lower than the in-plane resolution. Both 3D and purely 2D deep learning-based segmentation methods are deficient in dealing with such volumetric data since the performance of 3D methods suffers when confronting anisotropic data, and 2D methods disregard crucial volumetric information. Insufficient work has been done on 2.5D methods, in which 2D convolution is mainly used in concert with volumetric information. These models focus on learning the relationship across slices, but typically have many parameters to train. We offer a Cross-Slice Attention Module (CSAM) with minimal trainable parameters, which captures information across all the slices in the volume by applying semantic, positional, and slice attention on deep feature maps at different scales. Our extensive experiments using different network architectures and tasks demonstrate the usefulness and generalizability of CSAM. Associated code is available at https://github.com/aL3x-O-o-Hung/CSAM.

{{</citation>}}


## cs.DB (2)



### (97/108) FAIR Knowledge Graphs with Semantic Units: a Prototype (Lars Vogt, 2023)

{{<citation>}}

Lars Vogt. (2023)  
**FAIR Knowledge Graphs with Semantic Units: a Prototype**  

---
Primary Category: cs.DB  
Categories: cs-DB, cs.DB  
Keywords: AI, Knowledge Graph  
[Paper Link](http://arxiv.org/abs/2311.04761v1)  

---


**ABSTRACT**  
Knowledge graphs and ontologies are becoming increasingly important in the context of making data and metadata findable, accessible, interoperable, and reusable (FAIR). We introduce the concept of Semantic Units for organizing Knowledge Graphs into identifiable and semantically meaningful subgraphs. Each Semantic Unit is represented in the graph by its own resource that instantiates a Semantic Unit class. Different types of Semantic Units are distinguished, and together they can organize a Knowledge Graph into different levels of representational granularity with partially overlapping, partially enclosed subgraphs that users of Knowledge Graphs can refer to for making statements about statements. The use of Semantic Units in Knowledge Graphs supports making them FAIR and increases the human-reader-actionability of their data and metadata by increasing the graph's cognitive interoperability by increasing its explorability for a human reader. We introduce a minimal prototype web application for a user-driven FAIR Knowledge Graph that is based on Semantic Units.

{{</citation>}}


### (98/108) Validating ChatGPT Facts through RDF Knowledge Graphs and Sentence Similarity (Michalis Mountantonakis et al., 2023)

{{<citation>}}

Michalis Mountantonakis, Yannis Tzitzikas. (2023)  
**Validating ChatGPT Facts through RDF Knowledge Graphs and Sentence Similarity**  

---
Primary Category: cs.DB  
Categories: cs-AI, cs-DB, cs.DB  
Keywords: ChatGPT, GPT, Knowledge Graph, Sentence Similarity  
[Paper Link](http://arxiv.org/abs/2311.04524v1)  

---


**ABSTRACT**  
Since ChatGPT offers detailed responses without justifications, and erroneous facts even for popular persons, events and places, in this paper we present a novel pipeline that retrieves the response of ChatGPT in RDF and tries to validate the ChatGPT facts using one or more RDF Knowledge Graphs (KGs). To this end we leverage DBpedia and LODsyndesis (an aggregated Knowledge Graph that contains 2 billion triples from 400 RDF KGs of many domains) and short sentence embeddings, and introduce an algorithm that returns the more relevant triple(s) accompanied by their provenance and a confidence score. This enables the validation of ChatGPT responses and their enrichment with justifications and provenance. To evaluate this service (such services in general), we create an evaluation benchmark that includes 2,000 ChatGPT facts; specifically 1,000 facts for famous Greek Persons, 500 facts for popular Greek Places, and 500 facts for Events related to Greece. The facts were manually labelled (approximately 73% of ChatGPT facts were correct and 27% of facts were erroneous). The results are promising; indicatively for the whole benchmark, we managed to verify the 85.3% of the correct facts of ChatGPT and to find the correct answer for the 62.6% of the erroneous ChatGPT facts.

{{</citation>}}


## cs.MA (1)



### (99/108) Enhancing Multi-Agent Coordination through Common Operating Picture Integration (Peihong Yu et al., 2023)

{{<citation>}}

Peihong Yu, Bhoram Lee, Aswin Raghavan, Supun Samarasekara, Pratap Tokekar, James Zachary Hare. (2023)  
**Enhancing Multi-Agent Coordination through Common Operating Picture Integration**  

---
Primary Category: cs.MA  
Categories: cs-LG, cs-MA, cs-RO, cs.MA  
Keywords: Reinforcement Learning  
[Paper Link](http://arxiv.org/abs/2311.04740v1)  

---


**ABSTRACT**  
In multi-agent systems, agents possess only local observations of the environment. Communication between teammates becomes crucial for enhancing coordination. Past research has primarily focused on encoding local information into embedding messages which are unintelligible to humans. We find that using these messages in agent's policy learning leads to brittle policies when tested on out-of-distribution initial states. We present an approach to multi-agent coordination, where each agent is equipped with the capability to integrate its (history of) observations, actions and messages received into a Common Operating Picture (COP) and disseminate the COP. This process takes into account the dynamic nature of the environment and the shared mission. We conducted experiments in the StarCraft2 environment to validate our approach. Our results demonstrate the efficacy of COP integration, and show that COP-based training leads to robust policies compared to state-of-the-art Multi-Agent Reinforcement Learning (MARL) methods when faced with out-of-distribution initial states.

{{</citation>}}


## cs.NI (1)



### (100/108) AIRIC: Orchestration of Virtualized Radio Access Networks with Noisy Neighbours (J. Xavier Salvat Lozano et al., 2023)

{{<citation>}}

J. Xavier Salvat Lozano, Andres Garcia-Saavedra, Xi Li, Xavier Costa-Perez. (2023)  
**AIRIC: Orchestration of Virtualized Radio Access Networks with Noisy Neighbours**  

---
Primary Category: cs.NI  
Categories: cs-NI, cs.NI  
Keywords: AI  
[Paper Link](http://arxiv.org/abs/2311.04649v1)  

---


**ABSTRACT**  
Radio Access Networks virtualization (vRAN) is on its way becoming a reality driven by the new requirements in mobile networks, such as scalability and cost reduction. Unfortunately, there is no free lunch but a high price to be paid in terms of computing overhead introduced by noisy neighbors problem when multiple virtualized base station instances share computing platforms. In this paper, first, we thoroughly dissect the multiple sources of computing overhead in a vRAN, quantifying their different contributions to the overall performance degradation. Second, we design an AI-driven Radio Intelligent Controller (AIRIC) to orchestrate vRAN computing resources. AIRIC relies upon a hybrid neural network architecture combining a relation network (RN) and a deep Q-Network (DQN) such that: (i) the demand of concurrent virtual base stations is satisfied considering the overhead posed by the noisy neighbors problem while the operating costs of the vRAN infrastructure is minimized; and (ii) dynamically changing contexts in terms of network demand, signal-to-noise ratio (SNR) and the number of base station instances are efficiently supported. Our results show that AIRIC performs very closely to an offline optimal oracle, attaining up to 30% resource savings, and substantially outperforms existing benchmarks in service guarantees.

{{</citation>}}


## cs.SE (4)



### (101/108) Log Statements Generation via Deep Learning: Widening the Support Provided to Developers (Antonio Mastropaolo et al., 2023)

{{<citation>}}

Antonio Mastropaolo, Valentina Ferrari, Luca Pascarella, Gabriele Bavota. (2023)  
**Log Statements Generation via Deep Learning: Widening the Support Provided to Developers**  

---
Primary Category: cs.SE  
Categories: cs-SE, cs.SE  
Keywords: Information Retrieval  
[Paper Link](http://arxiv.org/abs/2311.04587v1)  

---


**ABSTRACT**  
Logging assists in monitoring events that transpire during the execution of software. Previous research has highlighted the challenges confronted by developers when it comes to logging, including dilemmas such as where to log, what data to record, and which log level to employ (e.g., info, fatal). In this context, we introduced LANCE, an approach rooted in deep learning (DL) that has demonstrated the ability to correctly inject a log statement into Java methods in ~15% of cases. Nevertheless, LANCE grapples with two primary constraints: (i) it presumes that a method necessitates the inclusion of logging statements and; (ii) it allows the injection of only a single (new) log statement, even in situations where the injection of multiple log statements might be essential. To address these limitations, we present LEONID, a DL-based technique that can distinguish between methods that do and do not require the inclusion of log statements. Furthermore, LEONID supports the injection of multiple log statements within a given method when necessary, and it also enhances LANCE's proficiency in generating meaningful log messages through the combination of DL and Information Retrieval (IR).

{{</citation>}}


### (102/108) GResilience: Trading Off Between the Greenness and the Resilience of Collaborative AI Systems (Diaeddin Rimawi et al., 2023)

{{<citation>}}

Diaeddin Rimawi, Antonio Liotta, Marco Todescato, Barbara Russo. (2023)  
**GResilience: Trading Off Between the Greenness and the Resilience of Collaborative AI Systems**  

---
Primary Category: cs.SE  
Categories: cs-AI, cs-RO, cs-SE, cs.SE  
Keywords: AI  
[Paper Link](http://arxiv.org/abs/2311.04569v1)  

---


**ABSTRACT**  
A Collaborative Artificial Intelligence System (CAIS) works with humans in a shared environment to achieve a common goal. To recover from a disruptive event that degrades its performance and ensures its resilience, a CAIS may then need to perform a set of actions either by the system, by the humans, or collaboratively together. As for any other system, recovery actions may cause energy adverse effects due to the additional required energy. Therefore, it is of paramount importance to understand which of the above actions can better trade-off between resilience and greenness. In this in-progress work, we propose an approach to automatically evaluate CAIS recovery actions for their ability to trade-off between the resilience and greenness of the system. We have also designed an experiment protocol and its application to a real CAIS demonstrator. Our approach aims to attack the problem from two perspectives: as a one-agent decision problem through optimization, which takes the decision based on the score of resilience and greenness, and as a two-agent decision problem through game theory, which takes the decision based on the payoff computed for resilience and greenness as two players of a cooperative game.

{{</citation>}}


### (103/108) CAIS-DMA: A Decision-Making Assistant for Collaborative AI Systems (Diaeddin Rimawi et al., 2023)

{{<citation>}}

Diaeddin Rimawi, Antonio Lotta, Marco Todescato, Barbara Russo. (2023)  
**CAIS-DMA: A Decision-Making Assistant for Collaborative AI Systems**  

---
Primary Category: cs.SE  
Categories: cs-AI, cs-SE, cs.SE  
Keywords: AI  
[Paper Link](http://arxiv.org/abs/2311.04562v1)  

---


**ABSTRACT**  
A Collaborative Artificial Intelligence System (CAIS) is a cyber-physical system that learns actions in collaboration with humans in a shared environment to achieve a common goal. In particular, a CAIS is equipped with an AI model to support the decision-making process of this collaboration. When an event degrades the performance of CAIS (i.e., a disruptive event), this decision-making process may be hampered or even stopped. Thus, it is of paramount importance to monitor the learning of the AI model, and eventually support its decision-making process in such circumstances. This paper introduces a new methodology to automatically support the decision-making process in CAIS when the system experiences performance degradation after a disruptive event. To this aim, we develop a framework that consists of three components: one manages or simulates CAIS's environment and disruptive events, the second automates the decision-making process, and the third provides a visual analysis of CAIS behavior. Overall, our framework automatically monitors the decision-making process, intervenes whenever a performance degradation occurs, and recommends the next action. We demonstrate our framework by implementing an example with a real-world collaborative robot, where the framework recommends the next action that balances between minimizing the recovery time (i.e., resilience), and minimizing the energy adverse effects (i.e., greenness).

{{</citation>}}


### (104/108) Evaluating Diverse Large Language Models for Automatic and General Bug Reproduction (Sungmin Kang et al., 2023)

{{<citation>}}

Sungmin Kang, Juyeon Yoon, Nargiz Askarbekkyzy, Shin Yoo. (2023)  
**Evaluating Diverse Large Language Models for Automatic and General Bug Reproduction**  

---
Primary Category: cs.SE  
Categories: cs-SE, cs.SE  
Keywords: AI, Language Model  
[Paper Link](http://arxiv.org/abs/2311.04532v2)  

---


**ABSTRACT**  
Bug reproduction is a critical developer activity that is also challenging to automate, as bug reports are often in natural language and thus can be difficult to transform to test cases consistently. As a result, existing techniques mostly focused on crash bugs, which are easier to automatically detect and verify. In this work, we overcome this limitation by using large language models (LLMs), which have been demonstrated to be adept at natural language processing and code generation. By prompting LLMs to generate bug-reproducing tests, and via a post-processing pipeline to automatically identify promising generated tests, our proposed technique LIBRO could successfully reproduce about one-third of all bugs in the widely used Defects4J benchmark. Furthermore, our extensive evaluation on 15 LLMs, including 11 open-source LLMs, suggests that open-source LLMs also demonstrate substantial potential, with the StarCoder LLM achieving 70% of the reproduction performance of the closed-source OpenAI LLM code-davinci-002 on the large Defects4J benchmark, and 90% of performance on a held-out bug dataset likely not part of any LLM's training data. In addition, our experiments on LLMs of different sizes show that bug reproduction using LIBRO improves as LLM size increases, providing information as to which LLMs can be used with the LIBRO pipeline.

{{</citation>}}


## cs.CY (1)



### (105/108) Text Finder Application for Android (Dr. Milind Godase et al., 2023)

{{<citation>}}

Dr. Milind Godase, Dr. Chandrani Singh, Kunal Dhongadi. (2023)  
**Text Finder Application for Android**  

---
Primary Category: cs.CY  
Categories: I-2-7, cs-CY, cs.CY, sinhgad-org  
Keywords: Google, OCR  
[Paper Link](http://arxiv.org/abs/2311.04579v1)  

---


**ABSTRACT**  
A Text Finder, an android application that utilizes Optical Character Recognition (OCR) technology with the help of Google Cloud Vision API to extract text from images taken with the device camera or from existing images in the users phone. The extracted text can be saved to the device storage where all previous extracts can be easily accessed on a user-friendly interface. The application also features editing, deletion and sharing options for the extracted text. The user interface is user-friendly, making the application accessible to students, professional and organizations for a variety of purposes, including document scanning, data entry, and information retrieval. Manual extraction of text by typing or writing from images can be very time-consuming and can be prone to errors. This application is an efficient and simple solution for extracted texts and organizing important information from the photos. This paper describes the technical details of the OCR technology and Googles ML Kit Text Recognition API used in the application, as well as the design, implementation and evaluation of the application in terms of performance and accuracy. The research also explores the key objectives and benefits of Text Finder, such as reducing the time and effort required and increasing the efficiency of document-based tasks.

{{</citation>}}


## physics.optics (1)



### (106/108) Free-Space Optical Spiking Neural Network (Reyhane Ahmadi et al., 2023)

{{<citation>}}

Reyhane Ahmadi, Amirreza Ahmadnejad, Somayyeh Koohi. (2023)  
**Free-Space Optical Spiking Neural Network**  

---
Primary Category: physics.optics  
Categories: cs-NE, physics-optics, physics.optics  
Keywords: AI  
[Paper Link](http://arxiv.org/abs/2311.04558v1)  

---


**ABSTRACT**  
Neuromorphic engineering has emerged as a promising avenue for developing brain-inspired computational systems. However, conventional electronic AI-based processors often encounter challenges related to processing speed and thermal dissipation. As an alternative, optical implementations of such processors have been proposed, capitalizing on the intrinsic information-processing capabilities of light. Within the realm of optical neuromorphic engineering, various optical neural networks (ONNs) have been explored. Among these, Spiking Neural Networks (SNNs) have exhibited notable success in emulating the computational principles of the human brain. Nevertheless, the integration of optical SNN processors has presented formidable obstacles, mainly when dealing with the computational demands of large datasets. In response to these challenges, we introduce a pioneering concept: the Free-space Optical deep Spiking Convolutional Neural Network (OSCNN). This novel approach draws inspiration from computational models of the human eye. We have meticulously designed various optical components within the OSCNN to tackle object detection tasks across prominent benchmark datasets, including MNIST, ETH 80, and Caltech. Our results demonstrate promising performance with minimal latency and power consumption compared to their electronic ONN counterparts. Additionally, we conducted several pertinent simulations, such as optical intensity to-latency conversion and synchronization. Of particular significance is the evaluation of the feature extraction layer, employing a Gabor filter bank, which stands to impact the practical deployment of diverse ONN architectures significantly.

{{</citation>}}


## q-fin.PM (1)



### (107/108) Causal Inference on Investment Constraints and Non-stationarity in Dynamic Portfolio Optimization through Reinforcement Learning (Yasuhiro Nakayama et al., 2023)

{{<citation>}}

Yasuhiro Nakayama, Tomochika Sawaki. (2023)  
**Causal Inference on Investment Constraints and Non-stationarity in Dynamic Portfolio Optimization through Reinforcement Learning**  

---
Primary Category: q-fin.PM  
Categories: cs-AI, q-fin-PM, q-fin.PM  
Keywords: Reinforcement Learning  
[Paper Link](http://arxiv.org/abs/2311.04946v1)  

---


**ABSTRACT**  
In this study, we have developed a dynamic asset allocation investment strategy using reinforcement learning techniques. To begin with, we have addressed the crucial issue of incorporating non-stationarity of financial time series data into reinforcement learning algorithms, which is a significant implementation in the application of reinforcement learning in investment strategies. Our findings highlight the significance of introducing certain variables such as regime change in the environment setting to enhance the prediction accuracy. Furthermore, the application of reinforcement learning in investment strategies provides a remarkable advantage of setting the optimization problem flexibly. This enables the integration of practical constraints faced by investors into the algorithm, resulting in efficient optimization. Our study has categorized the investment strategy formulation conditions into three main categories, including performance measurement indicators, portfolio management rules, and other constraints. We have evaluated the impact of incorporating these conditions into the environment and rewards in a reinforcement learning framework and examined how they influence investment behavior.

{{</citation>}}


## cond-mat.mtrl-sci (1)



### (108/108) AI-accelerated Discovery of Altermagnetic Materials (Ze-Feng Gao et al., 2023)

{{<citation>}}

Ze-Feng Gao, Shuai Qu, Bocheng Zeng, Yang Liu, Ji-Rong Wen, Hao Sun, Peng-Jie Guo, Zhong-Yi Lu. (2023)  
**AI-accelerated Discovery of Altermagnetic Materials**  

---
Primary Category: cond-mat.mtrl-sci  
Categories: cond-mat-mtrl-sci, cond-mat.mtrl-sci, cs-AI, physics-comp-ph  
Keywords: AI  
[Paper Link](http://arxiv.org/abs/2311.04418v2)  

---


**ABSTRACT**  
Altermagnetism, a new magnetic phase, has been theoretically proposed and experimentally verified to be distinct from ferromagnetism and antiferromagnetism. Although altermagnets have been found to possess many exotic physical properties, the very limited availability of known altermagnetic materials (e.g., 14 confirmed materials) hinders the study of such properties. Hence, discovering more types of altermagnetic materials is crucial for a comprehensive understanding of altermagnetism and thus facilitating new applications in the next-generation information technologies, e.g., storage devices and high-sensitivity sensors. Here, we report 25 new altermagnetic materials that cover metals, semiconductors, and insulators, discovered by an AI search engine unifying symmetry analysis, graph neural network pre-training, optimal transport theory, and first-principles electronic structure calculation. The wide range of electronic structural characteristics reveals that various novel physical properties manifest in these newly discovered altermagnetic materials, e.g., anomalous Hall effect, anomalous Kerr effect, and topological property. Noteworthy, we discovered 8 i-wave altermagnetic materials for the first time. Overall, the AI search engine performs much better than human experts and suggests a set of new altermagnetic materials with unique properties, outlining its potential for accelerated discovery of the materials with targeting properties.

{{</citation>}}
