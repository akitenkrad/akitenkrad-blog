---
draft: false
title: "arXiv @ 2023.07.01"
date: 2023-07-01
author: "akitenkrad"
description: ""
tags: ["arXiv", "Published:2023"]
menu:
  sidebar:
    name: "arXiv @ 2023.07.01"
    identifier: arxiv_20230701
    parent: 202307_arxiv
    weight: 10
math: true
---

<figure style="border:none; width:100%; display:flex; justify-content: center">
    <iframe src="pie.html" width=900 height=620 style="border:none"></iframe>
</figure>


## Primary Categories

- [cs.LG (9)](#cslg-9)
- [eess.IV (1)](#eessiv-1)
- [cs.CV (17)](#cscv-17)
- [cs.SE (3)](#csse-3)
- [cs.CL (9)](#cscl-9)
- [cs.IR (1)](#csir-1)
- [cs.AI (1)](#csai-1)
- [cs.HC (1)](#cshc-1)
- [cs.RO (2)](#csro-2)
- [cs.CY (2)](#cscy-2)
- [cs.NI (1)](#csni-1)
- [cs.NE (1)](#csne-1)
- [eess.SP (1)](#eesssp-1)
- [math.NA (1)](#mathna-1)

## cs.LG (9)



### (1/50) An Adaptive Optimization Approach to Personalized Financial Incentives in Mobile Behavioral Weight Loss Interventions (Qiaomei Li et al., 2023)

{{<citation>}}

Qiaomei Li, Kara L. Gavin, Corrine I. Voils, Yonatan Mintz. (2023)  
**An Adaptive Optimization Approach to Personalized Financial Incentives in Mobile Behavioral Weight Loss Interventions**  

---
Primary Category: cs.LG
Categories: cs-LG, cs.LG, math-OC  
Keywords: Financial  
[Paper Link](http://arxiv.org/abs/2307.00444v2)  

---


**ABSTRACT**  
Obesity is a critical healthcare issue affecting the United States. The least risky treatments available for obesity are behavioral interventions meant to promote diet and exercise. Often these interventions contain a mobile component that allows interventionists to collect participants level data and provide participants with incentives and goals to promote long term behavioral change. Recently, there has been interest in using direct financial incentives to promote behavior change. However, adherence is challenging in these interventions, as each participant will react differently to different incentive structure and amounts, leading researchers to consider personalized interventions. The key challenge for personalization, is that the clinicians do not know a priori how best to administer incentives to participants, and given finite intervention budgets how to disburse costly resources efficiently. In this paper, we consider this challenge of designing personalized weight loss interventions that use direct financial incentives to motivate weight loss while remaining within a budget. We create a machine learning approach that is able to predict how individuals may react to different incentive schedules within the context of a behavioral intervention. We use this predictive model in an adaptive framework that over the course of the intervention computes what incentives to disburse to participants and remain within the study budget. We provide both theoretical guarantees for our modeling and optimization approaches as well as demonstrate their performance in a simulated weight loss study. Our results highlight the cost efficiency and effectiveness of our personalized intervention design for weight loss.

{{</citation>}}


### (2/50) The future of human-centric eXplainable Artificial Intelligence (XAI) is not post-hoc explanations (Vinitra Swamy et al., 2023)

{{<citation>}}

Vinitra Swamy, Jibril Frej, Tanja Käser. (2023)  
**The future of human-centric eXplainable Artificial Intelligence (XAI) is not post-hoc explanations**  

---
Primary Category: cs.LG
Categories: cs-AI, cs-CY, cs-HC, cs-LG, cs.LG  
Keywords: AI  
[Paper Link](http://arxiv.org/abs/2307.00364v1)  

---


**ABSTRACT**  
Explainable Artificial Intelligence (XAI) plays a crucial role in enabling human understanding and trust in deep learning systems, often defined as determining which features are most important to a model's prediction. As models get larger, more ubiquitous, and pervasive in aspects of daily life, explainability is necessary to avoid or minimize adverse effects of model mistakes. Unfortunately, current approaches in human-centric XAI (e.g. predictive tasks in healthcare, education, or personalized ads) tend to rely on a single explainer. This is a particularly concerning trend when considering that recent work has identified systematic disagreement in explainability methods when applied to the same points and underlying black-box models. In this paper, we therefore present a call for action to address the limitations of current state-of-the-art explainers. We propose to shift from post-hoc explainability to designing interpretable neural network architectures; moving away from approximation techniques in human-centric and high impact applications. We identify five needs of human-centric XAI (real-time, accurate, actionable, human-interpretable, and consistent) and propose two schemes for interpretable-by-design neural network workflows (adaptive routing for interpretable conditional computation and diagnostic benchmarks for iterative model learning). We postulate that the future of human-centric XAI is neither in explaining black-boxes nor in reverting to traditional, interpretable models, but in neural networks that are intrinsically interpretable.

{{</citation>}}


### (3/50) A Comparative Study of Machine Learning Algorithms for Anomaly Detection in Industrial Environments: Performance and Environmental Impact (Álvaro Huertas-García et al., 2023)

{{<citation>}}

Álvaro Huertas-García, Carlos Martí-González, Rubén García Maezo, Alejandro Echeverría Rey. (2023)  
**A Comparative Study of Machine Learning Algorithms for Anomaly Detection in Industrial Environments: Performance and Environmental Impact**  

---
Primary Category: cs.LG
Categories: cs-AI, cs-LG, cs.LG  
Keywords: AI, Anomaly Detection  
[Paper Link](http://arxiv.org/abs/2307.00361v1)  

---


**ABSTRACT**  
In the context of Industry 4.0, the use of artificial intelligence (AI) and machine learning for anomaly detection is being hampered by high computational requirements and associated environmental effects. This study seeks to address the demands of high-performance machine learning models with environmental sustainability, contributing to the emerging discourse on 'Green AI.' An extensive variety of machine learning algorithms, coupled with various Multilayer Perceptron (MLP) configurations, were meticulously evaluated. Our investigation encapsulated a comprehensive suite of evaluation metrics, comprising Accuracy, Area Under the Curve (AUC), Recall, Precision, F1 Score, Kappa Statistic, Matthews Correlation Coefficient (MCC), and F1 Macro. Simultaneously, the environmental footprint of these models was gauged through considerations of time duration, CO2 equivalent, and energy consumption during the training, cross-validation, and inference phases. Traditional machine learning algorithms, such as Decision Trees and Random Forests, demonstrate robust efficiency and performance. However, superior outcomes were obtained with optimised MLP configurations, albeit with a commensurate increase in resource consumption. The study incorporated a multi-objective optimisation approach, invoking Pareto optimality principles, to highlight the trade-offs between a model's performance and its environmental impact. The insights derived underscore the imperative of striking a balance between model performance, complexity, and environmental implications, thus offering valuable directions for future work in the development of environmentally conscious machine learning models for industrial applications.

{{</citation>}}


### (4/50) Recursive Algorithmic Reasoning (Dulhan Jayalath et al., 2023)

{{<citation>}}

Dulhan Jayalath, Jonas Jürß, Petar Veličković. (2023)  
**Recursive Algorithmic Reasoning**  

---
Primary Category: cs.LG
Categories: cs-LG, cs.LG  
Keywords: GNN, Reasoning  
[Paper Link](http://arxiv.org/abs/2307.00337v1)  

---


**ABSTRACT**  
Learning models that execute algorithms can enable us to address a key problem in deep learning: generalizing to out-of-distribution data. However, neural networks are currently unable to execute recursive algorithms because they do not have arbitrarily large memory to store and recall state. To address this, we (1) propose a way to augment graph neural networks (GNNs) with a stack, and (2) develop an approach for capturing intermediate algorithm trajectories that improves algorithmic alignment with recursive algorithms over previous methods. The stack allows the network to learn to store and recall a portion of the state of the network at a particular time, analogous to the action of a call stack in a recursive algorithm. This augmentation permits the network to reason recursively. We empirically demonstrate that our proposals significantly improve generalization to larger input graphs over prior work on depth-first search (DFS).

{{</citation>}}


### (5/50) Variation-aware Vision Transformer Quantization (Xijie Huang et al., 2023)

{{<citation>}}

Xijie Huang, Zhiqiang Shen, Kwang-Ting Cheng. (2023)  
**Variation-aware Vision Transformer Quantization**  

---
Primary Category: cs.LG
Categories: cs-AI, cs-CV, cs-LG, cs.LG  
Keywords: ImageNet, QA, Quantization, Transformer, Transformers  
[Paper Link](http://arxiv.org/abs/2307.00331v1)  

---


**ABSTRACT**  
Despite the remarkable performance of Vision Transformers (ViTs) in various visual tasks, the expanding computation and model size of ViTs have increased the demand for improved efficiency during training and inference. To address the heavy computation and parameter drawbacks, quantization is frequently studied in the community as a representative model compression technique and has seen extensive use on CNNs. However, due to the unique properties of CNNs and ViTs, the quantization applications on ViTs are still limited and underexplored. In this paper, we identify the difficulty of ViT quantization on its unique variation behaviors, which differ from traditional CNN architectures. The variations indicate the magnitude of the parameter fluctuations and can also measure outlier conditions. Moreover, the variation behaviors reflect the various sensitivities to the quantization of each module. The quantization sensitivity analysis and comparison of ViTs with CNNs help us locate the underlying differences in variations. We also find that the variations in ViTs cause training oscillations, bringing instability during quantization-aware training (QAT). Correspondingly, we solve the variation problem with an efficient knowledge-distillation-based variation-aware quantization method. The multi-crop knowledge distillation scheme can accelerate and stabilize the training and alleviate the variation's influence during QAT. We also proposed a module-dependent quantization scheme and a variation-aware regularization term to suppress the oscillation of weights. On ImageNet-1K, we obtain a 77.66% Top-1 accuracy on the extremely low-bit scenario of 2-bit Swin-T, outperforming the previous state-of-the-art quantized model by 3.35%.

{{</citation>}}


### (6/50) Common Knowledge Learning for Generating Transferable Adversarial Examples (Ruijie Yang et al., 2023)

{{<citation>}}

Ruijie Yang, Yuanfang Guo, Junfu Wang, Jiantao Zhou, Yunhong Wang. (2023)  
**Common Knowledge Learning for Generating Transferable Adversarial Examples**  

---
Primary Category: cs.LG
Categories: cs-CV, cs-LG, cs.LG  
Keywords: Transformer  
[Paper Link](http://arxiv.org/abs/2307.00274v1)  

---


**ABSTRACT**  
This paper focuses on an important type of black-box attacks, i.e., transfer-based adversarial attacks, where the adversary generates adversarial examples by a substitute (source) model and utilize them to attack an unseen target model, without knowing its information. Existing methods tend to give unsatisfactory adversarial transferability when the source and target models are from different types of DNN architectures (e.g. ResNet-18 and Swin Transformer). In this paper, we observe that the above phenomenon is induced by the output inconsistency problem. To alleviate this problem while effectively utilizing the existing DNN models, we propose a common knowledge learning (CKL) framework to learn better network weights to generate adversarial examples with better transferability, under fixed network architectures. Specifically, to reduce the model-specific features and obtain better output distributions, we construct a multi-teacher framework, where the knowledge is distilled from different teacher architectures into one student network. By considering that the gradient of input is usually utilized to generated adversarial examples, we impose constraints on the gradients between the student and teacher models, to further alleviate the output inconsistency problem and enhance the adversarial transferability. Extensive experiments demonstrate that our proposed work can significantly improve the adversarial transferability.

{{</citation>}}


### (7/50) Hiding in Plain Sight: Differential Privacy Noise Exploitation for Evasion-resilient Localized Poisoning Attacks in Multiagent Reinforcement Learning (Md Tamjid Hossain et al., 2023)

{{<citation>}}

Md Tamjid Hossain, Hung La. (2023)  
**Hiding in Plain Sight: Differential Privacy Noise Exploitation for Evasion-resilient Localized Poisoning Attacks in Multiagent Reinforcement Learning**  

---
Primary Category: cs.LG
Categories: cs-CR, cs-LG, cs-MA, cs.LG  
Keywords: Reinforcement Learning  
[Paper Link](http://arxiv.org/abs/2307.00268v2)  

---


**ABSTRACT**  
Lately, differential privacy (DP) has been introduced in cooperative multiagent reinforcement learning (CMARL) to safeguard the agents' privacy against adversarial inference during knowledge sharing. Nevertheless, we argue that the noise introduced by DP mechanisms may inadvertently give rise to a novel poisoning threat, specifically in the context of private knowledge sharing during CMARL, which remains unexplored in the literature. To address this shortcoming, we present an adaptive, privacy-exploiting, and evasion-resilient localized poisoning attack (PeLPA) that capitalizes on the inherent DP-noise to circumvent anomaly detection systems and hinder the optimal convergence of the CMARL model. We rigorously evaluate our proposed PeLPA attack in diverse environments, encompassing both non-adversarial and multiple-adversarial contexts. Our findings reveal that, in a medium-scale environment, the PeLPA attack with attacker ratios of 20% and 40% can lead to an increase in average steps to goal by 50.69% and 64.41%, respectively. Furthermore, under similar conditions, PeLPA can result in a 1.4x and 1.6x computational time increase in optimal reward attainment and a 1.18x and 1.38x slower convergence for attacker ratios of 20% and 40%, respectively.

{{</citation>}}


### (8/50) InferTurbo: A Scalable System for Boosting Full-graph Inference of Graph Neural Network over Huge Graphs (Dalong Zhang et al., 2023)

{{<citation>}}

Dalong Zhang, Xianzheng Song, Zhiyang Hu, Yang Li, Miao Tao, Binbin Hu, Lin Wang, Zhiqiang Zhang, Jun Zhou. (2023)  
**InferTurbo: A Scalable System for Boosting Full-graph Inference of Graph Neural Network over Huge Graphs**  

---
Primary Category: cs.LG
Categories: cs-LG, cs.LG  
Keywords: GNN, Graph Neural Network  
[Paper Link](http://arxiv.org/abs/2307.00228v1)  

---


**ABSTRACT**  
GNN inference is a non-trivial task, especially in industrial scenarios with giant graphs, given three main challenges, i.e., scalability tailored for full-graph inference on huge graphs, inconsistency caused by stochastic acceleration strategies (e.g., sampling), and the serious redundant computation issue. To address the above challenges, we propose a scalable system named InferTurbo to boost the GNN inference tasks in industrial scenarios. Inspired by the philosophy of ``think-like-a-vertex", a GAS-like (Gather-Apply-Scatter) schema is proposed to describe the computation paradigm and data flow of GNN inference. The computation of GNNs is expressed in an iteration manner, in which a vertex would gather messages via in-edges and update its state information by forwarding an associated layer of GNNs with those messages and then send the updated information to other vertexes via out-edges. Following the schema, the proposed InferTurbo can be built with alternative backends (e.g., batch processing system or graph computing system). Moreover, InferTurbo introduces several strategies like shadow-nodes and partial-gather to handle nodes with large degrees for better load balancing. With InferTurbo, GNN inference can be hierarchically conducted over the full graph without sampling and redundant computation. Experimental results demonstrate that our system is robust and efficient for inference tasks over graphs containing some hub nodes with many adjacent edges. Meanwhile, the system gains a remarkable performance compared with the traditional inference pipeline, and it can finish a GNN inference task over a graph with tens of billions of nodes and hundreds of billions of edges within 2 hours.

{{</citation>}}


### (9/50) Re-Think and Re-Design Graph Neural Networks in Spaces of Continuous Graph Diffusion Functionals (Tingting Dan et al., 2023)

{{<citation>}}

Tingting Dan, Jiaqi Ding, Ziquan Wei, Shahar Z Kovalsky, Minjeong Kim, Won Hwa Kim, Guorong Wu. (2023)  
**Re-Think and Re-Design Graph Neural Networks in Spaces of Continuous Graph Diffusion Functionals**  

---
Primary Category: cs.LG
Categories: 05C85, I-2-6, cs-GR, cs-LG, cs.LG  
Keywords: GNN, Graph Neural Network, Graph Neural Networks  
[Paper Link](http://arxiv.org/abs/2307.00222v1)  

---


**ABSTRACT**  
Graph neural networks (GNNs) are widely used in domains like social networks and biological systems. However, the locality assumption of GNNs, which limits information exchange to neighboring nodes, hampers their ability to capture long-range dependencies and global patterns in graphs. To address this, we propose a new inductive bias based on variational analysis, drawing inspiration from the Brachistochrone problem. Our framework establishes a mapping between discrete GNN models and continuous diffusion functionals. This enables the design of application-specific objective functions in the continuous domain and the construction of discrete deep models with mathematical guarantees. To tackle over-smoothing in GNNs, we analyze the existing layer-by-layer graph embedding models and identify that they are equivalent to l2-norm integral functionals of graph gradients, which cause over-smoothing. Similar to edge-preserving filters in image denoising, we introduce total variation (TV) to align the graph diffusion pattern with global community topologies. Additionally, we devise a selective mechanism to address the trade-off between model depth and over-smoothing, which can be easily integrated into existing GNNs. Furthermore, we propose a novel generative adversarial network (GAN) that predicts spreading flows in graphs through a neural transport equation. To mitigate vanishing flows, we customize the objective function to minimize transportation within each community while maximizing inter-community flows. Our GNN models achieve state-of-the-art (SOTA) performance on popular graph learning benchmarks such as Cora, Citeseer, and Pubmed.

{{</citation>}}


## eess.IV (1)



### (10/50) Weighted Anisotropic-Isotropic Total Variation for Poisson Denoising (Kevin Bui et al., 2023)

{{<citation>}}

Kevin Bui, Yifei Lou, Fredrick Park, Jack Xin. (2023)  
**Weighted Anisotropic-Isotropic Total Variation for Poisson Denoising**  

---
Primary Category: eess.IV
Categories: cs-CV, cs-NA, eess-IV, eess.IV, math-NA  
Keywords: AI  
[Paper Link](http://arxiv.org/abs/2307.00439v1)  

---


**ABSTRACT**  
Poisson noise commonly occurs in images captured by photon-limited imaging systems such as in astronomy and medicine. As the distribution of Poisson noise depends on the pixel intensity value, noise levels vary from pixels to pixels. Hence, denoising a Poisson-corrupted image while preserving important details can be challenging. In this paper, we propose a Poisson denoising model by incorporating the weighted anisotropic-isotropic total variation (AITV) as a regularization. We then develop an alternating direction method of multipliers with a combination of a proximal operator for an efficient implementation. Lastly, numerical experiments demonstrate that our algorithm outperforms other Poisson denoising methods in terms of image quality and computational efficiency.

{{</citation>}}


## cs.CV (17)



### (11/50) One Copy Is All You Need: Resource-Efficient Streaming of Medical Imaging Data at Scale (Pranav Kulkarni et al., 2023)

{{<citation>}}

Pranav Kulkarni, Adway Kanhere, Eliot Siegel, Paul H. Yi, Vishwa S. Parekh. (2023)  
**One Copy Is All You Need: Resource-Efficient Streaming of Medical Imaging Data at Scale**  

---
Primary Category: cs.CV
Categories: cs-CV, cs-IR, cs-LG, cs.CV  
Keywords: AI  
[Paper Link](http://arxiv.org/abs/2307.00438v1)  

---


**ABSTRACT**  
Large-scale medical imaging datasets have accelerated development of artificial intelligence tools for clinical decision support. However, the large size of these datasets is a bottleneck for users with limited storage and bandwidth. Many users may not even require such large datasets as AI models are often trained on lower resolution images. If users could directly download at their desired resolution, storage and bandwidth requirements would significantly decrease. However, it is impossible to anticipate every users' requirements and impractical to store the data at multiple resolutions. What if we could store images at a single resolution but send them at different ones? We propose MIST, an open-source framework to operationalize progressive resolution for streaming medical images at multiple resolutions from a single high-resolution copy. We demonstrate that MIST can dramatically reduce imaging infrastructure inefficiencies for hosting and streaming medical images by >90%, while maintaining diagnostic quality for deep learning applications.

{{</citation>}}


### (12/50) Brightness-Restricted Adversarial Attack Patch (Mingzhen Shao, 2023)

{{<citation>}}

Mingzhen Shao. (2023)  
**Brightness-Restricted Adversarial Attack Patch**  

---
Primary Category: cs.CV
Categories: cs-CV, cs.CV  
Keywords: Adversarial Attack  
[Paper Link](http://arxiv.org/abs/2307.00421v1)  

---


**ABSTRACT**  
Adversarial attack patches have gained increasing attention due to their practical applicability in physical-world scenarios. However, the bright colors used in attack patches represent a significant drawback, as they can be easily identified by human observers. Moreover, even though these attacks have been highly successful in deceiving target networks, which specific features of the attack patch contribute to its success are still unknown. Our paper introduces a brightness-restricted patch (BrPatch) that uses optical characteristics to effectively reduce conspicuousness while preserving image independence. We also conducted an analysis of the impact of various image features (such as color, texture, noise, and size) on the effectiveness of an attack patch in physical-world deployment. Our experiments show that attack patches exhibit strong redundancy to brightness and are resistant to color transfer and noise. Based on our findings, we propose some additional methods to further reduce the conspicuousness of BrPatch. Our findings also explain the robustness of attack patches observed in physical-world scenarios.

{{</citation>}}


### (13/50) ProbVLM: Probabilistic Adapter for Frozen Vison-Language Models (Uddeshya Upadhyay et al., 2023)

{{<citation>}}

Uddeshya Upadhyay, Shyamgopal Karthik, Massimiliano Mancini, Zeynep Akata. (2023)  
**ProbVLM: Probabilistic Adapter for Frozen Vison-Language Models**  

---
Primary Category: cs.CV
Categories: cs-AI, cs-CV, cs-LG, cs.CV  
Keywords: Language Model  
[Paper Link](http://arxiv.org/abs/2307.00398v1)  

---


**ABSTRACT**  
Large-scale vision-language models (VLMs) like CLIP successfully find correspondences between images and text. Through the standard deterministic mapping process, an image or a text sample is mapped to a single vector in the embedding space. This is problematic: as multiple samples (images or text) can abstract the same concept in the physical world, deterministic embeddings do not reflect the inherent ambiguity in the embedding space. We propose ProbVLM, a probabilistic adapter that estimates probability distributions for the embeddings of pre-trained VLMs via inter/intra-modal alignment in a post-hoc manner without needing large-scale datasets or computing. On four challenging datasets, i.e., COCO, Flickr, CUB, and Oxford-flowers, we estimate the multi-modal embedding uncertainties for two VLMs, i.e., CLIP and BLIP, quantify the calibration of embedding uncertainties in retrieval tasks and show that ProbVLM outperforms other methods. Furthermore, we propose active learning and model selection as two real-world downstream tasks for VLMs and show that the estimated uncertainty aids both tasks. Lastly, we present a novel technique for visualizing the embedding distributions using a large-scale pre-trained latent diffusion model.

{{</citation>}}


### (14/50) MobileViG: Graph-Based Sparse Attention for Mobile Vision Applications (Mustafa Munir et al., 2023)

{{<citation>}}

Mustafa Munir, William Avery, Radu Marculescu. (2023)  
**MobileViG: Graph-Based Sparse Attention for Mobile Vision Applications**  

---
Primary Category: cs.CV
Categories: cs-CV, cs-LG, cs.CV  
Keywords: Attention, GNN, ImageNet  
[Paper Link](http://arxiv.org/abs/2307.00395v1)  

---


**ABSTRACT**  
Traditionally, convolutional neural networks (CNN) and vision transformers (ViT) have dominated computer vision. However, recently proposed vision graph neural networks (ViG) provide a new avenue for exploration. Unfortunately, for mobile applications, ViGs are computationally expensive due to the overhead of representing images as graph structures. In this work, we propose a new graph-based sparse attention mechanism, Sparse Vision Graph Attention (SVGA), that is designed for ViGs running on mobile devices. Additionally, we propose the first hybrid CNN-GNN architecture for vision tasks on mobile devices, MobileViG, which uses SVGA. Extensive experiments show that MobileViG beats existing ViG models and existing mobile CNN and ViT architectures in terms of accuracy and/or speed on image classification, object detection, and instance segmentation tasks. Our fastest model, MobileViG-Ti, achieves 75.7% top-1 accuracy on ImageNet-1K with 0.78 ms inference latency on iPhone 13 Mini NPU (compiled with CoreML), which is faster than MobileNetV2x1.4 (1.02 ms, 74.7% top-1) and MobileNetV2x1.0 (0.81 ms, 71.8% top-1). Our largest model, MobileViG-B obtains 82.6% top-1 accuracy with only 2.30 ms latency, which is faster and more accurate than the similarly sized EfficientFormer-L3 model (2.77 ms, 82.4%). Our work proves that well designed hybrid CNN-GNN architectures can be a new avenue of exploration for designing models that are extremely fast and accurate on mobile devices. Our code is publicly available at https://github.com/SLDGroup/MobileViG.

{{</citation>}}


### (15/50) Learning Content-enhanced Mask Transformer for Domain Generalized Urban-Scene Segmentation (Qi Bi et al., 2023)

{{<citation>}}

Qi Bi, Shaodi You, Theo Gevers. (2023)  
**Learning Content-enhanced Mask Transformer for Domain Generalized Urban-Scene Segmentation**  

---
Primary Category: cs.CV
Categories: cs-CV, cs.CV  
Keywords: Transformer  
[Paper Link](http://arxiv.org/abs/2307.00371v1)  

---


**ABSTRACT**  
Domain-generalized urban-scene semantic segmentation (USSS) aims to learn generalized semantic predictions across diverse urban-scene styles. Unlike domain gap challenges, USSS is unique in that the semantic categories are often similar in different urban scenes, while the styles can vary significantly due to changes in urban landscapes, weather conditions, lighting, and other factors. Existing approaches typically rely on convolutional neural networks (CNNs) to learn the content of urban scenes.   In this paper, we propose a Content-enhanced Mask TransFormer (CMFormer) for domain-generalized USSS. The main idea is to enhance the focus of the fundamental component, the mask attention mechanism, in Transformer segmentation models on content information. To achieve this, we introduce a novel content-enhanced mask attention mechanism. It learns mask queries from both the image feature and its down-sampled counterpart, as lower-resolution image features usually contain more robust content information and are less sensitive to style variations. These features are fused into a Transformer decoder and integrated into a multi-resolution content-enhanced mask attention learning scheme.   Extensive experiments conducted on various domain-generalized urban-scene segmentation datasets demonstrate that the proposed CMFormer significantly outperforms existing CNN-based methods for domain-generalized semantic segmentation, achieving improvements of up to 14.00\% in terms of mIoU (mean intersection over union). The source code for CMFormer will be made available at this \href{https://github.com/BiQiWHU/domain-generalized-urban-scene-segmentation}{repository}.

{{</citation>}}


### (16/50) Spatial-Temporal Enhanced Transformer Towards Multi-Frame 3D Object Detection (Yifan Zhang et al., 2023)

{{<citation>}}

Yifan Zhang, Zhiyu Zhu, Junhui Hou. (2023)  
**Spatial-Temporal Enhanced Transformer Towards Multi-Frame 3D Object Detection**  

---
Primary Category: cs.CV
Categories: cs-CV, cs.CV  
Keywords: Object Detection, Transformer  
[Paper Link](http://arxiv.org/abs/2307.00347v1)  

---


**ABSTRACT**  
The Detection Transformer (DETR) has revolutionized the design of CNN-based object detection systems, showcasing impressive performance. However, its potential in the domain of multi-frame 3D object detection remains largely unexplored. In this paper, we present STEMD, a novel end-to-end framework for multi-frame 3D object detection based on the DETR-like paradigm. Our approach treats multi-frame 3D object detection as a sequence-to-sequence task and effectively captures spatial-temporal dependencies at both the feature and query levels. To model the inter-object spatial interaction and complex temporal dependencies, we introduce the spatial-temporal graph attention network. This network represents queries as nodes in a graph and enables effective modeling of object interactions within a social context. In addition, to solve the problem of missing hard cases in the proposed output of the encoder in the current frame, we incorporate the output of the previous frame to initialize the query input of the decoder. Moreover, we tackle the issue of redundant detection results, where the model generates numerous overlapping boxes from similar queries. To mitigate this, we introduce an IoU regularization term in the loss function. This term aids in distinguishing between queries matched with the ground-truth box and queries that are similar but unmatched during the refinement process, leading to reduced redundancy and more accurate detections. Through extensive experiments, we demonstrate the effectiveness of our approach in handling challenging scenarios, while incurring only a minor additional computational overhead. The code will be available at \url{https://github.com/Eaphan/STEMD}.

{{</citation>}}


### (17/50) DeepMediX: A Deep Learning-Driven Resource-Efficient Medical Diagnosis Across the Spectrum (Kishore Babu Nampalle et al., 2023)

{{<citation>}}

Kishore Babu Nampalle, Pradeep Singh, Uppala Vivek Narayan, Balasubramanian Raman. (2023)  
**DeepMediX: A Deep Learning-Driven Resource-Efficient Medical Diagnosis Across the Spectrum**  

---
Primary Category: cs.CV
Categories: I-2-1, cs-CV, cs-LG, cs.CV  
Keywords: AI  
[Paper Link](http://arxiv.org/abs/2307.00324v1)  

---


**ABSTRACT**  
In the rapidly evolving landscape of medical imaging diagnostics, achieving high accuracy while preserving computational efficiency remains a formidable challenge. This work presents \texttt{DeepMediX}, a groundbreaking, resource-efficient model that significantly addresses this challenge. Built on top of the MobileNetV2 architecture, DeepMediX excels in classifying brain MRI scans and skin cancer images, with superior performance demonstrated on both binary and multiclass skin cancer datasets. It provides a solution to labor-intensive manual processes, the need for large datasets, and complexities related to image properties. DeepMediX's design also includes the concept of Federated Learning, enabling a collaborative learning approach without compromising data privacy. This approach allows diverse healthcare institutions to benefit from shared learning experiences without the necessity of direct data access, enhancing the model's predictive power while preserving the privacy and integrity of sensitive patient data. Its low computational footprint makes DeepMediX suitable for deployment on handheld devices, offering potential for real-time diagnostic support. Through rigorous testing on standard datasets, including the ISIC2018 for dermatological research, DeepMediX demonstrates exceptional diagnostic capabilities, matching the performance of existing models on almost all tasks and even outperforming them in some cases. The findings of this study underline significant implications for the development and deployment of AI-based tools in medical imaging and their integration into point-of-care settings. The source code and models generated would be released at https://github.com/kishorebabun/DeepMediX.

{{</citation>}}


### (18/50) PM-DETR: Domain Adaptive Prompt Memory for Object Detection with Transformers (Peidong Jia et al., 2023)

{{<citation>}}

Peidong Jia, Jiaming Liu, Senqiao Yang, Jiarui Wu, Xiaodong Xie, Shanghang Zhang. (2023)  
**PM-DETR: Domain Adaptive Prompt Memory for Object Detection with Transformers**  

---
Primary Category: cs.CV
Categories: 68T07, I-5-1, cs-CV, cs.CV  
Keywords: Object Detection, Transformer, Transformers  
[Paper Link](http://arxiv.org/abs/2307.00313v1)  

---


**ABSTRACT**  
The Transformer-based detectors (i.e., DETR) have demonstrated impressive performance on end-to-end object detection. However, transferring DETR to different data distributions may lead to a significant performance degradation. Existing adaptation techniques focus on model-based approaches, which aim to leverage feature alignment to narrow the distribution shift between different domains. In this study, we propose a hierarchical Prompt Domain Memory (PDM) for adapting detection transformers to different distributions. PDM comprehensively leverages the prompt memory to extract domain-specific knowledge and explicitly constructs a long-term memory space for the data distribution, which represents better domain diversity compared to existing methods. Specifically, each prompt and its corresponding distribution value are paired in the memory space, and we inject top M distribution-similar prompts into the input and multi-level embeddings of DETR. Additionally, we introduce the Prompt Memory Alignment (PMA) to reduce the discrepancy between the source and target domains by fully leveraging the domain-specific knowledge extracted from the prompt domain memory. Extensive experiments demonstrate that our method outperforms state-of-the-art domain adaptive object detection methods on three benchmarks, including scene, synthetic to real, and weather adaptation. Codes will be released.

{{</citation>}}


### (19/50) Adversarial Attacks and Defenses on 3D Point Cloud Classification: A Survey (Hanieh Naderi et al., 2023)

{{<citation>}}

Hanieh Naderi, Ivan V. Bajić. (2023)  
**Adversarial Attacks and Defenses on 3D Point Cloud Classification: A Survey**  

---
Primary Category: cs.CV
Categories: cs-CV, cs-LG, cs.CV, eess-IV  
Keywords: AI, Adversarial Attack  
[Paper Link](http://arxiv.org/abs/2307.00309v1)  

---


**ABSTRACT**  
Deep learning has successfully solved a wide range of tasks in 2D vision as a dominant AI technique. Recently, deep learning on 3D point clouds is becoming increasingly popular for addressing various tasks in this field. Despite remarkable achievements, deep learning algorithms are vulnerable to adversarial attacks. These attacks are imperceptible to the human eye but can easily fool deep neural networks in the testing and deployment stage. To encourage future research, this survey summarizes the current progress on adversarial attack and defense techniques on point cloud classification. This paper first introduces the principles and characteristics of adversarial attacks and summarizes and analyzes the adversarial example generation methods in recent years. Besides, it classifies defense strategies as input transformation, data optimization, and deep model modification. Finally, it presents several challenging issues and future research directions in this domain.

{{</citation>}}


### (20/50) All-in-SAM: from Weak Annotation to Pixel-wise Nuclei Segmentation with Prompt-based Finetuning (Can Cui et al., 2023)

{{<citation>}}

Can Cui, Ruining Deng, Quan Liu, Tianyuan Yao, Shunxing Bao, Lucas W. Remedios, Yucheng Tang, Yuankai Huo. (2023)  
**All-in-SAM: from Weak Annotation to Pixel-wise Nuclei Segmentation with Prompt-based Finetuning**  

---
Primary Category: cs.CV
Categories: cs-CV, cs-LG, cs.CV  
Keywords: AI  
[Paper Link](http://arxiv.org/abs/2307.00290v1)  

---


**ABSTRACT**  
The Segment Anything Model (SAM) is a recently proposed prompt-based segmentation model in a generic zero-shot segmentation approach. With the zero-shot segmentation capacity, SAM achieved impressive flexibility and precision on various segmentation tasks. However, the current pipeline requires manual prompts during the inference stage, which is still resource intensive for biomedical image segmentation. In this paper, instead of using prompts during the inference stage, we introduce a pipeline that utilizes the SAM, called all-in-SAM, through the entire AI development workflow (from annotation generation to model finetuning) without requiring manual prompts during the inference stage. Specifically, SAM is first employed to generate pixel-level annotations from weak prompts (e.g., points, bounding box). Then, the pixel-level annotations are used to finetune the SAM segmentation model rather than training from scratch. Our experimental results reveal two key findings: 1) the proposed pipeline surpasses the state-of-the-art (SOTA) methods in a nuclei segmentation task on the public Monuseg dataset, and 2) the utilization of weak and few annotations for SAM finetuning achieves competitive performance compared to using strong pixel-wise annotated data.

{{</citation>}}


### (21/50) Forward-Forward Algorithm for Hyperspectral Image Classification: A Preliminary Study (Sidike Paheding et al., 2023)

{{<citation>}}

Sidike Paheding, Abel A. Reyes-Angulo. (2023)  
**Forward-Forward Algorithm for Hyperspectral Image Classification: A Preliminary Study**  

---
Primary Category: cs.CV
Categories: cs-AI, cs-CV, cs-LG, cs.CV  
Keywords: Image Classification  
[Paper Link](http://arxiv.org/abs/2307.00231v1)  

---


**ABSTRACT**  
The back-propagation algorithm has long been the de-facto standard in optimizing weights and biases in neural networks, particularly in cutting-edge deep learning models. Its widespread adoption in fields like natural language processing, computer vision, and remote sensing has revolutionized automation in various tasks. The popularity of back-propagation stems from its ability to achieve outstanding performance in tasks such as classification, detection, and segmentation. Nevertheless, back-propagation is not without its limitations, encompassing sensitivity to initial conditions, vanishing gradients, overfitting, and computational complexity. The recent introduction of a forward-forward algorithm (FFA), which computes local goodness functions to optimize network parameters, alleviates the dependence on substantial computational resources and the constant need for architectural scaling. This study investigates the application of FFA for hyperspectral image classification. Experimental results and comparative analysis are provided with the use of the traditional back-propagation algorithm. Preliminary results show the potential behind FFA and its promises.

{{</citation>}}


### (22/50) StyleStegan: Leak-free Style Transfer Based on Feature Steganography (Xiujian Liang et al., 2023)

{{<citation>}}

Xiujian Liang, Bingshan Liu, Qichao Ying, Zhenxing Qian, Xinpeng Zhang. (2023)  
**StyleStegan: Leak-free Style Transfer Based on Feature Steganography**  

---
Primary Category: cs.CV
Categories: cs-CV, cs-MM, cs.CV  
Keywords: Style Transfer  
[Paper Link](http://arxiv.org/abs/2307.00225v1)  

---


**ABSTRACT**  
In modern social networks, existing style transfer methods suffer from a serious content leakage issue, which hampers the ability to achieve serial and reversible stylization, thereby hindering the further propagation of stylized images in social networks. To address this problem, we propose a leak-free style transfer method based on feature steganography. Our method consists of two main components: a style transfer method that accomplishes artistic stylization on the original image and an image steganography method that embeds content feature secrets on the stylized image. The main contributions of our work are as follows: 1) We identify and explain the phenomenon of content leakage and its underlying causes, which arise from content inconsistencies between the original image and its subsequent stylized image. 2) We design a neural flow model for achieving loss-free and biased-free style transfer. 3) We introduce steganography to hide content feature information on the stylized image and control the subsequent usage rights. 4) We conduct comprehensive experimental validation using publicly available datasets MS-COCO and Wikiart. The results demonstrate that StyleStegan successfully mitigates the content leakage issue in serial and reversible style transfer tasks. The SSIM performance metrics for these tasks are 14.98% and 7.28% higher, respectively, compared to a suboptimal baseline model.

{{</citation>}}


### (23/50) Q-YOLO: Efficient Inference for Real-time Object Detection (Mingze Wang et al., 2023)

{{<citation>}}

Mingze Wang, Huixin Sun, Jun Shi, Xuhui Liu, Baochang Zhang, Xianbin Cao. (2023)  
**Q-YOLO: Efficient Inference for Real-time Object Detection**  

---
Primary Category: cs.CV
Categories: cs-CV, cs.CV  
Keywords: Object Detection, Quantization  
[Paper Link](http://arxiv.org/abs/2307.04816v1)  

---


**ABSTRACT**  
Real-time object detection plays a vital role in various computer vision applications. However, deploying real-time object detectors on resource-constrained platforms poses challenges due to high computational and memory requirements. This paper describes a low-bit quantization method to build a highly efficient one-stage detector, dubbed as Q-YOLO, which can effectively address the performance degradation problem caused by activation distribution imbalance in traditional quantized YOLO models. Q-YOLO introduces a fully end-to-end Post-Training Quantization (PTQ) pipeline with a well-designed Unilateral Histogram-based (UH) activation quantization scheme, which determines the maximum truncation values through histogram analysis by minimizing the Mean Squared Error (MSE) quantization errors. Extensive experiments on the COCO dataset demonstrate the effectiveness of Q-YOLO, outperforming other PTQ methods while achieving a more favorable balance between accuracy and computational cost. This research contributes to advancing the efficient deployment of object detection models on resource-limited edge devices, enabling real-time detection with reduced computational and memory overhead.

{{</citation>}}


### (24/50) More for Less: Compact Convolutional Transformers Enable Robust Medical Image Classification with Limited Data (Andrew Kean Gao, 2023)

{{<citation>}}

Andrew Kean Gao. (2023)  
**More for Less: Compact Convolutional Transformers Enable Robust Medical Image Classification with Limited Data**  

---
Primary Category: cs.CV
Categories: I-4-9, I-2-10, cs-CV, cs-LG, cs.CV  
Keywords: Image Classification, Transformer, Transformers  
[Paper Link](http://arxiv.org/abs/2307.00213v1)  

---


**ABSTRACT**  
Transformers are very powerful tools for a variety of tasks across domains, from text generation to image captioning. However, transformers require substantial amounts of training data, which is often a challenge in biomedical settings, where high quality labeled data can be challenging or expensive to obtain. This study investigates the efficacy of Compact Convolutional Transformers (CCT) for robust medical image classification with limited data, addressing a key issue faced by conventional Vision Transformers - their requirement for large datasets. A hybrid of transformers and convolutional layers, CCTs demonstrate high accuracy on modestly sized datasets. We employed a benchmark dataset of peripheral blood cell images of eight distinct cell types, each represented by approximately 2,000 low-resolution (28x28x3 pixel) samples. Despite the dataset size being smaller than those typically used with Vision Transformers, we achieved a commendable classification accuracy of 92.49% and a micro-average ROC AUC of 0.9935. The CCT also learned quickly, exceeding 80% validation accuracy after five epochs. Analysis of per-class precision, recall, F1, and ROC showed that performance was strong across cell types. Our findings underscore the robustness of CCTs, indicating their potential as a solution to data scarcity issues prevalent in biomedical imaging. We substantiate the applicability of CCTs in data-constrained areas and encourage further work on CCTs.

{{</citation>}}


### (25/50) Internal-External Boundary Attention Fusion for Glass Surface Segmentation (Dongshen Han et al., 2023)

{{<citation>}}

Dongshen Han, Seungkyu Lee. (2023)  
**Internal-External Boundary Attention Fusion for Glass Surface Segmentation**  

---
Primary Category: cs.CV
Categories: cs-CV, cs.CV  
Keywords: Attention  
[Paper Link](http://arxiv.org/abs/2307.00212v1)  

---


**ABSTRACT**  
Glass surfaces of transparent objects and mirrors are not able to be uniquely and explicitly characterized by their visual appearances because they contain the visual appearance of other reflected or transmitted surfaces as well. Detecting glass regions from a single-color image is a challenging task. Recent deep-learning approaches have paid attention to the description of glass surface boundary where the transition of visual appearances between glass and non-glass surfaces are observed. In this work, we analytically investigate how glass surface boundary helps to characterize glass objects. Inspired by prior semantic segmentation approaches with challenging image types such as X-ray or CT scans, we propose separated internal-external boundary attention modules that individually learn and selectively integrate visual characteristics of the inside and outside region of glass surface from a single color image. Our proposed method is evaluated on six public benchmarks comparing with state-of-the-art methods showing promising results.

{{</citation>}}


### (26/50) AIGCIQA2023: A Large-scale Image Quality Assessment Database for AI Generated Images: from the Perspectives of Quality, Authenticity and Correspondence (Jiarui Wang et al., 2023)

{{<citation>}}

Jiarui Wang, Huiyu Duan, Jing Liu, Shi Chen, Xiongkuo Min, Guangtao Zhai. (2023)  
**AIGCIQA2023: A Large-scale Image Quality Assessment Database for AI Generated Images: from the Perspectives of Quality, Authenticity and Correspondence**  

---
Primary Category: cs.CV
Categories: cs-CV, cs.CV, eess-IV  
Keywords: AI, QA  
[Paper Link](http://arxiv.org/abs/2307.00211v2)  

---


**ABSTRACT**  
In this paper, in order to get a better understanding of the human visual preferences for AIGIs, a large-scale IQA database for AIGC is established, which is named as AIGCIQA2023. We first generate over 2000 images based on 6 state-of-the-art text-to-image generation models using 100 prompts. Based on these images, a well-organized subjective experiment is conducted to assess the human visual preferences for each image from three perspectives including quality, authenticity and correspondence. Finally, based on this large-scale database, we conduct a benchmark experiment to evaluate the performance of several state-of-the-art IQA metrics on our constructed database.

{{</citation>}}


### (27/50) Filter Pruning for Efficient CNNs via Knowledge-driven Differential Filter Sampler (Shaohui Lin et al., 2023)

{{<citation>}}

Shaohui Lin, Wenxuan Huang, Jiao Xie, Baochang Zhang, Yunhang Shen, Zhou Yu, Jungong Han, David Doermann. (2023)  
**Filter Pruning for Efficient CNNs via Knowledge-driven Differential Filter Sampler**  

---
Primary Category: cs.CV
Categories: cs-CV, cs.CV  
Keywords: ImageNet, Pruning  
[Paper Link](http://arxiv.org/abs/2307.00198v1)  

---


**ABSTRACT**  
Filter pruning simultaneously accelerates the computation and reduces the memory overhead of CNNs, which can be effectively applied to edge devices and cloud services. In this paper, we propose a novel Knowledge-driven Differential Filter Sampler~(KDFS) with Masked Filter Modeling~(MFM) framework for filter pruning, which globally prunes the redundant filters based on the prior knowledge of a pre-trained model in a differential and non-alternative optimization. Specifically, we design a differential sampler with learnable sampling parameters to build a binary mask vector for each layer, determining whether the corresponding filters are redundant. To learn the mask, we introduce masked filter modeling to construct PCA-like knowledge by aligning the intermediate features from the pre-trained teacher model and the outputs of the student decoder taking sampling features as the input. The mask and sampler are directly optimized by the Gumbel-Softmax Straight-Through Gradient Estimator in an end-to-end manner in combination with global pruning constraint, MFM reconstruction error, and dark knowledge. Extensive experiments demonstrate the proposed KDFS's effectiveness in compressing the base models on various datasets. For instance, the pruned ResNet-50 on ImageNet achieves $55.36\%$ computation reduction, and $42.86\%$ parameter reduction, while only dropping $0.35\%$ Top-1 accuracy, significantly outperforming the state-of-the-art methods. The code is available at \url{https://github.com/Osilly/KDFS}.

{{</citation>}}


## cs.SE (3)



### (28/50) PersonaGen: A Tool for Generating Personas from User Feedback (Xishuo Zhang et al., 2023)

{{<citation>}}

Xishuo Zhang, Lin Liu, Yi Wang, Xiao Liu, Hailong Wang, Anqi Ren, Chetan Arora. (2023)  
**PersonaGen: A Tool for Generating Personas from User Feedback**  

---
Primary Category: cs.SE
Categories: cs-SE, cs.SE  
Keywords: GPT, GPT-4  
[Paper Link](http://arxiv.org/abs/2307.00390v1)  

---


**ABSTRACT**  
Personas are crucial in software development processes, particularly in agile settings. However, no effective tools are available for generating personas from user feedback in agile software development processes. To fill this gap, we propose a novel tool that uses the GPT-4 model and knowledge graph to generate persona templates from well-processed user feedback, facilitating requirement analysis in agile software development processes. We developed a tool called PersonaGen. We evaluated PersonaGen using qualitative feedback from a small-scale user study involving student software projects. The results were mixed, highlighting challenges in persona-based educational practice and addressing non-functional requirements.

{{</citation>}}


### (29/50) Self-Supervised Query Reformulation for Code Search (Yuetian Mao et al., 2023)

{{<citation>}}

Yuetian Mao, Chengcheng Wan, Yuze Jiang, Xiaodong Gu. (2023)  
**Self-Supervised Query Reformulation for Code Search**  

---
Primary Category: cs.SE
Categories: cs-SE, cs.SE  
Keywords: Self-Supervised, T5, Transformer  
[Paper Link](http://arxiv.org/abs/2307.00267v1)  

---


**ABSTRACT**  
Automatic query reformulation is a widely utilized technology for enriching user requirements and enhancing the outcomes of code search. It can be conceptualized as a machine translation task, wherein the objective is to rephrase a given query into a more comprehensive alternative. While showing promising results, training such a model typically requires a large parallel corpus of query pairs (i.e., the original query and a reformulated query) that are confidential and unpublished by online code search engines. This restricts its practicality in software development processes. In this paper, we propose SSQR, a self-supervised query reformulation method that does not rely on any parallel query corpus. Inspired by pre-trained models, SSQR treats query reformulation as a masked language modeling task conducted on an extensive unannotated corpus of queries. SSQR extends T5 (a sequence-to-sequence model based on Transformer) with a new pre-training objective named corrupted query completion (CQC), which randomly masks words within a complete query and trains T5 to predict the masked content. Subsequently, for a given query to be reformulated, SSQR identifies potential locations for expansion and leverages the pre-trained T5 model to generate appropriate content to fill these gaps. The selection of expansions is then based on the information gain associated with each candidate. Evaluation results demonstrate that SSQR outperforms unsupervised baselines significantly and achieves competitive performance compared to supervised methods.

{{</citation>}}


### (30/50) A Requirements-Driven Platform for Validating Field Operations of Small Uncrewed Aerial Vehicles (Ankit Agrawal et al., 2023)

{{<citation>}}

Ankit Agrawal, Bohan Zhang, Yashaswini Shivalingaiah, Michael Vierhauser, Jane Cleland-Huang. (2023)  
**A Requirements-Driven Platform for Validating Field Operations of Small Uncrewed Aerial Vehicles**  

---
Primary Category: cs.SE
Categories: cs-SE, cs.SE  
Keywords: Drone  
[Paper Link](http://arxiv.org/abs/2307.00194v1)  

---


**ABSTRACT**  
Flight-time failures of small Uncrewed Aerial Systems (sUAS) can have a severe impact on people or the environment. Therefore, sUAS applications must be thoroughly evaluated and tested to ensure their adherence to specified requirements, and safe behavior under real-world conditions, such as poor weather, wireless interference, and satellite failure. However, current simulation environments for autonomous vehicles, including sUAS, provide limited support for validating their behavior in diverse environmental contexts and moreover, lack a test harness to facilitate structured testing based on system-level requirements. We address these shortcomings by eliciting and specifying requirements for an sUAS testing and simulation platform, and developing and deploying it. The constructed platform, DroneReqValidator (DRV), allows sUAS developers to define the operating context, configure multi-sUAS mission requirements, specify safety properties, and deploy their own custom sUAS applications in a high-fidelity 3D environment. The DRV Monitoring system collects runtime data from sUAS and the environment, analyzes compliance with safety properties, and captures violations. We report on two case studies in which we used our platform prior to real-world sUAS deployments, in order to evaluate sUAS mission behavior in various environmental contexts. Furthermore, we conducted a study with developers and found that DRV simplifies the process of specifying requirements-driven test scenarios and analyzing acceptance test results

{{</citation>}}


## cs.CL (9)



### (31/50) Low-Resource Cross-Lingual Adaptive Training for Nigerian Pidgin (Pin-Jie Lin et al., 2023)

{{<citation>}}

Pin-Jie Lin, Muhammed Saeed, Ernie Chang, Merel Scholman. (2023)  
**Low-Resource Cross-Lingual Adaptive Training for Nigerian Pidgin**  

---
Primary Category: cs.CL
Categories: cs-CL, cs.CL  
Keywords: BLEU, Low-Resource  
[Paper Link](http://arxiv.org/abs/2307.00382v1)  

---


**ABSTRACT**  
Developing effective spoken language processing systems for low-resource languages poses several challenges due to the lack of parallel data and limited resources for fine-tuning models. In this work, we target on improving upon both text classification and translation of Nigerian Pidgin (Naija) by collecting a large-scale parallel English-Pidgin corpus and further propose a framework of cross-lingual adaptive training that includes both continual and task adaptive training so as to adapt a base pre-trained model to low-resource languages. Our studies show that English pre-trained language models serve as a stronger prior than multilingual language models on English-Pidgin tasks with up to 2.38 BLEU improvements; and demonstrate that augmenting orthographic data and using task adaptive training with back-translation can have a significant impact on model performance.

{{</citation>}}


### (32/50) Revisiting Sample Size Determination in Natural Language Understanding (Ernie Chang et al., 2023)

{{<citation>}}

Ernie Chang, Muhammad Hassan Rashid, Pin-Jie Lin, Changsheng Zhao, Vera Demberg, Yangyang Shi, Vikas Chandra. (2023)  
**Revisiting Sample Size Determination in Natural Language Understanding**  

---
Primary Category: cs.CL
Categories: cs-CL, cs.CL  
Keywords: NLP, Natural Language Understanding  
[Paper Link](http://arxiv.org/abs/2307.00374v1)  

---


**ABSTRACT**  
Knowing exactly how many data points need to be labeled to achieve a certain model performance is a hugely beneficial step towards reducing the overall budgets for annotation. It pertains to both active learning and traditional data annotation, and is particularly beneficial for low resource scenarios. Nevertheless, it remains a largely under-explored area of research in NLP. We therefore explored various techniques for estimating the training sample size necessary to achieve a targeted performance value. We derived a simple yet effective approach to predict the maximum achievable model performance based on small amount of training samples - which serves as an early indicator during data annotation for data quality and sample size determination. We performed ablation studies on four language understanding tasks, and showed that the proposed approach allows us to forecast model performance within a small margin of mean absolute error (~ 0.9%) with only 10% data.

{{</citation>}}


### (33/50) BatGPT: A Bidirectional Autoregessive Talker from Generative Pre-trained Transformer (Zuchao Li et al., 2023)

{{<citation>}}

Zuchao Li, Shitou Zhang, Hai Zhao, Yifei Yang, Dongjie Yang. (2023)  
**BatGPT: A Bidirectional Autoregessive Talker from Generative Pre-trained Transformer**  

---
Primary Category: cs.CL
Categories: cs-CL, cs.CL  
Keywords: AI, GPT, Transformer  
[Paper Link](http://arxiv.org/abs/2307.00360v1)  

---


**ABSTRACT**  
BatGPT is a large-scale language model designed and trained jointly by Wuhan University and Shanghai Jiao Tong University. It is capable of generating highly natural and fluent text in response to various types of input, including text prompts, images, and audio. In the modeling level, we employ a bidirectional autoregressive architecture that allows the model to efficiently capture the complex dependencies of natural language, making it highly effective in tasks such as language generation, dialog systems, and question answering. Moreover, the bidirectional autoregressive modeling not only operates from left to right but also from right to left, effectively reducing fixed memory effects and alleviating model hallucinations.   In the training aspect, we propose a novel parameter expansion method for leveraging the pre-training of smaller models and employ reinforcement learning from both AI and human feedback, aimed at improving the model's alignment performance. Overall, these approaches significantly improve the effectiveness of BatGPT, and the model can be utilized for a wide range of natural language applications.

{{</citation>}}


### (34/50) Single Sequence Prediction over Reasoning Graphs for Multi-hop QA (Gowtham Ramesh et al., 2023)

{{<citation>}}

Gowtham Ramesh, Makesh Sreedhar, Junjie Hu. (2023)  
**Single Sequence Prediction over Reasoning Graphs for Multi-hop QA**  

---
Primary Category: cs.CL
Categories: cs-CL, cs-LG, cs.CL  
Keywords: QA, Reasoning  
[Paper Link](http://arxiv.org/abs/2307.00335v1)  

---


**ABSTRACT**  
Recent generative approaches for multi-hop question answering (QA) utilize the fusion-in-decoder method~\cite{izacard-grave-2021-leveraging} to generate a single sequence output which includes both a final answer and a reasoning path taken to arrive at that answer, such as passage titles and key facts from those passages. While such models can lead to better interpretability and high quantitative scores, they often have difficulty accurately identifying the passages corresponding to key entities in the context, resulting in incorrect passage hops and a lack of faithfulness in the reasoning path. To address this, we propose a single-sequence prediction method over a local reasoning graph (\model)\footnote{Code/Models will be released at \url{https://github.com/gowtham1997/SeqGraph}} that integrates a graph structure connecting key entities in each context passage to relevant subsequent passages for each question. We use a graph neural network to encode this graph structure and fuse the resulting representations into the entity representations of the model. Our experiments show significant improvements in answer exact-match/F1 scores and faithfulness of grounding in the reasoning path on the HotpotQA dataset and achieve state-of-the-art numbers on the Musique dataset with only up to a 4\% increase in model parameters.

{{</citation>}}


### (35/50) Let Me Teach You: Pedagogical Foundations of Feedback for Language Models (Beatriz Borges et al., 2023)

{{<citation>}}

Beatriz Borges, Niket Tandon, Tanja Käser, Antoine Bosselut. (2023)  
**Let Me Teach You: Pedagogical Foundations of Feedback for Language Models**  

---
Primary Category: cs.CL
Categories: cs-CL, cs.CL  
Keywords: Language Model  
[Paper Link](http://arxiv.org/abs/2307.00279v1)  

---


**ABSTRACT**  
Natural Language Feedback (NLF) is an increasingly popular avenue to align Large Language Models (LLMs) to human preferences. Despite the richness and diversity of the information it can convey, NLF is often hand-designed and arbitrary. In a different world, research in pedagogy has long established several effective feedback models. In this opinion piece, we compile ideas from pedagogy to introduce FELT, a feedback framework for LLMs that outlines the various characteristics of the feedback space, and a feedback content taxonomy based on these variables. Our taxonomy offers both a general mapping of the feedback space, as well as pedagogy-established discrete categories, allowing us to empirically demonstrate the impact of different feedback types on revised generations. In addition to streamlining existing NLF designs, FELT also brings out new, unexplored directions for research in NLF. We make our taxonomy available to the community, providing guides and examples for mapping our categorizations to future resources.

{{</citation>}}


### (36/50) Hierarchical Pretraining for Biomedical Term Embeddings (Bryan Cai et al., 2023)

{{<citation>}}

Bryan Cai, Sihang Zeng, Yucong Lin, Zheng Yuan, Doudou Zhou, Lu Tian. (2023)  
**Hierarchical Pretraining for Biomedical Term Embeddings**  

---
Primary Category: cs.CL
Categories: cs-AI, cs-CL, cs.CL  
Keywords: BERT, Embedding, NLP  
[Paper Link](http://arxiv.org/abs/2307.00266v1)  

---


**ABSTRACT**  
Electronic health records (EHR) contain narrative notes that provide extensive details on the medical condition and management of patients. Natural language processing (NLP) of clinical notes can use observed frequencies of clinical terms as predictive features for downstream applications such as clinical decision making and patient trajectory prediction. However, due to the vast number of highly similar and related clinical concepts, a more effective modeling strategy is to represent clinical terms as semantic embeddings via representation learning and use the low dimensional embeddings as feature vectors for predictive modeling. To achieve efficient representation, fine-tuning pretrained language models with biomedical knowledge graphs may generate better embeddings for biomedical terms than those from standard language models alone. These embeddings can effectively discriminate synonymous pairs of from those that are unrelated. However, they often fail to capture different degrees of similarity or relatedness for concepts that are hierarchical in nature. To overcome this limitation, we propose HiPrBERT, a novel biomedical term representation model trained on additionally complied data that contains hierarchical structures for various biomedical terms. We modify an existing contrastive loss function to extract information from these hierarchies. Our numerical experiments demonstrate that HiPrBERT effectively learns the pair-wise distance from hierarchical information, resulting in a substantially more informative embeddings for further biomedical applications

{{</citation>}}


### (37/50) Automatic Counterfactual Augmentation for Robust Text Classification Based on Word-Group Search (Rui Song et al., 2023)

{{<citation>}}

Rui Song, Fausto Giunchiglia, Yingji Li, Hao Xu. (2023)  
**Automatic Counterfactual Augmentation for Robust Text Classification Based on Word-Group Search**  

---
Primary Category: cs.CL
Categories: cs-AI, cs-CL, cs.CL  
Keywords: Augmentation, Text Classification  
[Paper Link](http://arxiv.org/abs/2307.01214v1)  

---


**ABSTRACT**  
Despite large-scale pre-trained language models have achieved striking results for text classificaion, recent work has raised concerns about the challenge of shortcut learning. In general, a keyword is regarded as a shortcut if it creates a superficial association with the label, resulting in a false prediction. Conversely, shortcut learning can be mitigated if the model relies on robust causal features that help produce sound predictions. To this end, many studies have explored post-hoc interpretable methods to mine shortcuts and causal features for robustness and generalization. However, most existing methods focus only on single word in a sentence and lack consideration of word-group, leading to wrong causal features. To solve this problem, we propose a new Word-Group mining approach, which captures the causal effect of any keyword combination and orders the combinations that most affect the prediction. Our approach bases on effective post-hoc analysis and beam search, which ensures the mining effect and reduces the complexity. Then, we build a counterfactual augmentation method based on the multiple word-groups, and use an adaptive voting mechanism to learn the influence of different augmentated samples on the prediction results, so as to force the model to pay attention to effective causal features. We demonstrate the effectiveness of the proposed method by several tasks on 8 affective review datasets and 4 toxic language datasets, including cross-domain text classificaion, text attack and gender fairness test.

{{</citation>}}


### (38/50) How far is Language Model from 100% Few-shot Named Entity Recognition in Medical Domain (Mingchen Li et al., 2023)

{{<citation>}}

Mingchen Li, Rui Zhang. (2023)  
**How far is Language Model from 100% Few-shot Named Entity Recognition in Medical Domain**  

---
Primary Category: cs.CL
Categories: cs-CL, cs.CL  
Keywords: BERT, GPT, GPT-4, Language Model, NER, Named Entity Recognition, T5  
[Paper Link](http://arxiv.org/abs/2307.00186v1)  

---


**ABSTRACT**  
Recent advancements in language models (LMs) have led to the emergence of powerful models such as Small LMs (e.g., T5) and Large LMs (e.g., GPT-4). These models have demonstrated exceptional capabilities across a wide range of tasks, such as name entity recognition (NER) in the general domain. (We define SLMs as pre-trained models with fewer parameters compared to models like GPT-3/3.5/4, such as T5, BERT, and others.) Nevertheless, their efficacy in the medical section remains uncertain and the performance of medical NER always needs high accuracy because of the particularity of the field. This paper aims to provide a thorough investigation to compare the performance of LMs in medical few-shot NER and answer How far is LMs from 100\% Few-shot NER in Medical Domain, and moreover to explore an effective entity recognizer to help improve the NER performance. Based on our extensive experiments conducted on 16 NER models spanning from 2018 to 2023, our findings clearly indicate that LLMs outperform SLMs in few-shot medical NER tasks, given the presence of suitable examples and appropriate logical frameworks. Despite the overall superiority of LLMs in few-shot medical NER tasks, it is important to note that they still encounter some challenges, such as misidentification, wrong template prediction, etc. Building on previous findings, we introduce a simple and effective method called \textsc{RT} (Retrieving and Thinking), which serves as retrievers, finding relevant examples, and as thinkers, employing a step-by-step reasoning process. Experimental results show that our proposed \textsc{RT} framework significantly outperforms the strong open baselines on the two open medical benchmark datasets

{{</citation>}}


### (39/50) Personality Traits in Large Language Models (Mustafa Safdari et al., 2023)

{{<citation>}}

Mustafa Safdari, Greg Serapio-García, Clément Crepy, Stephen Fitz, Peter Romero, Luning Sun, Marwa Abdulhai, Aleksandra Faust, Maja Matarić. (2023)  
**Personality Traits in Large Language Models**  

---
Primary Category: cs.CL
Categories: 68T35, I-2-7, cs-AI, cs-CL, cs-CY, cs-HC, cs.CL  
Keywords: Language Model  
[Paper Link](http://arxiv.org/abs/2307.00184v1)  

---


**ABSTRACT**  
The advent of large language models (LLMs) has revolutionized natural language processing, enabling the generation of coherent and contextually relevant text. As LLMs increasingly power conversational agents, the synthesized personality embedded in these models by virtue of their training on large amounts of human-generated data draws attention. Since personality is an important factor determining the effectiveness of communication, we present a comprehensive method for administering validated psychometric tests and quantifying, analyzing, and shaping personality traits exhibited in text generated from widely-used LLMs. We find that: 1) personality simulated in the outputs of some LLMs (under specific prompting configurations) is reliable and valid; 2) evidence of reliability and validity of LLM-simulated personality is stronger for larger and instruction fine-tuned models; and 3) personality in LLM outputs can be shaped along desired dimensions to mimic specific personality profiles. We also discuss potential applications and ethical implications of our measurement and shaping framework, especially regarding responsible use of LLMs.

{{</citation>}}


## cs.IR (1)



### (40/50) Effective Matching of Patients to Clinical Trials using Entity Extraction and Neural Re-ranking (Wojciech Kusa et al., 2023)

{{<citation>}}

Wojciech Kusa, Óscar E. Mendoza, Petr Knoth, Gabriella Pasi, Allan Hanbury. (2023)  
**Effective Matching of Patients to Clinical Trials using Entity Extraction and Neural Re-ranking**  

---
Primary Category: cs.IR
Categories: cs-CL, cs-IR, cs.IR  
Keywords: Clinical, Transformer  
[Paper Link](http://arxiv.org/abs/2307.00381v1)  

---


**ABSTRACT**  
Clinical trials (CTs) often fail due to inadequate patient recruitment. This paper tackles the challenges of CT retrieval by presenting an approach that addresses the patient-to-trials paradigm. Our approach involves two key components in a pipeline-based model: (i) a data enrichment technique for enhancing both queries and documents during the first retrieval stage, and (ii) a novel re-ranking schema that uses a Transformer network in a setup adapted to this task by leveraging the structure of the CT documents. We use named entity recognition and negation detection in both patient description and the eligibility section of CTs. We further classify patient descriptions and CT eligibility criteria into current, past, and family medical conditions. This extracted information is used to boost the importance of disease and drug mentions in both query and index for lexical retrieval. Furthermore, we propose a two-step training schema for the Transformer network used to re-rank the results from the lexical retrieval. The first step focuses on matching patient information with the descriptive sections of trials, while the second step aims to determine eligibility by matching patient information with the criteria section. Our findings indicate that the inclusion criteria section of the CT has a great influence on the relevance score in lexical models, and that the enrichment techniques for queries and documents improve the retrieval of relevant trials. The re-ranking strategy, based on our training schema, consistently enhances CT retrieval and shows improved performance by 15\% in terms of precision at retrieving eligible trials. The results of our experiments suggest the benefit of making use of extracted entities. Moreover, our proposed re-ranking schema shows promising effectiveness compared to larger neural models, even with limited training data.

{{</citation>}}


## cs.AI (1)



### (41/50) CephGPT-4: An Interactive Multimodal Cephalometric Measurement and Diagnostic System with Visual Large Language Model (Lei Ma et al., 2023)

{{<citation>}}

Lei Ma, Jincong Han, Zhaoxin Wang, Dian Zhang. (2023)  
**CephGPT-4: An Interactive Multimodal Cephalometric Measurement and Diagnostic System with Visual Large Language Model**  

---
Primary Category: cs.AI
Categories: cs-AI, cs-CL, cs-CV, cs.AI, eess-IV  
Keywords: GLM, GPT, GPT-4, Language Model  
[Paper Link](http://arxiv.org/abs/2307.07518v1)  

---


**ABSTRACT**  
Large-scale multimodal language models (LMMs) have achieved remarkable success in general domains. However, the exploration of diagnostic language models based on multimodal cephalometric medical data remains limited. In this paper, we propose a novel multimodal cephalometric analysis and diagnostic dialogue model. Firstly, a multimodal orthodontic medical dataset is constructed, comprising cephalometric images and doctor-patient dialogue data, with automatic analysis of cephalometric landmarks using U-net and generation of diagnostic reports. Then, the cephalometric dataset and generated diagnostic reports are separately fine-tuned on Minigpt-4 and VisualGLM. Results demonstrate that the CephGPT-4 model exhibits excellent performance and has the potential to revolutionize orthodontic measurement and diagnostic applications. These innovations hold revolutionary application potential in the field of orthodontics.

{{</citation>}}


## cs.HC (1)



### (42/50) Lottery and Sprint: Generate a Board Game with Design Sprint Method on Auto-GPT (Maya Grace Torii et al., 2023)

{{<citation>}}

Maya Grace Torii, Takahito Murakami, Yoichi Ochiai. (2023)  
**Lottery and Sprint: Generate a Board Game with Design Sprint Method on Auto-GPT**  

---
Primary Category: cs.HC
Categories: cs-HC, cs.HC  
Keywords: GPT  
[Paper Link](http://arxiv.org/abs/2307.00348v1)  

---


**ABSTRACT**  
In this paper, we present a novel approach using the Auto GPT system alongside Design Sprint methodology to facilitate board game creation for inexperienced users. We introduce the implementation of Auto GPT for generating diverse board games and the subsequent optimization process through a customized Design Sprint. A user study is conducted to investigate the playability and enjoyment of the generated games, revealing both successes and challenges in employing systems like Auto GPT for board game design. Insights and future research directions are proposed to overcome identified limitations and enhance computational-driven game creation.

{{</citation>}}


## cs.RO (2)



### (43/50) DoReMi: Grounding Language Model by Detecting and Recovering from Plan-Execution Misalignment (Yanjiang Guo et al., 2023)

{{<citation>}}

Yanjiang Guo, Yen-Jen Wang, Lihan Zha, Zheyuan Jiang, Jianyu Chen. (2023)  
**DoReMi: Grounding Language Model by Detecting and Recovering from Plan-Execution Misalignment**  

---
Primary Category: cs.RO
Categories: cs-AI, cs-RO, cs.RO  
Keywords: Language Model, QA  
[Paper Link](http://arxiv.org/abs/2307.00329v1)  

---


**ABSTRACT**  
Large language models encode a vast amount of semantic knowledge and possess remarkable understanding and reasoning capabilities. Previous research has explored how to ground language models in robotic tasks to ensure that the sequences generated by the language model are both logically correct and practically executable. However, low-level execution may deviate from the high-level plan due to environmental perturbations or imperfect controller design. In this paper, we propose DoReMi, a novel language model grounding framework that enables immediate Detection and Recovery from Misalignments between plan and execution. Specifically, during low-level skill execution, we use a vision question answering (VQA) model to regularly detect plan-execution misalignments. If certain misalignment occurs, our method will call the language model to re-plan in order to recover from misalignments. Experiments on various complex tasks including robot arms and humanoid robots demonstrate that our method can lead to higher task success rates and shorter task completion times. Videos of DoReMi are available at https://sites.google.com/view/doremi-paper.

{{</citation>}}


### (44/50) General Part Assembly Planning (Yulong Li et al., 2023)

{{<citation>}}

Yulong Li, Andy Zeng, Shuran Song. (2023)  
**General Part Assembly Planning**  

---
Primary Category: cs.RO
Categories: cs-AI, cs-RO, cs.RO  
Keywords: Transformer  
[Paper Link](http://arxiv.org/abs/2307.00206v1)  

---


**ABSTRACT**  
Most successes in autonomous robotic assembly have been restricted to single target or category. We propose to investigate general part assembly, the task of creating novel target assemblies with unseen part shapes. To tackle the planning of general part assembly, we present General Part Assembly Transformer (GPAT), a transformer based model architecture that accurately predicts part poses by inferring how each part shape corresponds to the target shape. Our experiments on both 3D CAD models and real-world scans demonstrate GPAT's generalization abilities to novel and diverse target and part shapes. Project website: https://general-part-assembly.github.io/

{{</citation>}}


## cs.CY (2)



### (45/50) RUI: A Web-based Road Updates Information System using Google Maps API (Benzar Glen S. Grepon et al., 2023)

{{<citation>}}

Benzar Glen S. Grepon, JC P. Margallo, Jonathan B. Maserin, Rio Al-Di A. Dompol. (2023)  
**RUI: A Web-based Road Updates Information System using Google Maps API**  

---
Primary Category: cs.CY
Categories: cs-CY, cs.CY  
Keywords: Google  
[Paper Link](http://arxiv.org/abs/2307.00323v1)  

---


**ABSTRACT**  
Knowing the current situation on every road in an area is still difficult to anticipate. Commuters, riders, and drivers are still dependent on road situations from a local news agency to be well informed and be updated on possible road updates such as vehicular accidents, government road and bridge projects/construction, and other related road obstructions. To give solutions regarding road updates, a web-based roads update information system has been developed that uses Google Maps API allowing people to view and be notified of the real-time updates of the road situation of a specific area. This paper discusses the main system functionalities, including sub-systems and modules of the system, the research approach and methodology, which is the Agile Model, and its impact on disseminating road information and its status. The project has been evaluated using ISO 25010. Based on the evaluation result, the project has been rated 4.21, signifying an excellent performance based on qualitative description through a Likert scale descriptive interpretation. The project has been running and hosted on the world wide web and is expected to expand its coverage area from its origin country to the rest of the world. Based on the initial findings of the study, the respondents agreed that the developed web system was functional and a massive help to commuters, riders, and people who travel a lot. The system's overall effectiveness and performance were excellent based on the criteria set by ISO/IEC 25010. It is recommended for future development to expand the coverage of the road updates, if possible, including the entire Philippine archipelago for long-drive commuters and drivers to be more updated in terms of road updates. Also, include the use of mobile applications for more user-friendly design and interactions.

{{</citation>}}


### (46/50) Finding differences in perspectives between designers and engineers to develop trustworthy AI for autonomous cars (Gustav Jonelid et al., 2023)

{{<citation>}}

Gustav Jonelid, K. R. Larsson. (2023)  
**Finding differences in perspectives between designers and engineers to develop trustworthy AI for autonomous cars**  

---
Primary Category: cs.CY
Categories: cs-AI, cs-CY, cs.CY  
Keywords: AI  
[Paper Link](http://arxiv.org/abs/2307.03193v1)  

---


**ABSTRACT**  
In the context of designing and implementing ethical Artificial Intelligence (AI), varying perspectives exist regarding developing trustworthy AI for autonomous cars. This study sheds light on the differences in perspectives and provides recommendations to minimize such divergences. By exploring the diverse viewpoints, we identify key factors contributing to the differences and propose strategies to bridge the gaps. This study goes beyond the trolley problem to visualize the complex challenges of trustworthy and ethical AI. Three pillars of trustworthy AI have been defined: transparency, reliability, and safety. This research contributes to the field of trustworthy AI for autonomous cars, providing practical recommendations to enhance the development of AI systems that prioritize both technological advancement and ethical principles.

{{</citation>}}


## cs.NI (1)



### (47/50) A Survey on Explainable AI for 6G O-RAN: Architecture, Use Cases, Challenges and Research Directions (Bouziane Brik et al., 2023)

{{<citation>}}

Bouziane Brik, Hatim Chergui, Lanfranco Zanzi, Francesco Devoti, Adlen Ksentini, Muhammad Shuaib Siddiqui, Xavier Costa-Pérez, Christos Verikoukis. (2023)  
**A Survey on Explainable AI for 6G O-RAN: Architecture, Use Cases, Challenges and Research Directions**  

---
Primary Category: cs.NI
Categories: cs-NI, cs.NI  
Keywords: AI  
[Paper Link](http://arxiv.org/abs/2307.00319v3)  

---


**ABSTRACT**  
The recent O-RAN specifications promote the evolution of RAN architecture by function disaggregation, adoption of open interfaces, and instantiation of a hierarchical closed-loop control architecture managed by RAN Intelligent Controllers (RICs) entities. This paves the road to novel data-driven network management approaches based on programmable logic. Aided by Artificial Intelligence (AI) and Machine Learning (ML), novel solutions targeting traditionally unsolved RAN management issues can be devised. Nevertheless, the adoption of such smart and autonomous systems is limited by the current inability of human operators to understand the decision process of such AI/ML solutions, affecting their trust in such novel tools. eXplainable AI (XAI) aims at solving this issue, enabling human users to better understand and effectively manage the emerging generation of artificially intelligent schemes, reducing the human-to-machine barrier. In this survey, we provide a summary of the XAI methods and metrics before studying their deployment over the O-RAN Alliance RAN architecture along with its main building blocks. We then present various use-cases and discuss the automation of XAI pipelines for O-RAN as well as the underlying security aspects. We also review some projects/standards that tackle this area. Finally, we identify different challenges and research directions that may arise from the heavy adoption of AI/ML decision entities in this context, focusing on how XAI can help to interpret, understand, and improve trust in O-RAN operational networks.

{{</citation>}}


## cs.NE (1)



### (48/50) AutoST: Training-free Neural Architecture Search for Spiking Transformers (Ziqing Wang et al., 2023)

{{<citation>}}

Ziqing Wang, Qidong Zhao, Jinku Cui, Xu Liu, Dongkuan Xu. (2023)  
**AutoST: Training-free Neural Architecture Search for Spiking Transformers**  

---
Primary Category: cs.NE
Categories: cs-CV, cs-LG, cs-NE, cs.NE  
Keywords: Transformer, Transformers  
[Paper Link](http://arxiv.org/abs/2307.00293v1)  

---


**ABSTRACT**  
Spiking Transformers have gained considerable attention because they achieve both the energy efficiency of Spiking Neural Networks (SNNs) and the high capacity of Transformers. However, the existing Spiking Transformer architectures, derived from ANNs, exhibit a notable architectural gap, resulting in suboptimal performance compared to their ANN counterparts. Traditional approaches to discovering optimal architectures primarily rely on either manual procedures, which are time-consuming, or Neural Architecture Search (NAS) methods, which are usually expensive in terms of memory footprints and computation time. To address these limitations, we introduce AutoST, a training-free NAS method for Spiking Transformers, to rapidly identify high-performance and energy-efficient Spiking Transformer architectures. Unlike existing training-free NAS methods, which struggle with the non-differentiability and high sparsity inherent in SNNs, we propose to utilize Floating-Point Operations (FLOPs) as a performance metric, which is independent of model computations and training dynamics, leading to a stronger correlation with performance. Moreover, to enable the search for energy-efficient architectures, we leverage activation patterns during initialization to estimate the energy consumption of Spiking Transformers. Our extensive experiments show that AutoST models outperform state-of-the-art manually or automatically designed SNN architectures on static and neuromorphic datasets, while significantly reducing energy consumption.

{{</citation>}}


## eess.SP (1)



### (49/50) Decoding Taste Information in Human Brain: A Temporal and Spatial Reconstruction Data Augmentation Method Coupled with Taste EEG (Xiuxin Xia et al., 2023)

{{<citation>}}

Xiuxin Xia, Yuchao Yang, Yan Shi, Wenbo Zheng, Hong Men. (2023)  
**Decoding Taste Information in Human Brain: A Temporal and Spatial Reconstruction Data Augmentation Method Coupled with Taste EEG**  

---
Primary Category: eess.SP
Categories: cs-HC, eess-SP, eess.SP  
Keywords: Augmentation  
[Paper Link](http://arxiv.org/abs/2307.05365v1)  

---


**ABSTRACT**  
For humans, taste is essential for perceiving food's nutrient content or harmful components. The current sensory evaluation of taste mainly relies on artificial sensory evaluation and electronic tongue, but the former has strong subjectivity and poor repeatability, and the latter is not flexible enough. This work proposed a strategy for acquiring and recognizing taste electroencephalogram (EEG), aiming to decode people's objective perception of taste through taste EEG. Firstly, according to the proposed experimental paradigm, the taste EEG of subjects under different taste stimulation was collected. Secondly, to avoid insufficient training of the model due to the small number of taste EEG samples, a Temporal and Spatial Reconstruction Data Augmentation (TSRDA) method was proposed, which effectively augmented the taste EEG by reconstructing the taste EEG's important features in temporal and spatial dimensions. Thirdly, a multi-view channel attention module was introduced into a designed convolutional neural network to extract the important features of the augmented taste EEG. The proposed method has accuracy of 99.56%, F1-score of 99.48%, and kappa of 99.38%, proving the method's ability to distinguish the taste EEG evoked by different taste stimuli successfully. In summary, combining TSRDA with taste EEG technology provides an objective and effective method for sensory evaluation of food taste.

{{</citation>}}


## math.NA (1)



### (50/50) Constrained Local Approximate Ideal Restriction for Advection-Diffusion Problems (Ahsan Ali et al., 2023)

{{<citation>}}

Ahsan Ali, James Brannick, Karsten Kahl, Oliver A. Krzysik, Jacob B. Schroder, Ben S. Southworth. (2023)  
**Constrained Local Approximate Ideal Restriction for Advection-Diffusion Problems**  

---
Primary Category: math.NA
Categories: 65N55 (Primary), 65N22, 65F08, 65F10 (Secondary), cs-NA, math-NA, math.NA  
Keywords: AI  
[Paper Link](http://arxiv.org/abs/2307.00229v1)  

---


**ABSTRACT**  
This paper focuses on developing a reduction-based algebraic multigrid method that is suitable for solving general (non)symmetric linear systems and is naturally robust from pure advection to pure diffusion. Initial motivation comes from a new reduction-based algebraic multigrid (AMG) approach, $\ell$AIR (local approximate ideal restriction), that was developed for solving advection-dominated problems. Though this new solver is very effective in the advection dominated regime, its performance degrades in cases where diffusion becomes dominant. This is consistent with the fact that in general, reduction-based AMG methods tend to suffer from growth in complexity and/or convergence rates as the problem size is increased, especially for diffusion dominated problems in two or three dimensions. Motivated by the success of $\ell$AIR in the advective regime, our aim in this paper is to generalize the AIR framework with the goal of improving the performance of the solver in diffusion dominated regimes. To do so, we propose a novel way to combine mode constraints as used commonly in energy minimization AMG methods with the local approximation of ideal operators used in $\ell$AIR. The resulting constrained $\ell$AIR (C$\ell$AIR) algorithm is able to achieve fast scalable convergence on advective and diffusive problems. In addition, it is able to achieve standard low complexity hierarchies in the diffusive regime through aggressive coarsening, something that has been previously difficult for reduction-based methods.

{{</citation>}}
