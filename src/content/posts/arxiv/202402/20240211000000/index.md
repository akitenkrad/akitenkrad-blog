---
draft: false
title: "arXiv @ 2024.02.11"
date: 2024-02-11
author: "akitenkrad"
description: ""
tags: ["arXiv", "Published:2024"]
menu:
  sidebar:
    name: "arXiv @ 2024.02.11"
    identifier: arxiv_20240211
    parent: 202402_arxiv
    weight: 10
math: true
---

<figure style="border:none; width:100%; display:flex; justify-content: center">
    <iframe src="pie.html" width=900 height=620 style="border:none"></iframe>
</figure>


## Primary Categories

- [cs.AI (12)](#csai-12)
- [cs.AR (2)](#csar-2)
- [cs.CE (2)](#csce-2)
- [cs.CG (1)](#cscg-1)
- [cs.CL (27)](#cscl-27)
- [cs.CR (2)](#cscr-2)
- [cs.CV (37)](#cscv-37)
- [cs.CY (1)](#cscy-1)
- [cs.DB (1)](#csdb-1)
- [cs.DC (3)](#csdc-3)
- [cs.DS (2)](#csds-2)
- [cs.HC (4)](#cshc-4)
- [cs.IR (4)](#csir-4)
- [cs.IT (3)](#csit-3)
- [cs.LG (50)](#cslg-50)
- [cs.MA (1)](#csma-1)
- [cs.NE (3)](#csne-3)
- [cs.RO (9)](#csro-9)
- [cs.SD (4)](#cssd-4)
- [cs.SE (4)](#csse-4)
- [cs.SI (3)](#cssi-3)
- [eess.AS (1)](#eessas-1)
- [eess.IV (1)](#eessiv-1)
- [eess.SP (1)](#eesssp-1)
- [eess.SY (5)](#eesssy-5)
- [math.NA (2)](#mathna-2)
- [math.OC (1)](#mathoc-1)
- [physics.flu-dyn (2)](#physicsflu-dyn-2)
- [physics.geo-ph (1)](#physicsgeo-ph-1)
- [q-bio.QM (1)](#q-bioqm-1)
- [stat.CO (1)](#statco-1)
- [stat.ME (1)](#statme-1)
- [stat.ML (5)](#statml-5)

## Keywords

<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th>keyword</th>
      <th>cs.AI</th>
      <th>cs.CL</th>
      <th>cs.CV</th>
      <th>cs.LG</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td>Active Learning</td>
      <td></td>
      <td></td>
      <td>1</td>
      <td>1</td>
    </tr>
    <tr>
      <td>Adversarial Attack</td>
      <td></td>
      <td></td>
      <td>1</td>
      <td>3</td>
    </tr>
    <tr>
      <td>Adversarial Learning</td>
      <td></td>
      <td></td>
      <td></td>
      <td>2</td>
    </tr>
    <tr>
      <td>Autoencoder</td>
      <td></td>
      <td></td>
      <td>1</td>
      <td></td>
    </tr>
    <tr>
      <td>Automatic Evaluation</td>
      <td></td>
      <td></td>
      <td>1</td>
      <td></td>
    </tr>
    <tr>
      <td>Automatic Speech Recognition</td>
      <td></td>
      <td>2</td>
      <td></td>
      <td></td>
    </tr>
    <tr>
      <td>BERT</td>
      <td></td>
      <td>2</td>
      <td></td>
      <td></td>
    </tr>
    <tr>
      <td>Bag-of-Words</td>
      <td></td>
      <td></td>
      <td>1</td>
      <td></td>
    </tr>
    <tr>
      <td>Bandit Algorithm</td>
      <td></td>
      <td></td>
      <td></td>
      <td>1</td>
    </tr>
    <tr>
      <td>Benchmarking</td>
      <td>3</td>
      <td>4</td>
      <td>12</td>
      <td>8</td>
    </tr>
    <tr>
      <td>ChatGPT</td>
      <td></td>
      <td>3</td>
      <td></td>
      <td></td>
    </tr>
    <tr>
      <td>Code Generation</td>
      <td></td>
      <td></td>
      <td></td>
      <td>2</td>
    </tr>
    <tr>
      <td>Continual Learning</td>
      <td></td>
      <td></td>
      <td></td>
      <td>2</td>
    </tr>
    <tr>
      <td>Contrastive Learning</td>
      <td></td>
      <td></td>
      <td>2</td>
      <td>2</td>
    </tr>
    <tr>
      <td>Convolution</td>
      <td></td>
      <td></td>
      <td>5</td>
      <td>2</td>
    </tr>
    <tr>
      <td>Convolutional Neural Network</td>
      <td></td>
      <td></td>
      <td>6</td>
      <td>3</td>
    </tr>
    <tr>
      <td>Counter-factual</td>
      <td>1</td>
      <td></td>
      <td></td>
      <td></td>
    </tr>
    <tr>
      <td>Counterfactual Reasoning</td>
      <td>1</td>
      <td></td>
      <td></td>
      <td></td>
    </tr>
    <tr>
      <td>Data Augmentation</td>
      <td></td>
      <td>2</td>
      <td>1</td>
      <td>2</td>
    </tr>
    <tr>
      <td>Dialogue System</td>
      <td></td>
      <td>1</td>
      <td></td>
      <td></td>
    </tr>
    <tr>
      <td>Disambiguation</td>
      <td></td>
      <td>1</td>
      <td></td>
      <td></td>
    </tr>
    <tr>
      <td>Domain Adaptation</td>
      <td></td>
      <td></td>
      <td>3</td>
      <td></td>
    </tr>
    <tr>
      <td>Event Detection</td>
      <td></td>
      <td>1</td>
      <td></td>
      <td></td>
    </tr>
    <tr>
      <td>Fact Verification</td>
      <td></td>
      <td>2</td>
      <td></td>
      <td></td>
    </tr>
    <tr>
      <td>Fairness</td>
      <td>1</td>
      <td></td>
      <td>1</td>
      <td>3</td>
    </tr>
    <tr>
      <td>Federated Learning</td>
      <td></td>
      <td></td>
      <td></td>
      <td>1</td>
    </tr>
    <tr>
      <td>Few-shot</td>
      <td>1</td>
      <td>2</td>
      <td>1</td>
      <td>2</td>
    </tr>
    <tr>
      <td>Fine-tuning</td>
      <td>3</td>
      <td>10</td>
      <td>2</td>
      <td>7</td>
    </tr>
    <tr>
      <td>Foundation Model</td>
      <td></td>
      <td></td>
      <td>1</td>
      <td></td>
    </tr>
    <tr>
      <td>GPT</td>
      <td>1</td>
      <td>6</td>
      <td>1</td>
      <td></td>
    </tr>
    <tr>
      <td>GPT-4</td>
      <td>1</td>
      <td>3</td>
      <td></td>
      <td></td>
    </tr>
    <tr>
      <td>Gaussian Process</td>
      <td></td>
      <td></td>
      <td></td>
      <td>1</td>
    </tr>
    <tr>
      <td>Gemini</td>
      <td></td>
      <td>1</td>
      <td></td>
      <td></td>
    </tr>
    <tr>
      <td>Generative AI</td>
      <td></td>
      <td>1</td>
      <td>1</td>
      <td>1</td>
    </tr>
    <tr>
      <td>Generative Adversarial Network</td>
      <td></td>
      <td></td>
      <td>3</td>
      <td>3</td>
    </tr>
    <tr>
      <td>Graph Contrastive Learning</td>
      <td></td>
      <td></td>
      <td></td>
      <td>1</td>
    </tr>
    <tr>
      <td>Graph Neural Network</td>
      <td></td>
      <td></td>
      <td></td>
      <td>6</td>
    </tr>
    <tr>
      <td>Grounding</td>
      <td>2</td>
      <td>1</td>
      <td>1</td>
      <td></td>
    </tr>
    <tr>
      <td>Hate Speech Detection</td>
      <td></td>
      <td>1</td>
      <td></td>
      <td></td>
    </tr>
    <tr>
      <td>Image2text</td>
      <td></td>
      <td></td>
      <td>1</td>
      <td></td>
    </tr>
    <tr>
      <td>In-context Learning</td>
      <td></td>
      <td>5</td>
      <td>3</td>
      <td>3</td>
    </tr>
    <tr>
      <td>Information Retrieval</td>
      <td>1</td>
      <td>1</td>
      <td></td>
      <td></td>
    </tr>
    <tr>
      <td>Instruction Following</td>
      <td></td>
      <td>1</td>
      <td></td>
      <td>1</td>
    </tr>
    <tr>
      <td>Instruction Tuning</td>
      <td>1</td>
      <td>3</td>
      <td></td>
      <td></td>
    </tr>
    <tr>
      <td>Knowledge Distillation</td>
      <td></td>
      <td></td>
      <td>3</td>
      <td>7</td>
    </tr>
    <tr>
      <td>Knowledge Graph</td>
      <td>1</td>
      <td>1</td>
      <td></td>
      <td></td>
    </tr>
    <tr>
      <td>Knowledge Transfer</td>
      <td></td>
      <td></td>
      <td></td>
      <td>1</td>
    </tr>
    <tr>
      <td>LLaMA</td>
      <td></td>
      <td>3</td>
      <td></td>
      <td></td>
    </tr>
    <tr>
      <td>Language Generation</td>
      <td></td>
      <td>1</td>
      <td></td>
      <td></td>
    </tr>
    <tr>
      <td>Large Language Model</td>
      <td>11</td>
      <td>32</td>
      <td>4</td>
      <td>14</td>
    </tr>
    <tr>
      <td>Logistic Regression</td>
      <td></td>
      <td></td>
      <td></td>
      <td>1</td>
    </tr>
    <tr>
      <td>Markov Decision Process</td>
      <td></td>
      <td></td>
      <td></td>
      <td>1</td>
    </tr>
    <tr>
      <td>Multi-modal</td>
      <td>2</td>
      <td></td>
      <td>9</td>
      <td>9</td>
    </tr>
    <tr>
      <td>Multiple Instance Learning</td>
      <td></td>
      <td></td>
      <td>1</td>
      <td></td>
    </tr>
    <tr>
      <td>Named Entity Recognition</td>
      <td></td>
      <td>2</td>
      <td></td>
      <td></td>
    </tr>
    <tr>
      <td>Natural Language Inference</td>
      <td></td>
      <td>2</td>
      <td></td>
      <td></td>
    </tr>
    <tr>
      <td>Natural Language Understanding</td>
      <td></td>
      <td>1</td>
      <td>1</td>
      <td></td>
    </tr>
    <tr>
      <td>Neural Machine Translation</td>
      <td></td>
      <td>4</td>
      <td></td>
      <td>1</td>
    </tr>
    <tr>
      <td>Node Classification</td>
      <td></td>
      <td></td>
      <td></td>
      <td>2</td>
    </tr>
    <tr>
      <td>Object Detection</td>
      <td></td>
      <td></td>
      <td>3</td>
      <td></td>
    </tr>
    <tr>
      <td>Offline Reinforcement Learning</td>
      <td></td>
      <td></td>
      <td></td>
      <td>1</td>
    </tr>
    <tr>
      <td>Open-Domain Dialogue</td>
      <td></td>
      <td>1</td>
      <td></td>
      <td></td>
    </tr>
    <tr>
      <td>Out-of-distribution</td>
      <td></td>
      <td>1</td>
      <td>4</td>
      <td></td>
    </tr>
    <tr>
      <td>PaLM</td>
      <td></td>
      <td>1</td>
      <td></td>
      <td></td>
    </tr>
    <tr>
      <td>Planning Domain Descrition Language</td>
      <td></td>
      <td>1</td>
      <td></td>
      <td></td>
    </tr>
    <tr>
      <td>Probabilistic Model</td>
      <td></td>
      <td></td>
      <td></td>
      <td>1</td>
    </tr>
    <tr>
      <td>Probabilistic Reasoning</td>
      <td>1</td>
      <td></td>
      <td></td>
      <td></td>
    </tr>
    <tr>
      <td>Prompt</td>
      <td>2</td>
      <td>4</td>
      <td>3</td>
      <td>4</td>
    </tr>
    <tr>
      <td>Prompt Learning</td>
      <td>1</td>
      <td></td>
      <td></td>
      <td></td>
    </tr>
    <tr>
      <td>Quantization</td>
      <td></td>
      <td>2</td>
      <td></td>
      <td>2</td>
    </tr>
    <tr>
      <td>Question Answering</td>
      <td></td>
      <td>7</td>
      <td></td>
      <td></td>
    </tr>
    <tr>
      <td>Reasoning</td>
      <td>6</td>
      <td>4</td>
      <td>3</td>
      <td>2</td>
    </tr>
    <tr>
      <td>Recommendation</td>
      <td></td>
      <td></td>
      <td></td>
      <td>1</td>
    </tr>
    <tr>
      <td>Recurrent Neural Network</td>
      <td></td>
      <td></td>
      <td></td>
      <td>1</td>
    </tr>
    <tr>
      <td>Reinforcement Learning</td>
      <td>2</td>
      <td></td>
      <td></td>
      <td>7</td>
    </tr>
    <tr>
      <td>Reinforcement Learning from Human Feedback</td>
      <td></td>
      <td></td>
      <td></td>
      <td>2</td>
    </tr>
    <tr>
      <td>Retrieval Augmentation</td>
      <td></td>
      <td>1</td>
      <td></td>
      <td></td>
    </tr>
    <tr>
      <td>Retrieval-Augmented Generation</td>
      <td>2</td>
      <td></td>
      <td></td>
      <td></td>
    </tr>
    <tr>
      <td>Sample Size</td>
      <td></td>
      <td></td>
      <td></td>
      <td>2</td>
    </tr>
    <tr>
      <td>Scaling Law</td>
      <td></td>
      <td>1</td>
      <td></td>
      <td></td>
    </tr>
    <tr>
      <td>Self-supervised Learning</td>
      <td></td>
      <td></td>
      <td>6</td>
      <td>5</td>
    </tr>
    <tr>
      <td>Self-supervised Pre-training</td>
      <td></td>
      <td></td>
      <td>1</td>
      <td></td>
    </tr>
    <tr>
      <td>Semantic Parsing</td>
      <td></td>
      <td>1</td>
      <td></td>
      <td></td>
    </tr>
    <tr>
      <td>Sentiment Analysis</td>
      <td></td>
      <td>1</td>
      <td></td>
      <td></td>
    </tr>
    <tr>
      <td>Simulation</td>
      <td></td>
      <td>1</td>
      <td></td>
      <td>5</td>
    </tr>
    <tr>
      <td>Simulator</td>
      <td></td>
      <td>1</td>
      <td></td>
      <td>5</td>
    </tr>
    <tr>
      <td>Stance Detection</td>
      <td></td>
      <td>1</td>
      <td></td>
      <td></td>
    </tr>
    <tr>
      <td>Stemming</td>
      <td></td>
      <td></td>
      <td></td>
      <td>1</td>
    </tr>
    <tr>
      <td>Stochastic Gradient Descent</td>
      <td></td>
      <td></td>
      <td></td>
      <td>4</td>
    </tr>
    <tr>
      <td>Summarization</td>
      <td></td>
      <td>2</td>
      <td></td>
      <td></td>
    </tr>
    <tr>
      <td>Supervised Learning</td>
      <td></td>
      <td>2</td>
      <td>3</td>
      <td>1</td>
    </tr>
    <tr>
      <td>Text Augmentation</td>
      <td></td>
      <td>1</td>
      <td></td>
      <td></td>
    </tr>
    <tr>
      <td>Text Generation</td>
      <td>1</td>
      <td>2</td>
      <td></td>
      <td></td>
    </tr>
    <tr>
      <td>Text Summarization</td>
      <td></td>
      <td>1</td>
      <td></td>
      <td></td>
    </tr>
    <tr>
      <td>Text2image</td>
      <td>1</td>
      <td></td>
      <td>2</td>
      <td></td>
    </tr>
    <tr>
      <td>Transfer Learning</td>
      <td></td>
      <td></td>
      <td>3</td>
      <td></td>
    </tr>
    <tr>
      <td>Transformer</td>
      <td></td>
      <td>1</td>
      <td>3</td>
      <td>7</td>
    </tr>
    <tr>
      <td>Unsupervised Learning</td>
      <td>1</td>
      <td></td>
      <td>4</td>
      <td>1</td>
    </tr>
    <tr>
      <td>Vision Transformer</td>
      <td></td>
      <td></td>
      <td>1</td>
      <td></td>
    </tr>
    <tr>
      <td>Vision-and-Language</td>
      <td></td>
      <td></td>
      <td>5</td>
      <td></td>
    </tr>
    <tr>
      <td>Weakly Supervised Learning</td>
      <td></td>
      <td></td>
      <td>1</td>
      <td></td>
    </tr>
    <tr>
      <td>Word Embedding</td>
      <td></td>
      <td>1</td>
      <td></td>
      <td></td>
    </tr>
    <tr>
      <td>Zero-shot</td>
      <td></td>
      <td>2</td>
      <td>2</td>
      <td>2</td>
    </tr>
    <tr>
      <td>human-in-the-loop</td>
      <td></td>
      <td></td>
      <td>1</td>
      <td></td>
    </tr>
  </tbody>
</table>

<script>
$(function() {
  $("table").addClass("keyword-table table-bordered border-success");
  $("table thead").addClass("sticky-top");
  $("table tbody td").css("text-align", "");
});
</script>


## cs.CL (27)



### (0/27 | 1/197) EntGPT: Linking Generative Large Language Models with Knowledge Bases (Yifan Ding et al., 2024)

{{<citation>}}

Yifan Ding, Amrit Poudel, Qingkai Zeng, Tim Weninger, Balaji Veeramani, Sanmitra Bhattacharya. (2024)  
**EntGPT: Linking Generative Large Language Models with Knowledge Bases**
<br/>
<button class="copy-to-clipboard" title="EntGPT: Linking Generative Large Language Models with Knowledge Bases" index=1>
  <span class="copy-to-clipboard-item">Copy Title<span>
</button>
<div class="toast toast-copied toast-index-1 align-items-center text-bg-secondary border-0 position-absolute top-0 end-0" role="alert" aria-live="assertive" aria-atomic="true">
  <div class="d-flex">
    <div class="toast-body">
      Copied!
    </div>
  </div>
</div>

---
Primary Category: cs.CL  
Categories: cs-CL, cs.CL  
Keyword Score: 120  
Keywords: Fine-tuning, Supervised Learning, Zero-shot, Disambiguation, Fact Verification, Grounding, Question Answering, Question Answering, Instruction Tuning, Large Language Model, Large Language Model, Prompt  
<a type="button" class="btn btn-outline-primary" href="http://arxiv.org/abs/2402.06738v1" target="_blank" >Paper Link</a>
<button type="button" class="btn btn-outline-primary download-pdf" url="https://arxiv.org/pdf/2402.06738v1.pdf" filename="2402.06738v1.pdf">Download PDF</button>

---


**ABSTRACT**  
The ability of <b>Large</b> <b>Language</b> <b>Models</b> <b>(LLMs)</b> to generate factually correct output remains relatively unexplored due to the lack of <b>fact-checking</b> <b>and</b> knowledge <b>grounding</b> during training and inference. In this work, we aim to address this challenge through the Entity <b>Disambiguation</b> (ED) task. We first consider <b>prompt</b> engineering, and design a three-step hard-prompting method to probe <b>LLMs'</b> ED performance without <b>supervised</b> <b>fine-tuning</b> (SFT). Overall, the <b>prompting</b> method improves the micro-F_1 score of the original vanilla models by a <b>large</b> <b>margin,</b> <b>on</b> some cases up to 36% and higher, and obtains comparable performance across 10 datasets when compared to existing methods with SFT. We further improve the knowledge <b>grounding</b> ability through <b>instruction</b> <b>tuning</b> (IT) with similar <b>prompts</b> and responses. The <b>instruction-tuned</b> <b>model</b> not only achieves higher micro-F1 score performance as compared to several baseline methods on <b>supervised</b> entity <b>disambiguation</b> tasks with an average micro-F_1 improvement of 2.1% over the existing baseline models, but also obtains higher accuracy on six <b>Question</b> <b>Answering</b> <b>(QA)</b> tasks in the <b>zero-shot</b> setting. Our methodologies apply to both open- and closed-source <b>LLMs.</b>

{{</citation>}}


### (1/27 | 2/197) Bryndza at ClimateActivism 2024: Stance, Target and Hate Event Detection via Retrieval-Augmented GPT-4 and LLaMA (Marek Šuppa et al., 2024)

{{<citation>}}

Marek Šuppa, Daniel Skala, Daniela Jašš, Samuel Sučík, Andrej Švec, Peter Hraška. (2024)  
**Bryndza at ClimateActivism 2024: Stance, Target and Hate Event Detection via Retrieval-Augmented GPT-4 and LLaMA**
<br/>
<button class="copy-to-clipboard" title="Bryndza at ClimateActivism 2024: Stance, Target and Hate Event Detection via Retrieval-Augmented GPT-4 and LLaMA" index=2>
  <span class="copy-to-clipboard-item">Copy Title<span>
</button>
<div class="toast toast-copied toast-index-2 align-items-center text-bg-secondary border-0 position-absolute top-0 end-0" role="alert" aria-live="assertive" aria-atomic="true">
  <div class="d-flex">
    <div class="toast-body">
      Copied!
    </div>
  </div>
</div>

---
Primary Category: cs.CL  
Categories: cs-AI, cs-CL, cs.CL  
Keyword Score: 100  
Keywords: Few-shot, GPT, GPT-4, LLaMA, Event Detection, Hate Speech Detection, Stance Detection, Large Language Model, Large Language Model, Retrieval Augmentation  
<a type="button" class="btn btn-outline-primary" href="http://arxiv.org/abs/2402.06549v1" target="_blank" >Paper Link</a>
<button type="button" class="btn btn-outline-primary download-pdf" url="https://arxiv.org/pdf/2402.06549v1.pdf" filename="2402.06549v1.pdf">Download PDF</button>

---


**ABSTRACT**  
This study details our approach for the CASE 2024 Shared Task on Climate Activism <b>Stance</b> <b>and</b> <b>Hate</b> <b>Event</b> <b>Detection,</b> focusing on <b>Hate</b> <b>Speech</b> <b>Detection,</b> <b>Hate</b> <b>Speech</b> <b>Target</b> Identification, and <b>Stance</b> <b>Detection</b> as classification challenges. We explored the capability of <b>Large</b> <b>Language</b> <b>Models</b> <b>(LLMs),</b> particularly <b>GPT-4,</b> in zero- or <b>few-shot</b> settings enhanced by <b>retrieval</b> <b>augmentation</b> and re-ranking for Tweet classification. Our goal was to determine if <b>LLMs</b> could match or surpass traditional methods in this context. We conducted an ablation study with <b>LLaMA</b> for comparison, and our results indicate that our models significantly outperformed the baselines, securing second place in the Target Detection task. The code for our submission is available at https://github.com/NaiveNeuron/bryndza-case-2024

{{</citation>}}


### (2/27 | 3/197) FaBERT: Pre-training BERT on Persian Blogs (Mostafa Masumi et al., 2024)

{{<citation>}}

Mostafa Masumi, Seyed Soroush Majd, Mehrnoush Shamsfard, Hamid Beigy. (2024)  
**FaBERT: Pre-training BERT on Persian Blogs**
<br/>
<button class="copy-to-clipboard" title="FaBERT: Pre-training BERT on Persian Blogs" index=3>
  <span class="copy-to-clipboard-item">Copy Title<span>
</button>
<div class="toast toast-copied toast-index-3 align-items-center text-bg-secondary border-0 position-absolute top-0 end-0" role="alert" aria-live="assertive" aria-atomic="true">
  <div class="d-flex">
    <div class="toast-body">
      Copied!
    </div>
  </div>
</div>

---
Primary Category: cs.CL  
Categories: cs-CL, cs.CL  
Keyword Score: 90  
Keywords: BERT, Named Entity Recognition, Named Entity Recognition, Natural Language Inference, Natural Language Inference, Natural Language Understanding, Question Answering, Question Answering, Sentiment Analysis  
<a type="button" class="btn btn-outline-primary" href="http://arxiv.org/abs/2402.06617v1" target="_blank" >Paper Link</a>
<button type="button" class="btn btn-outline-primary download-pdf" url="https://arxiv.org/pdf/2402.06617v1.pdf" filename="2402.06617v1.pdf">Download PDF</button>

---


**ABSTRACT**  
We introduce FaBERT, a Persian <b>BERT-base</b> model pre-trained on the HmBlogs corpus, encompassing both informal and formal Persian texts. FaBERT is designed to excel in traditional <b>Natural</b> <b>Language</b> <b>Understanding</b> (NLU) tasks, addressing the intricacies of diverse sentence structures and linguistic styles prevalent in the Persian language. In our comprehensive evaluation of FaBERT on 12 datasets in various downstream tasks, encompassing <b>Sentiment</b> <b>Analysis</b> (SA), <b>Named</b> <b>Entity</b> <b>Recognition</b> <b>(NER),</b> <b>Natural</b> <b>Language</b> <b>Inference</b> <b>(NLI),</b> <b>Question</b> <b>Answering</b> <b>(QA),</b> and <b>Question</b> <b>Paraphrasing</b> (QP), it consistently demonstrated improved performance, all achieved within a compact model size. The findings highlight the importance of utilizing diverse and cleaned corpora, such as HmBlogs, to enhance the performance of language models like <b>BERT</b> in Persian <b>Natural</b> <b>Language</b> <b>Processing</b> (NLP) applications. FaBERT is openly accessible at https://huggingface.co/sbunlp/fabert

{{</citation>}}


### (3/27 | 4/197) InternLM-Math: Open Math Large Language Models Toward Verifiable Reasoning (Huaiyuan Ying et al., 2024)

{{<citation>}}

Huaiyuan Ying, Shuo Zhang, Linyang Li, Zhejian Zhou, Yunfan Shao, Zhaoye Fei, Yichuan Ma, Jiawei Hong, Kuikun Liu, Ziyi Wang, Yudong Wang, Zijian Wu, Shuaibin Li, Fengzhe Zhou, Hongwei Liu, Songyang Zhang, Wenwei Zhang, Hang Yan, Xipeng Qiu, Jiayu Wang, Kai Chen, Dahua Lin. (2024)  
**InternLM-Math: Open Math Large Language Models Toward Verifiable Reasoning**
<br/>
<button class="copy-to-clipboard" title="InternLM-Math: Open Math Large Language Models Toward Verifiable Reasoning" index=4>
  <span class="copy-to-clipboard-item">Copy Title<span>
</button>
<div class="toast toast-copied toast-index-4 align-items-center text-bg-secondary border-0 position-absolute top-0 end-0" role="alert" aria-live="assertive" aria-atomic="true">
  <div class="d-flex">
    <div class="toast-body">
      Copied!
    </div>
  </div>
</div>

---
Primary Category: cs.CL  
Categories: cs-CL, cs.CL  
Keyword Score: 83  
Keywords: Benchmarking, Data Augmentation, Fine-tuning, Supervised Learning, Reasoning, In-context Learning, In-context Learning, Large Language Model, Large Language Model  
<a type="button" class="btn btn-outline-primary" href="http://arxiv.org/abs/2402.06332v1" target="_blank" >Paper Link</a>
<button type="button" class="btn btn-outline-primary download-pdf" url="https://arxiv.org/pdf/2402.06332v1.pdf" filename="2402.06332v1.pdf">Download PDF</button>

---


**ABSTRACT**  
The math abilities of <b>large</b> <b>language</b> <b>models</b> can represent their abstract <b>reasoning</b> ability. In this paper, we introduce and open-source our math <b>reasoning</b> <b>LLMs</b> InternLM-Math which is continue pre-trained from InternLM2. We unify chain-of-thought <b>reasoning,</b> reward modeling, formal <b>reasoning,</b> <b>data</b> <b>augmentation,</b> and code interpreter in a unified seq2seq format and supervise our model to be a versatile math reasoner, verifier, prover, and augmenter. These abilities can be used to develop the next math <b>LLMs</b> or self-iteration. InternLM-Math obtains open-sourced state-of-the-art performance under the setting of <b>in-context</b> <b>learning,</b> <b>supervised</b> <b>fine-tuning,</b> and code-assisted <b>reasoning</b> in various informal and formal <b>benchmarks</b> including GSM8K, MATH, Hungary math exam, MathBench-ZH, and MiniF2F. Our pre-trained model achieves 30.3 on the MiniF2F test set without <b>fine-tuning.</b> We further explore how to use LEAN to solve math problems and study its performance under the setting of multi-task learning which shows the possibility of using LEAN as a unified platform for solving and proving in math. Our models, codes, and <b>data</b> <b>are</b> released at \url{https://github.com/InternLM/InternLM-Math}.

{{</citation>}}


### (4/27 | 5/197) Large Language Models: A Survey (Shervin Minaee et al., 2024)

{{<citation>}}

Shervin Minaee, Tomas Mikolov, Narjes Nikzad, Meysam Chenaghlu, Richard Socher, Xavier Amatriain, Jianfeng Gao. (2024)  
**Large Language Models: A Survey**
<br/>
<button class="copy-to-clipboard" title="Large Language Models: A Survey" index=5>
  <span class="copy-to-clipboard-item">Copy Title<span>
</button>
<div class="toast toast-copied toast-index-5 align-items-center text-bg-secondary border-0 position-absolute top-0 end-0" role="alert" aria-live="assertive" aria-atomic="true">
  <div class="d-flex">
    <div class="toast-body">
      Copied!
    </div>
  </div>
</div>

---
Primary Category: cs.CL  
Categories: cs-AI, cs-CL, cs.CL  
Keyword Score: 83  
Keywords: Benchmarking, Fine-tuning, ChatGPT, GPT, LLaMA, PaLM, Large Language Model, Large Language Model, Scaling Law  
<a type="button" class="btn btn-outline-primary" href="http://arxiv.org/abs/2402.06196v1" target="_blank" >Paper Link</a>
<button type="button" class="btn btn-outline-primary download-pdf" url="https://arxiv.org/pdf/2402.06196v1.pdf" filename="2402.06196v1.pdf">Download PDF</button>

---


**ABSTRACT**  
<b>Large</b> <b>Language</b> <b>Models</b> <b>(LLMs)</b> have drawn a lot of attention due to their strong performance on a wide range of natural language tasks, since the release of <b>ChatGPT</b> in November 2022. <b>LLMs'</b> ability of general-purpose language understanding and generation is acquired by training billions of model's parameters on massive amounts of text data, as predicted by <b>scaling</b> <b>laws</b> \cite{kaplan2020scaling,hoffmann2022training}. The research area of <b>LLMs,</b> while very recent, is evolving rapidly in many different ways. In this paper, we review some of the most prominent <b>LLMs,</b> including three popular <b>LLM</b> families <b>(GPT,</b> <b>LLaMA,</b> <b>PaLM),</b> and discuss their characteristics, contributions and limitations. We also give an overview of techniques developed to build, and augment <b>LLMs.</b> We then survey popular datasets prepared for <b>LLM</b> training, <b>fine-tuning,</b> and evaluation, review widely used <b>LLM</b> evaluation metrics, and compare the performance of several popular <b>LLMs</b> on a set of representative <b>benchmarks.</b> Finally, we conclude the paper by discussing open challenges and future research directions.

{{</citation>}}


### (5/27 | 6/197) RareBench: Can LLMs Serve as Rare Diseases Specialists? (Xuanzhong Chen et al., 2024)

{{<citation>}}

Xuanzhong Chen, Xiaohao Mao, Qihan Guo, Lun Wang, Shuyang Zhang, Ting Chen. (2024)  
**RareBench: Can LLMs Serve as Rare Diseases Specialists?**
<br/>
<button class="copy-to-clipboard" title="RareBench: Can LLMs Serve as Rare Diseases Specialists?" index=6>
  <span class="copy-to-clipboard-item">Copy Title<span>
</button>
<div class="toast toast-copied toast-index-6 align-items-center text-bg-secondary border-0 position-absolute top-0 end-0" role="alert" aria-live="assertive" aria-atomic="true">
  <div class="d-flex">
    <div class="toast-body">
      Copied!
    </div>
  </div>
</div>

---
Primary Category: cs.CL  
Categories: cs-CL, cs.CL  
Keyword Score: 78  
Keywords: Benchmarking, Few-shot, Knowledge Graph, ChatGPT, GPT, GPT-4, Large Language Model, Large Language Model, Prompt  
<a type="button" class="btn btn-outline-primary" href="http://arxiv.org/abs/2402.06341v1" target="_blank" >Paper Link</a>
<button type="button" class="btn btn-outline-primary download-pdf" url="https://arxiv.org/pdf/2402.06341v1.pdf" filename="2402.06341v1.pdf">Download PDF</button>

---


**ABSTRACT**  
Generalist <b>Large</b> <b>Language</b> <b>Models</b> <b>(LLMs),</b> such as <b>GPT-4,</b> have shown considerable promise in various domains, including medical diagnosis. Rare diseases, affecting approximately 300 million people worldwide, often have unsatisfactory clinical diagnosis rates primarily due to a lack of experienced physicians and the complexity of differentiating among many rare diseases. In this context, recent news such as <b>"ChatGPT</b> correctly diagnosed a 4-year-old's rare disease after 17 doctors failed" underscore <b>LLMs'</b> potential, yet underexplored, role in clinically diagnosing rare diseases. To bridge this research gap, we introduce RareBench, a pioneering <b>benchmark</b> designed to systematically evaluate the capabilities of <b>LLMs</b> on 4 critical dimensions within the realm of rare diseases. Meanwhile, we have compiled the largest open-source dataset on rare disease patients, establishing a <b>benchmark</b> for future studies in this domain. To facilitate differential diagnosis of rare diseases, we develop a dynamic <b>few-shot</b> <b>prompt</b> methodology, leveraging a comprehensive rare disease <b>knowledge</b> <b>graph</b> synthesized from multiple <b>knowledge</b> <b>bases,</b> significantly enhancing <b>LLMs'</b> diagnostic performance. Moreover, we present an exhaustive comparative study of <b>GPT-4's</b> diagnostic capabilities against those of specialist physicians. Our experimental findings underscore the promising potential of integrating <b>LLMs</b> into the clinical diagnostic process for rare diseases. This paves the way for exciting possibilities in future advancements in this field.

{{</citation>}}


### (6/27 | 7/197) ResumeFlow: An LLM-facilitated Pipeline for Personalized Resume Generation and Refinement (Saurabh Bhausaheb Zinjad et al., 2024)

{{<citation>}}

Saurabh Bhausaheb Zinjad, Amrita Bhattacharjee, Amey Bhilegaonkar, Huan Liu. (2024)  
**ResumeFlow: An LLM-facilitated Pipeline for Personalized Resume Generation and Refinement**
<br/>
<button class="copy-to-clipboard" title="ResumeFlow: An LLM-facilitated Pipeline for Personalized Resume Generation and Refinement" index=7>
  <span class="copy-to-clipboard-item">Copy Title<span>
</button>
<div class="toast toast-copied toast-index-7 align-items-center text-bg-secondary border-0 position-absolute top-0 end-0" role="alert" aria-live="assertive" aria-atomic="true">
  <div class="d-flex">
    <div class="toast-body">
      Copied!
    </div>
  </div>
</div>

---
Primary Category: cs.CL  
Categories: cs-CL, cs-IR, cs.CL  
Keyword Score: 70  
Keywords: Fine-tuning, GPT, GPT-4, Gemini, Information Retrieval, Large Language Model, Large Language Model  
<a type="button" class="btn btn-outline-primary" href="http://arxiv.org/abs/2402.06221v1" target="_blank" >Paper Link</a>
<button type="button" class="btn btn-outline-primary download-pdf" url="https://arxiv.org/pdf/2402.06221v1.pdf" filename="2402.06221v1.pdf">Download PDF</button>

---


**ABSTRACT**  
Crafting the ideal, job-specific resume is a challenging task for many job applicants, especially for early-career applicants. While it is highly recommended that applicants tailor their resume to the specific role they are applying for, manually tailoring resumes to job descriptions and role-specific requirements is often (1) extremely time-consuming, and (2) prone to human errors. Furthermore, performing such a tailoring step at scale while applying to several roles may result in a lack of quality of the edited resumes. To tackle this problem, in this demo paper, we propose ResumeFlow: a <b>Large</b> <b>Language</b> <b>Model</b> <b>(LLM)</b> aided tool that enables an end user to simply provide their detailed resume and the desired job posting, and obtain a personalized resume specifically tailored to that specific job posting in the matter of a few seconds. Our proposed pipeline leverages the language understanding and <b>information</b> <b>extraction</b> capabilities of state-of-the-art <b>LLMs</b> such as OpenAI's <b>GPT-4</b> and Google's <b>Gemini,</b> in order to (1) extract details from a job description, (2) extract role-specific details from the user-provided resume, and then (3) use these to refine and generate a role-specific resume for the user. Our easy-to-use tool leverages the user-chosen <b>LLM</b> in a completely off-the-shelf manner, thus requiring no <b>fine-tuning.</b> We demonstrate the effectiveness of our tool via a video demo and propose novel task-specific evaluation metrics to control for alignment and hallucination. Our tool is available at https://job-aligned-resume.streamlit.app.

{{</citation>}}


### (7/27 | 8/197) Calibrating Long-form Generations from Large Language Models (Yukun Huang et al., 2024)

{{<citation>}}

Yukun Huang, Yixin Liu, Raghuveer Thirukovalluru, Arman Cohan, Bhuwan Dhingra. (2024)  
**Calibrating Long-form Generations from Large Language Models**
<br/>
<button class="copy-to-clipboard" title="Calibrating Long-form Generations from Large Language Models" index=8>
  <span class="copy-to-clipboard-item">Copy Title<span>
</button>
<div class="toast toast-copied toast-index-8 align-items-center text-bg-secondary border-0 position-absolute top-0 end-0" role="alert" aria-live="assertive" aria-atomic="true">
  <div class="d-flex">
    <div class="toast-body">
      Copied!
    </div>
  </div>
</div>

---
Primary Category: cs.CL  
Categories: cs-AI, cs-CL, cs-LG, cs.CL  
Keyword Score: 60  
Keywords: Fine-tuning, ChatGPT, Question Answering, Large Language Model, Large Language Model, Summarization  
<a type="button" class="btn btn-outline-primary" href="http://arxiv.org/abs/2402.06544v1" target="_blank" >Paper Link</a>
<button type="button" class="btn btn-outline-primary download-pdf" url="https://arxiv.org/pdf/2402.06544v1.pdf" filename="2402.06544v1.pdf">Download PDF</button>

---


**ABSTRACT**  
To enhance <b>Large</b> <b>Language</b> <b>Models'</b> <b>(LLMs)</b> reliability, calibration is essential -- the model's assessed confidence scores should align with the actual likelihood of its responses being correct. However, current confidence elicitation methods and calibration metrics typically rely on a binary true/false assessment of response correctness. This approach does not apply to long-form generation, where an answer can be partially correct. Addressing this gap, we introduce a unified calibration framework, in which both the correctness of the <b>LLMs'</b> responses and their associated confidence levels are treated as distributions across a range of scores. Within this framework, we develop three metrics to precisely evaluate <b>LLM</b> calibration and further propose two confidence elicitation methods based on self-consistency and self-evaluation. Our experiments, which include long-form <b>QA</b> and <b>summarization</b> tasks, demonstrate that larger models don't necessarily guarantee better calibration, that calibration performance is found to be metric-dependent, and that self-consistency methods excel in factoid datasets. We also find that calibration can be enhanced through techniques such as <b>fine-tuning,</b> integrating relevant source documents, scaling the temperature, and combining self-consistency with self-evaluation. Lastly, we showcase a practical application of our system: selecting and cascading open-source models and <b>ChatGPT</b> to optimize correctness given a limited API budget. This research not only challenges existing notions of <b>LLM</b> calibration but also offers practical methodologies for improving trustworthiness in long-form generation.

{{</citation>}}


### (8/27 | 9/197) Inducing Systematicity in Transformers by Attending to Structurally Quantized Embeddings (Yichen Jiang et al., 2024)

{{<citation>}}

Yichen Jiang, Xiang Zhou, Mohit Bansal. (2024)  
**Inducing Systematicity in Transformers by Attending to Structurally Quantized Embeddings**
<br/>
<button class="copy-to-clipboard" title="Inducing Systematicity in Transformers by Attending to Structurally Quantized Embeddings" index=9>
  <span class="copy-to-clipboard-item">Copy Title<span>
</button>
<div class="toast toast-copied toast-index-9 align-items-center text-bg-secondary border-0 position-absolute top-0 end-0" role="alert" aria-live="assertive" aria-atomic="true">
  <div class="d-flex">
    <div class="toast-body">
      Copied!
    </div>
  </div>
</div>

---
Primary Category: cs.CL  
Categories: cs-AI, cs-CL, cs-LG, cs.CL  
Keyword Score: 60  
Keywords: Quantization, Quantization, Transformer, Neural Machine Translation, Semantic Parsing, Word Embedding  
<a type="button" class="btn btn-outline-primary" href="http://arxiv.org/abs/2402.06492v1" target="_blank" >Paper Link</a>
<button type="button" class="btn btn-outline-primary download-pdf" url="https://arxiv.org/pdf/2402.06492v1.pdf" filename="2402.06492v1.pdf">Download PDF</button>

---


**ABSTRACT**  
<b>Transformers</b> generalize to novel compositions of structures and entities after being trained on a complex dataset, but easily overfit on datasets of insufficient complexity. We observe that when the training set is sufficiently complex, the model encodes sentences that have a common syntactic structure using a systematic attention pattern. Inspired by this observation, we propose SQ-Transformer (Structurally <b>Quantized)</b> that explicitly encourages systematicity in the embeddings and attention layers, even with a training set of low complexity. At the embedding level, we introduce Structure-oriented Vector <b>Quantization</b> (SoVQ) to cluster <b>word</b> <b>embeddings</b> into several classes of structurally equivalent entities. At the attention level, we devise the Systematic Attention Layer (SAL) and an alternative, Systematically Regularized Layer (SRL) that operate on the <b>quantized</b> <b>word</b> <b>embeddings</b> so that sentences of the same structure are encoded with invariant or similar attention patterns. Empirically, we show that SQ-Transformer achieves stronger compositional generalization than the vanilla <b>Transformer</b> on multiple low-complexity <b>semantic</b> <b>parsing</b> and <b>machine</b> <b>translation</b> datasets. In our analysis, we show that SoVQ indeed learns a syntactically clustered embedding space and SAL/SRL induces generalizable attention patterns, which lead to improved systematicity.

{{</citation>}}


### (9/27 | 10/197) NICE: To Optimize In-Context Examples or Not? (Pragya Srivastava et al., 2024)

{{<citation>}}

Pragya Srivastava, Satvik Golechha, Amit Deshpande, Amit Sharma. (2024)  
**NICE: To Optimize In-Context Examples or Not?**
<br/>
<button class="copy-to-clipboard" title="NICE: To Optimize In-Context Examples or Not?" index=10>
  <span class="copy-to-clipboard-item">Copy Title<span>
</button>
<div class="toast toast-copied toast-index-10 align-items-center text-bg-secondary border-0 position-absolute top-0 end-0" role="alert" aria-live="assertive" aria-atomic="true">
  <div class="d-flex">
    <div class="toast-body">
      Copied!
    </div>
  </div>
</div>

---
Primary Category: cs.CL  
Categories: cs-AI, cs-CL, cs-LG, cs.CL  
Keyword Score: 50  
Keywords: In-context Learning, In-context Learning, Large Language Model, Large Language Model, Prompt  
<a type="button" class="btn btn-outline-primary" href="http://arxiv.org/abs/2402.06733v1" target="_blank" >Paper Link</a>
<button type="button" class="btn btn-outline-primary download-pdf" url="https://arxiv.org/pdf/2402.06733v1.pdf" filename="2402.06733v1.pdf">Download PDF</button>

---


**ABSTRACT**  
Recent works have shown that <b>large</b> <b>language</b> <b>models</b> <b>(LLMs)</b> work remarkably well on a wide range of tasks through <b>in-context</b> <b>learning</b> and optimization of <b>in-context</b> <b>examples</b> (ICE). However, most of these studies assume either a fixed or no instruction provided in the <b>prompt,</b> leading to the apparent consensus that the optimization of <b>in-context</b> <b>examples</b> is critical for better performance. We challenge this consensus for instruction-tuned <b>LLMs</b> by investigating the necessity of optimizing <b>in-context</b> <b>examples</b> when task-specific instructions are provided, and find that there are tasks for which various ways of optimizing <b>in-context</b> <b>examples</b> yield diminishing returns. We introduce a task-specific metric called \metriclong{} (\metric) that quantifies the learnability of tasks from a given instruction, and provides a heuristic that helps decide whether to optimize for instructions or ICE for any new task. On a wide range of tasks and a systematically created instruction set with gradually added details, we validate our hypothesis empirically by computing \metric with query-dependent bins of examples, comparing different instructions with ICE selection methods, and performing label perturbation experiments. We conclude that tasks can be divided into two broad classes based on the \metric metric, where the returns on ICE optimization follow predictable trends when instructions are provided in the <b>prompt.</b>

{{</citation>}}


### (10/27 | 11/197) Aya Dataset: An Open-Access Collection for Multilingual Instruction Tuning (Shivalika Singh et al., 2024)

{{<citation>}}

Shivalika Singh, Freddie Vargus, Daniel Dsouza, Börje F. Karlsson, Abinaya Mahendiran, Wei-Yin Ko, Herumb Shandilya, Jay Patel, Deividas Mataciunas, Laura OMahony, Mike Zhang, Ramith Hettiarachchi, Joseph Wilson, Marina Machado, Luisa Souza Moura, Dominik Krzemiński, Hakimeh Fadaei, Irem Ergün, Ifeoma Okoh, Aisha Alaagib, Oshan Mudannayake, Zaid Alyafeai, Vu Minh Chien, Sebastian Ruder, Surya Guthikonda, Emad A. Alghamdi, Sebastian Gehrmann, Niklas Muennighoff, Max Bartolo, Julia Kreutzer, Ahmet Üstün, Marzieh Fadaee, Sara Hooker. (2024)  
**Aya Dataset: An Open-Access Collection for Multilingual Instruction Tuning**
<br/>
<button class="copy-to-clipboard" title="Aya Dataset: An Open-Access Collection for Multilingual Instruction Tuning" index=11>
  <span class="copy-to-clipboard-item">Copy Title<span>
</button>
<div class="toast toast-copied toast-index-11 align-items-center text-bg-secondary border-0 position-absolute top-0 end-0" role="alert" aria-live="assertive" aria-atomic="true">
  <div class="d-flex">
    <div class="toast-body">
      Copied!
    </div>
  </div>
</div>

---
Primary Category: cs.CL  
Categories: cs-AI, cs-CL, cs.CL  
Keyword Score: 50  
Keywords: Fine-tuning, Instruction Following, Instruction Tuning, Large Language Model, Large Language Model  
<a type="button" class="btn btn-outline-primary" href="http://arxiv.org/abs/2402.06619v1" target="_blank" >Paper Link</a>
<button type="button" class="btn btn-outline-primary download-pdf" url="https://arxiv.org/pdf/2402.06619v1.pdf" filename="2402.06619v1.pdf">Download PDF</button>

---


**ABSTRACT**  
Datasets are foundational to many breakthroughs in modern artificial intelligence. Many recent achievements in the space of natural language processing (NLP) can be attributed to the <b>finetuning</b> of pre-trained models on a diverse set of tasks that enables a <b>large</b> <b>language</b> <b>model</b> <b>(LLM)</b> to respond to <b>instructions.</b> <b>Instruction</b> <b>fine-tuning</b> (IFT) requires specifically constructed and annotated datasets. However, existing datasets are almost all in the English language. In this work, our primary goal is to bridge the language gap by building a human-curated <b>instruction-following</b> <b>dataset</b> spanning 65 languages. We worked with fluent speakers of languages from around the world to collect natural instances of <b>instructions</b> <b>and</b> completions. Furthermore, we create the most extensive multilingual collection to date, comprising 513 million instances through templating and translating existing datasets across 114 languages. In total, we contribute four key resources: we develop and open-source the Aya Annotation Platform, the Aya Dataset, the Aya Collection, and the Aya Evaluation Suite. The Aya initiative also serves as a valuable case study in participatory research, involving collaborators from 119 countries. We see this as a valuable framework for future research collaborations that aim to bridge gaps in resources.

{{</citation>}}


### (11/27 | 12/197) The Generative AI Paradox on Evaluation: What It Can Solve, It May Not Evaluate (Juhyun Oh et al., 2024)

{{<citation>}}

Juhyun Oh, Eunsu Kim, Inha Cha, Alice Oh. (2024)  
**The Generative AI Paradox on Evaluation: What It Can Solve, It May Not Evaluate**
<br/>
<button class="copy-to-clipboard" title="The Generative AI Paradox on Evaluation: What It Can Solve, It May Not Evaluate" index=12>
  <span class="copy-to-clipboard-item">Copy Title<span>
</button>
<div class="toast toast-copied toast-index-12 align-items-center text-bg-secondary border-0 position-absolute top-0 end-0" role="alert" aria-live="assertive" aria-atomic="true">
  <div class="d-flex">
    <div class="toast-body">
      Copied!
    </div>
  </div>
</div>

---
Primary Category: cs.CL  
Categories: cs-AI, cs-CL, cs.CL  
Keyword Score: 50  
Keywords: Generative AI, Question Answering, Question Answering, Large Language Model, Large Language Model  
<a type="button" class="btn btn-outline-primary" href="http://arxiv.org/abs/2402.06204v1" target="_blank" >Paper Link</a>
<button type="button" class="btn btn-outline-primary download-pdf" url="https://arxiv.org/pdf/2402.06204v1.pdf" filename="2402.06204v1.pdf">Download PDF</button>

---


**ABSTRACT**  
This paper explores the assumption that <b>Large</b> <b>Language</b> <b>Models</b> <b>(LLMs)</b> skilled in generation tasks are equally adept as evaluators. We assess the performance of three <b>LLMs</b> and one open-source LM in <b>Question-Answering</b> <b>(QA)</b> and evaluation tasks using the TriviaQA (Joshi et al., 2017) dataset. Results indicate a significant disparity, with <b>LLMs</b> exhibiting lower performance in evaluation tasks compared to generation tasks. Intriguingly, we discover instances of unfaithful evaluation where models accurately evaluate answers in areas where they lack competence, underscoring the need to examine the faithfulness and trustworthiness of <b>LLMs</b> as evaluators. This study contributes to the understanding of "the <b>Generative</b> <b>AI</b> Paradox" (West et al., 2023), highlighting a need to explore the correlation between <b>generative</b> <b>excellence</b> and evaluation proficiency, and the necessity to scrutinize the faithfulness aspect in model evaluations.

{{</citation>}}


### (12/27 | 13/197) Learn To be Efficient: Build Structured Sparsity in Large Language Models (Haizhong Zheng et al., 2024)

{{<citation>}}

Haizhong Zheng, Xiaoyan Bai, Beidi Chen, Fan Lai, Atul Prakash. (2024)  
**Learn To be Efficient: Build Structured Sparsity in Large Language Models**
<br/>
<button class="copy-to-clipboard" title="Learn To be Efficient: Build Structured Sparsity in Large Language Models" index=13>
  <span class="copy-to-clipboard-item">Copy Title<span>
</button>
<div class="toast toast-copied toast-index-13 align-items-center text-bg-secondary border-0 position-absolute top-0 end-0" role="alert" aria-live="assertive" aria-atomic="true">
  <div class="d-flex">
    <div class="toast-body">
      Copied!
    </div>
  </div>
</div>

---
Primary Category: cs.CL  
Categories: cs-AI, cs-CL, cs-LG, cs.CL  
Keyword Score: 50  
Keywords: GPT, LLaMA, Language Generation, Large Language Model, Large Language Model  
<a type="button" class="btn btn-outline-primary" href="http://arxiv.org/abs/2402.06126v2" target="_blank" >Paper Link</a>
<button type="button" class="btn btn-outline-primary download-pdf" url="https://arxiv.org/pdf/2402.06126v2.pdf" filename="2402.06126v2.pdf">Download PDF</button>

---


**ABSTRACT**  
<b>Large</b> <b>Language</b> <b>Models</b> <b>(LLMs)</b> have achieved remarkable success with their billion-level parameters, yet they incur high inference overheads. The emergence of activation sparsity in <b>LLMs</b> provides a natural approach to reduce this cost by involving only parts of the parameters for inference. Existing methods only focus on utilizing this naturally formed activation sparsity, overlooking the potential for further amplifying this inherent sparsity. In this paper, we hypothesize that <b>LLMs</b> can learn to be efficient by achieving more structured activation sparsity. To achieve this, we introduce a novel algorithm, Learn-To-be-Efficient (LTE), designed to train efficiency-aware <b>LLMs</b> to learn to activate fewer neurons and achieve a better trade-off between sparsity and performance. Furthermore, unlike SOTA MoEfication methods, which mainly focus on ReLU-based models, LTE can also be applied to <b>LLMs</b> like <b>GPT</b> and <b>LLaMA</b> with soft activation functions. We evaluate LTE on four models and eleven datasets. The experiments show that LTE achieves a better trade-off between sparsity and task performance. For instance, LTE with <b>LLaMA</b> provides a 1.83x-2.59x FLOPs speed-up on <b>language</b> <b>generation</b> tasks, outperforming the state-of-the-art methods.

{{</citation>}}


### (13/27 | 14/197) Understanding the Effects of Iterative Prompting on Truthfulness (Satyapriya Krishna et al., 2024)

{{<citation>}}

Satyapriya Krishna, Chirag Agarwal, Himabindu Lakkaraju. (2024)  
**Understanding the Effects of Iterative Prompting on Truthfulness**
<br/>
<button class="copy-to-clipboard" title="Understanding the Effects of Iterative Prompting on Truthfulness" index=14>
  <span class="copy-to-clipboard-item">Copy Title<span>
</button>
<div class="toast toast-copied toast-index-14 align-items-center text-bg-secondary border-0 position-absolute top-0 end-0" role="alert" aria-live="assertive" aria-atomic="true">
  <div class="d-flex">
    <div class="toast-body">
      Copied!
    </div>
  </div>
</div>

---
Primary Category: cs.CL  
Categories: cs-CL, cs.CL  
Keyword Score: 40  
Keywords: Text Generation, Large Language Model, Large Language Model, Prompt  
<a type="button" class="btn btn-outline-primary" href="http://arxiv.org/abs/2402.06625v1" target="_blank" >Paper Link</a>
<button type="button" class="btn btn-outline-primary download-pdf" url="https://arxiv.org/pdf/2402.06625v1.pdf" filename="2402.06625v1.pdf">Download PDF</button>

---


**ABSTRACT**  
The development of <b>Large</b> <b>Language</b> <b>Models</b> <b>(LLMs)</b> has notably transformed numerous sectors, offering impressive <b>text</b> <b>generation</b> capabilities. Yet, the reliability and truthfulness of these models remain pressing concerns. To this end, we investigate iterative <b>prompting,</b> a strategy hypothesized to refine <b>LLM</b> responses, assessing its impact on <b>LLM</b> truthfulness, an area which has not been thoroughly explored. Our extensive experiments delve into the intricacies of iterative <b>prompting</b> variants, examining their influence on the accuracy and calibration of model responses. Our findings reveal that naive <b>prompting</b> methods significantly undermine truthfulness, leading to exacerbated calibration errors. In response to these challenges, we introduce several <b>prompting</b> variants designed to address the identified issues. These variants demonstrate marked improvements over existing baselines, signaling a promising direction for future research. Our work provides a nuanced understanding of iterative <b>prompting</b> and introduces novel approaches to enhance the truthfulness of <b>LLMs,</b> thereby contributing to the development of more accurate and trustworthy AI systems.

{{</citation>}}


### (14/27 | 15/197) G-SciEdBERT: A Contextualized LLM for Science Assessment Tasks in German (Ehsan Latif et al., 2024)

{{<citation>}}

Ehsan Latif, Gyeong-Geon Lee, Knut Neuman, Tamara Kastorff, Xiaoming Zhai. (2024)  
**G-SciEdBERT: A Contextualized LLM for Science Assessment Tasks in German**
<br/>
<button class="copy-to-clipboard" title="G-SciEdBERT: A Contextualized LLM for Science Assessment Tasks in German" index=15>
  <span class="copy-to-clipboard-item">Copy Title<span>
</button>
<div class="toast toast-copied toast-index-15 align-items-center text-bg-secondary border-0 position-absolute top-0 end-0" role="alert" aria-live="assertive" aria-atomic="true">
  <div class="d-flex">
    <div class="toast-body">
      Copied!
    </div>
  </div>
</div>

---
Primary Category: cs.CL  
Categories: cs-AI, cs-CL, cs.CL  
Keyword Score: 40  
Keywords: Fine-tuning, BERT, Large Language Model, Large Language Model  
<a type="button" class="btn btn-outline-primary" href="http://arxiv.org/abs/2402.06584v1" target="_blank" >Paper Link</a>
<button type="button" class="btn btn-outline-primary download-pdf" url="https://arxiv.org/pdf/2402.06584v1.pdf" filename="2402.06584v1.pdf">Download PDF</button>

---


**ABSTRACT**  
The advancement of natural language processing has paved the way for automated scoring systems in various languages, such as German (e.g., German <b>BERT</b> [G-BERT]). Automatically scoring written responses to science questions in German is a complex task and challenging for standard G-BERT as they lack contextual knowledge in the science domain and may be unaligned with student writing styles. This paper developed a contextualized German Science Education <b>BERT</b> (G-SciEdBERT), an innovative <b>large</b> <b>language</b> <b>model</b> tailored for scoring German-written responses to science tasks. Using G-BERT, we pre-trained G-SciEdBERT on a corpus of 50K German written science responses with 5M tokens to the Programme for International Student Assessment (PISA) 2015. We <b>fine-tuned</b> G-SciEdBERT on 59 assessment items and examined the scoring accuracy. We then compared its performance with G-BERT. Our findings reveal a substantial improvement in scoring accuracy with G-SciEdBERT, demonstrating a 10% increase of quadratic weighted kappa compared to G-BERT (mean accuracy difference = 0.096, SD = 0.024). These insights underline the significance of specialized language models like G-SciEdBERT, which is trained to enhance the accuracy of automated scoring, offering a substantial contribution to the field of AI in education.

{{</citation>}}


### (15/27 | 16/197) Explaining Veracity Predictions with Evidence Summarization: A Multi-Task Model Approach (Recep Firat Cekinel et al., 2024)

{{<citation>}}

Recep Firat Cekinel, Pinar Karagoz. (2024)  
**Explaining Veracity Predictions with Evidence Summarization: A Multi-Task Model Approach**
<br/>
<button class="copy-to-clipboard" title="Explaining Veracity Predictions with Evidence Summarization: A Multi-Task Model Approach" index=16>
  <span class="copy-to-clipboard-item">Copy Title<span>
</button>
<div class="toast toast-copied toast-index-16 align-items-center text-bg-secondary border-0 position-absolute top-0 end-0" role="alert" aria-live="assertive" aria-atomic="true">
  <div class="d-flex">
    <div class="toast-body">
      Copied!
    </div>
  </div>
</div>

---
Primary Category: cs.CL  
Categories: cs-CL, cs.CL  
Keyword Score: 40  
Keywords: Fact Verification, Reasoning, Text Summarization, Summarization  
<a type="button" class="btn btn-outline-primary" href="http://arxiv.org/abs/2402.06443v1" target="_blank" >Paper Link</a>
<button type="button" class="btn btn-outline-primary download-pdf" url="https://arxiv.org/pdf/2402.06443v1.pdf" filename="2402.06443v1.pdf">Download PDF</button>

---


**ABSTRACT**  
The rapid dissemination of misinformation through social media increased the importance of automated <b>fact-checking.</b> <b>Furthermore,</b> studies on what deep neural models pay attention to when making predictions have increased in recent years. While significant progress has been made in this field, it has not yet reached a level of <b>reasoning</b> comparable to human <b>reasoning.</b> To address these gaps, we propose a multi-task explainable neural model for misinformation detection. Specifically, this work formulates an explanation generation process of the model's veracity prediction as a <b>text</b> <b>summarization</b> problem. Additionally, the performance of the proposed model is discussed on publicly available datasets and the findings are evaluated with related studies.

{{</citation>}}


### (16/27 | 17/197) Findings of the First Workshop on Simulating Conversational Intelligence in Chat (Yvette Graham et al., 2024)

{{<citation>}}

Yvette Graham, Mohammed Rameez Qureshi, Haider Khalid, Gerasimos Lampouras, Ignacio Iacobacci, Qun Liu. (2024)  
**Findings of the First Workshop on Simulating Conversational Intelligence in Chat**
<br/>
<button class="copy-to-clipboard" title="Findings of the First Workshop on Simulating Conversational Intelligence in Chat" index=17>
  <span class="copy-to-clipboard-item">Copy Title<span>
</button>
<div class="toast toast-copied toast-index-17 align-items-center text-bg-secondary border-0 position-absolute top-0 end-0" role="alert" aria-live="assertive" aria-atomic="true">
  <div class="d-flex">
    <div class="toast-body">
      Copied!
    </div>
  </div>
</div>

---
Primary Category: cs.CL  
Categories: cs-CL, cs.CL  
Keyword Score: 40  
Keywords: Simulation, Simulator, Open-Domain Dialogue, Reasoning  
<a type="button" class="btn btn-outline-primary" href="http://arxiv.org/abs/2402.06420v1" target="_blank" >Paper Link</a>
<button type="button" class="btn btn-outline-primary download-pdf" url="https://arxiv.org/pdf/2402.06420v1.pdf" filename="2402.06420v1.pdf">Download PDF</button>

---


**ABSTRACT**  
The aim of this workshop is to bring together experts working on <b>open-domain</b> <b>dialogue</b> research. In this speedily advancing research area many challenges still exist, such as learning information from conversations, engaging in realistic and convincing <b>simulation</b> of human intelligence and <b>reasoning.</b> SCI-CHAT follows previous workshops on open domain dialogue but with a focus on the <b>simulation</b> of intelligent conversation as judged in a live human evaluation. Models aim to include the ability to follow a challenging topic over a multi-turn conversation, while positing, refuting and <b>reasoning</b> over arguments. The workshop included both a research track and shared task. The main goal of this paper is to provide an overview of the shared task and a link to an additional paper that will include an in depth analysis of the shared task results following presentation at the workshop.

{{</citation>}}


### (17/27 | 18/197) Promoting Target Data in Context-aware Neural Machine Translation (Harritxu Gete et al., 2024)

{{<citation>}}

Harritxu Gete, Thierry Etchegoyhen. (2024)  
**Promoting Target Data in Context-aware Neural Machine Translation**
<br/>
<button class="copy-to-clipboard" title="Promoting Target Data in Context-aware Neural Machine Translation" index=18>
  <span class="copy-to-clipboard-item">Copy Title<span>
</button>
<div class="toast toast-copied toast-index-18 align-items-center text-bg-secondary border-0 position-absolute top-0 end-0" role="alert" aria-live="assertive" aria-atomic="true">
  <div class="d-flex">
    <div class="toast-body">
      Copied!
    </div>
  </div>
</div>

---
Primary Category: cs.CL  
Categories: cs-CL, cs.CL  
Keyword Score: 40  
Keywords: Neural Machine Translation, Neural Machine Translation, Neural Machine Translation, In-context Learning  
<a type="button" class="btn btn-outline-primary" href="http://arxiv.org/abs/2402.06342v1" target="_blank" >Paper Link</a>
<button type="button" class="btn btn-outline-primary download-pdf" url="https://arxiv.org/pdf/2402.06342v1.pdf" filename="2402.06342v1.pdf">Download PDF</button>

---


**ABSTRACT**  
Standard context-aware <b>neural</b> <b>machine</b> <b>translation</b> <b>(NMT)</b> typically relies on parallel document-level data, exploiting both source and target contexts. Concatenation-based approaches in particular, still a strong baseline for document-level <b>NMT,</b> prepend source and/or target context sentences to the sentences to be translated, with model variants that exploit equal amounts of source and target data on each side achieving state-of-the-art results. In this work, we investigate whether target data should be further promoted within standard concatenation-based approaches, as most document-level phenomena rely on information that is present on the target language side. We evaluate novel concatenation-based variants where the target context is prepended to the source language, either in isolation or in combination with the source context. Experimental results in English-Russian and Basque-Spanish show that including target context in the source leads to large improvements on target language phenomena. On source-dependent phenomena, using only target language context in the source achieves parity with state-of-the-art concatenation approaches, or slightly underperforms, whereas combining source and target context on the source side leads to significant gains across the board.

{{</citation>}}


### (18/27 | 19/197) Model Editing with Canonical Examples (John Hewitt et al., 2024)

{{<citation>}}

John Hewitt, Sarah Chen, Lanruo Lora Xie, Edward Adams, Percy Liang, Christopher D. Manning. (2024)  
**Model Editing with Canonical Examples**
<br/>
<button class="copy-to-clipboard" title="Model Editing with Canonical Examples" index=19>
  <span class="copy-to-clipboard-item">Copy Title<span>
</button>
<div class="toast toast-copied toast-index-19 align-items-center text-bg-secondary border-0 position-absolute top-0 end-0" role="alert" aria-live="assertive" aria-atomic="true">
  <div class="d-flex">
    <div class="toast-body">
      Copied!
    </div>
  </div>
</div>

---
Primary Category: cs.CL  
Categories: cs-CL, cs.CL  
Keyword Score: 40  
Keywords: Fine-tuning, Fine-tuning, Out-of-distribution, GPT  
<a type="button" class="btn btn-outline-primary" href="http://arxiv.org/abs/2402.06155v1" target="_blank" >Paper Link</a>
<button type="button" class="btn btn-outline-primary download-pdf" url="https://arxiv.org/pdf/2402.06155v1.pdf" filename="2402.06155v1.pdf">Download PDF</button>

---


**ABSTRACT**  
We introduce model editing with canonical examples, a setting in which (1) a single learning example is provided per desired behavior, (2) evaluation is performed exclusively <b>out-of-distribution,</b> and (3) deviation from an initial model is strictly limited. A canonical example is a simple instance of good behavior, e.g., The capital of Mauritius is Port Louis) or bad behavior, e.g., An aspect of researchers is coldhearted). The evaluation set contains more complex examples of each behavior (like a paragraph in which the capital of Mauritius is called for.) We create three datasets and modify three more for model editing with canonical examples, covering knowledge-intensive improvements, social bias mitigation, and syntactic edge cases. In our experiments on Pythia language models, we find that LoRA outperforms full <b>finetuning</b> and MEMIT. We then turn to the Backpack language model architecture because it is intended to enable targeted improvement. The Backpack defines a large bank of sense vectors--a decomposition of the different uses of each word--which are weighted and summed to form the output logits of the model. We propose sense <b>finetuning,</b> which selects and <b>finetunes</b> a few ($\approx$ 10) sense vectors for each canonical example, and find that it outperforms other <b>finetuning</b> methods, e.g., 4.8% improvement vs 0.3%. Finally, we improve <b>GPT-J-6B</b> by an inference-time ensemble with just the changes from sense <b>finetuning</b> of a 35x smaller Backpack, in one setting outperforming editing <b>GPT-J</b> itself (4.1% vs 1.0%).

{{</citation>}}


### (19/27 | 20/197) Language Model Sentence Completion with a Parser-Driven Rhetorical Control Method (Joshua Zingale et al., 2024)

{{<citation>}}

Joshua Zingale, Jugal Kalita. (2024)  
**Language Model Sentence Completion with a Parser-Driven Rhetorical Control Method**
<br/>
<button class="copy-to-clipboard" title="Language Model Sentence Completion with a Parser-Driven Rhetorical Control Method" index=20>
  <span class="copy-to-clipboard-item">Copy Title<span>
</button>
<div class="toast toast-copied toast-index-20 align-items-center text-bg-secondary border-0 position-absolute top-0 end-0" role="alert" aria-live="assertive" aria-atomic="true">
  <div class="d-flex">
    <div class="toast-body">
      Copied!
    </div>
  </div>
</div>

---
Primary Category: cs.CL  
Categories: cs-CL, cs.CL  
Keyword Score: 40  
Keywords: Fine-tuning, Text Generation, Large Language Model, Large Language Model  
<a type="button" class="btn btn-outline-primary" href="http://arxiv.org/abs/2402.06125v1" target="_blank" >Paper Link</a>
<button type="button" class="btn btn-outline-primary download-pdf" url="https://arxiv.org/pdf/2402.06125v1.pdf" filename="2402.06125v1.pdf">Download PDF</button>

---


**ABSTRACT**  
Controlled <b>text</b> <b>generation</b> (CTG) seeks to guide <b>large</b> <b>language</b> <b>model</b> <b>(LLM)</b> output to produce <b>text</b> <b>that</b> conforms to desired criteria. The current study presents a novel CTG algorithm that enforces adherence toward specific rhetorical relations in an <b>LLM</b> sentence-completion context by a parser-driven decoding scheme that requires no model <b>fine-tuning.</b> The method is validated both with automatic and human evaluation. The code is accessible on GitHub.

{{</citation>}}


### (20/27 | 21/197) Exploring Group and Symmetry Principles in Large Language Models (Shima Imani et al., 2024)

{{<citation>}}

Shima Imani, Hamid Palangi. (2024)  
**Exploring Group and Symmetry Principles in Large Language Models**
<br/>
<button class="copy-to-clipboard" title="Exploring Group and Symmetry Principles in Large Language Models" index=21>
  <span class="copy-to-clipboard-item">Copy Title<span>
</button>
<div class="toast toast-copied toast-index-21 align-items-center text-bg-secondary border-0 position-absolute top-0 end-0" role="alert" aria-live="assertive" aria-atomic="true">
  <div class="d-flex">
    <div class="toast-body">
      Copied!
    </div>
  </div>
</div>

---
Primary Category: cs.CL  
Categories: cs-CL, cs.CL  
Keyword Score: 30  
Keywords: Reasoning, Large Language Model, Large Language Model  
<a type="button" class="btn btn-outline-primary" href="http://arxiv.org/abs/2402.06120v1" target="_blank" >Paper Link</a>
<button type="button" class="btn btn-outline-primary download-pdf" url="https://arxiv.org/pdf/2402.06120v1.pdf" filename="2402.06120v1.pdf">Download PDF</button>

---


**ABSTRACT**  
<b>Large</b> <b>Language</b> <b>Models</b> <b>(LLMs)</b> have demonstrated impressive performance across a wide range of applications; however, assessing their <b>reasoning</b> capabilities remains a significant challenge. In this paper, we introduce a framework grounded in group and symmetry principles, which have played a crucial role in fields such as physics and mathematics, and offer another way to evaluate their capabilities. While the proposed framework is general, to showcase the benefits of employing these properties, we focus on arithmetic <b>reasoning</b> and investigate the performance of these models on four group properties: closure, identity, inverse, and associativity. Our findings reveal that <b>LLMs</b> studied in this work struggle to preserve group properties across different test regimes. In the closure test, we observe biases towards specific outputs and an abrupt degradation in their performance from 100% to 0% after a specific sequence length. They also perform poorly in the identity test, which represents adding irrelevant information in the context, and show sensitivity when subjected to inverse test, which examines the robustness of the model with respect to negation. In addition, we demonstrate that breaking down problems into smaller steps helps <b>LLMs</b> in the associativity test that we have conducted. To support these tests we have developed a synthetic dataset which will be released.

{{</citation>}}


### (21/27 | 22/197) Evaluation Metrics for Text Data Augmentation in NLP (Marcellus Amadeus et al., 2024)

{{<citation>}}

Marcellus Amadeus, William Alberto Cruz Castañeda. (2024)  
**Evaluation Metrics for Text Data Augmentation in NLP**
<br/>
<button class="copy-to-clipboard" title="Evaluation Metrics for Text Data Augmentation in NLP" index=22>
  <span class="copy-to-clipboard-item">Copy Title<span>
</button>
<div class="toast toast-copied toast-index-22 align-items-center text-bg-secondary border-0 position-absolute top-0 end-0" role="alert" aria-live="assertive" aria-atomic="true">
  <div class="d-flex">
    <div class="toast-body">
      Copied!
    </div>
  </div>
</div>

---
Primary Category: cs.CL  
Categories: cs-AI, cs-CL, cs.CL  
Keyword Score: 23  
Keywords: Benchmarking, Data Augmentation, Text Augmentation  
<a type="button" class="btn btn-outline-primary" href="http://arxiv.org/abs/2402.06766v1" target="_blank" >Paper Link</a>
<button type="button" class="btn btn-outline-primary download-pdf" url="https://arxiv.org/pdf/2402.06766v1.pdf" filename="2402.06766v1.pdf">Download PDF</button>

---


**ABSTRACT**  
Recent surveys on <b>data</b> <b>augmentation</b> for natural language processing have reported different techniques and advancements in the field. Several frameworks, tools, and repositories promote the implementation of <b>text</b> <b>data</b> <b>augmentation</b> pipelines. However, a lack of evaluation criteria and standards for method comparison due to different tasks, metrics, datasets, architectures, and experimental settings makes comparisons meaningless. Also, a lack of methods unification exists and <b>text</b> <b>data</b> <b>augmentation</b> research would benefit from unified metrics to compare different augmentation methods. Thus, academics and the industry endeavor relevant evaluation metrics for <b>text</b> <b>data</b> <b>augmentation</b> techniques. The contribution of this work is to provide a taxonomy of evaluation metrics for <b>text</b> <b>augmentation</b> methods and serve as a direction for a unified <b>benchmark.</b> The proposed taxonomy organizes categories that include tools for implementation and metrics calculation. Finally, with this study, we intend to present opportunities to explore the unification and standardization of <b>text</b> <b>data</b> <b>augmentation</b> metrics.

{{</citation>}}


### (22/27 | 23/197) TIC: Translate-Infer-Compile for accurate 'text to plan' using LLMs and logical intermediate representations (Sudhir Agarwal et al., 2024)

{{<citation>}}

Sudhir Agarwal, Anu Sreepathy. (2024)  
**TIC: Translate-Infer-Compile for accurate 'text to plan' using LLMs and logical intermediate representations**
<br/>
<button class="copy-to-clipboard" title="TIC: Translate-Infer-Compile for accurate 'text to plan' using LLMs and logical intermediate representations" index=23>
  <span class="copy-to-clipboard-item">Copy Title<span>
</button>
<div class="toast toast-copied toast-index-23 align-items-center text-bg-secondary border-0 position-absolute top-0 end-0" role="alert" aria-live="assertive" aria-atomic="true">
  <div class="d-flex">
    <div class="toast-body">
      Copied!
    </div>
  </div>
</div>

---
Primary Category: cs.CL  
Categories: cs-AI, cs-CL, cs.CL  
Keyword Score: 20  
Keywords: Planning Domain Descrition Language, Large Language Model  
<a type="button" class="btn btn-outline-primary" href="http://arxiv.org/abs/2402.06608v1" target="_blank" >Paper Link</a>
<button type="button" class="btn btn-outline-primary download-pdf" url="https://arxiv.org/pdf/2402.06608v1.pdf" filename="2402.06608v1.pdf">Download PDF</button>

---


**ABSTRACT**  
We study the problem of generating plans for given natural language planning task requests. On one hand, <b>LLMs</b> excel at natural language processing but do not perform well on planning. On the other hand, classical planning tools excel at planning tasks but require input in a structured language such as the Planning Domain Definition Language <b>(PDDL).</b> We leverage the strengths of both the techniques by using an <b>LLM</b> for generating the <b>PDDL</b> representation (task <b>PDDL)</b> of planning task requests followed by using a classical planner for computing a plan. Unlike previous approaches that use <b>LLMs</b> for generating task <b>PDDLs</b> directly, our approach comprises of (a) translate: using an <b>LLM</b> only for generating a logically interpretable intermediate representation of natural language task descriptions, (b) infer: deriving additional logically dependent information from the intermediate representation using a logic reasoner (currently, Answer Set Programming solver), and (c) compile: generating the target task <b>PDDL</b> from the base and inferred information. We observe that using an <b>LLM</b> to only output the intermediate representation significantly reduces <b>LLM</b> errors. Consequently, TIC approach achieves, for at least one <b>LLM,</b> high accuracy on task <b>PDDL</b> generation for all seven domains of our evaluation dataset.

{{</citation>}}


### (23/27 | 24/197) Self-consistent context aware conformer transducer for speech recognition (Konstantin Kolokolov et al., 2024)

{{<citation>}}

Konstantin Kolokolov, Pavel Pekichev, Karthik Raghunathan. (2024)  
**Self-consistent context aware conformer transducer for speech recognition**
<br/>
<button class="copy-to-clipboard" title="Self-consistent context aware conformer transducer for speech recognition" index=24>
  <span class="copy-to-clipboard-item">Copy Title<span>
</button>
<div class="toast toast-copied toast-index-24 align-items-center text-bg-secondary border-0 position-absolute top-0 end-0" role="alert" aria-live="assertive" aria-atomic="true">
  <div class="d-flex">
    <div class="toast-body">
      Copied!
    </div>
  </div>
</div>

---
Primary Category: cs.CL  
Categories: cs-CL, cs-SD, cs.CL, eess-AS  
Keyword Score: 20  
Keywords: Automatic Speech Recognition, Automatic Speech Recognition  
<a type="button" class="btn btn-outline-primary" href="http://arxiv.org/abs/2402.06592v1" target="_blank" >Paper Link</a>
<button type="button" class="btn btn-outline-primary download-pdf" url="https://arxiv.org/pdf/2402.06592v1.pdf" filename="2402.06592v1.pdf">Download PDF</button>

---


**ABSTRACT**  
We propose a novel neural network architecture based on conformer transducer that adds contextual information flow to the <b>ASR</b> systems. Our method improves the accuracy of recognizing uncommon words while not harming the word error rate of regular words. We explore the uncommon words accuracy improvement when we use the new model and/or shallow fusion with context language model. We found that combination of both provides cumulative gain in uncommon words recognition accuracy.

{{</citation>}}


### (24/27 | 25/197) A Unified Causal View of Instruction Tuning (Lu Chen et al., 2024)

{{<citation>}}

Lu Chen, Wei Huang, Ruqing Zhang, Wei Chen, Jiafeng Guo, Xueqi Cheng. (2024)  
**A Unified Causal View of Instruction Tuning**
<br/>
<button class="copy-to-clipboard" title="A Unified Causal View of Instruction Tuning" index=25>
  <span class="copy-to-clipboard-item">Copy Title<span>
</button>
<div class="toast toast-copied toast-index-25 align-items-center text-bg-secondary border-0 position-absolute top-0 end-0" role="alert" aria-live="assertive" aria-atomic="true">
  <div class="d-flex">
    <div class="toast-body">
      Copied!
    </div>
  </div>
</div>

---
Primary Category: cs.CL  
Categories: cs-CL, cs.CL  
Keyword Score: 20  
Keywords: Zero-shot, Instruction Tuning  
<a type="button" class="btn btn-outline-primary" href="http://arxiv.org/abs/2402.06220v1" target="_blank" >Paper Link</a>
<button type="button" class="btn btn-outline-primary download-pdf" url="https://arxiv.org/pdf/2402.06220v1.pdf" filename="2402.06220v1.pdf">Download PDF</button>

---


**ABSTRACT**  
<b>Instruction</b> <b>tuning</b> on a mixture of tasks has improved <b>zero-shot</b> capabilities in natural language processing (NLP). Nevertheless, existing methods often learn features that exhibit correlations between <b>instruction-formatted</b> <b>samples</b> and target labels, rather than causal relationships. Termed as ``spurious correlation'' in statistics, such a correlation may change drastically in a new task, making the effect from the learned features to be misleading. To this end, we develop a meta Structural Causal Model (meta-SCM) to integrate different NLP tasks under a single causal structure of the data. Specifically, the meta-SCM introduces multiple latent factors that represent properties of source context, only some of which causally influence the target labels for a specific task. The key idea is to learn task-required causal factors and only use those to make predictions for a given task. Theoretically, we prove the causal factor can be identified without mixing information from others. Guided by the identifiability, we propose a Structural <b>Instruction</b> <b>Tuning</b> (SIT) method to learn the task-required causal representations that can mimic the causal factors for each task. The utility of our approach is verified by improvements of <b>zero-shot</b> ability on a range of unseen datasets and tasks.

{{</citation>}}


### (25/27 | 26/197) Asking the Right Question at the Right Time: Human and Model Uncertainty Guidance to Ask Clarification Questions (Alberto Testoni et al., 2024)

{{<citation>}}

Alberto Testoni, Raquel Fernández. (2024)  
**Asking the Right Question at the Right Time: Human and Model Uncertainty Guidance to Ask Clarification Questions**
<br/>
<button class="copy-to-clipboard" title="Asking the Right Question at the Right Time: Human and Model Uncertainty Guidance to Ask Clarification Questions" index=26>
  <span class="copy-to-clipboard-item">Copy Title<span>
</button>
<div class="toast toast-copied toast-index-26 align-items-center text-bg-secondary border-0 position-absolute top-0 end-0" role="alert" aria-live="assertive" aria-atomic="true">
  <div class="d-flex">
    <div class="toast-body">
      Copied!
    </div>
  </div>
</div>

---
Primary Category: cs.CL  
Categories: cs-AI, cs-CL, cs.CL  
Keyword Score: 10  
Keywords: Dialogue System  
<a type="button" class="btn btn-outline-primary" href="http://arxiv.org/abs/2402.06509v1" target="_blank" >Paper Link</a>
<button type="button" class="btn btn-outline-primary download-pdf" url="https://arxiv.org/pdf/2402.06509v1.pdf" filename="2402.06509v1.pdf">Download PDF</button>

---


**ABSTRACT**  
Clarification questions are an essential <b>dialogue</b> <b>tool</b> to signal misunderstanding, ambiguities, and under-specification in language use. While humans are able to resolve uncertainty by asking questions since childhood, modern <b>dialogue</b> <b>systems</b> struggle to generate effective questions. To make progress in this direction, in this work we take a collaborative <b>dialogue</b> <b>task</b> as a testbed and study how model uncertainty relates to human uncertainty -- an as yet under-explored problem. We show that model uncertainty does not mirror human clarification-seeking behavior, which suggests that using human clarification questions as supervision for deciding when to ask may not be the most effective way to resolve model uncertainty. To address this issue, we propose an approach to generating clarification questions based on model uncertainty estimation, compare it to several alternatives, and show that it leads to significant improvements in terms of task success. Our findings highlight the importance of equipping <b>dialogue</b> <b>systems</b> with the ability to assess their own uncertainty and exploit in interaction.

{{</citation>}}


### (26/27 | 27/197) On the Efficacy of Eviction Policy for Key-Value Constrained Generative Language Model Inference (Siyu Ren et al., 2024)

{{<citation>}}

Siyu Ren, Kenny Q. Zhu. (2024)  
**On the Efficacy of Eviction Policy for Key-Value Constrained Generative Language Model Inference**
<br/>
<button class="copy-to-clipboard" title="On the Efficacy of Eviction Policy for Key-Value Constrained Generative Language Model Inference" index=27>
  <span class="copy-to-clipboard-item">Copy Title<span>
</button>
<div class="toast toast-copied toast-index-27 align-items-center text-bg-secondary border-0 position-absolute top-0 end-0" role="alert" aria-live="assertive" aria-atomic="true">
  <div class="d-flex">
    <div class="toast-body">
      Copied!
    </div>
  </div>
</div>

---
Primary Category: cs.CL  
Categories: cs-AI, cs-CL, cs.CL  
Keyword Score: 10  
Keywords: Large Language Model  
<a type="button" class="btn btn-outline-primary" href="http://arxiv.org/abs/2402.06262v1" target="_blank" >Paper Link</a>
<button type="button" class="btn btn-outline-primary download-pdf" url="https://arxiv.org/pdf/2402.06262v1.pdf" filename="2402.06262v1.pdf">Download PDF</button>

---


**ABSTRACT**  
Despite the recent success associated with Large Language Models~(LLMs), they are notably cost-prohibitive to deploy in resource-constrained environments due to their excessive memory and computational demands. In addition to model parameters, the key-value cache is also stored in GPU memory, growing linearly with batch size and sequence length. As a remedy, recent works have proposed various eviction policies for maintaining the overhead of key-value cache under a given budget. This paper embarks on the efficacy of existing eviction policies in terms of \textit{importance score calculation} and \textit{eviction scope construction}. We identify the deficiency of prior policies in these two aspects and introduce RoCo, a \underline{r}\underline{o}bust \underline{c}ache \underline{o}mission policy based on temporal attention scores and robustness measures. Extensive experimentation spanning prefilling and auto-regressive decoding stages validates the superiority of RoCo. Finally, we release EasyKV, a versatile software package dedicated to user-friendly key-value constrained generative inference. Code available at \url{https://github.com/DRSY/EasyKV}.

{{</citation>}}


## cs.LG (50)



### (0/50 | 28/197) Entropy-Regularized Token-Level Policy Optimization for Large Language Models (Muning Wen et al., 2024)

{{<citation>}}

Muning Wen, Cheng Deng, Jun Wang, Weinan Zhang, Ying Wen. (2024)  
**Entropy-Regularized Token-Level Policy Optimization for Large Language Models**
<br/>
<button class="copy-to-clipboard" title="Entropy-Regularized Token-Level Policy Optimization for Large Language Models" index=28>
  <span class="copy-to-clipboard-item">Copy Title<span>
</button>
<div class="toast toast-copied toast-index-28 align-items-center text-bg-secondary border-0 position-absolute top-0 end-0" role="alert" aria-live="assertive" aria-atomic="true">
  <div class="d-flex">
    <div class="toast-body">
      Copied!
    </div>
  </div>
</div>

---
Primary Category: cs.LG  
Categories: cs-AI, cs-LG, cs.LG  
Keyword Score: 110  
Keywords: Fine-tuning, Reinforcement Learning, Reinforcement Learning from Human Feedback, Supervised Learning, Code Generation, Stemming, In-context Learning, In-context Learning, Large Language Model, Large Language Model, Prompt  
<a type="button" class="btn btn-outline-primary" href="http://arxiv.org/abs/2402.06700v1" target="_blank" >Paper Link</a>
<button type="button" class="btn btn-outline-primary download-pdf" url="https://arxiv.org/pdf/2402.06700v1.pdf" filename="2402.06700v1.pdf">Download PDF</button>

---


**ABSTRACT**  
<b>Large</b> <b>Language</b> <b>Models</b> <b>(LLMs)</b> have shown promise as intelligent agents in interactive decision-making tasks. Traditional approaches often depend on meticulously designed <b>prompts,</b> high-quality examples, or additional reward models for <b>in-context</b> <b>learning,</b> <b>supervised</b> <b>fine-tuning,</b> or <b>RLHF.</b> <b>Reinforcement</b> <b>learning</b> (RL) presents a dynamic alternative for <b>LLMs</b> to overcome these dependencies by engaging directly with task-specific environments. Nonetheless, it faces significant hurdles: 1) instability <b>stemming</b> from the exponentially vast action space requiring exploration; 2) challenges in assigning token-level credit based on action-level reward signals, resulting in discord between maximizing rewards and accurately modeling corpus data. In response to these challenges, we introduce Entropy-Regularized Token-level Policy Optimization (ETPO), an entropy-augmented RL method tailored for optimizing <b>LLMs</b> at the token level. At the heart of ETPO is our novel per-token soft Bellman update, designed to harmonize the RL process with the principles of language modeling. This methodology decomposes the Q-function update from a coarse action-level view to a more granular token-level perspective, backed by theoretical proof of optimization consistency. Crucially, this decomposition renders linear time complexity in action exploration. We assess the effectiveness of ETPO within a simulated environment that models data science <b>code</b> <b>generation</b> as a series of multi-step interactive tasks; results show that ETPO achieves effective performance improvement on the CodeLlama-7B model and surpasses a variant PPO baseline inherited from <b>RLHF.</b> This underlines ETPO's potential as a robust method for refining the interactive decision-making capabilities of <b>LLMs.</b>

{{</citation>}}


### (1/50 | 29/197) Diffusion-ES: Gradient-free Planning with Diffusion for Autonomous Driving and Zero-Shot Instruction Following (Brian Yang et al., 2024)

{{<citation>}}

Brian Yang, Huangyuan Su, Nikolaos Gkanatsios, Tsung-Wei Ke, Ayush Jain, Jeff Schneider, Katerina Fragkiadaki. (2024)  
**Diffusion-ES: Gradient-free Planning with Diffusion for Autonomous Driving and Zero-Shot Instruction Following**
<br/>
<button class="copy-to-clipboard" title="Diffusion-ES: Gradient-free Planning with Diffusion for Autonomous Driving and Zero-Shot Instruction Following" index=29>
  <span class="copy-to-clipboard-item">Copy Title<span>
</button>
<div class="toast toast-copied toast-index-29 align-items-center text-bg-secondary border-0 position-absolute top-0 end-0" role="alert" aria-live="assertive" aria-atomic="true">
  <div class="d-flex">
    <div class="toast-body">
      Copied!
    </div>
  </div>
</div>

---
Primary Category: cs.LG  
Categories: cs-AI, cs-CL, cs-LG, cs-RO, cs.LG  
Keyword Score: 59  
Keywords: Benchmarking, Few-shot, Multi-modal, Multi-modal, Zero-shot, Instruction Following, Large Language Model, Prompt  
<a type="button" class="btn btn-outline-primary" href="http://arxiv.org/abs/2402.06559v1" target="_blank" >Paper Link</a>
<button type="button" class="btn btn-outline-primary download-pdf" url="https://arxiv.org/pdf/2402.06559v1.pdf" filename="2402.06559v1.pdf">Download PDF</button>

---


**ABSTRACT**  
Diffusion models excel at modeling complex and <b>multimodal</b> trajectory distributions for decision-making and control. Reward-gradient guided denoising has been recently proposed to generate trajectories that maximize both a differentiable reward function and the likelihood under the data distribution captured by a diffusion model. Reward-gradient guided denoising requires a differentiable reward function fitted to both clean and noised samples, limiting its applicability as a general trajectory optimizer. In this paper, we propose DiffusionES, a method that combines gradient-free optimization with trajectory denoising to optimize black-box non-differentiable objectives while staying in the data manifold. Diffusion-ES samples trajectories during evolutionary search from a diffusion model and scores them using a black-box reward function. It mutates high-scoring trajectories using a truncated diffusion process that applies a small number of noising and denoising steps, allowing for much more efficient exploration of the solution space. We show that DiffusionES achieves state-of-the-art performance on nuPlan, an established closed-loop planning <b>benchmark</b> for autonomous driving. Diffusion-ES outperforms existing sampling-based planners, reactive deterministic or diffusion-based policies, and reward-gradient guidance. Additionally, we show that unlike prior guidance methods, our method can optimize non-differentiable language-shaped reward functions generated by <b>few-shot</b> <b>LLM</b> <b>prompting.</b> When guided by a human teacher that issues <b>instructions</b> <b>to</b> follow, our method can generate novel, highly complex behaviors, such as aggressive lane weaving, which are not present in the training data. This allows us to solve the hardest nuPlan scenarios which are beyond the capabilities of existing trajectory optimization methods and driving policies.

{{</citation>}}


### (2/50 | 30/197) V-STaR: Training Verifiers for Self-Taught Reasoners (Arian Hosseini et al., 2024)

{{<citation>}}

Arian Hosseini, Xingdi Yuan, Nikolay Malkin, Aaron Courville, Alessandro Sordoni, Rishabh Agarwal. (2024)  
**V-STaR: Training Verifiers for Self-Taught Reasoners**
<br/>
<button class="copy-to-clipboard" title="V-STaR: Training Verifiers for Self-Taught Reasoners" index=30>
  <span class="copy-to-clipboard-item">Copy Title<span>
</button>
<div class="toast toast-copied toast-index-30 align-items-center text-bg-secondary border-0 position-absolute top-0 end-0" role="alert" aria-live="assertive" aria-atomic="true">
  <div class="d-flex">
    <div class="toast-body">
      Copied!
    </div>
  </div>
</div>

---
Primary Category: cs.LG  
Categories: cs-AI, cs-CL, cs-LG, cs.LG  
Keyword Score: 53  
Keywords: Benchmarking, Fine-tuning, Code Generation, Reasoning, Large Language Model, Large Language Model  
<a type="button" class="btn btn-outline-primary" href="http://arxiv.org/abs/2402.06457v1" target="_blank" >Paper Link</a>
<button type="button" class="btn btn-outline-primary download-pdf" url="https://arxiv.org/pdf/2402.06457v1.pdf" filename="2402.06457v1.pdf">Download PDF</button>

---


**ABSTRACT**  
Common self-improvement approaches for <b>large</b> <b>language</b> <b>models</b> <b>(LLMs),</b> such as STaR (Zelikman et al., 2022), iteratively <b>fine-tune</b> <b>LLMs</b> on self-generated solutions to improve their problem-solving ability. However, these approaches discard the <b>large</b> <b>amounts</b> <b>of</b> incorrect solutions generated during this process, potentially neglecting valuable information in such solutions. To address this shortcoming, we propose V-STaR that utilizes both the correct and incorrect solutions generated during the self-improvement process to train a verifier using DPO that judges correctness of model-generated solutions. This verifier is used at inference time to select one solution among many candidate solutions. Running V-STaR for multiple iterations results in progressively better reasoners and verifiers, delivering a 4% to 17% test accuracy improvement over existing self-improvement and verification approaches on common <b>code</b> <b>generation</b> and math <b>reasoning</b> <b>benchmarks</b> with LLaMA2 models.

{{</citation>}}


### (3/50 | 31/197) Estimating Player Performance in Different Contexts Using Fine-tuned Large Events Models (Tiago Mendes-Neves et al., 2024)

{{<citation>}}

Tiago Mendes-Neves, Luís Meireles, João Mendes-Moreira. (2024)  
**Estimating Player Performance in Different Contexts Using Fine-tuned Large Events Models**
<br/>
<button class="copy-to-clipboard" title="Estimating Player Performance in Different Contexts Using Fine-tuned Large Events Models" index=31>
  <span class="copy-to-clipboard-item">Copy Title<span>
</button>
<div class="toast toast-copied toast-index-31 align-items-center text-bg-secondary border-0 position-absolute top-0 end-0" role="alert" aria-live="assertive" aria-atomic="true">
  <div class="d-flex">
    <div class="toast-body">
      Copied!
    </div>
  </div>
</div>

---
Primary Category: cs.LG  
Categories: cs-LG, cs.LG  
Keyword Score: 50  
Keywords: Fine-tuning, Fine-tuning, Simulation, Simulator, Large Language Model  
<a type="button" class="btn btn-outline-primary" href="http://arxiv.org/abs/2402.06815v1" target="_blank" >Paper Link</a>
<button type="button" class="btn btn-outline-primary download-pdf" url="https://arxiv.org/pdf/2402.06815v1.pdf" filename="2402.06815v1.pdf">Download PDF</button>

---


**ABSTRACT**  
This paper introduces an innovative application of <b>Large</b> <b>Event</b> <b>Models</b> (LEMs), akin to <b>Large</b> <b>Language</b> <b>Models,</b> to the domain of soccer analytics. By learning the "language" of soccer - predicting variables for subsequent events rather than words LEMs facilitate the <b>simulation</b> of matches and offer various applications, including player performance prediction across different team contexts. We focus on <b>fine-tuning</b> LEMs with the WyScout dataset for the 2017-2018 Premier League season to derive specific insights into player contributions and team strategies. Our methodology involves adapting these models to reflect the nuanced dynamics of soccer, enabling the evaluation of hypothetical transfers. Our findings confirm the effectiveness and limitations of LEMs in soccer analytics, highlighting the model's capability to forecast teams' expected standings and explore high-profile scenarios, such as the potential effects of transferring Cristiano Ronaldo or Lionel Messi to different teams in the Premier League. This analysis underscores the importance of context in evaluating player quality. While general metrics may suggest significant differences between players, contextual analyses reveal narrower gaps in performance within specific team frameworks.

{{</citation>}}


### (4/50 | 32/197) RQP-SGD: Differential Private Machine Learning through Noisy SGD and Randomized Quantization (Ce Feng et al., 2024)

{{<citation>}}

Ce Feng, Parv Venkitasubramaniam. (2024)  
**RQP-SGD: Differential Private Machine Learning through Noisy SGD and Randomized Quantization**
<br/>
<button class="copy-to-clipboard" title="RQP-SGD: Differential Private Machine Learning through Noisy SGD and Randomized Quantization" index=32>
  <span class="copy-to-clipboard-item">Copy Title<span>
</button>
<div class="toast toast-copied toast-index-32 align-items-center text-bg-secondary border-0 position-absolute top-0 end-0" role="alert" aria-live="assertive" aria-atomic="true">
  <div class="d-flex">
    <div class="toast-body">
      Copied!
    </div>
  </div>
</div>

---
Primary Category: cs.LG  
Categories: cs-AI, cs-CR, cs-LG, cs.LG  
Keyword Score: 50  
Keywords: Quantization, Quantization, Stochastic Gradient Descent, Stochastic Gradient Descent, Prompt  
<a type="button" class="btn btn-outline-primary" href="http://arxiv.org/abs/2402.06606v1" target="_blank" >Paper Link</a>
<button type="button" class="btn btn-outline-primary download-pdf" url="https://arxiv.org/pdf/2402.06606v1.pdf" filename="2402.06606v1.pdf">Download PDF</button>

---


**ABSTRACT**  
The rise of IoT devices has <b>prompted</b> the demand for deploying machine learning at-the-edge with real-time, efficient, and secure data processing. In this context, implementing machine learning (ML) models with real-valued weight parameters can prove to be impractical particularly for large models, and there is a need to train models with <b>quantized</b> discrete weights. At the same time, these low-dimensional models also need to preserve privacy of the underlying dataset. In this work, we present RQP-SGD, a new approach for privacy-preserving <b>quantization</b> to train machine learning models for low-memory ML-at-the-edge. This approach combines differentially private <b>stochastic</b> <b>gradient</b> <b>descent</b> (DP-SGD) with randomized <b>quantization,</b> providing a measurable privacy guarantee in machine learning. In particular, we study the utility convergence of implementing RQP-SGD on ML tasks with convex objectives and <b>quantization</b> constraints and demonstrate its efficacy over deterministic <b>quantization.</b> Through experiments conducted on two datasets, we show the practical effectiveness of RQP-SGD.

{{</citation>}}


### (5/50 | 33/197) Distilling Morphology-Conditioned Hypernetworks for Efficient Universal Morphology Control (Zheng Xiong et al., 2024)

{{<citation>}}

Zheng Xiong, Risto Vuorio, Jacob Beck, Matthieu Zimmer, Kun Shao, Shimon Whiteson. (2024)  
**Distilling Morphology-Conditioned Hypernetworks for Efficient Universal Morphology Control**
<br/>
<button class="copy-to-clipboard" title="Distilling Morphology-Conditioned Hypernetworks for Efficient Universal Morphology Control" index=33>
  <span class="copy-to-clipboard-item">Copy Title<span>
</button>
<div class="toast toast-copied toast-index-33 align-items-center text-bg-secondary border-0 position-absolute top-0 end-0" role="alert" aria-live="assertive" aria-atomic="true">
  <div class="d-flex">
    <div class="toast-body">
      Copied!
    </div>
  </div>
</div>

---
Primary Category: cs.LG  
Categories: cs-LG, cs-RO, cs.LG  
Keyword Score: 43  
Keywords: Benchmarking, Knowledge Distillation, Knowledge Distillation, Zero-shot, Transformer  
<a type="button" class="btn btn-outline-primary" href="http://arxiv.org/abs/2402.06570v1" target="_blank" >Paper Link</a>
<button type="button" class="btn btn-outline-primary download-pdf" url="https://arxiv.org/pdf/2402.06570v1.pdf" filename="2402.06570v1.pdf">Download PDF</button>

---


**ABSTRACT**  
Learning a universal policy across different robot morphologies can significantly improve learning efficiency and enable <b>zero-shot</b> generalization to unseen morphologies. However, learning a highly performant universal policy requires sophisticated architectures like <b>transformers</b> (TF) that have larger memory and computational cost than simpler multi-layer perceptrons (MLP). To achieve both good performance like TF and high efficiency like MLP at inference time, we propose HyperDistill, which consists of: (1) A morphology-conditioned hypernetwork (HN) that generates robot-wise MLP policies, and (2) A policy <b>distillation</b> approach that is essential for successful training. We show that on UNIMAL, a <b>benchmark</b> with hundreds of diverse morphologies, HyperDistill performs as well as a universal TF teacher policy on both training and unseen test robots, but reduces model size by 6-14 times, and computational cost by 67-160 times in different environments. Our analysis attributes the efficiency advantage of HyperDistill at inference time to knowledge decoupling, i.e., the ability to decouple inter-task and intra-task knowledge, a general principle that could also be applied to improve inference efficiency in other domains.

{{</citation>}}


### (6/50 | 34/197) Forecasting Events in Soccer Matches Through Language (Tiago Mendes-Neves et al., 2024)

{{<citation>}}

Tiago Mendes-Neves, Luís Meireles, João Mendes-Moreira. (2024)  
**Forecasting Events in Soccer Matches Through Language**
<br/>
<button class="copy-to-clipboard" title="Forecasting Events in Soccer Matches Through Language" index=34>
  <span class="copy-to-clipboard-item">Copy Title<span>
</button>
<div class="toast toast-copied toast-index-34 align-items-center text-bg-secondary border-0 position-absolute top-0 end-0" role="alert" aria-live="assertive" aria-atomic="true">
  <div class="d-flex">
    <div class="toast-body">
      Copied!
    </div>
  </div>
</div>

---
Primary Category: cs.LG  
Categories: cs-CL, cs-LG, cs.LG  
Keyword Score: 40  
Keywords: Simulation, Simulator, Large Language Model, Large Language Model  
<a type="button" class="btn btn-outline-primary" href="http://arxiv.org/abs/2402.06820v1" target="_blank" >Paper Link</a>
<button type="button" class="btn btn-outline-primary download-pdf" url="https://arxiv.org/pdf/2402.06820v1.pdf" filename="2402.06820v1.pdf">Download PDF</button>

---


**ABSTRACT**  
This paper introduces an approach to predicting the next event in a soccer match, a challenge bearing remarkable similarities to the problem faced by <b>Large</b> <b>Language</b> <b>Models</b> <b>(LLMs).</b> Unlike other methods that severely limit event dynamics in soccer, often abstracting from many variables or relying on a mix of sequential models, our research proposes a novel technique inspired by the methodologies used in <b>LLMs.</b> These models predict a complete chain of variables that compose an event, significantly simplifying the construction of <b>Large</b> <b>Event</b> <b>Models</b> (LEMs) for soccer. Utilizing deep learning on the publicly available WyScout dataset, the proposed approach notably surpasses the performance of previous LEM proposals in critical areas, such as the prediction accuracy of the next event type. This paper highlights the utility of LEMs in various applications, including betting and match analytics. Moreover, we show that LEMs provide a <b>simulation</b> backbone on which many analytics pipelines can be built, an approach opposite to the current specialized single-purpose models. LEMs represent a pivotal advancement in soccer analytics, establishing a foundational framework for multifaceted analytics pipelines through a singular machine-learning model.

{{</citation>}}


### (7/50 | 35/197) Embedding Compression for Teacher-to-Student Knowledge Transfer (Yiwei Ding et al., 2024)

{{<citation>}}

Yiwei Ding, Alexander Lerch. (2024)  
**Embedding Compression for Teacher-to-Student Knowledge Transfer**
<br/>
<button class="copy-to-clipboard" title="Embedding Compression for Teacher-to-Student Knowledge Transfer" index=35>
  <span class="copy-to-clipboard-item">Copy Title<span>
</button>
<div class="toast toast-copied toast-index-35 align-items-center text-bg-secondary border-0 position-absolute top-0 end-0" role="alert" aria-live="assertive" aria-atomic="true">
  <div class="d-flex">
    <div class="toast-body">
      Copied!
    </div>
  </div>
</div>

---
Primary Category: cs.LG  
Categories: cs-LG, cs.LG  
Keyword Score: 40  
Keywords: Knowledge Distillation, Knowledge Distillation, Knowledge Transfer, Unsupervised Learning  
<a type="button" class="btn btn-outline-primary" href="http://arxiv.org/abs/2402.06761v1" target="_blank" >Paper Link</a>
<button type="button" class="btn btn-outline-primary download-pdf" url="https://arxiv.org/pdf/2402.06761v1.pdf" filename="2402.06761v1.pdf">Download PDF</button>

---


**ABSTRACT**  
Common <b>knowledge</b> <b>distillation</b> methods require the teacher model and the student model to be trained on the same task. However, the usage of embeddings as teachers has also been proposed for different source tasks and target tasks. Prior work that uses embeddings as teachers ignores the fact that the teacher embeddings are likely to contain irrelevant <b>knowledge</b> <b>for</b> the target task. To address this problem, we propose to use an embedding compression module with a trainable teacher transformation to obtain a compact teacher embedding. Results show that adding the embedding compression module improves the classification performance, especially for <b>unsupervised</b> teacher embeddings. Moreover, student models trained with the guidance of embeddings show stronger generalizability.

{{</citation>}}


### (8/50 | 36/197) ExGRG: Explicitly-Generated Relation Graph for Self-Supervised Representation Learning (Mahdi Naseri et al., 2024)

{{<citation>}}

Mahdi Naseri, Mahdi Biparva. (2024)  
**ExGRG: Explicitly-Generated Relation Graph for Self-Supervised Representation Learning**
<br/>
<button class="copy-to-clipboard" title="ExGRG: Explicitly-Generated Relation Graph for Self-Supervised Representation Learning" index=36>
  <span class="copy-to-clipboard-item">Copy Title<span>
</button>
<div class="toast toast-copied toast-index-36 align-items-center text-bg-secondary border-0 position-absolute top-0 end-0" role="alert" aria-live="assertive" aria-atomic="true">
  <div class="d-flex">
    <div class="toast-body">
      Copied!
    </div>
  </div>
</div>

---
Primary Category: cs.LG  
Categories: cs-AI, cs-LG, cs.LG  
Keyword Score: 40  
Keywords: Node Classification, Data Augmentation, Self-supervised Learning, Self-supervised Learning  
<a type="button" class="btn btn-outline-primary" href="http://arxiv.org/abs/2402.06737v1" target="_blank" >Paper Link</a>
<button type="button" class="btn btn-outline-primary download-pdf" url="https://arxiv.org/pdf/2402.06737v1.pdf" filename="2402.06737v1.pdf">Download PDF</button>

---


**ABSTRACT**  
<b>Self-supervised</b> <b>Learning</b> (SSL) has emerged as a powerful technique in pre-training deep learning models without relying on expensive annotated labels, instead leveraging embedded signals in unlabeled <b>data.</b> <b>While</b> SSL has shown remarkable success in computer vision tasks through intuitive <b>data</b> <b>augmentation,</b> its application to graph-structured <b>data</b> <b>poses</b> challenges due to the semantic-altering and counter-intuitive nature of graph augmentations. Addressing this limitation, this paper introduces a novel non-contrastive SSL approach to Explicitly Generate a compositional Relation Graph (ExGRG) instead of relying solely on the conventional augmentation-based implicit relation graph. ExGRG offers a framework for incorporating prior domain knowledge and online extracted information into the SSL invariance objective, drawing inspiration from the Laplacian Eigenmap and Expectation-Maximization (EM). Employing an EM perspective on SSL, our E-step involves relation graph generation to identify candidates to guide the SSL invariance objective, and M-step updates the model parameters by integrating the derived relational information. Extensive experimentation on diverse <b>node</b> <b>classification</b> datasets demonstrates the superiority of our method over state-of-the-art techniques, affirming ExGRG as an effective adoption of SSL for graph representation learning.

{{</citation>}}


### (9/50 | 37/197) Corruption Robust Offline Reinforcement Learning with Human Feedback (Debmalya Mandal et al., 2024)

{{<citation>}}

Debmalya Mandal, Andi Nika, Parameswaran Kamalaruban, Adish Singla, Goran Radanović. (2024)  
**Corruption Robust Offline Reinforcement Learning with Human Feedback**
<br/>
<button class="copy-to-clipboard" title="Corruption Robust Offline Reinforcement Learning with Human Feedback" index=37>
  <span class="copy-to-clipboard-item">Copy Title<span>
</button>
<div class="toast toast-copied toast-index-37 align-items-center text-bg-secondary border-0 position-absolute top-0 end-0" role="alert" aria-live="assertive" aria-atomic="true">
  <div class="d-flex">
    <div class="toast-body">
      Copied!
    </div>
  </div>
</div>

---
Primary Category: cs.LG  
Categories: cs-AI, cs-LG, cs.LG  
Keyword Score: 40  
Keywords: Offline Reinforcement Learning, Reinforcement Learning, Reinforcement Learning from Human Feedback, Adversarial Attack  
<a type="button" class="btn btn-outline-primary" href="http://arxiv.org/abs/2402.06734v1" target="_blank" >Paper Link</a>
<button type="button" class="btn btn-outline-primary download-pdf" url="https://arxiv.org/pdf/2402.06734v1.pdf" filename="2402.06734v1.pdf">Download PDF</button>

---


**ABSTRACT**  
We study data corruption robustness for <b>reinforcement</b> <b>learning</b> with human feedback <b>(RLHF)</b> in an <b>offline</b> <b>setting.</b> <b>Given</b> an <b>offline</b> <b>dataset</b> <b>of</b> pairs of trajectories along with feedback about human preferences, an $\varepsilon$-fraction of the pairs is corrupted (e.g., feedback flipped or trajectory features manipulated), capturing an <b>adversarial</b> <b>attack</b> or noisy human preferences. We aim to design algorithms that identify a near-optimal policy from the corrupted data, with provable guarantees. Existing theoretical works have separately studied the settings of corruption robust RL (learning from scalar rewards directly under corruption) and <b>offline</b> <b>RLHF</b> <b>(learning</b> from human feedback without corruption); however, they are inapplicable to our problem of dealing with corrupted data in <b>offline</b> <b>RLHF</b> <b>setting.</b> To this end, we design novel corruption robust <b>offline</b> <b>RLHF</b> <b>methods</b> under various assumptions on the coverage of the data-generating distributions. At a high level, our methodology robustifies an <b>offline</b> <b>RLHF</b> <b>framework</b> by first learning a reward model along with confidence sets and then learning a pessimistic optimal policy over the confidence set. Our key insight is that learning optimal policy can be done by leveraging an <b>offline</b> <b>corruption-robust</b> <b>RL</b> oracle in different ways (e.g., zero-order oracle or first-order oracle), depending on the data coverage assumptions. To our knowledge, ours is the first work that provides provable corruption robust <b>offline</b> <b>RLHF</b> <b>methods.</b>

{{</citation>}}


### (10/50 | 38/197) Deceptive Path Planning via Reinforcement Learning with Graph Neural Networks (Michael Y. Fatemi et al., 2024)

{{<citation>}}

Michael Y. Fatemi, Wesley A. Suttle, Brian M. Sadler. (2024)  
**Deceptive Path Planning via Reinforcement Learning with Graph Neural Networks**
<br/>
<button class="copy-to-clipboard" title="Deceptive Path Planning via Reinforcement Learning with Graph Neural Networks" index=38>
  <span class="copy-to-clipboard-item">Copy Title<span>
</button>
<div class="toast toast-copied toast-index-38 align-items-center text-bg-secondary border-0 position-absolute top-0 end-0" role="alert" aria-live="assertive" aria-atomic="true">
  <div class="d-flex">
    <div class="toast-body">
      Copied!
    </div>
  </div>
</div>

---
Primary Category: cs.LG  
Categories: 68T05, cs-LG, cs.LG  
Keyword Score: 40  
Keywords: Graph Neural Network, Fine-tuning, Knowledge Distillation, Reinforcement Learning  
<a type="button" class="btn btn-outline-primary" href="http://arxiv.org/abs/2402.06552v1" target="_blank" >Paper Link</a>
<button type="button" class="btn btn-outline-primary download-pdf" url="https://arxiv.org/pdf/2402.06552v1.pdf" filename="2402.06552v1.pdf">Download PDF</button>

---


**ABSTRACT**  
Deceptive path planning (DPP) is the problem of designing a path that hides its true goal from an outside observer. Existing methods for DPP rely on unrealistic assumptions, such as global state observability and perfect model knowledge, and are typically problem-specific, meaning that even minor changes to a previously solved problem can force expensive computation of an entirely new solution. Given these drawbacks, such methods do not generalize to unseen problem instances, lack scalability to realistic problem sizes, and preclude both on-the-fly tunability of deception levels and real-time adaptivity to changing environments. In this paper, we propose a <b>reinforcement</b> <b>learning</b> (RL)-based scheme for training policies to perform DPP over arbitrary weighted <b>graphs</b> <b>that</b> <b>overcomes</b> these issues. The core of our approach is the introduction of a local perception model for the agent, a new state space representation <b>distilling</b> the key components of the DPP problem, the use of <b>graph</b> <b>neural</b> <b>network-based</b> policies to facilitate generalization and scaling, and the introduction of new deception bonuses that translate the deception objectives of classical methods to the RL setting. Through extensive experimentation we show that, without additional <b>fine-tuning,</b> at test time the resulting policies successfully generalize, scale, enjoy tunable levels of deception, and adapt in real-time to changes in the environment.

{{</citation>}}


### (11/50 | 39/197) Safe Active Learning for Time-Series Modeling with Gaussian Processes (Christoph Zimmer et al., 2024)

{{<citation>}}

Christoph Zimmer, Mona Meister, Duy Nguyen-Tuong. (2024)  
**Safe Active Learning for Time-Series Modeling with Gaussian Processes**
<br/>
<button class="copy-to-clipboard" title="Safe Active Learning for Time-Series Modeling with Gaussian Processes" index=39>
  <span class="copy-to-clipboard-item">Copy Title<span>
</button>
<div class="toast toast-copied toast-index-39 align-items-center text-bg-secondary border-0 position-absolute top-0 end-0" role="alert" aria-live="assertive" aria-atomic="true">
  <div class="d-flex">
    <div class="toast-body">
      Copied!
    </div>
  </div>
</div>

---
Primary Category: cs.LG  
Categories: cs-LG, cs.LG, stat-ML  
Keyword Score: 40  
Keywords: Active Learning, Gaussian Process, Simulation, Simulator  
<a type="button" class="btn btn-outline-primary" href="http://arxiv.org/abs/2402.06276v1" target="_blank" >Paper Link</a>
<button type="button" class="btn btn-outline-primary download-pdf" url="https://arxiv.org/pdf/2402.06276v1.pdf" filename="2402.06276v1.pdf">Download PDF</button>

---


**ABSTRACT**  
Learning time-series models is useful for many applications, such as <b>simulation</b> and forecasting. In this study, we consider the problem of actively learning time-series models while taking given safety constraints into account. For time-series modeling we employ a <b>Gaussian</b> <b>process</b> with a nonlinear exogenous input structure. The proposed approach generates data appropriate for time series model learning, i.e. input and output trajectories, by dynamically exploring the input space. The approach parametrizes the input trajectory as consecutive trajectory sections, which are determined stepwise given safety requirements and past observations. We analyze the proposed algorithm and evaluate it empirically on a technical application. The results show the effectiveness of our approach in a realistic technical use case.

{{</citation>}}


### (12/50 | 40/197) Studious Bob Fight Back Against Jailbreaking via Prompt Adversarial Tuning (Yichuan Mo et al., 2024)

{{<citation>}}

Yichuan Mo, Yuji Wang, Zeming Wei, Yisen Wang. (2024)  
**Studious Bob Fight Back Against Jailbreaking via Prompt Adversarial Tuning**
<br/>
<button class="copy-to-clipboard" title="Studious Bob Fight Back Against Jailbreaking via Prompt Adversarial Tuning" index=40>
  <span class="copy-to-clipboard-item">Copy Title<span>
</button>
<div class="toast toast-copied toast-index-40 align-items-center text-bg-secondary border-0 position-absolute top-0 end-0" role="alert" aria-live="assertive" aria-atomic="true">
  <div class="d-flex">
    <div class="toast-body">
      Copied!
    </div>
  </div>
</div>

---
Primary Category: cs.LG  
Categories: cs-AI, cs-CL, cs-CR, cs-LG, cs.LG  
Keyword Score: 40  
Keywords: Adversarial Learning, Large Language Model, Large Language Model, Prompt  
<a type="button" class="btn btn-outline-primary" href="http://arxiv.org/abs/2402.06255v1" target="_blank" >Paper Link</a>
<button type="button" class="btn btn-outline-primary download-pdf" url="https://arxiv.org/pdf/2402.06255v1.pdf" filename="2402.06255v1.pdf">Download PDF</button>

---


**ABSTRACT**  
Although <b>Large</b> <b>Language</b> <b>Models</b> <b>(LLMs)</b> have achieved tremendous success in various applications, they are also susceptible to certain <b>prompts</b> that can induce them to bypass built-in safety measures and provide dangerous or illegal content, a phenomenon known as jailbreak. To protect <b>LLMs</b> from producing harmful information, various defense strategies are proposed, with most focusing on content filtering or <b>adversarial</b> <b>training</b> of models. In this paper, we propose an approach named <b>Prompt</b> <b>Adversarial</b> <b>Tuning</b> (PAT) to train a defense control mechanism, which is then embedded as a prefix to user <b>prompts</b> to implement our defense strategy. We design a training process similar to <b>adversarial</b> <b>training</b> to achieve our optimized goal, alternating between updating attack and defense controls. To our knowledge, we are the first to implement defense from the perspective of <b>prompt</b> tuning. Once employed, our method will hardly impact the operational efficiency of <b>LLMs.</b> Experiments show that our method is effective in both black-box and white-box settings, reducing the success rate of advanced attacks to nearly 0 while maintaining the benign answer rate of 80% to simple benign questions. Our work might potentially chart a new perspective for future explorations in <b>LLM</b> security.

{{</citation>}}


### (13/50 | 41/197) Jointly Learning Representations for Map Entities via Heterogeneous Graph Contrastive Learning (Jiawei Jiang et al., 2024)

{{<citation>}}

Jiawei Jiang, Yifan Yang, Jingyuan Wang, Junjie Wu. (2024)  
**Jointly Learning Representations for Map Entities via Heterogeneous Graph Contrastive Learning**
<br/>
<button class="copy-to-clipboard" title="Jointly Learning Representations for Map Entities via Heterogeneous Graph Contrastive Learning" index=41>
  <span class="copy-to-clipboard-item">Copy Title<span>
</button>
<div class="toast toast-copied toast-index-41 align-items-center text-bg-secondary border-0 position-absolute top-0 end-0" role="alert" aria-live="assertive" aria-atomic="true">
  <div class="d-flex">
    <div class="toast-body">
      Copied!
    </div>
  </div>
</div>

---
Primary Category: cs.LG  
Categories: cs-LG, cs.LG  
Keyword Score: 40  
Keywords: Graph Contrastive Learning, Contrastive Learning, Self-supervised Learning, Transformer  
<a type="button" class="btn btn-outline-primary" href="http://arxiv.org/abs/2402.06135v1" target="_blank" >Paper Link</a>
<button type="button" class="btn btn-outline-primary download-pdf" url="https://arxiv.org/pdf/2402.06135v1.pdf" filename="2402.06135v1.pdf">Download PDF</button>

---


**ABSTRACT**  
The electronic map plays a crucial role in geographic information systems, serving various urban managerial scenarios and daily life services. Developing effective Map Entity Representation Learning (MERL) methods is crucial to extracting embedding information from electronic maps and converting map entities into representation vectors for downstream applications. However, existing MERL methods typically focus on one specific category of map entities, such as POIs, road segments, or land parcels, which is insufficient for real-world diverse map-based applications and might lose latent structural and semantic information interacting between entities of different types. Moreover, using representations generated by separate models for different map entities can introduce inconsistencies. Motivated by this, we propose a novel method named HOME-GCL for learning representations of multiple categories of map entities. Our approach utilizes a heterogeneous map entity <b>graph</b> <b>(HOME</b> <b>graph)</b> <b>that</b> <b>integrates</b> both road segments and land parcels into a unified framework. A HOME encoder with parcel-segment joint feature encoding and heterogeneous <b>graph</b> <b>transformer</b> <b>is</b> then deliberately designed to convert segments and parcels into representation vectors. Moreover, we introduce two types of <b>contrastive</b> <b>learning</b> tasks, namely intra-entity and inter-entity tasks, to train the encoder in a <b>self-supervised</b> manner. Extensive experiments on three large-scale datasets covering road segment-based, land parcel-based, and trajectory-based tasks demonstrate the superiority of our approach. To the best of our knowledge, HOME-GCL is the first attempt to jointly learn representations for road segments and land parcels using a unified model.

{{</citation>}}


### (14/50 | 42/197) Hierarchical Transformers are Efficient Meta-Reinforcement Learners (Gresa Shala et al., 2024)

{{<citation>}}

Gresa Shala, André Biedenkapp, Josif Grabocka. (2024)  
**Hierarchical Transformers are Efficient Meta-Reinforcement Learners**
<br/>
<button class="copy-to-clipboard" title="Hierarchical Transformers are Efficient Meta-Reinforcement Learners" index=42>
  <span class="copy-to-clipboard-item">Copy Title<span>
</button>
<div class="toast toast-copied toast-index-42 align-items-center text-bg-secondary border-0 position-absolute top-0 end-0" role="alert" aria-live="assertive" aria-atomic="true">
  <div class="d-flex">
    <div class="toast-body">
      Copied!
    </div>
  </div>
</div>

---
Primary Category: cs.LG  
Categories: cs-AI, cs-LG, cs.LG  
Keyword Score: 33  
Keywords: Benchmarking, Knowledge Distillation, Reinforcement Learning, Transformer  
<a type="button" class="btn btn-outline-primary" href="http://arxiv.org/abs/2402.06402v1" target="_blank" >Paper Link</a>
<button type="button" class="btn btn-outline-primary download-pdf" url="https://arxiv.org/pdf/2402.06402v1.pdf" filename="2402.06402v1.pdf">Download PDF</button>

---


**ABSTRACT**  
We introduce Hierarchical <b>Transformers</b> for Meta-Reinforcement Learning (HTrMRL), a powerful online meta-reinforcement learning approach. HTrMRL aims to address the challenge of enabling <b>reinforcement</b> <b>learning</b> agents to perform effectively in previously unseen tasks. We demonstrate how past episodes serve as a rich source of information, which our model effectively <b>distills</b> and applies to new contexts. Our learned algorithm is capable of outperforming the previous state-of-the-art and provides more efficient meta-training while significantly improving generalization capabilities. Experimental results, obtained across various simulated tasks of the Meta-World <b>Benchmark,</b> indicate a significant improvement in learning efficiency and adaptability compared to the state-of-the-art on a variety of tasks. Our approach not only enhances the agent's ability to generalize from limited data but also paves the way for more robust and versatile AI systems.

{{</citation>}}


### (15/50 | 43/197) TEE4EHR: Transformer Event Encoder for Better Representation Learning in Electronic Health Records (Hojjat Karami et al., 2024)

{{<citation>}}

Hojjat Karami, David Atienza, Anisoara Ionescu. (2024)  
**TEE4EHR: Transformer Event Encoder for Better Representation Learning in Electronic Health Records**
<br/>
<button class="copy-to-clipboard" title="TEE4EHR: Transformer Event Encoder for Better Representation Learning in Electronic Health Records" index=43>
  <span class="copy-to-clipboard-item">Copy Title<span>
</button>
<div class="toast toast-copied toast-index-43 align-items-center text-bg-secondary border-0 position-absolute top-0 end-0" role="alert" aria-live="assertive" aria-atomic="true">
  <div class="d-flex">
    <div class="toast-body">
      Copied!
    </div>
  </div>
</div>

---
Primary Category: cs.LG  
Categories: cs-LG, cs.LG  
Keyword Score: 33  
Keywords: Benchmarking, Self-supervised Learning, Self-supervised Learning, Transformer  
<a type="button" class="btn btn-outline-primary" href="http://arxiv.org/abs/2402.06367v1" target="_blank" >Paper Link</a>
<button type="button" class="btn btn-outline-primary download-pdf" url="https://arxiv.org/pdf/2402.06367v1.pdf" filename="2402.06367v1.pdf">Download PDF</button>

---


**ABSTRACT**  
Irregular sampling of time series in electronic health records (EHRs) is one of the main challenges for developing machine learning models. Additionally, the pattern of missing data in certain clinical variables is not at random but depends on the decisions of clinicians and the state of the patient. Point process is a mathematical framework for analyzing event sequence data that is consistent with irregular sampling patterns. Our model, TEE4EHR, is a <b>transformer</b> event encoder (TEE) with point process loss that encodes the pattern of laboratory tests in EHRs. The utility of our TEE has been investigated in a variety of <b>benchmark</b> event sequence datasets. Additionally, we conduct experiments on two real-world EHR databases to provide a more comprehensive evaluation of our model. Firstly, in a <b>self-supervised</b> <b>learning</b> approach, the TEE is jointly learned with an existing attention-based deep neural network which gives superior performance in negative log-likelihood and future event prediction. Besides, we propose an algorithm for aggregating attention weights that can reveal the interaction between the events. Secondly, we transfer and freeze the learned TEE to the downstream task for the outcome prediction, where it outperforms state-of-the-art models for handling irregularly sampled time series. Furthermore, our results demonstrate that our approach can improve representation learning in EHRs and can be useful for clinical prediction tasks.

{{</citation>}}


### (16/50 | 44/197) Premier-TACO is a Few-Shot Policy Learner: Pretraining Multitask Representation via Temporal Action-Driven Contrastive Loss (Ruijie Zheng et al., 2024)

{{<citation>}}

Ruijie Zheng, Yongyuan Liang, Xiyao Wang, Shuang Ma, Hal Daumé III, Huazhe Xu, John Langford, Praveen Palanisamy, Kalyan Shankar Basu, Furong Huang. (2024)  
**Premier-TACO is a Few-Shot Policy Learner: Pretraining Multitask Representation via Temporal Action-Driven Contrastive Loss**
<br/>
<button class="copy-to-clipboard" title="Premier-TACO is a Few-Shot Policy Learner: Pretraining Multitask Representation via Temporal Action-Driven Contrastive Loss" index=44>
  <span class="copy-to-clipboard-item">Copy Title<span>
</button>
<div class="toast toast-copied toast-index-44 align-items-center text-bg-secondary border-0 position-absolute top-0 end-0" role="alert" aria-live="assertive" aria-atomic="true">
  <div class="d-flex">
    <div class="toast-body">
      Copied!
    </div>
  </div>
</div>

---
Primary Category: cs.LG  
Categories: cs-AI, cs-LG, cs-RO, cs.LG  
Keyword Score: 33  
Keywords: Benchmarking, Contrastive Learning, Few-shot, Fine-tuning  
<a type="button" class="btn btn-outline-primary" href="http://arxiv.org/abs/2402.06187v3" target="_blank" >Paper Link</a>
<button type="button" class="btn btn-outline-primary download-pdf" url="https://arxiv.org/pdf/2402.06187v3.pdf" filename="2402.06187v3.pdf">Download PDF</button>

---


**ABSTRACT**  
We present Premier-TACO, a multitask feature representation learning approach designed to improve <b>few-shot</b> policy learning efficiency in sequential decision-making tasks. Premier-TACO leverages a subset of multitask offline datasets for pretraining a general feature representation, which captures critical environmental dynamics and is <b>fine-tuned</b> using minimal expert demonstrations. It advances the temporal action <b>contrastive</b> <b>learning</b> (TACO) objective, known for state-of-the-art results in visual control tasks, by incorporating a novel negative example sampling strategy. This strategy is crucial in significantly boosting TACO's computational efficiency, making large-scale multitask offline pretraining feasible. Our extensive empirical evaluation in a diverse set of continuous control <b>benchmarks</b> including Deepmind Control Suite, MetaWorld, and LIBERO demonstrate Premier-TACO's effectiveness in pretraining visual representations, significantly enhancing <b>few-shot</b> imitation learning of novel tasks. Our code, pretraining data, as well as pretrained model checkpoints will be released at https://github.com/PremierTACO/premier-taco. Our project webpage is at https://premiertaco.github.io.

{{</citation>}}


### (17/50 | 45/197) RAMP: Boosting Adversarial Robustness Against Multiple $l_p$ Perturbations (Enyi Jiang et al., 2024)

{{<citation>}}

Enyi Jiang, Gagandeep Singh. (2024)  
**RAMP: Boosting Adversarial Robustness Against Multiple $l_p$ Perturbations**
<br/>
<button class="copy-to-clipboard" title="RAMP: Boosting Adversarial Robustness Against Multiple $l_p$ Perturbations" index=45>
  <span class="copy-to-clipboard-item">Copy Title<span>
</button>
<div class="toast toast-copied toast-index-45 align-items-center text-bg-secondary border-0 position-absolute top-0 end-0" role="alert" aria-live="assertive" aria-atomic="true">
  <div class="d-flex">
    <div class="toast-body">
      Copied!
    </div>
  </div>
</div>

---
Primary Category: cs.LG  
Categories: cs-CR, cs-LG, cs.LG  
Keyword Score: 30  
Keywords: Adversarial Learning, Fine-tuning, Adversarial Attack  
<a type="button" class="btn btn-outline-primary" href="http://arxiv.org/abs/2402.06827v1" target="_blank" >Paper Link</a>
<button type="button" class="btn btn-outline-primary download-pdf" url="https://arxiv.org/pdf/2402.06827v1.pdf" filename="2402.06827v1.pdf">Download PDF</button>

---


**ABSTRACT**  
There is considerable work on improving robustness against <b>adversarial</b> <b>attacks</b> bounded by a single $l_p$ norm using <b>adversarial</b> <b>training</b> (AT). However, the multiple-norm robustness (union accuracy) of AT models is still low. We observe that simultaneously obtaining good union and clean accuracy is hard since there are tradeoffs between robustness against multiple $l_p$ perturbations, and accuracy/robustness/efficiency. By analyzing the tradeoffs from the lens of distribution shifts, we identify the key tradeoff pair among $l_p$ attacks to boost efficiency and design a logit pairing loss to improve the union accuracy. Next, we connect natural training with AT via gradient projection, to find and incorporate useful information from natural training into AT, which moderates the accuracy/robustness tradeoff. Combining our contributions, we propose a framework called \textbf{RAMP}, to boost the robustness against multiple $l_p$ perturbations. We show \textbf{RAMP} can be easily adapted for both robust <b>fine-tuning</b> and full AT. For robust <b>fine-tuning,</b> \textbf{RAMP} obtains a union accuracy up to $53.5\%$ on CIFAR-10, and $29.7\%$ on ImageNet. For training from scratch, \textbf{RAMP} achieves SOTA union accuracy of $44.6\%$ and relatively good clean accuracy of $81.2\%$ on ResNet-18 against AutoAttack on CIFAR-10.

{{</citation>}}


### (18/50 | 46/197) Feedback Loops With Language Models Drive In-Context Reward Hacking (Alexander Pan et al., 2024)

{{<citation>}}

Alexander Pan, Erik Jones, Meena Jagadeesan, Jacob Steinhardt. (2024)  
**Feedback Loops With Language Models Drive In-Context Reward Hacking**
<br/>
<button class="copy-to-clipboard" title="Feedback Loops With Language Models Drive In-Context Reward Hacking" index=46>
  <span class="copy-to-clipboard-item">Copy Title<span>
</button>
<div class="toast toast-copied toast-index-46 align-items-center text-bg-secondary border-0 position-absolute top-0 end-0" role="alert" aria-live="assertive" aria-atomic="true">
  <div class="d-flex">
    <div class="toast-body">
      Copied!
    </div>
  </div>
</div>

---
Primary Category: cs.LG  
Categories: cs-AI, cs-CL, cs-LG, cs.LG  
Keyword Score: 30  
Keywords: Recommendation, In-context Learning, Large Language Model  
<a type="button" class="btn btn-outline-primary" href="http://arxiv.org/abs/2402.06627v1" target="_blank" >Paper Link</a>
<button type="button" class="btn btn-outline-primary download-pdf" url="https://arxiv.org/pdf/2402.06627v1.pdf" filename="2402.06627v1.pdf">Download PDF</button>

---


**ABSTRACT**  
Language models influence the external world: they query APIs that read and write to web pages, generate content that shapes human behavior, and run system commands as autonomous agents. These interactions form feedback loops: <b>LLM</b> outputs affect the world, which in turn affect subsequent <b>LLM</b> outputs. In this work, we show that feedback loops can cause <b>in-context</b> reward hacking (ICRH), where the <b>LLM</b> at test-time optimizes a (potentially implicit) objective but creates negative side effects in the process. For example, consider an <b>LLM</b> agent deployed to increase Twitter engagement; the <b>LLM</b> may retrieve its previous tweets into the context window and make them more controversial, increasing engagement but also toxicity. We identify and study two processes that lead to ICRH: output-refinement and policy-refinement. For these processes, evaluations on static datasets are insufficient -- they miss the feedback effects and thus cannot capture the most harmful behavior. In response, we provide three <b>recommendations</b> for evaluation to capture more instances of ICRH. As AI development accelerates, the effects of feedback loops will proliferate, increasing the need to understand their role in shaping <b>LLM</b> behavior.

{{</citation>}}


### (19/50 | 47/197) The Deep Equilibrium Algorithmic Reasoner (Dobrik Georgiev et al., 2024)

{{<citation>}}

Dobrik Georgiev, Pietro Liò, Davide Buffelli. (2024)  
**The Deep Equilibrium Algorithmic Reasoner**
<br/>
<button class="copy-to-clipboard" title="The Deep Equilibrium Algorithmic Reasoner" index=47>
  <span class="copy-to-clipboard-item">Copy Title<span>
</button>
<div class="toast toast-copied toast-index-47 align-items-center text-bg-secondary border-0 position-absolute top-0 end-0" role="alert" aria-live="assertive" aria-atomic="true">
  <div class="d-flex">
    <div class="toast-body">
      Copied!
    </div>
  </div>
</div>

---
Primary Category: cs.LG  
Categories: cs-LG, cs.LG  
Keyword Score: 30  
Keywords: Graph Neural Network, Graph Neural Network, Reasoning  
<a type="button" class="btn btn-outline-primary" href="http://arxiv.org/abs/2402.06445v1" target="_blank" >Paper Link</a>
<button type="button" class="btn btn-outline-primary download-pdf" url="https://arxiv.org/pdf/2402.06445v1.pdf" filename="2402.06445v1.pdf">Download PDF</button>

---


**ABSTRACT**  
Recent work on neural algorithmic <b>reasoning</b> has demonstrated that <b>graph</b> <b>neural</b> <b>networks</b> <b>(GNNs)</b> could learn to execute classical algorithms. Doing so, however, has always used a recurrent architecture, where each iteration of the <b>GNN</b> aligns with an algorithm's iteration. Since an algorithm's solution is often an equilibrium, we conjecture and empirically validate that one can train a network to solve algorithmic problems by directly finding the equilibrium. Note that this does not require matching each <b>GNN</b> iteration with a step of the algorithm.

{{</citation>}}


### (20/50 | 48/197) Trust the Process: Zero-Knowledge Machine Learning to Enhance Trust in Generative AI Interactions (Bianca-Mihaela Ganescu et al., 2024)

{{<citation>}}

Bianca-Mihaela Ganescu, Jonathan Passerat-Palmbach. (2024)  
**Trust the Process: Zero-Knowledge Machine Learning to Enhance Trust in Generative AI Interactions**
<br/>
<button class="copy-to-clipboard" title="Trust the Process: Zero-Knowledge Machine Learning to Enhance Trust in Generative AI Interactions" index=48>
  <span class="copy-to-clipboard-item">Copy Title<span>
</button>
<div class="toast toast-copied toast-index-48 align-items-center text-bg-secondary border-0 position-absolute top-0 end-0" role="alert" aria-live="assertive" aria-atomic="true">
  <div class="d-flex">
    <div class="toast-body">
      Copied!
    </div>
  </div>
</div>

---
Primary Category: cs.LG  
Categories: cs-CR, cs-LG, cs.LG  
Keyword Score: 30  
Keywords: Fairness, Generative AI, Transformer  
<a type="button" class="btn btn-outline-primary" href="http://arxiv.org/abs/2402.06414v1" target="_blank" >Paper Link</a>
<button type="button" class="btn btn-outline-primary download-pdf" url="https://arxiv.org/pdf/2402.06414v1.pdf" filename="2402.06414v1.pdf">Download PDF</button>

---


**ABSTRACT**  
<b>Generative</b> <b>AI,</b> exemplified by models like <b>transformers,</b> has opened up new possibilities in various domains but also raised concerns about <b>fairness,</b> transparency and reliability, especially in fields like medicine and law. This paper emphasizes the urgency of ensuring <b>fairness</b> and quality in these domains through <b>generative</b> <b>AI.</b> It explores using cryptographic techniques, particularly Zero-Knowledge Proofs (ZKPs), to address concerns regarding performance <b>fairness</b> and accuracy while protecting model privacy. Applying ZKPs to Machine Learning models, known as ZKML (Zero-Knowledge Machine Learning), enables independent validation of AI-generated content without revealing sensitive model information, promoting transparency and trust. ZKML enhances AI <b>fairness</b> by providing cryptographic audit trails for model predictions and ensuring uniform performance across users. We introduce snarkGPT, a practical ZKML implementation for <b>transformers,</b> to empower users to verify output accuracy and quality while preserving model privacy. We present a series of empirical results studying snarkGPT's scalability and performance to assess the feasibility and challenges of adopting a ZKML-powered approach to capture quality and performance <b>fairness</b> problems in <b>generative</b> <b>AI</b> models.

{{</citation>}}


### (21/50 | 49/197) Multi-class real-time crash risk forecasting using convolutional neural network: Istanbul case study (Behnaz Alafi et al., 2024)

{{<citation>}}

Behnaz Alafi, Saeid Moradi. (2024)  
**Multi-class real-time crash risk forecasting using convolutional neural network: Istanbul case study**
<br/>
<button class="copy-to-clipboard" title="Multi-class real-time crash risk forecasting using convolutional neural network: Istanbul case study" index=49>
  <span class="copy-to-clipboard-item">Copy Title<span>
</button>
<div class="toast toast-copied toast-index-49 align-items-center text-bg-secondary border-0 position-absolute top-0 end-0" role="alert" aria-live="assertive" aria-atomic="true">
  <div class="d-flex">
    <div class="toast-body">
      Copied!
    </div>
  </div>
</div>

---
Primary Category: cs.LG  
Categories: I-2-6; K-3-2; I-2-m, cs-LG, cs.LG  
Keyword Score: 30  
Keywords: Convolution, Convolutional Neural Network, Convolutional Neural Network  
<a type="button" class="btn btn-outline-primary" href="http://arxiv.org/abs/2402.06707v1" target="_blank" >Paper Link</a>
<button type="button" class="btn btn-outline-primary download-pdf" url="https://arxiv.org/pdf/2402.06707v1.pdf" filename="2402.06707v1.pdf">Download PDF</button>

---


**ABSTRACT**  
The performance of an artificial neural network (ANN) in forecasting crash risk is shown in this paper. To begin, some traffic and weather data are acquired as raw data. This data is then analyzed, and relevant characteristics are chosen to utilize as input data based on additional tree and Pearson correlation. Furthermore, crash and non-crash time data are separated; then, feature values for crash and non-crash events are written in three four-minute intervals prior to the crash and non-crash events using the average of all available values for that period. The number of non-crash samples was lowered after calculating crash likelihood for each period based on accident labeling. The proposed <b>CNN</b> model is capable of learning from recorded, processed, and categorized input characteristics such as traffic characteristics and meteorological conditions. The goal of this work is to forecast the chance of a real-time crash based on three periods before events. The area under the curve (AUC) for the receiver operating characteristic curve (ROC curve), as well as sensitivity as the true positive rate and specificity as the false positive rate, are shown and compared with three typical machine learning and neural network models. Finally, when it comes to the error value, AUC, sensitivity, and specificity parameters as performance variables, the executed model outperforms other models. The findings of this research suggest applying the <b>CNN</b> model as a multi-class prediction model for real-time crash risk prediction. Our emphasis is on multi-class prediction, while prior research used this for binary (two-class) categorization like crash and non-crash.

{{</citation>}}


### (22/50 | 50/197) Rethinking Node-wise Propagation for Large-scale Graph Learning (Xunkai Li et al., 2024)

{{<citation>}}

Xunkai Li, Jingyuan Ma, Zhengyu Wu, Daohan Su, Wentao Zhang, Rong-Hua Li, Guoren Wang. (2024)  
**Rethinking Node-wise Propagation for Large-scale Graph Learning**
<br/>
<button class="copy-to-clipboard" title="Rethinking Node-wise Propagation for Large-scale Graph Learning" index=50>
  <span class="copy-to-clipboard-item">Copy Title<span>
</button>
<div class="toast toast-copied toast-index-50 align-items-center text-bg-secondary border-0 position-absolute top-0 end-0" role="alert" aria-live="assertive" aria-atomic="true">
  <div class="d-flex">
    <div class="toast-body">
      Copied!
    </div>
  </div>
</div>

---
Primary Category: cs.LG  
Categories: cs-AI, cs-LG, cs-SI, cs.LG  
Keyword Score: 30  
Keywords: Node Classification, Graph Neural Network, Graph Neural Network  
<a type="button" class="btn btn-outline-primary" href="http://arxiv.org/abs/2402.06128v1" target="_blank" >Paper Link</a>
<button type="button" class="btn btn-outline-primary download-pdf" url="https://arxiv.org/pdf/2402.06128v1.pdf" filename="2402.06128v1.pdf">Download PDF</button>

---


**ABSTRACT**  
Scalable <b>graph</b> <b>neural</b> <b>networks</b> <b>(GNNs)</b> have emerged as a promising technique, which exhibits superior predictive performance and high running efficiency across numerous large-scale <b>graph-based</b> <b>web</b> <b>applications.</b> However, (i) Most scalable <b>GNNs</b> tend to treat all <b>nodes</b> <b>in</b> <b>graphs</b> <b>with</b> <b>the</b> same propagation rules, neglecting their topological uniqueness; (ii) Existing <b>node-wise</b> <b>propagation</b> optimization strategies are insufficient on web-scale <b>graphs</b> <b>with</b> <b>intricate</b> topology, where a full portrayal of <b>nodes'</b> <b>local</b> properties is required. Intuitively, different <b>nodes</b> <b>in</b> web-scale <b>graphs</b> <b>possess</b> <b>distinct</b> topological roles, and therefore propagating them indiscriminately or neglect local contexts may compromise the quality of <b>node</b> <b>representations.</b> This intricate topology in web-scale <b>graphs</b> <b>cannot</b> <b>be</b> matched by small-scale scenarios. To address the above issues, we propose \textbf{A}daptive \textbf{T}opology-aware \textbf{P}ropagation (ATP), which reduces potential high-bias propagation and extracts structural patterns of each <b>node</b> <b>in</b> a scalable manner to improve running efficiency and predictive performance. Remarkably, ATP is crafted to be a plug-and-play <b>node-wise</b> <b>propagation</b> optimization strategy, allowing for offline execution independent of the <b>graph</b> <b>learning</b> <b>process</b> in a new perspective. Therefore, this approach can be seamlessly integrated into most scalable <b>GNNs</b> while remain orthogonal to existing <b>node-wise</b> <b>propagation</b> optimization strategies. Extensive experiments on 12 datasets, including the most representative large-scale ogbn-papers100M, have demonstrated the effectiveness of ATP. Specifically, ATP has proven to be efficient in improving the performance of prevalent scalable <b>GNNs</b> for semi-supervised <b>node</b> <b>classification</b> while addressing redundant computational costs.

{{</citation>}}


### (23/50 | 51/197) FL-NAS: Towards Fairness of NAS for Resource Constrained Devices via Large Language Models (Ruiyang Qin et al., 2024)

{{<citation>}}

Ruiyang Qin, Yuting Hu, Zheyu Yan, Jinjun Xiong, Ahmed Abbasi, Yiyu Shi. (2024)  
**FL-NAS: Towards Fairness of NAS for Resource Constrained Devices via Large Language Models**
<br/>
<button class="copy-to-clipboard" title="FL-NAS: Towards Fairness of NAS for Resource Constrained Devices via Large Language Models" index=51>
  <span class="copy-to-clipboard-item">Copy Title<span>
</button>
<div class="toast toast-copied toast-index-51 align-items-center text-bg-secondary border-0 position-absolute top-0 end-0" role="alert" aria-live="assertive" aria-atomic="true">
  <div class="d-flex">
    <div class="toast-body">
      Copied!
    </div>
  </div>
</div>

---
Primary Category: cs.LG  
Categories: cs-AI, cs-LG, cs.LG  
Keyword Score: 30  
Keywords: Fairness, Large Language Model, Large Language Model  
<a type="button" class="btn btn-outline-primary" href="http://arxiv.org/abs/2402.06696v1" target="_blank" >Paper Link</a>
<button type="button" class="btn btn-outline-primary download-pdf" url="https://arxiv.org/pdf/2402.06696v1.pdf" filename="2402.06696v1.pdf">Download PDF</button>

---


**ABSTRACT**  
Neural Architecture Search (NAS) has become the de fecto tools in the industry in automating the design of deep neural networks for various applications, especially those driven by mobile and edge devices with limited computing resources. The emerging <b>large</b> <b>language</b> <b>models</b> <b>(LLMs),</b> due to their prowess, have also been incorporated into NAS recently and show some promising results. This paper conducts further exploration in this direction by considering three important design metrics simultaneously, i.e., model accuracy, <b>fairness,</b> and hardware deployment efficiency. We propose a novel <b>LLM-based</b> NAS framework, FL-NAS, in this paper, and show experimentally that FL-NAS can indeed find high-performing DNNs, beating state-of-the-art DNN models by orders-of-magnitude across almost all design considerations.

{{</citation>}}


### (24/50 | 52/197) AI enhanced data assimilation and uncertainty quantification applied to Geological Carbon Storage (G. S. Seabra et al., 2024)

{{<citation>}}

G. S. Seabra, N. T. Mücke, V. L. S. Silva, D. Voskov, F. Vossepoel. (2024)  
**AI enhanced data assimilation and uncertainty quantification applied to Geological Carbon Storage**
<br/>
<button class="copy-to-clipboard" title="AI enhanced data assimilation and uncertainty quantification applied to Geological Carbon Storage" index=52>
  <span class="copy-to-clipboard-item">Copy Title<span>
</button>
<div class="toast toast-copied toast-index-52 align-items-center text-bg-secondary border-0 position-absolute top-0 end-0" role="alert" aria-live="assertive" aria-atomic="true">
  <div class="d-flex">
    <div class="toast-body">
      Copied!
    </div>
  </div>
</div>

---
Primary Category: cs.LG  
Categories: J-2, cs-LG, cs.LG  
Keyword Score: 30  
Keywords: Simulation, Simulator, Transformer  
<a type="button" class="btn btn-outline-primary" href="http://arxiv.org/abs/2402.06110v1" target="_blank" >Paper Link</a>
<button type="button" class="btn btn-outline-primary download-pdf" url="https://arxiv.org/pdf/2402.06110v1.pdf" filename="2402.06110v1.pdf">Download PDF</button>

---


**ABSTRACT**  
This study investigates the integration of machine learning (ML) and data assimilation (DA) techniques, focusing on implementing surrogate models for Geological Carbon Storage (GCS) projects while maintaining high fidelity physical results in posterior states. Initially, we evaluate the surrogate modeling capability of two distinct machine learning models, Fourier Neural Operators (FNOs) and <b>Transformer</b> UNet (T-UNet), in the context of CO$_2$ injection <b>simulations</b> within channelized reservoirs. We introduce the Surrogate-based hybrid ESMDA (SH-ESMDA), an adaptation of the traditional Ensemble Smoother with Multiple Data Assimilation (ESMDA). This method uses FNOs and T-UNet as surrogate models and has the potential to make the standard ESMDA process at least 50% faster or more, depending on the number of assimilation steps. Additionally, we introduce Surrogate-based Hybrid RML (SH-RML), a variational data assimilation approach that relies on the randomized maximum likelihood (RML) where both the FNO and the T-UNet enable the computation of gradients for the optimization of the objective function, and a high-fidelity model is employed for the computation of the posterior states. Our comparative analyses show that SH-RML offers better uncertainty quantification compared to conventional ESMDA for the case study.

{{</citation>}}


### (25/50 | 53/197) Monitored Markov Decision Processes (Simone Parisi et al., 2024)

{{<citation>}}

Simone Parisi, Montaser Mohammedalamen, Alireza Kazemipour, Matthew E. Taylor, Michael Bowling. (2024)  
**Monitored Markov Decision Processes**
<br/>
<button class="copy-to-clipboard" title="Monitored Markov Decision Processes" index=53>
  <span class="copy-to-clipboard-item">Copy Title<span>
</button>
<div class="toast toast-copied toast-index-53 align-items-center text-bg-secondary border-0 position-absolute top-0 end-0" role="alert" aria-live="assertive" aria-atomic="true">
  <div class="d-flex">
    <div class="toast-body">
      Copied!
    </div>
  </div>
</div>

---
Primary Category: cs.LG  
Categories: cs-LG, cs.LG  
Keyword Score: 20  
Keywords: Markov Decision Process, Reinforcement Learning  
<a type="button" class="btn btn-outline-primary" href="http://arxiv.org/abs/2402.06819v2" target="_blank" >Paper Link</a>
<button type="button" class="btn btn-outline-primary download-pdf" url="https://arxiv.org/pdf/2402.06819v2.pdf" filename="2402.06819v2.pdf">Download PDF</button>

---


**ABSTRACT**  
In <b>reinforcement</b> <b>learning</b> (RL), an agent learns to perform a task by interacting with an environment and receiving feedback (a numerical reward) for its actions. However, the assumption that rewards are always observable is often not applicable in real-world problems. For example, the agent may need to ask a human to supervise its actions or activate a monitoring system to receive feedback. There may even be a period of time before rewards become observable, or a period of time after which rewards are no longer given. In other words, there are cases where the environment generates rewards in response to the agent's actions but the agent cannot observe them. In this paper, we formalize a novel but general RL framework - Monitored <b>MDPs</b> - where the agent cannot always observe rewards. We discuss the theoretical and practical consequences of this setting, show challenges raised even in toy environments, and propose algorithms to begin to tackle this novel setting. This paper introduces a powerful new formalism that encompasses both new and existing problems and lays the foundation for future research.

{{</citation>}}


### (26/50 | 54/197) Explain Variance of Prediction in Variational Time Series Models for Clinical Deterioration Prediction (Jiacheng Liu et al., 2024)

{{<citation>}}

Jiacheng Liu, Jaideep Srivastava. (2024)  
**Explain Variance of Prediction in Variational Time Series Models for Clinical Deterioration Prediction**
<br/>
<button class="copy-to-clipboard" title="Explain Variance of Prediction in Variational Time Series Models for Clinical Deterioration Prediction" index=54>
  <span class="copy-to-clipboard-item">Copy Title<span>
</button>
<div class="toast toast-copied toast-index-54 align-items-center text-bg-secondary border-0 position-absolute top-0 end-0" role="alert" aria-live="assertive" aria-atomic="true">
  <div class="d-flex">
    <div class="toast-body">
      Copied!
    </div>
  </div>
</div>

---
Primary Category: cs.LG  
Categories: cs-LG, cs.LG  
Keyword Score: 20  
Keywords: Recurrent Neural Network, Transformer  
<a type="button" class="btn btn-outline-primary" href="http://arxiv.org/abs/2402.06808v1" target="_blank" >Paper Link</a>
<button type="button" class="btn btn-outline-primary download-pdf" url="https://arxiv.org/pdf/2402.06808v1.pdf" filename="2402.06808v1.pdf">Download PDF</button>

---


**ABSTRACT**  
In healthcare, thanks to many model agnostic methods, explainability of the prediction scores made by deep learning applications has improved. However, we note that for daily or hourly risk of deterioration prediction of in-hospital patients, not only the predicted risk probability score matters, but also the variance of the risk scores play key roles in aiding clinical decision making. In this paper, we propose to use delta's method to approximate variance of prediction deterministically, such that the SHAP method can be adopted to attribute contribution of variance. The prediction variance is estimated by sampling the conditional hidden space in variational models and is propagated to input clinical variables based on Shapley values of the variance game. This approach works with variational time series models such as variational <b>recurrent</b> <b>neural</b> <b>networks</b> and variational <b>transformers.</b> We further argue that variational time series models are perfect fits for achieving a balance between predictive power and explainability through a series of experiments on a public clinical ICU datasets. Since SHAP values are additive, we also postulate that the SHAP importance of clinical variables with respect to prediction variations can guide their frequency of measurements.

{{</citation>}}


### (27/50 | 55/197) Low-Rank Learning by Design: the Role of Network Architecture and Activation Linearity in Gradient Rank Collapse (Bradley T. Baker et al., 2024)

{{<citation>}}

Bradley T. Baker, Barak A. Pearlmutter, Robyn Miller, Vince D. Calhoun, Sergey M. Plis. (2024)  
**Low-Rank Learning by Design: the Role of Network Architecture and Activation Linearity in Gradient Rank Collapse**
<br/>
<button class="copy-to-clipboard" title="Low-Rank Learning by Design: the Role of Network Architecture and Activation Linearity in Gradient Rank Collapse" index=55>
  <span class="copy-to-clipboard-item">Copy Title<span>
</button>
<div class="toast toast-copied toast-index-55 align-items-center text-bg-secondary border-0 position-absolute top-0 end-0" role="alert" aria-live="assertive" aria-atomic="true">
  <div class="d-flex">
    <div class="toast-body">
      Copied!
    </div>
  </div>
</div>

---
Primary Category: cs.LG  
Categories: cs-LG, cs.LG  
Keyword Score: 20  
Keywords: Convolution, Convolutional Neural Network  
<a type="button" class="btn btn-outline-primary" href="http://arxiv.org/abs/2402.06751v1" target="_blank" >Paper Link</a>
<button type="button" class="btn btn-outline-primary download-pdf" url="https://arxiv.org/pdf/2402.06751v1.pdf" filename="2402.06751v1.pdf">Download PDF</button>

---


**ABSTRACT**  
Our understanding of learning dynamics of deep neural networks (DNNs) remains incomplete. Recent research has begun to uncover the mathematical principles underlying these networks, including the phenomenon of "Neural Collapse", where linear classifiers within DNNs converge to specific geometrical structures during late-stage training. However, the role of geometric constraints in learning extends beyond this terminal phase. For instance, gradients in fully-connected layers naturally develop a low-rank structure due to the accumulation of rank-one outer products over a training batch. Despite the attention given to methods that exploit this structure for memory saving or regularization, the emergence of low-rank learning as an inherent aspect of certain DNN architectures has been under-explored. In this paper, we conduct a comprehensive study of gradient rank in DNNs, examining how architectural choices and structure of the data effect gradient rank bounds. Our theoretical analysis provides these bounds for training fully-connected, recurrent, and <b>convolutional</b> <b>neural</b> <b>networks.</b> We also demonstrate, both theoretically and empirically, how design choices like activation function linearity, bottleneck layer introduction, <b>convolutional</b> <b>stride,</b> <b>and</b> sequence truncation influence these bounds. Our findings not only contribute to the understanding of learning dynamics in DNNs, but also provide practical guidance for deep learning engineers to make informed design decisions.

{{</citation>}}


### (28/50 | 56/197) Dynamic Graph Information Bottleneck (Haonan Yuan et al., 2024)

{{<citation>}}

Haonan Yuan, Qingyun Sun, Xingcheng Fu, Cheng Ji, Jianxin Li. (2024)  
**Dynamic Graph Information Bottleneck**
<br/>
<button class="copy-to-clipboard" title="Dynamic Graph Information Bottleneck" index=56>
  <span class="copy-to-clipboard-item">Copy Title<span>
</button>
<div class="toast toast-copied toast-index-56 align-items-center text-bg-secondary border-0 position-absolute top-0 end-0" role="alert" aria-live="assertive" aria-atomic="true">
  <div class="d-flex">
    <div class="toast-body">
      Copied!
    </div>
  </div>
</div>

---
Primary Category: cs.LG  
Categories: cs-AI, cs-LG, cs.LG  
Keyword Score: 20  
Keywords: Graph Neural Network, Adversarial Attack  
<a type="button" class="btn btn-outline-primary" href="http://arxiv.org/abs/2402.06716v1" target="_blank" >Paper Link</a>
<button type="button" class="btn btn-outline-primary download-pdf" url="https://arxiv.org/pdf/2402.06716v1.pdf" filename="2402.06716v1.pdf">Download PDF</button>

---


**ABSTRACT**  
Dynamic <b>Graphs</b> <b>widely</b> <b>exist</b> in the real world, which carry complicated spatial and temporal feature patterns, challenging their representation learning. Dynamic <b>Graph</b> <b>Neural</b> <b>Networks</b> (DGNNs) have shown impressive predictive abilities by exploiting the intrinsic dynamics. However, DGNNs exhibit limited robustness, prone to <b>adversarial</b> <b>attacks.</b> This paper presents the novel Dynamic <b>Graph</b> <b>Information</b> <b>Bottleneck</b> (DGIB) framework to learn robust and discriminative representations. Leveraged by the Information Bottleneck (IB) principle, we first propose the expected optimal representations should satisfy the Minimal-Sufficient-Consensual (MSC) Condition. To compress redundant as well as conserve meritorious information into latent representation, DGIB iteratively directs and refines the structural and feature information flow passing through <b>graph</b> <b>snapshots.</b> <b>To</b> meet the MSC Condition, we decompose the overall IB objectives into DGIB$_{MS}$ and DGIB$_C$, in which the DGIB$_{MS}$ channel aims to learn the minimal and sufficient representations, with the DGIB$_{MS}$ channel guarantees the predictive consensus. Extensive experiments on real-world and synthetic dynamic <b>graph</b> <b>datasets</b> <b>demonstrate</b> the superior robustness of DGIB against <b>adversarial</b> <b>attacks</b> compared with state-of-the-art baselines in the link prediction task. To the best of our knowledge, DGIB is the first work to learn robust representations of dynamic <b>graphs</b> <b>grounded</b> <b>in</b> the information-theoretic IB principle.

{{</citation>}}


### (29/50 | 57/197) Fairness of Exposure in Online Restless Multi-armed Bandits (Archit Sood et al., 2024)

{{<citation>}}

Archit Sood, Shweta Jain, Sujit Gujar. (2024)  
**Fairness of Exposure in Online Restless Multi-armed Bandits**
<br/>
<button class="copy-to-clipboard" title="Fairness of Exposure in Online Restless Multi-armed Bandits" index=57>
  <span class="copy-to-clipboard-item">Copy Title<span>
</button>
<div class="toast toast-copied toast-index-57 align-items-center text-bg-secondary border-0 position-absolute top-0 end-0" role="alert" aria-live="assertive" aria-atomic="true">
  <div class="d-flex">
    <div class="toast-body">
      Copied!
    </div>
  </div>
</div>

---
Primary Category: cs.LG  
Categories: cs-LG, cs.LG, stat-ML  
Keyword Score: 20  
Keywords: Bandit Algorithm, Fairness  
<a type="button" class="btn btn-outline-primary" href="http://arxiv.org/abs/2402.06348v1" target="_blank" >Paper Link</a>
<button type="button" class="btn btn-outline-primary download-pdf" url="https://arxiv.org/pdf/2402.06348v1.pdf" filename="2402.06348v1.pdf">Download PDF</button>

---


**ABSTRACT**  
Restless multi-armed <b>bandits</b> (RMABs) generalize the multi-armed <b>bandits</b> where each arm exhibits Markovian behavior and transitions according to their transition dynamics. Solutions to RMAB exist for both offline and online cases. However, they do not consider the distribution of pulls among the arms. Studies have shown that optimal policies lead to unfairness, where some arms are not exposed enough. Existing works in <b>fairness</b> in RMABs focus heavily on the offline case, which diminishes their application in real-world scenarios where the environment is largely unknown. In the online scenario, we propose the first fair RMAB framework, where each arm receives pulls in proportion to its merit. We define the merit of an arm as a function of its stationary reward distribution. We prove that our algorithm achieves sublinear <b>fairness</b> regret in the single pull case $O(\sqrt{T\ln T})$, with $T$ being the total number of episodes. Empirically, we show that our algorithm performs well in the multi-pull scenario as well.

{{</citation>}}


### (30/50 | 58/197) How Uniform Random Weights Induce Non-uniform Bias: Typical Interpolating Neural Networks Generalize with Narrow Teachers (Gon Buzaglo et al., 2024)

{{<citation>}}

Gon Buzaglo, Itamar Harel, Mor Shpigel Nacson, Alon Brutzkus, Nathan Srebro, Daniel Soudry. (2024)  
**How Uniform Random Weights Induce Non-uniform Bias: Typical Interpolating Neural Networks Generalize with Narrow Teachers**
<br/>
<button class="copy-to-clipboard" title="How Uniform Random Weights Induce Non-uniform Bias: Typical Interpolating Neural Networks Generalize with Narrow Teachers" index=58>
  <span class="copy-to-clipboard-item">Copy Title<span>
</button>
<div class="toast toast-copied toast-index-58 align-items-center text-bg-secondary border-0 position-absolute top-0 end-0" role="alert" aria-live="assertive" aria-atomic="true">
  <div class="d-flex">
    <div class="toast-body">
      Copied!
    </div>
  </div>
</div>

---
Primary Category: cs.LG  
Categories: cs-LG, cs.LG, stat-ML  
Keyword Score: 20  
Keywords: Stochastic Gradient Descent, Stochastic Gradient Descent  
<a type="button" class="btn btn-outline-primary" href="http://arxiv.org/abs/2402.06323v1" target="_blank" >Paper Link</a>
<button type="button" class="btn btn-outline-primary download-pdf" url="https://arxiv.org/pdf/2402.06323v1.pdf" filename="2402.06323v1.pdf">Download PDF</button>

---


**ABSTRACT**  
Background. A main theoretical puzzle is why over-parameterized Neural Networks (NNs) generalize well when trained to zero loss (i.e., so they interpolate the data). Usually, the NN is trained with <b>Stochastic</b> <b>Gradient</b> <b>Descent</b> <b>(SGD)</b> or one of its variants. However, recent empirical work examined the generalization of a random NN that interpolates the data: the NN was sampled from a seemingly uniform prior over the parameters, conditioned on that the NN perfectly classifying the training set. Interestingly, such a NN sample typically generalized as well as <b>SGD-trained</b> NNs. Contributions. We prove that such a random NN interpolator typically generalizes well if there exists an underlying narrow ``teacher NN" that agrees with the labels. Specifically, we show that such a `flat' prior over the NN parametrization induces a rich prior over the NN functions, due to the redundancy in the NN structure. In particular, this creates a bias towards simpler functions, which require less relevant parameters to represent -- enabling learning with a sample complexity approximately proportional to the complexity of the teacher (roughly, the number of non-redundant parameters), rather than the student's.

{{</citation>}}


### (31/50 | 59/197) TimEHR: Image-based Time Series Generation for Electronic Health Records (Hojjat Karami et al., 2024)

{{<citation>}}

Hojjat Karami, Mary-Anne Hartley, David Atienza, Anisoara Ionescu. (2024)  
**TimEHR: Image-based Time Series Generation for Electronic Health Records**
<br/>
<button class="copy-to-clipboard" title="TimEHR: Image-based Time Series Generation for Electronic Health Records" index=59>
  <span class="copy-to-clipboard-item">Copy Title<span>
</button>
<div class="toast toast-copied toast-index-59 align-items-center text-bg-secondary border-0 position-absolute top-0 end-0" role="alert" aria-live="assertive" aria-atomic="true">
  <div class="d-flex">
    <div class="toast-body">
      Copied!
    </div>
  </div>
</div>

---
Primary Category: cs.LG  
Categories: cs-LG, cs.LG  
Keyword Score: 20  
Keywords: Generative Adversarial Network, Generative Adversarial Network  
<a type="button" class="btn btn-outline-primary" href="http://arxiv.org/abs/2402.06318v1" target="_blank" >Paper Link</a>
<button type="button" class="btn btn-outline-primary download-pdf" url="https://arxiv.org/pdf/2402.06318v1.pdf" filename="2402.06318v1.pdf">Download PDF</button>

---


**ABSTRACT**  
Time series in Electronic Health Records (EHRs) present unique challenges for <b>generative</b> <b>models,</b> <b>such</b> as irregular sampling, missing values, and high dimensionality. In this paper, we propose a novel <b>generative</b> <b>adversarial</b> <b>network</b> <b>(GAN)</b> model, TimEHR, to generate time series data from EHRs. In particular, TimEHR treats time series as images and is based on two conditional <b>GANs.</b> The first <b>GAN</b> generates missingness patterns, and the second <b>GAN</b> generates time series values based on the missingness pattern. Experimental results on three real-world EHR datasets show that TimEHR outperforms state-of-the-art methods in terms of fidelity, utility, and privacy metrics.

{{</citation>}}


### (32/50 | 60/197) Iterated Denoising Energy Matching for Sampling from Boltzmann Densities (Tara Akhound-Sadegh et al., 2024)

{{<citation>}}

Tara Akhound-Sadegh, Jarrid Rector-Brooks, Avishek Joey Bose, Sarthak Mittal, Pablo Lemos, Cheng-Hao Liu, Marcin Sendera, Siamak Ravanbakhsh, Gauthier Gidel, Yoshua Bengio, Nikolay Malkin, Alexander Tong. (2024)  
**Iterated Denoising Energy Matching for Sampling from Boltzmann Densities**
<br/>
<button class="copy-to-clipboard" title="Iterated Denoising Energy Matching for Sampling from Boltzmann Densities" index=60>
  <span class="copy-to-clipboard-item">Copy Title<span>
</button>
<div class="toast toast-copied toast-index-60 align-items-center text-bg-secondary border-0 position-absolute top-0 end-0" role="alert" aria-live="assertive" aria-atomic="true">
  <div class="d-flex">
    <div class="toast-body">
      Copied!
    </div>
  </div>
</div>

---
Primary Category: cs.LG  
Categories: cs-LG, cs.LG, stat-ML  
Keyword Score: 20  
Keywords: Simulation, Simulator  
<a type="button" class="btn btn-outline-primary" href="http://arxiv.org/abs/2402.06121v1" target="_blank" >Paper Link</a>
<button type="button" class="btn btn-outline-primary download-pdf" url="https://arxiv.org/pdf/2402.06121v1.pdf" filename="2402.06121v1.pdf">Download PDF</button>

---


**ABSTRACT**  
Efficiently generating statistically independent samples from an unnormalized probability distribution, such as equilibrium samples of many-body systems, is a foundational problem in science. In this paper, we propose Iterated Denoising Energy Matching (iDEM), an iterative algorithm that uses a novel stochastic score matching objective leveraging solely the energy function and its gradient -- and no data samples -- to train a diffusion-based sampler. Specifically, iDEM alternates between (I) sampling regions of high model density from a diffusion-based sampler and (II) using these samples in our stochastic matching objective to further improve the sampler. iDEM is scalable to high dimensions as the inner matching objective, is <b>simulation-free,</b> and requires no MCMC samples. Moreover, by leveraging the fast mode mixing behavior of diffusion, iDEM smooths out the energy landscape enabling efficient exploration and learning of an amortized sampler. We evaluate iDEM on a suite of tasks ranging from standard synthetic energy functions to invariant $n$-body particle systems. We show that the proposed approach achieves state-of-the-art performance on all metrics and trains $2-5\times$ faster, which allows it to be the first method to train using energy on the challenging $55$-particle Lennard-Jones system.

{{</citation>}}


### (33/50 | 61/197) Multimodal Clinical Trial Outcome Prediction with Large Language Models (Wenhao Zheng et al., 2024)

{{<citation>}}

Wenhao Zheng, Dongsheng Peng, Hongxia Xu, Hongtu Zhu, Tianfan Fu, Huaxiu Yao. (2024)  
**Multimodal Clinical Trial Outcome Prediction with Large Language Models**
<br/>
<button class="copy-to-clipboard" title="Multimodal Clinical Trial Outcome Prediction with Large Language Models" index=61>
  <span class="copy-to-clipboard-item">Copy Title<span>
</button>
<div class="toast toast-copied toast-index-61 align-items-center text-bg-secondary border-0 position-absolute top-0 end-0" role="alert" aria-live="assertive" aria-atomic="true">
  <div class="d-flex">
    <div class="toast-body">
      Copied!
    </div>
  </div>
</div>

---
Primary Category: cs.LG  
Categories: cs-CL, cs-LG, cs.LG  
Keyword Score: 16  
Keywords: Multi-modal, Multi-modal, Large Language Model  
<a type="button" class="btn btn-outline-primary" href="http://arxiv.org/abs/2402.06512v1" target="_blank" >Paper Link</a>
<button type="button" class="btn btn-outline-primary download-pdf" url="https://arxiv.org/pdf/2402.06512v1.pdf" filename="2402.06512v1.pdf">Download PDF</button>

---


**ABSTRACT**  
The clinical trial is a pivotal and costly process, often spanning multiple years and requiring substantial financial resources. Therefore, the development of clinical trial outcome prediction models aims to exclude drugs likely to fail and holds the potential for significant cost savings. Recent data-driven attempts leverage deep learning methods to integrate <b>multimodal</b> data for predicting clinical trial outcomes. However, these approaches rely on manually designed modal-specific encoders, which limits both the extensibility to adapt new modalities and the ability to discern similar information patterns across different modalities. To address these issues, we propose a <b>multimodal</b> mixture-of-experts (LIFTED) approach for clinical trial outcome prediction. Specifically, LIFTED unifies different modality data by transforming them into natural language descriptions. Then, LIFTED constructs unified noise-resilient encoders to extract information from modal-specific language descriptions. Subsequently, a sparse Mixture-of-Experts framework is employed to further refine the representations, enabling LIFTED to identify similar information patterns across different modalities and extract more consistent representations from those patterns using the same expert model. Finally, a mixture-of-experts module is further employed to dynamically integrate different modality representations for prediction, which gives LIFTED the ability to automatically weigh different modalities and pay more attention to critical information. The experiments demonstrate that LIFTED significantly enhances performance in predicting clinical trial outcomes across all three phases compared to the best baseline, showcasing the effectiveness of our proposed key components.

{{</citation>}}


### (34/50 | 62/197) Multimodal Interpretable Data-Driven Models for Early Prediction of Antimicrobial Multidrug Resistance Using Multivariate Time-Series (Sergio Martínez-Agüero et al., 2024)

{{<citation>}}

Sergio Martínez-Agüero, Antonio G. Marques, Inmaculada Mora-Jiménez, Joaquín Alvárez-Rodríguez, Cristina Soguero-Ruiza. (2024)  
**Multimodal Interpretable Data-Driven Models for Early Prediction of Antimicrobial Multidrug Resistance Using Multivariate Time-Series**
<br/>
<button class="copy-to-clipboard" title="Multimodal Interpretable Data-Driven Models for Early Prediction of Antimicrobial Multidrug Resistance Using Multivariate Time-Series" index=62>
  <span class="copy-to-clipboard-item">Copy Title<span>
</button>
<div class="toast toast-copied toast-index-62 align-items-center text-bg-secondary border-0 position-absolute top-0 end-0" role="alert" aria-live="assertive" aria-atomic="true">
  <div class="d-flex">
    <div class="toast-body">
      Copied!
    </div>
  </div>
</div>

---
Primary Category: cs.LG  
Categories: cs-LG, cs.LG, q-bio-QM  
Keyword Score: 16  
Keywords: Multi-modal, Multi-modal, Neural Machine Translation  
<a type="button" class="btn btn-outline-primary" href="http://arxiv.org/abs/2402.06295v1" target="_blank" >Paper Link</a>
<button type="button" class="btn btn-outline-primary download-pdf" url="https://arxiv.org/pdf/2402.06295v1.pdf" filename="2402.06295v1.pdf">Download PDF</button>

---


**ABSTRACT**  
Electronic health records (EHR) is an inherently <b>multimodal</b> register of the patient's health status characterized by static data and multivariate time series <b>(MTS).</b> While <b>MTS</b> are a valuable tool for clinical prediction, their fusion with other data modalities can possibly result in more thorough insights and more accurate results. Deep neural networks (DNNs) have emerged as fundamental tools for identifying and defining underlying patterns in the healthcare domain. However, fundamental improvements in interpretability are needed for DNN models to be widely used in the clinical setting. In this study, we present an approach built on a collection of interpretable <b>multimodal</b> data-driven models that may anticipate and understand the emergence of antimicrobial multidrug resistance (AMR) germs in the intensive care unit (ICU) of the University Hospital of Fuenlabrada (Madrid, Spain). The profile and initial health status of the patient are modeled using static variables, while the evolution of the patient's health status during the ICU stay is modeled using several <b>MTS,</b> including mechanical ventilation and antibiotics intake. The <b>multimodal</b> DNNs models proposed in this paper include interpretable principles in addition to being effective at predicting AMR and providing an explainable prediction support system for AMR in the ICU. Furthermore, our proposed methodology based on <b>multimodal</b> models and interpretability schemes can be leveraged in additional clinical problems dealing with EHR data, broadening the impact and applicability of our results.

{{</citation>}}


### (35/50 | 63/197) Improved Evidential Deep Learning via a Mixture of Dirichlet Distributions (J. Jon Ryu et al., 2024)

{{<citation>}}

J. Jon Ryu, Maohao Shen, Soumya Ghosh, Yuheng Bu, Prasanna Sattigeri, Subhro Das, Gregory W. Wornell. (2024)  
**Improved Evidential Deep Learning via a Mixture of Dirichlet Distributions**
<br/>
<button class="copy-to-clipboard" title="Improved Evidential Deep Learning via a Mixture of Dirichlet Distributions" index=63>
  <span class="copy-to-clipboard-item">Copy Title<span>
</button>
<div class="toast toast-copied toast-index-63 align-items-center text-bg-secondary border-0 position-absolute top-0 end-0" role="alert" aria-live="assertive" aria-atomic="true">
  <div class="d-flex">
    <div class="toast-body">
      Copied!
    </div>
  </div>
</div>

---
Primary Category: cs.LG  
Categories: cs-LG, cs.LG, stat-ML  
Keyword Score: 13  
Keywords: Knowledge Distillation, Sample Size  
<a type="button" class="btn btn-outline-primary" href="http://arxiv.org/abs/2402.06160v1" target="_blank" >Paper Link</a>
<button type="button" class="btn btn-outline-primary download-pdf" url="https://arxiv.org/pdf/2402.06160v1.pdf" filename="2402.06160v1.pdf">Download PDF</button>

---


**ABSTRACT**  
This paper explores a modern predictive uncertainty estimation approach, called evidential deep learning (EDL), in which a single neural network model is trained to learn a meta distribution over the predictive distribution by minimizing a specific objective function. Despite their strong empirical performance, recent studies by Bengs et al. identify a fundamental pitfall of the existing methods: the learned epistemic uncertainty may not vanish even in the infinite-sample limit. We corroborate the observation by providing a unifying view of a class of widely used objectives from the literature. Our analysis reveals that the EDL methods essentially train a meta distribution by minimizing a certain divergence measure between the distribution and a <b>sample-size-independent</b> <b>target</b> distribution, resulting in spurious epistemic uncertainty. Grounded in theoretical principles, we propose learning a consistent target distribution by modeling it with a mixture of Dirichlet distributions and learning via variational inference. Afterward, a final meta distribution model <b>distills</b> the learned uncertainty from the target model. Experimental results across various uncertainty-based downstream tasks demonstrate the superiority of our proposed method, and illustrate the practical implications arising from the consistency and inconsistency of learned epistemic uncertainty.

{{</citation>}}


### (36/50 | 64/197) Generative Nowcasting of Marine Fog Visibility in the Grand Banks area and Sable Island in Canada (Eren Gultepe et al., 2024)

{{<citation>}}

Eren Gultepe, Sen Wang, Byron Blomquist, Harindra J. S. Fernando, O. Patrick Kreidl, David J. Delene, Ismail Gultepe. (2024)  
**Generative Nowcasting of Marine Fog Visibility in the Grand Banks area and Sable Island in Canada**
<br/>
<button class="copy-to-clipboard" title="Generative Nowcasting of Marine Fog Visibility in the Grand Banks area and Sable Island in Canada" index=64>
  <span class="copy-to-clipboard-item">Copy Title<span>
</button>
<div class="toast toast-copied toast-index-64 align-items-center text-bg-secondary border-0 position-absolute top-0 end-0" role="alert" aria-live="assertive" aria-atomic="true">
  <div class="d-flex">
    <div class="toast-body">
      Copied!
    </div>
  </div>
</div>

---
Primary Category: cs.LG  
Categories: cs-LG, cs.LG, physics-ao-ph  
Keyword Score: 10  
Keywords: Generative Adversarial Network  
<a type="button" class="btn btn-outline-primary" href="http://arxiv.org/abs/2402.06800v1" target="_blank" >Paper Link</a>
<button type="button" class="btn btn-outline-primary download-pdf" url="https://arxiv.org/pdf/2402.06800v1.pdf" filename="2402.06800v1.pdf">Download PDF</button>

---


**ABSTRACT**  
This study presents the application of <b>generative</b> <b>deep</b> <b>learning</b> techniques to evaluate marine fog visibility nowcasting using the FATIMA (Fog and turbulence interactions in the marine atmosphere) campaign observations collected during July 2022 in the North Atlantic in the Grand Banks area and vicinity of Sable Island (SI), northeast of Canada. The measurements were collected using the Vaisala Forward Scatter Sensor model FD70 and Weather Transmitter model WXT50, and Gill R3A ultrasonic anemometer mounted on the Research Vessel Atlantic Condor. To perform nowcasting, the time series of fog visibility (Vis), wind speed, dew point depression, and relative humidity with respect to water were preprocessed to have lagged time step features. <b>Generative</b> <b>nowcasting</b> <b>of</b> Vis time series for lead times of 30 and 60 minutes were performed using conditional <b>generative</b> <b>adversarial</b> <b>networks</b> (cGAN) regression at visibility thresholds of Vis < 1 km and < 10 km. Extreme gradient boosting (XGBoost) was used as a baseline method for comparison against cGAN. At the 30 min lead time, Vis was best predicted with cGAN at Vis < 1 km (RMSE = 0.151 km) and with XGBoost at Vis < 10 km (RMSE = 2.821 km). At the 60 min lead time, Vis was best predicted with XGBoost at Vis < 1 km (RMSE = 0.167 km) and Vis < 10 km (RMSE = 3.508 km), but the cGAN RMSE was similar to XGBoost. Despite nowcasting Vis at 30 min being quite difficult, the ability of the cGAN model to track the variation in Vis at 1 km suggests that there is potential for <b>generative</b> <b>analysis</b> <b>of</b> marine fog visibility using observational meteorological parameters.

{{</citation>}}


### (37/50 | 65/197) Scalable Kernel Logistic Regression with Nyström Approximation: Theoretical Analysis and Application to Discrete Choice Modelling (José Ángel Martín-Baos et al., 2024)

{{<citation>}}

José Ángel Martín-Baos, Ricardo García-Ródenas, Luis Rodriguez-Benitez, Michel Bierlaire. (2024)  
**Scalable Kernel Logistic Regression with Nyström Approximation: Theoretical Analysis and Application to Discrete Choice Modelling**
<br/>
<button class="copy-to-clipboard" title="Scalable Kernel Logistic Regression with Nyström Approximation: Theoretical Analysis and Application to Discrete Choice Modelling" index=65>
  <span class="copy-to-clipboard-item">Copy Title<span>
</button>
<div class="toast toast-copied toast-index-65 align-items-center text-bg-secondary border-0 position-absolute top-0 end-0" role="alert" aria-live="assertive" aria-atomic="true">
  <div class="d-flex">
    <div class="toast-body">
      Copied!
    </div>
  </div>
</div>

---
Primary Category: cs.LG  
Categories: cs-LG, cs.LG, stat-ML  
Keyword Score: 10  
Keywords: Logistic Regression  
<a type="button" class="btn btn-outline-primary" href="http://arxiv.org/abs/2402.06763v1" target="_blank" >Paper Link</a>
<button type="button" class="btn btn-outline-primary download-pdf" url="https://arxiv.org/pdf/2402.06763v1.pdf" filename="2402.06763v1.pdf">Download PDF</button>

---


**ABSTRACT**  
The application of kernel-based Machine Learning (ML) techniques to discrete choice modelling using large datasets often faces challenges due to memory requirements and the considerable number of parameters involved in these models. This complexity hampers the efficient training of large-scale models. This paper addresses these problems of scalability by introducing the Nystr\"om approximation for Kernel <b>Logistic</b> <b>Regression</b> (KLR) on large datasets. The study begins by presenting a theoretical analysis in which: i) the set of KLR solutions is characterised, ii) an upper bound to the solution of KLR with Nystr\"om approximation is provided, and finally iii) a specialisation of the optimisation algorithms to Nystr\"om KLR is described. After this, the Nystr\"om KLR is computationally validated. Four landmark selection methods are tested, including basic uniform sampling, a k-means sampling strategy, and two non-uniform methods grounded in leverage scores. The performance of these strategies is evaluated using large-scale transport mode choice datasets and is compared with traditional methods such as Multinomial Logit (MNL) and contemporary ML techniques. The study also assesses the efficiency of various optimisation techniques for the proposed Nystr\"om KLR model. The performance of gradient descent, Momentum, Adam, and L-BFGS-B optimisation methods is examined on these datasets. Among these strategies, the k-means Nystr\"om KLR approach emerges as a successful solution for applying KLR to large datasets, particularly when combined with the L-BFGS-B and Adam optimisation methods. The results highlight the ability of this strategy to handle datasets exceeding 200,000 observations while maintaining robust performance.

{{</citation>}}


### (38/50 | 66/197) Where is the Truth? The Risk of Getting Confounded in a Continual World (Florian Peter Busch et al., 2024)

{{<citation>}}

Florian Peter Busch, Roshni Kamath, Rupert Mitchell, Wolfgang Stammer, Kristian Kersting, Martin Mundt. (2024)  
**Where is the Truth? The Risk of Getting Confounded in a Continual World**
<br/>
<button class="copy-to-clipboard" title="Where is the Truth? The Risk of Getting Confounded in a Continual World" index=66>
  <span class="copy-to-clipboard-item">Copy Title<span>
</button>
<div class="toast toast-copied toast-index-66 align-items-center text-bg-secondary border-0 position-absolute top-0 end-0" role="alert" aria-live="assertive" aria-atomic="true">
  <div class="d-flex">
    <div class="toast-body">
      Copied!
    </div>
  </div>
</div>

---
Primary Category: cs.LG  
Categories: cs-LG, cs.LG, stat-ML  
Keyword Score: 10  
Keywords: Continual Learning  
<a type="button" class="btn btn-outline-primary" href="http://arxiv.org/abs/2402.06434v1" target="_blank" >Paper Link</a>
<button type="button" class="btn btn-outline-primary download-pdf" url="https://arxiv.org/pdf/2402.06434v1.pdf" filename="2402.06434v1.pdf">Download PDF</button>

---


**ABSTRACT**  
A dataset is confounded if it is most easily solved via a spurious correlation which fails to generalize to new data. We will show that, in a <b>continual</b> <b>learning</b> setting where confounders may vary in time across tasks, the resulting challenge far exceeds the standard forgetting problem normally considered. In particular, we derive mathematically the effect of such confounders on the space of valid joint solutions to sets of confounded tasks. Interestingly, our theory predicts that for many such <b>continual</b> <b>datasets,</b> spurious correlations are easily ignored when the tasks are trained on jointly, but it is far harder to avoid confounding when they are considered sequentially. We construct such a dataset and demonstrate empirically that standard <b>continual</b> <b>learning</b> methods fail to ignore confounders, while training jointly on all tasks is successful. Our continually confounded dataset, ConCon, is based on CLEVR images and demonstrates the need for <b>continual</b> <b>learning</b> methods with more robust behavior with respect to confounding.

{{</citation>}}


### (39/50 | 67/197) High-Precision Geosteering via Reinforcement Learning and Particle Filters (Ressi Bonti Muhammad et al., 2024)

{{<citation>}}

Ressi Bonti Muhammad, Apoorv Srivastava, Sergey Alyaev, Reidar Brumer Bratvold, Daniel M. Tartakovsky. (2024)  
**High-Precision Geosteering via Reinforcement Learning and Particle Filters**
<br/>
<button class="copy-to-clipboard" title="High-Precision Geosteering via Reinforcement Learning and Particle Filters" index=67>
  <span class="copy-to-clipboard-item">Copy Title<span>
</button>
<div class="toast toast-copied toast-index-67 align-items-center text-bg-secondary border-0 position-absolute top-0 end-0" role="alert" aria-live="assertive" aria-atomic="true">
  <div class="d-flex">
    <div class="toast-body">
      Copied!
    </div>
  </div>
</div>

---
Primary Category: cs.LG  
Categories: cs-AI, cs-LG, cs.LG, physics-geo-ph  
Keyword Score: 10  
Keywords: Reinforcement Learning  
<a type="button" class="btn btn-outline-primary" href="http://arxiv.org/abs/2402.06377v1" target="_blank" >Paper Link</a>
<button type="button" class="btn btn-outline-primary download-pdf" url="https://arxiv.org/pdf/2402.06377v1.pdf" filename="2402.06377v1.pdf">Download PDF</button>

---


**ABSTRACT**  
Geosteering, a key component of drilling operations, traditionally involves manual interpretation of various data sources such as well-log data. This introduces subjective biases and inconsistent procedures. Academic attempts to solve geosteering decision optimization with greedy optimization and Approximate Dynamic Programming (ADP) showed promise but lacked adaptivity to realistic diverse scenarios. <b>Reinforcement</b> <b>learning</b> (RL) offers a solution to these challenges, facilitating optimal decision-making through reward-based iterative learning. State estimation methods, e.g., particle filter (PF), provide a complementary strategy for geosteering decision-making based on online information. We integrate an RL-based geosteering with PF to address realistic geosteering scenarios. Our framework deploys PF to process real-time well-log data to estimate the location of the well relative to the stratigraphic layers, which then informs the RL-based decision-making process. We compare our method's performance with that of using solely either RL or PF. Our findings indicate a synergy between RL and PF in yielding optimized geosteering decisions.

{{</citation>}}


### (40/50 | 68/197) Continual Learning on Graphs: A Survey (Zonggui Tian et al., 2024)

{{<citation>}}

Zonggui Tian, Du Zhang, Hong-Ning Dai. (2024)  
**Continual Learning on Graphs: A Survey**
<br/>
<button class="copy-to-clipboard" title="Continual Learning on Graphs: A Survey" index=68>
  <span class="copy-to-clipboard-item">Copy Title<span>
</button>
<div class="toast toast-copied toast-index-68 align-items-center text-bg-secondary border-0 position-absolute top-0 end-0" role="alert" aria-live="assertive" aria-atomic="true">
  <div class="d-flex">
    <div class="toast-body">
      Copied!
    </div>
  </div>
</div>

---
Primary Category: cs.LG  
Categories: cs-LG, cs.LG  
Keyword Score: 10  
Keywords: Continual Learning  
<a type="button" class="btn btn-outline-primary" href="http://arxiv.org/abs/2402.06330v1" target="_blank" >Paper Link</a>
<button type="button" class="btn btn-outline-primary download-pdf" url="https://arxiv.org/pdf/2402.06330v1.pdf" filename="2402.06330v1.pdf">Download PDF</button>

---


**ABSTRACT**  
Recently, <b>continual</b> <b>graph</b> learning has been increasingly adopted for diverse graph-structured data processing tasks in non-stationary environments. Despite its promising learning capability, current studies on <b>continual</b> <b>graph</b> learning mainly focus on mitigating the catastrophic forgetting problem while ignoring continuous performance improvement. To bridge this gap, this article aims to provide a comprehensive survey of recent efforts on <b>continual</b> <b>graph</b> learning. Specifically, we introduce a new taxonomy of <b>continual</b> <b>graph</b> learning from the perspective of overcoming catastrophic forgetting. Moreover, we systematically analyze the challenges of applying these <b>continual</b> <b>graph</b> learning methods in improving performance continuously and then discuss the possible solutions. Finally, we present open issues and future directions pertaining to the development of <b>continual</b> <b>graph</b> learning and discuss how they impact continuous performance improvement.

{{</citation>}}


### (41/50 | 69/197) Evaluating Membership Inference Attacks and Defenses in Federated Learning (Gongxi Zhu et al., 2024)

{{<citation>}}

Gongxi Zhu, Donghao Li, Hanlin Gu, Yuxing Han, Yuan Yao, Lixin Fan, Qiang Yang. (2024)  
**Evaluating Membership Inference Attacks and Defenses in Federated Learning**
<br/>
<button class="copy-to-clipboard" title="Evaluating Membership Inference Attacks and Defenses in Federated Learning" index=69>
  <span class="copy-to-clipboard-item">Copy Title<span>
</button>
<div class="toast toast-copied toast-index-69 align-items-center text-bg-secondary border-0 position-absolute top-0 end-0" role="alert" aria-live="assertive" aria-atomic="true">
  <div class="d-flex">
    <div class="toast-body">
      Copied!
    </div>
  </div>
</div>

---
Primary Category: cs.LG  
Categories: cs-CR, cs-LG, cs.LG  
Keyword Score: 10  
Keywords: Federated Learning  
<a type="button" class="btn btn-outline-primary" href="http://arxiv.org/abs/2402.06289v1" target="_blank" >Paper Link</a>
<button type="button" class="btn btn-outline-primary download-pdf" url="https://arxiv.org/pdf/2402.06289v1.pdf" filename="2402.06289v1.pdf">Download PDF</button>

---


**ABSTRACT**  
Membership Inference Attacks (MIAs) pose a growing threat to privacy preservation in <b>federated</b> <b>learning.</b> The semi-honest attacker, e.g., the server, may determine whether a particular sample belongs to a target client according to the observed model information. This paper conducts an evaluation of existing MIAs and corresponding defense strategies. Our evaluation on MIAs reveals two important findings about the trend of MIAs. Firstly, combining model information from multiple communication rounds (Multi-temporal) enhances the overall effectiveness of MIAs compared to utilizing model information from a single epoch. Secondly, incorporating models from non-target clients (Multi-spatial) significantly improves the effectiveness of MIAs, particularly when the clients' data is homogeneous. This highlights the importance of considering the temporal and spatial model information in MIAs. Next, we assess the effectiveness via privacy-utility tradeoff for two type defense mechanisms against MIAs: Gradient Perturbation and Data Replacement. Our results demonstrate that Data Replacement mechanisms achieve a more optimal balance between preserving privacy and maintaining model utility. Therefore, we recommend the adoption of Data Replacement methods as a defense strategy against MIAs. Our code is available in https://github.com/Liar-Mask/FedMIA.

{{</citation>}}


### (42/50 | 70/197) Value function interference and greedy action selection in value-based multi-objective reinforcement learning (Peter Vamplew et al., 2024)

{{<citation>}}

Peter Vamplew, Cameron Foale, Richard Dazeley. (2024)  
**Value function interference and greedy action selection in value-based multi-objective reinforcement learning**
<br/>
<button class="copy-to-clipboard" title="Value function interference and greedy action selection in value-based multi-objective reinforcement learning" index=70>
  <span class="copy-to-clipboard-item">Copy Title<span>
</button>
<div class="toast toast-copied toast-index-70 align-items-center text-bg-secondary border-0 position-absolute top-0 end-0" role="alert" aria-live="assertive" aria-atomic="true">
  <div class="d-flex">
    <div class="toast-body">
      Copied!
    </div>
  </div>
</div>

---
Primary Category: cs.LG  
Categories: cs-LG, cs.LG  
Keyword Score: 10  
Keywords: Reinforcement Learning  
<a type="button" class="btn btn-outline-primary" href="http://arxiv.org/abs/2402.06266v1" target="_blank" >Paper Link</a>
<button type="button" class="btn btn-outline-primary download-pdf" url="https://arxiv.org/pdf/2402.06266v1.pdf" filename="2402.06266v1.pdf">Download PDF</button>

---


**ABSTRACT**  
Multi-objective <b>reinforcement</b> <b>learning</b> (MORL) algorithms extend conventional <b>reinforcement</b> <b>learning</b> (RL) to the more general case of problems with multiple, conflicting objectives, represented by vector-valued rewards. Widely-used scalar RL methods such as Q-learning can be modified to handle multiple objectives by (1) learning vector-valued value functions, and (2) performing action selection using a scalarisation or ordering operator which reflects the user's utility with respect to the different objectives. However, as we demonstrate here, if the user's utility function maps widely varying vector-values to similar levels of utility, this can lead to interference in the value-function learned by the agent, leading to convergence to sub-optimal policies. This will be most prevalent in stochastic environments when optimising for the Expected Scalarised Return criterion, but we present a simple example showing that interference can also arise in deterministic environments. We demonstrate empirically that avoiding the use of random tie-breaking when identifying greedy actions can ameliorate, but not fully overcome, the problems caused by value function interference.

{{</citation>}}


### (43/50 | 71/197) Pushing Boundaries: Mixup's Influence on Neural Collapse (Quinn Fisher et al., 2024)

{{<citation>}}

Quinn Fisher, Haoming Meng, Vardan Papyan. (2024)  
**Pushing Boundaries: Mixup's Influence on Neural Collapse**
<br/>
<button class="copy-to-clipboard" title="Pushing Boundaries: Mixup's Influence on Neural Collapse" index=71>
  <span class="copy-to-clipboard-item">Copy Title<span>
</button>
<div class="toast toast-copied toast-index-71 align-items-center text-bg-secondary border-0 position-absolute top-0 end-0" role="alert" aria-live="assertive" aria-atomic="true">
  <div class="d-flex">
    <div class="toast-body">
      Copied!
    </div>
  </div>
</div>

---
Primary Category: cs.LG  
Categories: cs-LG, cs.LG  
Keyword Score: 10  
Keywords: Data Augmentation  
<a type="button" class="btn btn-outline-primary" href="http://arxiv.org/abs/2402.06171v1" target="_blank" >Paper Link</a>
<button type="button" class="btn btn-outline-primary download-pdf" url="https://arxiv.org/pdf/2402.06171v1.pdf" filename="2402.06171v1.pdf">Download PDF</button>

---


**ABSTRACT**  
Mixup is a <b>data</b> <b>augmentation</b> strategy that employs convex combinations of training instances and their respective labels to augment the robustness and calibration of deep neural networks. Despite its widespread adoption, the nuanced mechanisms that underpin its success are not entirely understood. The observed phenomenon of Neural Collapse, where the last-layer activations and classifier of deep networks converge to a simplex equiangular tight frame (ETF), provides a compelling motivation to explore whether mixup induces alternative geometric configurations and whether those could explain its success. In this study, we delve into the last-layer activations of training <b>data</b> <b>for</b> deep networks subjected to mixup, aiming to uncover insights into its operational efficacy. Our investigation, spanning various architectures and dataset pairs, reveals that mixup's last-layer activations predominantly converge to a distinctive configuration different than one might expect. In this configuration, activations from mixed-up examples of identical classes align with the classifier, while those from different classes delineate channels along the decision boundary. Moreover, activations in earlier layers exhibit patterns, as if trained with manifold mixup. These findings are unexpected, as mixed-up features are not simple convex combinations of feature class means (as one might get, for example, by training mixup with the mean squared error loss). By analyzing this distinctive geometric configuration, we elucidate the mechanisms by which mixup enhances model calibration. To further validate our empirical observations, we conduct a theoretical analysis under the assumption of an unconstrained features model, utilizing the mixup loss. Through this, we characterize and derive the optimal last-layer features under the assumption that the classifier forms a simplex ETF.

{{</citation>}}


### (44/50 | 72/197) Domain Generalization with Small Data (Kecheng Chen et al., 2024)

{{<citation>}}

Kecheng Chen, Elena Gal, Hong Yan, Haoliang Li. (2024)  
**Domain Generalization with Small Data**
<br/>
<button class="copy-to-clipboard" title="Domain Generalization with Small Data" index=72>
  <span class="copy-to-clipboard-item">Copy Title<span>
</button>
<div class="toast toast-copied toast-index-72 align-items-center text-bg-secondary border-0 position-absolute top-0 end-0" role="alert" aria-live="assertive" aria-atomic="true">
  <div class="d-flex">
    <div class="toast-body">
      Copied!
    </div>
  </div>
</div>

---
Primary Category: cs.LG  
Categories: cs-CV, cs-LG, cs.LG  
Keyword Score: 10  
Keywords: Probabilistic Model  
<a type="button" class="btn btn-outline-primary" href="http://arxiv.org/abs/2402.06150v1" target="_blank" >Paper Link</a>
<button type="button" class="btn btn-outline-primary download-pdf" url="https://arxiv.org/pdf/2402.06150v1.pdf" filename="2402.06150v1.pdf">Download PDF</button>

---


**ABSTRACT**  
In this work, we propose to tackle the problem of domain generalization in the context of \textit{insufficient samples}. Instead of extracting latent feature embeddings based on deterministic models, we propose to learn a domain-invariant representation based on the <b>probabilistic</b> <b>framework</b> by mapping each data point into <b>probabilistic</b> <b>embeddings.</b> Specifically, we first extend empirical maximum mean discrepancy (MMD) to a novel <b>probabilistic</b> <b>MMD</b> that can measure the discrepancy between mixture distributions (i.e., source domains) consisting of a series of latent distributions rather than latent points. Moreover, instead of imposing the contrastive semantic alignment (CSA) loss based on pairs of latent points, a novel <b>probabilistic</b> <b>CSA</b> loss encourages positive <b>probabilistic</b> <b>embedding</b> pairs to be closer while pulling other negative ones apart. Benefiting from the learned representation captured by <b>probabilistic</b> <b>models,</b> our proposed method can marriage the measurement on the \textit{distribution over distributions} (i.e., the global perspective alignment) and the distribution-based contrastive semantic alignment (i.e., the local perspective alignment). Extensive experimental results on three challenging medical datasets show the effectiveness of our proposed method in the context of insufficient data compared with state-of-the-art methods.

{{</citation>}}


### (45/50 | 73/197) Revealing Multimodal Contrastive Representation Learning through Latent Partial Causal Models (Yuhang Liu et al., 2024)

{{<citation>}}

Yuhang Liu, Zhen Zhang, Dong Gong, Biwei Huang, Mingming Gong, Anton van den Hengel, Kun Zhang, Javen Qinfeng Shi. (2024)  
**Revealing Multimodal Contrastive Representation Learning through Latent Partial Causal Models**
<br/>
<button class="copy-to-clipboard" title="Revealing Multimodal Contrastive Representation Learning through Latent Partial Causal Models" index=73>
  <span class="copy-to-clipboard-item">Copy Title<span>
</button>
<div class="toast toast-copied toast-index-73 align-items-center text-bg-secondary border-0 position-absolute top-0 end-0" role="alert" aria-live="assertive" aria-atomic="true">
  <div class="d-flex">
    <div class="toast-body">
      Copied!
    </div>
  </div>
</div>

---
Primary Category: cs.LG  
Categories: cs-CV, cs-LG, cs.LG, stat-ML  
Keyword Score: 6  
Keywords: Multi-modal, Multi-modal  
<a type="button" class="btn btn-outline-primary" href="http://arxiv.org/abs/2402.06223v1" target="_blank" >Paper Link</a>
<button type="button" class="btn btn-outline-primary download-pdf" url="https://arxiv.org/pdf/2402.06223v1.pdf" filename="2402.06223v1.pdf">Download PDF</button>

---


**ABSTRACT**  
<b>Multimodal</b> contrastive representation learning methods have proven successful across a range of domains, partly due to their ability to generate meaningful shared representations of complex phenomena. To enhance the depth of analysis and understanding of these acquired representations, we introduce a unified causal model specifically designed for <b>multimodal</b> data. By examining this model, we show that <b>multimodal</b> contrastive representation learning excels at identifying latent coupled variables within the proposed unified model, up to linear or permutation transformations resulting from different assumptions. Our findings illuminate the potential of pre-trained <b>multimodal</b> models, eg, CLIP, in learning disentangled representations through a surprisingly simple yet highly effective tool: linear independent component analysis. Experiments demonstrate the robustness of our findings, even when the assumptions are violated, and validate the effectiveness of the proposed method in learning disentangled representations.

{{</citation>}}


### (46/50 | 74/197) A Kalman Filter Based Framework for Monitoring the Performance of In-Hospital Mortality Prediction Models Over Time (Jiacheng Liu et al., 2024)

{{<citation>}}

Jiacheng Liu, Lisa Kirkland, Jaideep Srivastava. (2024)  
**A Kalman Filter Based Framework for Monitoring the Performance of In-Hospital Mortality Prediction Models Over Time**
<br/>
<button class="copy-to-clipboard" title="A Kalman Filter Based Framework for Monitoring the Performance of In-Hospital Mortality Prediction Models Over Time" index=74>
  <span class="copy-to-clipboard-item">Copy Title<span>
</button>
<div class="toast toast-copied toast-index-74 align-items-center text-bg-secondary border-0 position-absolute top-0 end-0" role="alert" aria-live="assertive" aria-atomic="true">
  <div class="d-flex">
    <div class="toast-body">
      Copied!
    </div>
  </div>
</div>

---
Primary Category: cs.LG  
Categories: cs-LG, cs.LG  
Keyword Score: 3  
Keywords: Sample Size  
<a type="button" class="btn btn-outline-primary" href="http://arxiv.org/abs/2402.06812v1" target="_blank" >Paper Link</a>
<button type="button" class="btn btn-outline-primary download-pdf" url="https://arxiv.org/pdf/2402.06812v1.pdf" filename="2402.06812v1.pdf">Download PDF</button>

---


**ABSTRACT**  
Unlike in a clinical trial, where researchers get to determine the least number of positive and negative <b>samples</b> <b>required,</b> or in a machine learning study where the size and the class distribution of the validation set is static and known, in a real-world scenario, there is little control over the size and distribution of incoming patients. As a result, when measured during different time periods, evaluation metrics like Area under the Receiver Operating Curve (AUCROC) and Area Under the Precision-Recall Curve(AUCPR) may not be directly comparable. Therefore, in this study, for binary classifiers running in a long time period, we proposed to adjust these performance metrics for <b>sample</b> <b>size</b> and class distribution, so that a fair comparison can be made between two time periods. Note that the number of <b>samples</b> <b>and</b> the class distribution, namely the ratio of positive <b>samples,</b> <b>are</b> two robustness factors which affect the variance of AUCROC. To better estimate the mean of performance metrics and understand the change of performance over time, we propose a Kalman filter based framework with extrapolated variance adjusted for the total number of <b>samples</b> <b>and</b> the number of positive <b>samples</b> <b>during</b> different time periods. The efficacy of this method is demonstrated first on a synthetic dataset and then retrospectively applied to a 2-days ahead in-hospital mortality prediction model for COVID-19 patients during 2021 and 2022. Further, we conclude that our prediction model is not significantly affected by the evolution of the disease, improved treatments and changes in hospital operational plans.

{{</citation>}}


### (47/50 | 75/197) Refining Myocardial Infarction Detection: A Novel Multi-Modal Composite Kernel Strategy in One-Class Classification (Muhammad Uzair Zahid et al., 2024)

{{<citation>}}

Muhammad Uzair Zahid, Aysen Degerli, Fahad Sohrab, Serkan Kiranyaz, Moncef Gabbouj. (2024)  
**Refining Myocardial Infarction Detection: A Novel Multi-Modal Composite Kernel Strategy in One-Class Classification**
<br/>
<button class="copy-to-clipboard" title="Refining Myocardial Infarction Detection: A Novel Multi-Modal Composite Kernel Strategy in One-Class Classification" index=75>
  <span class="copy-to-clipboard-item">Copy Title<span>
</button>
<div class="toast toast-copied toast-index-75 align-items-center text-bg-secondary border-0 position-absolute top-0 end-0" role="alert" aria-live="assertive" aria-atomic="true">
  <div class="d-flex">
    <div class="toast-body">
      Copied!
    </div>
  </div>
</div>

---
Primary Category: cs.LG  
Categories: cs-AI, cs-LG, cs.LG, eess-SP  
Keyword Score: 3  
Keywords: Multi-modal  
<a type="button" class="btn btn-outline-primary" href="http://arxiv.org/abs/2402.06530v1" target="_blank" >Paper Link</a>
<button type="button" class="btn btn-outline-primary download-pdf" url="https://arxiv.org/pdf/2402.06530v1.pdf" filename="2402.06530v1.pdf">Download PDF</button>

---


**ABSTRACT**  
Early detection of myocardial infarction (MI), a critical condition arising from coronary artery disease (CAD), is vital to prevent further myocardial damage. This study introduces a novel method for early MI detection using a one-class classification (OCC) algorithm in echocardiography. Our study overcomes the challenge of limited echocardiography data availability by adopting a novel approach based on <b>Multi-modal</b> Subspace Support Vector Data Description. The proposed technique involves a specialized MI detection framework employing multi-view echocardiography incorporating a composite kernel in the non-linear projection trick, fusing Gaussian and Laplacian sigmoid functions. Additionally, we enhance the update strategy of the projection matrices by adapting maximization for both or one of the modalities in the optimization process. Our method boosts MI detection capability by efficiently transforming features extracted from echocardiography data into an optimized lower-dimensional subspace. The OCC model trained specifically on target class instances from the comprehensive HMC-QU dataset that includes multiple echocardiography views indicates a marked improvement in MI detection accuracy. Our findings reveal that our proposed multi-view approach achieves a geometric mean of 71.24\%, signifying a substantial advancement in echocardiography-based MI diagnosis and offering more precise and efficient diagnostic tools.

{{</citation>}}


### (48/50 | 76/197) Electricity Price Forecasting in the Irish Balancing Market (Ciaran O'Connor et al., 2024)

{{<citation>}}

Ciaran O'Connor, Joseph Collins, Steven Prestwich, Andrea Visentin. (2024)  
**Electricity Price Forecasting in the Irish Balancing Market**
<br/>
<button class="copy-to-clipboard" title="Electricity Price Forecasting in the Irish Balancing Market" index=76>
  <span class="copy-to-clipboard-item">Copy Title<span>
</button>
<div class="toast toast-copied toast-index-76 align-items-center text-bg-secondary border-0 position-absolute top-0 end-0" role="alert" aria-live="assertive" aria-atomic="true">
  <div class="d-flex">
    <div class="toast-body">
      Copied!
    </div>
  </div>
</div>

---
Primary Category: cs.LG  
Categories: cs-LG, cs.LG, q-fin-PR  
Keyword Score: 3  
Keywords: Benchmarking  
<a type="button" class="btn btn-outline-primary" href="http://arxiv.org/abs/2402.06714v1" target="_blank" >Paper Link</a>
<button type="button" class="btn btn-outline-primary download-pdf" url="https://arxiv.org/pdf/2402.06714v1.pdf" filename="2402.06714v1.pdf">Download PDF</button>

---


**ABSTRACT**  
Short-term electricity markets are becoming more relevant due to less-predictable renewable energy sources, attracting considerable attention from the industry. The balancing market is the closest to real-time and the most volatile among them. Its price forecasting literature is limited, inconsistent and outdated, with few deep learning attempts and no public dataset. This work applies to the Irish balancing market a variety of price prediction techniques proven successful in the widely studied day-ahead market. We compare statistical, machine learning, and deep learning models using a framework that investigates the impact of different training sizes. The framework defines hyperparameters and calibration settings; the dataset and models are made public to ensure reproducibility and to be used as <b>benchmarks</b> for future works. An extensive numerical study shows that well-performing models in the day-ahead market do not perform well in the balancing one, highlighting that these markets are fundamentally different constructs. The best model is LEAR, a statistical approach based on LASSO, which outperforms more complex and computationally demanding approaches.

{{</citation>}}


### (49/50 | 77/197) An Algorithmic Framework for Constructing Multiple Decision Trees by Evaluating Their Combination Performance Throughout the Construction Process (Keito Tajima et al., 2024)

{{<citation>}}

Keito Tajima, Naoki Ichijo, Yuta Nakahara, Toshiyasu Matsushima. (2024)  
**An Algorithmic Framework for Constructing Multiple Decision Trees by Evaluating Their Combination Performance Throughout the Construction Process**
<br/>
<button class="copy-to-clipboard" title="An Algorithmic Framework for Constructing Multiple Decision Trees by Evaluating Their Combination Performance Throughout the Construction Process" index=77>
  <span class="copy-to-clipboard-item">Copy Title<span>
</button>
<div class="toast toast-copied toast-index-77 align-items-center text-bg-secondary border-0 position-absolute top-0 end-0" role="alert" aria-live="assertive" aria-atomic="true">
  <div class="d-flex">
    <div class="toast-body">
      Copied!
    </div>
  </div>
</div>

---
Primary Category: cs.LG  
Categories: cs-LG, cs.LG  
Keyword Score: 3  
Keywords: Benchmarking  
<a type="button" class="btn btn-outline-primary" href="http://arxiv.org/abs/2402.06452v1" target="_blank" >Paper Link</a>
<button type="button" class="btn btn-outline-primary download-pdf" url="https://arxiv.org/pdf/2402.06452v1.pdf" filename="2402.06452v1.pdf">Download PDF</button>

---


**ABSTRACT**  
Predictions using a combination of decision trees are known to be effective in machine learning. Typical ideas for constructing a combination of decision trees for prediction are bagging and boosting. Bagging independently constructs decision trees without evaluating their combination performance and averages them afterward. Boosting constructs decision trees sequentially, only evaluating a combination performance of a new decision tree and the fixed past decision trees at each step. Therefore, neither method directly constructs nor evaluates a combination of decision trees for the final prediction. When the final prediction is based on a combination of decision trees, it is natural to evaluate the appropriateness of the combination when constructing them. In this study, we propose a new algorithmic framework that constructs decision trees simultaneously and evaluates their combination performance throughout the construction process. Our framework repeats two procedures. In the first procedure, we construct new candidates of combinations of decision trees to find a proper combination of decision trees. In the second procedure, we evaluate each combination performance of decision trees under some criteria and select a better combination. To confirm the performance of the proposed framework, we perform experiments on synthetic and <b>benchmark</b> data.

{{</citation>}}


## cs.AI (12)



### (0/12 | 78/197) GLaM: Fine-Tuning Large Language Models for Domain Knowledge Graph Alignment via Neighborhood Partitioning and Generative Subgraph Encoding (Stefan Dernbach et al., 2024)

{{<citation>}}

Stefan Dernbach, Khushbu Agarwal, Alejandro Zuniga, Michael Henry, Sutanay Choudhury. (2024)  
**GLaM: Fine-Tuning Large Language Models for Domain Knowledge Graph Alignment via Neighborhood Partitioning and Generative Subgraph Encoding**
<br/>
<button class="copy-to-clipboard" title="GLaM: Fine-Tuning Large Language Models for Domain Knowledge Graph Alignment via Neighborhood Partitioning and Generative Subgraph Encoding" index=78>
  <span class="copy-to-clipboard-item">Copy Title<span>
</button>
<div class="toast toast-copied toast-index-78 align-items-center text-bg-secondary border-0 position-absolute top-0 end-0" role="alert" aria-live="assertive" aria-atomic="true">
  <div class="d-flex">
    <div class="toast-body">
      Copied!
    </div>
  </div>
</div>

---
Primary Category: cs.AI  
Categories: cs-AI, cs.AI  
Keyword Score: 85  
Keywords: Fine-tuning, Knowledge Graph, Retrieval-Augmented Generation, Retrieval-Augmented Generation, Grounding, Reasoning, Text Generation, Large Language Model, Large Language Model  
<a type="button" class="btn btn-outline-primary" href="http://arxiv.org/abs/2402.06764v1" target="_blank" >Paper Link</a>
<button type="button" class="btn btn-outline-primary download-pdf" url="https://arxiv.org/pdf/2402.06764v1.pdf" filename="2402.06764v1.pdf">Download PDF</button>

---


**ABSTRACT**  
Integrating <b>large</b> <b>language</b> <b>models</b> <b>(LLMs)</b> with <b>knowledge</b> <b>graphs</b> derived from domain-specific data represents an important advancement towards more powerful and factual <b>reasoning.</b> As these models grow more capable, it is crucial to enable them to perform multi-step inferences over real-world <b>knowledge</b> <b>graphs</b> while minimizing hallucination. While <b>large</b> <b>language</b> <b>models</b> excel at conversation and <b>text</b> <b>generation,</b> their ability to reason over domain-specialized graphs of interconnected entities remains limited. For example, can we query a <b>LLM</b> to identify the optimal contact in a professional network for a specific goal, based on relationships and attributes in a private database? The answer is no--such capabilities lie beyond current methods. However, this question underscores a critical technical gap that must be addressed. Many high-value applications in areas such as science, security, and e-commerce rely on proprietary <b>knowledge</b> <b>graphs</b> encoding unique structures, relationships, and logical constraints. We introduce a <b>fine-tuning</b> framework for developing Graph-aligned LAnguage Models (GLaM) that transforms a <b>knowledge</b> <b>graph</b> into an alternate <b>text</b> <b>representation</b> with labeled question-answer pairs. We demonstrate that <b>grounding</b> the models in specific graph-based <b>knowledge</b> <b>expands</b> the models' capacity for structure-based <b>reasoning.</b> Our methodology leverages the <b>large-language</b> <b>model's</b> <b>generative</b> capabilities to create the dataset and proposes an efficient alternate to <b>retrieval-augmented</b> <b>generation</b> <b>styled</b> methods.

{{</citation>}}


### (1/12 | 79/197) LLaVA-Docent: Instruction Tuning with Multimodal Large Language Model to Support Art Appreciation Education (Unggi Lee et al., 2024)

{{<citation>}}

Unggi Lee, Minji Jeon, Yunseo Lee, Gyuri Byun, Yoorim Son, Jaeyoon Shin, Hongkyu Ko, Hyeoncheol Kim. (2024)  
**LLaVA-Docent: Instruction Tuning with Multimodal Large Language Model to Support Art Appreciation Education**
<br/>
<button class="copy-to-clipboard" title="LLaVA-Docent: Instruction Tuning with Multimodal Large Language Model to Support Art Appreciation Education" index=79>
  <span class="copy-to-clipboard-item">Copy Title<span>
</button>
<div class="toast toast-copied toast-index-79 align-items-center text-bg-secondary border-0 position-absolute top-0 end-0" role="alert" aria-live="assertive" aria-atomic="true">
  <div class="d-flex">
    <div class="toast-body">
      Copied!
    </div>
  </div>
</div>

---
Primary Category: cs.AI  
Categories: cs-AI, cs-CL, cs-SI, cs.AI  
Keyword Score: 62  
Keywords: Benchmarking, Benchmarking, Few-shot, Multi-modal, Multi-modal, GPT, GPT-4, Instruction Tuning, Large Language Model  
<a type="button" class="btn btn-outline-primary" href="http://arxiv.org/abs/2402.06264v1" target="_blank" >Paper Link</a>
<button type="button" class="btn btn-outline-primary download-pdf" url="https://arxiv.org/pdf/2402.06264v1.pdf" filename="2402.06264v1.pdf">Download PDF</button>

---


**ABSTRACT**  
Art appreciation is vital in nurturing critical thinking and emotional intelligence among learners. However, traditional art appreciation education has often been hindered by limited access to art resources, especially for disadvantaged students, and an imbalanced emphasis on STEM subjects in mainstream education. In response to these challenges, recent technological advancements have paved the way for innovative solutions. This study explores the application of <b>multi-modal</b> <b>large</b> <b>language</b> <b>models</b> (MLLMs) in art appreciation education, focusing on developing LLaVA-Docent, a model that leverages these advancements. Our approach involved a comprehensive literature review and consultations with experts in the field, leading to developing a robust data framework. Utilizing this framework, we generated a virtual dialogue dataset that was leveraged by <b>GPT-4.</b> This dataset was instrumental in training the MLLM, named LLaVA-Docent. Six researchers conducted quantitative and qualitative evaluations of LLaVA-Docent to assess its effectiveness, <b>benchmarking</b> it against the <b>GPT-4</b> model in a <b>few-shot</b> setting. The evaluation process revealed distinct strengths and weaknesses of the LLaVA-Docent model. Our findings highlight the efficacy of LLaVA-Docent in enhancing the accessibility and engagement of art appreciation education. By harnessing the potential of MLLMs, this study makes a significant contribution to the field of art education, proposing a novel methodology that reimagines the way art appreciation is taught and experienced.

{{</citation>}}


### (2/12 | 80/197) The Quantified Boolean Bayesian Network: Theory and Experiments with a Logical Graphical Model (Gregory Coppola, 2024)

{{<citation>}}

Gregory Coppola. (2024)  
**The Quantified Boolean Bayesian Network: Theory and Experiments with a Logical Graphical Model**
<br/>
<button class="copy-to-clipboard" title="The Quantified Boolean Bayesian Network: Theory and Experiments with a Logical Graphical Model" index=80>
  <span class="copy-to-clipboard-item">Copy Title<span>
</button>
<div class="toast toast-copied toast-index-80 align-items-center text-bg-secondary border-0 position-absolute top-0 end-0" role="alert" aria-live="assertive" aria-atomic="true">
  <div class="d-flex">
    <div class="toast-body">
      Copied!
    </div>
  </div>
</div>

---
Primary Category: cs.AI  
Categories: cs-AI, cs-IR, cs.AI  
Keyword Score: 50  
Keywords: Information Retrieval, Probabilistic Reasoning, Reasoning, Large Language Model, Large Language Model  
<a type="button" class="btn btn-outline-primary" href="http://arxiv.org/abs/2402.06557v1" target="_blank" >Paper Link</a>
<button type="button" class="btn btn-outline-primary download-pdf" url="https://arxiv.org/pdf/2402.06557v1.pdf" filename="2402.06557v1.pdf">Download PDF</button>

---


**ABSTRACT**  
This paper introduces the Quantified Boolean Bayesian Network (QBBN), which provides a unified view of logical and <b>probabilistic</b> <b>reasoning.</b> The QBBN is meant to address a central problem with the <b>Large</b> <b>Language</b> <b>Model</b> <b>(LLM),</b> which has become extremely popular in <b>Information</b> <b>Retrieval,</b> which is that the <b>LLM</b> hallucinates. A Bayesian Network, by construction, cannot hallucinate, because it can only return answers that it can explain. We show how a Bayesian Network over an unbounded number of boolean variables can be configured to represent the logical <b>reasoning</b> underlying human language. We do this by creating a key-value version of the First-Order Calculus, for which we can prove consistency and completeness. We show that the model is trivially trained over fully observed data, but that inference is non-trivial. Exact inference in a Bayesian Network is intractable (i.e. $\Omega(2^N)$ for $N$ variables). For inference, we investigate the use of Loopy Belief Propagation (LBP), which is not guaranteed to converge, but which has been shown to often converge in practice. Our experiments show that LBP indeed does converge very reliably, and our analysis shows that a round of LBP takes time $O(N2^n)$, where $N$ bounds the number of variables considered, and $n$ bounds the number of incoming connections to any factor, and further improvements may be possible. Our network is specifically designed to alternate between AND and OR gates in a Boolean Algebra, which connects more closely to logical <b>reasoning,</b> allowing a completeness proof for an expanded version of our network, and also allows inference to follow specific but adequate pathways, that turn out to be fast.

{{</citation>}}


### (3/12 | 81/197) Introspective Planning: Guiding Language-Enabled Agents to Refine Their Own Uncertainty (Kaiqu Liang et al., 2024)

{{<citation>}}

Kaiqu Liang, Zixu Zhang, Jaime Fernández Fisac. (2024)  
**Introspective Planning: Guiding Language-Enabled Agents to Refine Their Own Uncertainty**
<br/>
<button class="copy-to-clipboard" title="Introspective Planning: Guiding Language-Enabled Agents to Refine Their Own Uncertainty" index=81>
  <span class="copy-to-clipboard-item">Copy Title<span>
</button>
<div class="toast toast-copied toast-index-81 align-items-center text-bg-secondary border-0 position-absolute top-0 end-0" role="alert" aria-live="assertive" aria-atomic="true">
  <div class="d-flex">
    <div class="toast-body">
      Copied!
    </div>
  </div>
</div>

---
Primary Category: cs.AI  
Categories: cs-AI, cs-CL, cs-LG, cs.AI  
Keyword Score: 50  
Keywords: Fine-tuning, Grounding, Reasoning, Large Language Model, Large Language Model  
<a type="button" class="btn btn-outline-primary" href="http://arxiv.org/abs/2402.06529v1" target="_blank" >Paper Link</a>
<button type="button" class="btn btn-outline-primary download-pdf" url="https://arxiv.org/pdf/2402.06529v1.pdf" filename="2402.06529v1.pdf">Download PDF</button>

---


**ABSTRACT**  
<b>Large</b> <b>language</b> <b>models</b> <b>(LLMs)</b> exhibit advanced <b>reasoning</b> skills, enabling robots to comprehend natural language instructions and strategically plan high-level actions through proper <b>grounding.</b> However, <b>LLM</b> hallucination may result in robots confidently executing plans that are misaligned with user goals or, in extreme cases, unsafe. Additionally, inherent ambiguity in natural language instructions can induce task uncertainty, particularly in situations where multiple valid options exist. To address this issue, <b>LLMs</b> must identify such uncertainty and proactively seek clarification. This paper explores the concept of introspective planning as a systematic method for guiding <b>LLMs</b> in forming uncertainty--aware plans for robotic task execution without the need for <b>fine-tuning.</b> We investigate uncertainty quantification in task-level robot planning and demonstrate that introspection significantly improves both success rates and safety compared to state-of-the-art <b>LLM-based</b> planning approaches. Furthermore, we assess the effectiveness of introspective planning in conjunction with conformal prediction, revealing that this combination yields tighter confidence bounds, thereby maintaining statistical success guarantees with fewer superfluous user clarification queries.

{{</citation>}}


### (4/12 | 82/197) ACTER: Diverse and Actionable Counterfactual Sequences for Explaining and Diagnosing RL Policies (Jasmina Gajcin et al., 2024)

{{<citation>}}

Jasmina Gajcin, Ivana Dusparic. (2024)  
**ACTER: Diverse and Actionable Counterfactual Sequences for Explaining and Diagnosing RL Policies**
<br/>
<button class="copy-to-clipboard" title="ACTER: Diverse and Actionable Counterfactual Sequences for Explaining and Diagnosing RL Policies" index=82>
  <span class="copy-to-clipboard-item">Copy Title<span>
</button>
<div class="toast toast-copied toast-index-82 align-items-center text-bg-secondary border-0 position-absolute top-0 end-0" role="alert" aria-live="assertive" aria-atomic="true">
  <div class="d-flex">
    <div class="toast-body">
      Copied!
    </div>
  </div>
</div>

---
Primary Category: cs.AI  
Categories: cs-AI, cs-LG, cs.AI  
Keyword Score: 40  
Keywords: Counter-factual, Reinforcement Learning, Counterfactual Reasoning, Reasoning  
<a type="button" class="btn btn-outline-primary" href="http://arxiv.org/abs/2402.06503v1" target="_blank" >Paper Link</a>
<button type="button" class="btn btn-outline-primary download-pdf" url="https://arxiv.org/pdf/2402.06503v1.pdf" filename="2402.06503v1.pdf">Download PDF</button>

---


**ABSTRACT**  
Understanding how failure occurs and how it can be prevented in <b>reinforcement</b> <b>learning</b> (RL) is necessary to enable debugging, maintain user trust, and develop personalized policies. <b>Counterfactual</b> <b>reasoning</b> has often been used to assign blame and understand failure by searching for the closest possible world in which the failure is avoided. However, current <b>counterfactual</b> <b>state</b> explanations in RL can only explain an outcome using just the current state features and offer no actionable recourse on how a negative outcome could have been prevented. In this work, we propose ACTER (Actionable <b>Counterfactual</b> <b>Sequences</b> for Explaining <b>Reinforcement</b> <b>Learning</b> Outcomes), an algorithm for generating <b>counterfactual</b> <b>sequences</b> that provides actionable advice on how failure can be avoided. ACTER investigates actions leading to a failure and uses the evolutionary algorithm NSGA-II to generate <b>counterfactual</b> <b>sequences</b> of actions that prevent it with minimal changes and high certainty even in stochastic environments. Additionally, ACTER generates a set of multiple diverse <b>counterfactual</b> <b>sequences</b> that enable users to correct failure in the way that best fits their preferences. We also introduce three diversity metrics that can be used for evaluating the diversity of <b>counterfactual</b> <b>sequences.</b> We evaluate ACTER in two RL environments, with both discrete and continuous actions, and show that it can generate actionable and diverse <b>counterfactual</b> <b>sequences.</b> We conduct a user study to explore how explanations generated by ACTER help users identify and correct failure.

{{</citation>}}


### (5/12 | 83/197) Understanding the Weakness of Large Language Model Agents within a Complex Android Environment (Mingzhe Xing et al., 2024)

{{<citation>}}

Mingzhe Xing, Rongkai Zhang, Hui Xue, Qi Chen, Fan Yang, Zhen Xiao. (2024)  
**Understanding the Weakness of Large Language Model Agents within a Complex Android Environment**
<br/>
<button class="copy-to-clipboard" title="Understanding the Weakness of Large Language Model Agents within a Complex Android Environment" index=83>
  <span class="copy-to-clipboard-item">Copy Title<span>
</button>
<div class="toast toast-copied toast-index-83 align-items-center text-bg-secondary border-0 position-absolute top-0 end-0" role="alert" aria-live="assertive" aria-atomic="true">
  <div class="d-flex">
    <div class="toast-body">
      Copied!
    </div>
  </div>
</div>

---
Primary Category: cs.AI  
Categories: cs-AI, cs-HC, cs-SE, cs.AI  
Keyword Score: 33  
Keywords: Benchmarking, Reasoning, Large Language Model, Large Language Model  
<a type="button" class="btn btn-outline-primary" href="http://arxiv.org/abs/2402.06596v1" target="_blank" >Paper Link</a>
<button type="button" class="btn btn-outline-primary download-pdf" url="https://arxiv.org/pdf/2402.06596v1.pdf" filename="2402.06596v1.pdf">Download PDF</button>

---


**ABSTRACT**  
<b>Large</b> <b>language</b> <b>models</b> <b>(LLMs)</b> have empowered intelligent agents to execute intricate tasks within domain-specific software such as browsers and games. However, when applied to general-purpose software systems like operating systems, <b>LLM</b> agents face three primary challenges. Firstly, the action space is vast and dynamic, posing difficulties for <b>LLM</b> agents to maintain an up-to-date understanding and deliver accurate responses. Secondly, real-world tasks often require inter-application cooperation}, demanding farsighted planning from <b>LLM</b> agents. Thirdly, agents need to identify optimal solutions aligning with user constraints, such as security concerns and preferences. These challenges motivate AndroidArena, an environment and <b>benchmark</b> designed to evaluate <b>LLM</b> agents on a modern operating system. To address high-cost of manpower, we design a scalable and semi-automated method to construct the <b>benchmark.</b> In the task evaluation, AndroidArena incorporates accurate and adaptive metrics to address the issue of non-unique solutions. Our findings reveal that even state-of-the-art <b>LLM</b> agents struggle in cross-APP scenarios and adhering to specific constraints. Additionally, we identify a lack of four key capabilities, i.e., understanding, <b>reasoning,</b> exploration, and reflection, as primary reasons for the failure of <b>LLM</b> agents. Furthermore, we provide empirical analysis on the failure of reflection, and improve the success rate by 27% with our proposed exploration strategy. This work is the first to present valuable insights in understanding fine-grained weakness of <b>LLM</b> agents, and offers a path forward for future research in this area. Environment, <b>benchmark,</b> and evaluation code for AndroidArena are released at https://github.com/AndroidArenaAgent/AndroidArena.

{{</citation>}}


### (6/12 | 84/197) Debating with More Persuasive LLMs Leads to More Truthful Answers (Akbir Khan et al., 2024)

{{<citation>}}

Akbir Khan, John Hughes, Dan Valentine, Laura Ruis, Kshitij Sachan, Ansh Radhakrishnan, Edward Grefenstette, Samuel R. Bowman, Tim Rocktäschel, Ethan Perez. (2024)  
**Debating with More Persuasive LLMs Leads to More Truthful Answers**
<br/>
<button class="copy-to-clipboard" title="Debating with More Persuasive LLMs Leads to More Truthful Answers" index=84>
  <span class="copy-to-clipboard-item">Copy Title<span>
</button>
<div class="toast toast-copied toast-index-84 align-items-center text-bg-secondary border-0 position-absolute top-0 end-0" role="alert" aria-live="assertive" aria-atomic="true">
  <div class="d-flex">
    <div class="toast-body">
      Copied!
    </div>
  </div>
</div>

---
Primary Category: cs.AI  
Categories: cs-AI, cs-CL, cs.AI  
Keyword Score: 30  
Keywords: Unsupervised Learning, Large Language Model, Large Language Model  
<a type="button" class="btn btn-outline-primary" href="http://arxiv.org/abs/2402.06782v1" target="_blank" >Paper Link</a>
<button type="button" class="btn btn-outline-primary download-pdf" url="https://arxiv.org/pdf/2402.06782v1.pdf" filename="2402.06782v1.pdf">Download PDF</button>

---


**ABSTRACT**  
Common methods for aligning <b>large</b> <b>language</b> <b>models</b> <b>(LLMs)</b> with desired behaviour heavily rely on human-labelled data. However, as models grow increasingly sophisticated, they will surpass human expertise, and the role of human evaluation will evolve into non-experts overseeing experts. In anticipation of this, we ask: can weaker models assess the correctness of stronger models? We investigate this question in an analogous setting, where stronger models (experts) possess the necessary information to answer questions and weaker models (non-experts) lack this information. The method we evaluate is \textit{debate}, where two <b>LLM</b> experts each argue for a different answer, and a non-expert selects the answer. We find that debate consistently helps both non-expert models and humans answer questions, achieving 76\% and 88\% accuracy respectively (naive baselines obtain 48\% and 60\%). Furthermore, optimising expert debaters for persuasiveness in an <b>unsupervised</b> manner improves non-expert ability to identify the truth in debates. Our results provide encouraging empirical evidence for the viability of aligning models with debate in the absence of ground truth.

{{</citation>}}


### (7/12 | 85/197) Prompt Learning on Temporal Interaction Graphs (Xi Chen et al., 2024)

{{<citation>}}

Xi Chen, Siwei Zhang, Yun Xiong, Xixi Wu, Jiawei Zhang, Xiangguo Sun, Yao Zhang, Yinglong Zhao, Yulin Kang. (2024)  
**Prompt Learning on Temporal Interaction Graphs**
<br/>
<button class="copy-to-clipboard" title="Prompt Learning on Temporal Interaction Graphs" index=85>
  <span class="copy-to-clipboard-item">Copy Title<span>
</button>
<div class="toast toast-copied toast-index-85 align-items-center text-bg-secondary border-0 position-absolute top-0 end-0" role="alert" aria-live="assertive" aria-atomic="true">
  <div class="d-flex">
    <div class="toast-body">
      Copied!
    </div>
  </div>
</div>

---
Primary Category: cs.AI  
Categories: cs-AI, cs-LG, cs-SI, cs.AI  
Keyword Score: 30  
Keywords: Fine-tuning, Prompt, Prompt Learning  
<a type="button" class="btn btn-outline-primary" href="http://arxiv.org/abs/2402.06326v1" target="_blank" >Paper Link</a>
<button type="button" class="btn btn-outline-primary download-pdf" url="https://arxiv.org/pdf/2402.06326v1.pdf" filename="2402.06326v1.pdf">Download PDF</button>

---


**ABSTRACT**  
Temporal Interaction Graphs (TIGs) are widely utilized to represent real-world systems. To facilitate representation learning on TIGs, researchers have proposed a series of TIG models. However, these models are still facing two tough gaps between the pre-training and downstream predictions in their ``pre-train, predict'' training paradigm. First, the temporal discrepancy between the pre-training and inference data severely undermines the models' applicability in distant future predictions on the dynamically evolving data. Second, the semantic divergence between pretext and downstream tasks hinders their practical applications, as they struggle to align with their learning and prediction capabilities across application scenarios. Recently, the ``pre-train, <b>prompt''</b> <b>paradigm</b> has emerged as a lightweight mechanism for model generalization. Applying this paradigm is a potential solution to solve the aforementioned challenges. However, the adaptation of this paradigm to TIGs is not straightforward. The application of <b>prompting</b> <b>in</b> static graph contexts falls short in temporal settings due to a lack of consideration for time-sensitive dynamics and a deficiency in expressive power. To address this issue, we introduce Temporal Interaction Graph <b>Prompting</b> <b>(TIGPrompt),</b> a versatile framework that seamlessly integrates with TIG models, bridging both the temporal and semantic gaps. In detail, we propose a temporal <b>prompt</b> <b>generator</b> to offer temporally-aware <b>prompts</b> <b>for</b> different tasks. These <b>prompts</b> <b>stand</b> out for their minimalistic design, relying solely on the tuning of the <b>prompt</b> <b>generator</b> with very little supervision data. To cater to varying computational resource demands, we propose an extended ``pre-train, <b>prompt-based</b> <b>fine-tune''</b> paradigm, offering greater flexibility. Through extensive experiments, the TIGPrompt demonstrates the SOTA performance and remarkable efficiency advantages.

{{</citation>}}


### (8/12 | 86/197) Human Aesthetic Preference-Based Large Text-to-Image Model Personalization: Kandinsky Generation as an Example (Aven-Le Zhou et al., 2024)

{{<citation>}}

Aven-Le Zhou, Yu-Ao Wang, Wei Wu, Kang Zhang. (2024)  
**Human Aesthetic Preference-Based Large Text-to-Image Model Personalization: Kandinsky Generation as an Example**
<br/>
<button class="copy-to-clipboard" title="Human Aesthetic Preference-Based Large Text-to-Image Model Personalization: Kandinsky Generation as an Example" index=86>
  <span class="copy-to-clipboard-item">Copy Title<span>
</button>
<div class="toast toast-copied toast-index-86 align-items-center text-bg-secondary border-0 position-absolute top-0 end-0" role="alert" aria-live="assertive" aria-atomic="true">
  <div class="d-flex">
    <div class="toast-body">
      Copied!
    </div>
  </div>
</div>

---
Primary Category: cs.AI  
Categories: cs-AI, cs-HC, cs-MM, cs.AI  
Keyword Score: 20  
Keywords: Text2image, Prompt  
<a type="button" class="btn btn-outline-primary" href="http://arxiv.org/abs/2402.06389v1" target="_blank" >Paper Link</a>
<button type="button" class="btn btn-outline-primary download-pdf" url="https://arxiv.org/pdf/2402.06389v1.pdf" filename="2402.06389v1.pdf">Download PDF</button>

---


**ABSTRACT**  
With the advancement of neural generative capabilities, the art community has actively embraced GenAI (generative artificial intelligence) for creating painterly content. Large <b>text-to-image</b> models can quickly generate aesthetically pleasing outcomes. However, the process can be non-deterministic and often involves tedious trial-and-error, as users struggle with formulating effective <b>prompts</b> to achieve their desired results. This paper introduces a <b>prompting-free</b> generative approach that empowers users to automatically generate personalized painterly content that incorporates their aesthetic preferences in a customized artistic style. This approach involves utilizing ``semantic injection'' to customize an artist model in a specific artistic style, and further leveraging a genetic algorithm to optimize the <b>prompt</b> generation process through real-time iterative human feedback. By solely relying on the user's aesthetic evaluation and preference for the artist model-generated images, this approach creates the user a personalized model that encompasses their aesthetic preferences and the customized artistic style.

{{</citation>}}


### (9/12 | 87/197) Discipline and Label: A WEIRD Genealogy and Social Theory of Data Annotation (Andrew Smart et al., 2024)

{{<citation>}}

Andrew Smart, Ding Wang, Ellis Monk, Mark Díaz, Atoosa Kasirzadeh, Erin Van Liemt, Sonja Schmer-Galunder. (2024)  
**Discipline and Label: A WEIRD Genealogy and Social Theory of Data Annotation**
<br/>
<button class="copy-to-clipboard" title="Discipline and Label: A WEIRD Genealogy and Social Theory of Data Annotation" index=87>
  <span class="copy-to-clipboard-item">Copy Title<span>
</button>
<div class="toast toast-copied toast-index-87 align-items-center text-bg-secondary border-0 position-absolute top-0 end-0" role="alert" aria-live="assertive" aria-atomic="true">
  <div class="d-flex">
    <div class="toast-body">
      Copied!
    </div>
  </div>
</div>

---
Primary Category: cs.AI  
Categories: cs-AI, cs.AI  
Keyword Score: 10  
Keywords: Fairness  
<a type="button" class="btn btn-outline-primary" href="http://arxiv.org/abs/2402.06811v1" target="_blank" >Paper Link</a>
<button type="button" class="btn btn-outline-primary download-pdf" url="https://arxiv.org/pdf/2402.06811v1.pdf" filename="2402.06811v1.pdf">Download PDF</button>

---


**ABSTRACT**  
Data annotation remains the sine qua non of machine learning and AI. Recent empirical work on data annotation has begun to highlight the importance of rater diversity for <b>fairness,</b> model performance, and new lines of research have begun to examine the working conditions for data annotation workers, the impacts and role of annotator subjectivity on labels, and the potential psychological harms from aspects of annotation work. This paper outlines a critical genealogy of data annotation; starting with its psychological and perceptual aspects. We draw on similarities with critiques of the rise of computerized lab-based psychological experiments in the 1970's which question whether these experiments permit the generalization of results beyond the laboratory settings within which these results are typically obtained. Do data annotations permit the generalization of results beyond the settings, or locations, in which they were obtained? Psychology is overly reliant on participants from Western, Educated, Industrialized, Rich, and Democratic societies (WEIRD). Many of the people who work as data annotation platform workers, however, are not from WEIRD countries; most data annotation workers are based in Global South countries. Social categorizations and classifications from WEIRD countries are imposed on non-WEIRD annotators through instructions and tasks, and through them, on data, which is then used to train or evaluate AI models in WEIRD countries. We synthesize evidence from several recent lines of research and argue that data annotation is a form of automated social categorization that risks entrenching outdated and static social categories that are in reality dynamic and changing. We propose a framework for understanding the interplay of the global social conditions of data annotation with the subjective phenomenological experience of data annotation work.

{{</citation>}}


### (10/12 | 88/197) Predictive representations: building blocks of intelligence (Wilka Carvalho et al., 2024)

{{<citation>}}

Wilka Carvalho, Momchil S. Tomov, William de Cothi, Caswell Barry, Samuel J. Gershman. (2024)  
**Predictive representations: building blocks of intelligence**
<br/>
<button class="copy-to-clipboard" title="Predictive representations: building blocks of intelligence" index=88>
  <span class="copy-to-clipboard-item">Copy Title<span>
</button>
<div class="toast toast-copied toast-index-88 align-items-center text-bg-secondary border-0 position-absolute top-0 end-0" role="alert" aria-live="assertive" aria-atomic="true">
  <div class="d-flex">
    <div class="toast-body">
      Copied!
    </div>
  </div>
</div>

---
Primary Category: cs.AI  
Categories: cs-AI, cs-LG, cs.AI  
Keyword Score: 10  
Keywords: Reinforcement Learning  
<a type="button" class="btn btn-outline-primary" href="http://arxiv.org/abs/2402.06590v1" target="_blank" >Paper Link</a>
<button type="button" class="btn btn-outline-primary download-pdf" url="https://arxiv.org/pdf/2402.06590v1.pdf" filename="2402.06590v1.pdf">Download PDF</button>

---


**ABSTRACT**  
Adaptive behavior often requires predicting future events. The theory of <b>reinforcement</b> <b>learning</b> prescribes what kinds of predictive representations are useful and how to compute them. This paper integrates these theoretical ideas with work on cognition and neuroscience. We pay special attention to the successor representation (SR) and its generalizations, which have been widely applied both as engineering tools and models of brain function. This convergence suggests that particular kinds of predictive representations may function as versatile building blocks of intelligence.

{{</citation>}}


### (11/12 | 89/197) Modelling Human Values for AI Reasoning (Nardine Osman et al., 2024)

{{<citation>}}

Nardine Osman, Mark d'Inverno. (2024)  
**Modelling Human Values for AI Reasoning**
<br/>
<button class="copy-to-clipboard" title="Modelling Human Values for AI Reasoning" index=89>
  <span class="copy-to-clipboard-item">Copy Title<span>
</button>
<div class="toast toast-copied toast-index-89 align-items-center text-bg-secondary border-0 position-absolute top-0 end-0" role="alert" aria-live="assertive" aria-atomic="true">
  <div class="d-flex">
    <div class="toast-body">
      Copied!
    </div>
  </div>
</div>

---
Primary Category: cs.AI  
Categories: 68T01, I-2-4, cs-AI, cs-MA, cs.AI  
Keyword Score: 10  
Keywords: Reasoning  
<a type="button" class="btn btn-outline-primary" href="http://arxiv.org/abs/2402.06359v1" target="_blank" >Paper Link</a>
<button type="button" class="btn btn-outline-primary download-pdf" url="https://arxiv.org/pdf/2402.06359v1.pdf" filename="2402.06359v1.pdf">Download PDF</button>

---


**ABSTRACT**  
One of today's most significant societal challenges is building AI systems whose behaviour, or the behaviour it enables within communities of interacting agents (human and artificial), aligns with human values. To address this challenge, we detail a formal model of human values for their explicit computational representation. To our knowledge, this has not been attempted as yet, which is surprising given the growing volume of research integrating values within AI. Taking as our starting point the wealth of research investigating the nature of human values from social psychology over the last few decades, we set out to provide such a formal model. We show how this model can provide the foundational apparatus for AI-based <b>reasoning</b> over values, and demonstrate its applicability in real-world use cases. We illustrate how our model captures the key ideas from social psychology research and propose a roadmap for future integrated, and interdisciplinary, research into human values in AI. The ability to automatically reason over values not only helps address the value alignment problem but also facilitates the design of AI systems that can support individuals and communities in making more informed, value-aligned decisions. More and more, individuals and organisations are motivated to understand their values more explicitly and explore whether their behaviours and attitudes properly reflect them. Our work on modelling human values will enable AI systems to be designed and deployed to meet this growing need.

{{</citation>}}


## cs.IR (4)



### (0/4 | 90/197) ExaRanker-Open: Synthetic Explanation for IR using Open-Source LLMs (Fernando Ferraretto et al., 2024)

{{<citation>}}

Fernando Ferraretto, Thiago Laitz, Roberto Lotufo, Rodrigo Nogueira. (2024)  
**ExaRanker-Open: Synthetic Explanation for IR using Open-Source LLMs**
<br/>
<button class="copy-to-clipboard" title="ExaRanker-Open: Synthetic Explanation for IR using Open-Source LLMs" index=90>
  <span class="copy-to-clipboard-item">Copy Title<span>
</button>
<div class="toast toast-copied toast-index-90 align-items-center text-bg-secondary border-0 position-absolute top-0 end-0" role="alert" aria-live="assertive" aria-atomic="true">
  <div class="d-flex">
    <div class="toast-body">
      Copied!
    </div>
  </div>
</div>

---
Primary Category: cs.IR  
Categories: cs-AI, cs-CL, cs-IR, cs.IR  
Keyword Score: 70  
Keywords: Data Augmentation, GPT, GPT-3, GPT-3.5, Information Retrieval, Natural Language Explanation, Large Language Model  
<a type="button" class="btn btn-outline-primary" href="http://arxiv.org/abs/2402.06334v1" target="_blank" >Paper Link</a>
<button type="button" class="btn btn-outline-primary download-pdf" url="https://arxiv.org/pdf/2402.06334v1.pdf" filename="2402.06334v1.pdf">Download PDF</button>

---


**ABSTRACT**  
ExaRanker recently introduced an approach to training <b>information</b> <b>retrieval</b> (IR) models, incorporating <b>natural</b> <b>language</b> <b>explanations</b> as additional labels. The method addresses the challenge of limited labeled examples, leading to improvements in the effectiveness of IR models. However, the initial results were based on proprietary language models such as <b>GPT-3.5,</b> which posed constraints on dataset size due to its cost and <b>data</b> <b>privacy.</b> In this paper, we introduce ExaRanker-Open, where we adapt and explore the use of open-source language models to generate explanations. The method has been tested using different <b>LLMs</b> and datasets sizes to better comprehend the effective contribution of <b>data</b> <b>augmentation.</b> Our findings reveal that incorporating explanations consistently enhances neural rankers, with benefits escalating as the <b>LLM</b> size increases. Notably, the <b>data</b> <b>augmentation</b> method proves advantageous even with large datasets, as evidenced by ExaRanker surpassing the target baseline by 0.6 nDCG@10 points in our study. To encourage further advancements by the research community, we have open-sourced both the code and datasets at https://github.com/unicamp-dl/ExaRanker.

{{</citation>}}


### (1/4 | 91/197) Fairly Evaluating Large Language Model-based Recommendation Needs Revisit the Cross-Entropy Loss (Cong Xu et al., 2024)

{{<citation>}}

Cong Xu, Zhangchi Zhu, Jun Wang, Jianyong Wang, Wei Zhang. (2024)  
**Fairly Evaluating Large Language Model-based Recommendation Needs Revisit the Cross-Entropy Loss**
<br/>
<button class="copy-to-clipboard" title="Fairly Evaluating Large Language Model-based Recommendation Needs Revisit the Cross-Entropy Loss" index=91>
  <span class="copy-to-clipboard-item">Copy Title<span>
</button>
<div class="toast toast-copied toast-index-91 align-items-center text-bg-secondary border-0 position-absolute top-0 end-0" role="alert" aria-live="assertive" aria-atomic="true">
  <div class="d-flex">
    <div class="toast-body">
      Copied!
    </div>
  </div>
</div>

---
Primary Category: cs.IR  
Categories: cs-IR, cs.IR  
Keyword Score: 40  
Keywords: Fine-tuning, Recommendation, Large Language Model, Large Language Model  
<a type="button" class="btn btn-outline-primary" href="http://arxiv.org/abs/2402.06216v1" target="_blank" >Paper Link</a>
<button type="button" class="btn btn-outline-primary download-pdf" url="https://arxiv.org/pdf/2402.06216v1.pdf" filename="2402.06216v1.pdf">Download PDF</button>

---


**ABSTRACT**  
<b>Large</b> <b>language</b> <b>models</b> <b>(LLMs)</b> have gained much attention in the <b>recommendation</b> community; some studies have observed that <b>LLMs,</b> <b>fine-tuned</b> by the cross-entropy loss with a full softmax, could achieve state-of-the-art performance already. However, these claims are drawn from unobjective and unfair comparisons. In view of the substantial quantity of items in reality, conventional recommenders typically adopt a pointwise/pairwise loss function instead for training. This substitute however causes severe performance degradation, leading to under-estimation of conventional methods and over-confidence in the ranking capability of <b>LLMs.</b> In this work, we theoretically justify the superiority of cross-entropy, and showcase that it can be adequately replaced by some elementary approximations with certain necessary modifications. The remarkable results across three public datasets corroborate that even in a practical sense, existing <b>LLM-based</b> methods are not as effective as claimed for next-item <b>recommendation.</b> We hope that these theoretical understandings in conjunction with the empirical results will facilitate an objective evaluation of <b>LLM-based</b> <b>recommendation</b> in the future.

{{</citation>}}


### (2/4 | 92/197) CoSearchAgent: A Lightweight Collaborative Search Agent with Large Language Models (Peiyuan Gong et al., 2024)

{{<citation>}}

Peiyuan Gong, Jiamian Li, Jiaxin Mao. (2024)  
**CoSearchAgent: A Lightweight Collaborative Search Agent with Large Language Models**
<br/>
<button class="copy-to-clipboard" title="CoSearchAgent: A Lightweight Collaborative Search Agent with Large Language Models" index=92>
  <span class="copy-to-clipboard-item">Copy Title<span>
</button>
<div class="toast toast-copied toast-index-92 align-items-center text-bg-secondary border-0 position-absolute top-0 end-0" role="alert" aria-live="assertive" aria-atomic="true">
  <div class="d-flex">
    <div class="toast-body">
      Copied!
    </div>
  </div>
</div>

---
Primary Category: cs.IR  
Categories: cs-AI, cs-CL, cs-IR, cs.IR  
Keyword Score: 20  
Keywords: Large Language Model, Large Language Model  
<a type="button" class="btn btn-outline-primary" href="http://arxiv.org/abs/2402.06360v1" target="_blank" >Paper Link</a>
<button type="button" class="btn btn-outline-primary download-pdf" url="https://arxiv.org/pdf/2402.06360v1.pdf" filename="2402.06360v1.pdf">Download PDF</button>

---


**ABSTRACT**  
Collaborative search supports multiple users working together to accomplish a specific search task. Research has found that designing lightweight collaborative search plugins within instant messaging platforms aligns better with users' collaborative habits. However, due to the complexity of multi-user interaction scenarios, it is challenging to implement a fully functioning lightweight collaborative search system. Therefore, previous studies on lightweight collaborative search had to rely on the Wizard of Oz paradigm. In recent years, <b>large</b> <b>language</b> <b>models</b> <b>(LLMs)</b> have been demonstrated to interact naturally with users and achieve complex information-seeking tasks through <b>LLM-based</b> agents. Hence, to better support the research in collaborative search, in this demo, we propose CoSearchAgent, a lightweight collaborative search agent powered by <b>LLMs.</b> CoSearchAgent is designed as a Slack plugin that can support collaborative search during multi-party conversations on this platform. Equipped with the capacity to understand the queries and context in multi-user conversations and the ability to search the Web for relevant information via APIs, CoSearchAgent can respond to user queries with answers grounded on the relevant search results. It can also ask clarifying questions when the information needs are unclear. The proposed CoSearchAgent is highly flexible and would be useful for supporting further research on collaborative search. The code and demo video are accessible.

{{</citation>}}


### (3/4 | 93/197) Collaborative filtering, K-nearest neighbor and cosine similarity in home decor recommender systems (Nanna Bach Munkholm et al., 2024)

{{<citation>}}

Nanna Bach Munkholm, Robert Alphinas, Torben Tambo. (2024)  
**Collaborative filtering, K-nearest neighbor and cosine similarity in home decor recommender systems**
<br/>
<button class="copy-to-clipboard" title="Collaborative filtering, K-nearest neighbor and cosine similarity in home decor recommender systems" index=93>
  <span class="copy-to-clipboard-item">Copy Title<span>
</button>
<div class="toast toast-copied toast-index-93 align-items-center text-bg-secondary border-0 position-absolute top-0 end-0" role="alert" aria-live="assertive" aria-atomic="true">
  <div class="d-flex">
    <div class="toast-body">
      Copied!
    </div>
  </div>
</div>

---
Primary Category: cs.IR  
Categories: cs-IR, cs-SI, cs.IR  
Keyword Score: 10  
Keywords: Recommender System  
<a type="button" class="btn btn-outline-primary" href="http://arxiv.org/abs/2402.06233v1" target="_blank" >Paper Link</a>
<button type="button" class="btn btn-outline-primary download-pdf" url="https://arxiv.org/pdf/2402.06233v1.pdf" filename="2402.06233v1.pdf">Download PDF</button>

---


**ABSTRACT**  
An architectural framework, based on collaborative filtering using K-nearest neighbor and cosine similarity, was developed and implemented to fit the requirements for the company DecorRaid. The aim of the paper is to test different evaluation techniques within the environment to research the <b>recommender</b> <b>systems</b> performance. Three perspectives were found relevant for evaluating a <b>recommender</b> <b>system</b> in the specific environment, namely dataset, system and user perspective. With these perspectives it was possible to gain a broader view of the <b>recommender</b> <b>systems</b> performance. Online A/B split testing was conducted to compare the performance of small adjustments to the RS and to test the relevance of the evaluation techniques. Key factors are solving the sparsity and cold start problem, where the suggestion is to research a hybrid RS combining Content-based and CF based techniques.

{{</citation>}}


## cs.CV (37)



### (0/37 | 94/197) On the Out-Of-Distribution Generalization of Multimodal Large Language Models (Xingxuan Zhang et al., 2024)

{{<citation>}}

Xingxuan Zhang, Jiansheng Li, Wenjing Chu, Junjia Hai, Renzhe Xu, Yuqing Yang, Shikai Guan, Jiazheng Xu, Peng Cui. (2024)  
**On the Out-Of-Distribution Generalization of Multimodal Large Language Models**
<br/>
<button class="copy-to-clipboard" title="On the Out-Of-Distribution Generalization of Multimodal Large Language Models" index=94>
  <span class="copy-to-clipboard-item">Copy Title<span>
</button>
<div class="toast toast-copied toast-index-94 align-items-center text-bg-secondary border-0 position-absolute top-0 end-0" role="alert" aria-live="assertive" aria-atomic="true">
  <div class="d-flex">
    <div class="toast-body">
      Copied!
    </div>
  </div>
</div>

---
Primary Category: cs.CV  
Categories: cs-AI, cs-CV, cs.CV  
Keyword Score: 66  
Keywords: Multi-modal, Multi-modal, Out-of-distribution, Zero-shot, In-context Learning, In-context Learning, In-context Learning, Large Language Model  
<a type="button" class="btn btn-outline-primary" href="http://arxiv.org/abs/2402.06599v1" target="_blank" >Paper Link</a>
<button type="button" class="btn btn-outline-primary download-pdf" url="https://arxiv.org/pdf/2402.06599v1.pdf" filename="2402.06599v1.pdf">Download PDF</button>

---


**ABSTRACT**  
We investigate the generalization boundaries of current <b>Multimodal</b> <b>Large</b> <b>Language</b> <b>Models</b> (MLLMs) via comprehensive evaluation under <b>out-of-distribution</b> scenarios and domain-specific tasks. We evaluate their <b>zero-shot</b> generalization across synthetic images, real-world distributional shifts, and specialized datasets like medical and molecular imagery. Empirical results indicate that MLLMs struggle with generalization beyond common training domains, limiting their direct application without adaptation. To understand the cause of unreliable performance, we analyze three hypotheses: semantic misinterpretation, visual feature extraction insufficiency, and mapping deficiency. Results identify mapping deficiency as the primary hurdle. To address this problem, we show that <b>in-context</b> <b>learning</b> <b>(ICL)</b> can significantly enhance MLLMs' generalization, opening new avenues for overcoming generalization barriers. We further explore the robustness of <b>ICL</b> under distribution shifts and show its vulnerability to domain shifts, label shifts, and spurious correlation shifts between <b>in-context</b> <b>examples</b> and test data.

{{</citation>}}


### (1/37 | 95/197) Masked LoGoNet: Fast and Accurate 3D Image Analysis for Medical Domain (Amin Karimi Monsefi et al., 2024)

{{<citation>}}

Amin Karimi Monsefi, Payam Karisani, Mengxi Zhou, Stacey Choi, Nathan Doble, Heng Ji, Srinivasan Parthasarathy, Rajiv Ramnath. (2024)  
**Masked LoGoNet: Fast and Accurate 3D Image Analysis for Medical Domain**
<br/>
<button class="copy-to-clipboard" title="Masked LoGoNet: Fast and Accurate 3D Image Analysis for Medical Domain" index=95>
  <span class="copy-to-clipboard-item">Copy Title<span>
</button>
<div class="toast toast-copied toast-index-95 align-items-center text-bg-secondary border-0 position-absolute top-0 end-0" role="alert" aria-live="assertive" aria-atomic="true">
  <div class="d-flex">
    <div class="toast-body">
      Copied!
    </div>
  </div>
</div>

---
Primary Category: cs.CV  
Categories: cs-CV, cs-LG, cs.CV  
Keyword Score: 63  
Keywords: Benchmarking, Contrastive Learning, Convolutional Neural Network, Self-supervised Learning, Self-supervised Learning, Transformer, Vision Transformer  
<a type="button" class="btn btn-outline-primary" href="http://arxiv.org/abs/2402.06190v1" target="_blank" >Paper Link</a>
<button type="button" class="btn btn-outline-primary download-pdf" url="https://arxiv.org/pdf/2402.06190v1.pdf" filename="2402.06190v1.pdf">Download PDF</button>

---


**ABSTRACT**  
Standard modern machine-learning-based imaging methods have faced challenges in medical applications due to the high cost of dataset construction and, thereby, the limited labeled training data available. Additionally, upon deployment, these methods are usually used to process a large volume of data on a daily basis, imposing a high maintenance cost on medical facilities. In this paper, we introduce a new neural network architecture, termed LoGoNet, with a tailored <b>self-supervised</b> <b>learning</b> (SSL) method to mitigate such challenges. LoGoNet integrates a novel feature extractor within a U-shaped architecture, leveraging Large Kernel Attention (LKA) and a dual encoding strategy to capture both long-range and short-range feature dependencies adeptly. This is in contrast to existing methods that rely on increasing network capacity to enhance feature extraction. This combination of novel techniques in our model is especially beneficial in medical image segmentation, given the difficulty of learning intricate and often irregular body organ shapes, such as the spleen. Complementary, we propose a novel SSL method tailored for 3D images to compensate for the lack of large labeled datasets. The method combines masking and <b>contrastive</b> <b>learning</b> techniques within a multi-task learning framework and is compatible with both <b>Vision</b> <b>Transformer</b> (ViT) and <b>CNN-based</b> models. We demonstrate the efficacy of our methods in numerous tasks across two standard datasets (i.e., BTCV and MSD). <b>Benchmark</b> comparisons with eight state-of-the-art models highlight LoGoNet's superior performance in both inference time and accuracy.

{{</citation>}}


### (2/37 | 96/197) BarlowTwins-CXR : Enhancing Chest X-Ray abnormality localization in heterogeneous data with cross-domain self-supervised learning (Haoyue Sheng et al., 2024)

{{<citation>}}

Haoyue Sheng, Linrui Ma, Jean-Francois Samson, Dianbo Liu. (2024)  
**BarlowTwins-CXR : Enhancing Chest X-Ray abnormality localization in heterogeneous data with cross-domain self-supervised learning**
<br/>
<button class="copy-to-clipboard" title="BarlowTwins-CXR : Enhancing Chest X-Ray abnormality localization in heterogeneous data with cross-domain self-supervised learning" index=96>
  <span class="copy-to-clipboard-item">Copy Title<span>
</button>
<div class="toast toast-copied toast-index-96 align-items-center text-bg-secondary border-0 position-absolute top-0 end-0" role="alert" aria-live="assertive" aria-atomic="true">
  <div class="d-flex">
    <div class="toast-body">
      Copied!
    </div>
  </div>
</div>

---
Primary Category: cs.CV  
Categories: I-2-1; J-3; I-4-9, cs-CV, cs.CV  
Keyword Score: 60  
Keywords: Fine-tuning, Self-supervised Learning, Self-supervised Learning, Self-supervised Pre-training, Supervised Learning, Transfer Learning  
<a type="button" class="btn btn-outline-primary" href="http://arxiv.org/abs/2402.06499v1" target="_blank" >Paper Link</a>
<button type="button" class="btn btn-outline-primary download-pdf" url="https://arxiv.org/pdf/2402.06499v1.pdf" filename="2402.06499v1.pdf">Download PDF</button>

---


**ABSTRACT**  
Background: Chest X-ray imaging-based abnormality localization, essential in diagnosing various diseases, faces significant clinical challenges due to complex interpretations and the growing workload of radiologists. While recent advances in deep learning offer promising solutions, there is still a critical issue of domain inconsistency in cross-domain <b>transfer</b> <b>learning,</b> which hampers the efficiency and accuracy of diagnostic processes. This study aims to address the domain inconsistency problem and improve autonomic abnormality localization performance of heterogeneous chest X-ray image analysis, by developing a <b>self-supervised</b> <b>learning</b> strategy called "BarlwoTwins-CXR". Methods: We utilized two publicly available datasets: the NIH Chest X-ray Dataset and the VinDr-CXR. The BarlowTwins-CXR approach was conducted in a two-stage training process. Initially, <b>self-supervised</b> <b>pre-training</b> was performed using an adjusted Barlow Twins algorithm on the NIH dataset with a Resnet50 backbone pre-trained on ImageNet. This was followed by <b>supervised</b> <b>fine-tuning</b> on the VinDr-CXR dataset using Faster R-CNN with Feature Pyramid Network (FPN). Results: Our experiments showed a significant improvement in model performance with BarlowTwins-CXR. The approach achieved a 3% increase in mAP50 accuracy compared to traditional ImageNet pre-trained models. In addition, the Ablation CAM method revealed enhanced precision in localizing chest abnormalities. Conclusion: BarlowTwins-CXR significantly enhances the efficiency and accuracy of chest X-ray image-based abnormality localization, outperforming traditional <b>transfer</b> <b>learning</b> methods and effectively overcoming domain inconsistency in cross-domain scenarios. Our experiment results demonstrate the potential of using <b>self-supervised</b> <b>learning</b> to improve the generalizability of models in medical settings with limited amounts of heterogeneous data.

{{</citation>}}


### (3/37 | 97/197) A self-supervised framework for learning whole slide representations (Xinhai Hou et al., 2024)

{{<citation>}}

Xinhai Hou, Cheng Jiang, Akhil Kondepudi, Yiwei Lyu, Asadur Zaman Chowdury, Honglak Lee, Todd C. Hollon. (2024)  
**A self-supervised framework for learning whole slide representations**
<br/>
<button class="copy-to-clipboard" title="A self-supervised framework for learning whole slide representations" index=97>
  <span class="copy-to-clipboard-item">Copy Title<span>
</button>
<div class="toast toast-copied toast-index-97 align-items-center text-bg-secondary border-0 position-absolute top-0 end-0" role="alert" aria-live="assertive" aria-atomic="true">
  <div class="d-flex">
    <div class="toast-body">
      Copied!
    </div>
  </div>
</div>

---
Primary Category: cs.CV  
Categories: cs-AI, cs-CV, cs-LG, cs.CV  
Keyword Score: 53  
Keywords: Benchmarking, Out-of-distribution, Self-supervised Learning, Supervised Learning, Transformer, Vision-and-Language  
<a type="button" class="btn btn-outline-primary" href="http://arxiv.org/abs/2402.06188v1" target="_blank" >Paper Link</a>
<button type="button" class="btn btn-outline-primary download-pdf" url="https://arxiv.org/pdf/2402.06188v1.pdf" filename="2402.06188v1.pdf">Download PDF</button>

---


**ABSTRACT**  
Whole slide imaging is fundamental to biomedical microscopy and computational pathology. However, whole slide images (WSIs) present a complex computer vision challenge due to their gigapixel size, diverse histopathologic features, spatial heterogeneity, and limited/absent data annotations. These challenges highlight that <b>supervised</b> training alone can result in suboptimal whole slide representations. <b>Self-supervised</b> representation learning can achieve high-quality WSI visual feature learning for downstream diagnostic tasks, such as cancer diagnosis or molecular genetic prediction. Here, we present a general <b>self-supervised</b> whole slide learning (S3L) framework for gigapixel-scale self-supervision of WSIs. S3L combines data transformation strategies from <b>transformer-based</b> vision and language modeling into a single unified framework to generate paired views for self-supervision. S3L leverages the inherent regional heterogeneity, histologic feature variability, and information redundancy within WSIs to learn high-quality whole-slide representations. We <b>benchmark</b> S3L visual representations on two diagnostic tasks for two biomedical microscopy modalities. S3L significantly outperforms WSI baselines for cancer diagnosis and genetic mutation prediction. Additionally, S3L achieves good performance using both in-domain and <b>out-of-distribution</b> patch encoders, demonstrating good flexibility and generalizability.

{{</citation>}}


### (4/37 | 98/197) ViGoR: Improving Visual Grounding of Large Vision Language Models with Fine-Grained Reward Modeling (Siming Yan et al., 2024)

{{<citation>}}

Siming Yan, Min Bai, Weifeng Chen, Xiong Zhou, Qixing Huang, Li Erran Li. (2024)  
**ViGoR: Improving Visual Grounding of Large Vision Language Models with Fine-Grained Reward Modeling**
<br/>
<button class="copy-to-clipboard" title="ViGoR: Improving Visual Grounding of Large Vision Language Models with Fine-Grained Reward Modeling" index=98>
  <span class="copy-to-clipboard-item">Copy Title<span>
</button>
<div class="toast toast-copied toast-index-98 align-items-center text-bg-secondary border-0 position-absolute top-0 end-0" role="alert" aria-live="assertive" aria-atomic="true">
  <div class="d-flex">
    <div class="toast-body">
      Copied!
    </div>
  </div>
</div>

---
Primary Category: cs.CV  
Categories: cs-AI, cs-CV, cs.CV  
Keyword Score: 53  
Keywords: Benchmarking, Grounding, Natural Language Understanding, Reasoning, Large Language Model, Vision-and-Language  
<a type="button" class="btn btn-outline-primary" href="http://arxiv.org/abs/2402.06118v1" target="_blank" >Paper Link</a>
<button type="button" class="btn btn-outline-primary download-pdf" url="https://arxiv.org/pdf/2402.06118v1.pdf" filename="2402.06118v1.pdf">Download PDF</button>

---


**ABSTRACT**  
By combining <b>natural</b> <b>language</b> <b>understanding</b> and the generation capabilities and breadth of knowledge of <b>large</b> <b>language</b> <b>models</b> with image perception, recent <b>large</b> <b>vision</b> <b>language</b> models (LVLMs) have shown unprecedented <b>reasoning</b> capabilities in the real world. However, the generated text often suffers from inaccurate <b>grounding</b> in the visual input, resulting in errors such as hallucinating nonexistent scene elements, missing significant parts of the scene, and inferring incorrect attributes and relationships between objects. To address these issues, we introduce a novel framework, ViGoR (Visual <b>Grounding</b> Through Fine-Grained Reward Modeling) that utilizes fine-grained reward modeling to significantly enhance the visual <b>grounding</b> of LVLMs over pre-trained baselines. This improvement is efficiently achieved using much cheaper human evaluations instead of full supervisions, as well as automated methods. We show the effectiveness of our approach through numerous metrics on several <b>benchmarks.</b> Additionally, we construct a comprehensive and challenging dataset specifically designed to validate the visual <b>grounding</b> capabilities of LVLMs. Finally, we plan to release our human annotation comprising approximately 16,000 images and generated text pairs with fine-grained evaluations to contribute to related research in the community.

{{</citation>}}


### (5/37 | 99/197) Video Annotator: A framework for efficiently building video classifiers using vision-language models and active learning (Amir Ziai et al., 2024)

{{<citation>}}

Amir Ziai, Aneesh Vartakavi. (2024)  
**Video Annotator: A framework for efficiently building video classifiers using vision-language models and active learning**
<br/>
<button class="copy-to-clipboard" title="Video Annotator: A framework for efficiently building video classifiers using vision-language models and active learning" index=99>
  <span class="copy-to-clipboard-item">Copy Title<span>
</button>
<div class="toast toast-copied toast-index-99 align-items-center text-bg-secondary border-0 position-absolute top-0 end-0" role="alert" aria-live="assertive" aria-atomic="true">
  <div class="d-flex">
    <div class="toast-body">
      Copied!
    </div>
  </div>
</div>

---
Primary Category: cs.CV  
Categories: cs-CV, cs-LG, cs.CV  
Keyword Score: 50  
Keywords: Active Learning, Foundation Model, Zero-shot, human-in-the-loop, Vision-and-Language  
<a type="button" class="btn btn-outline-primary" href="http://arxiv.org/abs/2402.06560v1" target="_blank" >Paper Link</a>
<button type="button" class="btn btn-outline-primary download-pdf" url="https://arxiv.org/pdf/2402.06560v1.pdf" filename="2402.06560v1.pdf">Download PDF</button>

---


**ABSTRACT**  
High-quality and consistent annotations are fundamental to the successful development of robust machine learning models. Traditional data annotation methods are resource-intensive and inefficient, often leading to a reliance on third-party annotators who are not the domain experts. Hard samples, which are usually the most informative for model training, tend to be difficult to label accurately and consistently without business context. These can arise unpredictably during the annotation process, requiring a variable number of iterations and rounds of feedback, leading to unforeseen expenses and time commitments to guarantee quality. We posit that more direct involvement of domain experts, using a <b>human-in-the-loop</b> system, can resolve many of these practical challenges. We propose a novel framework we call Video Annotator (VA) for annotating, managing, and iterating on video classification datasets. Our approach offers a new paradigm for an end-user-centered model development process, enhancing the efficiency, usability, and effectiveness of video classifiers. Uniquely, VA allows for a continuous annotation process, seamlessly integrating data collection and model training. We leverage the <b>zero-shot</b> capabilities of <b>vision-language</b> <b>foundation</b> <b>models</b> combined with <b>active</b> <b>learning</b> techniques, and demonstrate that VA enables the efficient creation of high-quality models. VA achieves a median 6.8 point improvement in Average Precision relative to the most competitive baseline across a wide-ranging assortment of tasks. We release a dataset with 153k labels across 56 video understanding tasks annotated by three professional video editors using VA, and also release code to replicate our experiments at: http://github.com/netflix/videoannotator.

{{</citation>}}


### (6/37 | 100/197) ControlUDA: Controllable Diffusion-assisted Unsupervised Domain Adaptation for Cross-Weather Semantic Segmentation (Fengyi Shen et al., 2024)

{{<citation>}}

Fengyi Shen, Li Zhou, Kagan Kucukaytekin, Ziyuan Liu, He Wang, Alois Knoll. (2024)  
**ControlUDA: Controllable Diffusion-assisted Unsupervised Domain Adaptation for Cross-Weather Semantic Segmentation**
<br/>
<button class="copy-to-clipboard" title="ControlUDA: Controllable Diffusion-assisted Unsupervised Domain Adaptation for Cross-Weather Semantic Segmentation" index=100>
  <span class="copy-to-clipboard-item">Copy Title<span>
</button>
<div class="toast toast-copied toast-index-100 align-items-center text-bg-secondary border-0 position-absolute top-0 end-0" role="alert" aria-live="assertive" aria-atomic="true">
  <div class="d-flex">
    <div class="toast-body">
      Copied!
    </div>
  </div>
</div>

---
Primary Category: cs.CV  
Categories: cs-CV, cs.CV  
Keyword Score: 43  
Keywords: Benchmarking, Unsupervised Learning, Text2image, Domain Adaptation, Prompt  
<a type="button" class="btn btn-outline-primary" href="http://arxiv.org/abs/2402.06446v1" target="_blank" >Paper Link</a>
<button type="button" class="btn btn-outline-primary download-pdf" url="https://arxiv.org/pdf/2402.06446v1.pdf" filename="2402.06446v1.pdf">Download PDF</button>

---


**ABSTRACT**  
Data generation is recognized as a potent strategy for <b>unsupervised</b> <b>domain</b> <b>adaptation</b> (UDA) pertaining semantic segmentation in adverse weathers. Nevertheless, these adverse weather scenarios encompass multiple possibilities, and high-fidelity data synthesis with controllable weather is under-researched in previous UDA works. The recent strides in large-scale <b>text-to-image</b> diffusion models (DM) have ushered in a novel avenue for research, enabling the generation of realistic images conditioned on semantic labels. This capability proves instrumental for cross-domain data synthesis from source to target <b>domain</b> <b>owing</b> to their shared label space. Thus, source <b>domain</b> <b>labels</b> can be paired with those generated pseudo target data for training UDA. However, from the UDA perspective, there exists several challenges for DM training: (i) ground-truth labels from target <b>domain</b> <b>are</b> missing; (ii) the <b>prompt</b> generator may produce vague or noisy descriptions of images from adverse weathers; (iii) existing arts often struggle to well handle the complex scene structure and geometry of urban scenes when conditioned only on semantic labels. To tackle the above issues, we propose ControlUDA, a diffusion-assisted framework tailored for UDA segmentation under adverse weather conditions. It first leverages target prior from a pre-trained segmentor for tuning the DM, compensating the missing target <b>domain</b> <b>labels;</b> It also contains UDAControlNet, a condition-fused multi-scale and <b>prompt-enhanced</b> network targeted at high-fidelity data generation in adverse weathers. Training UDA with our generated data brings the model performances to a new milestone (72.0 mIoU) on the popular Cityscapes-to-ACDC <b>benchmark</b> for adverse weathers. Furthermore, ControlUDA helps to achieve good model generalizability on unseen data.

{{</citation>}}


### (7/37 | 101/197) Multi-source-free Domain Adaptation via Uncertainty-aware Adaptive Distillation (Yaxuan Song et al., 2024)

{{<citation>}}

Yaxuan Song, Jianan Fan, Dongnan Liu, Weidong Cai. (2024)  
**Multi-source-free Domain Adaptation via Uncertainty-aware Adaptive Distillation**
<br/>
<button class="copy-to-clipboard" title="Multi-source-free Domain Adaptation via Uncertainty-aware Adaptive Distillation" index=101>
  <span class="copy-to-clipboard-item">Copy Title<span>
</button>
<div class="toast toast-copied toast-index-101 align-items-center text-bg-secondary border-0 position-absolute top-0 end-0" role="alert" aria-live="assertive" aria-atomic="true">
  <div class="d-flex">
    <div class="toast-body">
      Copied!
    </div>
  </div>
</div>

---
Primary Category: cs.CV  
Categories: cs-CV, cs.CV  
Keyword Score: 43  
Keywords: Benchmarking, Knowledge Distillation, Knowledge Distillation, Unsupervised Learning, Domain Adaptation  
<a type="button" class="btn btn-outline-primary" href="http://arxiv.org/abs/2402.06213v1" target="_blank" >Paper Link</a>
<button type="button" class="btn btn-outline-primary download-pdf" url="https://arxiv.org/pdf/2402.06213v1.pdf" filename="2402.06213v1.pdf">Download PDF</button>

---


**ABSTRACT**  
Source-free <b>domain</b> <b>adaptation</b> (SFDA) alleviates the <b>domain</b> <b>discrepancy</b> among data obtained from <b>domains</b> <b>without</b> accessing the data for the awareness of data privacy. However, existing conventional SFDA methods face inherent limitations in medical contexts, where medical data are typically collected from multiple institutions using various equipment. To address this problem, we propose a simple yet effective method, named Uncertainty-aware Adaptive <b>Distillation</b> (UAD) for the multi-source-free <b>unsupervised</b> <b>domain</b> <b>adaptation</b> (MSFDA) setting. UAD aims to perform well-calibrated <b>knowledge</b> <b>distillation</b> from (i) model level to deliver coordinated and reliable base model initialisation and (ii) instance level via model adaptation guided by high-quality pseudo-labels, thereby obtaining a high-performance target <b>domain</b> <b>model.</b> To verify its general applicability, we evaluate UAD on two image-based diagnosis <b>benchmarks</b> among two multi-centre datasets, where our method shows a significant performance gain compared with existing works. The code will be available soon.

{{</citation>}}


### (8/37 | 102/197) Is it safe to cross? Interpretable Risk Assessment with GPT-4V for Safety-Aware Street Crossing (Hochul Hwang et al., 2024)

{{<citation>}}

Hochul Hwang, Sunjae Kwon, Yekyung Kim, Donghyun Kim. (2024)  
**Is it safe to cross? Interpretable Risk Assessment with GPT-4V for Safety-Aware Street Crossing**
<br/>
<button class="copy-to-clipboard" title="Is it safe to cross? Interpretable Risk Assessment with GPT-4V for Safety-Aware Street Crossing" index=102>
  <span class="copy-to-clipboard-item">Copy Title<span>
</button>
<div class="toast toast-copied toast-index-102 align-items-center text-bg-secondary border-0 position-absolute top-0 end-0" role="alert" aria-live="assertive" aria-atomic="true">
  <div class="d-flex">
    <div class="toast-body">
      Copied!
    </div>
  </div>
</div>

---
Primary Category: cs.CV  
Categories: cs-AI, cs-CV, cs.CV  
Keyword Score: 36  
Keywords: Multi-modal, Multi-modal, GPT, Reasoning, Prompt  
<a type="button" class="btn btn-outline-primary" href="http://arxiv.org/abs/2402.06794v1" target="_blank" >Paper Link</a>
<button type="button" class="btn btn-outline-primary download-pdf" url="https://arxiv.org/pdf/2402.06794v1.pdf" filename="2402.06794v1.pdf">Download PDF</button>

---


**ABSTRACT**  
Safely navigating street intersections is a complex challenge for blind and low-vision individuals, as it requires a nuanced understanding of the surrounding context - a task heavily reliant on visual cues. Traditional methods for assisting in this decision-making process often fall short, lacking the ability to provide a comprehensive scene analysis and safety level. This paper introduces an innovative approach that leverages large <b>multimodal</b> models (LMMs) to interpret complex street crossing scenes, offering a potential advancement over conventional traffic signal recognition techniques. By generating a safety score and scene description in natural language, our method supports safe decision-making for the blind and low-vision individuals. We collected crosswalk intersection data that contains multiview egocentric images captured by a quadruped robot and annotated the images with corresponding safety scores based on our predefined safety score categorization. Grounded on the visual knowledge, extracted from images, and text <b>prompt,</b> we evaluate a large <b>multimodal</b> model for safety score prediction and scene description. Our findings highlight the <b>reasoning</b> and safety score prediction capabilities of a LMM, activated by various <b>prompts,</b> as a pathway to developing a trustworthy system, crucial for applications requiring reliable decision-making support.

{{</citation>}}


### (9/37 | 103/197) Learning Contrastive Feature Representations for Facial Action Unit Detection (Ziqiao Shang et al., 2024)

{{<citation>}}

Ziqiao Shang, Bin Liu, Fei Teng, Tianrui Li. (2024)  
**Learning Contrastive Feature Representations for Facial Action Unit Detection**
<br/>
<button class="copy-to-clipboard" title="Learning Contrastive Feature Representations for Facial Action Unit Detection" index=103>
  <span class="copy-to-clipboard-item">Copy Title<span>
</button>
<div class="toast toast-copied toast-index-103 align-items-center text-bg-secondary border-0 position-absolute top-0 end-0" role="alert" aria-live="assertive" aria-atomic="true">
  <div class="d-flex">
    <div class="toast-body">
      Copied!
    </div>
  </div>
</div>

---
Primary Category: cs.CV  
Categories: cs-AI, cs-CV, cs-LG, cs.CV  
Keyword Score: 33  
Keywords: Benchmarking, Contrastive Learning, Self-supervised Learning, Supervised Learning  
<a type="button" class="btn btn-outline-primary" href="http://arxiv.org/abs/2402.06165v1" target="_blank" >Paper Link</a>
<button type="button" class="btn btn-outline-primary download-pdf" url="https://arxiv.org/pdf/2402.06165v1.pdf" filename="2402.06165v1.pdf">Download PDF</button>

---


**ABSTRACT**  
The predominant approach to facial action unit (AU) detection revolves around a <b>supervised</b> multi-label binary classification problem. Existing methodologies often encode pixel-level information of AUs, thereby imposing substantial demands on model complexity and expressiveness. Moreover, this practice elevates the susceptibility to overfitting due to the presence of noisy AU labels. In the present study, we introduce a <b>contrastive</b> <b>learning</b> framework enhanced by both <b>supervised</b> and <b>self-supervised</b> signals. The objective is to acquire discriminative features, deviating from the conventional pixel-level learning paradigm within the domain of AU detection. To address the challenge posed by noisy AU labels, we augment the <b>supervised</b> signal through the introduction of a <b>self-supervised</b> signal. This augmentation is achieved through positive sample sampling, encompassing three distinct types of positive sample pairs. Furthermore, to mitigate the imbalanced distribution of each AU type, we employ an importance re-weighting strategy tailored for minority AUs. The resulting loss, denoted as AUNCE, is proposed to encapsulate this strategy. Our experimental assessments, conducted on two widely-utilized <b>benchmark</b> datasets (BP4D and DISFA), underscore the superior performance of our approach compared to state-of-the-art methods in the realm of AU detection.

{{</citation>}}


### (10/37 | 104/197) Transfer learning with generative models for object detection on limited datasets (Matteo Paiano et al., 2024)

{{<citation>}}

Matteo Paiano, Stefano Martina, Carlotta Giannelli, Filippo Caruso. (2024)  
**Transfer learning with generative models for object detection on limited datasets**
<br/>
<button class="copy-to-clipboard" title="Transfer learning with generative models for object detection on limited datasets" index=104>
  <span class="copy-to-clipboard-item">Copy Title<span>
</button>
<div class="toast toast-copied toast-index-104 align-items-center text-bg-secondary border-0 position-absolute top-0 end-0" role="alert" aria-live="assertive" aria-atomic="true">
  <div class="d-flex">
    <div class="toast-body">
      Copied!
    </div>
  </div>
</div>

---
Primary Category: cs.CV  
Categories: 68T05, 68T07, 68T10, 68T45,, I-2-6; I-2-0; I-4-8; I-4-9; I-5-1; I-5-0; I-5-4; J-3, cond-mat-dis-nn, cs-AI, cs-CV, cs-LG, cs-NA, cs.CV, math-NA  
Keyword Score: 30  
Keywords: Object Detection, Generative AI, Transfer Learning  
<a type="button" class="btn btn-outline-primary" href="http://arxiv.org/abs/2402.06784v1" target="_blank" >Paper Link</a>
<button type="button" class="btn btn-outline-primary download-pdf" url="https://arxiv.org/pdf/2402.06784v1.pdf" filename="2402.06784v1.pdf">Download PDF</button>

---


**ABSTRACT**  
The availability of data is limited in some fields, especially for <b>object</b> <b>detection</b> tasks, where it is necessary to have correctly labeled bounding boxes around each <b>object.</b> <b>A</b> notable example of such data scarcity is found in the domain of marine biology, where it is useful to develop methods to automatically detect submarine species for environmental monitoring. To address this data limitation, the state-of-the-art machine learning strategies employ two main approaches. The first involves pretraining models on existing datasets before generalizing to the specific domain of interest. The second strategy is to create synthetic datasets specifically tailored to the target domain using methods like copy-paste techniques or ad-hoc simulators. The first strategy often faces a significant domain shift, while the second demands custom solutions crafted for the specific task. In response to these challenges, here we propose a <b>transfer</b> <b>learning</b> framework that is valid for a generic scenario. In this framework, generated images help to improve the performances of an <b>object</b> <b>detector</b> in a few-real data regime. This is achieved through a diffusion-based <b>generative</b> <b>model</b> that was pretrained on large generic datasets, and is not trained on the task-specific domain. We validate our approach on <b>object</b> <b>detection</b> tasks, specifically focusing on fishes in an underwater environment, and on the more common domain of cars in an urban setting. Our method achieves detection performance comparable to models trained on thousands of images, using only a few hundreds of input data. Our results pave the way for new <b>generative</b> <b>AI-based</b> protocols for machine learning applications in various domains, for instance ranging from geophysics to biology and medicine.

{{</citation>}}


### (11/37 | 105/197) Image-based Deep Learning for the time-dependent prediction of fresh concrete properties (Max Meyer et al., 2024)

{{<citation>}}

Max Meyer, Amadeus Langer, Max Mehltretter, Dries Beyer, Max Coenen, Tobias Schack, Michael Haist, Christian Heipke. (2024)  
**Image-based Deep Learning for the time-dependent prediction of fresh concrete properties**
<br/>
<button class="copy-to-clipboard" title="Image-based Deep Learning for the time-dependent prediction of fresh concrete properties" index=105>
  <span class="copy-to-clipboard-item">Copy Title<span>
</button>
<div class="toast toast-copied toast-index-105 align-items-center text-bg-secondary border-0 position-absolute top-0 end-0" role="alert" aria-live="assertive" aria-atomic="true">
  <div class="d-flex">
    <div class="toast-body">
      Copied!
    </div>
  </div>
</div>

---
Primary Category: cs.CV  
Categories: cs-CV, cs.CV, eess-IV  
Keyword Score: 30  
Keywords: Convolution, Convolutional Neural Network, Convolutional Neural Network  
<a type="button" class="btn btn-outline-primary" href="http://arxiv.org/abs/2402.06611v1" target="_blank" >Paper Link</a>
<button type="button" class="btn btn-outline-primary download-pdf" url="https://arxiv.org/pdf/2402.06611v1.pdf" filename="2402.06611v1.pdf">Download PDF</button>

---


**ABSTRACT**  
Increasing the degree of digitisation and automation in the concrete production process can play a crucial role in reducing the CO$_2$ emissions that are associated with the production of concrete. In this paper, a method is presented that makes it possible to predict the properties of fresh concrete during the mixing process based on stereoscopic image sequences of the concretes flow behaviour. A <b>Convolutional</b> <b>Neural</b> <b>Network</b> <b>(CNN)</b> is used for the prediction, which receives the images supported by information on the mix design as input. In addition, the network receives temporal information in the form of the time difference between the time at which the images are taken and the time at which the reference values of the concretes are carried out. With this temporal information, the network implicitly learns the time-dependent behaviour of the concretes properties. The network predicts the slump flow diameter, the yield stress and the plastic viscosity. The time-dependent prediction potentially opens up the pathway to determine the temporal development of the fresh concrete properties already during mixing. This provides a huge advantage for the concrete industry. As a result, countermeasures can be taken in a timely manner. It is shown that an approach based on depth and optical flow images, supported by information of the mix design, achieves the best results.

{{</citation>}}


### (12/37 | 106/197) Large Language Models for Captioning and Retrieving Remote Sensing Images (João Daniel Silva et al., 2024)

{{<citation>}}

João Daniel Silva, João Magalhães, Devis Tuia, Bruno Martins. (2024)  
**Large Language Models for Captioning and Retrieving Remote Sensing Images**
<br/>
<button class="copy-to-clipboard" title="Large Language Models for Captioning and Retrieving Remote Sensing Images" index=106>
  <span class="copy-to-clipboard-item">Copy Title<span>
</button>
<div class="toast toast-copied toast-index-106 align-items-center text-bg-secondary border-0 position-absolute top-0 end-0" role="alert" aria-live="assertive" aria-atomic="true">
  <div class="d-flex">
    <div class="toast-body">
      Copied!
    </div>
  </div>
</div>

---
Primary Category: cs.CV  
Categories: cs-CV, cs.CV  
Keyword Score: 30  
Keywords: Text2image, Large Language Model, Vision-and-Language  
<a type="button" class="btn btn-outline-primary" href="http://arxiv.org/abs/2402.06475v1" target="_blank" >Paper Link</a>
<button type="button" class="btn btn-outline-primary download-pdf" url="https://arxiv.org/pdf/2402.06475v1.pdf" filename="2402.06475v1.pdf">Download PDF</button>

---


**ABSTRACT**  
Image captioning and cross-modal retrieval are examples of tasks that involve the joint analysis of visual and linguistic information. In connection to remote sensing imagery, these tasks can help non-expert users in extracting relevant Earth observation information for a variety of applications. Still, despite some previous efforts, the development and application of vision and language models to the remote sensing domain have been hindered by the relatively small size of the available datasets and models used in previous studies. In this work, we propose RS-CapRet, a Vision and Language method for remote sensing tasks, in particular image captioning and <b>text-image</b> retrieval. We specifically propose to use a highly capable <b>large</b> <b>decoder</b> <b>language</b> model together with image encoders adapted to remote sensing imagery through contrastive language-image pre-training. To bridge together the image encoder and language decoder, we propose training simple linear layers with examples from combining different remote sensing image captioning datasets, keeping the other parameters frozen. RS-CapRet can then generate descriptions for remote sensing images and retrieve images from textual descriptions, achieving SOTA or competitive performance with existing methods. Qualitative results illustrate that RS-CapRet can effectively leverage the pre-trained <b>large</b> <b>language</b> <b>model</b> to describe remote sensing images, retrieve them based on different types of queries, and also show the ability to process interleaved sequences of images and text in a dialogue manner.

{{</citation>}}


### (13/37 | 107/197) Multiple Instance Learning for Cheating Detection and Localization in Online Examinations (Yemeng Liu et al., 2024)

{{<citation>}}

Yemeng Liu, Jing Ren, Jianshuo Xu, Xiaomei Bai, Roopdeep Kaur, Feng Xia. (2024)  
**Multiple Instance Learning for Cheating Detection and Localization in Online Examinations**
<br/>
<button class="copy-to-clipboard" title="Multiple Instance Learning for Cheating Detection and Localization in Online Examinations" index=107>
  <span class="copy-to-clipboard-item">Copy Title<span>
</button>
<div class="toast toast-copied toast-index-107 align-items-center text-bg-secondary border-0 position-absolute top-0 end-0" role="alert" aria-live="assertive" aria-atomic="true">
  <div class="d-flex">
    <div class="toast-body">
      Copied!
    </div>
  </div>
</div>

---
Primary Category: cs.CV  
Categories: 68T40, 68T45, I-2-10; I-5-4, cs-AI, cs-CV, cs-CY, cs-LG, cs.CV  
Keyword Score: 30  
Keywords: Convolution, Multiple Instance Learning, Weakly Supervised Learning  
<a type="button" class="btn btn-outline-primary" href="http://arxiv.org/abs/2402.06107v1" target="_blank" >Paper Link</a>
<button type="button" class="btn btn-outline-primary download-pdf" url="https://arxiv.org/pdf/2402.06107v1.pdf" filename="2402.06107v1.pdf">Download PDF</button>

---


**ABSTRACT**  
The spread of the Coronavirus disease-2019 epidemic has caused many courses and exams to be conducted online. The cheating behavior detection model in examination invigilation systems plays a pivotal role in guaranteeing the equality of long-distance examinations. However, cheating behavior is rare, and most researchers do not comprehensively take into account features such as head posture, gaze angle, body posture, and background information in the task of cheating behavior detection. In this paper, we develop and present CHEESE, a CHEating detection framework via <b>multiplE</b> <b>inStancE</b> <b>learning.</b> The framework consists of a label generator that implements <b>weak</b> <b>supervision</b> and a feature encoder to learn discriminative features. In addition, the framework combines body posture and background features extracted by 3D <b>convolution</b> with eye gaze, head posture and facial features captured by OpenFace 2.0. These features are fed into the spatio-temporal graph module by stitching to analyze the spatio-temporal changes in video clips to detect the cheating behaviors. Our experiments on three datasets, UCF-Crime, ShanghaiTech and Online Exam Proctoring (OEP), prove the effectiveness of our method as compared to the state-of-the-art approaches, and obtain the frame-level AUC score of 87.58% on the OEP dataset.

{{</citation>}}


### (14/37 | 108/197) Neural Rendering based Urban Scene Reconstruction for Autonomous Driving (Shihao Shen et al., 2024)

{{<citation>}}

Shihao Shen, Louis Kerofsky, Varun Ravi Kumar, Senthil Yogamani. (2024)  
**Neural Rendering based Urban Scene Reconstruction for Autonomous Driving**
<br/>
<button class="copy-to-clipboard" title="Neural Rendering based Urban Scene Reconstruction for Autonomous Driving" index=108>
  <span class="copy-to-clipboard-item">Copy Title<span>
</button>
<div class="toast toast-copied toast-index-108 align-items-center text-bg-secondary border-0 position-absolute top-0 end-0" role="alert" aria-live="assertive" aria-atomic="true">
  <div class="d-flex">
    <div class="toast-body">
      Copied!
    </div>
  </div>
</div>

---
Primary Category: cs.CV  
Categories: cs-CV, cs-RO, cs.CV  
Keyword Score: 26  
Keywords: Object Detection, Data Augmentation, Multi-modal, Multi-modal  
<a type="button" class="btn btn-outline-primary" href="http://arxiv.org/abs/2402.06826v1" target="_blank" >Paper Link</a>
<button type="button" class="btn btn-outline-primary download-pdf" url="https://arxiv.org/pdf/2402.06826v1.pdf" filename="2402.06826v1.pdf">Download PDF</button>

---


**ABSTRACT**  
Dense 3D reconstruction has many applications in automated driving including automated annotation validation, <b>multimodal</b> <b>data</b> <b>augmentation,</b> providing ground truth annotations for systems lacking LiDAR, as well as enhancing auto-labeling accuracy. LiDAR provides highly accurate but sparse depth, whereas camera images enable estimation of dense depth but noisy particularly at long ranges. In this paper, we harness the strengths of both sensors and propose a <b>multimodal</b> 3D scene reconstruction using a framework combining neural implicit surfaces and radiance fields. In particular, our method estimates dense and accurate 3D structures and creates an implicit map representation based on signed distance fields, which can be further rendered into RGB images, and depth maps. A mesh can be extracted from the learned signed distance field and culled based on occlusion. Dynamic <b>objects</b> <b>are</b> efficiently filtered on the fly during sampling using 3D <b>object</b> <b>detection</b> models. We demonstrate qualitative and quantitative results on challenging automotive scenes.

{{</citation>}}


### (15/37 | 109/197) Improving 2D-3D Dense Correspondences with Diffusion Models for 6D Object Pose Estimation (Peter Hönig et al., 2024)

{{<citation>}}

Peter Hönig, Stefan Thalhammer, Markus Vincze. (2024)  
**Improving 2D-3D Dense Correspondences with Diffusion Models for 6D Object Pose Estimation**
<br/>
<button class="copy-to-clipboard" title="Improving 2D-3D Dense Correspondences with Diffusion Models for 6D Object Pose Estimation" index=109>
  <span class="copy-to-clipboard-item">Copy Title<span>
</button>
<div class="toast toast-copied toast-index-109 align-items-center text-bg-secondary border-0 position-absolute top-0 end-0" role="alert" aria-live="assertive" aria-atomic="true">
  <div class="d-flex">
    <div class="toast-body">
      Copied!
    </div>
  </div>
</div>

---
Primary Category: cs.CV  
Categories: cs-CV, cs.CV  
Keyword Score: 26  
Keywords: Autoencoder, Benchmarking, Benchmarking, Generative Adversarial Network  
<a type="button" class="btn btn-outline-primary" href="http://arxiv.org/abs/2402.06436v1" target="_blank" >Paper Link</a>
<button type="button" class="btn btn-outline-primary download-pdf" url="https://arxiv.org/pdf/2402.06436v1.pdf" filename="2402.06436v1.pdf">Download PDF</button>

---


**ABSTRACT**  
Estimating 2D-3D correspondences between RGB images and 3D space is a fundamental problem in 6D object pose estimation. Recent pose estimators use dense correspondence maps and Point-to-Point algorithms to estimate object poses. The accuracy of pose estimation depends heavily on the quality of the dense correspondence maps and their ability to withstand occlusion, clutter, and challenging material properties. Currently, dense correspondence maps are estimated using image-to-image translation models based on <b>GANs,</b> <b>Autoencoders,</b> or direct regression models. However, recent advancements in image-to-image translation have led to diffusion models being the superior choice when evaluated on <b>benchmarking</b> datasets. In this study, we compare image-to-image translation networks based on <b>GANs</b> and diffusion models for the downstream task of 6D object pose estimation. Our results demonstrate that the diffusion-based image-to-image translation model outperforms the <b>GAN,</b> revealing potential for further improvements in 6D object pose estimation models.

{{</citation>}}


### (16/37 | 110/197) GS-CLIP: Gaussian Splatting for Contrastive Language-Image-3D Pretraining from Real-World Data (Haoyuan Li et al., 2024)

{{<citation>}}

Haoyuan Li, Yanpeng Zhou, Yihan Zeng, Hang Xu, Xiaodan Liang. (2024)  
**GS-CLIP: Gaussian Splatting for Contrastive Language-Image-3D Pretraining from Real-World Data**
<br/>
<button class="copy-to-clipboard" title="GS-CLIP: Gaussian Splatting for Contrastive Language-Image-3D Pretraining from Real-World Data" index=110>
  <span class="copy-to-clipboard-item">Copy Title<span>
</button>
<div class="toast toast-copied toast-index-110 align-items-center text-bg-secondary border-0 position-absolute top-0 end-0" role="alert" aria-live="assertive" aria-atomic="true">
  <div class="d-flex">
    <div class="toast-body">
      Copied!
    </div>
  </div>
</div>

---
Primary Category: cs.CV  
Categories: cs-CV, cs.CV  
Keyword Score: 26  
Keywords: Multi-modal, Multi-modal, Image2text, Vision-and-Language  
<a type="button" class="btn btn-outline-primary" href="http://arxiv.org/abs/2402.06198v2" target="_blank" >Paper Link</a>
<button type="button" class="btn btn-outline-primary download-pdf" url="https://arxiv.org/pdf/2402.06198v2.pdf" filename="2402.06198v2.pdf">Download PDF</button>

---


**ABSTRACT**  
3D Shape represented as point cloud has achieve advancements in <b>multimodal</b> pre-training to align image and language descriptions, which is curial to object identification, classification, and retrieval. However, the discrete representations of point cloud lost the object's surface shape information and creates a gap between rendering results and 2D correspondences. To address this problem, we propose GS-CLIP for the first attempt to introduce 3DGS (3D Gaussian Splatting) into <b>multimodal</b> pre-training to enhance 3D representation. GS-CLIP leverages a pre-trained <b>vision-language</b> model for a learned common visual and textual space on massive real world <b>image-text</b> pairs and then learns a 3D Encoder for aligning 3DGS optimized per object. Additionally, a novel Gaussian-Aware Fusion is proposed to extract and fuse global explicit feature. As a general framework for language-image-3D pre-training, GS-CLIP is agnostic to 3D backbone networks. Experiments on challenging shows that GS-CLIP significantly improves the state-of-the-art, outperforming the previously best results.

{{</citation>}}


### (17/37 | 111/197) ContPhy: Continuum Physical Concept Learning and Reasoning from Videos (Zhicheng Zheng et al., 2024)

{{<citation>}}

Zhicheng Zheng, Xin Yan, Zhenfang Chen, Jingzhou Wang, Qin Zhi Eddie Lim, Joshua B. Tenenbaum, Chuang Gan. (2024)  
**ContPhy: Continuum Physical Concept Learning and Reasoning from Videos**
<br/>
<button class="copy-to-clipboard" title="ContPhy: Continuum Physical Concept Learning and Reasoning from Videos" index=111>
  <span class="copy-to-clipboard-item">Copy Title<span>
</button>
<div class="toast toast-copied toast-index-111 align-items-center text-bg-secondary border-0 position-absolute top-0 end-0" role="alert" aria-live="assertive" aria-atomic="true">
  <div class="d-flex">
    <div class="toast-body">
      Copied!
    </div>
  </div>
</div>

---
Primary Category: cs.CV  
Categories: cs-CV, cs.CV  
Keyword Score: 23  
Keywords: Benchmarking, Reasoning, Large Language Model  
<a type="button" class="btn btn-outline-primary" href="http://arxiv.org/abs/2402.06119v1" target="_blank" >Paper Link</a>
<button type="button" class="btn btn-outline-primary download-pdf" url="https://arxiv.org/pdf/2402.06119v1.pdf" filename="2402.06119v1.pdf">Download PDF</button>

---


**ABSTRACT**  
We introduce the Continuum Physical Dataset (ContPhy), a novel <b>benchmark</b> for assessing machine physical commonsense. ContPhy complements existing physical <b>reasoning</b> <b>benchmarks</b> by encompassing the inference of diverse physical properties, such as mass and density, across various scenarios and predicting corresponding dynamics. We evaluated a range of AI models and found that they still struggle to achieve satisfactory performance on ContPhy, which shows that the current AI models still lack physical commonsense for the continuum, especially soft-bodies, and illustrates the value of the proposed dataset. We also introduce an oracle model (ContPRO) that marries the particle-based physical dynamic models with the recent <b>large</b> <b>language</b> <b>models,</b> which enjoy the advantages of both models, precise dynamic predictions, and interpretable <b>reasoning.</b> ContPhy aims to spur progress in perception and <b>reasoning</b> within diverse physical settings, narrowing the divide between human and machine intelligence in understanding the physical world. Project page: https://physical-reasoning-project.github.io.

{{</citation>}}


### (18/37 | 112/197) Domain Adaptation Using Pseudo Labels (Sachin Chhabra et al., 2024)

{{<citation>}}

Sachin Chhabra, Hemanth Venkateswara, Baoxin Li. (2024)  
**Domain Adaptation Using Pseudo Labels**
<br/>
<button class="copy-to-clipboard" title="Domain Adaptation Using Pseudo Labels" index=112>
  <span class="copy-to-clipboard-item">Copy Title<span>
</button>
<div class="toast toast-copied toast-index-112 align-items-center text-bg-secondary border-0 position-absolute top-0 end-0" role="alert" aria-live="assertive" aria-atomic="true">
  <div class="d-flex">
    <div class="toast-body">
      Copied!
    </div>
  </div>
</div>

---
Primary Category: cs.CV  
Categories: cs-CV, cs.CV  
Keyword Score: 20  
Keywords: Unsupervised Learning, Domain Adaptation  
<a type="button" class="btn btn-outline-primary" href="http://arxiv.org/abs/2402.06809v1" target="_blank" >Paper Link</a>
<button type="button" class="btn btn-outline-primary download-pdf" url="https://arxiv.org/pdf/2402.06809v1.pdf" filename="2402.06809v1.pdf">Download PDF</button>

---


**ABSTRACT**  
In the absence of labeled target data, <b>unsupervised</b> <b>domain</b> <b>adaptation</b> approaches seek to align the marginal distributions of the source and target <b>domains</b> <b>in</b> order to train a classifier for the target. <b>Unsupervised</b> <b>domain</b> <b>alignment</b> procedures are category-agnostic and end up misaligning the categories. We address this problem by deploying a pretrained network to determine accurate labels for the target <b>domain</b> <b>using</b> a multi-stage pseudo-label refinement procedure. The filters are based on the confidence, distance (conformity), and consistency of the pseudo labels. Our results on multiple datasets demonstrate the effectiveness of our simple procedure in comparison with complex state-of-the-art techniques.

{{</citation>}}


### (19/37 | 113/197) Hybridnet for depth estimation and semantic segmentation (Dalila Sánchez-Escobedo et al., 2024)

{{<citation>}}

Dalila Sánchez-Escobedo, Xiao Lin, Josep R. Casas, Montse Pardàs. (2024)  
**Hybridnet for depth estimation and semantic segmentation**
<br/>
<button class="copy-to-clipboard" title="Hybridnet for depth estimation and semantic segmentation" index=113>
  <span class="copy-to-clipboard-item">Copy Title<span>
</button>
<div class="toast toast-copied toast-index-113 align-items-center text-bg-secondary border-0 position-absolute top-0 end-0" role="alert" aria-live="assertive" aria-atomic="true">
  <div class="d-flex">
    <div class="toast-body">
      Copied!
    </div>
  </div>
</div>

---
Primary Category: cs.CV  
Categories: cs-CV, cs.CV  
Keyword Score: 20  
Keywords: Convolution, Convolutional Neural Network  
<a type="button" class="btn btn-outline-primary" href="http://arxiv.org/abs/2402.06539v1" target="_blank" >Paper Link</a>
<button type="button" class="btn btn-outline-primary download-pdf" url="https://arxiv.org/pdf/2402.06539v1.pdf" filename="2402.06539v1.pdf">Download PDF</button>

---


**ABSTRACT**  
Semantic segmentation and depth estimation are two important tasks in the area of image processing. Traditionally, these two tasks are addressed in an independent manner. However, for those applications where geometric and semantic information is required, such as robotics or autonomous navigation,depth or semantic segmentation alone are not sufficient. In this paper, depth estimation and semantic segmentation are addressed together from a single input image through a hybrid <b>convolutional</b> <b>network.</b> Different from the state of the art methods where features are extracted by a sole feature extraction network for both tasks, the proposed HybridNet improves the features extraction by separating the relevant features for one task from those which are relevant for both. Experimental results demonstrate that HybridNet results are comparable with the state of the art methods, as well as the single task methods that HybridNet is based on.

{{</citation>}}


### (20/37 | 114/197) Feature Density Estimation for Out-of-Distribution Detection via Normalizing Flows (Evan D. Cook et al., 2024)

{{<citation>}}

Evan D. Cook, Marc-Antoine Lavoie, Steven L. Waslander. (2024)  
**Feature Density Estimation for Out-of-Distribution Detection via Normalizing Flows**
<br/>
<button class="copy-to-clipboard" title="Feature Density Estimation for Out-of-Distribution Detection via Normalizing Flows" index=114>
  <span class="copy-to-clipboard-item">Copy Title<span>
</button>
<div class="toast toast-copied toast-index-114 align-items-center text-bg-secondary border-0 position-absolute top-0 end-0" role="alert" aria-live="assertive" aria-atomic="true">
  <div class="d-flex">
    <div class="toast-body">
      Copied!
    </div>
  </div>
</div>

---
Primary Category: cs.CV  
Categories: cs-CV, cs.CV  
Keyword Score: 20  
Keywords: Out-of-distribution, Unsupervised Learning  
<a type="button" class="btn btn-outline-primary" href="http://arxiv.org/abs/2402.06537v1" target="_blank" >Paper Link</a>
<button type="button" class="btn btn-outline-primary download-pdf" url="https://arxiv.org/pdf/2402.06537v1.pdf" filename="2402.06537v1.pdf">Download PDF</button>

---


**ABSTRACT**  
<b>Out-of-distribution</b> (OOD) detection is a critical task for safe deployment of learning systems in the open world setting. In this work, we investigate the use of feature density estimation via normalizing flows for OOD detection and present a fully <b>unsupervised</b> approach which requires no exposure to OOD data, avoiding researcher bias in OOD sample selection. This is a post-hoc method which can be applied to any pretrained model, and involves training a lightweight auxiliary normalizing flow model to perform the <b>out-of-distribution</b> detection via density thresholding. Experiments on OOD detection in image classification show strong results for far-OOD data detection with only a single epoch of flow training, including 98.2% AUROC for ImageNet-1k vs. Textures, which exceeds the state of the art by 7.8%. We additionally explore the connection between the feature space distribution of the pretrained model and the performance of our method. Finally, we provide insights into training pitfalls that have plagued normalizing flows for use in OOD detection.

{{</citation>}}


### (21/37 | 115/197) CurveFormer++: 3D Lane Detection by Curve Propagation with Temporal Curve Queries and Attention (Yifeng Bai et al., 2024)

{{<citation>}}

Yifeng Bai, Zhirong Chen, Pengpeng Liang, Erkang Cheng. (2024)  
**CurveFormer++: 3D Lane Detection by Curve Propagation with Temporal Curve Queries and Attention**
<br/>
<button class="copy-to-clipboard" title="CurveFormer++: 3D Lane Detection by Curve Propagation with Temporal Curve Queries and Attention" index=115>
  <span class="copy-to-clipboard-item">Copy Title<span>
</button>
<div class="toast toast-copied toast-index-115 align-items-center text-bg-secondary border-0 position-absolute top-0 end-0" role="alert" aria-live="assertive" aria-atomic="true">
  <div class="d-flex">
    <div class="toast-body">
      Copied!
    </div>
  </div>
</div>

---
Primary Category: cs.CV  
Categories: cs-CV, cs.CV  
Keyword Score: 20  
Keywords: Convolutional Neural Network, Transformer  
<a type="button" class="btn btn-outline-primary" href="http://arxiv.org/abs/2402.06423v1" target="_blank" >Paper Link</a>
<button type="button" class="btn btn-outline-primary download-pdf" url="https://arxiv.org/pdf/2402.06423v1.pdf" filename="2402.06423v1.pdf">Download PDF</button>

---


**ABSTRACT**  
In autonomous driving, 3D lane detection using monocular cameras is an important task for various downstream planning and control tasks. Recent <b>CNN</b> and <b>Transformer</b> approaches usually apply a two-stage scheme in the model design. The first stage transforms the image feature from a front image into a bird's-eye-view (BEV) representation. Subsequently, a sub-network processes the BEV feature map to generate the 3D detection results. However, these approaches heavily rely on a challenging image feature transformation module from a perspective view to a BEV representation. In our work, we present CurveFormer++, a single-stage <b>Transformer-based</b> method that does not require the image feature view transform module and directly infers 3D lane detection results from the perspective image features. Specifically, our approach models the 3D detection task as a curve propagation problem, where each lane is represented by a curve query with a dynamic and ordered anchor point set. By employing a <b>Transformer</b> decoder, the model can iteratively refine the 3D lane detection results. A curve cross-attention module is introduced in the <b>Transformer</b> decoder to calculate similarities between image features and curve queries of lanes. To handle varying lane lengths, we employ context sampling and anchor point restriction techniques to compute more relevant image features for a curve query. Furthermore, we apply a temporal fusion module that incorporates selected informative sparse curve queries and their corresponding anchor point sets to leverage historical lane information. In the experiments, we evaluate our approach for the 3D lane detection task on two publicly available real-world datasets. The results demonstrate that our method provides outstanding performance compared with both <b>CNN</b> and <b>Transformer</b> based methods. We also conduct ablation studies to analyze the impact of each component in our approach.

{{</citation>}}


### (22/37 | 116/197) Multisource Semisupervised Adversarial Domain Generalization Network for Cross-Scene Sea\textendash Land Clutter Classification (Xiaoxuan Zhang et al., 2024)

{{<citation>}}

Xiaoxuan Zhang, Quan Pan, Salvador García. (2024)  
**Multisource Semisupervised Adversarial Domain Generalization Network for Cross-Scene Sea\textendash Land Clutter Classification**
<br/>
<button class="copy-to-clipboard" title="Multisource Semisupervised Adversarial Domain Generalization Network for Cross-Scene Sea\textendash Land Clutter Classification" index=116>
  <span class="copy-to-clipboard-item">Copy Title<span>
</button>
<div class="toast toast-copied toast-index-116 align-items-center text-bg-secondary border-0 position-absolute top-0 end-0" role="alert" aria-live="assertive" aria-atomic="true">
  <div class="d-flex">
    <div class="toast-body">
      Copied!
    </div>
  </div>
</div>

---
Primary Category: cs.CV  
Categories: cs-CV, cs.CV  
Keyword Score: 20  
Keywords: Generative Adversarial Network, Generative Adversarial Network  
<a type="button" class="btn btn-outline-primary" href="http://arxiv.org/abs/2402.06315v1" target="_blank" >Paper Link</a>
<button type="button" class="btn btn-outline-primary download-pdf" url="https://arxiv.org/pdf/2402.06315v1.pdf" filename="2402.06315v1.pdf">Download PDF</button>

---


**ABSTRACT**  
Deep learning (DL)-based sea\textendash land clutter classification for sky-wave over-the-horizon-radar (OTHR) has become a novel research topic. In engineering applications, real-time predictions of sea\textendash land clutter with existing distribution discrepancies are crucial. To solve this problem, this article proposes a novel Multisource Semisupervised Adversarial Domain Generalization Network (MSADGN) for cross-scene sea\textendash land clutter classification. MSADGN can extract domain-invariant and domain-specific features from one labeled source domain and multiple unlabeled source domains, and then generalize these features to an arbitrary unseen target domain for real-time prediction of sea\textendash land clutter. Specifically, MSADGN consists of three modules: domain-related pseudolabeling module, domain-invariant module, and domain-specific module. The first module introduces an improved pseudolabel method called domain-related pseudolabel, which is designed to generate reliable pseudolabels to fully exploit unlabeled source domains. The second module utilizes a <b>generative</b> <b>adversarial</b> <b>network</b> <b>(GAN)</b> with a multidiscriminator to extract domain-invariant features, to enhance the model's transferability in the target domain. The third module employs a parallel multiclassifier branch to extract domain-specific features, to enhance the model's discriminability in the target domain. The effectiveness of our method is validated in twelve domain generalizations (DG) scenarios. Meanwhile, we selected 10 state-of-the-art DG methods for comparison. The experimental results demonstrate the superiority of our method.

{{</citation>}}


### (23/37 | 117/197) HeadStudio: Text to Animatable Head Avatars with 3D Gaussian Splatting (Zhenglin Zhou et al., 2024)

{{<citation>}}

Zhenglin Zhou, Fan Ma, Hehe Fan, Yi Yang. (2024)  
**HeadStudio: Text to Animatable Head Avatars with 3D Gaussian Splatting**
<br/>
<button class="copy-to-clipboard" title="HeadStudio: Text to Animatable Head Avatars with 3D Gaussian Splatting" index=117>
  <span class="copy-to-clipboard-item">Copy Title<span>
</button>
<div class="toast toast-copied toast-index-117 align-items-center text-bg-secondary border-0 position-absolute top-0 end-0" role="alert" aria-live="assertive" aria-atomic="true">
  <div class="d-flex">
    <div class="toast-body">
      Copied!
    </div>
  </div>
</div>

---
Primary Category: cs.CV  
Categories: cs-CV, cs.CV  
Keyword Score: 20  
Keywords: Knowledge Distillation, Prompt  
<a type="button" class="btn btn-outline-primary" href="http://arxiv.org/abs/2402.06149v1" target="_blank" >Paper Link</a>
<button type="button" class="btn btn-outline-primary download-pdf" url="https://arxiv.org/pdf/2402.06149v1.pdf" filename="2402.06149v1.pdf">Download PDF</button>

---


**ABSTRACT**  
Creating digital avatars from textual <b>prompts</b> has long been a desirable yet challenging task. Despite the promising outcomes obtained through 2D diffusion priors in recent works, current methods face challenges in achieving high-quality and animated avatars effectively. In this paper, we present $\textbf{HeadStudio}$, a novel framework that utilizes 3D Gaussian splatting to generate realistic and animated avatars from text <b>prompts.</b> Our method drives 3D Gaussians semantically to create a flexible and achievable appearance through the intermediate FLAME representation. Specifically, we incorporate the FLAME into both 3D representation and score <b>distillation:</b> 1) FLAME-based 3D Gaussian splatting, driving 3D Gaussian points by rigging each point to a FLAME mesh. 2) FLAME-based score <b>distillation</b> sampling, utilizing FLAME-based fine-grained control signal to guide score <b>distillation</b> from the text <b>prompt.</b> Extensive experiments demonstrate the efficacy of HeadStudio in generating animatable avatars from textual <b>prompts,</b> exhibiting visually appealing appearances. The avatars are capable of rendering high-quality real-time ($\geq 40$ fps) novel views at a resolution of 1024. They can be smoothly controlled by real-world speech and video. We hope that HeadStudio can advance digital avatar creation and that the present method can widely be applied across various domains.

{{</citation>}}


### (24/37 | 118/197) More than the Sum of Its Parts: Ensembling Backbone Networks for Few-Shot Segmentation (Nico Catalano et al., 2024)

{{<citation>}}

Nico Catalano, Alessandro Maranelli, Agnese Chiatti, Matteo Matteucci. (2024)  
**More than the Sum of Its Parts: Ensembling Backbone Networks for Few-Shot Segmentation**
<br/>
<button class="copy-to-clipboard" title="More than the Sum of Its Parts: Ensembling Backbone Networks for Few-Shot Segmentation" index=118>
  <span class="copy-to-clipboard-item">Copy Title<span>
</button>
<div class="toast toast-copied toast-index-118 align-items-center text-bg-secondary border-0 position-absolute top-0 end-0" role="alert" aria-live="assertive" aria-atomic="true">
  <div class="d-flex">
    <div class="toast-body">
      Copied!
    </div>
  </div>
</div>

---
Primary Category: cs.CV  
Categories: cs-CV, cs-LG, cs.CV  
Keyword Score: 13  
Keywords: Benchmarking, Few-shot  
<a type="button" class="btn btn-outline-primary" href="http://arxiv.org/abs/2402.06581v1" target="_blank" >Paper Link</a>
<button type="button" class="btn btn-outline-primary download-pdf" url="https://arxiv.org/pdf/2402.06581v1.pdf" filename="2402.06581v1.pdf">Download PDF</button>

---


**ABSTRACT**  
Semantic segmentation is a key prerequisite to robust image understanding for applications in \acrlong{ai} and Robotics. \acrlong{fss}, in particular, concerns the extension and optimization of traditional segmentation methods in challenging conditions where limited training examples are available. A predominant approach in \acrlong{fss} is to rely on a single backbone for visual feature extraction. Choosing which backbone to leverage is a deciding factor contributing to the overall performance. In this work, we interrogate on whether fusing features from different backbones can improve the ability of \acrlong{fss} models to capture richer visual features. To tackle this question, we propose and compare two ensembling techniques-Independent Voting and Feature Fusion. Among the available \acrlong{fss} methods, we implement the proposed ensembling techniques on PANet. The module dedicated to predicting segmentation masks from the backbone embeddings in PANet avoids trainable parameters, creating a controlled `in vitro' setting for isolating the impact of different ensembling strategies. Leveraging the complementary strengths of different backbones, our approach outperforms the original single-backbone PANet across standard <b>benchmarks</b> even in challenging one-shot learning scenarios. Specifically, it achieved a performance improvement of +7.37\% on PASCAL-5\textsuperscript{i} and of +10.68\% on COCO-20\textsuperscript{i} in the top-performing scenario where three backbones are combined. These results, together with the qualitative inspection of the predicted subject masks, suggest that relying on multiple backbones in PANet leads to a more comprehensive feature representation, thus expediting the successful application of \acrlong{fss} methods in challenging, data-scarce environments.

{{</citation>}}


### (25/37 | 119/197) TETRIS: Towards Exploring the Robustness of Interactive Segmentation (Andrey Moskalenko et al., 2024)

{{<citation>}}

Andrey Moskalenko, Vlad Shakhuro, Anna Vorontsova, Anton Konushin, Anton Antonov, Alexander Krapukhin, Denis Shepelev, Konstantin Soshin. (2024)  
**TETRIS: Towards Exploring the Robustness of Interactive Segmentation**
<br/>
<button class="copy-to-clipboard" title="TETRIS: Towards Exploring the Robustness of Interactive Segmentation" index=119>
  <span class="copy-to-clipboard-item">Copy Title<span>
</button>
<div class="toast toast-copied toast-index-119 align-items-center text-bg-secondary border-0 position-absolute top-0 end-0" role="alert" aria-live="assertive" aria-atomic="true">
  <div class="d-flex">
    <div class="toast-body">
      Copied!
    </div>
  </div>
</div>

---
Primary Category: cs.CV  
Categories: 68T45, I-4-6, cs-CV, cs-HC, cs.CV  
Keyword Score: 13  
Keywords: Benchmarking, Adversarial Attack  
<a type="button" class="btn btn-outline-primary" href="http://arxiv.org/abs/2402.06132v1" target="_blank" >Paper Link</a>
<button type="button" class="btn btn-outline-primary download-pdf" url="https://arxiv.org/pdf/2402.06132v1.pdf" filename="2402.06132v1.pdf">Download PDF</button>

---


**ABSTRACT**  
Interactive segmentation methods rely on user inputs to iteratively update the selection mask. A click specifying the object of interest is arguably the most simple and intuitive interaction type, and thereby the most common choice for interactive segmentation. However, user clicking patterns in the interactive segmentation context remain unexplored. Accordingly, interactive segmentation evaluation strategies rely more on intuition and common sense rather than empirical studies (e.g., assuming that users tend to click in the center of the area with the largest error). In this work, we conduct a real user study to investigate real user clicking patterns. This study reveals that the intuitive assumption made in the common evaluation strategy may not hold. As a result, interactive segmentation models may show high scores in the standard <b>benchmarks,</b> but it does not imply that they would perform well in a real world scenario. To assess the applicability of interactive segmentation methods, we propose a novel evaluation strategy providing a more comprehensive analysis of a model's performance. To this end, we propose a methodology for finding extreme user inputs by a direct optimization in a white-box <b>adversarial</b> <b>attack</b> on the interactive segmentation model. Based on the performance with such <b>adversarial</b> <b>user</b> inputs, we assess the robustness of interactive segmentation models w.r.t click positions. Besides, we introduce a novel <b>benchmark</b> for measuring the robustness of interactive segmentation, and report the results of an extensive evaluation of dozens of models.

{{</citation>}}


### (26/37 | 120/197) Spatially-Attentive Patch-Hierarchical Network with Adaptive Sampling for Motion Deblurring (Maitreya Suin et al., 2024)

{{<citation>}}

Maitreya Suin, Kuldeep Purohit, A. N. Rajagopalan. (2024)  
**Spatially-Attentive Patch-Hierarchical Network with Adaptive Sampling for Motion Deblurring**
<br/>
<button class="copy-to-clipboard" title="Spatially-Attentive Patch-Hierarchical Network with Adaptive Sampling for Motion Deblurring" index=120>
  <span class="copy-to-clipboard-item">Copy Title<span>
</button>
<div class="toast toast-copied toast-index-120 align-items-center text-bg-secondary border-0 position-absolute top-0 end-0" role="alert" aria-live="assertive" aria-atomic="true">
  <div class="d-flex">
    <div class="toast-body">
      Copied!
    </div>
  </div>
</div>

---
Primary Category: cs.CV  
Categories: cs-CV, cs.CV  
Keyword Score: 13  
Keywords: Benchmarking, Convolution  
<a type="button" class="btn btn-outline-primary" href="http://arxiv.org/abs/2402.06117v1" target="_blank" >Paper Link</a>
<button type="button" class="btn btn-outline-primary download-pdf" url="https://arxiv.org/pdf/2402.06117v1.pdf" filename="2402.06117v1.pdf">Download PDF</button>

---


**ABSTRACT**  
This paper tackles the problem of motion deblurring of dynamic scenes. Although end-to-end fully <b>convolutional</b> designs have recently advanced the state-of-the-art in non-uniform motion deblurring, their performance-complexity trade-off is still sub-optimal. Most existing approaches achieve a large receptive field by increasing the number of generic <b>convolution</b> layers and kernel size. In this work, we propose a pixel adaptive and feature attentive design for handling large blur variations across different spatial locations and process each test image adaptively. We design a content-aware global-local filtering module that significantly improves performance by considering not only global dependencies but also by dynamically exploiting neighboring pixel information. We further introduce a pixel-adaptive non-uniform sampling strategy that implicitly discovers the difficult-to-restore regions present in the image and, in turn, performs fine-grained refinement in a progressive manner. Extensive qualitative and quantitative comparisons with prior art on deblurring <b>benchmarks</b> demonstrate that our approach performs favorably against the state-of-the-art deblurring algorithms.

{{</citation>}}


### (27/37 | 121/197) Event-to-Video Conversion for Overhead Object Detection (Darryl Hannan et al., 2024)

{{<citation>}}

Darryl Hannan, Ragib Arnab, Gavin Parpart, Garrett T. Kenyon, Edward Kim, Yijing Watkins. (2024)  
**Event-to-Video Conversion for Overhead Object Detection**
<br/>
<button class="copy-to-clipboard" title="Event-to-Video Conversion for Overhead Object Detection" index=121>
  <span class="copy-to-clipboard-item">Copy Title<span>
</button>
<div class="toast toast-copied toast-index-121 align-items-center text-bg-secondary border-0 position-absolute top-0 end-0" role="alert" aria-live="assertive" aria-atomic="true">
  <div class="d-flex">
    <div class="toast-body">
      Copied!
    </div>
  </div>
</div>

---
Primary Category: cs.CV  
Categories: cs-CV, cs.CV  
Keyword Score: 10  
Keywords: Object Detection  
<a type="button" class="btn btn-outline-primary" href="http://arxiv.org/abs/2402.06805v1" target="_blank" >Paper Link</a>
<button type="button" class="btn btn-outline-primary download-pdf" url="https://arxiv.org/pdf/2402.06805v1.pdf" filename="2402.06805v1.pdf">Download PDF</button>

---


**ABSTRACT**  
Collecting overhead imagery using an event camera is desirable due to the energy efficiency of the image sensor compared to standard cameras. However, event cameras complicate downstream image processing, especially for complex tasks such as <b>object</b> <b>detection.</b> In this paper, we investigate the viability of event streams for overhead <b>object</b> <b>detection.</b> We demonstrate that across a number of standard modeling approaches, there is a significant gap in performance between dense event representations and corresponding RGB frames. We establish that this gap is, in part, due to a lack of overlap between the event representations and the pre-training data used to initialize the weights of the <b>object</b> <b>detectors.</b> Then, we apply event-to-video conversion models that convert event streams into gray-scale video to close this gap. We demonstrate that this approach results in a large performance increase, outperforming even event-specific <b>object</b> <b>detection</b> techniques on our overhead target task. These results suggest that better alignment between event representations and existing large pre-trained models may result in greater short-term performance gains compared to end-to-end event-specific architectural improvements.

{{</citation>}}


### (28/37 | 122/197) Fingerprinting New York City's Scaffolding Problem with Longitudinal Dashcam Data (Dorin Shapira et al., 2024)

{{<citation>}}

Dorin Shapira, Matt Franchi, Wendy Ju. (2024)  
**Fingerprinting New York City's Scaffolding Problem with Longitudinal Dashcam Data**
<br/>
<button class="copy-to-clipboard" title="Fingerprinting New York City's Scaffolding Problem with Longitudinal Dashcam Data" index=122>
  <span class="copy-to-clipboard-item">Copy Title<span>
</button>
<div class="toast toast-copied toast-index-122 align-items-center text-bg-secondary border-0 position-absolute top-0 end-0" role="alert" aria-live="assertive" aria-atomic="true">
  <div class="d-flex">
    <div class="toast-body">
      Copied!
    </div>
  </div>
</div>

---
Primary Category: cs.CV  
Categories: cs-CV, cs-CY, cs.CV  
Keyword Score: 10  
Keywords: Out-of-distribution  
<a type="button" class="btn btn-outline-primary" href="http://arxiv.org/abs/2402.06801v1" target="_blank" >Paper Link</a>
<button type="button" class="btn btn-outline-primary download-pdf" url="https://arxiv.org/pdf/2402.06801v1.pdf" filename="2402.06801v1.pdf">Download PDF</button>

---


**ABSTRACT**  
Scaffolds, also called sidewalk sheds, are intended to be temporary structures to protect pedestrians from construction and repair hazards. However, some sidewalk sheds are left up for years. Long-term scaffolding becomes eyesores, creates accessibility issues on sidewalks, and gives cover to illicit activity. Today, there are over 8,000 active permits for scaffolds in NYC; the more problematic scaffolds are likely expired or unpermitted. This research uses computer vision on street-level imagery to develop a longitudinal map of scaffolding throughout the city. Using a dataset of 29,156,833 dashcam images taken between August 2023 and January 2024, we develop an algorithm to track the presence of scaffolding over time. We also design and implement methods to match detected scaffolds to reported locations of active scaffolding permits, enabling the identification of sidewalk sheds without corresponding permits. We identify 850,766 images of scaffolding, tagging 5,156 active sidewalk sheds and estimating 529 unpermitted sheds. We discuss the implications of an in-the-wild scaffolding classifier for urban tech, innovations to governmental inspection processes, and <b>out-of-distribution</b> evaluations outside of New York City.

{{</citation>}}


### (29/37 | 123/197) Transferring facade labels between point clouds with semantic octrees while considering change detection (Sophia Schwarz et al., 2024)

{{<citation>}}

Sophia Schwarz, Tanja Pilz, Olaf Wysocki, Ludwig Hoegner, Uwe Stilla. (2024)  
**Transferring facade labels between point clouds with semantic octrees while considering change detection**
<br/>
<button class="copy-to-clipboard" title="Transferring facade labels between point clouds with semantic octrees while considering change detection" index=123>
  <span class="copy-to-clipboard-item">Copy Title<span>
</button>
<div class="toast toast-copied toast-index-123 align-items-center text-bg-secondary border-0 position-absolute top-0 end-0" role="alert" aria-live="assertive" aria-atomic="true">
  <div class="d-flex">
    <div class="toast-body">
      Copied!
    </div>
  </div>
</div>

---
Primary Category: cs.CV  
Categories: cs-CV, cs-LG, cs.CV  
Keyword Score: 10  
Keywords: Transfer Learning  
<a type="button" class="btn btn-outline-primary" href="http://arxiv.org/abs/2402.06531v1" target="_blank" >Paper Link</a>
<button type="button" class="btn btn-outline-primary download-pdf" url="https://arxiv.org/pdf/2402.06531v1.pdf" filename="2402.06531v1.pdf">Download PDF</button>

---


**ABSTRACT**  
Point clouds and high-resolution 3D data have become increasingly important in various fields, including surveying, construction, and virtual reality. However, simply having this data is not enough; to extract useful information, semantic labeling is crucial. In this context, we propose a method to <b>transfer</b> <b>annotations</b> from a labeled to an unlabeled point cloud using an octree structure. The structure also analyses changes between the point clouds. Our experiments confirm that our method effectively <b>transfers</b> <b>annotations</b> while addressing changes. The primary contribution of this project is the development of the method for automatic label <b>transfer</b> <b>between</b> two different point clouds that represent the same real-world object. The proposed method can be of great importance for data-driven deep learning algorithms as it can also allow circumventing stochastic <b>transfer</b> <b>learning</b> by deterministic label <b>transfer</b> <b>between</b> datasets depicting the same objects.

{{</citation>}}


### (30/37 | 124/197) Reconstructing facade details using MLS point clouds and Bag-of-Words approach (Thomas Froech et al., 2024)

{{<citation>}}

Thomas Froech, Olaf Wysocki, Ludwig Hoegner, Uwe Stilla. (2024)  
**Reconstructing facade details using MLS point clouds and Bag-of-Words approach**
<br/>
<button class="copy-to-clipboard" title="Reconstructing facade details using MLS point clouds and Bag-of-Words approach" index=124>
  <span class="copy-to-clipboard-item">Copy Title<span>
</button>
<div class="toast toast-copied toast-index-124 align-items-center text-bg-secondary border-0 position-absolute top-0 end-0" role="alert" aria-live="assertive" aria-atomic="true">
  <div class="d-flex">
    <div class="toast-body">
      Copied!
    </div>
  </div>
</div>

---
Primary Category: cs.CV  
Categories: cs-CV, cs-LG, cs.CV  
Keyword Score: 10  
Keywords: Bag-of-Words  
<a type="button" class="btn btn-outline-primary" href="http://arxiv.org/abs/2402.06521v1" target="_blank" >Paper Link</a>
<button type="button" class="btn btn-outline-primary download-pdf" url="https://arxiv.org/pdf/2402.06521v1.pdf" filename="2402.06521v1.pdf">Download PDF</button>

---


**ABSTRACT**  
In the reconstruction of fa\c{c}ade elements, the identification of specific object types remains challenging and is often circumvented by rectangularity assumptions or the use of bounding boxes. We propose a new approach for the reconstruction of 3D fa\c{c}ade details. We combine MLS point clouds and a pre-defined 3D model library using a BoW concept, which we augment by incorporating semi-global features. We conduct experiments on the models superimposed with random noise and on the TUM-FA\c{C}ADE dataset. Our method demonstrates promising results, improving the conventional BoW approach. It holds the potential to be utilized for more realistic facade reconstruction without rectangularity assumptions, which can be used in applications such as testing automated driving functions or estimating fa\c{c}ade solar potential.

{{</citation>}}


### (31/37 | 125/197) Iris-SAM: Iris Segmentation Using a Foundational Model (Parisa Farmanifard et al., 2024)

{{<citation>}}

Parisa Farmanifard, Arun Ross. (2024)  
**Iris-SAM: Iris Segmentation Using a Foundational Model**
<br/>
<button class="copy-to-clipboard" title="Iris-SAM: Iris Segmentation Using a Foundational Model" index=125>
  <span class="copy-to-clipboard-item">Copy Title<span>
</button>
<div class="toast toast-copied toast-index-125 align-items-center text-bg-secondary border-0 position-absolute top-0 end-0" role="alert" aria-live="assertive" aria-atomic="true">
  <div class="d-flex">
    <div class="toast-body">
      Copied!
    </div>
  </div>
</div>

---
Primary Category: cs.CV  
Categories: cs-CV, cs.CV  
Keyword Score: 10  
Keywords: Fine-tuning  
<a type="button" class="btn btn-outline-primary" href="http://arxiv.org/abs/2402.06497v1" target="_blank" >Paper Link</a>
<button type="button" class="btn btn-outline-primary download-pdf" url="https://arxiv.org/pdf/2402.06497v1.pdf" filename="2402.06497v1.pdf">Download PDF</button>

---


**ABSTRACT**  
Iris segmentation is a critical component of an iris biometric system and it involves extracting the annular iris region from an ocular image. In this work, we develop a pixel-level iris segmentation model from a foundational model, viz., Segment Anything Model (SAM), that has been successfully used for segmenting arbitrary objects. The primary contribution of this work lies in the integration of different loss functions during the <b>fine-tuning</b> of SAM on ocular images. In particular, the importance of Focal Loss is borne out in the <b>fine-tuning</b> process since it strategically addresses the class imbalance problem (i.e., iris versus non-iris pixels). Experiments on ND-IRIS-0405, CASIA-Iris-Interval-v3, and IIT-Delhi-Iris datasets convey the efficacy of the trained model for the task of iris segmentation. For instance, on the ND-IRIS-0405 dataset, an average segmentation accuracy of 99.58% was achieved, compared to the best baseline performance of 89.75%.

{{</citation>}}


### (32/37 | 126/197) Maia: A Real-time Non-Verbal Chat for Human-AI Interaction (Dragos Costea et al., 2024)

{{<citation>}}

Dragos Costea, Alina Marcu, Cristina Lazar, Marius Leordeanu. (2024)  
**Maia: A Real-time Non-Verbal Chat for Human-AI Interaction**
<br/>
<button class="copy-to-clipboard" title="Maia: A Real-time Non-Verbal Chat for Human-AI Interaction" index=126>
  <span class="copy-to-clipboard-item">Copy Title<span>
</button>
<div class="toast toast-copied toast-index-126 align-items-center text-bg-secondary border-0 position-absolute top-0 end-0" role="alert" aria-live="assertive" aria-atomic="true">
  <div class="d-flex">
    <div class="toast-body">
      Copied!
    </div>
  </div>
</div>

---
Primary Category: cs.CV  
Categories: cs-CV, cs.CV  
Keyword Score: 10  
Keywords: Automatic Evaluation  
<a type="button" class="btn btn-outline-primary" href="http://arxiv.org/abs/2402.06385v1" target="_blank" >Paper Link</a>
<button type="button" class="btn btn-outline-primary download-pdf" url="https://arxiv.org/pdf/2402.06385v1.pdf" filename="2402.06385v1.pdf">Download PDF</button>

---


**ABSTRACT**  
Face-to-face communication modeling in computer vision is an area of research focusing on developing algorithms that can recognize and analyze non-verbal cues and behaviors during face-to-face interactions. We propose an alternative to text chats for Human-AI interaction, based on non-verbal visual communication only, using facial expressions and head movements that mirror, but also improvise over the human user, to efficiently engage with the users, and capture their attention in a low-cost and real-time fashion. Our goal is to track and analyze facial expressions, and other non-verbal cues in real-time, and use this information to build models that can predict and understand human behavior. We offer three different complementary approaches, based on retrieval, statistical, and deep learning techniques. We provide human as well as <b>automatic</b> <b>evaluations</b> and discuss the advantages and disadvantages of each direction.

{{</citation>}}


### (33/37 | 127/197) FD-Vision Mamba for Endoscopic Exposure Correction (Zhuoran Zheng et al., 2024)

{{<citation>}}

Zhuoran Zheng, Jun Zhang. (2024)  
**FD-Vision Mamba for Endoscopic Exposure Correction**
<br/>
<button class="copy-to-clipboard" title="FD-Vision Mamba for Endoscopic Exposure Correction" index=127>
  <span class="copy-to-clipboard-item">Copy Title<span>
</button>
<div class="toast toast-copied toast-index-127 align-items-center text-bg-secondary border-0 position-absolute top-0 end-0" role="alert" aria-live="assertive" aria-atomic="true">
  <div class="d-flex">
    <div class="toast-body">
      Copied!
    </div>
  </div>
</div>

---
Primary Category: cs.CV  
Categories: cs-CV, cs.CV  
Keyword Score: 10  
Keywords: Convolution  
<a type="button" class="btn btn-outline-primary" href="http://arxiv.org/abs/2402.06378v2" target="_blank" >Paper Link</a>
<button type="button" class="btn btn-outline-primary download-pdf" url="https://arxiv.org/pdf/2402.06378v2.pdf" filename="2402.06378v2.pdf">Download PDF</button>

---


**ABSTRACT**  
In endoscopic imaging, the recorded images are prone to exposure abnormalities, so maintaining high-quality images is important to assist healthcare professionals in performing decision-making. To overcome this issue, We design a frequency-domain based network, called FD-Vision Mamba (FDVM-Net), which achieves high-quality image exposure correction by reconstructing the frequency domain of endoscopic images. Specifically, inspired by the State Space Sequence Models (SSMs), we develop a C-SSM block that integrates the local feature extraction ability of the <b>convolutional</b> layer with the ability of the SSM to capture long-range dependencies. A two-path network is built using C-SSM as the basic function cell, and these two paths deal with the phase and amplitude information of the image, respectively. Finally, a degraded endoscopic image is reconstructed by FDVM-Net to obtain a high-quality clear image. Extensive experimental results demonstrate that our method achieves state-of-the-art results in terms of speed and accuracy, and it is noteworthy that our method can enhance endoscopic images of arbitrary resolution. The URL of the code is \url{https://github.com/zzr-idam/FDVM-Net}.

{{</citation>}}


### (34/37 | 128/197) Towards actionability for open medical imaging datasets: lessons from community-contributed platforms for data management and stewardship (Amelia Jiménez-Sánchez et al., 2024)

{{<citation>}}

Amelia Jiménez-Sánchez, Natalia-Rozalia Avlona, Dovile Juodelyte, Théo Sourget, Caroline Vang-Larsen, Hubert Dariusz Zając, Veronika Cheplygina. (2024)  
**Towards actionability for open medical imaging datasets: lessons from community-contributed platforms for data management and stewardship**
<br/>
<button class="copy-to-clipboard" title="Towards actionability for open medical imaging datasets: lessons from community-contributed platforms for data management and stewardship" index=128>
  <span class="copy-to-clipboard-item">Copy Title<span>
</button>
<div class="toast toast-copied toast-index-128 align-items-center text-bg-secondary border-0 position-absolute top-0 end-0" role="alert" aria-live="assertive" aria-atomic="true">
  <div class="d-flex">
    <div class="toast-body">
      Copied!
    </div>
  </div>
</div>

---
Primary Category: cs.CV  
Categories: cs-CV, cs.CV  
Keyword Score: 10  
Keywords: Fairness  
<a type="button" class="btn btn-outline-primary" href="http://arxiv.org/abs/2402.06353v1" target="_blank" >Paper Link</a>
<button type="button" class="btn btn-outline-primary download-pdf" url="https://arxiv.org/pdf/2402.06353v1.pdf" filename="2402.06353v1.pdf">Download PDF</button>

---


**ABSTRACT**  
Medical imaging datasets are fundamental to artificial intelligence (AI) in healthcare. The accuracy, robustness and <b>fairness</b> of diagnostic algorithms depend on the data (and its quality) on which the models are trained and evaluated. Medical imaging datasets have become increasingly available to the public, and are often hosted on Community-Contributed Platforms (CCP), including private companies like Kaggle or HuggingFace. While open data is important to enhance the redistribution of data's public value, we find that the current CCP governance model fails to uphold the quality needed and recommended practices for sharing, documenting, and evaluating datasets. In this paper we investigate medical imaging datasets on CCPs and how they are documented, shared, and maintained. We first highlight some differences between medical imaging and computer vision, particularly in the potentially harmful downstream effects due to poor adoption of recommended dataset management practices. We then analyze 20 (10 medical and 10 computer vision) popular datasets on CCPs and find vague licenses, lack of persistent identifiers and storage, duplicates and missing metadata, with differences between the platforms. We present "actionability" as a conceptual metric to reveal the data quality gap between characteristics of data on CCPs and the desired characteristics of data for AI in healthcare. Finally, we propose a commons-based stewardship model for documenting, sharing and maintaining datasets on CCPs and end with a discussion of limitations and open questions.

{{</citation>}}


### (35/37 | 129/197) Insomnia Identification via Electroencephalography (Olviya Udeshika et al., 2024)

{{<citation>}}

Olviya Udeshika, Dilshan Lakshitha, Nilantha Premakumara, Surangani Bandara. (2024)  
**Insomnia Identification via Electroencephalography**
<br/>
<button class="copy-to-clipboard" title="Insomnia Identification via Electroencephalography" index=129>
  <span class="copy-to-clipboard-item">Copy Title<span>
</button>
<div class="toast toast-copied toast-index-129 align-items-center text-bg-secondary border-0 position-absolute top-0 end-0" role="alert" aria-live="assertive" aria-atomic="true">
  <div class="d-flex">
    <div class="toast-body">
      Copied!
    </div>
  </div>
</div>

---
Primary Category: cs.CV  
Categories: cs-CV, cs.CV  
Keyword Score: 10  
Keywords: Convolutional Neural Network  
<a type="button" class="btn btn-outline-primary" href="http://arxiv.org/abs/2402.06251v1" target="_blank" >Paper Link</a>
<button type="button" class="btn btn-outline-primary download-pdf" url="https://arxiv.org/pdf/2402.06251v1.pdf" filename="2402.06251v1.pdf">Download PDF</button>

---


**ABSTRACT**  
Insomnia is a serious sleep disorder caused by abnormal or excessive neural activity in the brain. An estimated 50 million people worldwide are thought to be affected by this condition, which is the second most severe neurological disease after stroke. In order to ensure a quick recovery, an early and accurate diagnosis of insomnia enables more effective drug and treatment administration. This study proposes a method that uses deep learning to automatically identify patients with insomnia. A set of optimal features are extracted from spectral and temporal domains, including the relative power of {\sigma}, \b{eta} and {\gamma} bands, the total power, the absolute slow wave power, the power ratios of {\theta}, {\alpha}, {\gamma}, \b{eta}, {\theta}/{\alpha}, {\theta}/\b{eta}, {\alpha}/{\gamma} and {\alpha}/\b{eta}, mean, zero crossing rate, mobility, complexity, sleep efficiency and total sleep time, to accurately quantify the differences between insomnia patients and healthy subjects and develops a 1D <b>CNN</b> model for the classification process. With the experiments use Fp2 and C4 EEG channels with 50 insomnia patients and 50 healthy subjects, the proposed model arrives 99.34% accuracy without sleep stage annotation. Using the features only from a single channel, the study proposes a smart solution for insomnia patients which allows machine learning to be to simplify current sleep monitoring hardware and improve in-home ambulatory monitoring.

{{</citation>}}


### (36/37 | 130/197) Quantifying and Enhancing Multi-modal Robustness with Modality Preference (Zequn Yang et al., 2024)

{{<citation>}}

Zequn Yang, Yake Wei, Ce Liang, Di Hu. (2024)  
**Quantifying and Enhancing Multi-modal Robustness with Modality Preference**
<br/>
<button class="copy-to-clipboard" title="Quantifying and Enhancing Multi-modal Robustness with Modality Preference" index=130>
  <span class="copy-to-clipboard-item">Copy Title<span>
</button>
<div class="toast toast-copied toast-index-130 align-items-center text-bg-secondary border-0 position-absolute top-0 end-0" role="alert" aria-live="assertive" aria-atomic="true">
  <div class="d-flex">
    <div class="toast-body">
      Copied!
    </div>
  </div>
</div>

---
Primary Category: cs.CV  
Categories: cs-CV, cs-MM, cs.CV  
Keyword Score: 3  
Keywords: Multi-modal  
<a type="button" class="btn btn-outline-primary" href="http://arxiv.org/abs/2402.06244v1" target="_blank" >Paper Link</a>
<button type="button" class="btn btn-outline-primary download-pdf" url="https://arxiv.org/pdf/2402.06244v1.pdf" filename="2402.06244v1.pdf">Download PDF</button>

---


**ABSTRACT**  
<b>Multi-modal</b> models have shown a promising capability to effectively integrate information from various sources, yet meanwhile, they are found vulnerable to pervasive perturbations, such as uni-modal attacks and missing conditions. To counter these perturbations, robust <b>multi-modal</b> representations are highly expected, which are positioned well away from the discriminative <b>multi-modal</b> decision boundary. In this paper, different from conventional empirical studies, we focus on a commonly used joint <b>multi-modal</b> framework and theoretically discover that larger uni-modal representation margins and more reliable integration for modalities are essential components for achieving higher robustness. This discovery can further explain the limitation of <b>multi-modal</b> robustness and the phenomenon that <b>multi-modal</b> models are often vulnerable to attacks on the specific modality. Moreover, our analysis reveals how the widespread issue, that the model has different preferences for modalities, limits the <b>multi-modal</b> robustness by influencing the essential components and could lead to attacks on the specific modality highly effective. Inspired by our theoretical finding, we introduce a training procedure called Certifiable Robust <b>Multi-modal</b> Training (CRMT), which can alleviate this influence from modality preference and explicitly regulate essential components to significantly improve robustness in a certifiable manner. Our method demonstrates substantial improvements in performance and robustness compared with existing methods. Furthermore, our training procedure can be easily extended to enhance other robust training strategies, highlighting its credibility and flexibility.

{{</citation>}}


## stat.ML (5)



### (0/5 | 131/197) Flexible infinite-width graph convolutional networks and the importance of representation learning (Ben Anson et al., 2024)

{{<citation>}}

Ben Anson, Edward Milsom, Laurence Aitchison. (2024)  
**Flexible infinite-width graph convolutional networks and the importance of representation learning**
<br/>
<button class="copy-to-clipboard" title="Flexible infinite-width graph convolutional networks and the importance of representation learning" index=131>
  <span class="copy-to-clipboard-item">Copy Title<span>
</button>
<div class="toast toast-copied toast-index-131 align-items-center text-bg-secondary border-0 position-absolute top-0 end-0" role="alert" aria-live="assertive" aria-atomic="true">
  <div class="d-flex">
    <div class="toast-body">
      Copied!
    </div>
  </div>
</div>

---
Primary Category: stat.ML  
Categories: cs-LG, stat-ML, stat.ML  
Keyword Score: 60  
Keywords: Graph Convolutional Network, Graph Classification, Node Classification, Convolution, Convolutional Neural Network, Gaussian Process  
<a type="button" class="btn btn-outline-primary" href="http://arxiv.org/abs/2402.06525v1" target="_blank" >Paper Link</a>
<button type="button" class="btn btn-outline-primary download-pdf" url="https://arxiv.org/pdf/2402.06525v1.pdf" filename="2402.06525v1.pdf">Download PDF</button>

---


**ABSTRACT**  
A common theoretical approach to understanding neural networks is to take an infinite-width limit, at which point the outputs become <b>Gaussian</b> <b>process</b> (GP) distributed. This is known as a neural network <b>Gaussian</b> <b>process</b> (NNGP). However, the NNGP kernel is fixed, and tunable only through a small number of hyperparameters, eliminating any possibility of representation learning. This contrasts with finite-width NNs, which are often believed to perform well precisely because they are able to learn representations. Thus in simplifying NNs to make them theoretically tractable, NNGPs may eliminate precisely what makes them work well (representation learning). This motivated us to understand whether representation learning is necessary in a range of <b>graph</b> <b>classification</b> <b>tasks.</b> We develop a precise tool for this task, the <b>graph</b> <b>convolutional</b> <b>deep</b> kernel machine. This is very similar to an NNGP, in that it is an infinite width limit and uses kernels, but comes with a `knob' to control the amount of representation learning. We found that representation learning is necessary (in the sense that it gives dramatic performance improvements) in <b>graph</b> <b>classification</b> <b>tasks</b> and heterophilous <b>node</b> <b>classification</b> tasks, but not in homophilous <b>node</b> <b>classification</b> tasks.

{{</citation>}}


### (1/5 | 132/197) On the Convergence Rate of the Stochastic Gradient Descent (SGD) and application to a modified policy gradient for the Multi Armed Bandit (Stefana Anita et al., 2024)

{{<citation>}}

Stefana Anita, Gabriel Turinici. (2024)  
**On the Convergence Rate of the Stochastic Gradient Descent (SGD) and application to a modified policy gradient for the Multi Armed Bandit**
<br/>
<button class="copy-to-clipboard" title="On the Convergence Rate of the Stochastic Gradient Descent (SGD) and application to a modified policy gradient for the Multi Armed Bandit" index=132>
  <span class="copy-to-clipboard-item">Copy Title<span>
</button>
<div class="toast toast-copied toast-index-132 align-items-center text-bg-secondary border-0 position-absolute top-0 end-0" role="alert" aria-live="assertive" aria-atomic="true">
  <div class="d-flex">
    <div class="toast-body">
      Copied!
    </div>
  </div>
</div>

---
Primary Category: stat.ML  
Categories: cs-AI, cs-DS, cs-LG, cs-NA, math-NA, stat-ML, stat.ML  
Keyword Score: 30  
Keywords: Bandit Algorithm, Stochastic Gradient Descent, Stochastic Gradient Descent  
<a type="button" class="btn btn-outline-primary" href="http://arxiv.org/abs/2402.06388v1" target="_blank" >Paper Link</a>
<button type="button" class="btn btn-outline-primary download-pdf" url="https://arxiv.org/pdf/2402.06388v1.pdf" filename="2402.06388v1.pdf">Download PDF</button>

---


**ABSTRACT**  
We present a self-contained proof of the convergence rate of the <b>Stochastic</b> <b>Gradient</b> <b>Descent</b> <b>(SGD)</b> when the learning rate follows an inverse time decays schedule; we next apply the results to the convergence of a modified form of policy gradient Multi-Armed <b>Bandit</b> (MAB) with $L2$ regularization.

{{</citation>}}


### (2/5 | 133/197) POTEC: Off-Policy Learning for Large Action Spaces via Two-Stage Policy Decomposition (Yuta Saito et al., 2024)

{{<citation>}}

Yuta Saito, Jihan Yao, Thorsten Joachims. (2024)  
**POTEC: Off-Policy Learning for Large Action Spaces via Two-Stage Policy Decomposition**
<br/>
<button class="copy-to-clipboard" title="POTEC: Off-Policy Learning for Large Action Spaces via Two-Stage Policy Decomposition" index=133>
  <span class="copy-to-clipboard-item">Copy Title<span>
</button>
<div class="toast toast-copied toast-index-133 align-items-center text-bg-secondary border-0 position-absolute top-0 end-0" role="alert" aria-live="assertive" aria-atomic="true">
  <div class="d-flex">
    <div class="toast-body">
      Copied!
    </div>
  </div>
</div>

---
Primary Category: stat.ML  
Categories: cs-LG, stat-ML, stat.ML  
Keyword Score: 10  
Keywords: Bandit Algorithm  
<a type="button" class="btn btn-outline-primary" href="http://arxiv.org/abs/2402.06151v1" target="_blank" >Paper Link</a>
<button type="button" class="btn btn-outline-primary download-pdf" url="https://arxiv.org/pdf/2402.06151v1.pdf" filename="2402.06151v1.pdf">Download PDF</button>

---


**ABSTRACT**  
We study off-policy learning (OPL) of contextual <b>bandit</b> policies in large discrete action spaces where existing methods -- most of which rely crucially on reward-regression models or importance-weighted policy gradients -- fail due to excessive bias or variance. To overcome these issues in OPL, we propose a novel two-stage algorithm, called Policy Optimization via Two-Stage Policy Decomposition (POTEC). It leverages clustering in the action space and learns two different policies via policy- and regression-based approaches, respectively. In particular, we derive a novel low-variance gradient estimator that enables to learn a first-stage policy for cluster selection efficiently via a policy-based approach. To select a specific action within the cluster sampled by the first-stage policy, POTEC uses a second-stage policy derived from a regression-based approach within each cluster. We show that a local correctness condition, which only requires that the regression model preserves the relative expected reward differences of the actions within each cluster, ensures that our policy-gradient estimator is unbiased and the second-stage policy is optimal. We also show that POTEC provides a strict generalization of policy- and regression-based approaches and their associated assumptions. Comprehensive experiments demonstrate that POTEC provides substantial improvements in OPL effectiveness particularly in large and structured action spaces.

{{</citation>}}


### (3/5 | 134/197) Particle Denoising Diffusion Sampler (Angus Phillips et al., 2024)

{{<citation>}}

Angus Phillips, Hai-Dang Dau, Michael John Hutchinson, Valentin De Bortoli, George Deligiannidis, Arnaud Doucet. (2024)  
**Particle Denoising Diffusion Sampler**
<br/>
<button class="copy-to-clipboard" title="Particle Denoising Diffusion Sampler" index=134>
  <span class="copy-to-clipboard-item">Copy Title<span>
</button>
<div class="toast toast-copied toast-index-134 align-items-center text-bg-secondary border-0 position-absolute top-0 end-0" role="alert" aria-live="assertive" aria-atomic="true">
  <div class="d-flex">
    <div class="toast-body">
      Copied!
    </div>
  </div>
</div>

---
Primary Category: stat.ML  
Categories: cs-LG, stat-CO, stat-ML, stat.ML  
Keyword Score: 6  
Keywords: Multi-modal, Multi-modal  
<a type="button" class="btn btn-outline-primary" href="http://arxiv.org/abs/2402.06320v1" target="_blank" >Paper Link</a>
<button type="button" class="btn btn-outline-primary download-pdf" url="https://arxiv.org/pdf/2402.06320v1.pdf" filename="2402.06320v1.pdf">Download PDF</button>

---


**ABSTRACT**  
Denoising diffusion models have become ubiquitous for generative modeling. The core idea is to transport the data distribution to a Gaussian by using a diffusion. Approximate samples from the data distribution are then obtained by estimating the time-reversal of this diffusion using score matching ideas. We follow here a similar strategy to sample from unnormalized probability densities and compute their normalizing constants. However, the time-reversed diffusion is here simulated by using an original iterative particle scheme relying on a novel score matching loss. Contrary to standard denoising diffusion models, the resulting Particle Denoising Diffusion Sampler (PDDS) provides asymptotically consistent estimates under mild assumptions. We demonstrate PDDS on <b>multimodal</b> and high dimensional sampling tasks.

{{</citation>}}


### (4/5 | 135/197) Boosting-Based Sequential Meta-Tree Ensemble Construction for Improved Decision Trees (Ryota Maniwa et al., 2024)

{{<citation>}}

Ryota Maniwa, Naoki Ichijo, Yuta Nakahara, Toshiyasu Matsushima. (2024)  
**Boosting-Based Sequential Meta-Tree Ensemble Construction for Improved Decision Trees**
<br/>
<button class="copy-to-clipboard" title="Boosting-Based Sequential Meta-Tree Ensemble Construction for Improved Decision Trees" index=135>
  <span class="copy-to-clipboard-item">Copy Title<span>
</button>
<div class="toast toast-copied toast-index-135 align-items-center text-bg-secondary border-0 position-absolute top-0 end-0" role="alert" aria-live="assertive" aria-atomic="true">
  <div class="d-flex">
    <div class="toast-body">
      Copied!
    </div>
  </div>
</div>

---
Primary Category: stat.ML  
Categories: cs-LG, stat-ML, stat.ML  
Keyword Score: 3  
Keywords: Benchmarking  
<a type="button" class="btn btn-outline-primary" href="http://arxiv.org/abs/2402.06386v1" target="_blank" >Paper Link</a>
<button type="button" class="btn btn-outline-primary download-pdf" url="https://arxiv.org/pdf/2402.06386v1.pdf" filename="2402.06386v1.pdf">Download PDF</button>

---


**ABSTRACT**  
A decision tree is one of the most popular approaches in machine learning fields. However, it suffers from the problem of overfitting caused by overly deepened trees. Then, a meta-tree is recently proposed. It solves the problem of overfitting caused by overly deepened trees. Moreover, the meta-tree guarantees statistical optimality based on Bayes decision theory. Therefore, the meta-tree is expected to perform better than the decision tree. In contrast to a single decision tree, it is known that ensembles of decision trees, which are typically constructed boosting algorithms, are more effective in improving predictive performance. Thus, it is expected that ensembles of meta-trees are more effective in improving predictive performance than a single meta-tree, and there are no previous studies that construct multiple meta-trees in boosting. Therefore, in this study, we propose a method to construct multiple meta-trees using a boosting approach. Through experiments with synthetic and <b>benchmark</b> datasets, we conduct a performance comparison between the proposed methods and the conventional methods using ensembles of decision trees. Furthermore, while ensembles of decision trees can cause overfitting as well as a single decision tree, experiments confirmed that ensembles of meta-trees can prevent overfitting due to the tree depth.

{{</citation>}}


## cs.CR (2)



### (0/2 | 136/197) StruQ: Defending Against Prompt Injection with Structured Queries (Sizhe Chen et al., 2024)

{{<citation>}}

Sizhe Chen, Julien Piet, Chawin Sitawarin, David Wagner. (2024)  
**StruQ: Defending Against Prompt Injection with Structured Queries**
<br/>
<button class="copy-to-clipboard" title="StruQ: Defending Against Prompt Injection with Structured Queries" index=136>
  <span class="copy-to-clipboard-item">Copy Title<span>
</button>
<div class="toast toast-copied toast-index-136 align-items-center text-bg-secondary border-0 position-absolute top-0 end-0" role="alert" aria-live="assertive" aria-atomic="true">
  <div class="d-flex">
    <div class="toast-body">
      Copied!
    </div>
  </div>
</div>

---
Primary Category: cs.CR  
Categories: cs-CR, cs.CR  
Keyword Score: 60  
Keywords: Fine-tuning, Fine-tuning, Instruction Tuning, Large Language Model, Large Language Model, Prompt  
<a type="button" class="btn btn-outline-primary" href="http://arxiv.org/abs/2402.06363v1" target="_blank" >Paper Link</a>
<button type="button" class="btn btn-outline-primary download-pdf" url="https://arxiv.org/pdf/2402.06363v1.pdf" filename="2402.06363v1.pdf">Download PDF</button>

---


**ABSTRACT**  
Recent advances in <b>Large</b> <b>Language</b> <b>Models</b> <b>(LLMs)</b> enable exciting <b>LLM-integrated</b> applications, which perform text-based tasks by utilizing their advanced language understanding capabilities. However, as <b>LLMs</b> have improved, so have the attacks against them. <b>Prompt</b> injection attacks are an important threat: they trick the model to deviate from the original application's <b>instructions</b> <b>and</b> instead follow user directives. These attacks rely on the <b>LLM's</b> ability to follow <b>instructions</b> <b>and</b> inability to separate the <b>prompts</b> and user data. We introduce structured queries, a general approach to tackle this problem. Structured queries separate <b>prompts</b> and data into two channels. We implement a system that supports structured queries. This system is made of (1) a secure front-end that formats a <b>prompt</b> and user data into a special format, and (2) a specially trained <b>LLM</b> that can produce high-quality outputs from these inputs. The <b>LLM</b> is trained using a novel <b>fine-tuning</b> strategy: we convert a base (non-instruction-tuned) <b>LLM</b> to a structured <b>instruction-tuned</b> <b>model</b> that will only follow <b>instructions</b> <b>in</b> the <b>prompt</b> portion of a query. To do so, we augment standard <b>instruction</b> <b>tuning</b> datasets with examples that also include <b>instructions</b> <b>in</b> the data portion of the query, and <b>fine-tune</b> the model to ignore these. Our system significantly improves resistance to <b>prompt</b> injection attacks, with little or no impact on utility. Our code is released at https://github.com/Sizhe-Chen/PromptInjectionDefense.

{{</citation>}}


### (1/2 | 137/197) Towards Principled Assessment of Tabular Data Synthesis Algorithms (Yuntao Du et al., 2024)

{{<citation>}}

Yuntao Du, Ninghui Li. (2024)  
**Towards Principled Assessment of Tabular Data Synthesis Algorithms**
<br/>
<button class="copy-to-clipboard" title="Towards Principled Assessment of Tabular Data Synthesis Algorithms" index=137>
  <span class="copy-to-clipboard-item">Copy Title<span>
</button>
<div class="toast toast-copied toast-index-137 align-items-center text-bg-secondary border-0 position-absolute top-0 end-0" role="alert" aria-live="assertive" aria-atomic="true">
  <div class="d-flex">
    <div class="toast-body">
      Copied!
    </div>
  </div>
</div>

---
Primary Category: cs.CR  
Categories: cs-CR, cs-DB, cs-LG, cs.CR  
Keyword Score: 10  
Keywords: Large Language Model  
<a type="button" class="btn btn-outline-primary" href="http://arxiv.org/abs/2402.06806v1" target="_blank" >Paper Link</a>
<button type="button" class="btn btn-outline-primary download-pdf" url="https://arxiv.org/pdf/2402.06806v1.pdf" filename="2402.06806v1.pdf">Download PDF</button>

---


**ABSTRACT**  
Data synthesis has been advocated as an important approach for utilizing data while protecting data privacy. A <b>large</b> <b>number</b> <b>of</b> tabular data synthesis algorithms (which we call synthesizers) have been proposed. Some synthesizers satisfy Differential Privacy, while others aim to provide privacy in a heuristic fashion. A comprehensive understanding of the strengths and weaknesses of these synthesizers remains elusive due to lacking principled evaluation metrics and missing head-to-head comparisons of newly developed synthesizers that take advantage of diffusion models and <b>large</b> <b>language</b> <b>models</b> with state-of-the-art marginal-based synthesizers. In this paper, we present a principled and systematic evaluation framework for assessing tabular data synthesis algorithms. Specifically, we examine and critique existing evaluation metrics, and introduce a set of new metrics in terms of fidelity, privacy, and utility to address their limitations. Based on the proposed metrics, we also devise a unified objective for tuning, which can consistently improve the quality of synthetic data for all methods. We conducted extensive evaluations of 8 different types of synthesizers on 12 datasets and identified some interesting findings, which offer new directions for privacy-preserving data synthesis.

{{</citation>}}


## cs.SE (4)



### (0/4 | 138/197) Delving into Parameter-Efficient Fine-Tuning in Code Change Learning: An Empirical Study (Shuo Liu et al., 2024)

{{<citation>}}

Shuo Liu, Jacky Keung, Zhen Yang, Fang Liu, Qilin Zhou, Yihan Liao. (2024)  
**Delving into Parameter-Efficient Fine-Tuning in Code Change Learning: An Empirical Study**
<br/>
<button class="copy-to-clipboard" title="Delving into Parameter-Efficient Fine-Tuning in Code Change Learning: An Empirical Study" index=138>
  <span class="copy-to-clipboard-item">Copy Title<span>
</button>
<div class="toast toast-copied toast-index-138 align-items-center text-bg-secondary border-0 position-absolute top-0 end-0" role="alert" aria-live="assertive" aria-atomic="true">
  <div class="d-flex">
    <div class="toast-body">
      Copied!
    </div>
  </div>
</div>

---
Primary Category: cs.SE  
Categories: cs-SE, cs.SE  
Keyword Score: 60  
Keywords: Fine-tuning, Knowledge Transfer, Low-Resource, Pre-trained Language Model, Pre-trained Language Model, Summarization  
<a type="button" class="btn btn-outline-primary" href="http://arxiv.org/abs/2402.06247v1" target="_blank" >Paper Link</a>
<button type="button" class="btn btn-outline-primary download-pdf" url="https://arxiv.org/pdf/2402.06247v1.pdf" filename="2402.06247v1.pdf">Download PDF</button>

---


**ABSTRACT**  
Compared to Full-Model <b>Fine-Tuning</b> (FMFT), Parameter Efficient <b>Fine-Tuning</b> (PEFT) has demonstrated superior performance and lower computational overhead in several code understanding tasks, such as code <b>summarization</b> and code search. This advantage can be attributed to PEFT's ability to alleviate the catastrophic forgetting issue of <b>Pre-trained</b> <b>Language</b> <b>Models</b> <b>(PLMs)</b> by updating only a small number of parameters. As a result, PEFT effectively harnesses the <b>pre-trained</b> <b>general-purpose</b> <b>knowledge</b> <b>for</b> downstream tasks. However, existing studies primarily involve static code comprehension, aligning with the pre-training paradigm of recent <b>PLMs</b> and facilitating <b>knowledge</b> <b>transfer,</b> but they do not account for dynamic code changes. Thus, it remains unclear whether PEFT outperforms FMFT in task-specific adaptation for code-change-related tasks. To address this question, we examine two prevalent PEFT methods, namely Adapter Tuning (AT) and Low-Rank Adaptation (LoRA), and compare their performance with FMFT on five popular <b>PLMs.</b> Specifically, we evaluate their performance on two widely-studied code-change-related tasks: Just-In-Time Defect Prediction (JIT-DP) and Commit Message Generation (CMG). The results demonstrate that both AT and LoRA achieve state-of-the-art (SOTA) results in JIT-DP and exhibit comparable performances in CMG when compared to FMFT and other SOTA approaches. Furthermore, AT and LoRA exhibit superiority in cross-lingual and <b>low-resource</b> scenarios. We also conduct three probing tasks to explain the efficacy of PEFT techniques on JIT-DP and CMG tasks from both static and dynamic perspectives. The study indicates that PEFT, particularly through the use of AT and LoRA, offers promising advantages in code-change-related tasks, surpassing FMFT in certain aspects.

{{</citation>}}


### (1/4 | 139/197) CigaR: Cost-efficient Program Repair with LLMs (Dávid Hidvégi et al., 2024)

{{<citation>}}

Dávid Hidvégi, Khashayar Etemadi, Sofia Bobadilla, Martin Monperrus. (2024)  
**CigaR: Cost-efficient Program Repair with LLMs**
<br/>
<button class="copy-to-clipboard" title="CigaR: Cost-efficient Program Repair with LLMs" index=139>
  <span class="copy-to-clipboard-item">Copy Title<span>
</button>
<div class="toast toast-copied toast-index-139 align-items-center text-bg-secondary border-0 position-absolute top-0 end-0" role="alert" aria-live="assertive" aria-atomic="true">
  <div class="d-flex">
    <div class="toast-body">
      Copied!
    </div>
  </div>
</div>

---
Primary Category: cs.SE  
Categories: cs-SE, cs.SE  
Keyword Score: 30  
Keywords: Large Language Model, Large Language Model, Prompt  
<a type="button" class="btn btn-outline-primary" href="http://arxiv.org/abs/2402.06598v1" target="_blank" >Paper Link</a>
<button type="button" class="btn btn-outline-primary download-pdf" url="https://arxiv.org/pdf/2402.06598v1.pdf" filename="2402.06598v1.pdf">Download PDF</button>

---


**ABSTRACT**  
<b>Large</b> <b>language</b> <b>models</b> <b>(LLM)</b> have proven to be effective at automated program repair (APR). However, using <b>LLMs</b> can be highly costly, with companies invoicing users by the number of tokens. In this paper, we propose CigaR, the first <b>LLM-based</b> APR tool that focuses on minimizing the repair cost. CigaR works in two major steps: generating a plausible patch and multiplying plausible patches. CigaR optimizes the <b>prompts</b> and the <b>prompt</b> setting to maximize the information given to <b>LLMs</b> in the smallest possible number of tokens. Our experiments on 267 bugs from the widely used Defects4J dataset shows that CigaR reduces the token cost by 62. On average, CigaR spends 171k tokens per bug while the baseline uses 451k tokens. On the subset of bugs that are fixed by both, CigaR spends 20k per bug while the baseline uses 695k tokens, a cost saving of 97. Our extensive experiments show that CigaR is a cost-effective <b>LLM-based</b> program repair tool that uses a low number of tokens to generate automatic patches.

{{</citation>}}


### (2/4 | 140/197) Empirically Exploring How Novices Write Software Models in Alloy (Ana Jovanovic et al., 2024)

{{<citation>}}

Ana Jovanovic, Allison Sullivan. (2024)  
**Empirically Exploring How Novices Write Software Models in Alloy**
<br/>
<button class="copy-to-clipboard" title="Empirically Exploring How Novices Write Software Models in Alloy" index=140>
  <span class="copy-to-clipboard-item">Copy Title<span>
</button>
<div class="toast toast-copied toast-index-140 align-items-center text-bg-secondary border-0 position-absolute top-0 end-0" role="alert" aria-live="assertive" aria-atomic="true">
  <div class="d-flex">
    <div class="toast-body">
      Copied!
    </div>
  </div>
</div>

---
Primary Category: cs.SE  
Categories: cs-SE, cs.SE  
Keyword Score: 13  
Keywords: Benchmarking, Reasoning  
<a type="button" class="btn btn-outline-primary" href="http://arxiv.org/abs/2402.06624v1" target="_blank" >Paper Link</a>
<button type="button" class="btn btn-outline-primary download-pdf" url="https://arxiv.org/pdf/2402.06624v1.pdf" filename="2402.06624v1.pdf">Download PDF</button>

---


**ABSTRACT**  
Writing declarative models has numerous benefits, ranging from automated <b>reasoning</b> and correction of design-level properties before systems are built, to automated testing and debugging of their implementations after they are built. Alloy is a declarative modeling language that is well-suited for verifying system designs. A key strength of Alloy is its scenario-finding toolset, the Analyzer, which allows users to explore all valid scenarios that adhere to the model's constraints up to a user-provided scope. However, even with visualized scenarios, it is difficult to write correct Alloy models. To address this, a growing body of work explores different techniques for debugging Alloy models. In order to develop and evaluate these techniques in an effective manor, this paper presents an empirical study of over 97,000 models written by novice users trying to learn Alloy. We investigate how users write both correct and incorrect models in order to produce a comprehensive <b>benchmark</b> for future use as well as a series of observations to guide debugging and educational efforts for Alloy model development.

{{</citation>}}


### (3/4 | 141/197) SWITCH: An Exemplar for Evaluating Self-Adaptive ML-Enabled Systems (Arya Marda et al., 2024)

{{<citation>}}

Arya Marda, Shubham Kulkarni, Karthik Vaidhyanathan. (2024)  
**SWITCH: An Exemplar for Evaluating Self-Adaptive ML-Enabled Systems**
<br/>
<button class="copy-to-clipboard" title="SWITCH: An Exemplar for Evaluating Self-Adaptive ML-Enabled Systems" index=141>
  <span class="copy-to-clipboard-item">Copy Title<span>
</button>
<div class="toast toast-copied toast-index-141 align-items-center text-bg-secondary border-0 position-absolute top-0 end-0" role="alert" aria-live="assertive" aria-atomic="true">
  <div class="d-flex">
    <div class="toast-body">
      Copied!
    </div>
  </div>
</div>

---
Primary Category: cs.SE  
Categories: cs-SE, cs.SE  
Keyword Score: 10  
Keywords: Object Detection  
<a type="button" class="btn btn-outline-primary" href="http://arxiv.org/abs/2402.06351v1" target="_blank" >Paper Link</a>
<button type="button" class="btn btn-outline-primary download-pdf" url="https://arxiv.org/pdf/2402.06351v1.pdf" filename="2402.06351v1.pdf">Download PDF</button>

---


**ABSTRACT**  
Addressing runtime uncertainties in Machine Learning-Enabled Systems (MLS) is crucial for maintaining Quality of Service (QoS). The Machine Learning Model Balancer is a concept that addresses these uncertainties by facilitating dynamic ML model switching, showing promise in improving QoS in MLS. Leveraging this concept, this paper introduces SWITCH, an exemplar developed to enhance self-adaptive capabilities in such systems through dynamic model switching in runtime. SWITCH is designed as a comprehensive web service catering to a broad range of ML scenarios, with its implementation demonstrated through an <b>object</b> <b>detection</b> use case. SWITCH provides researchers with a flexible platform to apply and evaluate their ML model switching strategies, aiming to enhance QoS in MLS. SWITCH features advanced input handling, real-time data processing, and logging for adaptation metrics supplemented with an interactive real-time dashboard for enhancing system observability. This paper details SWITCH's architecture, self-adaptation strategies through ML model switching, and its empirical validation through a case study, illustrating its potential to improve QoS in MLS. By enabling a hands-on approach to explore adaptive behaviors in ML systems, SWITCH contributes a valuable tool to the SEAMS community for research into self-adaptive mechanisms for MLS and their practical applications.

{{</citation>}}


## cs.RO (9)



### (0/9 | 142/197) NavFormer: A Transformer Architecture for Robot Target-Driven Navigation in Unknown and Dynamic Environments (Haitong Wang et al., 2024)

{{<citation>}}

Haitong Wang, Aaron Hao Tan, Goldie Nejat. (2024)  
**NavFormer: A Transformer Architecture for Robot Target-Driven Navigation in Unknown and Dynamic Environments**
<br/>
<button class="copy-to-clipboard" title="NavFormer: A Transformer Architecture for Robot Target-Driven Navigation in Unknown and Dynamic Environments" index=142>
  <span class="copy-to-clipboard-item">Copy Title<span>
</button>
<div class="toast toast-copied toast-index-142 align-items-center text-bg-secondary border-0 position-absolute top-0 end-0" role="alert" aria-live="assertive" aria-atomic="true">
  <div class="d-flex">
    <div class="toast-body">
      Copied!
    </div>
  </div>
</div>

---
Primary Category: cs.RO  
Categories: cs-RO, cs.RO  
Keyword Score: 50  
Keywords: Fine-tuning, Self-supervised Learning, Self-supervised Learning, Transformer, Reasoning  
<a type="button" class="btn btn-outline-primary" href="http://arxiv.org/abs/2402.06838v1" target="_blank" >Paper Link</a>
<button type="button" class="btn btn-outline-primary download-pdf" url="https://arxiv.org/pdf/2402.06838v1.pdf" filename="2402.06838v1.pdf">Download PDF</button>

---


**ABSTRACT**  
In unknown cluttered and dynamic environments such as disaster scenes, mobile robots need to perform target-driven navigation in order to find people or objects of interest, while being solely guided by images of the targets. In this paper, we introduce NavFormer, a novel end-to-end <b>transformer</b> architecture developed for robot target-driven navigation in unknown and dynamic environments. NavFormer leverages the strengths of both 1) <b>transformers</b> for sequential data processing and 2) <b>self-supervised</b> <b>learning</b> (SSL) for visual representation to reason about spatial layouts and to perform collision-avoidance in dynamic settings. The architecture uniquely combines dual-visual encoders consisting of a static encoder for extracting invariant environment features for spatial <b>reasoning,</b> and a general encoder for dynamic obstacle avoidance. The primary robot navigation task is decomposed into two sub-tasks for training: single robot exploration and multi-robot collision avoidance. We perform cross-task training to enable the transfer of learned skills to the complex primary navigation task without the need for task-specific <b>fine-tuning.</b> Simulated experiments demonstrate that NavFormer can effectively navigate a mobile robot in diverse unknown environments, outperforming existing state-of-the-art methods in terms of success rate and success weighted by (normalized inverse) path length. Furthermore, a comprehensive ablation study is performed to evaluate the impact of the main design choices of the structure and training of NavFormer, further validating their effectiveness in the overall system.

{{</citation>}}


### (1/9 | 143/197) LLMs for Coding and Robotics Education (Peng Shu et al., 2024)

{{<citation>}}

Peng Shu, Huaqin Zhao, Hanqi Jiang, Yiwei Li, Shaochen Xu, Yi Pan, Zihao Wu, Zhengliang Liu, Guoyu Lu, Le Guan, Gong Chen, Xianqiao Wang Tianming Liu. (2024)  
**LLMs for Coding and Robotics Education**
<br/>
<button class="copy-to-clipboard" title="LLMs for Coding and Robotics Education" index=143>
  <span class="copy-to-clipboard-item">Copy Title<span>
</button>
<div class="toast toast-copied toast-index-143 align-items-center text-bg-secondary border-0 position-absolute top-0 end-0" role="alert" aria-live="assertive" aria-atomic="true">
  <div class="d-flex">
    <div class="toast-body">
      Copied!
    </div>
  </div>
</div>

---
Primary Category: cs.RO  
Categories: cs-AI, cs-RO, cs.RO  
Keyword Score: 46  
Keywords: Multi-modal, Multi-modal, GPT, Code Generation, Large Language Model, Large Language Model  
<a type="button" class="btn btn-outline-primary" href="http://arxiv.org/abs/2402.06116v1" target="_blank" >Paper Link</a>
<button type="button" class="btn btn-outline-primary download-pdf" url="https://arxiv.org/pdf/2402.06116v1.pdf" filename="2402.06116v1.pdf">Download PDF</button>

---


**ABSTRACT**  
<b>Large</b> <b>language</b> <b>models</b> and <b>multimodal</b> <b>large</b> <b>language</b> <b>models</b> have revolutionized artificial intelligence recently. An increasing number of regions are now embracing these advanced technologies. Within this context, robot coding education is garnering increasing attention. To teach young children how to <b>code</b> <b>and</b> compete in robot challenges, <b>large</b> <b>language</b> <b>models</b> are being utilized for robot <b>code</b> <b>explanation,</b> generation, and modification. In this paper, we highlight an important trend in robot coding education. We test several mainstream <b>large</b> <b>language</b> <b>models</b> on both traditional coding tasks and the more challenging task of robot <b>code</b> <b>generation,</b> which includes block diagrams. Our results show that <b>GPT-4V</b> outperforms other models in all of our tests but struggles with generating block diagram images.

{{</citation>}}


### (2/9 | 144/197) Reasoning Grasping via Multimodal Large Language Model (Shiyu Jin et al., 2024)

{{<citation>}}

Shiyu Jin, Jinxuan Xu, Yutian Lei, Liangjun Zhang. (2024)  
**Reasoning Grasping via Multimodal Large Language Model**
<br/>
<button class="copy-to-clipboard" title="Reasoning Grasping via Multimodal Large Language Model" index=144>
  <span class="copy-to-clipboard-item">Copy Title<span>
</button>
<div class="toast toast-copied toast-index-144 align-items-center text-bg-secondary border-0 position-absolute top-0 end-0" role="alert" aria-live="assertive" aria-atomic="true">
  <div class="d-flex">
    <div class="toast-body">
      Copied!
    </div>
  </div>
</div>

---
Primary Category: cs.RO  
Categories: cs-RO, cs.RO  
Keyword Score: 39  
Keywords: Benchmarking, Multi-modal, Multi-modal, Reasoning, Large Language Model, Large Language Model  
<a type="button" class="btn btn-outline-primary" href="http://arxiv.org/abs/2402.06798v1" target="_blank" >Paper Link</a>
<button type="button" class="btn btn-outline-primary download-pdf" url="https://arxiv.org/pdf/2402.06798v1.pdf" filename="2402.06798v1.pdf">Download PDF</button>

---


**ABSTRACT**  
Despite significant progress in robotic systems for operation within human-centric environments, existing models still heavily rely on explicit human commands to identify and manipulate specific objects. This limits their effectiveness in environments where understanding and acting on implicit human intentions are crucial. In this study, we introduce a novel task: <b>reasoning</b> grasping, where robots need to generate grasp poses based on indirect verbal instructions or intentions. To accomplish this, we propose an end-to-end <b>reasoning</b> grasping model that integrates a <b>multi-modal</b> <b>Large</b> <b>Language</b> <b>Model</b> <b>(LLM)</b> with a vision-based robotic grasping framework. In addition, we present the first <b>reasoning</b> grasping <b>benchmark</b> dataset generated from the GraspNet-1 billion, incorporating implicit instructions for object-level and part-level grasping, and this dataset will soon be available for public access. Our results show that directly integrating CLIP or LLaVA with the grasp detection model performs poorly on the challenging <b>reasoning</b> grasping tasks, while our proposed model demonstrates significantly enhanced performance both in the <b>reasoning</b> grasping <b>benchmark</b> and real-world experiments.

{{</citation>}}


### (3/9 | 145/197) Learn to Teach: Improve Sample Efficiency in Teacher-student Learning for Sim-to-Real Transfer (Feiyang Wu et al., 2024)

{{<citation>}}

Feiyang Wu, Zhaoyuan Gu, Ye Zhao, Anqi Wu. (2024)  
**Learn to Teach: Improve Sample Efficiency in Teacher-student Learning for Sim-to-Real Transfer**
<br/>
<button class="copy-to-clipboard" title="Learn to Teach: Improve Sample Efficiency in Teacher-student Learning for Sim-to-Real Transfer" index=145>
  <span class="copy-to-clipboard-item">Copy Title<span>
</button>
<div class="toast toast-copied toast-index-145 align-items-center text-bg-secondary border-0 position-absolute top-0 end-0" role="alert" aria-live="assertive" aria-atomic="true">
  <div class="d-flex">
    <div class="toast-body">
      Copied!
    </div>
  </div>
</div>

---
Primary Category: cs.RO  
Categories: cs-LG, cs-RO, cs.RO  
Keyword Score: 33  
Keywords: Benchmarking, Reinforcement Learning, Simulation, Simulator  
<a type="button" class="btn btn-outline-primary" href="http://arxiv.org/abs/2402.06783v1" target="_blank" >Paper Link</a>
<button type="button" class="btn btn-outline-primary download-pdf" url="https://arxiv.org/pdf/2402.06783v1.pdf" filename="2402.06783v1.pdf">Download PDF</button>

---


**ABSTRACT**  
<b>Simulation-to-reality</b> (sim-to-real) transfer is a fundamental problem for robot learning. Domain Randomization, which adds randomization during training, is a powerful technique that effectively addresses the sim-to-real gap. However, the noise in observations makes learning significantly harder. Recently, studies have shown that employing a teacher-student learning paradigm can accelerate training in randomized environments. Learned with privileged information, a teacher agent can instruct the student agent to operate in noisy environments. However, this approach is often not sample efficient as the experience collected by the teacher is discarded completely when training the student, wasting information revealed by the environment. In this work, we extend the teacher-student learning paradigm by proposing a sample efficient learning framework termed Learn to Teach (L2T) that recycles experience collected by the teacher agent. We observe that the dynamics of the environments for both agents remain unchanged, and the state space of the teacher is coupled with the observation space of the student. We show that a single-loop algorithm can train both the teacher and student agents under both <b>Reinforcement</b> <b>Learning</b> and Inverse <b>Reinforcement</b> <b>Learning</b> contexts. We implement variants of our methods, conduct experiments on the MuJoCo <b>benchmark,</b> and apply our methods to the Cassie robot locomotion problem. Extensive experiments show that our method achieves competitive performance while only requiring environmental interaction with the teacher.

{{</citation>}}


### (4/9 | 146/197) Reinforcement Learning for Blind Stair Climbing with Legged and Wheeled-Legged Robots (Simon Chamorro et al., 2024)

{{<citation>}}

Simon Chamorro, Victor Klemm, Miguel de la Iglesia Valls, Christopher Pal, Roland Siegwart. (2024)  
**Reinforcement Learning for Blind Stair Climbing with Legged and Wheeled-Legged Robots**
<br/>
<button class="copy-to-clipboard" title="Reinforcement Learning for Blind Stair Climbing with Legged and Wheeled-Legged Robots" index=146>
  <span class="copy-to-clipboard-item">Copy Title<span>
</button>
<div class="toast toast-copied toast-index-146 align-items-center text-bg-secondary border-0 position-absolute top-0 end-0" role="alert" aria-live="assertive" aria-atomic="true">
  <div class="d-flex">
    <div class="toast-body">
      Copied!
    </div>
  </div>
</div>

---
Primary Category: cs.RO  
Categories: cs-RO, cs.RO  
Keyword Score: 30  
Keywords: Reinforcement Learning, Simulation, Simulator  
<a type="button" class="btn btn-outline-primary" href="http://arxiv.org/abs/2402.06143v1" target="_blank" >Paper Link</a>
<button type="button" class="btn btn-outline-primary download-pdf" url="https://arxiv.org/pdf/2402.06143v1.pdf" filename="2402.06143v1.pdf">Download PDF</button>

---


**ABSTRACT**  
In recent years, legged and wheeled-legged robots have gained prominence for tasks in environments predominantly created for humans across various domains. One significant challenge faced by many of these robots is their limited capability to navigate stairs, which hampers their functionality in multi-story environments. This study proposes a method aimed at addressing this limitation, employing <b>reinforcement</b> <b>learning</b> to develop a versatile controller applicable to a wide range of robots. In contrast to the conventional velocity-based controllers, our approach builds upon a position-based formulation of the RL task, which we show to be vital for stair climbing. Furthermore, the methodology leverages an asymmetric actor-critic structure, enabling the utilization of privileged information from simulated environments during training while eliminating the reliance on exteroceptive sensors during real-world deployment. Another key feature of the proposed approach is the incorporation of a boolean observation within the controller, enabling the activation or deactivation of a stair-climbing mode. We present our results on different quadrupeds and bipedal robots in <b>simulation</b> and showcase how our method allows the balancing robot Ascento to climb 15cm stairs in the real world, a task that was previously impossible for this robot.

{{</citation>}}


### (5/9 | 147/197) ASAP-MPC: An Asynchronous Update Scheme for Online Motion Planning with Nonlinear Model Predictive Control (Dries Dirckx et al., 2024)

{{<citation>}}

Dries Dirckx, Mathias Bos, Bastiaan Vandewal, Lander Vanroye, Wilm Decré, Jan Swevers. (2024)  
**ASAP-MPC: An Asynchronous Update Scheme for Online Motion Planning with Nonlinear Model Predictive Control**
<br/>
<button class="copy-to-clipboard" title="ASAP-MPC: An Asynchronous Update Scheme for Online Motion Planning with Nonlinear Model Predictive Control" index=147>
  <span class="copy-to-clipboard-item">Copy Title<span>
</button>
<div class="toast toast-copied toast-index-147 align-items-center text-bg-secondary border-0 position-absolute top-0 end-0" role="alert" aria-live="assertive" aria-atomic="true">
  <div class="d-flex">
    <div class="toast-body">
      Copied!
    </div>
  </div>
</div>

---
Primary Category: cs.RO  
Categories: cs-RO, cs.RO, math-OC  
Keyword Score: 20  
Keywords: Simulation, Simulator  
<a type="button" class="btn btn-outline-primary" href="http://arxiv.org/abs/2402.06263v1" target="_blank" >Paper Link</a>
<button type="button" class="btn btn-outline-primary download-pdf" url="https://arxiv.org/pdf/2402.06263v1.pdf" filename="2402.06263v1.pdf">Download PDF</button>

---


**ABSTRACT**  
This paper presents a Nonlinear Model Predictive Control (NMPC) scheme targeted at motion planning for mechatronic motion systems, such as drones and mobile platforms. NMPC-based motion planning typically requires low computation times to be able to provide control inputs at the required rate for system stability, disturbance rejection, and overall performance. Although there exist various ways in literature to reduce the solution times in NMPC, such times may not be low enough to allow real-time implementations. This paper presents ASAP-MPC, an approach to handle varying, sometimes restrictively large, solution times with an asynchronous update scheme, always allowing for full convergence and real-time execution. The NMPC algorithm is combined with a linear state feedback controller tracking the optimised trajectories for improved robustness against possible disturbances and plant-model mismatch. ASAP-MPC seamlessly merges trajectories, resulting from subsequent NMPC solutions, providing a smooth and continuous overall trajectory for the motion system. This frameworks applicability to embedded applications is shown on two different experiment setups where a state-of-the-art method fails: a quadcopter flying through a cluttered environment in hardware-in-the-loop <b>simulation</b> and a scale model truck-trailer manoeuvring in a structured lab environment.

{{</citation>}}


### (6/9 | 148/197) Virtual and Remote Robotic Laboratory Using EJS, MATLAB and LabVIEW (Dictino Chaos et al., 2024)

{{<citation>}}

Dictino Chaos, Jesús Chacón, Jose Antonio Lopez-Orozco, Sebastian Dormido. (2024)  
**Virtual and Remote Robotic Laboratory Using EJS, MATLAB and LabVIEW**
<br/>
<button class="copy-to-clipboard" title="Virtual and Remote Robotic Laboratory Using EJS, MATLAB and LabVIEW" index=148>
  <span class="copy-to-clipboard-item">Copy Title<span>
</button>
<div class="toast toast-copied toast-index-148 align-items-center text-bg-secondary border-0 position-absolute top-0 end-0" role="alert" aria-live="assertive" aria-atomic="true">
  <div class="d-flex">
    <div class="toast-body">
      Copied!
    </div>
  </div>
</div>

---
Primary Category: cs.RO  
Categories: cs-RO, cs-SY, cs.RO, eess-SY  
Keyword Score: 20  
Keywords: Simulation, Simulator  
<a type="button" class="btn btn-outline-primary" href="http://arxiv.org/abs/2402.06203v1" target="_blank" >Paper Link</a>
<button type="button" class="btn btn-outline-primary download-pdf" url="https://arxiv.org/pdf/2402.06203v1.pdf" filename="2402.06203v1.pdf">Download PDF</button>

---


**ABSTRACT**  
This paper describes the design and implementation of a virtual and remote laboratory based on Easy Java <b>Simulations</b> (EJS) and LabVIEW. The main application of this laboratory is to improve the study of sensors in Mobile Robotics, dealing with the problems that arise on the real world experiments. This laboratory allows the user to work from their homes, tele-operating a real robot that takes measurements from its sensors in order to obtain a map of its environment. In addition, the application allows interacting with a robot <b>simulation</b> (virtual laboratory) or with a real robot (remote laboratory), with the same simple and intuitive graphical user interface in EJS. Thus, students can develop signal processing and control algorithms for the robot in <b>simulation</b> and then deploy them on the real robot for testing purposes. Practical examples of application of the laboratory on the inter University Master of Systems Engineering and Automatic Control are presented.

{{</citation>}}


### (7/9 | 149/197) Dynamic Q-planning for Online UAV Path Planning in Unknown and Complex Environments (Lidia Gianne Souza da Rocha et al., 2024)

{{<citation>}}

Lidia Gianne Souza da Rocha, Kenny Anderson Queiroz Caldas, Marco Henrique Terra, Fabio Ramos, Kelen Cristiane Teixeira Vivaldini. (2024)  
**Dynamic Q-planning for Online UAV Path Planning in Unknown and Complex Environments**
<br/>
<button class="copy-to-clipboard" title="Dynamic Q-planning for Online UAV Path Planning in Unknown and Complex Environments" index=149>
  <span class="copy-to-clipboard-item">Copy Title<span>
</button>
<div class="toast toast-copied toast-index-149 align-items-center text-bg-secondary border-0 position-absolute top-0 end-0" role="alert" aria-live="assertive" aria-atomic="true">
  <div class="d-flex">
    <div class="toast-body">
      Copied!
    </div>
  </div>
</div>

---
Primary Category: cs.RO  
Categories: cs-RO, cs.RO  
Keyword Score: 10  
Keywords: Reinforcement Learning  
<a type="button" class="btn btn-outline-primary" href="http://arxiv.org/abs/2402.06297v1" target="_blank" >Paper Link</a>
<button type="button" class="btn btn-outline-primary download-pdf" url="https://arxiv.org/pdf/2402.06297v1.pdf" filename="2402.06297v1.pdf">Download PDF</button>

---


**ABSTRACT**  
Unmanned Aerial Vehicles need an online path planning capability to move in high-risk missions in unknown and complex environments to complete them safely. However, many algorithms reported in the literature may not return reliable trajectories to solve online problems in these scenarios. The Q-Learning algorithm, a <b>Reinforcement</b> <b>Learning</b> Technique, can generate trajectories in real-time and has demonstrated fast and reliable results. This technique, however, has the disadvantage of defining the iteration number. If this value is not well defined, it will take a long time or not return an optimal trajectory. Therefore, we propose a method to dynamically choose the number of iterations to obtain the best performance of Q-Learning. The proposed method is compared to the Q-Learning algorithm with a fixed number of iterations, A*, Rapid-Exploring Random Tree, and Particle Swarm Optimization. As a result, the proposed Q-learning algorithm demonstrates the efficacy and reliability of online path planning with a dynamic number of iterations to carry out online missions in unknown and complex environments.

{{</citation>}}


### (8/9 | 150/197) Continuous-Time Radar-Inertial and Lidar-Inertial Odometry using a Gaussian Process Motion Prior (Keenan Burnett et al., 2024)

{{<citation>}}

Keenan Burnett, Angela P. Schoellig, Timothy D. Barfoot. (2024)  
**Continuous-Time Radar-Inertial and Lidar-Inertial Odometry using a Gaussian Process Motion Prior**
<br/>
<button class="copy-to-clipboard" title="Continuous-Time Radar-Inertial and Lidar-Inertial Odometry using a Gaussian Process Motion Prior" index=150>
  <span class="copy-to-clipboard-item">Copy Title<span>
</button>
<div class="toast toast-copied toast-index-150 align-items-center text-bg-secondary border-0 position-absolute top-0 end-0" role="alert" aria-live="assertive" aria-atomic="true">
  <div class="d-flex">
    <div class="toast-body">
      Copied!
    </div>
  </div>
</div>

---
Primary Category: cs.RO  
Categories: cs-RO, cs.RO  
Keyword Score: 10  
Keywords: Gaussian Process  
<a type="button" class="btn btn-outline-primary" href="http://arxiv.org/abs/2402.06174v1" target="_blank" >Paper Link</a>
<button type="button" class="btn btn-outline-primary download-pdf" url="https://arxiv.org/pdf/2402.06174v1.pdf" filename="2402.06174v1.pdf">Download PDF</button>

---


**ABSTRACT**  
In this work, we demonstrate continuous-time radar-inertial and lidar-inertial odometry using a <b>Gaussian</b> <b>process</b> motion prior. Using a sparse prior, we demonstrate improved computational complexity during preintegration and interpolation. We use a white-noise-on-acceleration motion prior and treat the gyroscope as a direct measurement of the state while preintegrating accelerometer measurements to form relative velocity factors. Our odometry is implemented using sliding-window batch trajectory estimation. To our knowledge, our work is the first to demonstrate radar-inertial odometry with a spinning mechanical radar using both gyroscope and accelerometer measurements. We improve the performance of our radar odometry by 19\% by incorporating an IMU. Our approach is efficient and we demonstrate real-time performance. Code for this project can be found at: https://github.com/utiasASRL/steam_icp

{{</citation>}}


## cs.HC (4)



### (0/4 | 151/197) Task Supportive and Personalized Human-Large Language Model Interaction: A User Study (Ben Wang et al., 2024)

{{<citation>}}

Ben Wang, Jiqun Liu, Jamshed Karimnazarov, Nicolas Thompson. (2024)  
**Task Supportive and Personalized Human-Large Language Model Interaction: A User Study**
<br/>
<button class="copy-to-clipboard" title="Task Supportive and Personalized Human-Large Language Model Interaction: A User Study" index=151>
  <span class="copy-to-clipboard-item">Copy Title<span>
</button>
<div class="toast toast-copied toast-index-151 align-items-center text-bg-secondary border-0 position-absolute top-0 end-0" role="alert" aria-live="assertive" aria-atomic="true">
  <div class="d-flex">
    <div class="toast-body">
      Copied!
    </div>
  </div>
</div>

---
Primary Category: cs.HC  
Categories: cs-HC, cs-IR, cs.HC  
Keyword Score: 50  
Keywords: ChatGPT, Information Retrieval, Large Language Model, Large Language Model, Prompt  
<a type="button" class="btn btn-outline-primary" href="http://arxiv.org/abs/2402.06170v1" target="_blank" >Paper Link</a>
<button type="button" class="btn btn-outline-primary download-pdf" url="https://arxiv.org/pdf/2402.06170v1.pdf" filename="2402.06170v1.pdf">Download PDF</button>

---


**ABSTRACT**  
<b>Large</b> <b>language</b> <b>model</b> <b>(LLM)</b> applications, such as <b>ChatGPT,</b> are a powerful tool for online <b>information-seeking</b> <b>(IS)</b> and problem-solving tasks. However, users still face challenges initializing and refining <b>prompts,</b> and their cognitive barriers and biased perceptions further impede task completion. These issues reflect broader challenges identified within the fields of IS and interactive <b>information</b> <b>retrieval</b> (IIR). To address these, our approach integrates task context and user perceptions into human-ChatGPT interactions through <b>prompt</b> engineering. We developed a <b>ChatGPT-like</b> platform integrated with supportive functions, including perception articulation, <b>prompt</b> suggestion, and conversation explanation. Our findings of a user study demonstrate that the supportive functions help users manage expectations, reduce cognitive loads, better refine <b>prompts,</b> and increase user engagement. This research enhances our comprehension of designing proactive and user-centric systems with <b>LLMs.</b> It offers insights into evaluating human-LLM interactions and emphasizes potential challenges for under served users.

{{</citation>}}


### (1/4 | 152/197) ScreenAgent: A Vision Language Model-driven Computer Control Agent (Runliang Niu et al., 2024)

{{<citation>}}

Runliang Niu, Jindong Li, Shiqi Wang, Yali Fu, Xiyu Hu, Xueyuan Leng, He Kong, Yi Chang, Qi Wang. (2024)  
**ScreenAgent: A Vision Language Model-driven Computer Control Agent**
<br/>
<button class="copy-to-clipboard" title="ScreenAgent: A Vision Language Model-driven Computer Control Agent" index=152>
  <span class="copy-to-clipboard-item">Copy Title<span>
</button>
<div class="toast toast-copied toast-index-152 align-items-center text-bg-secondary border-0 position-absolute top-0 end-0" role="alert" aria-live="assertive" aria-atomic="true">
  <div class="d-flex">
    <div class="toast-body">
      Copied!
    </div>
  </div>
</div>

---
Primary Category: cs.HC  
Categories: cs-AI, cs-CV, cs-HC, cs.HC  
Keyword Score: 40  
Keywords: GPT, Large Language Model, Large Language Model, Vision-and-Language  
<a type="button" class="btn btn-outline-primary" href="http://arxiv.org/abs/2402.07945v1" target="_blank" >Paper Link</a>
<button type="button" class="btn btn-outline-primary download-pdf" url="https://arxiv.org/pdf/2402.07945v1.pdf" filename="2402.07945v1.pdf">Download PDF</button>

---


**ABSTRACT**  
Existing <b>Large</b> <b>Language</b> <b>Models</b> <b>(LLM)</b> can invoke a variety of tools and APIs to complete complex tasks. The computer, as the most powerful and universal tool, could potentially be controlled directly by a trained <b>LLM</b> agent. Powered by the computer, we can hopefully build a more generalized agent to assist humans in various daily digital works. In this paper, we construct an environment for a Vision Language Model (VLM) agent to interact with a real computer screen. Within this environment, the agent can observe screenshots and manipulate the Graphics User Interface (GUI) by outputting mouse and keyboard actions. We also design an automated control pipeline that includes planning, acting, and reflecting phases, guiding the agent to continuously interact with the environment and complete multi-step tasks. Additionally, we construct the ScreenAgent Dataset, which collects screenshots and action sequences when completing a variety of daily computer tasks. Finally, we trained a model, ScreenAgent, which achieved computer control capabilities comparable to <b>GPT-4V</b> and demonstrated more precise UI positioning capabilities. Our attempts could inspire further research on building a generalist <b>LLM</b> agent. The code is available at \url{https://github.com/niuzaisheng/ScreenAgent}.

{{</citation>}}


### (2/4 | 153/197) Exploring Interaction Patterns for Debugging: Enhancing Conversational Capabilities of AI-assistants (Bhavya Chopra et al., 2024)

{{<citation>}}

Bhavya Chopra, Yasharth Bajpai, Param Biyani, Gustavo Soares, Arjun Radhakrishna, Chris Parnin, Sumit Gulwani. (2024)  
**Exploring Interaction Patterns for Debugging: Enhancing Conversational Capabilities of AI-assistants**
<br/>
<button class="copy-to-clipboard" title="Exploring Interaction Patterns for Debugging: Enhancing Conversational Capabilities of AI-assistants" index=153>
  <span class="copy-to-clipboard-item">Copy Title<span>
</button>
<div class="toast toast-copied toast-index-153 align-items-center text-bg-secondary border-0 position-absolute top-0 end-0" role="alert" aria-live="assertive" aria-atomic="true">
  <div class="d-flex">
    <div class="toast-body">
      Copied!
    </div>
  </div>
</div>

---
Primary Category: cs.HC  
Categories: cs-AI, cs-HC, cs-SE, cs.HC  
Keyword Score: 30  
Keywords: Natural Language Explanation, Large Language Model, Large Language Model  
<a type="button" class="btn btn-outline-primary" href="http://arxiv.org/abs/2402.06229v1" target="_blank" >Paper Link</a>
<button type="button" class="btn btn-outline-primary download-pdf" url="https://arxiv.org/pdf/2402.06229v1.pdf" filename="2402.06229v1.pdf">Download PDF</button>

---


**ABSTRACT**  
The widespread availability of <b>Large</b> <b>Language</b> <b>Models</b> <b>(LLMs)</b> within Integrated Development Environments (IDEs) has led to their speedy adoption. Conversational interactions with <b>LLMs</b> enable programmers to obtain <b>natural</b> <b>language</b> <b>explanations</b> for various software development tasks. However, <b>LLMs</b> often leap to action without sufficient context, giving rise to implicit assumptions and inaccurate responses. Conversations between developers and <b>LLMs</b> are primarily structured as question-answer pairs, where the developer is responsible for asking the the right questions and sustaining conversations across multiple turns. In this paper, we draw inspiration from interaction patterns and conversation analysis -- to design Robin, an enhanced conversational AI-assistant for debugging. Through a within-subjects user study with 12 industry professionals, we find that equipping the <b>LLM</b> to -- (1) leverage the insert expansion interaction pattern, (2) facilitate turn-taking, and (3) utilize debugging workflows -- leads to lowered conversation barriers, effective fault localization, and 5x improvement in bug resolution rates.

{{</citation>}}


### (3/4 | 154/197) 'When He Feels Cold, He Goes to the Seahorse'-Blending Generative AI into Multimaterial Storymaking for Family Expressive Arts Therapy (Di Liu et al., 2024)

{{<citation>}}

Di Liu, Hanqing Zhou, Pengcheng An. (2024)  
**'When He Feels Cold, He Goes to the Seahorse'-Blending Generative AI into Multimaterial Storymaking for Family Expressive Arts Therapy**
<br/>
<button class="copy-to-clipboard" title="'When He Feels Cold, He Goes to the Seahorse'-Blending Generative AI into Multimaterial Storymaking for Family Expressive Arts Therapy" index=154>
  <span class="copy-to-clipboard-item">Copy Title<span>
</button>
<div class="toast toast-copied toast-index-154 align-items-center text-bg-secondary border-0 position-absolute top-0 end-0" role="alert" aria-live="assertive" aria-atomic="true">
  <div class="d-flex">
    <div class="toast-body">
      Copied!
    </div>
  </div>
</div>

---
Primary Category: cs.HC  
Categories: cs-AI, cs-HC, cs.HC  
Keyword Score: 20  
Keywords: Generative AI, Knowledge Distillation  
<a type="button" class="btn btn-outline-primary" href="http://arxiv.org/abs/2402.06472v1" target="_blank" >Paper Link</a>
<button type="button" class="btn btn-outline-primary download-pdf" url="https://arxiv.org/pdf/2402.06472v1.pdf" filename="2402.06472v1.pdf">Download PDF</button>

---


**ABSTRACT**  
Storymaking, as an integrative form of expressive arts therapy, is an effective means to foster family communication. Yet, the integration of <b>generative</b> <b>AI</b> as expressive materials in therapeutic storymaking remains underexplored. And there is a lack of HCI implications on how to support families and therapists in this context. Addressing this, our study involved five weeks of storymaking sessions with seven families guided by a professional therapist. In these sessions, the families used both traditional art-making materials and image-based <b>generative</b> <b>AI</b> to create and evolve their family stories. Via the rich empirical data and commentaries from four expert therapists, we contextualize how families creatively melded AI and traditional expressive materials to externalize their ideas and feelings. Through the lens of Expressive Therapies Continuum (ETC), we characterize the therapeutic implications of AI as expressive materials. Desirable interaction qualities to support children, parents, and therapists are <b>distilled</b> for future HCI research.

{{</citation>}}


## cs.CE (2)



### (0/2 | 155/197) A plastic correction algorithm for full-field elasto-plastic finite element simulations : critical assessment of predictive capabilities and improvement by machine learning (Abhishek Palchoudhary et al., 2024)

{{<citation>}}

Abhishek Palchoudhary, Simone Peter, Vincent Maurel, Cristian Ovalle, Pierre Kerfriden. (2024)  
**A plastic correction algorithm for full-field elasto-plastic finite element simulations : critical assessment of predictive capabilities and improvement by machine learning**
<br/>
<button class="copy-to-clipboard" title="A plastic correction algorithm for full-field elasto-plastic finite element simulations : critical assessment of predictive capabilities and improvement by machine learning" index=155>
  <span class="copy-to-clipboard-item">Copy Title<span>
</button>
<div class="toast toast-copied toast-index-155 align-items-center text-bg-secondary border-0 position-absolute top-0 end-0" role="alert" aria-live="assertive" aria-atomic="true">
  <div class="d-flex">
    <div class="toast-body">
      Copied!
    </div>
  </div>
</div>

---
Primary Category: cs.CE  
Categories: cs-CE, cs.CE  
Keyword Score: 40  
Keywords: Convolution, Convolutional Neural Network, Simulation, Simulator  
<a type="button" class="btn btn-outline-primary" href="http://arxiv.org/abs/2402.06313v1" target="_blank" >Paper Link</a>
<button type="button" class="btn btn-outline-primary download-pdf" url="https://arxiv.org/pdf/2402.06313v1.pdf" filename="2402.06313v1.pdf">Download PDF</button>

---


**ABSTRACT**  
This paper introduces a new local plastic correction algorithm developed to accelerate finite element <b>simulations</b> for structures with elasto-plastic constitutive laws. The proposed method belongs to the category of generalized multiaxial Neuber-type methods enabled by pointwise proportional evolution rules. The algorithm numerically integrates J2 plasticity laws as a function of the finite element elastic response of the structure, to obtain full-field 3D elasto-plastic quantities for any proportionally applied loading. Examples of the numerical capabilities of this algorithm are shown on a structure containing a distribution of pores, for monotonic and fatigue loading. The approximation errors due to the proposed local plastic correction are also investigated. As a second point of innovation, we show that the proposed local plastic correction can be accelerated when dealing with large-scale structures by employing a simple meta-model, with virtually no added errors. Finally, we develop and investigate the merits of an additional deep-learning-based corrective layer to reduce approximations errors on a subset of structures for which full elasto-plastic FE <b>simulations</b> are performed, the solutions of which are subsequently used as training set for a <b>Convolutional</b> <b>Neural</b> <b>Network</b> algorithm designed to learn the error between full FE and plastic correction approximations.

{{</citation>}}


### (1/2 | 156/197) Energy-based PINNs for solving coupled field problems: concepts and application to the optimal design of an induction heater (Marco Baldan et al., 2024)

{{<citation>}}

Marco Baldan, Paolo Di Barba. (2024)  
**Energy-based PINNs for solving coupled field problems: concepts and application to the optimal design of an induction heater**
<br/>
<button class="copy-to-clipboard" title="Energy-based PINNs for solving coupled field problems: concepts and application to the optimal design of an induction heater" index=156>
  <span class="copy-to-clipboard-item">Copy Title<span>
</button>
<div class="toast toast-copied toast-index-156 align-items-center text-bg-secondary border-0 position-absolute top-0 end-0" role="alert" aria-live="assertive" aria-atomic="true">
  <div class="d-flex">
    <div class="toast-body">
      Copied!
    </div>
  </div>
</div>

---
Primary Category: cs.CE  
Categories: cs-CE, cs.CE  
Keyword Score: 3  
Keywords: Benchmarking  
<a type="button" class="btn btn-outline-primary" href="http://arxiv.org/abs/2402.06261v1" target="_blank" >Paper Link</a>
<button type="button" class="btn btn-outline-primary download-pdf" url="https://arxiv.org/pdf/2402.06261v1.pdf" filename="2402.06261v1.pdf">Download PDF</button>

---


**ABSTRACT**  
Physics-informed neural networks (PINNs) are neural networks (NNs) that directly encode model equations, like Partial Differential Equations (PDEs), in the network itself. While most of the PINN algorithms in the literature minimize the local residual of the governing equations, there are energy-based approaches that take a different path by minimizing the variational energy of the model. We show that in the case of the steady thermal equation weakly coupled to magnetic equation, the energy-based approach displays multiple advantages compared to the standard residual-based PINN: it is more computationally efficient, it requires a lower order of derivatives to compute, and it involves less hyperparameters. The analyzed <b>benchmark</b> problem is the optimal design of an inductor for the controlled heating of a graphite plate. The optimized device is designed involving a multi-physics problem: a time-harmonic magnetic problem and a steady thermal problem. For the former, a deep neural network solving the direct problem is supervisedly trained on Finite Element Analysis (FEA) data. In turn, the solution of the latter relies on a hypernetwork that takes as input the inductor geometry parameters and outputs the model weights of an energy-based PINN (or ePINN). Eventually, the ePINN predicts the temperature field within the graphite plate.

{{</citation>}}


## physics.flu-dyn (2)



### (0/2 | 157/197) Neural SPH: Improved Neural Modeling of Lagrangian Fluid Dynamics (Artur P. Toshev et al., 2024)

{{<citation>}}

Artur P. Toshev, Jonas A. Erbesdobler, Nikolaus A. Adams, Johannes Brandstetter. (2024)  
**Neural SPH: Improved Neural Modeling of Lagrangian Fluid Dynamics**
<br/>
<button class="copy-to-clipboard" title="Neural SPH: Improved Neural Modeling of Lagrangian Fluid Dynamics" index=157>
  <span class="copy-to-clipboard-item">Copy Title<span>
</button>
<div class="toast toast-copied toast-index-157 align-items-center text-bg-secondary border-0 position-absolute top-0 end-0" role="alert" aria-live="assertive" aria-atomic="true">
  <div class="d-flex">
    <div class="toast-body">
      Copied!
    </div>
  </div>
</div>

---
Primary Category: physics.flu-dyn  
Categories: cs-LG, physics-flu-dyn, physics.flu-dyn  
Keyword Score: 40  
Keywords: Graph Neural Network, Graph Neural Network, Simulation, Simulator  
<a type="button" class="btn btn-outline-primary" href="http://arxiv.org/abs/2402.06275v1" target="_blank" >Paper Link</a>
<button type="button" class="btn btn-outline-primary download-pdf" url="https://arxiv.org/pdf/2402.06275v1.pdf" filename="2402.06275v1.pdf">Download PDF</button>

---


**ABSTRACT**  
Smoothed particle hydrodynamics (SPH) is omnipresent in modern engineering and scientific disciplines. SPH is a class of Lagrangian schemes that discretize fluid dynamics via finite material points that are tracked through the evolving velocity field. Due to the particle-like nature of the <b>simulation,</b> <b>graph</b> <b>neural</b> <b>networks</b> <b>(GNNs)</b> have emerged as appealing and successful surrogates. However, the practical utility of such <b>GNN-based</b> simulators relies on their ability to faithfully model physics, providing accurate and stable predictions over long time horizons - which is a notoriously hard problem. In this work, we identify particle clustering originating from tensile instabilities as one of the primary pitfalls. Based on these insights, we enhance both training and rollout inference of state-of-the-art <b>GNN-based</b> simulators with varying components from standard SPH solvers, including pressure, viscous, and external force components. All neural SPH-enhanced simulators achieve better performance, often by orders of magnitude, than the baseline <b>GNNs,</b> allowing for significantly longer rollouts and significantly better physics modeling. Code available under (https://github.com/tumaer/neuralsph).

{{</citation>}}


### (1/2 | 158/197) Precision Air Flow Control via EHD Actuator: A Co-simulation and Control Design Case Study (Afshin Shaygani et al., 2024)

{{<citation>}}

Afshin Shaygani, Kazimierz Adamiak, Mehrdad R. Kermani. (2024)  
**Precision Air Flow Control via EHD Actuator: A Co-simulation and Control Design Case Study**
<br/>
<button class="copy-to-clipboard" title="Precision Air Flow Control via EHD Actuator: A Co-simulation and Control Design Case Study" index=158>
  <span class="copy-to-clipboard-item">Copy Title<span>
</button>
<div class="toast toast-copied toast-index-158 align-items-center text-bg-secondary border-0 position-absolute top-0 end-0" role="alert" aria-live="assertive" aria-atomic="true">
  <div class="d-flex">
    <div class="toast-body">
      Copied!
    </div>
  </div>
</div>

---
Primary Category: physics.flu-dyn  
Categories: cs-SY, eess-SY, physics-flu-dyn, physics-plasm-ph, physics.flu-dyn  
Keyword Score: 20  
Keywords: Simulation, Simulator  
<a type="button" class="btn btn-outline-primary" href="http://arxiv.org/abs/2402.06588v1" target="_blank" >Paper Link</a>
<button type="button" class="btn btn-outline-primary download-pdf" url="https://arxiv.org/pdf/2402.06588v1.pdf" filename="2402.06588v1.pdf">Download PDF</button>

---


**ABSTRACT**  
A Dielectric Barrier Discharge (DBD) plasma actuator for controlling airflow is proposed. It consists of diverging and converging nozzles, two concentric cylinders and an actuator mounted in-between the two cylinders. The actuator employs electrohydrodynamic (EHD) body force to induce an air jet within the air gap between the two cylinders, effectively creating a suction area while passing through the diverging nozzle, due to the Coanda effect. While merging with the air stream inside the inner cylinder, the Coanda jet effectively enhances amplification of the airflow. The outflow rate is measured by a velocity sensor at the outlet and controlled by the plasma actuator. The control strategy is based on the Active Disturbance Rejection Control (ADRC) and compared to the baseline PID controller. The actuator was modelled by seamlessly linking two modeling platforms for a co-simulation study. The CFD <b>simulation</b> of the plasma and airflow was carried out in the COMSOL multi-physics commercial software, and the control was implemented in the Simulink. The DBD plasma model was based on the two-species model of discharge, and the electric body force, calculated from the plasma <b>simulation,</b> was used in the Navier-Stokes equation for the turbulent flow <b>simulation.</b> The plasma-air flow system was analyzed using the input (the actuator voltage) and output (the outlet flow rate) data for the control design. Finally, the performance of the system of air flow control device was tested and discussed in the co-simulation process.

{{</citation>}}


## eess.AS (1)



### (0/1 | 159/197) Data-driven Joint Detection and Localization of Acoustic Reflectors (H. Nazim Bicer et al., 2024)

{{<citation>}}

H. Nazim Bicer, Cagdas Tuna, Andreas Walther, Emanuël A. P. Habets. (2024)  
**Data-driven Joint Detection and Localization of Acoustic Reflectors**
<br/>
<button class="copy-to-clipboard" title="Data-driven Joint Detection and Localization of Acoustic Reflectors" index=159>
  <span class="copy-to-clipboard-item">Copy Title<span>
</button>
<div class="toast toast-copied toast-index-159 align-items-center text-bg-secondary border-0 position-absolute top-0 end-0" role="alert" aria-live="assertive" aria-atomic="true">
  <div class="d-flex">
    <div class="toast-body">
      Copied!
    </div>
  </div>
</div>

---
Primary Category: eess.AS  
Categories: cs-SD, eess-AS, eess.AS  
Keyword Score: 40  
Keywords: Convolution, Simulation, Simulator, Recurrent Neural Network  
<a type="button" class="btn btn-outline-primary" href="http://arxiv.org/abs/2402.06246v1" target="_blank" >Paper Link</a>
<button type="button" class="btn btn-outline-primary download-pdf" url="https://arxiv.org/pdf/2402.06246v1.pdf" filename="2402.06246v1.pdf">Download PDF</button>

---


**ABSTRACT**  
Room geometry inference algorithms rely on the localization of acoustic reflectors to identify boundary surfaces of an enclosure. Rooms with highly absorptive walls or walls at large distances from the measurement setup pose challenges for such algorithms. As it is not always possible to localize all walls, we present a data-driven method to jointly detect and localize acoustic reflectors that correspond to nearby and/or reflective walls. A multi-branch <b>convolutional</b> <b>recurrent</b> <b>neural</b> <b>network</b> is employed for this purpose. The network's input consists of a time-domain acoustic beamforming map, obtained via Radon transform from multi-channel room impulse responses. A modified loss function is proposed that forces the network to pay more attention to walls that can be estimated with a small error. <b>Simulation</b> results show that the proposed method can detect nearby and/or reflective walls and improve the localization performance for the detected walls.

{{</citation>}}


## cs.DC (3)



### (0/3 | 160/197) Anubis: Towards Reliable Cloud AI Infrastructure via Proactive Validation (Yifan Xiong et al., 2024)

{{<citation>}}

Yifan Xiong, Yuting Jiang, Ziyue Yang, Lei Qu, Guoshuai Zhao, Shuguang Liu, Dong Zhong, Boris Pinzur, Jie Zhang, Yang Wang, Jithin Jose, Hossein Pourreza, Jeff Baxter, Kushal Datta, Prabhat Ram, Luke Melton, Joe Chau, Peng Cheng, Yongqiang Xiong, Lidong Zhou. (2024)  
**Anubis: Towards Reliable Cloud AI Infrastructure via Proactive Validation**
<br/>
<button class="copy-to-clipboard" title="Anubis: Towards Reliable Cloud AI Infrastructure via Proactive Validation" index=160>
  <span class="copy-to-clipboard-item">Copy Title<span>
</button>
<div class="toast toast-copied toast-index-160 align-items-center text-bg-secondary border-0 position-absolute top-0 end-0" role="alert" aria-live="assertive" aria-atomic="true">
  <div class="d-flex">
    <div class="toast-body">
      Copied!
    </div>
  </div>
</div>

---
Primary Category: cs.DC  
Categories: cs-DC, cs.DC  
Keyword Score: 33  
Keywords: Benchmarking, Simulation, Simulator, Prompt  
<a type="button" class="btn btn-outline-primary" href="http://arxiv.org/abs/2402.06194v1" target="_blank" >Paper Link</a>
<button type="button" class="btn btn-outline-primary download-pdf" url="https://arxiv.org/pdf/2402.06194v1.pdf" filename="2402.06194v1.pdf">Download PDF</button>

---


**ABSTRACT**  
Reliability in cloud AI infrastructure is crucial for cloud service providers, <b>prompting</b> the widespread use of hardware redundancies. However, these redundancies can inadvertently lead to hidden degradation, so called "gray failure", for AI workloads, significantly affecting end-to-end performance and concealing performance issues, which complicates root cause analysis for failures and regressions. We introduce Anubis, a proactive validation system for AI infrastructure that mitigates hidden degradation caused by hardware redundancies and enhances overall reliability. Anubis features a comprehensive <b>benchmark</b> suite, capable of evaluating individual hardware components and representing most real AI workloads. It comprises a Validator which learns <b>benchmark</b> criteria to clearly pinpoint defective components. Additionally, Anubis incorporates a Selector to balance validation time and issue-related penalties, enabling optimal timing for validation execution with a tailored subset of <b>benchmarks.</b> Through testbed evaluation and <b>simulation,</b> we demonstrate that Anubis can increase the mean time between incidents by up to 22.61x. Anubis has been successfully deployed in Azure production, validating hundreds of thousands of GPUs over the last two years.

{{</citation>}}


### (1/3 | 161/197) Population Protocols for Exact Plurality Consensus -- How a small chance of failure helps to eliminate insignificant opinions (Gregor Bankhamer et al., 2024)

{{<citation>}}

Gregor Bankhamer, Petra Berenbrink, Felix Biermeier, Robert Elsässer, Hamed Hosseinpour, Dominik Kaaser, Peter Kling. (2024)  
**Population Protocols for Exact Plurality Consensus -- How a small chance of failure helps to eliminate insignificant opinions**
<br/>
<button class="copy-to-clipboard" title="Population Protocols for Exact Plurality Consensus -- How a small chance of failure helps to eliminate insignificant opinions" index=161>
  <span class="copy-to-clipboard-item">Copy Title<span>
</button>
<div class="toast toast-copied toast-index-161 align-items-center text-bg-secondary border-0 position-absolute top-0 end-0" role="alert" aria-live="assertive" aria-atomic="true">
  <div class="d-flex">
    <div class="toast-body">
      Copied!
    </div>
  </div>
</div>

---
Primary Category: cs.DC  
Categories: cs-DC, cs.DC  
Keyword Score: 10  
Keywords: Pruning  
<a type="button" class="btn btn-outline-primary" href="http://arxiv.org/abs/2402.06471v1" target="_blank" >Paper Link</a>
<button type="button" class="btn btn-outline-primary download-pdf" url="https://arxiv.org/pdf/2402.06471v1.pdf" filename="2402.06471v1.pdf">Download PDF</button>

---


**ABSTRACT**  
We consider the \emph{exact plurality consensus} problem for \emph{population protocols}. Here, $n$ anonymous agents start each with one of $k$ opinions. Their goal is to agree on the initially most frequent opinion (the \emph{plurality opinion}) via random, pairwise interactions. The case of $k = 2$ opinions is known as the \emph{majority problem}. Recent breakthroughs led to an always correct, exact majority population protocol that is both time- and space-optimal, needing $O(\log n)$ states per agent and, with high probability, $O(\log n)$ time~[Doty, Eftekhari, Gasieniec, Severson, Stachowiak, and Uznanski; 2021]. We know that any always correct protocol requires $\Omega(k^2)$ states, while the currently best protocol needs $O(k^{11})$ states~[Natale and Ramezani; 2019]. For ordered opinions, this can be improved to $O(k^6)$~[Gasieniec, Hamilton, Martin, Spirakis, and Stachowiak; 2016]. We design protocols for plurality consensus that beat the quadratic lower bound by allowing a negligible failure probability. While our protocols might fail, they identify the plurality opinion with high probability even if the bias is $1$. Our first protocol achieves this via $k-1$ tournaments in time $O(k \cdot \log n)$ using $O(k + \log n)$ states. While it assumes an ordering on the opinions, we remove this restriction in our second protocol, at the cost of a slightly increased time $O(k \cdot \log n + \log^2 n)$. By efficiently <b>pruning</b> insignificant opinions, our final protocol reduces the number of tournaments at the cost of a slightly increased state complexity $O(k \cdot \log\log n + \log n)$. This improves the time to $O(n / x_{\max} \cdot \log n + \log^2 n)$, where $x_{\max}$ is the initial size of the plurality. Note that $n/x_{\max}$ is at most $k$ and can be much smaller (e.g., in case of a large bias or if there are many small opinions).

{{</citation>}}


### (2/3 | 162/197) Decentralized Proactive Model Offloading and Resource Allocation for Split and Federated Learning (Binbin Huang et al., 2024)

{{<citation>}}

Binbin Huang, Hailiang Zhao, Lingbin Wang, Wenzhuo Qian, Yuyu Yin, Shuiguang Deng. (2024)  
**Decentralized Proactive Model Offloading and Resource Allocation for Split and Federated Learning**
<br/>
<button class="copy-to-clipboard" title="Decentralized Proactive Model Offloading and Resource Allocation for Split and Federated Learning" index=162>
  <span class="copy-to-clipboard-item">Copy Title<span>
</button>
<div class="toast toast-copied toast-index-162 align-items-center text-bg-secondary border-0 position-absolute top-0 end-0" role="alert" aria-live="assertive" aria-atomic="true">
  <div class="d-flex">
    <div class="toast-body">
      Copied!
    </div>
  </div>
</div>

---
Primary Category: cs.DC  
Categories: cs-DC, cs.DC  
Keyword Score: 10  
Keywords: Federated Learning  
<a type="button" class="btn btn-outline-primary" href="http://arxiv.org/abs/2402.06123v1" target="_blank" >Paper Link</a>
<button type="button" class="btn btn-outline-primary download-pdf" url="https://arxiv.org/pdf/2402.06123v1.pdf" filename="2402.06123v1.pdf">Download PDF</button>

---


**ABSTRACT**  
In the resource-constrained IoT-edge environment, Split <b>Federated</b> <b>(SplitFed)</b> learning is implemented to enhance training efficiency. This method involves each IoT device dividing its full DNN model at a designated layer into a device-side model and a server-side model, then offloading the latter to the edge server. However, existing research overlooks four critical issues as follows: (1) the heterogeneity of IoT devices' resource capacities and the sizes of their local data samples impact training efficiency; (2) the influence of the edge server's computation and network resource allocation on training efficiency; (3) the data leakage risk associated with the offloaded server-side sub-model; (4) the privacy drawbacks of current centralized algorithms. Consequently, proactively identifying the optimal cut layer and server resource requirements for each IoT device to minimize training latency while adhering to data leakage risk rate constraint remains a challenging issue. To address these problems, this paper first formulates the latency and data leakage risk of training DNN models using Split <b>Federated</b> <b>learning.</b> Next, we frame the Split <b>Federated</b> <b>learning</b> problem as a mixed-integer nonlinear programming challenge. To tackle this, we propose a decentralized Proactive Model Offloading and Resource Allocation (DP-MORA) scheme, empowering each IoT device to determine its cut layer and resource requirements based on its local multidimensional training configuration, without knowledge of other devices' configurations. Extensive experiments on two real-world datasets demonstrate that the DP-MORA scheme effectively reduces DNN model training latency, enhances training efficiency, and complies with data leakage risk constraints compared to several baseline algorithms across various experimental settings.

{{</citation>}}


## cs.SI (3)



### (0/3 | 163/197) If Turing played piano with an artificial partner (Dobromir Dotov et al., 2024)

{{<citation>}}

Dobromir Dotov, Dante Camarena, Zack Harris, Joanna Spyra, Pietro Gagliano, Laurel Trainor. (2024)  
**If Turing played piano with an artificial partner**
<br/>
<button class="copy-to-clipboard" title="If Turing played piano with an artificial partner" index=163>
  <span class="copy-to-clipboard-item">Copy Title<span>
</button>
<div class="toast toast-copied toast-index-163 align-items-center text-bg-secondary border-0 position-absolute top-0 end-0" role="alert" aria-live="assertive" aria-atomic="true">
  <div class="d-flex">
    <div class="toast-body">
      Copied!
    </div>
  </div>
</div>

---
Primary Category: cs.SI  
Categories: cs-AI, cs-LG, cs-SD, cs-SI, cs.SI  
Keyword Score: 30  
Keywords: Autoencoder, Variational Autoencoder, Large Language Model  
<a type="button" class="btn btn-outline-primary" href="http://arxiv.org/abs/2402.08690v1" target="_blank" >Paper Link</a>
<button type="button" class="btn btn-outline-primary download-pdf" url="https://arxiv.org/pdf/2402.08690v1.pdf" filename="2402.08690v1.pdf">Download PDF</button>

---


**ABSTRACT**  
Music is an inherently social activity that allows people to share experiences and feel connected with one another. There has been little progress in designing artificial partners exhibiting a similar social experience as playing with another person. Neural network architectures that implement generative models, such as <b>large</b> <b>language</b> <b>models,</b> are suited for producing musical scores. Playing music socially, however, involves more than playing a score; it must complement the other musicians' ideas and keep time correctly. We addressed the question of whether a convincing social experience is made possible by a generative model trained to produce musical scores, not necessarily optimized for synchronization and continuation. The network, a <b>variational</b> <b>autoencoder</b> trained on a <b>large</b> <b>corpus</b> <b>of</b> digital scores, was adapted for a timed call-and-response task with a human partner. Participants played piano with a human or artificial partner-in various configurations-and rated the performance quality and first-person experience of self-other integration. Overall, the artificial partners held promise but were rated lower than human partners. The artificial partner with simplest design and highest similarity parameter was not rated differently from the human partners on some measures, suggesting that interactive rather than generative sophistication is important in enabling social AI.

{{</citation>}}


### (1/3 | 164/197) What We Know About Using Non-Engagement Signals in Content Ranking (Tom Cunningham et al., 2024)

{{<citation>}}

Tom Cunningham, Sana Pandey, Leif Sigerson, Jonathan Stray, Jeff Allen, Bonnie Barrilleaux, Ravi Iyer, Smitha Milli, Mohit Kothari, Behnam Rezaei. (2024)  
**What We Know About Using Non-Engagement Signals in Content Ranking**
<br/>
<button class="copy-to-clipboard" title="What We Know About Using Non-Engagement Signals in Content Ranking" index=164>
  <span class="copy-to-clipboard-item">Copy Title<span>
</button>
<div class="toast toast-copied toast-index-164 align-items-center text-bg-secondary border-0 position-absolute top-0 end-0" role="alert" aria-live="assertive" aria-atomic="true">
  <div class="d-flex">
    <div class="toast-body">
      Copied!
    </div>
  </div>
</div>

---
Primary Category: cs.SI  
Categories: H-3-3; H-4-3, cs-SI, cs.SI  
Keyword Score: 10  
Keywords: Generative AI  
<a type="button" class="btn btn-outline-primary" href="http://arxiv.org/abs/2402.06831v1" target="_blank" >Paper Link</a>
<button type="button" class="btn btn-outline-primary download-pdf" url="https://arxiv.org/pdf/2402.06831v1.pdf" filename="2402.06831v1.pdf">Download PDF</button>

---


**ABSTRACT**  
Many online platforms predominantly rank items by predicted user engagement. We believe that there is much unrealized potential in including non-engagement signals, which can improve outcomes both for platforms and for society as a whole. Based on a daylong workshop with experts from industry and academia, we formulate a series of propositions and document each as best we can from public evidence, including quantitative results where possible. There is strong evidence that ranking by predicted engagement is effective in increasing user retention. However retention can be further increased by incorporating other signals, including item "quality" proxies and asking users what they want to see with "item-level" surveys. There is also evidence that "diverse engagement" is an effective quality signal. Ranking changes can alter the prevalence of self-reported experiences of various kinds (e.g. harassment) but seldom have large enough effects on attitude measures like user satisfaction, well-being, polarization etc. to be measured in typical experiments. User controls over ranking often have low usage rates, but when used they do correlate well with quality and item-level surveys. There was no strong evidence on the impact of transparency/explainability on retention. There is reason to believe that <b>generative</b> <b>AI</b> could be used to create better quality signals and enable new kinds of user controls.

{{</citation>}}


### (2/3 | 165/197) A new edge betweenness measure using a game theoretical approach: an application to hierarchical community detection (Daniel Gómez et al., 2024)

{{<citation>}}

Daniel Gómez, Javier Castro, Inmaculada Gutiérrez, Rosa Espínola. (2024)  
**A new edge betweenness measure using a game theoretical approach: an application to hierarchical community detection**
<br/>
<button class="copy-to-clipboard" title="A new edge betweenness measure using a game theoretical approach: an application to hierarchical community detection" index=165>
  <span class="copy-to-clipboard-item">Copy Title<span>
</button>
<div class="toast toast-copied toast-index-165 align-items-center text-bg-secondary border-0 position-absolute top-0 end-0" role="alert" aria-live="assertive" aria-atomic="true">
  <div class="d-flex">
    <div class="toast-body">
      Copied!
    </div>
  </div>
</div>

---
Primary Category: cs.SI  
Categories: 91A, 91B82, 62, 65K, G-3, cs-SI, cs.SI, math-ST, stat-TH  
Keyword Score: 10  
Keywords: Hierarchical Clustering  
<a type="button" class="btn btn-outline-primary" href="http://arxiv.org/abs/2402.06373v1" target="_blank" >Paper Link</a>
<button type="button" class="btn btn-outline-primary download-pdf" url="https://arxiv.org/pdf/2402.06373v1.pdf" filename="2402.06373v1.pdf">Download PDF</button>

---


**ABSTRACT**  
In this paper we formally define the <b>hierarchical</b> <b>clustering</b> network problem (HCNP) as the problem to find a good <b>hierarchical</b> <b>partition</b> of a network. This new problem focuses on the dynamic process of the clustering rather than on the final picture of the clustering process. To address it, we introduce a new ierarchical clustering algorithm in networks, based on a new shortest path betweenness measure. To calculate it, the communication between each pair of nodes is weighed by he importance of the nodes that establish this communication. The weights or importance associated to each pair of nodes are calculated as the Shapley value of a game, named as the linear modularity game. This new measure, (the node-game shortest path betweenness measure), is used to obtain a <b>hierarchical</b> <b>partition</b> of the network by eliminating the link with the highest value. To evaluate the performance of our algorithm, we introduce several criteria that allow us to compare different dendrograms of a network from two point of view: modularity and homogeneity. Finally, we propose a faster algorithm based on a simplification of the node-game shortest path betweenness measure, whose order is quadratic on sparse networks. This fast version is competitive from a computational point of view with other <b>hierarchical</b> <b>fast</b> algorithms, and, in general, it provides better results.

{{</citation>}}


## cs.SD (4)



### (0/4 | 166/197) Exploiting spatial diversity for increasing the robustness of sound source localization systems against reverberation (Guillermo Garcia-Barrios et al., 2024)

{{<citation>}}

Guillermo Garcia-Barrios, Eduardo Latorre Iglesias, Juana M. Gutierrez-Arriola, Ruben Fraile, Nicolas Saenz-Lechon, Victor Jose Osma-Ruiz. (2024)  
**Exploiting spatial diversity for increasing the robustness of sound source localization systems against reverberation**
<br/>
<button class="copy-to-clipboard" title="Exploiting spatial diversity for increasing the robustness of sound source localization systems against reverberation" index=166>
  <span class="copy-to-clipboard-item">Copy Title<span>
</button>
<div class="toast toast-copied toast-index-166 align-items-center text-bg-secondary border-0 position-absolute top-0 end-0" role="alert" aria-live="assertive" aria-atomic="true">
  <div class="d-flex">
    <div class="toast-body">
      Copied!
    </div>
  </div>
</div>

---
Primary Category: cs.SD  
Categories: cs-SD, cs.SD, eess-AS, eess-SP  
Keyword Score: 30  
Keywords: Recommendation, Simulation, Simulator  
<a type="button" class="btn btn-outline-primary" href="http://arxiv.org/abs/2402.06411v1" target="_blank" >Paper Link</a>
<button type="button" class="btn btn-outline-primary download-pdf" url="https://arxiv.org/pdf/2402.06411v1.pdf" filename="2402.06411v1.pdf">Download PDF</button>

---


**ABSTRACT**  
Acoustic reverberation is one of the most relevant factors that hampers the localization of a sound source inside a room. To date, several approaches have been proposed to deal with it, but have not always been evaluated under realistic conditions. This paper proposes exploiting spatial diversity as an alternative approach to achieve robustness against reverberation. The theoretical arguments supporting this approach are first presented and later confirmed by means of <b>simulation</b> results and real measurements. <b>Simulations</b> are run for reverberation times up to 2 s, thus providing results with a wider range of validity than in other previous research works. It is concluded that the use of systems consisting of several, sufficiently separated, small arrays leads to the best results in reverberant environments. Some <b>recommendations</b> are given regarding the choice of the array sizes, the separation among them, and the way to combine SRP-PHAT maps obtained from diverse arrays.

{{</citation>}}


### (1/4 | 167/197) A New Approach to Voice Authenticity (Nicolas M. Müller et al., 2024)

{{<citation>}}

Nicolas M. Müller, Piotr Kawa, Shen Hu, Matthias Neu, Jennifer Williams, Philip Sperl, Konstantin Böttinger. (2024)  
**A New Approach to Voice Authenticity**
<br/>
<button class="copy-to-clipboard" title="A New Approach to Voice Authenticity" index=167>
  <span class="copy-to-clipboard-item">Copy Title<span>
</button>
<div class="toast toast-copied toast-index-167 align-items-center text-bg-secondary border-0 position-absolute top-0 end-0" role="alert" aria-live="assertive" aria-atomic="true">
  <div class="d-flex">
    <div class="toast-body">
      Copied!
    </div>
  </div>
</div>

---
Primary Category: cs.SD  
Categories: cs-AI, cs-SD, cs.SD, eess-AS  
Keyword Score: 30  
Keywords: Text-to-speech, Text-to-speech, Summarization  
<a type="button" class="btn btn-outline-primary" href="http://arxiv.org/abs/2402.06304v1" target="_blank" >Paper Link</a>
<button type="button" class="btn btn-outline-primary download-pdf" url="https://arxiv.org/pdf/2402.06304v1.pdf" filename="2402.06304v1.pdf">Download PDF</button>

---


**ABSTRACT**  
Voice faking, driven primarily by recent advances in <b>text-to-speech</b> <b>(TTS)</b> synthesis technology, poses significant societal challenges. Currently, the prevailing assumption is that unaltered human speech can be considered genuine, while fake speech comes from <b>TTS</b> synthesis. We argue that this binary distinction is oversimplified. For instance, altered playback speeds can be used for malicious purposes, like in the 'Drunken Nancy Pelosi' incident. Similarly, editing of audio clips can be done ethically, e.g., for brevity or <b>summarization</b> in news reporting or podcasts, but editing can also create misleading narratives. In this paper, we propose a conceptual shift away from the binary paradigm of audio being either 'fake' or 'real'. Instead, our focus is on pinpointing 'voice edits', which encompass traditional modifications like filters and cuts, as well as <b>TTS</b> synthesis and VC systems. We delineate 6 categories and curate a new challenge dataset rooted in the M-AILABS corpus, for which we present baseline detection systems. And most importantly, we argue that merely categorizing audio as fake or real is a dangerous over-simplification that will fail to move the field of speech technology forward.

{{</citation>}}


### (2/4 | 168/197) Analytical model for the relation between signal bandwidth and spatial resolution in Steered-Response Power Phase Transform (SRP-PHAT) maps (Guillermo Garcia-Barrios et al., 2024)

{{<citation>}}

Guillermo Garcia-Barrios, Juana M. Gutierrez-Arriola, Nicolas Saenz-Lechon, Victor Jose Osma-Ruiz, Ruben Fraile. (2024)  
**Analytical model for the relation between signal bandwidth and spatial resolution in Steered-Response Power Phase Transform (SRP-PHAT) maps**
<br/>
<button class="copy-to-clipboard" title="Analytical model for the relation between signal bandwidth and spatial resolution in Steered-Response Power Phase Transform (SRP-PHAT) maps" index=168>
  <span class="copy-to-clipboard-item">Copy Title<span>
</button>
<div class="toast toast-copied toast-index-168 align-items-center text-bg-secondary border-0 position-absolute top-0 end-0" role="alert" aria-live="assertive" aria-atomic="true">
  <div class="d-flex">
    <div class="toast-body">
      Copied!
    </div>
  </div>
</div>

---
Primary Category: cs.SD  
Categories: cs-SD, cs.SD, eess-AS, eess-SP  
Keyword Score: 20  
Keywords: Simulation, Simulator  
<a type="button" class="btn btn-outline-primary" href="http://arxiv.org/abs/2402.06586v1" target="_blank" >Paper Link</a>
<button type="button" class="btn btn-outline-primary download-pdf" url="https://arxiv.org/pdf/2402.06586v1.pdf" filename="2402.06586v1.pdf">Download PDF</button>

---


**ABSTRACT**  
An analysis of the relationship between the bandwidth of acoustic signals and the required resolution of steered-response power phase transform (SRP-PHAT) maps used for sound source localization is presented. This relationship does not rely on the far-field assumption, nor does it depend on any specific array topology. The proposed analysis considers the computation of a SRP map as a process of sampling a set of generalized cross-correlation (GCC) functions, each one corresponding to a different microphone pair. From this approach, we derive a rule that relates GCC bandwidth with inter-microphone distance, resolution of the SRP map, and the potential position of the sound source relative to the array position. This rule is a sufficient condition for an aliasing-free calculation of the specified SRP-PHAT map. <b>Simulation</b> results show that limiting the bandwidth of the GCC according to such rule leads to significant reductions in sound source localization errors when sources are not in the immediate vicinity of the microphone array. These error reductions are more relevant for coarser resolutions of the SRP map, and they happen in both anechoic and reverberant environments.

{{</citation>}}


### (3/4 | 169/197) MusicMagus: Zero-Shot Text-to-Music Editing via Diffusion Models (Yixiao Zhang et al., 2024)

{{<citation>}}

Yixiao Zhang, Yukara Ikemiya, Gus Xia, Naoki Murata, Marco Martínez, Wei-Hsiang Liao, Yuki Mitsufuji, Simon Dixon. (2024)  
**MusicMagus: Zero-Shot Text-to-Music Editing via Diffusion Models**
<br/>
<button class="copy-to-clipboard" title="MusicMagus: Zero-Shot Text-to-Music Editing via Diffusion Models" index=169>
  <span class="copy-to-clipboard-item">Copy Title<span>
</button>
<div class="toast toast-copied toast-index-169 align-items-center text-bg-secondary border-0 position-absolute top-0 end-0" role="alert" aria-live="assertive" aria-atomic="true">
  <div class="d-flex">
    <div class="toast-body">
      Copied!
    </div>
  </div>
</div>

---
Primary Category: cs.SD  
Categories: cs-AI, cs-MM, cs-SD, cs.SD, eess-AS  
Keyword Score: 20  
Keywords: Supervised Learning, Zero-shot  
<a type="button" class="btn btn-outline-primary" href="http://arxiv.org/abs/2402.06178v1" target="_blank" >Paper Link</a>
<button type="button" class="btn btn-outline-primary download-pdf" url="https://arxiv.org/pdf/2402.06178v1.pdf" filename="2402.06178v1.pdf">Download PDF</button>

---


**ABSTRACT**  
Recent advances in text-to-music generation models have opened new avenues in musical creativity. However, music generation usually involves iterative refinements, and how to edit the generated music remains a significant challenge. This paper introduces a novel approach to the editing of music generated by such models, enabling the modification of specific attributes, such as genre, mood and instrument, while maintaining other aspects unchanged. Our method transforms text editing to \textit{latent space manipulation} while adding an extra constraint to enforce consistency. It seamlessly integrates with existing pretrained text-to-music diffusion models without requiring additional training. Experimental results demonstrate superior performance over both <b>zero-shot</b> and certain <b>supervised</b> baselines in style and timbre transfer evaluations. Additionally, we showcase the practical applicability of our approach in real-world music editing scenarios.

{{</citation>}}


## stat.CO (1)



### (0/1 | 170/197) Relative frequencies of constrained events in stochastic processes: An analytical approach (S. Rusconi et al., 2024)

{{<citation>}}

S. Rusconi, E. Akhmatskaya, D. Sokolovski, N. Ballard, J. C. de la Cal. (2024)  
**Relative frequencies of constrained events in stochastic processes: An analytical approach**
<br/>
<button class="copy-to-clipboard" title="Relative frequencies of constrained events in stochastic processes: An analytical approach" index=170>
  <span class="copy-to-clipboard-item">Copy Title<span>
</button>
<div class="toast toast-copied toast-index-170 align-items-center text-bg-secondary border-0 position-absolute top-0 end-0" role="alert" aria-live="assertive" aria-atomic="true">
  <div class="d-flex">
    <div class="toast-body">
      Copied!
    </div>
  </div>
</div>

---
Primary Category: stat.CO  
Categories: cond-mat-mtrl-sci, cond-mat-soft, cs-CE, physics-chem-ph, stat-CO, stat.CO  
Keyword Score: 23  
Keywords: Sample Size, Simulation, Simulator  
<a type="button" class="btn btn-outline-primary" href="http://arxiv.org/abs/2402.06536v1" target="_blank" >Paper Link</a>
<button type="button" class="btn btn-outline-primary download-pdf" url="https://arxiv.org/pdf/2402.06536v1.pdf" filename="2402.06536v1.pdf">Download PDF</button>

---


**ABSTRACT**  
The stochastic <b>simulation</b> algorithm (SSA) and the corresponding Monte Carlo (MC) method are among the most common approaches for studying stochastic processes. They rely on knowledge of interevent probability density functions (PDFs) and on information about dependencies between all possible events. Analytical representations of a PDF are difficult to specify in advance, in many real life applications. Knowing the shapes of PDFs, and using experimental data, different optimization schemes can be applied in order to evaluate probability density functions and, therefore, the properties of the studied system. Such methods, however, are computationally demanding, and often not feasible. We show that, in the case where experimentally accessed properties are directly related to the frequencies of events involved, it may be possible to replace the heavy Monte Carlo core of optimization schemes with an analytical solution. Such a replacement not only provides a more accurate estimation of the properties of the process, but also reduces the <b>simulation</b> time by a factor of order of the <b>sample</b> <b>size</b> (at least $\approx 10^4$). The proposed analytical approach is valid for any choice of PDF. The accuracy, computational efficiency, and advantages of the method over MC procedures are demonstrated in the exactly solvable case and in the evaluation of branching fractions in controlled radical polymerization (CRP) of acrylic monomers. This polymerization can be modeled by a constrained stochastic process. Constrained systems are quite common, and this makes the method useful for various applications.

{{</citation>}}


## eess.SY (5)



### (0/5 | 171/197) N-1 Reduced Optimal Power Flow Using Augmented Hierarchical Graph Neural Network (Thuan Pham et al., 2024)

{{<citation>}}

Thuan Pham, Xingpeng Li. (2024)  
**N-1 Reduced Optimal Power Flow Using Augmented Hierarchical Graph Neural Network**
<br/>
<button class="copy-to-clipboard" title="N-1 Reduced Optimal Power Flow Using Augmented Hierarchical Graph Neural Network" index=171>
  <span class="copy-to-clipboard-item">Copy Title<span>
</button>
<div class="toast toast-copied toast-index-171 align-items-center text-bg-secondary border-0 position-absolute top-0 end-0" role="alert" aria-live="assertive" aria-atomic="true">
  <div class="d-flex">
    <div class="toast-body">
      Copied!
    </div>
  </div>
</div>

---
Primary Category: eess.SY  
Categories: cs-LG, cs-SY, eess-SY, eess.SY  
Keyword Score: 23  
Keywords: Graph Neural Network, Graph Neural Network, Benchmarking  
<a type="button" class="btn btn-outline-primary" href="http://arxiv.org/abs/2402.06226v1" target="_blank" >Paper Link</a>
<button type="button" class="btn btn-outline-primary download-pdf" url="https://arxiv.org/pdf/2402.06226v1.pdf" filename="2402.06226v1.pdf">Download PDF</button>

---


**ABSTRACT**  
Optimal power flow (OPF) is used to perform generation redispatch in power system real-time operations. N-1 OPF can ensure safe grid operations under diverse contingency scenarios. For large and intricate power networks with numerous variables and constraints, achieving an optimal solution for real-time N-1 OPF necessitates substantial computational resources. To mitigate this challenge, machine learning (ML) is introduced as an additional tool for predicting congested or heavily loaded lines dynamically. In this paper, an advanced ML model known as the augmented hierarchical <b>graph</b> <b>neural</b> <b>network</b> (AHGNN) was proposed to predict critical congested lines and create N-1 reduced OPF (N-1 ROPF). The proposed AHGNN-enabled N-1 ROPF can result in a remarkable reduction in computing time while retaining the solution quality. Several variations of <b>GNN-based</b> ML models are also implemented as <b>benchmark</b> to demonstrate effectiveness of the proposed AHGNN approach. Case studies prove the proposed AHGNN and the associated N-1 ROPF are highly effective in reducing computation time while preserving solution quality, highlighting the promising potential of ML, particularly <b>GNN</b> in enhancing power system operations.

{{</citation>}}


### (1/5 | 172/197) EJS, JIL Server, and LabVIEW: An Architecture for Rapid Development of Remote Labs (Jesús Chacón et al., 2024)

{{<citation>}}

Jesús Chacón, Hector Vargas, Gonzalo Farias, Jose Sánchez, Sebastián Dormido. (2024)  
**EJS, JIL Server, and LabVIEW: An Architecture for Rapid Development of Remote Labs**
<br/>
<button class="copy-to-clipboard" title="EJS, JIL Server, and LabVIEW: An Architecture for Rapid Development of Remote Labs" index=172>
  <span class="copy-to-clipboard-item">Copy Title<span>
</button>
<div class="toast toast-copied toast-index-172 align-items-center text-bg-secondary border-0 position-absolute top-0 end-0" role="alert" aria-live="assertive" aria-atomic="true">
  <div class="d-flex">
    <div class="toast-body">
      Copied!
    </div>
  </div>
</div>

---
Primary Category: eess.SY  
Categories: cs-SY, eess-SY, eess.SY  
Keyword Score: 20  
Keywords: Simulation, Simulator  
<a type="button" class="btn btn-outline-primary" href="http://arxiv.org/abs/2402.06206v1" target="_blank" >Paper Link</a>
<button type="button" class="btn btn-outline-primary download-pdf" url="https://arxiv.org/pdf/2402.06206v1.pdf" filename="2402.06206v1.pdf">Download PDF</button>

---


**ABSTRACT**  
Designing and developing web-enabled remote laboratories for pedagogical purposes is not an easy task. Often, developers (generally, educators who know the subjects they teach but lack of the technical and programming skills required to build Internet-based educational applications) end up discarding the idea of exploring these new teaching and learning experiences mainly due to the technical issues that must be mastered. To tackle this problem, authors present a novel technique that allows developers to create remote labs in a quick, didactical, and straightforward way. This framework is based on the use of two well-known software tools in the scope of engineering education, Easy Java <b>Simulations</b> and LabVIEW. The development exploits a new feature of Easy Java <b>Simulations</b> known as EJS-elements that enables Java developers to create and integrate their own authoring libraries (elements) into EJS, thus increasing its application possibilities. Particularly, the EJS element here presented allows to LabVIEW programs be controlled from EJS applications through a communication network. This paper presents the element creation details and how this can be used to create web-enabled experimentation environments for educational purposes. A step by step example of development of a remote lab for automatic control education is described.

{{</citation>}}


### (2/5 | 173/197) Distributed Safe Navigation of Multi-Agent Systems using Control Barrier Function-Based Optimal Controllers (Pol Mestres et al., 2024)

{{<citation>}}

Pol Mestres, Carlos Nieto-Granda, Jorge Cortés. (2024)  
**Distributed Safe Navigation of Multi-Agent Systems using Control Barrier Function-Based Optimal Controllers**
<br/>
<button class="copy-to-clipboard" title="Distributed Safe Navigation of Multi-Agent Systems using Control Barrier Function-Based Optimal Controllers" index=173>
  <span class="copy-to-clipboard-item">Copy Title<span>
</button>
<div class="toast toast-copied toast-index-173 align-items-center text-bg-secondary border-0 position-absolute top-0 end-0" role="alert" aria-live="assertive" aria-atomic="true">
  <div class="d-flex">
    <div class="toast-body">
      Copied!
    </div>
  </div>
</div>

---
Primary Category: eess.SY  
Categories: cs-SY, eess-SY, eess.SY  
Keyword Score: 20  
Keywords: Simulation, Simulator  
<a type="button" class="btn btn-outline-primary" href="http://arxiv.org/abs/2402.06195v1" target="_blank" >Paper Link</a>
<button type="button" class="btn btn-outline-primary download-pdf" url="https://arxiv.org/pdf/2402.06195v1.pdf" filename="2402.06195v1.pdf">Download PDF</button>

---


**ABSTRACT**  
This paper proposes a distributed controller synthesis framework for safe navigation of multi-agent systems. We leverage control barrier functions to formulate collision avoidance with obstacles and teammates as constraints on the control input for a state-dependent network optimization problem that encodes team formation and the navigation task. Our algorithmic solution is valid for general nonlinear control dynamics and optimization problems. The resulting controller is distributed, satisfies the safety constraints at all times, and is asymptotically optimal. We illustrate its performance in a team of differential-drive robots in a variety of complex environments, both in <b>simulation</b> and in hardware.

{{</citation>}}


### (3/5 | 174/197) Cooperative Nonlinear Guidance Strategies for Guaranteed Pursuit-Evasion (Saurabh Kumar et al., 2024)

{{<citation>}}

Saurabh Kumar, Shashi Ranjan Kumar, Abhinav Sinha. (2024)  
**Cooperative Nonlinear Guidance Strategies for Guaranteed Pursuit-Evasion**
<br/>
<button class="copy-to-clipboard" title="Cooperative Nonlinear Guidance Strategies for Guaranteed Pursuit-Evasion" index=174>
  <span class="copy-to-clipboard-item">Copy Title<span>
</button>
<div class="toast toast-copied toast-index-174 align-items-center text-bg-secondary border-0 position-absolute top-0 end-0" role="alert" aria-live="assertive" aria-atomic="true">
  <div class="d-flex">
    <div class="toast-body">
      Copied!
    </div>
  </div>
</div>

---
Primary Category: eess.SY  
Categories: cs-MA, cs-RO, cs-SY, eess-SY, eess.SY, math-DS, math-OC  
Keyword Score: 20  
Keywords: Simulation, Simulator  
<a type="button" class="btn btn-outline-primary" href="http://arxiv.org/abs/2402.06176v1" target="_blank" >Paper Link</a>
<button type="button" class="btn btn-outline-primary download-pdf" url="https://arxiv.org/pdf/2402.06176v1.pdf" filename="2402.06176v1.pdf">Download PDF</button>

---


**ABSTRACT**  
This paper addresses the pursuit-evasion problem involving three agents -- a purser, an evader, and a defender. We develop cooperative guidance laws for the evader-defender team that guarantee that the defender intercepts the pursuer before it reaches the vicinity of the evader. Unlike heuristic methods, optimal control, differential game formulation, and recently proposed time-constrained guidance techniques, we propose a geometric solution to safeguard the evader from the pursuer's incoming threat. The proposed strategy is computationally efficient and expected to be scalable as the number of agents increases. Another alluring feature of the proposed strategy is that the evader-defender team does not require the knowledge of the pursuer's strategy and that the pursuer's interception is guaranteed from arbitrary initial engagement geometries. We further show that the necessary error variables for the evader-defender team vanish within a time that can be exactly prescribed prior to the three-body engagement. Finally, we demonstrate the efficacy of the proposed cooperative defense strategy via <b>simulation</b> in diverse engagement scenarios.

{{</citation>}}


### (4/5 | 175/197) Provably Safe Finite-Time Guidance for Marine Vehicles (Bhawana Singh et al., 2024)

{{<citation>}}

Bhawana Singh, Karim Ahmadi Dastgerdi, Nikolaos Athanasopoulos, Wasif Naeem, Benoit Lecallard. (2024)  
**Provably Safe Finite-Time Guidance for Marine Vehicles**
<br/>
<button class="copy-to-clipboard" title="Provably Safe Finite-Time Guidance for Marine Vehicles" index=175>
  <span class="copy-to-clipboard-item">Copy Title<span>
</button>
<div class="toast toast-copied toast-index-175 align-items-center text-bg-secondary border-0 position-absolute top-0 end-0" role="alert" aria-live="assertive" aria-atomic="true">
  <div class="d-flex">
    <div class="toast-body">
      Copied!
    </div>
  </div>
</div>

---
Primary Category: eess.SY  
Categories: cs-SY, eess-SY, eess.SY  
Keyword Score: 3  
Keywords: Benchmarking  
<a type="button" class="btn btn-outline-primary" href="http://arxiv.org/abs/2402.06291v1" target="_blank" >Paper Link</a>
<button type="button" class="btn btn-outline-primary download-pdf" url="https://arxiv.org/pdf/2402.06291v1.pdf" filename="2402.06291v1.pdf">Download PDF</button>

---


**ABSTRACT**  
We consider a new control strategy for marine navigation, equipped with finite-time convergence characteristics. We provide mathematical guarantees for waypoint reaching and obstacle avoidance for different encounter scenarios, by deriving conditions under which (i) convergence to waypoint and (ii) safe obstacle avoidance is achieved while (iii) satisfying input constraints. We propose a predefined-time heading control to enforce ship heading error convergence and waypoint reaching in finite time. Using this as a building block, we develop a provably safe algorithm for safe waypoint navigation by strategically and automatically introducing intermediate virtual waypoints. Using Imazu problems as <b>benchmarks,</b> we show that the proposed method is better than other existing strategies such as Velocity Obstacle Avoidance and biased Line-of-Sight methods, in terms of the safe distance between the ship and the obstacles, cross track error, control effort, waypoint reaching time and ship path length.

{{</citation>}}


## cs.CY (1)



### (0/1 | 176/197) You Still See Me: How Data Protection Supports the Architecture of ML Surveillance (Rui-Jie Yew et al., 2024)

{{<citation>}}

Rui-Jie Yew, Lucy Qin, Suresh Venkatasubramanian. (2024)  
**You Still See Me: How Data Protection Supports the Architecture of ML Surveillance**
<br/>
<button class="copy-to-clipboard" title="You Still See Me: How Data Protection Supports the Architecture of ML Surveillance" index=176>
  <span class="copy-to-clipboard-item">Copy Title<span>
</button>
<div class="toast toast-copied toast-index-176 align-items-center text-bg-secondary border-0 position-absolute top-0 end-0" role="alert" aria-live="assertive" aria-atomic="true">
  <div class="d-flex">
    <div class="toast-body">
      Copied!
    </div>
  </div>
</div>

---
Primary Category: cs.CY  
Categories: cs-CR, cs-CY, cs.CY  
Keyword Score: 20  
Keywords: Federated Learning, Knowledge Distillation  
<a type="button" class="btn btn-outline-primary" href="http://arxiv.org/abs/2402.06609v1" target="_blank" >Paper Link</a>
<button type="button" class="btn btn-outline-primary download-pdf" url="https://arxiv.org/pdf/2402.06609v1.pdf" filename="2402.06609v1.pdf">Download PDF</button>

---


**ABSTRACT**  
Data forms the backbone of machine learning. Thus, data protection law has strong bearing on how ML systems are governed. Given that most requirements accompany the processing of personal data, organizations have an incentive to keep their data out of legal scope. Privacy-preserving techniques incentivized by data protection law -- data protection techniques -- constitute an important strategy for ML development because they are used to <b>distill</b> data until it potentially falls outside the scope of data protection laws. In this paper, we examine the impact of a rhetoric that deems data wrapped in privacy-preserving techniques as data that is "good-to-go". We show how the application of data protection techniques in the development of ML systems -- from private set intersection as part of dataset curation to homomorphic encryption and <b>federated</b> <b>learning</b> as part of model computation to the framing of the privacy-utility trade-off as part of model updating -- can further support individual monitoring and data consolidation. With data accumulation at the core of how the ML pipeline is configured, we argue that data protection techniques are often instrumentalized in ways that support infrastructures of surveillance, rather than to protect individuals associated with data. Finally, we propose technology and policy strategies to evaluate data protection techniques in light of the protections they actually confer. We conclude by highlighting the role that security technologists might play in devising policies that combat surveillance ML technologies -- recommending the adversarial mindset inherent to the profession to more precisely articulate and prevent the use of "privacy-preserving" scaffoldings that support surveillance.

{{</citation>}}


## eess.IV (1)



### (0/1 | 177/197) Cardiac ultrasound simulation for autonomous ultrasound navigation (Abdoul Aziz Amadou et al., 2024)

{{<citation>}}

Abdoul Aziz Amadou, Laura Peralta, Paul Dryburgh, Paul Klein, Kaloian Petkov, Richard James Housden, Vivek Singh, Rui Liao, Young-Ho Kim, Florin Christian Ghesu, Tommaso Mansi, Ronak Rajani, Alistair Young, Kawal Rhode. (2024)  
**Cardiac ultrasound simulation for autonomous ultrasound navigation**
<br/>
<button class="copy-to-clipboard" title="Cardiac ultrasound simulation for autonomous ultrasound navigation" index=177>
  <span class="copy-to-clipboard-item">Copy Title<span>
</button>
<div class="toast toast-copied toast-index-177 align-items-center text-bg-secondary border-0 position-absolute top-0 end-0" role="alert" aria-live="assertive" aria-atomic="true">
  <div class="d-flex">
    <div class="toast-body">
      Copied!
    </div>
  </div>
</div>

---
Primary Category: eess.IV  
Categories: I-6-0; I-5-4; J-3, cs-CV, cs-LG, eess-IV, eess.IV  
Keyword Score: 20  
Keywords: Simulation, Simulator  
<a type="button" class="btn btn-outline-primary" href="http://arxiv.org/abs/2402.06463v1" target="_blank" >Paper Link</a>
<button type="button" class="btn btn-outline-primary download-pdf" url="https://arxiv.org/pdf/2402.06463v1.pdf" filename="2402.06463v1.pdf">Download PDF</button>

---


**ABSTRACT**  
Ultrasound is well-established as an imaging modality for diagnostic and interventional purposes. However, the image quality varies with operator skills as acquiring and interpreting ultrasound images requires extensive training due to the imaging artefacts, the range of acquisition parameters and the variability of patient anatomies. Automating the image acquisition task could improve acquisition reproducibility and quality but training such an algorithm requires large amounts of navigation data, not saved in routine examinations. Thus, we propose a method to generate large amounts of ultrasound images from other modalities and from arbitrary positions, such that this pipeline can later be used by learning algorithms for navigation. We present a novel <b>simulation</b> pipeline which uses segmentations from other modalities, an optimized volumetric data representation and GPU-accelerated Monte Carlo path tracing to generate view-dependent and patient-specific ultrasound images. We extensively validate the correctness of our pipeline with a phantom experiment, where structures' sizes, contrast and speckle noise properties are assessed. Furthermore, we demonstrate its usability to train neural networks for navigation in an echocardiography view classification experiment by generating synthetic images from more than 1000 patients. Networks pre-trained with our <b>simulations</b> achieve significantly superior performance in settings where large real datasets are not available, especially for under-represented classes. The proposed approach allows for fast and accurate patient-specific ultrasound image generation, and its usability for training networks for navigation-related tasks is demonstrated.

{{</citation>}}


## eess.SP (1)



### (0/1 | 178/197) Outage performance of the $α$-Beaulieu-Xie Shadowed Fading Channel Model (Aleksey S. Gvozdarev, 2024)

{{<citation>}}

Aleksey S. Gvozdarev. (2024)  
**Outage performance of the $α$-Beaulieu-Xie Shadowed Fading Channel Model**
<br/>
<button class="copy-to-clipboard" title="Outage performance of the $α$-Beaulieu-Xie Shadowed Fading Channel Model" index=178>
  <span class="copy-to-clipboard-item">Copy Title<span>
</button>
<div class="toast toast-copied toast-index-178 align-items-center text-bg-secondary border-0 position-absolute top-0 end-0" role="alert" aria-live="assertive" aria-atomic="true">
  <div class="d-flex">
    <div class="toast-body">
      Copied!
    </div>
  </div>
</div>

---
Primary Category: eess.SP  
Categories: 94A05, 68M18, cs-IT, eess-SP, eess.SP, math-IT  
Keyword Score: 20  
Keywords: Simulation, Simulator  
<a type="button" class="btn btn-outline-primary" href="http://arxiv.org/abs/2402.06337v1" target="_blank" >Paper Link</a>
<button type="button" class="btn btn-outline-primary download-pdf" url="https://arxiv.org/pdf/2402.06337v1.pdf" filename="2402.06337v1.pdf">Download PDF</button>

---


**ABSTRACT**  
The research presents the closed-form outage analysis of the newly presented $\alpha$-modification of the shadowed Beaulieu-Xie fading model for wireless communications. For the considered channel, the closed-form analytical expressions for the outage probability (including its upper and lower bounds), raw moments, amount of fading, and channel quality estimation indicator are derived. The carried out thorough numerical <b>simulation</b> and analysis demonstrates strong agreement with the presented closed-form solutions and illustrates the relationship between the outage probability and channel parameters.

{{</citation>}}


## cs.CG (1)



### (0/1 | 179/197) CoRe-GD: A Hierarchical Framework for Scalable Graph Visualization with GNNs (Florian Grötschla et al., 2024)

{{<citation>}}

Florian Grötschla, Joël Mathys, Robert Veres, Roger Wattenhofer. (2024)  
**CoRe-GD: A Hierarchical Framework for Scalable Graph Visualization with GNNs**
<br/>
<button class="copy-to-clipboard" title="CoRe-GD: A Hierarchical Framework for Scalable Graph Visualization with GNNs" index=179>
  <span class="copy-to-clipboard-item">Copy Title<span>
</button>
<div class="toast toast-copied toast-index-179 align-items-center text-bg-secondary border-0 position-absolute top-0 end-0" role="alert" aria-live="assertive" aria-atomic="true">
  <div class="d-flex">
    <div class="toast-body">
      Copied!
    </div>
  </div>
</div>

---
Primary Category: cs.CG  
Categories: cs-CG, cs-LG, cs.CG  
Keyword Score: 20  
Keywords: Graph Neural Network, Graph Neural Network  
<a type="button" class="btn btn-outline-primary" href="http://arxiv.org/abs/2402.06706v1" target="_blank" >Paper Link</a>
<button type="button" class="btn btn-outline-primary download-pdf" url="https://arxiv.org/pdf/2402.06706v1.pdf" filename="2402.06706v1.pdf">Download PDF</button>

---


**ABSTRACT**  
<b>Graph</b> <b>Visualization,</b> <b>also</b> known as <b>Graph</b> <b>Drawing,</b> <b>aims</b> to find geometric embeddings of <b>graphs</b> <b>that</b> <b>optimize</b> certain criteria. Stress is a widely used metric; stress is minimized when every pair of nodes is positioned at their shortest path distance. However, stress optimization presents computational challenges due to its inherent complexity and is usually solved using heuristics in practice. We introduce a scalable <b>Graph</b> <b>Neural</b> <b>Network</b> <b>(GNN)</b> based <b>Graph</b> <b>Drawing</b> <b>framework</b> with sub-quadratic runtime that can learn to optimize stress. Inspired by classical stress optimization techniques and force-directed layout algorithms, we create a coarsening hierarchy for the input <b>graph.</b> <b>Beginning</b> <b>at</b> the coarsest level, we iteratively refine and un-coarsen the layout, until we generate an embedding for the original <b>graph.</b> <b>To</b> <b>enhance</b> information propagation within the network, we propose a novel positional rewiring technique based on intermediate node positions. Our empirical evaluation demonstrates that the framework achieves state-of-the-art performance while remaining scalable.

{{</citation>}}


## math.NA (2)



### (0/2 | 180/197) An integrated heart-torso electromechanical model for the simulation of electrophysiogical outputs accounting for myocardial deformation (Elena Zappon et al., 2024)

{{<citation>}}

Elena Zappon, Matteo Salvador, Roberto Piersanti, Francesco Regazzoni, Luca Dede', Alfio Quarteroni. (2024)  
**An integrated heart-torso electromechanical model for the simulation of electrophysiogical outputs accounting for myocardial deformation**
<br/>
<button class="copy-to-clipboard" title="An integrated heart-torso electromechanical model for the simulation of electrophysiogical outputs accounting for myocardial deformation" index=180>
  <span class="copy-to-clipboard-item">Copy Title<span>
</button>
<div class="toast toast-copied toast-index-180 align-items-center text-bg-secondary border-0 position-absolute top-0 end-0" role="alert" aria-live="assertive" aria-atomic="true">
  <div class="d-flex">
    <div class="toast-body">
      Copied!
    </div>
  </div>
</div>

---
Primary Category: math.NA  
Categories: 65Z05, 92C10, 92C50, G-1-10; I-6-5; I-6-4; J-3, cs-NA, math-NA, math.NA  
Keyword Score: 20  
Keywords: Simulation, Simulator  
<a type="button" class="btn btn-outline-primary" href="http://arxiv.org/abs/2402.06308v1" target="_blank" >Paper Link</a>
<button type="button" class="btn btn-outline-primary download-pdf" url="https://arxiv.org/pdf/2402.06308v1.pdf" filename="2402.06308v1.pdf">Download PDF</button>

---


**ABSTRACT**  
When generating in-silico clinical electrophysiological outputs, such as electrocardiograms (ECGs) and body surface potential maps (BSPMs), mathematical models have relied on single physics, i.e. of the cardiac electrophysiology (EP), neglecting the role of the heart motion. Since the heart is the most powerful source of electrical activity in the human body, its motion dynamically shifts the position of the principal electrical sources in the torso, influencing electrical potential distribution and potentially altering the EP outputs. In this work, we propose a computational model for the <b>simulation</b> of ECGs and BSPMs by coupling a cardiac electromechanical model with a model that simulates the propagation of the EP signal in the torso, thanks to a flexible numerical approach, that simulates the torso domain deformation induced by the myocardial displacement. Our model accounts for the major mechano-electrical feedbacks, along with unidirectional displacement and potential couplings from the heart to the surrounding body. For the numerical discretization, we employ a versatile intergrid transfer operator that allows for the use of different Finite Element spaces to be used in the cardiac and torso domains. Our numerical results are obtained on a realistic 3D biventricular-torso geometry, and cover both cases of sinus rhythm and ventricular tachycardia (VT), solving both the electromechanical-torso model in dynamical domains, and the classical electrophysiology-torso model in static domains. By comparing standard 12-lead ECG and BSPMs, we highlight the non-negligible effects of the myocardial contraction on the EP-outputs, especially in pathological conditions, such as the VT.

{{</citation>}}


### (1/2 | 181/197) Mesh-robust stability and convergence of variable-step deferred correction methods based on the BDF2 formula (Jiahe Yue et al., 2024)

{{<citation>}}

Jiahe Yue, Hong-lin Liao, Nan Liu. (2024)  
**Mesh-robust stability and convergence of variable-step deferred correction methods based on the BDF2 formula**
<br/>
<button class="copy-to-clipboard" title="Mesh-robust stability and convergence of variable-step deferred correction methods based on the BDF2 formula" index=181>
  <span class="copy-to-clipboard-item">Copy Title<span>
</button>
<div class="toast toast-copied toast-index-181 align-items-center text-bg-secondary border-0 position-absolute top-0 end-0" role="alert" aria-live="assertive" aria-atomic="true">
  <div class="d-flex">
    <div class="toast-body">
      Copied!
    </div>
  </div>
</div>

---
Primary Category: math.NA  
Categories: 65M06, 65M12, cs-NA, math-NA, math.NA  
Keyword Score: 10  
Keywords: Convolution  
<a type="button" class="btn btn-outline-primary" href="http://arxiv.org/abs/2402.06129v1" target="_blank" >Paper Link</a>
<button type="button" class="btn btn-outline-primary download-pdf" url="https://arxiv.org/pdf/2402.06129v1.pdf" filename="2402.06129v1.pdf">Download PDF</button>

---


**ABSTRACT**  
We provide a new theoretical framework for the variable-step deferred correction (DC) methods based on the well-known BDF2 formula. By using the discrete orthogonal <b>convolution</b> kernels, some high-order BDF2-DC methods are proven to be stable on arbitrary time grids according to the recent definition of stability (SINUM, 60: 2253-2272). It significantly relaxes the existing step-ratio restrictions for the BDF2-DC methods (BIT, 62: 1789-1822). The associated sharp error estimates are established by taking the numerical effects of the starting approximations into account, and they suggest that the BDF2-DC methods have no aftereffect, that is, the lower-order starting scheme for the BDF2 scheme will not cause a loss in the accuracy of the high-order BDF2-DC methods. Extensive tests on the graded and random time meshes are presented to support the new theory.

{{</citation>}}


## cs.NE (3)



### (0/3 | 182/197) Towards Chip-in-the-loop Spiking Neural Network Training via Metropolis-Hastings Sampling (Ali Safa et al., 2024)

{{<citation>}}

Ali Safa, Vikrant Jaltare, Samira Sebt, Kameron Gano, Johannes Leugering, Georges Gielen, Gert Cauwenberghs. (2024)  
**Towards Chip-in-the-loop Spiking Neural Network Training via Metropolis-Hastings Sampling**
<br/>
<button class="copy-to-clipboard" title="Towards Chip-in-the-loop Spiking Neural Network Training via Metropolis-Hastings Sampling" index=182>
  <span class="copy-to-clipboard-item">Copy Title<span>
</button>
<div class="toast toast-copied toast-index-182 align-items-center text-bg-secondary border-0 position-absolute top-0 end-0" role="alert" aria-live="assertive" aria-atomic="true">
  <div class="d-flex">
    <div class="toast-body">
      Copied!
    </div>
  </div>
</div>

---
Primary Category: cs.NE  
Categories: cs-CV, cs-NE, cs.NE  
Keyword Score: 20  
Keywords: Simulation, Simulator  
<a type="button" class="btn btn-outline-primary" href="http://arxiv.org/abs/2402.06284v1" target="_blank" >Paper Link</a>
<button type="button" class="btn btn-outline-primary download-pdf" url="https://arxiv.org/pdf/2402.06284v1.pdf" filename="2402.06284v1.pdf">Download PDF</button>

---


**ABSTRACT**  
This paper studies the use of Metropolis-Hastings sampling for training Spiking Neural Network (SNN) hardware subject to strong unknown non-idealities, and compares the proposed approach to the common use of the backpropagation of error (backprop) algorithm and surrogate gradients, widely used to train SNNs in literature. <b>Simulations</b> are conducted within a chip-in-the-loop training context, where an SNN subject to unknown distortion must be trained to detect cancer from measurements, within a biomedical application context. Our results show that the proposed approach strongly outperforms the use of backprop by up to $27\%$ higher accuracy when subject to strong hardware non-idealities. Furthermore, our results also show that the proposed approach outperforms backprop in terms of SNN generalization, needing $>10 \times$ less training data for achieving effective accuracy. These findings make the proposed training approach well-suited for SNN implementations in analog subthreshold circuits and other emerging technologies where unknown hardware non-idealities can jeopardize backprop.

{{</citation>}}


### (1/3 | 183/197) Fine-Tuning Surrogate Gradient Learning for Optimal Hardware Performance in Spiking Neural Networks (Ilkin Aliyev et al., 2024)

{{<citation>}}

Ilkin Aliyev, Tosiron Adegbija. (2024)  
**Fine-Tuning Surrogate Gradient Learning for Optimal Hardware Performance in Spiking Neural Networks**
<br/>
<button class="copy-to-clipboard" title="Fine-Tuning Surrogate Gradient Learning for Optimal Hardware Performance in Spiking Neural Networks" index=183>
  <span class="copy-to-clipboard-item">Copy Title<span>
</button>
<div class="toast toast-copied toast-index-183 align-items-center text-bg-secondary border-0 position-absolute top-0 end-0" role="alert" aria-live="assertive" aria-atomic="true">
  <div class="d-flex">
    <div class="toast-body">
      Copied!
    </div>
  </div>
</div>

---
Primary Category: cs.NE  
Categories: cs-NE, cs.NE  
Keyword Score: 20  
Keywords: Fine-tuning, Fine-tuning  
<a type="button" class="btn btn-outline-primary" href="http://arxiv.org/abs/2402.06211v1" target="_blank" >Paper Link</a>
<button type="button" class="btn btn-outline-primary download-pdf" url="https://arxiv.org/pdf/2402.06211v1.pdf" filename="2402.06211v1.pdf">Download PDF</button>

---


**ABSTRACT**  
The highly sparse activations in Spiking Neural Networks (SNNs) can provide tremendous energy efficiency benefits when carefully exploited in hardware. The behavior of sparsity in SNNs is uniquely shaped by the dataset and training hyperparameters. This work reveals novel insights into the impacts of training on hardware performance. Specifically, we explore the trade-offs between model accuracy and hardware efficiency. We focus on three key hyperparameters: surrogate gradient functions, beta, and membrane threshold. Results on an FPGA-based hardware platform show that the fast sigmoid surrogate function yields a lower firing rate with similar accuracy compared to the arctangent surrogate on the SVHN dataset. Furthermore, by cross-sweeping the beta and membrane threshold hyperparameters, we can achieve a 48% reduction in hardware-based inference latency with only 2.88% trade-off in inference accuracy compared to the default setting. Overall, this study highlights the importance of <b>fine-tuning</b> model hyperparameters as crucial for designing efficient SNN hardware accelerators, evidenced by the <b>fine-tuned</b> model achieving a 1.72x improvement in accelerator efficiency (FPS/W) compared to the most recent work.

{{</citation>}}


### (2/3 | 184/197) A Functional Analysis Approach to Symbolic Regression (Kirill Antonov et al., 2024)

{{<citation>}}

Kirill Antonov, Roman Kalkreuth, Kaifeng Yang, Thomas Bäck, Niki van Stein, Anna V Kononova. (2024)  
**A Functional Analysis Approach to Symbolic Regression**
<br/>
<button class="copy-to-clipboard" title="A Functional Analysis Approach to Symbolic Regression" index=184>
  <span class="copy-to-clipboard-item">Copy Title<span>
</button>
<div class="toast toast-copied toast-index-184 align-items-center text-bg-secondary border-0 position-absolute top-0 end-0" role="alert" aria-live="assertive" aria-atomic="true">
  <div class="d-flex">
    <div class="toast-body">
      Copied!
    </div>
  </div>
</div>

---
Primary Category: cs.NE  
Categories: cs-AI, cs-NE, cs.NE  
Keyword Score: 6  
Keywords: Benchmarking, Benchmarking  
<a type="button" class="btn btn-outline-primary" href="http://arxiv.org/abs/2402.06299v1" target="_blank" >Paper Link</a>
<button type="button" class="btn btn-outline-primary download-pdf" url="https://arxiv.org/pdf/2402.06299v1.pdf" filename="2402.06299v1.pdf">Download PDF</button>

---


**ABSTRACT**  
Symbolic regression (SR) poses a significant challenge for randomized search heuristics due to its reliance on the synthesis of expressions for input-output mappings. Although traditional genetic programming (GP) algorithms have achieved success in various domains, they exhibit limited performance when tree-based representations are used for SR. To address these limitations, we introduce a novel SR approach called Fourier Tree Growing (FTG) that draws insights from functional analysis. This new perspective enables us to perform optimization directly in a different space, thus avoiding intricate symbolic expressions. Our proposed algorithm exhibits significant performance improvements over traditional GP methods on a range of classical one-dimensional <b>benchmarking</b> problems. To identify and explain limiting factors of GP and FTG, we perform experiments on a large-scale polynomials <b>benchmark</b> with high-order polynomials up to degree 100. To the best of the authors' knowledge, this work represents the pioneering application of functional analysis in addressing SR problems. The superior performance of the proposed algorithm and insights into the limitations of GP open the way for further advancing GP for SR and related areas of explainable machine learning.

{{</citation>}}


## cs.IT (3)



### (0/3 | 185/197) Coverage and Rate Analysis for Distributed RISs-Assisted mmWave Communications (Yuan Xu et al., 2024)

{{<citation>}}

Yuan Xu, Chongwen Huang, Wei Li, Yongxu Zhu, Zhaohui Yang, Jiguang He, Jun Yang, Zhaoyang Zhang, Chau Yuen, Merouane Debbah. (2024)  
**Coverage and Rate Analysis for Distributed RISs-Assisted mmWave Communications**
<br/>
<button class="copy-to-clipboard" title="Coverage and Rate Analysis for Distributed RISs-Assisted mmWave Communications" index=185>
  <span class="copy-to-clipboard-item">Copy Title<span>
</button>
<div class="toast toast-copied toast-index-185 align-items-center text-bg-secondary border-0 position-absolute top-0 end-0" role="alert" aria-live="assertive" aria-atomic="true">
  <div class="d-flex">
    <div class="toast-body">
      Copied!
    </div>
  </div>
</div>

---
Primary Category: cs.IT  
Categories: cs-IT, cs.IT, eess-SP, math-IT  
Keyword Score: 20  
Keywords: Simulation, Simulator  
<a type="button" class="btn btn-outline-primary" href="http://arxiv.org/abs/2402.06154v1" target="_blank" >Paper Link</a>
<button type="button" class="btn btn-outline-primary download-pdf" url="https://arxiv.org/pdf/2402.06154v1.pdf" filename="2402.06154v1.pdf">Download PDF</button>

---


**ABSTRACT**  
The millimeter wave (mmWave) has received considerable interest due to its expansive bandwidth and high frequency. However, a noteworthy challenge arises from its vulnerability to blockages, leading to reduced coverage and achievable rates. To address these limitations, a potential solution is to deploy distributed reconfigurable intelligent surfaces (RISs), which comprise many low-cost and passively reflected elements, and can facilitate the establishment of extra communication links. In this paper, we leverage stochastic geometry to investigate the ergodic coverage probability and the achievable rate in both distributed RISs-assisted single-cell and multi-cell mmWave wireless communication systems. Specifically, we first establish the system model considering the stochastically distributed blockages, RISs and users by the Poisson point process. Then we give the association criterion and derive the association probabilities, the distance distributions, and the conditional coverage probabilities for two cases of associations between base stations and users without or with RISs. Finally, we use Campbell's theorem and the total probability theorem to obtain the closed-form expressions of the ergodic coverage probability and the achievable rate. <b>Simulation</b> results verify the effectiveness of our analysis method, and demonstrate that by deploying distributed RISs, the ergodic coverage probability is significantly improved by approximately 50%, and the achievable rate is increased by more than 1.5 times.

{{</citation>}}


### (1/3 | 186/197) High-Rate Fair-Density Parity-Check Codes (Hessam Mahdavifar, 2024)

{{<citation>}}

Hessam Mahdavifar. (2024)  
**High-Rate Fair-Density Parity-Check Codes**
<br/>
<button class="copy-to-clipboard" title="High-Rate Fair-Density Parity-Check Codes" index=186>
  <span class="copy-to-clipboard-item">Copy Title<span>
</button>
<div class="toast toast-copied toast-index-186 align-items-center text-bg-secondary border-0 position-absolute top-0 end-0" role="alert" aria-live="assertive" aria-atomic="true">
  <div class="d-flex">
    <div class="toast-body">
      Copied!
    </div>
  </div>
</div>

---
Primary Category: cs.IT  
Categories: cs-IT, cs.IT, math-IT  
Keyword Score: 10  
Keywords: Message-Passing  
<a type="button" class="btn btn-outline-primary" href="http://arxiv.org/abs/2402.06814v1" target="_blank" >Paper Link</a>
<button type="button" class="btn btn-outline-primary download-pdf" url="https://arxiv.org/pdf/2402.06814v1.pdf" filename="2402.06814v1.pdf">Download PDF</button>

---


**ABSTRACT**  
We introduce fair-density parity-check (FDPC) codes targeting high-rate applications. In particular, we start with a base parity-check matrix $H_b$ of dimension $2 \sqrt{n} \times n$, where $n$ is the code block length, and the number of ones in each row and column of $H_b$ is equal to $\sqrt{n}$ and $2$, respectively. We propose a deterministic combinatorial method for picking the base matrix $H_b$, assuming $n=4t^2$ for some integer $t \geq 2$. We then extend this by obtaining permuted versions of $H_b$ (e.g., via random permutations of its columns) and stacking them on top of each other leading to codes of dimension $k \geq n-2s\sqrt{n}+s$, for some $s \geq 2$, referred to as order-$s$ FDPC codes. We propose methods to explicitly characterize and bound the weight distribution of the new codes and utilize them to derive union-type approximate upper bounds on their error probability under Maximum Likelihood (ML) decoding. For the binary erasure channel (BEC), we demonstrate that the approximate ML bound of FDPC codes closely follows the random coding upper bound (RCU) for a wide range of channel parameters. Also, remarkably, FDPC codes, under the low-complexity min-sum decoder, improve upon 5G-LDPC codes for transmission over the binary-input additive white Gaussian noise (B-AWGN) channel by almost 0.5dB (for $n=1024$, and rate $=0.878$). Furthermore, we propose a new decoder as a combination of weighted min-sum <b>message-passing</b> (MP) decoding algorithm together with a new progressive list (PL) decoding component, referred to as the MP-PL decoder, to further boost the performance of FDPC codes. This paper opens new avenues for a fresh investigation of new code constructions and decoding algorithms in high-rate regimes suitable for ultra-high throughput (high-frequency/optical) applications.

{{</citation>}}


### (2/3 | 187/197) Multi-Modal Concurrent Transmission (Majid Nasiri Khormuji et al., 2024)

{{<citation>}}

Majid Nasiri Khormuji, Alberto Giuseppe Perotti, Qin Yi, Branislav Popovic. (2024)  
**Multi-Modal Concurrent Transmission**
<br/>
<button class="copy-to-clipboard" title="Multi-Modal Concurrent Transmission" index=187>
  <span class="copy-to-clipboard-item">Copy Title<span>
</button>
<div class="toast toast-copied toast-index-187 align-items-center text-bg-secondary border-0 position-absolute top-0 end-0" role="alert" aria-live="assertive" aria-atomic="true">
  <div class="d-flex">
    <div class="toast-body">
      Copied!
    </div>
  </div>
</div>

---
Primary Category: cs.IT  
Categories: cs-IT, cs.IT, eess-SP, math-IT  
Keyword Score: 3  
Keywords: Multi-modal  
<a type="button" class="btn btn-outline-primary" href="http://arxiv.org/abs/2402.06306v1" target="_blank" >Paper Link</a>
<button type="button" class="btn btn-outline-primary download-pdf" url="https://arxiv.org/pdf/2402.06306v1.pdf" filename="2402.06306v1.pdf">Download PDF</button>

---


**ABSTRACT**  
This paper introduces a novel physical-layer method labelled as <b>Multi-Modal</b> Concurrent Transmission (MMCT) for efficient transmission of multiple data streams with different reliability-latency performance requirements. The MMCT arranges data from multiple streams within a same physical-layer transport block wherein stream-specific modulation and coding scheme (MCS) selection is combined with joint mapping of modulated codewords to Multiple-Input Multiple-Output spatial layers and frequency resources. Mapping to spatial-frequency resources with higher Signal-to-Noise Ratios (SNRs) provides the required performance boost for the more demanding streams. In tactile internet applications, wherein haptic feedback/actuation and audio-video streams flow in parallel, the method provides significant SNR and spectral efficiency enhancements compared to conventional 3GPP New Radio (NR) transmission methods.

{{</citation>}}


## cs.MA (1)



### (0/1 | 188/197) CityFlowER: An Efficient and Realistic Traffic Simulator with Embedded Machine Learning Models (Longchao Da et al., 2024)

{{<citation>}}

Longchao Da, Chen Chu, Weinan Zhang, Hua Wei. (2024)  
**CityFlowER: An Efficient and Realistic Traffic Simulator with Embedded Machine Learning Models**
<br/>
<button class="copy-to-clipboard" title="CityFlowER: An Efficient and Realistic Traffic Simulator with Embedded Machine Learning Models" index=188>
  <span class="copy-to-clipboard-item">Copy Title<span>
</button>
<div class="toast toast-copied toast-index-188 align-items-center text-bg-secondary border-0 position-absolute top-0 end-0" role="alert" aria-live="assertive" aria-atomic="true">
  <div class="d-flex">
    <div class="toast-body">
      Copied!
    </div>
  </div>
</div>

---
Primary Category: cs.MA  
Categories: G-3, cs-LG, cs-MA, cs.MA  
Keyword Score: 20  
Keywords: Simulation, Simulator  
<a type="button" class="btn btn-outline-primary" href="http://arxiv.org/abs/2402.06127v1" target="_blank" >Paper Link</a>
<button type="button" class="btn btn-outline-primary download-pdf" url="https://arxiv.org/pdf/2402.06127v1.pdf" filename="2402.06127v1.pdf">Download PDF</button>

---


**ABSTRACT**  
Traffic <b>simulation</b> is an essential tool for transportation infrastructure planning, intelligent traffic control policy learning, and traffic flow analysis. Its effectiveness relies heavily on the realism of the simulators used. Traditional traffic simulators, such as SUMO and CityFlow, are often limited by their reliance on rule-based models with hyperparameters that oversimplify driving behaviors, resulting in unrealistic <b>simulations.</b> To enhance realism, some simulators have provided Application Programming Interfaces (APIs) to interact with Machine Learning (ML) models, which learn from observed data and offer more sophisticated driving behavior models. However, this approach faces challenges in scalability and time efficiency as vehicle numbers increase. Addressing these limitations, we introduce CityFlowER, an advancement over the existing CityFlow simulator, designed for efficient and realistic city-wide traffic <b>simulation.</b> CityFlowER innovatively pre-embeds ML models within the simulator, eliminating the need for external API interactions and enabling faster data computation. This approach allows for a blend of rule-based and ML behavior models for individual vehicles, offering unparalleled flexibility and efficiency, particularly in large-scale <b>simulations.</b> We provide detailed comparisons with existing simulators, implementation insights, and comprehensive experiments to demonstrate CityFlowER's superiority in terms of realism, efficiency, and adaptability.

{{</citation>}}


## physics.geo-ph (1)



### (0/1 | 189/197) Controllable seismic velocity synthesis using generative diffusion models (Fu Wang et al., 2024)

{{<citation>}}

Fu Wang, Xinquan Huang, Tariq Alkhalifah. (2024)  
**Controllable seismic velocity synthesis using generative diffusion models**
<br/>
<button class="copy-to-clipboard" title="Controllable seismic velocity synthesis using generative diffusion models" index=189>
  <span class="copy-to-clipboard-item">Copy Title<span>
</button>
<div class="toast toast-copied toast-index-189 align-items-center text-bg-secondary border-0 position-absolute top-0 end-0" role="alert" aria-live="assertive" aria-atomic="true">
  <div class="d-flex">
    <div class="toast-body">
      Copied!
    </div>
  </div>
</div>

---
Primary Category: physics.geo-ph  
Categories: cs-LG, physics-geo-ph, physics.geo-ph  
Keyword Score: 13  
Keywords: Multi-modal, Out-of-distribution  
<a type="button" class="btn btn-outline-primary" href="http://arxiv.org/abs/2402.06277v1" target="_blank" >Paper Link</a>
<button type="button" class="btn btn-outline-primary download-pdf" url="https://arxiv.org/pdf/2402.06277v1.pdf" filename="2402.06277v1.pdf">Download PDF</button>

---


**ABSTRACT**  
Accurate seismic velocity estimations are vital to understanding Earth's subsurface structures, assessing natural resources, and evaluating seismic hazards. Machine learning-based inversion algorithms have shown promising performance in regional (i.e., for exploration) and global velocity estimation, while their effectiveness hinges on access to large and diverse training datasets whose distributions generally cover the target solutions. Additionally, enhancing the precision and reliability of velocity estimation also requires incorporating prior information, e.g., geological classes, well logs, and subsurface structures, but current statistical or neural network-based methods are not flexible enough to handle such <b>multi-modal</b> information. To address both challenges, we propose to use conditional generative diffusion models for seismic velocity synthesis, in which we readily incorporate those priors. This approach enables the generation of seismic velocities that closely match the expected target distribution, offering datasets informed by both expert knowledge and measured data to support training for data-driven geophysical methods. We demonstrate the flexibility and effectiveness of our method through training diffusion models on the OpenFWI dataset under various conditions, including class labels, well logs, reflectivity images, as well as the combination of these priors. The performance of the approach under <b>out-of-distribution</b> conditions further underscores its generalization ability, showcasing its potential to provide tailored priors for velocity inverse problems and create specific training datasets for machine learning-based geophysical applications.

{{</citation>}}


## cs.DS (2)



### (0/2 | 190/197) Value-based Resource Matching with Fairness Criteria: Application to Agricultural Water Trading (Abhijin Adiga et al., 2024)

{{<citation>}}

Abhijin Adiga, Yohai Trabelsi, Tanvir Ferdousi, Madhav Marathe, S. S. Ravi, Samarth Swarup, Anil Kumar Vullikanti, Mandy L. Wilson, Sarit Kraus, Reetwika Basu, Supriya Savalkar, Matthew Yourek, Michael Brady, Kirti Rajagopalan, Jonathan Yoder. (2024)  
**Value-based Resource Matching with Fairness Criteria: Application to Agricultural Water Trading**
<br/>
<button class="copy-to-clipboard" title="Value-based Resource Matching with Fairness Criteria: Application to Agricultural Water Trading" index=190>
  <span class="copy-to-clipboard-item">Copy Title<span>
</button>
<div class="toast toast-copied toast-index-190 align-items-center text-bg-secondary border-0 position-absolute top-0 end-0" role="alert" aria-live="assertive" aria-atomic="true">
  <div class="d-flex">
    <div class="toast-body">
      Copied!
    </div>
  </div>
</div>

---
Primary Category: cs.DS  
Categories: cs-DS, cs-MA, cs.DS  
Keyword Score: 10  
Keywords: Fairness  
<a type="button" class="btn btn-outline-primary" href="http://arxiv.org/abs/2402.06576v2" target="_blank" >Paper Link</a>
<button type="button" class="btn btn-outline-primary download-pdf" url="https://arxiv.org/pdf/2402.06576v2.pdf" filename="2402.06576v2.pdf">Download PDF</button>

---


**ABSTRACT**  
Optimal allocation of agricultural water in the event of droughts is an important global problem. In addressing this problem, many aspects, including the welfare of farmers, the economy, and the environment, must be considered. Under this backdrop, our work focuses on several resource-matching problems accounting for agents with multi-crop portfolios, geographic constraints, and <b>fairness.</b> First, we address a matching problem where the goal is to maximize a welfare function in two-sided markets where buyers' requirements and sellers' supplies are represented by value functions that assign prices (or costs) to specified volumes of water. For the setting where the value functions satisfy certain monotonicity properties, we present an efficient algorithm that maximizes a social welfare function. When there are minimum water requirement constraints, we present a randomized algorithm which ensures that the constraints are satisfied in expectation. For a single seller--multiple buyers setting with <b>fairness</b> constraints, we design an efficient algorithm that maximizes the minimum level of satisfaction of any buyer. We also present computational complexity results that highlight the limits on the generalizability of our results. We evaluate the algorithms developed in our work with experiments on both real-world and synthetic data sets with respect to drought severity, value functions, and seniority of agents.

{{</citation>}}


### (1/2 | 191/197) Assortment Planning with Sponsored Products (Shaojie Tang et al., 2024)

{{<citation>}}

Shaojie Tang, Shuzhang Cai, Jing Yuan, Kai Han. (2024)  
**Assortment Planning with Sponsored Products**
<br/>
<button class="copy-to-clipboard" title="Assortment Planning with Sponsored Products" index=191>
  <span class="copy-to-clipboard-item">Copy Title<span>
</button>
<div class="toast toast-copied toast-index-191 align-items-center text-bg-secondary border-0 position-absolute top-0 end-0" role="alert" aria-live="assertive" aria-atomic="true">
  <div class="d-flex">
    <div class="toast-body">
      Copied!
    </div>
  </div>
</div>

---
Primary Category: cs.DS  
Categories: cs-AI, cs-DS, cs-IR, cs.DS  
Keyword Score: 10  
Keywords: Recommendation  
<a type="button" class="btn btn-outline-primary" href="http://arxiv.org/abs/2402.06158v1" target="_blank" >Paper Link</a>
<button type="button" class="btn btn-outline-primary download-pdf" url="https://arxiv.org/pdf/2402.06158v1.pdf" filename="2402.06158v1.pdf">Download PDF</button>

---


**ABSTRACT**  
In the rapidly evolving landscape of retail, assortment planning plays a crucial role in determining the success of a business. With the rise of sponsored products and their increasing prominence in online marketplaces, retailers face new challenges in effectively managing their product assortment in the presence of sponsored products. Remarkably, previous research in assortment planning largely overlooks the existence of sponsored products and their potential impact on overall <b>recommendation</b> effectiveness. Instead, they commonly make the simplifying assumption that all products are either organic or non-sponsored. This research gap underscores the necessity for a more thorough investigation of the assortment planning challenge when sponsored products are in play. We formulate the assortment planning problem in the presence of sponsored products as a combinatorial optimization task. The ultimate objective is to compute an assortment plan that optimizes expected revenue while considering the specific requirements of placing sponsored products strategically.

{{</citation>}}


## math.OC (1)



### (0/1 | 192/197) Bandit Convex Optimisation (Tor Lattimore, 2024)

{{<citation>}}

Tor Lattimore. (2024)  
**Bandit Convex Optimisation**
<br/>
<button class="copy-to-clipboard" title="Bandit Convex Optimisation" index=192>
  <span class="copy-to-clipboard-item">Copy Title<span>
</button>
<div class="toast toast-copied toast-index-192 align-items-center text-bg-secondary border-0 position-absolute top-0 end-0" role="alert" aria-live="assertive" aria-atomic="true">
  <div class="d-flex">
    <div class="toast-body">
      Copied!
    </div>
  </div>
</div>

---
Primary Category: math.OC  
Categories: cs-LG, math-OC, math.OC, stat-ML  
Keyword Score: 10  
Keywords: Bandit Algorithm  
<a type="button" class="btn btn-outline-primary" href="http://arxiv.org/abs/2402.06535v1" target="_blank" >Paper Link</a>
<button type="button" class="btn btn-outline-primary download-pdf" url="https://arxiv.org/pdf/2402.06535v1.pdf" filename="2402.06535v1.pdf">Download PDF</button>

---


**ABSTRACT**  
<b>Bandit</b> convex optimisation is a fundamental framework for studying zeroth-order convex optimisation. These notes cover the many tools used for this problem, including cutting plane methods, interior point methods, continuous exponential weights, gradient descent and online Newton step. The nuances between the many assumptions and setups are explained. Although there is not much truly new here, some existing tools are applied in novel ways to obtain new algorithms. A few bounds are improved in minor ways.

{{</citation>}}


## cs.AR (2)



### (0/2 | 193/197) PULSE: Parametric Hardware Units for Low-power Sparsity-Aware Convolution Engine (Ilkin Aliyev et al., 2024)

{{<citation>}}

Ilkin Aliyev, Tosiron Adegbija. (2024)  
**PULSE: Parametric Hardware Units for Low-power Sparsity-Aware Convolution Engine**
<br/>
<button class="copy-to-clipboard" title="PULSE: Parametric Hardware Units for Low-power Sparsity-Aware Convolution Engine" index=193>
  <span class="copy-to-clipboard-item">Copy Title<span>
</button>
<div class="toast toast-copied toast-index-193 align-items-center text-bg-secondary border-0 position-absolute top-0 end-0" role="alert" aria-live="assertive" aria-atomic="true">
  <div class="d-flex">
    <div class="toast-body">
      Copied!
    </div>
  </div>
</div>

---
Primary Category: cs.AR  
Categories: cs-AR, cs.AR  
Keyword Score: 10  
Keywords: Convolution  
<a type="button" class="btn btn-outline-primary" href="http://arxiv.org/abs/2402.06210v1" target="_blank" >Paper Link</a>
<button type="button" class="btn btn-outline-primary download-pdf" url="https://arxiv.org/pdf/2402.06210v1.pdf" filename="2402.06210v1.pdf">Download PDF</button>

---


**ABSTRACT**  
Spiking Neural Networks (SNNs) have become popular for their more bio-realistic behavior than Artificial Neural Networks (ANNs). However, effectively leveraging the intrinsic, unstructured sparsity of SNNs in hardware is challenging, especially due to the variability in sparsity across network layers. This variability depends on several factors, including the input dataset, encoding scheme, and neuron model. Most existing SNN accelerators fail to account for the layer-specific workloads of an application (model + dataset), leading to high energy consumption. To address this, we propose a design-time parametric hardware generator that takes layer-wise sparsity and the number of processing elements as inputs and synthesizes the corresponding hardware. The proposed design compresses sparse spike trains using a priority encoder and efficiently shifts the activations across the network's layers. We demonstrate the robustness of our proposed approach by first profiling a given application's characteristics followed by performing efficient resource allocation. Results on a Xilinx Kintex FPGA (Field Programmable Gate Arrays) using MNIST, FashionMNIST, and SVHN datasets show a 3.14x improvement in accelerator efficiency (FPS/W) compared to a sparsity-oblivious systolic array-based accelerator. Compared to the most recent sparsity-aware work, our solution improves efficiency by 1.72x.

{{</citation>}}


### (1/2 | 194/197) Algorithm-hardware co-design for Energy-Efficient A/D conversion in ReRAM-based accelerators (Chenguang Zhang et al., 2024)

{{<citation>}}

Chenguang Zhang, Zhihang Yuan, Xingchen Li, Guangyu Sun. (2024)  
**Algorithm-hardware co-design for Energy-Efficient A/D conversion in ReRAM-based accelerators**
<br/>
<button class="copy-to-clipboard" title="Algorithm-hardware co-design for Energy-Efficient A/D conversion in ReRAM-based accelerators" index=194>
  <span class="copy-to-clipboard-item">Copy Title<span>
</button>
<div class="toast toast-copied toast-index-194 align-items-center text-bg-secondary border-0 position-absolute top-0 end-0" role="alert" aria-live="assertive" aria-atomic="true">
  <div class="d-flex">
    <div class="toast-body">
      Copied!
    </div>
  </div>
</div>

---
Primary Category: cs.AR  
Categories: cs-AR, cs.AR  
Keyword Score: 10  
Keywords: Quantization  
<a type="button" class="btn btn-outline-primary" href="http://arxiv.org/abs/2402.06164v1" target="_blank" >Paper Link</a>
<button type="button" class="btn btn-outline-primary download-pdf" url="https://arxiv.org/pdf/2402.06164v1.pdf" filename="2402.06164v1.pdf">Download PDF</button>

---


**ABSTRACT**  
Deep neural networks are widely deployed in many fields. Due to the in-situ computation (known as processing in memory) capacity of the Resistive Random Access Memory (ReRAM) crossbar, ReRAM-based accelerator shows potential in accelerating DNN with low power and high performance. However, despite power advantage, such kind of accelerators suffer from the high power consumption of peripheral circuits, especially Analog-to-Digital Converter (ADC), which account for over 60 percent of total power consumption. This problem hinders the ReRAM-based accelerator to achieve higher efficiency. Some redundant Analog-to-Digital conversion operations have no contribution to maintaining inference accuracy, and such operations can be eliminated by modifying the ADC searching logic. Based on such observations, we propose an algorithm-hardware co-design method and explore the co-design approach in both hardware design and <b>quantization</b> algorithms. Firstly, we focus on the distribution output along the crossbar's bit-lines and identify the fine-grained redundant ADC sampling bits. % of weight and To further compress ADC bits, we propose a hardware-friendly <b>quantization</b> method and coding scheme, in which different <b>quantization</b> strategy was applied to the partial results in different intervals. To support the two features above, we propose a lightweight architectural design based on SAR-ADC\@. It's worth mentioning that our method is not only more energy efficient but also retains the flexibility of the algorithm. Experiments demonstrate that our method can reduce about $1.6 \sim 2.3 \times$ ADC power reduction.

{{</citation>}}


## stat.ME (1)



### (0/1 | 195/197) Peeking with PEAK: Sequential, Nonparametric Composite Hypothesis Tests for Means of Multiple Data Streams (Brian Cho et al., 2024)

{{<citation>}}

Brian Cho, Kyra Gan, Nathan Kallus. (2024)  
**Peeking with PEAK: Sequential, Nonparametric Composite Hypothesis Tests for Means of Multiple Data Streams**
<br/>
<button class="copy-to-clipboard" title="Peeking with PEAK: Sequential, Nonparametric Composite Hypothesis Tests for Means of Multiple Data Streams" index=195>
  <span class="copy-to-clipboard-item">Copy Title<span>
</button>
<div class="toast toast-copied toast-index-195 align-items-center text-bg-secondary border-0 position-absolute top-0 end-0" role="alert" aria-live="assertive" aria-atomic="true">
  <div class="d-flex">
    <div class="toast-body">
      Copied!
    </div>
  </div>
</div>

---
Primary Category: stat.ME  
Categories: cs-LG, stat-ME, stat-ML, stat.ME  
Keyword Score: 10  
Keywords: Bandit Algorithm  
<a type="button" class="btn btn-outline-primary" href="http://arxiv.org/abs/2402.06122v1" target="_blank" >Paper Link</a>
<button type="button" class="btn btn-outline-primary download-pdf" url="https://arxiv.org/pdf/2402.06122v1.pdf" filename="2402.06122v1.pdf">Download PDF</button>

---


**ABSTRACT**  
We propose a novel nonparametric sequential test for composite hypotheses for means of multiple data streams. Our proposed method, \emph{peeking with expectation-based averaged capital} (PEAK), builds upon the testing-as-betting framework and provides a non-asymptotic $\alpha$-level test across any stopping time. PEAK is computationally tractable and efficiently rejects hypotheses that are incorrect across all potential distributions that satisfy our nonparametric assumption, enabling joint composite hypothesis testing on multiple streams of data. We numerically validate our theoretical findings under the best arm identification and threshold identification in the <b>bandit</b> setting, illustrating the computational efficiency of our method against state-of-the-art testing methods.

{{</citation>}}


## q-bio.QM (1)



### (0/1 | 196/197) evolSOM: an R Package for evolutionary conservation analysis with SOMs (Santiago Prochetto et al., 2024)

{{<citation>}}

Santiago Prochetto, Renata Reinheimer, Georgina Stegmayer. (2024)  
**evolSOM: an R Package for evolutionary conservation analysis with SOMs**
<br/>
<button class="copy-to-clipboard" title="evolSOM: an R Package for evolutionary conservation analysis with SOMs" index=196>
  <span class="copy-to-clipboard-item">Copy Title<span>
</button>
<div class="toast toast-copied toast-index-196 align-items-center text-bg-secondary border-0 position-absolute top-0 end-0" role="alert" aria-live="assertive" aria-atomic="true">
  <div class="d-flex">
    <div class="toast-body">
      Copied!
    </div>
  </div>
</div>

---
Primary Category: q-bio.QM  
Categories: cs-LG, q-bio-PE, q-bio-QM, q-bio.QM  
Keyword Score: 6  
Keywords: Multi-modal, Multi-modal  
<a type="button" class="btn btn-outline-primary" href="http://arxiv.org/abs/2402.07948v1" target="_blank" >Paper Link</a>
<button type="button" class="btn btn-outline-primary download-pdf" url="https://arxiv.org/pdf/2402.07948v1.pdf" filename="2402.07948v1.pdf">Download PDF</button>

---


**ABSTRACT**  
Motivation: Unraveling the connection between genes and traits is crucial for solving many biological puzzles. Genes provide instructions for building cellular machinery, directing the processes that sustain life. RNA molecules and proteins, derived from these genetic instructions, play crucial roles in shaping cell structures, influencing reactions, and guiding behavior. This fundamental biological principle links genetic makeup to observable traits, but integrating and extracting meaningful relationships from this complex, <b>multimodal</b> data presents a significant challenge. Results: We introduce evolSOM, a novel R package that utilizes Self-Organizing Maps (SOMs) to explore and visualize the conservation of biological variables, easing the integration of phenotypic and genotypic attributes. By constructing species-specific or condition-specific SOMs that capture non-redundant patterns, evolSOM allows the analysis of displacement of biological variables between species or conditions. Variables displaced together suggest membership in the same regulatory network, and the nature of the displacement may hold biological significance. The package automatically calculates and graphically presents these displacements, enabling efficient comparison and revealing conserved and displaced variables. The package facilitates the integration of diverse phenotypic data types, enabling the exploration of potential gene drivers underlying observed phenotypic changes. Its user-friendly interface and visualization capabilities enhance the accessibility of complex network analyses. Illustratively, we employed evolSOM to study the displacement of genes and phenotypic traits, successfully identifying potential drivers of phenotypic differentiation in grass leaves. Availability: The package is open-source and is available at https://github.com/sanprochetto/evolSOM.

{{</citation>}}


## cs.DB (1)



### (0/1 | 197/197) Retrieve, Merge, Predict: Augmenting Tables with Data Lakes (Riccardo Cappuzzo et al., 2024)

{{<citation>}}

Riccardo Cappuzzo, Gael Varoquaux, Aimee Coelho, Paolo Papotti. (2024)  
**Retrieve, Merge, Predict: Augmenting Tables with Data Lakes**
<br/>
<button class="copy-to-clipboard" title="Retrieve, Merge, Predict: Augmenting Tables with Data Lakes" index=197>
  <span class="copy-to-clipboard-item">Copy Title<span>
</button>
<div class="toast toast-copied toast-index-197 align-items-center text-bg-secondary border-0 position-absolute top-0 end-0" role="alert" aria-live="assertive" aria-atomic="true">
  <div class="d-flex">
    <div class="toast-body">
      Copied!
    </div>
  </div>
</div>

---
Primary Category: cs.DB  
Categories: cs-DB, cs-LG, cs.DB  
Keyword Score: 6  
Keywords: Benchmarking, Benchmarking  
<a type="button" class="btn btn-outline-primary" href="http://arxiv.org/abs/2402.06282v2" target="_blank" >Paper Link</a>
<button type="button" class="btn btn-outline-primary download-pdf" url="https://arxiv.org/pdf/2402.06282v2.pdf" filename="2402.06282v2.pdf">Download PDF</button>

---


**ABSTRACT**  
We present an in-depth analysis of data discovery in data lakes, focusing on table augmentation for given machine learning tasks. We analyze alternative methods used in the three main steps: retrieving joinable tables, merging information, and predicting with the resultant table. As data lakes, the paper uses YADL (Yet Another Data Lake) -- a novel dataset we developed as a tool for <b>benchmarking</b> this data discovery task -- and Open Data US, a well-referenced real data lake. Through systematic exploration on both lakes, our study outlines the importance of accurately retrieving join candidates and the efficiency of simple merging methods. We report new insights on the benefits of existing solutions and on their limitations, aiming at guiding future research in this space.

{{</citation>}}
