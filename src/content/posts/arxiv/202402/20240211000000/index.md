---
draft: false
title: "arXiv @ 2024.02.11"
date: 2024-02-11
author: "akitenkrad"
description: ""
tags: ["arXiv", "Published:2024"]
menu:
  sidebar:
    name: "arXiv @ 2024.02.11"
    identifier: arxiv_20240211
    parent: 202402_arxiv
    weight: 10
math: true
---

<figure style="border:none; width:100%; display:flex; justify-content: center">
    <iframe src="pie.html" width=900 height=620 style="border:none"></iframe>
</figure>


## Primary Categories

- [cs.AI (9)](#csai-9)
- [cs.AR (2)](#csar-2)
- [cs.CE (1)](#csce-1)
- [cs.CL (24)](#cscl-24)
- [cs.CR (1)](#cscr-1)
- [cs.CV (30)](#cscv-30)
- [cs.CY (1)](#cscy-1)
- [cs.DC (2)](#csdc-2)
- [cs.DS (2)](#csds-2)
- [cs.HC (3)](#cshc-3)
- [cs.IR (4)](#csir-4)
- [cs.IT (1)](#csit-1)
- [cs.LG (29)](#cslg-29)
- [cs.MA (1)](#csma-1)
- [cs.NE (2)](#csne-2)
- [cs.RO (6)](#csro-6)
- [cs.SD (4)](#cssd-4)
- [cs.SE (4)](#csse-4)
- [cs.SI (1)](#cssi-1)
- [eess.AS (1)](#eessas-1)
- [eess.IV (1)](#eessiv-1)
- [eess.SP (1)](#eesssp-1)
- [eess.SY (4)](#eesssy-4)
- [math.NA (2)](#mathna-2)
- [math.OC (1)](#mathoc-1)
- [physics.flu-dyn (2)](#physicsflu-dyn-2)
- [physics.geo-ph (1)](#physicsgeo-ph-1)
- [stat.CO (1)](#statco-1)
- [stat.ME (1)](#statme-1)
- [stat.ML (3)](#statml-3)

## Keywords

<table border="1" class="dataframe">
  <thead class='sticky-top'>
    <tr style="text-align: right;">
      <th>category</th>
      <th>cs.CL</th>
      <th>cs.CV</th>
      <th>cs.LG</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>Active Learning</th>
      <td></td>
      <td>1</td>
      <td>1</td>
    </tr>
    <tr>
      <th>Adversarial Attack</th>
      <td></td>
      <td>1</td>
      <td></td>
    </tr>
    <tr>
      <th>Adversarial Learning</th>
      <td></td>
      <td></td>
      <td>1</td>
    </tr>
    <tr>
      <th>Autoencoder</th>
      <td></td>
      <td>1</td>
      <td></td>
    </tr>
    <tr>
      <th>Automatic Evaluation</th>
      <td></td>
      <td>1</td>
      <td></td>
    </tr>
    <tr>
      <th>Automatic Speech Recognition</th>
      <td>2</td>
      <td></td>
      <td></td>
    </tr>
    <tr>
      <th>BERT</th>
      <td>2</td>
      <td></td>
      <td></td>
    </tr>
    <tr>
      <th>Bag-of-Words</th>
      <td></td>
      <td>1</td>
      <td></td>
    </tr>
    <tr>
      <th>Bandit Algorithm</th>
      <td></td>
      <td></td>
      <td>1</td>
    </tr>
    <tr>
      <th>ChatGPT</th>
      <td>3</td>
      <td></td>
      <td></td>
    </tr>
    <tr>
      <th>Code Generation</th>
      <td></td>
      <td></td>
      <td>1</td>
    </tr>
    <tr>
      <th>Continual Learning</th>
      <td></td>
      <td></td>
      <td>2</td>
    </tr>
    <tr>
      <th>Contrastive Learning</th>
      <td></td>
      <td>2</td>
      <td>2</td>
    </tr>
    <tr>
      <th>Convolution</th>
      <td></td>
      <td>5</td>
      <td></td>
    </tr>
    <tr>
      <th>Convolutional Neural Network</th>
      <td></td>
      <td>6</td>
      <td></td>
    </tr>
    <tr>
      <th>Data Augmentation</th>
      <td>1</td>
      <td></td>
      <td>1</td>
    </tr>
    <tr>
      <th>Dialogue System</th>
      <td>1</td>
      <td></td>
      <td></td>
    </tr>
    <tr>
      <th>Domain Adaptation</th>
      <td></td>
      <td>2</td>
      <td></td>
    </tr>
    <tr>
      <th>Event Detection</th>
      <td>1</td>
      <td></td>
      <td></td>
    </tr>
    <tr>
      <th>Fact Verification</th>
      <td>1</td>
      <td></td>
      <td></td>
    </tr>
    <tr>
      <th>Fairness</th>
      <td></td>
      <td>1</td>
      <td>2</td>
    </tr>
    <tr>
      <th>Few-shot</th>
      <td>2</td>
      <td>1</td>
      <td>2</td>
    </tr>
    <tr>
      <th>Fine-tuning</th>
      <td>9</td>
      <td>2</td>
      <td>3</td>
    </tr>
    <tr>
      <th>Foundation Model</th>
      <td></td>
      <td>1</td>
      <td></td>
    </tr>
    <tr>
      <th>GPT</th>
      <td>6</td>
      <td></td>
      <td></td>
    </tr>
    <tr>
      <th>GPT-4</th>
      <td>3</td>
      <td></td>
      <td></td>
    </tr>
    <tr>
      <th>Gaussian Process</th>
      <td></td>
      <td></td>
      <td>1</td>
    </tr>
    <tr>
      <th>Generative AI</th>
      <td>1</td>
      <td></td>
      <td>1</td>
    </tr>
    <tr>
      <th>Generative Adversarial Network</th>
      <td></td>
      <td>3</td>
      <td>2</td>
    </tr>
    <tr>
      <th>Graph Neural Network</th>
      <td></td>
      <td></td>
      <td>5</td>
    </tr>
    <tr>
      <th>Grounding</th>
      <td></td>
      <td>1</td>
      <td></td>
    </tr>
    <tr>
      <th>Hate Speech Detection</th>
      <td>1</td>
      <td></td>
      <td></td>
    </tr>
    <tr>
      <th>Image2text</th>
      <td></td>
      <td>1</td>
      <td></td>
    </tr>
    <tr>
      <th>In-context Learning</th>
      <td>3</td>
      <td>3</td>
      <td>1</td>
    </tr>
    <tr>
      <th>Information Retrieval</th>
      <td>1</td>
      <td></td>
      <td></td>
    </tr>
    <tr>
      <th>Instruction Following</th>
      <td>1</td>
      <td></td>
      <td>1</td>
    </tr>
    <tr>
      <th>Instruction Tuning</th>
      <td>2</td>
      <td></td>
      <td></td>
    </tr>
    <tr>
      <th>Knowledge Distillation</th>
      <td></td>
      <td>3</td>
      <td>5</td>
    </tr>
    <tr>
      <th>LLaMA</th>
      <td>3</td>
      <td></td>
      <td></td>
    </tr>
    <tr>
      <th>Language Generation</th>
      <td>1</td>
      <td></td>
      <td></td>
    </tr>
    <tr>
      <th>Large Language Model</th>
      <td>28</td>
      <td>4</td>
      <td>7</td>
    </tr>
    <tr>
      <th>Multiple Instance Learning</th>
      <td></td>
      <td>1</td>
      <td></td>
    </tr>
    <tr>
      <th>Named Entity Recognition</th>
      <td>2</td>
      <td></td>
      <td></td>
    </tr>
    <tr>
      <th>Natural Language Inference</th>
      <td>2</td>
      <td></td>
      <td></td>
    </tr>
    <tr>
      <th>Natural Language Understanding</th>
      <td>1</td>
      <td>1</td>
      <td></td>
    </tr>
    <tr>
      <th>Neural Machine Translation</th>
      <td>4</td>
      <td></td>
      <td>1</td>
    </tr>
    <tr>
      <th>Node Classification</th>
      <td></td>
      <td></td>
      <td>1</td>
    </tr>
    <tr>
      <th>Open-Domain Dialogue</th>
      <td>1</td>
      <td></td>
      <td></td>
    </tr>
    <tr>
      <th>Out-of-distribution</th>
      <td>1</td>
      <td>3</td>
      <td></td>
    </tr>
    <tr>
      <th>PaLM</th>
      <td>1</td>
      <td></td>
      <td></td>
    </tr>
    <tr>
      <th>Probabilistic Model</th>
      <td></td>
      <td></td>
      <td>1</td>
    </tr>
    <tr>
      <th>Prompt</th>
      <td>2</td>
      <td>2</td>
      <td>3</td>
    </tr>
    <tr>
      <th>Quantization</th>
      <td>2</td>
      <td></td>
      <td>2</td>
    </tr>
    <tr>
      <th>Question Answering</th>
      <td>5</td>
      <td></td>
      <td></td>
    </tr>
    <tr>
      <th>Reasoning</th>
      <td>4</td>
      <td>2</td>
      <td>2</td>
    </tr>
    <tr>
      <th>Recommendation</th>
      <td></td>
      <td></td>
      <td>1</td>
    </tr>
    <tr>
      <th>Reinforcement Learning</th>
      <td></td>
      <td></td>
      <td>4</td>
    </tr>
    <tr>
      <th>Retrieval Augmentation</th>
      <td>1</td>
      <td></td>
      <td></td>
    </tr>
    <tr>
      <th>Sample Size</th>
      <td></td>
      <td></td>
      <td>1</td>
    </tr>
    <tr>
      <th>Scaling Law</th>
      <td>1</td>
      <td></td>
      <td></td>
    </tr>
    <tr>
      <th>Self-supervised Learning</th>
      <td></td>
      <td>6</td>
      <td>3</td>
    </tr>
    <tr>
      <th>Self-supervised Pre-training</th>
      <td></td>
      <td>1</td>
      <td></td>
    </tr>
    <tr>
      <th>Semantic Parsing</th>
      <td>1</td>
      <td></td>
      <td></td>
    </tr>
    <tr>
      <th>Sentiment Analysis</th>
      <td>1</td>
      <td></td>
      <td></td>
    </tr>
    <tr>
      <th>Simulation</th>
      <td>1</td>
      <td></td>
      <td>3</td>
    </tr>
    <tr>
      <th>Simulator</th>
      <td>1</td>
      <td></td>
      <td>3</td>
    </tr>
    <tr>
      <th>Stance Detection</th>
      <td>1</td>
      <td></td>
      <td></td>
    </tr>
    <tr>
      <th>Stochastic Gradient Descent</th>
      <td></td>
      <td></td>
      <td>4</td>
    </tr>
    <tr>
      <th>Summarization</th>
      <td>2</td>
      <td></td>
      <td></td>
    </tr>
    <tr>
      <th>Supervised Learning</th>
      <td>1</td>
      <td>3</td>
      <td></td>
    </tr>
    <tr>
      <th>Text Generation</th>
      <td>2</td>
      <td></td>
      <td></td>
    </tr>
    <tr>
      <th>Text Summarization</th>
      <td>1</td>
      <td></td>
      <td></td>
    </tr>
    <tr>
      <th>Text2image</th>
      <td></td>
      <td>2</td>
      <td></td>
    </tr>
    <tr>
      <th>Transfer Learning</th>
      <td></td>
      <td>2</td>
      <td></td>
    </tr>
    <tr>
      <th>Transformer</th>
      <td>1</td>
      <td>3</td>
      <td>6</td>
    </tr>
    <tr>
      <th>Unsupervised Learning</th>
      <td></td>
      <td>3</td>
      <td></td>
    </tr>
    <tr>
      <th>Vision-and-Language</th>
      <td></td>
      <td>5</td>
      <td></td>
    </tr>
    <tr>
      <th>Weakly Supervised Learning</th>
      <td></td>
      <td>1</td>
      <td></td>
    </tr>
    <tr>
      <th>Word Embedding</th>
      <td>1</td>
      <td></td>
      <td></td>
    </tr>
    <tr>
      <th>Zero-shot</th>
      <td>1</td>
      <td>2</td>
      <td>2</td>
    </tr>
    <tr>
      <th>human-in-the-loop</th>
      <td></td>
      <td>1</td>
      <td></td>
    </tr>
  </tbody>
</table>

<script>
$(function() {
  $("table").addClass("keyword-table table-bordered");
  $("table thead").addClass("sticky-top");
  $("table tbody td").css("text-align", "");
});
</script>


## cs.CL (24)



### (1/145) Bryndza at ClimateActivism 2024: Stance, Target and Hate Event Detection via Retrieval-Augmented GPT-4 and LLaMA (Marek Å uppa et al., 2024)

{{<citation>}}

Marek Å uppa, Daniel Skala, Daniela JaÅ¡Å¡, Samuel SuÄÃ­k, Andrej Å vec, Peter HraÅ¡ka. (2024)  
**Bryndza at ClimateActivism 2024: Stance, Target and Hate Event Detection via Retrieval-Augmented GPT-4 and LLaMA**
<br/>
<button class="copy-to-clipboard" title="Bryndza at ClimateActivism 2024: Stance, Target and Hate Event Detection via Retrieval-Augmented GPT-4 and LLaMA" index=1>
  <span class="copy-to-clipboard-item">Copy Title<span>
</button>
<div class="toast toast-copied toast-index-1 align-items-center text-bg-secondary border-0 position-absolute top-0 end-0" role="alert" aria-live="assertive" aria-atomic="true">
  <div class="d-flex">
    <div class="toast-body">
      Copied!
    </div>
  </div>
</div>

---
Primary Category: cs.CL  
Categories: cs-AI, cs-CL, cs.CL  
Keyword Score: 100  
Keywords: Few-shot, GPT, GPT-4, LLaMA, Event Detection, Hate Speech Detection, Stance Detection, Large Language Model, Large Language Model, Retrieval Augmentation  
<a type="button" class="btn btn-outline-primary" href="http://arxiv.org/abs/2402.06549v1" target="_blank" >Paper Link</a>
<button type="button" class="btn btn-outline-primary download-pdf" url="https://arxiv.org/pdf/2402.06549v1.pdf" filename="2402.06549v1.pdf">Download PDF</button>

---


**ABSTRACT**  
This study details our approach for the CASE 2024 Shared Task on Climate Activism <b>Stance</b> <b>and</b> <b>Hate</b> <b>Event</b> <b>Detection,</b> focusing on <b>Hate</b> <b>Speech</b> <b>Detection,</b> <b>Hate</b> <b>Speech</b> <b>Target</b> Identification, and <b>Stance</b> <b>Detection</b> as classification challenges. We explored the capability of <b>Large</b> <b>Language</b> <b>Models</b> <b>(LLMs),</b> particularly <b>GPT-4,</b> in zero- or <b>few-shot</b> settings enhanced by <b>retrieval</b> <b>augmentation</b> and re-ranking for Tweet classification. Our goal was to determine if <b>LLMs</b> could match or surpass traditional methods in this context. We conducted an ablation study with <b>LLaMA</b> for comparison, and our results indicate that our models significantly outperformed the baselines, securing second place in the Target Detection task. The code for our submission is available at https://github.com/NaiveNeuron/bryndza-case-2024

{{</citation>}}


### (2/145) FaBERT: Pre-training BERT on Persian Blogs (Mostafa Masumi et al., 2024)

{{<citation>}}

Mostafa Masumi, Seyed Soroush Majd, Mehrnoush Shamsfard, Hamid Beigy. (2024)  
**FaBERT: Pre-training BERT on Persian Blogs**
<br/>
<button class="copy-to-clipboard" title="FaBERT: Pre-training BERT on Persian Blogs" index=2>
  <span class="copy-to-clipboard-item">Copy Title<span>
</button>
<div class="toast toast-copied toast-index-2 align-items-center text-bg-secondary border-0 position-absolute top-0 end-0" role="alert" aria-live="assertive" aria-atomic="true">
  <div class="d-flex">
    <div class="toast-body">
      Copied!
    </div>
  </div>
</div>

---
Primary Category: cs.CL  
Categories: cs-CL, cs.CL  
Keyword Score: 90  
Keywords: BERT, Named Entity Recognition, Named Entity Recognition, Natural Language Inference, Natural Language Inference, Natural Language Understanding, Question Answering, Question Answering, Sentiment Analysis  
<a type="button" class="btn btn-outline-primary" href="http://arxiv.org/abs/2402.06617v1" target="_blank" >Paper Link</a>
<button type="button" class="btn btn-outline-primary download-pdf" url="https://arxiv.org/pdf/2402.06617v1.pdf" filename="2402.06617v1.pdf">Download PDF</button>

---


**ABSTRACT**  
We introduce FaBERT, a Persian <b>BERT-base</b> model pre-trained on the HmBlogs corpus, encompassing both informal and formal Persian texts. FaBERT is designed to excel in traditional <b>Natural</b> <b>Language</b> <b>Understanding</b> (NLU) tasks, addressing the intricacies of diverse sentence structures and linguistic styles prevalent in the Persian language. In our comprehensive evaluation of FaBERT on 12 datasets in various downstream tasks, encompassing <b>Sentiment</b> <b>Analysis</b> (SA), <b>Named</b> <b>Entity</b> <b>Recognition</b> <b>(NER),</b> <b>Natural</b> <b>Language</b> <b>Inference</b> <b>(NLI),</b> <b>Question</b> <b>Answering</b> <b>(QA),</b> and <b>Question</b> <b>Paraphrasing</b> (QP), it consistently demonstrated improved performance, all achieved within a compact model size. The findings highlight the importance of utilizing diverse and cleaned corpora, such as HmBlogs, to enhance the performance of language models like <b>BERT</b> in Persian <b>Natural</b> <b>Language</b> <b>Processing</b> (NLP) applications. FaBERT is openly accessible at https://huggingface.co/sbunlp/fabert

{{</citation>}}


### (3/145) InternLM-Math: Open Math Large Language Models Toward Verifiable Reasoning (Huaiyuan Ying et al., 2024)

{{<citation>}}

Huaiyuan Ying, Shuo Zhang, Linyang Li, Zhejian Zhou, Yunfan Shao, Zhaoye Fei, Yichuan Ma, Jiawei Hong, Kuikun Liu, Ziyi Wang, Yudong Wang, Zijian Wu, Shuaibin Li, Fengzhe Zhou, Hongwei Liu, Songyang Zhang, Wenwei Zhang, Hang Yan, Xipeng Qiu, Jiayu Wang, Kai Chen, Dahua Lin. (2024)  
**InternLM-Math: Open Math Large Language Models Toward Verifiable Reasoning**
<br/>
<button class="copy-to-clipboard" title="InternLM-Math: Open Math Large Language Models Toward Verifiable Reasoning" index=3>
  <span class="copy-to-clipboard-item">Copy Title<span>
</button>
<div class="toast toast-copied toast-index-3 align-items-center text-bg-secondary border-0 position-absolute top-0 end-0" role="alert" aria-live="assertive" aria-atomic="true">
  <div class="d-flex">
    <div class="toast-body">
      Copied!
    </div>
  </div>
</div>

---
Primary Category: cs.CL  
Categories: cs-CL, cs.CL  
Keyword Score: 80  
Keywords: Data Augmentation, Fine-tuning, Supervised Learning, Reasoning, In-context Learning, In-context Learning, Large Language Model, Large Language Model  
<a type="button" class="btn btn-outline-primary" href="http://arxiv.org/abs/2402.06332v1" target="_blank" >Paper Link</a>
<button type="button" class="btn btn-outline-primary download-pdf" url="https://arxiv.org/pdf/2402.06332v1.pdf" filename="2402.06332v1.pdf">Download PDF</button>

---


**ABSTRACT**  
The math abilities of <b>large</b> <b>language</b> <b>models</b> can represent their abstract <b>reasoning</b> ability. In this paper, we introduce and open-source our math <b>reasoning</b> <b>LLMs</b> InternLM-Math which is continue pre-trained from InternLM2. We unify chain-of-thought <b>reasoning,</b> reward modeling, formal <b>reasoning,</b> <b>data</b> <b>augmentation,</b> and code interpreter in a unified seq2seq format and supervise our model to be a versatile math reasoner, verifier, prover, and augmenter. These abilities can be used to develop the next math <b>LLMs</b> or self-iteration. InternLM-Math obtains open-sourced state-of-the-art performance under the setting of <b>in-context</b> <b>learning,</b> <b>supervised</b> <b>fine-tuning,</b> and code-assisted <b>reasoning</b> in various informal and formal benchmarks including GSM8K, MATH, Hungary math exam, MathBench-ZH, and MiniF2F. Our pre-trained model achieves 30.3 on the MiniF2F test set without <b>fine-tuning.</b> We further explore how to use LEAN to solve math problems and study its performance under the setting of multi-task learning which shows the possibility of using LEAN as a unified platform for solving and proving in math. Our models, codes, and <b>data</b> <b>are</b> released at \url{https://github.com/InternLM/InternLM-Math}.

{{</citation>}}


### (4/145) Large Language Models: A Survey (Shervin Minaee et al., 2024)

{{<citation>}}

Shervin Minaee, Tomas Mikolov, Narjes Nikzad, Meysam Chenaghlu, Richard Socher, Xavier Amatriain, Jianfeng Gao. (2024)  
**Large Language Models: A Survey**
<br/>
<button class="copy-to-clipboard" title="Large Language Models: A Survey" index=4>
  <span class="copy-to-clipboard-item">Copy Title<span>
</button>
<div class="toast toast-copied toast-index-4 align-items-center text-bg-secondary border-0 position-absolute top-0 end-0" role="alert" aria-live="assertive" aria-atomic="true">
  <div class="d-flex">
    <div class="toast-body">
      Copied!
    </div>
  </div>
</div>

---
Primary Category: cs.CL  
Categories: cs-AI, cs-CL, cs.CL  
Keyword Score: 80  
Keywords: Fine-tuning, ChatGPT, GPT, LLaMA, PaLM, Large Language Model, Large Language Model, Scaling Law  
<a type="button" class="btn btn-outline-primary" href="http://arxiv.org/abs/2402.06196v1" target="_blank" >Paper Link</a>
<button type="button" class="btn btn-outline-primary download-pdf" url="https://arxiv.org/pdf/2402.06196v1.pdf" filename="2402.06196v1.pdf">Download PDF</button>

---


**ABSTRACT**  
<b>Large</b> <b>Language</b> <b>Models</b> <b>(LLMs)</b> have drawn a lot of attention due to their strong performance on a wide range of natural language tasks, since the release of <b>ChatGPT</b> in November 2022. <b>LLMs'</b> ability of general-purpose language understanding and generation is acquired by training billions of model's parameters on massive amounts of text data, as predicted by <b>scaling</b> <b>laws</b> \cite{kaplan2020scaling,hoffmann2022training}. The research area of <b>LLMs,</b> while very recent, is evolving rapidly in many different ways. In this paper, we review some of the most prominent <b>LLMs,</b> including three popular <b>LLM</b> families <b>(GPT,</b> <b>LLaMA,</b> <b>PaLM),</b> and discuss their characteristics, contributions and limitations. We also give an overview of techniques developed to build, and augment <b>LLMs.</b> We then survey popular datasets prepared for <b>LLM</b> training, <b>fine-tuning,</b> and evaluation, review widely used <b>LLM</b> evaluation metrics, and compare the performance of several popular <b>LLMs</b> on a set of representative benchmarks. Finally, we conclude the paper by discussing open challenges and future research directions.

{{</citation>}}


### (5/145) RareBench: Can LLMs Serve as Rare Diseases Specialists? (Xuanzhong Chen et al., 2024)

{{<citation>}}

Xuanzhong Chen, Xiaohao Mao, Qihan Guo, Lun Wang, Shuyang Zhang, Ting Chen. (2024)  
**RareBench: Can LLMs Serve as Rare Diseases Specialists?**
<br/>
<button class="copy-to-clipboard" title="RareBench: Can LLMs Serve as Rare Diseases Specialists?" index=5>
  <span class="copy-to-clipboard-item">Copy Title<span>
</button>
<div class="toast toast-copied toast-index-5 align-items-center text-bg-secondary border-0 position-absolute top-0 end-0" role="alert" aria-live="assertive" aria-atomic="true">
  <div class="d-flex">
    <div class="toast-body">
      Copied!
    </div>
  </div>
</div>

---
Primary Category: cs.CL  
Categories: cs-CL, cs.CL  
Keyword Score: 70  
Keywords: Few-shot, ChatGPT, GPT, GPT-4, Large Language Model, Large Language Model, Prompt  
<a type="button" class="btn btn-outline-primary" href="http://arxiv.org/abs/2402.06341v1" target="_blank" >Paper Link</a>
<button type="button" class="btn btn-outline-primary download-pdf" url="https://arxiv.org/pdf/2402.06341v1.pdf" filename="2402.06341v1.pdf">Download PDF</button>

---


**ABSTRACT**  
Generalist <b>Large</b> <b>Language</b> <b>Models</b> <b>(LLMs),</b> such as <b>GPT-4,</b> have shown considerable promise in various domains, including medical diagnosis. Rare diseases, affecting approximately 300 million people worldwide, often have unsatisfactory clinical diagnosis rates primarily due to a lack of experienced physicians and the complexity of differentiating among many rare diseases. In this context, recent news such as <b>"ChatGPT</b> correctly diagnosed a 4-year-old's rare disease after 17 doctors failed" underscore <b>LLMs'</b> potential, yet underexplored, role in clinically diagnosing rare diseases. To bridge this research gap, we introduce RareBench, a pioneering benchmark designed to systematically evaluate the capabilities of <b>LLMs</b> on 4 critical dimensions within the realm of rare diseases. Meanwhile, we have compiled the largest open-source dataset on rare disease patients, establishing a benchmark for future studies in this domain. To facilitate differential diagnosis of rare diseases, we develop a dynamic <b>few-shot</b> <b>prompt</b> methodology, leveraging a comprehensive rare disease knowledge graph synthesized from multiple knowledge bases, significantly enhancing <b>LLMs'</b> diagnostic performance. Moreover, we present an exhaustive comparative study of <b>GPT-4's</b> diagnostic capabilities against those of specialist physicians. Our experimental findings underscore the promising potential of integrating <b>LLMs</b> into the clinical diagnostic process for rare diseases. This paves the way for exciting possibilities in future advancements in this field.

{{</citation>}}


### (6/145) Calibrating Long-form Generations from Large Language Models (Yukun Huang et al., 2024)

{{<citation>}}

Yukun Huang, Yixin Liu, Raghuveer Thirukovalluru, Arman Cohan, Bhuwan Dhingra. (2024)  
**Calibrating Long-form Generations from Large Language Models**
<br/>
<button class="copy-to-clipboard" title="Calibrating Long-form Generations from Large Language Models" index=6>
  <span class="copy-to-clipboard-item">Copy Title<span>
</button>
<div class="toast toast-copied toast-index-6 align-items-center text-bg-secondary border-0 position-absolute top-0 end-0" role="alert" aria-live="assertive" aria-atomic="true">
  <div class="d-flex">
    <div class="toast-body">
      Copied!
    </div>
  </div>
</div>

---
Primary Category: cs.CL  
Categories: cs-AI, cs-CL, cs-LG, cs.CL  
Keyword Score: 60  
Keywords: Fine-tuning, ChatGPT, Question Answering, Large Language Model, Large Language Model, Summarization  
<a type="button" class="btn btn-outline-primary" href="http://arxiv.org/abs/2402.06544v1" target="_blank" >Paper Link</a>
<button type="button" class="btn btn-outline-primary download-pdf" url="https://arxiv.org/pdf/2402.06544v1.pdf" filename="2402.06544v1.pdf">Download PDF</button>

---


**ABSTRACT**  
To enhance <b>Large</b> <b>Language</b> <b>Models'</b> <b>(LLMs)</b> reliability, calibration is essential -- the model's assessed confidence scores should align with the actual likelihood of its responses being correct. However, current confidence elicitation methods and calibration metrics typically rely on a binary true/false assessment of response correctness. This approach does not apply to long-form generation, where an answer can be partially correct. Addressing this gap, we introduce a unified calibration framework, in which both the correctness of the <b>LLMs'</b> responses and their associated confidence levels are treated as distributions across a range of scores. Within this framework, we develop three metrics to precisely evaluate <b>LLM</b> calibration and further propose two confidence elicitation methods based on self-consistency and self-evaluation. Our experiments, which include long-form <b>QA</b> and <b>summarization</b> tasks, demonstrate that larger models don't necessarily guarantee better calibration, that calibration performance is found to be metric-dependent, and that self-consistency methods excel in factoid datasets. We also find that calibration can be enhanced through techniques such as <b>fine-tuning,</b> integrating relevant source documents, scaling the temperature, and combining self-consistency with self-evaluation. Lastly, we showcase a practical application of our system: selecting and cascading open-source models and <b>ChatGPT</b> to optimize correctness given a limited API budget. This research not only challenges existing notions of <b>LLM</b> calibration but also offers practical methodologies for improving trustworthiness in long-form generation.

{{</citation>}}


### (7/145) Inducing Systematicity in Transformers by Attending to Structurally Quantized Embeddings (Yichen Jiang et al., 2024)

{{<citation>}}

Yichen Jiang, Xiang Zhou, Mohit Bansal. (2024)  
**Inducing Systematicity in Transformers by Attending to Structurally Quantized Embeddings**
<br/>
<button class="copy-to-clipboard" title="Inducing Systematicity in Transformers by Attending to Structurally Quantized Embeddings" index=7>
  <span class="copy-to-clipboard-item">Copy Title<span>
</button>
<div class="toast toast-copied toast-index-7 align-items-center text-bg-secondary border-0 position-absolute top-0 end-0" role="alert" aria-live="assertive" aria-atomic="true">
  <div class="d-flex">
    <div class="toast-body">
      Copied!
    </div>
  </div>
</div>

---
Primary Category: cs.CL  
Categories: cs-AI, cs-CL, cs-LG, cs.CL  
Keyword Score: 60  
Keywords: Quantization, Quantization, Transformer, Neural Machine Translation, Semantic Parsing, Word Embedding  
<a type="button" class="btn btn-outline-primary" href="http://arxiv.org/abs/2402.06492v1" target="_blank" >Paper Link</a>
<button type="button" class="btn btn-outline-primary download-pdf" url="https://arxiv.org/pdf/2402.06492v1.pdf" filename="2402.06492v1.pdf">Download PDF</button>

---


**ABSTRACT**  
<b>Transformers</b> generalize to novel compositions of structures and entities after being trained on a complex dataset, but easily overfit on datasets of insufficient complexity. We observe that when the training set is sufficiently complex, the model encodes sentences that have a common syntactic structure using a systematic attention pattern. Inspired by this observation, we propose SQ-Transformer (Structurally <b>Quantized)</b> that explicitly encourages systematicity in the embeddings and attention layers, even with a training set of low complexity. At the embedding level, we introduce Structure-oriented Vector <b>Quantization</b> (SoVQ) to cluster <b>word</b> <b>embeddings</b> into several classes of structurally equivalent entities. At the attention level, we devise the Systematic Attention Layer (SAL) and an alternative, Systematically Regularized Layer (SRL) that operate on the <b>quantized</b> <b>word</b> <b>embeddings</b> so that sentences of the same structure are encoded with invariant or similar attention patterns. Empirically, we show that SQ-Transformer achieves stronger compositional generalization than the vanilla <b>Transformer</b> on multiple low-complexity <b>semantic</b> <b>parsing</b> and <b>machine</b> <b>translation</b> datasets. In our analysis, we show that SoVQ indeed learns a syntactically clustered embedding space and SAL/SRL induces generalizable attention patterns, which lead to improved systematicity.

{{</citation>}}


### (8/145) ResumeFlow: An LLM-facilitated Pipeline for Personalized Resume Generation and Refinement (Saurabh Bhausaheb Zinjad et al., 2024)

{{<citation>}}

Saurabh Bhausaheb Zinjad, Amrita Bhattacharjee, Amey Bhilegaonkar, Huan Liu. (2024)  
**ResumeFlow: An LLM-facilitated Pipeline for Personalized Resume Generation and Refinement**
<br/>
<button class="copy-to-clipboard" title="ResumeFlow: An LLM-facilitated Pipeline for Personalized Resume Generation and Refinement" index=8>
  <span class="copy-to-clipboard-item">Copy Title<span>
</button>
<div class="toast toast-copied toast-index-8 align-items-center text-bg-secondary border-0 position-absolute top-0 end-0" role="alert" aria-live="assertive" aria-atomic="true">
  <div class="d-flex">
    <div class="toast-body">
      Copied!
    </div>
  </div>
</div>

---
Primary Category: cs.CL  
Categories: cs-CL, cs-IR, cs.CL  
Keyword Score: 60  
Keywords: Fine-tuning, GPT, GPT-4, Information Retrieval, Large Language Model, Large Language Model  
<a type="button" class="btn btn-outline-primary" href="http://arxiv.org/abs/2402.06221v1" target="_blank" >Paper Link</a>
<button type="button" class="btn btn-outline-primary download-pdf" url="https://arxiv.org/pdf/2402.06221v1.pdf" filename="2402.06221v1.pdf">Download PDF</button>

---


**ABSTRACT**  
Crafting the ideal, job-specific resume is a challenging task for many job applicants, especially for early-career applicants. While it is highly recommended that applicants tailor their resume to the specific role they are applying for, manually tailoring resumes to job descriptions and role-specific requirements is often (1) extremely time-consuming, and (2) prone to human errors. Furthermore, performing such a tailoring step at scale while applying to several roles may result in a lack of quality of the edited resumes. To tackle this problem, in this demo paper, we propose ResumeFlow: a <b>Large</b> <b>Language</b> <b>Model</b> <b>(LLM)</b> aided tool that enables an end user to simply provide their detailed resume and the desired job posting, and obtain a personalized resume specifically tailored to that specific job posting in the matter of a few seconds. Our proposed pipeline leverages the language understanding and <b>information</b> <b>extraction</b> capabilities of state-of-the-art <b>LLMs</b> such as OpenAI's <b>GPT-4</b> and Google's Gemini, in order to (1) extract details from a job description, (2) extract role-specific details from the user-provided resume, and then (3) use these to refine and generate a role-specific resume for the user. Our easy-to-use tool leverages the user-chosen <b>LLM</b> in a completely off-the-shelf manner, thus requiring no <b>fine-tuning.</b> We demonstrate the effectiveness of our tool via a video demo and propose novel task-specific evaluation metrics to control for alignment and hallucination. Our tool is available at https://job-aligned-resume.streamlit.app.

{{</citation>}}


### (9/145) Aya Dataset: An Open-Access Collection for Multilingual Instruction Tuning (Shivalika Singh et al., 2024)

{{<citation>}}

Shivalika Singh, Freddie Vargus, Daniel Dsouza, BÃ¶rje F. Karlsson, Abinaya Mahendiran, Wei-Yin Ko, Herumb Shandilya, Jay Patel, Deividas Mataciunas, Laura OMahony, Mike Zhang, Ramith Hettiarachchi, Joseph Wilson, Marina Machado, Luisa Souza Moura, Dominik KrzemiÅski, Hakimeh Fadaei, Irem ErgÃ¼n, Ifeoma Okoh, Aisha Alaagib, Oshan Mudannayake, Zaid Alyafeai, Vu Minh Chien, Sebastian Ruder, Surya Guthikonda, Emad A. Alghamdi, Sebastian Gehrmann, Niklas Muennighoff, Max Bartolo, Julia Kreutzer, Ahmet ÃstÃ¼n, Marzieh Fadaee, Sara Hooker. (2024)  
**Aya Dataset: An Open-Access Collection for Multilingual Instruction Tuning**
<br/>
<button class="copy-to-clipboard" title="Aya Dataset: An Open-Access Collection for Multilingual Instruction Tuning" index=9>
  <span class="copy-to-clipboard-item">Copy Title<span>
</button>
<div class="toast toast-copied toast-index-9 align-items-center text-bg-secondary border-0 position-absolute top-0 end-0" role="alert" aria-live="assertive" aria-atomic="true">
  <div class="d-flex">
    <div class="toast-body">
      Copied!
    </div>
  </div>
</div>

---
Primary Category: cs.CL  
Categories: cs-AI, cs-CL, cs.CL  
Keyword Score: 50  
Keywords: Fine-tuning, Instruction Following, Instruction Tuning, Large Language Model, Large Language Model  
<a type="button" class="btn btn-outline-primary" href="http://arxiv.org/abs/2402.06619v1" target="_blank" >Paper Link</a>
<button type="button" class="btn btn-outline-primary download-pdf" url="https://arxiv.org/pdf/2402.06619v1.pdf" filename="2402.06619v1.pdf">Download PDF</button>

---


**ABSTRACT**  
Datasets are foundational to many breakthroughs in modern artificial intelligence. Many recent achievements in the space of natural language processing (NLP) can be attributed to the <b>finetuning</b> of pre-trained models on a diverse set of tasks that enables a <b>large</b> <b>language</b> <b>model</b> <b>(LLM)</b> to respond to <b>instructions.</b> <b>Instruction</b> <b>fine-tuning</b> (IFT) requires specifically constructed and annotated datasets. However, existing datasets are almost all in the English language. In this work, our primary goal is to bridge the language gap by building a human-curated <b>instruction-following</b> <b>dataset</b> spanning 65 languages. We worked with fluent speakers of languages from around the world to collect natural instances of <b>instructions</b> <b>and</b> completions. Furthermore, we create the most extensive multilingual collection to date, comprising 513 million instances through templating and translating existing datasets across 114 languages. In total, we contribute four key resources: we develop and open-source the Aya Annotation Platform, the Aya Dataset, the Aya Collection, and the Aya Evaluation Suite. The Aya initiative also serves as a valuable case study in participatory research, involving collaborators from 119 countries. We see this as a valuable framework for future research collaborations that aim to bridge gaps in resources.

{{</citation>}}


### (10/145) The Generative AI Paradox on Evaluation: What It Can Solve, It May Not Evaluate (Juhyun Oh et al., 2024)

{{<citation>}}

Juhyun Oh, Eunsu Kim, Inha Cha, Alice Oh. (2024)  
**The Generative AI Paradox on Evaluation: What It Can Solve, It May Not Evaluate**
<br/>
<button class="copy-to-clipboard" title="The Generative AI Paradox on Evaluation: What It Can Solve, It May Not Evaluate" index=10>
  <span class="copy-to-clipboard-item">Copy Title<span>
</button>
<div class="toast toast-copied toast-index-10 align-items-center text-bg-secondary border-0 position-absolute top-0 end-0" role="alert" aria-live="assertive" aria-atomic="true">
  <div class="d-flex">
    <div class="toast-body">
      Copied!
    </div>
  </div>
</div>

---
Primary Category: cs.CL  
Categories: cs-AI, cs-CL, cs.CL  
Keyword Score: 50  
Keywords: Generative AI, Question Answering, Question Answering, Large Language Model, Large Language Model  
<a type="button" class="btn btn-outline-primary" href="http://arxiv.org/abs/2402.06204v1" target="_blank" >Paper Link</a>
<button type="button" class="btn btn-outline-primary download-pdf" url="https://arxiv.org/pdf/2402.06204v1.pdf" filename="2402.06204v1.pdf">Download PDF</button>

---


**ABSTRACT**  
This paper explores the assumption that <b>Large</b> <b>Language</b> <b>Models</b> <b>(LLMs)</b> skilled in generation tasks are equally adept as evaluators. We assess the performance of three <b>LLMs</b> and one open-source LM in <b>Question-Answering</b> <b>(QA)</b> and evaluation tasks using the TriviaQA (Joshi et al., 2017) dataset. Results indicate a significant disparity, with <b>LLMs</b> exhibiting lower performance in evaluation tasks compared to generation tasks. Intriguingly, we discover instances of unfaithful evaluation where models accurately evaluate answers in areas where they lack competence, underscoring the need to examine the faithfulness and trustworthiness of <b>LLMs</b> as evaluators. This study contributes to the understanding of "the <b>Generative</b> <b>AI</b> Paradox" (West et al., 2023), highlighting a need to explore the correlation between <b>generative</b> <b>excellence</b> and evaluation proficiency, and the necessity to scrutinize the faithfulness aspect in model evaluations.

{{</citation>}}


### (11/145) Learn To be Efficient: Build Structured Sparsity in Large Language Models (Haizhong Zheng et al., 2024)

{{<citation>}}

Haizhong Zheng, Xiaoyan Bai, Beidi Chen, Fan Lai, Atul Prakash. (2024)  
**Learn To be Efficient: Build Structured Sparsity in Large Language Models**
<br/>
<button class="copy-to-clipboard" title="Learn To be Efficient: Build Structured Sparsity in Large Language Models" index=11>
  <span class="copy-to-clipboard-item">Copy Title<span>
</button>
<div class="toast toast-copied toast-index-11 align-items-center text-bg-secondary border-0 position-absolute top-0 end-0" role="alert" aria-live="assertive" aria-atomic="true">
  <div class="d-flex">
    <div class="toast-body">
      Copied!
    </div>
  </div>
</div>

---
Primary Category: cs.CL  
Categories: cs-AI, cs-CL, cs-LG, cs.CL  
Keyword Score: 50  
Keywords: GPT, LLaMA, Language Generation, Large Language Model, Large Language Model  
<a type="button" class="btn btn-outline-primary" href="http://arxiv.org/abs/2402.06126v1" target="_blank" >Paper Link</a>
<button type="button" class="btn btn-outline-primary download-pdf" url="https://arxiv.org/pdf/2402.06126v1.pdf" filename="2402.06126v1.pdf">Download PDF</button>

---


**ABSTRACT**  
<b>Large</b> <b>Language</b> <b>Models</b> <b>(LLMs)</b> have achieved remarkable success with their billion-level parameters, yet they incur high inference overheads. The emergence of activation sparsity in <b>LLMs</b> provides a natural approach to reduce this cost by involving only parts of the parameters for inference. Existing methods only focus on utilizing this naturally formed activation sparsity, overlooking the potential for further amplifying this inherent sparsity. In this paper, we hypothesize that <b>LLMs</b> can learn to be efficient by achieving more structured activation sparsity.To achieve this, we introduce a novel algorithm, Learn-To-be-Efficient (LTE), designed to train efficiency-aware <b>LLMs</b> to learn to activate fewer neurons and achieve a better trade-off between sparsity and performance. Furthermore, unlike SOTA MoEfication methods, which mainly focus on ReLU-based models, LTE can also be applied to <b>LLMs</b> like <b>GPT</b> and <b>LLaMA</b> with soft activation functions. We evaluate LTE on four models and eleven datasets. The experiments show that LTE achieves a better trade-off between sparsity and task performance. For instance, LTE with <b>LLaMA</b> provides a 1.83x-2.59x FLOPs speed-up on <b>language</b> <b>generation</b> tasks, outperforming the state-of-the-art methods.

{{</citation>}}


### (12/145) Understanding the Effects of Iterative Prompting on Truthfulness (Satyapriya Krishna et al., 2024)

{{<citation>}}

Satyapriya Krishna, Chirag Agarwal, Himabindu Lakkaraju. (2024)  
**Understanding the Effects of Iterative Prompting on Truthfulness**
<br/>
<button class="copy-to-clipboard" title="Understanding the Effects of Iterative Prompting on Truthfulness" index=12>
  <span class="copy-to-clipboard-item">Copy Title<span>
</button>
<div class="toast toast-copied toast-index-12 align-items-center text-bg-secondary border-0 position-absolute top-0 end-0" role="alert" aria-live="assertive" aria-atomic="true">
  <div class="d-flex">
    <div class="toast-body">
      Copied!
    </div>
  </div>
</div>

---
Primary Category: cs.CL  
Categories: cs-CL, cs.CL  
Keyword Score: 40  
Keywords: Text Generation, Large Language Model, Large Language Model, Prompt  
<a type="button" class="btn btn-outline-primary" href="http://arxiv.org/abs/2402.06625v1" target="_blank" >Paper Link</a>
<button type="button" class="btn btn-outline-primary download-pdf" url="https://arxiv.org/pdf/2402.06625v1.pdf" filename="2402.06625v1.pdf">Download PDF</button>

---


**ABSTRACT**  
The development of <b>Large</b> <b>Language</b> <b>Models</b> <b>(LLMs)</b> has notably transformed numerous sectors, offering impressive <b>text</b> <b>generation</b> capabilities. Yet, the reliability and truthfulness of these models remain pressing concerns. To this end, we investigate iterative <b>prompting,</b> a strategy hypothesized to refine <b>LLM</b> responses, assessing its impact on <b>LLM</b> truthfulness, an area which has not been thoroughly explored. Our extensive experiments delve into the intricacies of iterative <b>prompting</b> variants, examining their influence on the accuracy and calibration of model responses. Our findings reveal that naive <b>prompting</b> methods significantly undermine truthfulness, leading to exacerbated calibration errors. In response to these challenges, we introduce several <b>prompting</b> variants designed to address the identified issues. These variants demonstrate marked improvements over existing baselines, signaling a promising direction for future research. Our work provides a nuanced understanding of iterative <b>prompting</b> and introduces novel approaches to enhance the truthfulness of <b>LLMs,</b> thereby contributing to the development of more accurate and trustworthy AI systems.

{{</citation>}}


### (13/145) G-SciEdBERT: A Contextualized LLM for Science Assessment Tasks in German (Ehsan Latif et al., 2024)

{{<citation>}}

Ehsan Latif, Gyeong-Geon Lee, Knut Neuman, Tamara Kastorff, Xiaoming Zhai. (2024)  
**G-SciEdBERT: A Contextualized LLM for Science Assessment Tasks in German**
<br/>
<button class="copy-to-clipboard" title="G-SciEdBERT: A Contextualized LLM for Science Assessment Tasks in German" index=13>
  <span class="copy-to-clipboard-item">Copy Title<span>
</button>
<div class="toast toast-copied toast-index-13 align-items-center text-bg-secondary border-0 position-absolute top-0 end-0" role="alert" aria-live="assertive" aria-atomic="true">
  <div class="d-flex">
    <div class="toast-body">
      Copied!
    </div>
  </div>
</div>

---
Primary Category: cs.CL  
Categories: cs-AI, cs-CL, cs.CL  
Keyword Score: 40  
Keywords: Fine-tuning, BERT, Large Language Model, Large Language Model  
<a type="button" class="btn btn-outline-primary" href="http://arxiv.org/abs/2402.06584v1" target="_blank" >Paper Link</a>
<button type="button" class="btn btn-outline-primary download-pdf" url="https://arxiv.org/pdf/2402.06584v1.pdf" filename="2402.06584v1.pdf">Download PDF</button>

---


**ABSTRACT**  
The advancement of natural language processing has paved the way for automated scoring systems in various languages, such as German (e.g., German <b>BERT</b> [G-BERT]). Automatically scoring written responses to science questions in German is a complex task and challenging for standard G-BERT as they lack contextual knowledge in the science domain and may be unaligned with student writing styles. This paper developed a contextualized German Science Education <b>BERT</b> (G-SciEdBERT), an innovative <b>large</b> <b>language</b> <b>model</b> tailored for scoring German-written responses to science tasks. Using G-BERT, we pre-trained G-SciEdBERT on a corpus of 50K German written science responses with 5M tokens to the Programme for International Student Assessment (PISA) 2015. We <b>fine-tuned</b> G-SciEdBERT on 59 assessment items and examined the scoring accuracy. We then compared its performance with G-BERT. Our findings reveal a substantial improvement in scoring accuracy with G-SciEdBERT, demonstrating a 10% increase of quadratic weighted kappa compared to G-BERT (mean accuracy difference = 0.096, SD = 0.024). These insights underline the significance of specialized language models like G-SciEdBERT, which is trained to enhance the accuracy of automated scoring, offering a substantial contribution to the field of AI in education.

{{</citation>}}


### (14/145) Explaining Veracity Predictions with Evidence Summarization: A Multi-Task Model Approach (Recep Firat Cekinel et al., 2024)

{{<citation>}}

Recep Firat Cekinel, Pinar Karagoz. (2024)  
**Explaining Veracity Predictions with Evidence Summarization: A Multi-Task Model Approach**
<br/>
<button class="copy-to-clipboard" title="Explaining Veracity Predictions with Evidence Summarization: A Multi-Task Model Approach" index=14>
  <span class="copy-to-clipboard-item">Copy Title<span>
</button>
<div class="toast toast-copied toast-index-14 align-items-center text-bg-secondary border-0 position-absolute top-0 end-0" role="alert" aria-live="assertive" aria-atomic="true">
  <div class="d-flex">
    <div class="toast-body">
      Copied!
    </div>
  </div>
</div>

---
Primary Category: cs.CL  
Categories: cs-CL, cs.CL  
Keyword Score: 40  
Keywords: Fact Verification, Reasoning, Text Summarization, Summarization  
<a type="button" class="btn btn-outline-primary" href="http://arxiv.org/abs/2402.06443v1" target="_blank" >Paper Link</a>
<button type="button" class="btn btn-outline-primary download-pdf" url="https://arxiv.org/pdf/2402.06443v1.pdf" filename="2402.06443v1.pdf">Download PDF</button>

---


**ABSTRACT**  
The rapid dissemination of misinformation through social media increased the importance of automated <b>fact-checking.</b> <b>Furthermore,</b> studies on what deep neural models pay attention to when making predictions have increased in recent years. While significant progress has been made in this field, it has not yet reached a level of <b>reasoning</b> comparable to human <b>reasoning.</b> To address these gaps, we propose a multi-task explainable neural model for misinformation detection. Specifically, this work formulates an explanation generation process of the model's veracity prediction as a <b>text</b> <b>summarization</b> problem. Additionally, the performance of the proposed model is discussed on publicly available datasets and the findings are evaluated with related studies.

{{</citation>}}


### (15/145) Findings of the First Workshop on Simulating Conversational Intelligence in Chat (Yvette Graham et al., 2024)

{{<citation>}}

Yvette Graham, Mohammed Rameez Qureshi, Haider Khalid, Gerasimos Lampouras, Ignacio Iacobacci, Qun Liu. (2024)  
**Findings of the First Workshop on Simulating Conversational Intelligence in Chat**
<br/>
<button class="copy-to-clipboard" title="Findings of the First Workshop on Simulating Conversational Intelligence in Chat" index=15>
  <span class="copy-to-clipboard-item">Copy Title<span>
</button>
<div class="toast toast-copied toast-index-15 align-items-center text-bg-secondary border-0 position-absolute top-0 end-0" role="alert" aria-live="assertive" aria-atomic="true">
  <div class="d-flex">
    <div class="toast-body">
      Copied!
    </div>
  </div>
</div>

---
Primary Category: cs.CL  
Categories: cs-CL, cs.CL  
Keyword Score: 40  
Keywords: Simulation, Simulator, Open-Domain Dialogue, Reasoning  
<a type="button" class="btn btn-outline-primary" href="http://arxiv.org/abs/2402.06420v1" target="_blank" >Paper Link</a>
<button type="button" class="btn btn-outline-primary download-pdf" url="https://arxiv.org/pdf/2402.06420v1.pdf" filename="2402.06420v1.pdf">Download PDF</button>

---


**ABSTRACT**  
The aim of this workshop is to bring together experts working on <b>open-domain</b> <b>dialogue</b> research. In this speedily advancing research area many challenges still exist, such as learning information from conversations, engaging in realistic and convincing <b>simulation</b> of human intelligence and <b>reasoning.</b> SCI-CHAT follows previous workshops on open domain dialogue but with a focus on the <b>simulation</b> of intelligent conversation as judged in a live human evaluation. Models aim to include the ability to follow a challenging topic over a multi-turn conversation, while positing, refuting and <b>reasoning</b> over arguments. The workshop included both a research track and shared task. The main goal of this paper is to provide an overview of the shared task and a link to an additional paper that will include an in depth analysis of the shared task results following presentation at the workshop.

{{</citation>}}


### (16/145) Promoting Target Data in Context-aware Neural Machine Translation (Harritxu Gete et al., 2024)

{{<citation>}}

Harritxu Gete, Thierry Etchegoyhen. (2024)  
**Promoting Target Data in Context-aware Neural Machine Translation**
<br/>
<button class="copy-to-clipboard" title="Promoting Target Data in Context-aware Neural Machine Translation" index=16>
  <span class="copy-to-clipboard-item">Copy Title<span>
</button>
<div class="toast toast-copied toast-index-16 align-items-center text-bg-secondary border-0 position-absolute top-0 end-0" role="alert" aria-live="assertive" aria-atomic="true">
  <div class="d-flex">
    <div class="toast-body">
      Copied!
    </div>
  </div>
</div>

---
Primary Category: cs.CL  
Categories: cs-CL, cs.CL  
Keyword Score: 40  
Keywords: Neural Machine Translation, Neural Machine Translation, Neural Machine Translation, In-context Learning  
<a type="button" class="btn btn-outline-primary" href="http://arxiv.org/abs/2402.06342v1" target="_blank" >Paper Link</a>
<button type="button" class="btn btn-outline-primary download-pdf" url="https://arxiv.org/pdf/2402.06342v1.pdf" filename="2402.06342v1.pdf">Download PDF</button>

---


**ABSTRACT**  
Standard context-aware <b>neural</b> <b>machine</b> <b>translation</b> <b>(NMT)</b> typically relies on parallel document-level data, exploiting both source and target contexts. Concatenation-based approaches in particular, still a strong baseline for document-level <b>NMT,</b> prepend source and/or target context sentences to the sentences to be translated, with model variants that exploit equal amounts of source and target data on each side achieving state-of-the-art results. In this work, we investigate whether target data should be further promoted within standard concatenation-based approaches, as most document-level phenomena rely on information that is present on the target language side. We evaluate novel concatenation-based variants where the target context is prepended to the source language, either in isolation or in combination with the source context. Experimental results in English-Russian and Basque-Spanish show that including target context in the source leads to large improvements on target language phenomena. On source-dependent phenomena, using only target language context in the source achieves parity with state-of-the-art concatenation approaches, or slightly underperforms, whereas combining source and target context on the source side leads to significant gains across the board.

{{</citation>}}


### (17/145) Model Editing with Canonical Examples (John Hewitt et al., 2024)

{{<citation>}}

John Hewitt, Sarah Chen, Lanruo Lora Xie, Edward Adams, Percy Liang, Christopher D. Manning. (2024)  
**Model Editing with Canonical Examples**
<br/>
<button class="copy-to-clipboard" title="Model Editing with Canonical Examples" index=17>
  <span class="copy-to-clipboard-item">Copy Title<span>
</button>
<div class="toast toast-copied toast-index-17 align-items-center text-bg-secondary border-0 position-absolute top-0 end-0" role="alert" aria-live="assertive" aria-atomic="true">
  <div class="d-flex">
    <div class="toast-body">
      Copied!
    </div>
  </div>
</div>

---
Primary Category: cs.CL  
Categories: cs-CL, cs.CL  
Keyword Score: 40  
Keywords: Fine-tuning, Fine-tuning, Out-of-distribution, GPT  
<a type="button" class="btn btn-outline-primary" href="http://arxiv.org/abs/2402.06155v1" target="_blank" >Paper Link</a>
<button type="button" class="btn btn-outline-primary download-pdf" url="https://arxiv.org/pdf/2402.06155v1.pdf" filename="2402.06155v1.pdf">Download PDF</button>

---


**ABSTRACT**  
We introduce model editing with canonical examples, a setting in which (1) a single learning example is provided per desired behavior, (2) evaluation is performed exclusively <b>out-of-distribution,</b> and (3) deviation from an initial model is strictly limited. A canonical example is a simple instance of good behavior, e.g., The capital of Mauritius is Port Louis) or bad behavior, e.g., An aspect of researchers is coldhearted). The evaluation set contains more complex examples of each behavior (like a paragraph in which the capital of Mauritius is called for.) We create three datasets and modify three more for model editing with canonical examples, covering knowledge-intensive improvements, social bias mitigation, and syntactic edge cases. In our experiments on Pythia language models, we find that LoRA outperforms full <b>finetuning</b> and MEMIT. We then turn to the Backpack language model architecture because it is intended to enable targeted improvement. The Backpack defines a large bank of sense vectors--a decomposition of the different uses of each word--which are weighted and summed to form the output logits of the model. We propose sense <b>finetuning,</b> which selects and <b>finetunes</b> a few ($\approx$ 10) sense vectors for each canonical example, and find that it outperforms other <b>finetuning</b> methods, e.g., 4.8% improvement vs 0.3%. Finally, we improve <b>GPT-J-6B</b> by an inference-time ensemble with just the changes from sense <b>finetuning</b> of a 35x smaller Backpack, in one setting outperforming editing <b>GPT-J</b> itself (4.1% vs 1.0%).

{{</citation>}}


### (18/145) Language Model Sentence Completion with a Parser-Driven Rhetorical Control Method (Joshua Zingale et al., 2024)

{{<citation>}}

Joshua Zingale, Jugal Kalita. (2024)  
**Language Model Sentence Completion with a Parser-Driven Rhetorical Control Method**
<br/>
<button class="copy-to-clipboard" title="Language Model Sentence Completion with a Parser-Driven Rhetorical Control Method" index=18>
  <span class="copy-to-clipboard-item">Copy Title<span>
</button>
<div class="toast toast-copied toast-index-18 align-items-center text-bg-secondary border-0 position-absolute top-0 end-0" role="alert" aria-live="assertive" aria-atomic="true">
  <div class="d-flex">
    <div class="toast-body">
      Copied!
    </div>
  </div>
</div>

---
Primary Category: cs.CL  
Categories: cs-CL, cs.CL  
Keyword Score: 40  
Keywords: Fine-tuning, Text Generation, Large Language Model, Large Language Model  
<a type="button" class="btn btn-outline-primary" href="http://arxiv.org/abs/2402.06125v1" target="_blank" >Paper Link</a>
<button type="button" class="btn btn-outline-primary download-pdf" url="https://arxiv.org/pdf/2402.06125v1.pdf" filename="2402.06125v1.pdf">Download PDF</button>

---


**ABSTRACT**  
Controlled <b>text</b> <b>generation</b> (CTG) seeks to guide <b>large</b> <b>language</b> <b>model</b> <b>(LLM)</b> output to produce <b>text</b> <b>that</b> conforms to desired criteria. The current study presents a novel CTG algorithm that enforces adherence toward specific rhetorical relations in an <b>LLM</b> sentence-completion context by a parser-driven decoding scheme that requires no model <b>fine-tuning.</b> The method is validated both with automatic and human evaluation. The code is accessible on GitHub.

{{</citation>}}


### (19/145) Exploring Group and Symmetry Principles in Large Language Models (Shima Imani et al., 2024)

{{<citation>}}

Shima Imani, Hamid Palangi. (2024)  
**Exploring Group and Symmetry Principles in Large Language Models**
<br/>
<button class="copy-to-clipboard" title="Exploring Group and Symmetry Principles in Large Language Models" index=19>
  <span class="copy-to-clipboard-item">Copy Title<span>
</button>
<div class="toast toast-copied toast-index-19 align-items-center text-bg-secondary border-0 position-absolute top-0 end-0" role="alert" aria-live="assertive" aria-atomic="true">
  <div class="d-flex">
    <div class="toast-body">
      Copied!
    </div>
  </div>
</div>

---
Primary Category: cs.CL  
Categories: cs-CL, cs.CL  
Keyword Score: 30  
Keywords: Reasoning, Large Language Model, Large Language Model  
<a type="button" class="btn btn-outline-primary" href="http://arxiv.org/abs/2402.06120v1" target="_blank" >Paper Link</a>
<button type="button" class="btn btn-outline-primary download-pdf" url="https://arxiv.org/pdf/2402.06120v1.pdf" filename="2402.06120v1.pdf">Download PDF</button>

---


**ABSTRACT**  
<b>Large</b> <b>Language</b> <b>Models</b> <b>(LLMs)</b> have demonstrated impressive performance across a wide range of applications; however, assessing their <b>reasoning</b> capabilities remains a significant challenge. In this paper, we introduce a framework grounded in group and symmetry principles, which have played a crucial role in fields such as physics and mathematics, and offer another way to evaluate their capabilities. While the proposed framework is general, to showcase the benefits of employing these properties, we focus on arithmetic <b>reasoning</b> and investigate the performance of these models on four group properties: closure, identity, inverse, and associativity. Our findings reveal that <b>LLMs</b> studied in this work struggle to preserve group properties across different test regimes. In the closure test, we observe biases towards specific outputs and an abrupt degradation in their performance from 100% to 0% after a specific sequence length. They also perform poorly in the identity test, which represents adding irrelevant information in the context, and show sensitivity when subjected to inverse test, which examines the robustness of the model with respect to negation. In addition, we demonstrate that breaking down problems into smaller steps helps <b>LLMs</b> in the associativity test that we have conducted. To support these tests we have developed a synthetic dataset which will be released.

{{</citation>}}


### (20/145) Self-consistent context aware conformer transducer for speech recognition (Konstantin Kolokolov et al., 2024)

{{<citation>}}

Konstantin Kolokolov, Pavel Pekichev, Karthik Raghunathan. (2024)  
**Self-consistent context aware conformer transducer for speech recognition**
<br/>
<button class="copy-to-clipboard" title="Self-consistent context aware conformer transducer for speech recognition" index=20>
  <span class="copy-to-clipboard-item">Copy Title<span>
</button>
<div class="toast toast-copied toast-index-20 align-items-center text-bg-secondary border-0 position-absolute top-0 end-0" role="alert" aria-live="assertive" aria-atomic="true">
  <div class="d-flex">
    <div class="toast-body">
      Copied!
    </div>
  </div>
</div>

---
Primary Category: cs.CL  
Categories: cs-CL, cs-SD, cs.CL, eess-AS  
Keyword Score: 20  
Keywords: Automatic Speech Recognition, Automatic Speech Recognition  
<a type="button" class="btn btn-outline-primary" href="http://arxiv.org/abs/2402.06592v1" target="_blank" >Paper Link</a>
<button type="button" class="btn btn-outline-primary download-pdf" url="https://arxiv.org/pdf/2402.06592v1.pdf" filename="2402.06592v1.pdf">Download PDF</button>

---


**ABSTRACT**  
We propose a novel neural network architecture based on conformer transducer that adds contextual information flow to the <b>ASR</b> systems. Our method improves the accuracy of recognizing uncommon words while not harming the word error rate of regular words. We explore the uncommon words accuracy improvement when we use the new model and/or shallow fusion with context language model. We found that combination of both provides cumulative gain in uncommon words recognition accuracy.

{{</citation>}}


### (21/145) A Unified Causal View of Instruction Tuning (Lu Chen et al., 2024)

{{<citation>}}

Lu Chen, Wei Huang, Ruqing Zhang, Wei Chen, Jiafeng Guo, Xueqi Cheng. (2024)  
**A Unified Causal View of Instruction Tuning**
<br/>
<button class="copy-to-clipboard" title="A Unified Causal View of Instruction Tuning" index=21>
  <span class="copy-to-clipboard-item">Copy Title<span>
</button>
<div class="toast toast-copied toast-index-21 align-items-center text-bg-secondary border-0 position-absolute top-0 end-0" role="alert" aria-live="assertive" aria-atomic="true">
  <div class="d-flex">
    <div class="toast-body">
      Copied!
    </div>
  </div>
</div>

---
Primary Category: cs.CL  
Categories: cs-CL, cs.CL  
Keyword Score: 20  
Keywords: Zero-shot, Instruction Tuning  
<a type="button" class="btn btn-outline-primary" href="http://arxiv.org/abs/2402.06220v1" target="_blank" >Paper Link</a>
<button type="button" class="btn btn-outline-primary download-pdf" url="https://arxiv.org/pdf/2402.06220v1.pdf" filename="2402.06220v1.pdf">Download PDF</button>

---


**ABSTRACT**  
<b>Instruction</b> <b>tuning</b> on a mixture of tasks has improved <b>zero-shot</b> capabilities in natural language processing (NLP). Nevertheless, existing methods often learn features that exhibit correlations between <b>instruction-formatted</b> <b>samples</b> and target labels, rather than causal relationships. Termed as ``spurious correlation'' in statistics, such a correlation may change drastically in a new task, making the effect from the learned features to be misleading. To this end, we develop a meta Structural Causal Model (meta-SCM) to integrate different NLP tasks under a single causal structure of the data. Specifically, the meta-SCM introduces multiple latent factors that represent properties of source context, only some of which causally influence the target labels for a specific task. The key idea is to learn task-required causal factors and only use those to make predictions for a given task. Theoretically, we prove the causal factor can be identified without mixing information from others. Guided by the identifiability, we propose a Structural <b>Instruction</b> <b>Tuning</b> (SIT) method to learn the task-required causal representations that can mimic the causal factors for each task. The utility of our approach is verified by improvements of <b>zero-shot</b> ability on a range of unseen datasets and tasks.

{{</citation>}}


### (22/145) TIC: Translate-Infer-Compile for accurate 'text to plan' using LLMs and logical intermediate representations (Sudhir Agarwal et al., 2024)

{{<citation>}}

Sudhir Agarwal, Anu Sreepathy. (2024)  
**TIC: Translate-Infer-Compile for accurate 'text to plan' using LLMs and logical intermediate representations**
<br/>
<button class="copy-to-clipboard" title="TIC: Translate-Infer-Compile for accurate 'text to plan' using LLMs and logical intermediate representations" index=22>
  <span class="copy-to-clipboard-item">Copy Title<span>
</button>
<div class="toast toast-copied toast-index-22 align-items-center text-bg-secondary border-0 position-absolute top-0 end-0" role="alert" aria-live="assertive" aria-atomic="true">
  <div class="d-flex">
    <div class="toast-body">
      Copied!
    </div>
  </div>
</div>

---
Primary Category: cs.CL  
Categories: cs-AI, cs-CL, cs.CL  
Keyword Score: 10  
Keywords: Large Language Model  
<a type="button" class="btn btn-outline-primary" href="http://arxiv.org/abs/2402.06608v1" target="_blank" >Paper Link</a>
<button type="button" class="btn btn-outline-primary download-pdf" url="https://arxiv.org/pdf/2402.06608v1.pdf" filename="2402.06608v1.pdf">Download PDF</button>

---


**ABSTRACT**  
We study the problem of generating plans for given natural language planning task requests. On one hand, <b>LLMs</b> excel at natural language processing but do not perform well on planning. On the other hand, classical planning tools excel at planning tasks but require input in a structured language such as the Planning Domain Definition Language (PDDL). We leverage the strengths of both the techniques by using an <b>LLM</b> for generating the PDDL representation (task PDDL) of planning task requests followed by using a classical planner for computing a plan. Unlike previous approaches that use <b>LLMs</b> for generating task PDDLs directly, our approach comprises of (a) translate: using an <b>LLM</b> only for generating a logically interpretable intermediate representation of natural language task descriptions, (b) infer: deriving additional logically dependent information from the intermediate representation using a logic reasoner (currently, Answer Set Programming solver), and (c) compile: generating the target task PDDL from the base and inferred information. We observe that using an <b>LLM</b> to only output the intermediate representation significantly reduces <b>LLM</b> errors. Consequently, TIC approach achieves, for at least one <b>LLM,</b> high accuracy on task PDDL generation for all seven domains of our evaluation dataset.

{{</citation>}}


### (23/145) Asking the Right Question at the Right Time: Human and Model Uncertainty Guidance to Ask Clarification Questions (Alberto Testoni et al., 2024)

{{<citation>}}

Alberto Testoni, Raquel FernÃ¡ndez. (2024)  
**Asking the Right Question at the Right Time: Human and Model Uncertainty Guidance to Ask Clarification Questions**
<br/>
<button class="copy-to-clipboard" title="Asking the Right Question at the Right Time: Human and Model Uncertainty Guidance to Ask Clarification Questions" index=23>
  <span class="copy-to-clipboard-item">Copy Title<span>
</button>
<div class="toast toast-copied toast-index-23 align-items-center text-bg-secondary border-0 position-absolute top-0 end-0" role="alert" aria-live="assertive" aria-atomic="true">
  <div class="d-flex">
    <div class="toast-body">
      Copied!
    </div>
  </div>
</div>

---
Primary Category: cs.CL  
Categories: cs-AI, cs-CL, cs.CL  
Keyword Score: 10  
Keywords: Dialogue System  
<a type="button" class="btn btn-outline-primary" href="http://arxiv.org/abs/2402.06509v1" target="_blank" >Paper Link</a>
<button type="button" class="btn btn-outline-primary download-pdf" url="https://arxiv.org/pdf/2402.06509v1.pdf" filename="2402.06509v1.pdf">Download PDF</button>

---


**ABSTRACT**  
Clarification questions are an essential <b>dialogue</b> <b>tool</b> to signal misunderstanding, ambiguities, and under-specification in language use. While humans are able to resolve uncertainty by asking questions since childhood, modern <b>dialogue</b> <b>systems</b> struggle to generate effective questions. To make progress in this direction, in this work we take a collaborative <b>dialogue</b> <b>task</b> as a testbed and study how model uncertainty relates to human uncertainty -- an as yet under-explored problem. We show that model uncertainty does not mirror human clarification-seeking behavior, which suggests that using human clarification questions as supervision for deciding when to ask may not be the most effective way to resolve model uncertainty. To address this issue, we propose an approach to generating clarification questions based on model uncertainty estimation, compare it to several alternatives, and show that it leads to significant improvements in terms of task success. Our findings highlight the importance of equipping <b>dialogue</b> <b>systems</b> with the ability to assess their own uncertainty and exploit in interaction.

{{</citation>}}


### (24/145) On the Efficacy of Eviction Policy for Key-Value Constrained Generative Language Model Inference (Siyu Ren et al., 2024)

{{<citation>}}

Siyu Ren, Kenny Q. Zhu. (2024)  
**On the Efficacy of Eviction Policy for Key-Value Constrained Generative Language Model Inference**
<br/>
<button class="copy-to-clipboard" title="On the Efficacy of Eviction Policy for Key-Value Constrained Generative Language Model Inference" index=24>
  <span class="copy-to-clipboard-item">Copy Title<span>
</button>
<div class="toast toast-copied toast-index-24 align-items-center text-bg-secondary border-0 position-absolute top-0 end-0" role="alert" aria-live="assertive" aria-atomic="true">
  <div class="d-flex">
    <div class="toast-body">
      Copied!
    </div>
  </div>
</div>

---
Primary Category: cs.CL  
Categories: cs-AI, cs-CL, cs.CL  
Keyword Score: 10  
Keywords: Large Language Model  
<a type="button" class="btn btn-outline-primary" href="http://arxiv.org/abs/2402.06262v1" target="_blank" >Paper Link</a>
<button type="button" class="btn btn-outline-primary download-pdf" url="https://arxiv.org/pdf/2402.06262v1.pdf" filename="2402.06262v1.pdf">Download PDF</button>

---


**ABSTRACT**  
Despite the recent success associated with Large Language Models~(LLMs), they are notably cost-prohibitive to deploy in resource-constrained environments due to their excessive memory and computational demands. In addition to model parameters, the key-value cache is also stored in GPU memory, growing linearly with batch size and sequence length. As a remedy, recent works have proposed various eviction policies for maintaining the overhead of key-value cache under a given budget. This paper embarks on the efficacy of existing eviction policies in terms of \textit{importance score calculation} and \textit{eviction scope construction}. We identify the deficiency of prior policies in these two aspects and introduce RoCo, a \underline{r}\underline{o}bust \underline{c}ache \underline{o}mission policy based on temporal attention scores and robustness measures. Extensive experimentation spanning prefilling and auto-regressive decoding stages validates the superiority of RoCo. Finally, we release EasyKV, a versatile software package dedicated to user-friendly key-value constrained generative inference. Code available at \url{https://github.com/DRSY/EasyKV}.

{{</citation>}}


## cs.IR (4)



### (25/145) ExaRanker-Open: Synthetic Explanation for IR using Open-Source LLMs (Fernando Ferraretto et al., 2024)

{{<citation>}}

Fernando Ferraretto, Thiago Laitz, Roberto Lotufo, Rodrigo Nogueira. (2024)  
**ExaRanker-Open: Synthetic Explanation for IR using Open-Source LLMs**
<br/>
<button class="copy-to-clipboard" title="ExaRanker-Open: Synthetic Explanation for IR using Open-Source LLMs" index=25>
  <span class="copy-to-clipboard-item">Copy Title<span>
</button>
<div class="toast toast-copied toast-index-25 align-items-center text-bg-secondary border-0 position-absolute top-0 end-0" role="alert" aria-live="assertive" aria-atomic="true">
  <div class="d-flex">
    <div class="toast-body">
      Copied!
    </div>
  </div>
</div>

---
Primary Category: cs.IR  
Categories: cs-AI, cs-CL, cs-IR, cs.IR  
Keyword Score: 70  
Keywords: Data Augmentation, GPT, GPT-3, GPT-3.5, Information Retrieval, Natural Language Explanation, Large Language Model  
<a type="button" class="btn btn-outline-primary" href="http://arxiv.org/abs/2402.06334v1" target="_blank" >Paper Link</a>
<button type="button" class="btn btn-outline-primary download-pdf" url="https://arxiv.org/pdf/2402.06334v1.pdf" filename="2402.06334v1.pdf">Download PDF</button>

---


**ABSTRACT**  
ExaRanker recently introduced an approach to training <b>information</b> <b>retrieval</b> (IR) models, incorporating <b>natural</b> <b>language</b> <b>explanations</b> as additional labels. The method addresses the challenge of limited labeled examples, leading to improvements in the effectiveness of IR models. However, the initial results were based on proprietary language models such as <b>GPT-3.5,</b> which posed constraints on dataset size due to its cost and <b>data</b> <b>privacy.</b> In this paper, we introduce ExaRanker-Open, where we adapt and explore the use of open-source language models to generate explanations. The method has been tested using different <b>LLMs</b> and datasets sizes to better comprehend the effective contribution of <b>data</b> <b>augmentation.</b> Our findings reveal that incorporating explanations consistently enhances neural rankers, with benefits escalating as the <b>LLM</b> size increases. Notably, the <b>data</b> <b>augmentation</b> method proves advantageous even with large datasets, as evidenced by ExaRanker surpassing the target baseline by 0.6 nDCG@10 points in our study. To encourage further advancements by the research community, we have open-sourced both the code and datasets at https://github.com/unicamp-dl/ExaRanker.

{{</citation>}}


### (26/145) Fairly Evaluating Large Language Model-based Recommendation Needs Revisit the Cross-Entropy Loss (Cong Xu et al., 2024)

{{<citation>}}

Cong Xu, Zhangchi Zhu, Jun Wang, Jianyong Wang, Wei Zhang. (2024)  
**Fairly Evaluating Large Language Model-based Recommendation Needs Revisit the Cross-Entropy Loss**
<br/>
<button class="copy-to-clipboard" title="Fairly Evaluating Large Language Model-based Recommendation Needs Revisit the Cross-Entropy Loss" index=26>
  <span class="copy-to-clipboard-item">Copy Title<span>
</button>
<div class="toast toast-copied toast-index-26 align-items-center text-bg-secondary border-0 position-absolute top-0 end-0" role="alert" aria-live="assertive" aria-atomic="true">
  <div class="d-flex">
    <div class="toast-body">
      Copied!
    </div>
  </div>
</div>

---
Primary Category: cs.IR  
Categories: cs-IR, cs.IR  
Keyword Score: 40  
Keywords: Fine-tuning, Recommendation, Large Language Model, Large Language Model  
<a type="button" class="btn btn-outline-primary" href="http://arxiv.org/abs/2402.06216v1" target="_blank" >Paper Link</a>
<button type="button" class="btn btn-outline-primary download-pdf" url="https://arxiv.org/pdf/2402.06216v1.pdf" filename="2402.06216v1.pdf">Download PDF</button>

---


**ABSTRACT**  
<b>Large</b> <b>language</b> <b>models</b> <b>(LLMs)</b> have gained much attention in the <b>recommendation</b> community; some studies have observed that <b>LLMs,</b> <b>fine-tuned</b> by the cross-entropy loss with a full softmax, could achieve state-of-the-art performance already. However, these claims are drawn from unobjective and unfair comparisons. In view of the substantial quantity of items in reality, conventional recommenders typically adopt a pointwise/pairwise loss function instead for training. This substitute however causes severe performance degradation, leading to under-estimation of conventional methods and over-confidence in the ranking capability of <b>LLMs.</b> In this work, we theoretically justify the superiority of cross-entropy, and showcase that it can be adequately replaced by some elementary approximations with certain necessary modifications. The remarkable results across three public datasets corroborate that even in a practical sense, existing <b>LLM-based</b> methods are not as effective as claimed for next-item <b>recommendation.</b> We hope that these theoretical understandings in conjunction with the empirical results will facilitate an objective evaluation of <b>LLM-based</b> <b>recommendation</b> in the future.

{{</citation>}}


### (27/145) CoSearchAgent: A Lightweight Collaborative Search Agent with Large Language Models (Peiyuan Gong et al., 2024)

{{<citation>}}

Peiyuan Gong, Jiamian Li, Jiaxin Mao. (2024)  
**CoSearchAgent: A Lightweight Collaborative Search Agent with Large Language Models**
<br/>
<button class="copy-to-clipboard" title="CoSearchAgent: A Lightweight Collaborative Search Agent with Large Language Models" index=27>
  <span class="copy-to-clipboard-item">Copy Title<span>
</button>
<div class="toast toast-copied toast-index-27 align-items-center text-bg-secondary border-0 position-absolute top-0 end-0" role="alert" aria-live="assertive" aria-atomic="true">
  <div class="d-flex">
    <div class="toast-body">
      Copied!
    </div>
  </div>
</div>

---
Primary Category: cs.IR  
Categories: cs-AI, cs-CL, cs-IR, cs.IR  
Keyword Score: 20  
Keywords: Large Language Model, Large Language Model  
<a type="button" class="btn btn-outline-primary" href="http://arxiv.org/abs/2402.06360v1" target="_blank" >Paper Link</a>
<button type="button" class="btn btn-outline-primary download-pdf" url="https://arxiv.org/pdf/2402.06360v1.pdf" filename="2402.06360v1.pdf">Download PDF</button>

---


**ABSTRACT**  
Collaborative search supports multiple users working together to accomplish a specific search task. Research has found that designing lightweight collaborative search plugins within instant messaging platforms aligns better with users' collaborative habits. However, due to the complexity of multi-user interaction scenarios, it is challenging to implement a fully functioning lightweight collaborative search system. Therefore, previous studies on lightweight collaborative search had to rely on the Wizard of Oz paradigm. In recent years, <b>large</b> <b>language</b> <b>models</b> <b>(LLMs)</b> have been demonstrated to interact naturally with users and achieve complex information-seeking tasks through <b>LLM-based</b> agents. Hence, to better support the research in collaborative search, in this demo, we propose CoSearchAgent, a lightweight collaborative search agent powered by <b>LLMs.</b> CoSearchAgent is designed as a Slack plugin that can support collaborative search during multi-party conversations on this platform. Equipped with the capacity to understand the queries and context in multi-user conversations and the ability to search the Web for relevant information via APIs, CoSearchAgent can respond to user queries with answers grounded on the relevant search results. It can also ask clarifying questions when the information needs are unclear. The proposed CoSearchAgent is highly flexible and would be useful for supporting further research on collaborative search. The code and demo video are accessible.

{{</citation>}}


### (28/145) Collaborative filtering, K-nearest neighbor and cosine similarity in home decor recommender systems (Nanna Bach Munkholm et al., 2024)

{{<citation>}}

Nanna Bach Munkholm, Robert Alphinas, Torben Tambo. (2024)  
**Collaborative filtering, K-nearest neighbor and cosine similarity in home decor recommender systems**
<br/>
<button class="copy-to-clipboard" title="Collaborative filtering, K-nearest neighbor and cosine similarity in home decor recommender systems" index=28>
  <span class="copy-to-clipboard-item">Copy Title<span>
</button>
<div class="toast toast-copied toast-index-28 align-items-center text-bg-secondary border-0 position-absolute top-0 end-0" role="alert" aria-live="assertive" aria-atomic="true">
  <div class="d-flex">
    <div class="toast-body">
      Copied!
    </div>
  </div>
</div>

---
Primary Category: cs.IR  
Categories: cs-IR, cs-SI, cs.IR  
Keyword Score: 10  
Keywords: Recommender System  
<a type="button" class="btn btn-outline-primary" href="http://arxiv.org/abs/2402.06233v1" target="_blank" >Paper Link</a>
<button type="button" class="btn btn-outline-primary download-pdf" url="https://arxiv.org/pdf/2402.06233v1.pdf" filename="2402.06233v1.pdf">Download PDF</button>

---


**ABSTRACT**  
An architectural framework, based on collaborative filtering using K-nearest neighbor and cosine similarity, was developed and implemented to fit the requirements for the company DecorRaid. The aim of the paper is to test different evaluation techniques within the environment to research the <b>recommender</b> <b>systems</b> performance. Three perspectives were found relevant for evaluating a <b>recommender</b> <b>system</b> in the specific environment, namely dataset, system and user perspective. With these perspectives it was possible to gain a broader view of the <b>recommender</b> <b>systems</b> performance. Online A/B split testing was conducted to compare the performance of small adjustments to the RS and to test the relevance of the evaluation techniques. Key factors are solving the sparsity and cold start problem, where the suggestion is to research a hybrid RS combining Content-based and CF based techniques.

{{</citation>}}


## cs.CV (30)



### (29/145) On the Out-Of-Distribution Generalization of Multimodal Large Language Models (Xingxuan Zhang et al., 2024)

{{<citation>}}

Xingxuan Zhang, Jiansheng Li, Wenjing Chu, Junjia Hai, Renzhe Xu, Yuqing Yang, Shikai Guan, Jiazheng Xu, Peng Cui. (2024)  
**On the Out-Of-Distribution Generalization of Multimodal Large Language Models**
<br/>
<button class="copy-to-clipboard" title="On the Out-Of-Distribution Generalization of Multimodal Large Language Models" index=29>
  <span class="copy-to-clipboard-item">Copy Title<span>
</button>
<div class="toast toast-copied toast-index-29 align-items-center text-bg-secondary border-0 position-absolute top-0 end-0" role="alert" aria-live="assertive" aria-atomic="true">
  <div class="d-flex">
    <div class="toast-body">
      Copied!
    </div>
  </div>
</div>

---
Primary Category: cs.CV  
Categories: cs-AI, cs-CV, cs.CV  
Keyword Score: 60  
Keywords: Out-of-distribution, Zero-shot, In-context Learning, In-context Learning, In-context Learning, Large Language Model  
<a type="button" class="btn btn-outline-primary" href="http://arxiv.org/abs/2402.06599v1" target="_blank" >Paper Link</a>
<button type="button" class="btn btn-outline-primary download-pdf" url="https://arxiv.org/pdf/2402.06599v1.pdf" filename="2402.06599v1.pdf">Download PDF</button>

---


**ABSTRACT**  
We investigate the generalization boundaries of current Multimodal <b>Large</b> <b>Language</b> <b>Models</b> (MLLMs) via comprehensive evaluation under <b>out-of-distribution</b> scenarios and domain-specific tasks. We evaluate their <b>zero-shot</b> generalization across synthetic images, real-world distributional shifts, and specialized datasets like medical and molecular imagery. Empirical results indicate that MLLMs struggle with generalization beyond common training domains, limiting their direct application without adaptation. To understand the cause of unreliable performance, we analyze three hypotheses: semantic misinterpretation, visual feature extraction insufficiency, and mapping deficiency. Results identify mapping deficiency as the primary hurdle. To address this problem, we show that <b>in-context</b> <b>learning</b> <b>(ICL)</b> can significantly enhance MLLMs' generalization, opening new avenues for overcoming generalization barriers. We further explore the robustness of <b>ICL</b> under distribution shifts and show its vulnerability to domain shifts, label shifts, and spurious correlation shifts between <b>in-context</b> <b>examples</b> and test data.

{{</citation>}}


### (30/145) BarlowTwins-CXR : Enhancing Chest X-Ray abnormality localization in heterogeneous data with cross-domain self-supervised learning (Haoyue Sheng et al., 2024)

{{<citation>}}

Haoyue Sheng, Linrui Ma, Jean-Francois Samson, Dianbo Liu. (2024)  
**BarlowTwins-CXR : Enhancing Chest X-Ray abnormality localization in heterogeneous data with cross-domain self-supervised learning**
<br/>
<button class="copy-to-clipboard" title="BarlowTwins-CXR : Enhancing Chest X-Ray abnormality localization in heterogeneous data with cross-domain self-supervised learning" index=30>
  <span class="copy-to-clipboard-item">Copy Title<span>
</button>
<div class="toast toast-copied toast-index-30 align-items-center text-bg-secondary border-0 position-absolute top-0 end-0" role="alert" aria-live="assertive" aria-atomic="true">
  <div class="d-flex">
    <div class="toast-body">
      Copied!
    </div>
  </div>
</div>

---
Primary Category: cs.CV  
Categories: I-2-1; J-3; I-4-9, cs-CV, cs.CV  
Keyword Score: 60  
Keywords: Fine-tuning, Self-supervised Learning, Self-supervised Learning, Self-supervised Pre-training, Supervised Learning, Transfer Learning  
<a type="button" class="btn btn-outline-primary" href="http://arxiv.org/abs/2402.06499v1" target="_blank" >Paper Link</a>
<button type="button" class="btn btn-outline-primary download-pdf" url="https://arxiv.org/pdf/2402.06499v1.pdf" filename="2402.06499v1.pdf">Download PDF</button>

---


**ABSTRACT**  
Background: Chest X-ray imaging-based abnormality localization, essential in diagnosing various diseases, faces significant clinical challenges due to complex interpretations and the growing workload of radiologists. While recent advances in deep learning offer promising solutions, there is still a critical issue of domain inconsistency in cross-domain <b>transfer</b> <b>learning,</b> which hampers the efficiency and accuracy of diagnostic processes. This study aims to address the domain inconsistency problem and improve autonomic abnormality localization performance of heterogeneous chest X-ray image analysis, by developing a <b>self-supervised</b> <b>learning</b> strategy called "BarlwoTwins-CXR". Methods: We utilized two publicly available datasets: the NIH Chest X-ray Dataset and the VinDr-CXR. The BarlowTwins-CXR approach was conducted in a two-stage training process. Initially, <b>self-supervised</b> <b>pre-training</b> was performed using an adjusted Barlow Twins algorithm on the NIH dataset with a Resnet50 backbone pre-trained on ImageNet. This was followed by <b>supervised</b> <b>fine-tuning</b> on the VinDr-CXR dataset using Faster R-CNN with Feature Pyramid Network (FPN). Results: Our experiments showed a significant improvement in model performance with BarlowTwins-CXR. The approach achieved a 3% increase in mAP50 accuracy compared to traditional ImageNet pre-trained models. In addition, the Ablation CAM method revealed enhanced precision in localizing chest abnormalities. Conclusion: BarlowTwins-CXR significantly enhances the efficiency and accuracy of chest X-ray image-based abnormality localization, outperforming traditional <b>transfer</b> <b>learning</b> methods and effectively overcoming domain inconsistency in cross-domain scenarios. Our experiment results demonstrate the potential of using <b>self-supervised</b> <b>learning</b> to improve the generalizability of models in medical settings with limited amounts of heterogeneous data.

{{</citation>}}


### (31/145) Video Annotator: A framework for efficiently building video classifiers using vision-language models and active learning (Amir Ziai et al., 2024)

{{<citation>}}

Amir Ziai, Aneesh Vartakavi. (2024)  
**Video Annotator: A framework for efficiently building video classifiers using vision-language models and active learning**
<br/>
<button class="copy-to-clipboard" title="Video Annotator: A framework for efficiently building video classifiers using vision-language models and active learning" index=31>
  <span class="copy-to-clipboard-item">Copy Title<span>
</button>
<div class="toast toast-copied toast-index-31 align-items-center text-bg-secondary border-0 position-absolute top-0 end-0" role="alert" aria-live="assertive" aria-atomic="true">
  <div class="d-flex">
    <div class="toast-body">
      Copied!
    </div>
  </div>
</div>

---
Primary Category: cs.CV  
Categories: cs-CV, cs-LG, cs.CV  
Keyword Score: 50  
Keywords: Active Learning, Foundation Model, Zero-shot, human-in-the-loop, Vision-and-Language  
<a type="button" class="btn btn-outline-primary" href="http://arxiv.org/abs/2402.06560v1" target="_blank" >Paper Link</a>
<button type="button" class="btn btn-outline-primary download-pdf" url="https://arxiv.org/pdf/2402.06560v1.pdf" filename="2402.06560v1.pdf">Download PDF</button>

---


**ABSTRACT**  
High-quality and consistent annotations are fundamental to the successful development of robust machine learning models. Traditional data annotation methods are resource-intensive and inefficient, often leading to a reliance on third-party annotators who are not the domain experts. Hard samples, which are usually the most informative for model training, tend to be difficult to label accurately and consistently without business context. These can arise unpredictably during the annotation process, requiring a variable number of iterations and rounds of feedback, leading to unforeseen expenses and time commitments to guarantee quality. We posit that more direct involvement of domain experts, using a <b>human-in-the-loop</b> system, can resolve many of these practical challenges. We propose a novel framework we call Video Annotator (VA) for annotating, managing, and iterating on video classification datasets. Our approach offers a new paradigm for an end-user-centered model development process, enhancing the efficiency, usability, and effectiveness of video classifiers. Uniquely, VA allows for a continuous annotation process, seamlessly integrating data collection and model training. We leverage the <b>zero-shot</b> capabilities of <b>vision-language</b> <b>foundation</b> <b>models</b> combined with <b>active</b> <b>learning</b> techniques, and demonstrate that VA enables the efficient creation of high-quality models. VA achieves a median 6.8 point improvement in Average Precision relative to the most competitive baseline across a wide-ranging assortment of tasks. We release a dataset with 153k labels across 56 video understanding tasks annotated by three professional video editors using VA, and also release code to replicate our experiments at: http://github.com/netflix/videoannotator.

{{</citation>}}


### (32/145) Masked LoGoNet: Fast and Accurate 3D Image Analysis for Medical Domain (Amin Karimi Monsefi et al., 2024)

{{<citation>}}

Amin Karimi Monsefi, Payam Karisani, Mengxi Zhou, Stacey Choi, Nathan Doble, Heng Ji, Srinivasan Parthasarathy, Rajiv Ramnath. (2024)  
**Masked LoGoNet: Fast and Accurate 3D Image Analysis for Medical Domain**
<br/>
<button class="copy-to-clipboard" title="Masked LoGoNet: Fast and Accurate 3D Image Analysis for Medical Domain" index=32>
  <span class="copy-to-clipboard-item">Copy Title<span>
</button>
<div class="toast toast-copied toast-index-32 align-items-center text-bg-secondary border-0 position-absolute top-0 end-0" role="alert" aria-live="assertive" aria-atomic="true">
  <div class="d-flex">
    <div class="toast-body">
      Copied!
    </div>
  </div>
</div>

---
Primary Category: cs.CV  
Categories: cs-CV, cs-LG, cs.CV  
Keyword Score: 50  
Keywords: Contrastive Learning, Convolutional Neural Network, Self-supervised Learning, Self-supervised Learning, Transformer  
<a type="button" class="btn btn-outline-primary" href="http://arxiv.org/abs/2402.06190v1" target="_blank" >Paper Link</a>
<button type="button" class="btn btn-outline-primary download-pdf" url="https://arxiv.org/pdf/2402.06190v1.pdf" filename="2402.06190v1.pdf">Download PDF</button>

---


**ABSTRACT**  
Standard modern machine-learning-based imaging methods have faced challenges in medical applications due to the high cost of dataset construction and, thereby, the limited labeled training data available. Additionally, upon deployment, these methods are usually used to process a large volume of data on a daily basis, imposing a high maintenance cost on medical facilities. In this paper, we introduce a new neural network architecture, termed LoGoNet, with a tailored <b>self-supervised</b> <b>learning</b> (SSL) method to mitigate such challenges. LoGoNet integrates a novel feature extractor within a U-shaped architecture, leveraging Large Kernel Attention (LKA) and a dual encoding strategy to capture both long-range and short-range feature dependencies adeptly. This is in contrast to existing methods that rely on increasing network capacity to enhance feature extraction. This combination of novel techniques in our model is especially beneficial in medical image segmentation, given the difficulty of learning intricate and often irregular body organ shapes, such as the spleen. Complementary, we propose a novel SSL method tailored for 3D images to compensate for the lack of large labeled datasets. The method combines masking and <b>contrastive</b> <b>learning</b> techniques within a multi-task learning framework and is compatible with both Vision <b>Transformer</b> (ViT) and <b>CNN-based</b> models. We demonstrate the efficacy of our methods in numerous tasks across two standard datasets (i.e., BTCV and MSD). Benchmark comparisons with eight state-of-the-art models highlight LoGoNet's superior performance in both inference time and accuracy.

{{</citation>}}


### (33/145) A self-supervised framework for learning whole slide representations (Xinhai Hou et al., 2024)

{{<citation>}}

Xinhai Hou, Cheng Jiang, Akhil Kondepudi, Yiwei Lyu, Asadur Zaman Chowdury, Honglak Lee, Todd C. Hollon. (2024)  
**A self-supervised framework for learning whole slide representations**
<br/>
<button class="copy-to-clipboard" title="A self-supervised framework for learning whole slide representations" index=33>
  <span class="copy-to-clipboard-item">Copy Title<span>
</button>
<div class="toast toast-copied toast-index-33 align-items-center text-bg-secondary border-0 position-absolute top-0 end-0" role="alert" aria-live="assertive" aria-atomic="true">
  <div class="d-flex">
    <div class="toast-body">
      Copied!
    </div>
  </div>
</div>

---
Primary Category: cs.CV  
Categories: cs-AI, cs-CV, cs-LG, cs.CV  
Keyword Score: 50  
Keywords: Out-of-distribution, Self-supervised Learning, Supervised Learning, Transformer, Vision-and-Language  
<a type="button" class="btn btn-outline-primary" href="http://arxiv.org/abs/2402.06188v1" target="_blank" >Paper Link</a>
<button type="button" class="btn btn-outline-primary download-pdf" url="https://arxiv.org/pdf/2402.06188v1.pdf" filename="2402.06188v1.pdf">Download PDF</button>

---


**ABSTRACT**  
Whole slide imaging is fundamental to biomedical microscopy and computational pathology. However, whole slide images (WSIs) present a complex computer vision challenge due to their gigapixel size, diverse histopathologic features, spatial heterogeneity, and limited/absent data annotations. These challenges highlight that <b>supervised</b> training alone can result in suboptimal whole slide representations. <b>Self-supervised</b> representation learning can achieve high-quality WSI visual feature learning for downstream diagnostic tasks, such as cancer diagnosis or molecular genetic prediction. Here, we present a general <b>self-supervised</b> whole slide learning (S3L) framework for gigapixel-scale self-supervision of WSIs. S3L combines data transformation strategies from <b>transformer-based</b> vision and language modeling into a single unified framework to generate paired views for self-supervision. S3L leverages the inherent regional heterogeneity, histologic feature variability, and information redundancy within WSIs to learn high-quality whole-slide representations. We benchmark S3L visual representations on two diagnostic tasks for two biomedical microscopy modalities. S3L significantly outperforms WSI baselines for cancer diagnosis and genetic mutation prediction. Additionally, S3L achieves good performance using both in-domain and <b>out-of-distribution</b> patch encoders, demonstrating good flexibility and generalizability.

{{</citation>}}


### (34/145) ViGoR: Improving Visual Grounding of Large Vision Language Models with Fine-Grained Reward Modeling (Siming Yan et al., 2024)

{{<citation>}}

Siming Yan, Min Bai, Weifeng Chen, Xiong Zhou, Qixing Huang, Li Erran Li. (2024)  
**ViGoR: Improving Visual Grounding of Large Vision Language Models with Fine-Grained Reward Modeling**
<br/>
<button class="copy-to-clipboard" title="ViGoR: Improving Visual Grounding of Large Vision Language Models with Fine-Grained Reward Modeling" index=34>
  <span class="copy-to-clipboard-item">Copy Title<span>
</button>
<div class="toast toast-copied toast-index-34 align-items-center text-bg-secondary border-0 position-absolute top-0 end-0" role="alert" aria-live="assertive" aria-atomic="true">
  <div class="d-flex">
    <div class="toast-body">
      Copied!
    </div>
  </div>
</div>

---
Primary Category: cs.CV  
Categories: cs-AI, cs-CV, cs.CV  
Keyword Score: 50  
Keywords: Grounding, Natural Language Understanding, Reasoning, Large Language Model, Vision-and-Language  
<a type="button" class="btn btn-outline-primary" href="http://arxiv.org/abs/2402.06118v1" target="_blank" >Paper Link</a>
<button type="button" class="btn btn-outline-primary download-pdf" url="https://arxiv.org/pdf/2402.06118v1.pdf" filename="2402.06118v1.pdf">Download PDF</button>

---


**ABSTRACT**  
By combining <b>natural</b> <b>language</b> <b>understanding</b> and the generation capabilities and breadth of knowledge of <b>large</b> <b>language</b> <b>models</b> with image perception, recent <b>large</b> <b>vision</b> <b>language</b> models (LVLMs) have shown unprecedented <b>reasoning</b> capabilities in the real world. However, the generated text often suffers from inaccurate <b>grounding</b> in the visual input, resulting in errors such as hallucinating nonexistent scene elements, missing significant parts of the scene, and inferring incorrect attributes and relationships between objects. To address these issues, we introduce a novel framework, ViGoR (Visual <b>Grounding</b> Through Fine-Grained Reward Modeling) that utilizes fine-grained reward modeling to significantly enhance the visual <b>grounding</b> of LVLMs over pre-trained baselines. This improvement is efficiently achieved using much cheaper human evaluations instead of full supervisions, as well as automated methods. We show the effectiveness of our approach through numerous metrics on several benchmarks. Additionally, we construct a comprehensive and challenging dataset specifically designed to validate the visual <b>grounding</b> capabilities of LVLMs. Finally, we plan to release our human annotation comprising approximately 16,000 images and generated text pairs with fine-grained evaluations to contribute to related research in the community.

{{</citation>}}


### (35/145) ControlUDA: Controllable Diffusion-assisted Unsupervised Domain Adaptation for Cross-Weather Semantic Segmentation (Fengyi Shen et al., 2024)

{{<citation>}}

Fengyi Shen, Li Zhou, Kagan Kucukaytekin, Ziyuan Liu, He Wang, Alois Knoll. (2024)  
**ControlUDA: Controllable Diffusion-assisted Unsupervised Domain Adaptation for Cross-Weather Semantic Segmentation**
<br/>
<button class="copy-to-clipboard" title="ControlUDA: Controllable Diffusion-assisted Unsupervised Domain Adaptation for Cross-Weather Semantic Segmentation" index=35>
  <span class="copy-to-clipboard-item">Copy Title<span>
</button>
<div class="toast toast-copied toast-index-35 align-items-center text-bg-secondary border-0 position-absolute top-0 end-0" role="alert" aria-live="assertive" aria-atomic="true">
  <div class="d-flex">
    <div class="toast-body">
      Copied!
    </div>
  </div>
</div>

---
Primary Category: cs.CV  
Categories: cs-CV, cs.CV  
Keyword Score: 40  
Keywords: Unsupervised Learning, Text2image, Domain Adaptation, Prompt  
<a type="button" class="btn btn-outline-primary" href="http://arxiv.org/abs/2402.06446v1" target="_blank" >Paper Link</a>
<button type="button" class="btn btn-outline-primary download-pdf" url="https://arxiv.org/pdf/2402.06446v1.pdf" filename="2402.06446v1.pdf">Download PDF</button>

---


**ABSTRACT**  
Data generation is recognized as a potent strategy for <b>unsupervised</b> <b>domain</b> <b>adaptation</b> (UDA) pertaining semantic segmentation in adverse weathers. Nevertheless, these adverse weather scenarios encompass multiple possibilities, and high-fidelity data synthesis with controllable weather is under-researched in previous UDA works. The recent strides in large-scale <b>text-to-image</b> diffusion models (DM) have ushered in a novel avenue for research, enabling the generation of realistic images conditioned on semantic labels. This capability proves instrumental for cross-domain data synthesis from source to target <b>domain</b> <b>owing</b> to their shared label space. Thus, source <b>domain</b> <b>labels</b> can be paired with those generated pseudo target data for training UDA. However, from the UDA perspective, there exists several challenges for DM training: (i) ground-truth labels from target <b>domain</b> <b>are</b> missing; (ii) the <b>prompt</b> generator may produce vague or noisy descriptions of images from adverse weathers; (iii) existing arts often struggle to well handle the complex scene structure and geometry of urban scenes when conditioned only on semantic labels. To tackle the above issues, we propose ControlUDA, a diffusion-assisted framework tailored for UDA segmentation under adverse weather conditions. It first leverages target prior from a pre-trained segmentor for tuning the DM, compensating the missing target <b>domain</b> <b>labels;</b> It also contains UDAControlNet, a condition-fused multi-scale and <b>prompt-enhanced</b> network targeted at high-fidelity data generation in adverse weathers. Training UDA with our generated data brings the model performances to a new milestone (72.0 mIoU) on the popular Cityscapes-to-ACDC benchmark for adverse weathers. Furthermore, ControlUDA helps to achieve good model generalizability on unseen data.

{{</citation>}}


### (36/145) Multi-source-free Domain Adaptation via Uncertainty-aware Adaptive Distillation (Yaxuan Song et al., 2024)

{{<citation>}}

Yaxuan Song, Jianan Fan, Dongnan Liu, Weidong Cai. (2024)  
**Multi-source-free Domain Adaptation via Uncertainty-aware Adaptive Distillation**
<br/>
<button class="copy-to-clipboard" title="Multi-source-free Domain Adaptation via Uncertainty-aware Adaptive Distillation" index=36>
  <span class="copy-to-clipboard-item">Copy Title<span>
</button>
<div class="toast toast-copied toast-index-36 align-items-center text-bg-secondary border-0 position-absolute top-0 end-0" role="alert" aria-live="assertive" aria-atomic="true">
  <div class="d-flex">
    <div class="toast-body">
      Copied!
    </div>
  </div>
</div>

---
Primary Category: cs.CV  
Categories: cs-CV, cs.CV  
Keyword Score: 40  
Keywords: Knowledge Distillation, Knowledge Distillation, Unsupervised Learning, Domain Adaptation  
<a type="button" class="btn btn-outline-primary" href="http://arxiv.org/abs/2402.06213v1" target="_blank" >Paper Link</a>
<button type="button" class="btn btn-outline-primary download-pdf" url="https://arxiv.org/pdf/2402.06213v1.pdf" filename="2402.06213v1.pdf">Download PDF</button>

---


**ABSTRACT**  
Source-free <b>domain</b> <b>adaptation</b> (SFDA) alleviates the <b>domain</b> <b>discrepancy</b> among data obtained from <b>domains</b> <b>without</b> accessing the data for the awareness of data privacy. However, existing conventional SFDA methods face inherent limitations in medical contexts, where medical data are typically collected from multiple institutions using various equipment. To address this problem, we propose a simple yet effective method, named Uncertainty-aware Adaptive <b>Distillation</b> (UAD) for the multi-source-free <b>unsupervised</b> <b>domain</b> <b>adaptation</b> (MSFDA) setting. UAD aims to perform well-calibrated <b>knowledge</b> <b>distillation</b> from (i) model level to deliver coordinated and reliable base model initialisation and (ii) instance level via model adaptation guided by high-quality pseudo-labels, thereby obtaining a high-performance target <b>domain</b> <b>model.</b> To verify its general applicability, we evaluate UAD on two image-based diagnosis benchmarks among two multi-centre datasets, where our method shows a significant performance gain compared with existing works. The code will be available soon.

{{</citation>}}


### (37/145) Image-based Deep Learning for the time-dependent prediction of fresh concrete properties (Max Meyer et al., 2024)

{{<citation>}}

Max Meyer, Amadeus Langer, Max Mehltretter, Dries Beyer, Max Coenen, Tobias Schack, Michael Haist, Christian Heipke. (2024)  
**Image-based Deep Learning for the time-dependent prediction of fresh concrete properties**
<br/>
<button class="copy-to-clipboard" title="Image-based Deep Learning for the time-dependent prediction of fresh concrete properties" index=37>
  <span class="copy-to-clipboard-item">Copy Title<span>
</button>
<div class="toast toast-copied toast-index-37 align-items-center text-bg-secondary border-0 position-absolute top-0 end-0" role="alert" aria-live="assertive" aria-atomic="true">
  <div class="d-flex">
    <div class="toast-body">
      Copied!
    </div>
  </div>
</div>

---
Primary Category: cs.CV  
Categories: cs-CV, cs.CV, eess-IV  
Keyword Score: 30  
Keywords: Convolution, Convolutional Neural Network, Convolutional Neural Network  
<a type="button" class="btn btn-outline-primary" href="http://arxiv.org/abs/2402.06611v1" target="_blank" >Paper Link</a>
<button type="button" class="btn btn-outline-primary download-pdf" url="https://arxiv.org/pdf/2402.06611v1.pdf" filename="2402.06611v1.pdf">Download PDF</button>

---


**ABSTRACT**  
Increasing the degree of digitisation and automation in the concrete production process can play a crucial role in reducing the CO$_2$ emissions that are associated with the production of concrete. In this paper, a method is presented that makes it possible to predict the properties of fresh concrete during the mixing process based on stereoscopic image sequences of the concretes flow behaviour. A <b>Convolutional</b> <b>Neural</b> <b>Network</b> <b>(CNN)</b> is used for the prediction, which receives the images supported by information on the mix design as input. In addition, the network receives temporal information in the form of the time difference between the time at which the images are taken and the time at which the reference values of the concretes are carried out. With this temporal information, the network implicitly learns the time-dependent behaviour of the concretes properties. The network predicts the slump flow diameter, the yield stress and the plastic viscosity. The time-dependent prediction potentially opens up the pathway to determine the temporal development of the fresh concrete properties already during mixing. This provides a huge advantage for the concrete industry. As a result, countermeasures can be taken in a timely manner. It is shown that an approach based on depth and optical flow images, supported by information of the mix design, achieves the best results.

{{</citation>}}


### (38/145) Large Language Models for Captioning and Retrieving Remote Sensing Images (JoÃ£o Daniel Silva et al., 2024)

{{<citation>}}

JoÃ£o Daniel Silva, JoÃ£o MagalhÃ£es, Devis Tuia, Bruno Martins. (2024)  
**Large Language Models for Captioning and Retrieving Remote Sensing Images**
<br/>
<button class="copy-to-clipboard" title="Large Language Models for Captioning and Retrieving Remote Sensing Images" index=38>
  <span class="copy-to-clipboard-item">Copy Title<span>
</button>
<div class="toast toast-copied toast-index-38 align-items-center text-bg-secondary border-0 position-absolute top-0 end-0" role="alert" aria-live="assertive" aria-atomic="true">
  <div class="d-flex">
    <div class="toast-body">
      Copied!
    </div>
  </div>
</div>

---
Primary Category: cs.CV  
Categories: cs-CV, cs.CV  
Keyword Score: 30  
Keywords: Text2image, Large Language Model, Vision-and-Language  
<a type="button" class="btn btn-outline-primary" href="http://arxiv.org/abs/2402.06475v1" target="_blank" >Paper Link</a>
<button type="button" class="btn btn-outline-primary download-pdf" url="https://arxiv.org/pdf/2402.06475v1.pdf" filename="2402.06475v1.pdf">Download PDF</button>

---


**ABSTRACT**  
Image captioning and cross-modal retrieval are examples of tasks that involve the joint analysis of visual and linguistic information. In connection to remote sensing imagery, these tasks can help non-expert users in extracting relevant Earth observation information for a variety of applications. Still, despite some previous efforts, the development and application of vision and language models to the remote sensing domain have been hindered by the relatively small size of the available datasets and models used in previous studies. In this work, we propose RS-CapRet, a Vision and Language method for remote sensing tasks, in particular image captioning and <b>text-image</b> retrieval. We specifically propose to use a highly capable <b>large</b> <b>decoder</b> <b>language</b> model together with image encoders adapted to remote sensing imagery through contrastive language-image pre-training. To bridge together the image encoder and language decoder, we propose training simple linear layers with examples from combining different remote sensing image captioning datasets, keeping the other parameters frozen. RS-CapRet can then generate descriptions for remote sensing images and retrieve images from textual descriptions, achieving SOTA or competitive performance with existing methods. Qualitative results illustrate that RS-CapRet can effectively leverage the pre-trained <b>large</b> <b>language</b> <b>model</b> to describe remote sensing images, retrieve them based on different types of queries, and also show the ability to process interleaved sequences of images and text in a dialogue manner.

{{</citation>}}


### (39/145) Learning Contrastive Feature Representations for Facial Action Unit Detection (Ziqiao Shang et al., 2024)

{{<citation>}}

Ziqiao Shang, Bin Liu, Fei Teng, Tianrui Li. (2024)  
**Learning Contrastive Feature Representations for Facial Action Unit Detection**
<br/>
<button class="copy-to-clipboard" title="Learning Contrastive Feature Representations for Facial Action Unit Detection" index=39>
  <span class="copy-to-clipboard-item">Copy Title<span>
</button>
<div class="toast toast-copied toast-index-39 align-items-center text-bg-secondary border-0 position-absolute top-0 end-0" role="alert" aria-live="assertive" aria-atomic="true">
  <div class="d-flex">
    <div class="toast-body">
      Copied!
    </div>
  </div>
</div>

---
Primary Category: cs.CV  
Categories: cs-AI, cs-CV, cs-LG, cs.CV  
Keyword Score: 30  
Keywords: Contrastive Learning, Self-supervised Learning, Supervised Learning  
<a type="button" class="btn btn-outline-primary" href="http://arxiv.org/abs/2402.06165v1" target="_blank" >Paper Link</a>
<button type="button" class="btn btn-outline-primary download-pdf" url="https://arxiv.org/pdf/2402.06165v1.pdf" filename="2402.06165v1.pdf">Download PDF</button>

---


**ABSTRACT**  
The predominant approach to facial action unit (AU) detection revolves around a <b>supervised</b> multi-label binary classification problem. Existing methodologies often encode pixel-level information of AUs, thereby imposing substantial demands on model complexity and expressiveness. Moreover, this practice elevates the susceptibility to overfitting due to the presence of noisy AU labels. In the present study, we introduce a <b>contrastive</b> <b>learning</b> framework enhanced by both <b>supervised</b> and <b>self-supervised</b> signals. The objective is to acquire discriminative features, deviating from the conventional pixel-level learning paradigm within the domain of AU detection. To address the challenge posed by noisy AU labels, we augment the <b>supervised</b> signal through the introduction of a <b>self-supervised</b> signal. This augmentation is achieved through positive sample sampling, encompassing three distinct types of positive sample pairs. Furthermore, to mitigate the imbalanced distribution of each AU type, we employ an importance re-weighting strategy tailored for minority AUs. The resulting loss, denoted as AUNCE, is proposed to encapsulate this strategy. Our experimental assessments, conducted on two widely-utilized benchmark datasets (BP4D and DISFA), underscore the superior performance of our approach compared to state-of-the-art methods in the realm of AU detection.

{{</citation>}}


### (40/145) Multiple Instance Learning for Cheating Detection and Localization in Online Examinations (Yemeng Liu et al., 2024)

{{<citation>}}

Yemeng Liu, Jing Ren, Jianshuo Xu, Xiaomei Bai, Roopdeep Kaur, Feng Xia. (2024)  
**Multiple Instance Learning for Cheating Detection and Localization in Online Examinations**
<br/>
<button class="copy-to-clipboard" title="Multiple Instance Learning for Cheating Detection and Localization in Online Examinations" index=40>
  <span class="copy-to-clipboard-item">Copy Title<span>
</button>
<div class="toast toast-copied toast-index-40 align-items-center text-bg-secondary border-0 position-absolute top-0 end-0" role="alert" aria-live="assertive" aria-atomic="true">
  <div class="d-flex">
    <div class="toast-body">
      Copied!
    </div>
  </div>
</div>

---
Primary Category: cs.CV  
Categories: 68T40, 68T45, I-2-10; I-5-4, cs-AI, cs-CV, cs-CY, cs-LG, cs.CV  
Keyword Score: 30  
Keywords: Convolution, Multiple Instance Learning, Weakly Supervised Learning  
<a type="button" class="btn btn-outline-primary" href="http://arxiv.org/abs/2402.06107v1" target="_blank" >Paper Link</a>
<button type="button" class="btn btn-outline-primary download-pdf" url="https://arxiv.org/pdf/2402.06107v1.pdf" filename="2402.06107v1.pdf">Download PDF</button>

---


**ABSTRACT**  
The spread of the Coronavirus disease-2019 epidemic has caused many courses and exams to be conducted online. The cheating behavior detection model in examination invigilation systems plays a pivotal role in guaranteeing the equality of long-distance examinations. However, cheating behavior is rare, and most researchers do not comprehensively take into account features such as head posture, gaze angle, body posture, and background information in the task of cheating behavior detection. In this paper, we develop and present CHEESE, a CHEating detection framework via <b>multiplE</b> <b>inStancE</b> <b>learning.</b> The framework consists of a label generator that implements <b>weak</b> <b>supervision</b> and a feature encoder to learn discriminative features. In addition, the framework combines body posture and background features extracted by 3D <b>convolution</b> with eye gaze, head posture and facial features captured by OpenFace 2.0. These features are fed into the spatio-temporal graph module by stitching to analyze the spatio-temporal changes in video clips to detect the cheating behaviors. Our experiments on three datasets, UCF-Crime, ShanghaiTech and Online Exam Proctoring (OEP), prove the effectiveness of our method as compared to the state-of-the-art approaches, and obtain the frame-level AUC score of 87.58% on the OEP dataset.

{{</citation>}}


### (41/145) Hybridnet for depth estimation and semantic segmentation (Dalila SÃ¡nchez-Escobedo et al., 2024)

{{<citation>}}

Dalila SÃ¡nchez-Escobedo, Xiao Lin, Josep R. Casas, Montse PardÃ s. (2024)  
**Hybridnet for depth estimation and semantic segmentation**
<br/>
<button class="copy-to-clipboard" title="Hybridnet for depth estimation and semantic segmentation" index=41>
  <span class="copy-to-clipboard-item">Copy Title<span>
</button>
<div class="toast toast-copied toast-index-41 align-items-center text-bg-secondary border-0 position-absolute top-0 end-0" role="alert" aria-live="assertive" aria-atomic="true">
  <div class="d-flex">
    <div class="toast-body">
      Copied!
    </div>
  </div>
</div>

---
Primary Category: cs.CV  
Categories: cs-CV, cs.CV  
Keyword Score: 20  
Keywords: Convolution, Convolutional Neural Network  
<a type="button" class="btn btn-outline-primary" href="http://arxiv.org/abs/2402.06539v1" target="_blank" >Paper Link</a>
<button type="button" class="btn btn-outline-primary download-pdf" url="https://arxiv.org/pdf/2402.06539v1.pdf" filename="2402.06539v1.pdf">Download PDF</button>

---


**ABSTRACT**  
Semantic segmentation and depth estimation are two important tasks in the area of image processing. Traditionally, these two tasks are addressed in an independent manner. However, for those applications where geometric and semantic information is required, such as robotics or autonomous navigation,depth or semantic segmentation alone are not sufficient. In this paper, depth estimation and semantic segmentation are addressed together from a single input image through a hybrid <b>convolutional</b> <b>network.</b> Different from the state of the art methods where features are extracted by a sole feature extraction network for both tasks, the proposed HybridNet improves the features extraction by separating the relevant features for one task from those which are relevant for both. Experimental results demonstrate that HybridNet results are comparable with the state of the art methods, as well as the single task methods that HybridNet is based on.

{{</citation>}}


### (42/145) Feature Density Estimation for Out-of-Distribution Detection via Normalizing Flows (Evan D. Cook et al., 2024)

{{<citation>}}

Evan D. Cook, Marc-Antoine Lavoie, Steven L. Waslander. (2024)  
**Feature Density Estimation for Out-of-Distribution Detection via Normalizing Flows**
<br/>
<button class="copy-to-clipboard" title="Feature Density Estimation for Out-of-Distribution Detection via Normalizing Flows" index=42>
  <span class="copy-to-clipboard-item">Copy Title<span>
</button>
<div class="toast toast-copied toast-index-42 align-items-center text-bg-secondary border-0 position-absolute top-0 end-0" role="alert" aria-live="assertive" aria-atomic="true">
  <div class="d-flex">
    <div class="toast-body">
      Copied!
    </div>
  </div>
</div>

---
Primary Category: cs.CV  
Categories: cs-CV, cs.CV  
Keyword Score: 20  
Keywords: Out-of-distribution, Unsupervised Learning  
<a type="button" class="btn btn-outline-primary" href="http://arxiv.org/abs/2402.06537v1" target="_blank" >Paper Link</a>
<button type="button" class="btn btn-outline-primary download-pdf" url="https://arxiv.org/pdf/2402.06537v1.pdf" filename="2402.06537v1.pdf">Download PDF</button>

---


**ABSTRACT**  
<b>Out-of-distribution</b> (OOD) detection is a critical task for safe deployment of learning systems in the open world setting. In this work, we investigate the use of feature density estimation via normalizing flows for OOD detection and present a fully <b>unsupervised</b> approach which requires no exposure to OOD data, avoiding researcher bias in OOD sample selection. This is a post-hoc method which can be applied to any pretrained model, and involves training a lightweight auxiliary normalizing flow model to perform the <b>out-of-distribution</b> detection via density thresholding. Experiments on OOD detection in image classification show strong results for far-OOD data detection with only a single epoch of flow training, including 98.2% AUROC for ImageNet-1k vs. Textures, which exceeds the state of the art by 7.8%. We additionally explore the connection between the feature space distribution of the pretrained model and the performance of our method. Finally, we provide insights into training pitfalls that have plagued normalizing flows for use in OOD detection.

{{</citation>}}


### (43/145) Improving 2D-3D Dense Correspondences with Diffusion Models for 6D Object Pose Estimation (Peter HÃ¶nig et al., 2024)

{{<citation>}}

Peter HÃ¶nig, Stefan Thalhammer, Markus Vincze. (2024)  
**Improving 2D-3D Dense Correspondences with Diffusion Models for 6D Object Pose Estimation**
<br/>
<button class="copy-to-clipboard" title="Improving 2D-3D Dense Correspondences with Diffusion Models for 6D Object Pose Estimation" index=43>
  <span class="copy-to-clipboard-item">Copy Title<span>
</button>
<div class="toast toast-copied toast-index-43 align-items-center text-bg-secondary border-0 position-absolute top-0 end-0" role="alert" aria-live="assertive" aria-atomic="true">
  <div class="d-flex">
    <div class="toast-body">
      Copied!
    </div>
  </div>
</div>

---
Primary Category: cs.CV  
Categories: cs-CV, cs.CV  
Keyword Score: 20  
Keywords: Autoencoder, Generative Adversarial Network  
<a type="button" class="btn btn-outline-primary" href="http://arxiv.org/abs/2402.06436v1" target="_blank" >Paper Link</a>
<button type="button" class="btn btn-outline-primary download-pdf" url="https://arxiv.org/pdf/2402.06436v1.pdf" filename="2402.06436v1.pdf">Download PDF</button>

---


**ABSTRACT**  
Estimating 2D-3D correspondences between RGB images and 3D space is a fundamental problem in 6D object pose estimation. Recent pose estimators use dense correspondence maps and Point-to-Point algorithms to estimate object poses. The accuracy of pose estimation depends heavily on the quality of the dense correspondence maps and their ability to withstand occlusion, clutter, and challenging material properties. Currently, dense correspondence maps are estimated using image-to-image translation models based on <b>GANs,</b> <b>Autoencoders,</b> or direct regression models. However, recent advancements in image-to-image translation have led to diffusion models being the superior choice when evaluated on benchmarking datasets. In this study, we compare image-to-image translation networks based on <b>GANs</b> and diffusion models for the downstream task of 6D object pose estimation. Our results demonstrate that the diffusion-based image-to-image translation model outperforms the <b>GAN,</b> revealing potential for further improvements in 6D object pose estimation models.

{{</citation>}}


### (44/145) CurveFormer++: 3D Lane Detection by Curve Propagation with Temporal Curve Queries and Attention (Yifeng Bai et al., 2024)

{{<citation>}}

Yifeng Bai, Zhirong Chen, Pengpeng Liang, Erkang Cheng. (2024)  
**CurveFormer++: 3D Lane Detection by Curve Propagation with Temporal Curve Queries and Attention**
<br/>
<button class="copy-to-clipboard" title="CurveFormer++: 3D Lane Detection by Curve Propagation with Temporal Curve Queries and Attention" index=44>
  <span class="copy-to-clipboard-item">Copy Title<span>
</button>
<div class="toast toast-copied toast-index-44 align-items-center text-bg-secondary border-0 position-absolute top-0 end-0" role="alert" aria-live="assertive" aria-atomic="true">
  <div class="d-flex">
    <div class="toast-body">
      Copied!
    </div>
  </div>
</div>

---
Primary Category: cs.CV  
Categories: cs-CV, cs.CV  
Keyword Score: 20  
Keywords: Convolutional Neural Network, Transformer  
<a type="button" class="btn btn-outline-primary" href="http://arxiv.org/abs/2402.06423v1" target="_blank" >Paper Link</a>
<button type="button" class="btn btn-outline-primary download-pdf" url="https://arxiv.org/pdf/2402.06423v1.pdf" filename="2402.06423v1.pdf">Download PDF</button>

---


**ABSTRACT**  
In autonomous driving, 3D lane detection using monocular cameras is an important task for various downstream planning and control tasks. Recent <b>CNN</b> and <b>Transformer</b> approaches usually apply a two-stage scheme in the model design. The first stage transforms the image feature from a front image into a bird's-eye-view (BEV) representation. Subsequently, a sub-network processes the BEV feature map to generate the 3D detection results. However, these approaches heavily rely on a challenging image feature transformation module from a perspective view to a BEV representation. In our work, we present CurveFormer++, a single-stage <b>Transformer-based</b> method that does not require the image feature view transform module and directly infers 3D lane detection results from the perspective image features. Specifically, our approach models the 3D detection task as a curve propagation problem, where each lane is represented by a curve query with a dynamic and ordered anchor point set. By employing a <b>Transformer</b> decoder, the model can iteratively refine the 3D lane detection results. A curve cross-attention module is introduced in the <b>Transformer</b> decoder to calculate similarities between image features and curve queries of lanes. To handle varying lane lengths, we employ context sampling and anchor point restriction techniques to compute more relevant image features for a curve query. Furthermore, we apply a temporal fusion module that incorporates selected informative sparse curve queries and their corresponding anchor point sets to leverage historical lane information. In the experiments, we evaluate our approach for the 3D lane detection task on two publicly available real-world datasets. The results demonstrate that our method provides outstanding performance compared with both <b>CNN</b> and <b>Transformer</b> based methods. We also conduct ablation studies to analyze the impact of each component in our approach.

{{</citation>}}


### (45/145) Multisource Semisupervised Adversarial Domain Generalization Network for Cross-Scene Sea\textendash Land Clutter Classification (Xiaoxuan Zhang et al., 2024)

{{<citation>}}

Xiaoxuan Zhang, Quan Pan, Salvador GarcÃ­a. (2024)  
**Multisource Semisupervised Adversarial Domain Generalization Network for Cross-Scene Sea\textendash Land Clutter Classification**
<br/>
<button class="copy-to-clipboard" title="Multisource Semisupervised Adversarial Domain Generalization Network for Cross-Scene Sea\textendash Land Clutter Classification" index=45>
  <span class="copy-to-clipboard-item">Copy Title<span>
</button>
<div class="toast toast-copied toast-index-45 align-items-center text-bg-secondary border-0 position-absolute top-0 end-0" role="alert" aria-live="assertive" aria-atomic="true">
  <div class="d-flex">
    <div class="toast-body">
      Copied!
    </div>
  </div>
</div>

---
Primary Category: cs.CV  
Categories: cs-CV, cs.CV  
Keyword Score: 20  
Keywords: Generative Adversarial Network, Generative Adversarial Network  
<a type="button" class="btn btn-outline-primary" href="http://arxiv.org/abs/2402.06315v1" target="_blank" >Paper Link</a>
<button type="button" class="btn btn-outline-primary download-pdf" url="https://arxiv.org/pdf/2402.06315v1.pdf" filename="2402.06315v1.pdf">Download PDF</button>

---


**ABSTRACT**  
Deep learning (DL)-based sea\textendash land clutter classification for sky-wave over-the-horizon-radar (OTHR) has become a novel research topic. In engineering applications, real-time predictions of sea\textendash land clutter with existing distribution discrepancies are crucial. To solve this problem, this article proposes a novel Multisource Semisupervised Adversarial Domain Generalization Network (MSADGN) for cross-scene sea\textendash land clutter classification. MSADGN can extract domain-invariant and domain-specific features from one labeled source domain and multiple unlabeled source domains, and then generalize these features to an arbitrary unseen target domain for real-time prediction of sea\textendash land clutter. Specifically, MSADGN consists of three modules: domain-related pseudolabeling module, domain-invariant module, and domain-specific module. The first module introduces an improved pseudolabel method called domain-related pseudolabel, which is designed to generate reliable pseudolabels to fully exploit unlabeled source domains. The second module utilizes a <b>generative</b> <b>adversarial</b> <b>network</b> <b>(GAN)</b> with a multidiscriminator to extract domain-invariant features, to enhance the model's transferability in the target domain. The third module employs a parallel multiclassifier branch to extract domain-specific features, to enhance the model's discriminability in the target domain. The effectiveness of our method is validated in twelve domain generalizations (DG) scenarios. Meanwhile, we selected 10 state-of-the-art DG methods for comparison. The experimental results demonstrate the superiority of our method.

{{</citation>}}


### (46/145) GS-CLIP: Gaussian Splatting for Contrastive Language-Image-3D Pretraining from Real-World Data (Haoyuan Li et al., 2024)

{{<citation>}}

Haoyuan Li, Yanpeng Zhou, Yihan Zeng, Hang Xu, Xiaodan Liang. (2024)  
**GS-CLIP: Gaussian Splatting for Contrastive Language-Image-3D Pretraining from Real-World Data**
<br/>
<button class="copy-to-clipboard" title="GS-CLIP: Gaussian Splatting for Contrastive Language-Image-3D Pretraining from Real-World Data" index=46>
  <span class="copy-to-clipboard-item">Copy Title<span>
</button>
<div class="toast toast-copied toast-index-46 align-items-center text-bg-secondary border-0 position-absolute top-0 end-0" role="alert" aria-live="assertive" aria-atomic="true">
  <div class="d-flex">
    <div class="toast-body">
      Copied!
    </div>
  </div>
</div>

---
Primary Category: cs.CV  
Categories: cs-CV, cs.CV  
Keyword Score: 20  
Keywords: Image2text, Vision-and-Language  
<a type="button" class="btn btn-outline-primary" href="http://arxiv.org/abs/2402.06198v1" target="_blank" >Paper Link</a>
<button type="button" class="btn btn-outline-primary download-pdf" url="https://arxiv.org/pdf/2402.06198v1.pdf" filename="2402.06198v1.pdf">Download PDF</button>

---


**ABSTRACT**  
3D Shape represented as point cloud has achieve advancements in multimodal pre-training to align image and language descriptions, which is curial to object identification, classification, and retrieval. However, the discrete representations of point cloud lost the object's surface shape information and creates a gap between rendering results and 2D correspondences. To address this problem, we propose GS-CLIP for the first attempt to introduce 3DGS (3D Gaussian Splatting) into multimodal pre-training to enhance 3D representation. GS-CLIP leverages a pre-trained <b>vision-language</b> model for a learned common visual and textual space on massive real world <b>image-text</b> pairs and then learns a 3D Encoder for aligning 3DGS optimized per object. Additionally, a novel Gaussian-Aware Fusion is proposed to extract and fuse global explicit feature. As a general framework for language-image-3D pre-training, GS-CLIP is agnostic to 3D backbone networks. Experiments on challenging shows that GS-CLIP significantly improves the state-of-the-art, outperforming the previously best results.

{{</citation>}}


### (47/145) HeadStudio: Text to Animatable Head Avatars with 3D Gaussian Splatting (Zhenglin Zhou et al., 2024)

{{<citation>}}

Zhenglin Zhou, Fan Ma, Hehe Fan, Yi Yang. (2024)  
**HeadStudio: Text to Animatable Head Avatars with 3D Gaussian Splatting**
<br/>
<button class="copy-to-clipboard" title="HeadStudio: Text to Animatable Head Avatars with 3D Gaussian Splatting" index=47>
  <span class="copy-to-clipboard-item">Copy Title<span>
</button>
<div class="toast toast-copied toast-index-47 align-items-center text-bg-secondary border-0 position-absolute top-0 end-0" role="alert" aria-live="assertive" aria-atomic="true">
  <div class="d-flex">
    <div class="toast-body">
      Copied!
    </div>
  </div>
</div>

---
Primary Category: cs.CV  
Categories: cs-CV, cs.CV  
Keyword Score: 20  
Keywords: Knowledge Distillation, Prompt  
<a type="button" class="btn btn-outline-primary" href="http://arxiv.org/abs/2402.06149v1" target="_blank" >Paper Link</a>
<button type="button" class="btn btn-outline-primary download-pdf" url="https://arxiv.org/pdf/2402.06149v1.pdf" filename="2402.06149v1.pdf">Download PDF</button>

---


**ABSTRACT**  
Creating digital avatars from textual <b>prompts</b> has long been a desirable yet challenging task. Despite the promising outcomes obtained through 2D diffusion priors in recent works, current methods face challenges in achieving high-quality and animated avatars effectively. In this paper, we present $\textbf{HeadStudio}$, a novel framework that utilizes 3D Gaussian splatting to generate realistic and animated avatars from text <b>prompts.</b> Our method drives 3D Gaussians semantically to create a flexible and achievable appearance through the intermediate FLAME representation. Specifically, we incorporate the FLAME into both 3D representation and score <b>distillation:</b> 1) FLAME-based 3D Gaussian splatting, driving 3D Gaussian points by rigging each point to a FLAME mesh. 2) FLAME-based score <b>distillation</b> sampling, utilizing FLAME-based fine-grained control signal to guide score <b>distillation</b> from the text <b>prompt.</b> Extensive experiments demonstrate the efficacy of HeadStudio in generating animatable avatars from textual <b>prompts,</b> exhibiting visually appealing appearances. The avatars are capable of rendering high-quality real-time ($\geq 40$ fps) novel views at a resolution of 1024. They can be smoothly controlled by real-world speech and video. We hope that HeadStudio can advance digital avatar creation and that the present method can widely be applied across various domains.

{{</citation>}}


### (48/145) ContPhy: Continuum Physical Concept Learning and Reasoning from Videos (Zhicheng Zheng et al., 2024)

{{<citation>}}

Zhicheng Zheng, Xin Yan, Zhenfang Chen, Jingzhou Wang, Qin Zhi Eddie Lim, Joshua B. Tenenbaum, Chuang Gan. (2024)  
**ContPhy: Continuum Physical Concept Learning and Reasoning from Videos**
<br/>
<button class="copy-to-clipboard" title="ContPhy: Continuum Physical Concept Learning and Reasoning from Videos" index=48>
  <span class="copy-to-clipboard-item">Copy Title<span>
</button>
<div class="toast toast-copied toast-index-48 align-items-center text-bg-secondary border-0 position-absolute top-0 end-0" role="alert" aria-live="assertive" aria-atomic="true">
  <div class="d-flex">
    <div class="toast-body">
      Copied!
    </div>
  </div>
</div>

---
Primary Category: cs.CV  
Categories: cs-CV, cs.CV  
Keyword Score: 20  
Keywords: Reasoning, Large Language Model  
<a type="button" class="btn btn-outline-primary" href="http://arxiv.org/abs/2402.06119v1" target="_blank" >Paper Link</a>
<button type="button" class="btn btn-outline-primary download-pdf" url="https://arxiv.org/pdf/2402.06119v1.pdf" filename="2402.06119v1.pdf">Download PDF</button>

---


**ABSTRACT**  
We introduce the Continuum Physical Dataset (ContPhy), a novel benchmark for assessing machine physical commonsense. ContPhy complements existing physical <b>reasoning</b> benchmarks by encompassing the inference of diverse physical properties, such as mass and density, across various scenarios and predicting corresponding dynamics. We evaluated a range of AI models and found that they still struggle to achieve satisfactory performance on ContPhy, which shows that the current AI models still lack physical commonsense for the continuum, especially soft-bodies, and illustrates the value of the proposed dataset. We also introduce an oracle model (ContPRO) that marries the particle-based physical dynamic models with the recent <b>large</b> <b>language</b> <b>models,</b> which enjoy the advantages of both models, precise dynamic predictions, and interpretable <b>reasoning.</b> ContPhy aims to spur progress in perception and <b>reasoning</b> within diverse physical settings, narrowing the divide between human and machine intelligence in understanding the physical world. Project page: https://physical-reasoning-project.github.io.

{{</citation>}}


### (49/145) More than the Sum of Its Parts: Ensembling Backbone Networks for Few-Shot Segmentation (Nico Catalano et al., 2024)

{{<citation>}}

Nico Catalano, Alessandro Maranelli, Agnese Chiatti, Matteo Matteucci. (2024)  
**More than the Sum of Its Parts: Ensembling Backbone Networks for Few-Shot Segmentation**
<br/>
<button class="copy-to-clipboard" title="More than the Sum of Its Parts: Ensembling Backbone Networks for Few-Shot Segmentation" index=49>
  <span class="copy-to-clipboard-item">Copy Title<span>
</button>
<div class="toast toast-copied toast-index-49 align-items-center text-bg-secondary border-0 position-absolute top-0 end-0" role="alert" aria-live="assertive" aria-atomic="true">
  <div class="d-flex">
    <div class="toast-body">
      Copied!
    </div>
  </div>
</div>

---
Primary Category: cs.CV  
Categories: cs-CV, cs-LG, cs.CV  
Keyword Score: 10  
Keywords: Few-shot  
<a type="button" class="btn btn-outline-primary" href="http://arxiv.org/abs/2402.06581v1" target="_blank" >Paper Link</a>
<button type="button" class="btn btn-outline-primary download-pdf" url="https://arxiv.org/pdf/2402.06581v1.pdf" filename="2402.06581v1.pdf">Download PDF</button>

---


**ABSTRACT**  
Semantic segmentation is a key prerequisite to robust image understanding for applications in \acrlong{ai} and Robotics. \acrlong{fss}, in particular, concerns the extension and optimization of traditional segmentation methods in challenging conditions where limited training examples are available. A predominant approach in \acrlong{fss} is to rely on a single backbone for visual feature extraction. Choosing which backbone to leverage is a deciding factor contributing to the overall performance. In this work, we interrogate on whether fusing features from different backbones can improve the ability of \acrlong{fss} models to capture richer visual features. To tackle this question, we propose and compare two ensembling techniques-Independent Voting and Feature Fusion. Among the available \acrlong{fss} methods, we implement the proposed ensembling techniques on PANet. The module dedicated to predicting segmentation masks from the backbone embeddings in PANet avoids trainable parameters, creating a controlled `in vitro' setting for isolating the impact of different ensembling strategies. Leveraging the complementary strengths of different backbones, our approach outperforms the original single-backbone PANet across standard benchmarks even in challenging one-shot learning scenarios. Specifically, it achieved a performance improvement of +7.37\% on PASCAL-5\textsuperscript{i} and of +10.68\% on COCO-20\textsuperscript{i} in the top-performing scenario where three backbones are combined. These results, together with the qualitative inspection of the predicted subject masks, suggest that relying on multiple backbones in PANet leads to a more comprehensive feature representation, thus expediting the successful application of \acrlong{fss} methods in challenging, data-scarce environments.

{{</citation>}}


### (50/145) Transferring facade labels between point clouds with semantic octrees while considering change detection (Sophia Schwarz et al., 2024)

{{<citation>}}

Sophia Schwarz, Tanja Pilz, Olaf Wysocki, Ludwig Hoegner, Uwe Stilla. (2024)  
**Transferring facade labels between point clouds with semantic octrees while considering change detection**
<br/>
<button class="copy-to-clipboard" title="Transferring facade labels between point clouds with semantic octrees while considering change detection" index=50>
  <span class="copy-to-clipboard-item">Copy Title<span>
</button>
<div class="toast toast-copied toast-index-50 align-items-center text-bg-secondary border-0 position-absolute top-0 end-0" role="alert" aria-live="assertive" aria-atomic="true">
  <div class="d-flex">
    <div class="toast-body">
      Copied!
    </div>
  </div>
</div>

---
Primary Category: cs.CV  
Categories: cs-CV, cs-LG, cs.CV  
Keyword Score: 10  
Keywords: Transfer Learning  
<a type="button" class="btn btn-outline-primary" href="http://arxiv.org/abs/2402.06531v1" target="_blank" >Paper Link</a>
<button type="button" class="btn btn-outline-primary download-pdf" url="https://arxiv.org/pdf/2402.06531v1.pdf" filename="2402.06531v1.pdf">Download PDF</button>

---


**ABSTRACT**  
Point clouds and high-resolution 3D data have become increasingly important in various fields, including surveying, construction, and virtual reality. However, simply having this data is not enough; to extract useful information, semantic labeling is crucial. In this context, we propose a method to <b>transfer</b> <b>annotations</b> from a labeled to an unlabeled point cloud using an octree structure. The structure also analyses changes between the point clouds. Our experiments confirm that our method effectively <b>transfers</b> <b>annotations</b> while addressing changes. The primary contribution of this project is the development of the method for automatic label <b>transfer</b> <b>between</b> two different point clouds that represent the same real-world object. The proposed method can be of great importance for data-driven deep learning algorithms as it can also allow circumventing stochastic <b>transfer</b> <b>learning</b> by deterministic label <b>transfer</b> <b>between</b> datasets depicting the same objects.

{{</citation>}}


### (51/145) Reconstructing facade details using MLS point clouds and Bag-of-Words approach (Thomas Froech et al., 2024)

{{<citation>}}

Thomas Froech, Olaf Wysocki, Ludwig Hoegner, Uwe Stilla. (2024)  
**Reconstructing facade details using MLS point clouds and Bag-of-Words approach**
<br/>
<button class="copy-to-clipboard" title="Reconstructing facade details using MLS point clouds and Bag-of-Words approach" index=51>
  <span class="copy-to-clipboard-item">Copy Title<span>
</button>
<div class="toast toast-copied toast-index-51 align-items-center text-bg-secondary border-0 position-absolute top-0 end-0" role="alert" aria-live="assertive" aria-atomic="true">
  <div class="d-flex">
    <div class="toast-body">
      Copied!
    </div>
  </div>
</div>

---
Primary Category: cs.CV  
Categories: cs-CV, cs-LG, cs.CV  
Keyword Score: 10  
Keywords: Bag-of-Words  
<a type="button" class="btn btn-outline-primary" href="http://arxiv.org/abs/2402.06521v1" target="_blank" >Paper Link</a>
<button type="button" class="btn btn-outline-primary download-pdf" url="https://arxiv.org/pdf/2402.06521v1.pdf" filename="2402.06521v1.pdf">Download PDF</button>

---


**ABSTRACT**  
In the reconstruction of fa\c{c}ade elements, the identification of specific object types remains challenging and is often circumvented by rectangularity assumptions or the use of bounding boxes. We propose a new approach for the reconstruction of 3D fa\c{c}ade details. We combine MLS point clouds and a pre-defined 3D model library using a BoW concept, which we augment by incorporating semi-global features. We conduct experiments on the models superimposed with random noise and on the TUM-FA\c{C}ADE dataset. Our method demonstrates promising results, improving the conventional BoW approach. It holds the potential to be utilized for more realistic facade reconstruction without rectangularity assumptions, which can be used in applications such as testing automated driving functions or estimating fa\c{c}ade solar potential.

{{</citation>}}


### (52/145) Iris-SAM: Iris Segmentation Using a Foundational Model (Parisa Farmanifard et al., 2024)

{{<citation>}}

Parisa Farmanifard, Arun Ross. (2024)  
**Iris-SAM: Iris Segmentation Using a Foundational Model**
<br/>
<button class="copy-to-clipboard" title="Iris-SAM: Iris Segmentation Using a Foundational Model" index=52>
  <span class="copy-to-clipboard-item">Copy Title<span>
</button>
<div class="toast toast-copied toast-index-52 align-items-center text-bg-secondary border-0 position-absolute top-0 end-0" role="alert" aria-live="assertive" aria-atomic="true">
  <div class="d-flex">
    <div class="toast-body">
      Copied!
    </div>
  </div>
</div>

---
Primary Category: cs.CV  
Categories: cs-CV, cs.CV  
Keyword Score: 10  
Keywords: Fine-tuning  
<a type="button" class="btn btn-outline-primary" href="http://arxiv.org/abs/2402.06497v1" target="_blank" >Paper Link</a>
<button type="button" class="btn btn-outline-primary download-pdf" url="https://arxiv.org/pdf/2402.06497v1.pdf" filename="2402.06497v1.pdf">Download PDF</button>

---


**ABSTRACT**  
Iris segmentation is a critical component of an iris biometric system and it involves extracting the annular iris region from an ocular image. In this work, we develop a pixel-level iris segmentation model from a foundational model, viz., Segment Anything Model (SAM), that has been successfully used for segmenting arbitrary objects. The primary contribution of this work lies in the integration of different loss functions during the <b>fine-tuning</b> of SAM on ocular images. In particular, the importance of Focal Loss is borne out in the <b>fine-tuning</b> process since it strategically addresses the class imbalance problem (i.e., iris versus non-iris pixels). Experiments on ND-IRIS-0405, CASIA-Iris-Interval-v3, and IIT-Delhi-Iris datasets convey the efficacy of the trained model for the task of iris segmentation. For instance, on the ND-IRIS-0405 dataset, an average segmentation accuracy of 99.58% was achieved, compared to the best baseline performance of 89.75%.

{{</citation>}}


### (53/145) Maia: A Real-time Non-Verbal Chat for Human-AI Interaction (Dragos Costea et al., 2024)

{{<citation>}}

Dragos Costea, Alina Marcu, Cristina Lazar, Marius Leordeanu. (2024)  
**Maia: A Real-time Non-Verbal Chat for Human-AI Interaction**
<br/>
<button class="copy-to-clipboard" title="Maia: A Real-time Non-Verbal Chat for Human-AI Interaction" index=53>
  <span class="copy-to-clipboard-item">Copy Title<span>
</button>
<div class="toast toast-copied toast-index-53 align-items-center text-bg-secondary border-0 position-absolute top-0 end-0" role="alert" aria-live="assertive" aria-atomic="true">
  <div class="d-flex">
    <div class="toast-body">
      Copied!
    </div>
  </div>
</div>

---
Primary Category: cs.CV  
Categories: cs-CV, cs.CV  
Keyword Score: 10  
Keywords: Automatic Evaluation  
<a type="button" class="btn btn-outline-primary" href="http://arxiv.org/abs/2402.06385v1" target="_blank" >Paper Link</a>
<button type="button" class="btn btn-outline-primary download-pdf" url="https://arxiv.org/pdf/2402.06385v1.pdf" filename="2402.06385v1.pdf">Download PDF</button>

---


**ABSTRACT**  
Face-to-face communication modeling in computer vision is an area of research focusing on developing algorithms that can recognize and analyze non-verbal cues and behaviors during face-to-face interactions. We propose an alternative to text chats for Human-AI interaction, based on non-verbal visual communication only, using facial expressions and head movements that mirror, but also improvise over the human user, to efficiently engage with the users, and capture their attention in a low-cost and real-time fashion. Our goal is to track and analyze facial expressions, and other non-verbal cues in real-time, and use this information to build models that can predict and understand human behavior. We offer three different complementary approaches, based on retrieval, statistical, and deep learning techniques. We provide human as well as <b>automatic</b> <b>evaluations</b> and discuss the advantages and disadvantages of each direction.

{{</citation>}}


### (54/145) FD-Vision Mamba for Endoscopic Exposure Correction (Zhuoran Zheng et al., 2024)

{{<citation>}}

Zhuoran Zheng, Jun Zhang. (2024)  
**FD-Vision Mamba for Endoscopic Exposure Correction**
<br/>
<button class="copy-to-clipboard" title="FD-Vision Mamba for Endoscopic Exposure Correction" index=54>
  <span class="copy-to-clipboard-item">Copy Title<span>
</button>
<div class="toast toast-copied toast-index-54 align-items-center text-bg-secondary border-0 position-absolute top-0 end-0" role="alert" aria-live="assertive" aria-atomic="true">
  <div class="d-flex">
    <div class="toast-body">
      Copied!
    </div>
  </div>
</div>

---
Primary Category: cs.CV  
Categories: cs-CV, cs.CV  
Keyword Score: 10  
Keywords: Convolution  
<a type="button" class="btn btn-outline-primary" href="http://arxiv.org/abs/2402.06378v1" target="_blank" >Paper Link</a>
<button type="button" class="btn btn-outline-primary download-pdf" url="https://arxiv.org/pdf/2402.06378v1.pdf" filename="2402.06378v1.pdf">Download PDF</button>

---


**ABSTRACT**  
In endoscopic imaging, the recorded images are prone to exposure abnormalities, so maintaining high-quality images is important to assist healthcare professionals in performing decision-making. To overcome this issue, We design a frequency-domain based network, called FD-Vision Mamba (FDVM-Net), which achieves high-quality image exposure correction by reconstructing the frequency domain of endoscopic images. Specifically, inspired by the State Space Sequence Models (SSMs), we develop a C-SSM block that integrates the local feature extraction ability of the <b>convolutional</b> layer with the ability of the SSM to capture long-range dependencies. A two-path network is built using C-SSM as the basic function cell, and these two paths deal with the phase and amplitude information of the image, respectively. Finally, a degraded endoscopic image is reconstructed by FDVM-Net to obtain a high-quality clear image. Extensive experimental results demonstrate that our method achieves state-of-the-art results in terms of speed and accuracy, and it is noteworthy that our method can enhance endoscopic images of arbitrary resolution. The URL of the code is \url{https://github.com/zzr-idam/FDVM-Net}.

{{</citation>}}


### (55/145) Towards actionability for open medical imaging datasets: lessons from community-contributed platforms for data management and stewardship (Amelia JimÃ©nez-SÃ¡nchez et al., 2024)

{{<citation>}}

Amelia JimÃ©nez-SÃ¡nchez, Natalia-Rozalia Avlona, Dovile Juodelyte, ThÃ©o Sourget, Caroline Vang-Larsen, Hubert Dariusz ZajÄc, Veronika Cheplygina. (2024)  
**Towards actionability for open medical imaging datasets: lessons from community-contributed platforms for data management and stewardship**
<br/>
<button class="copy-to-clipboard" title="Towards actionability for open medical imaging datasets: lessons from community-contributed platforms for data management and stewardship" index=55>
  <span class="copy-to-clipboard-item">Copy Title<span>
</button>
<div class="toast toast-copied toast-index-55 align-items-center text-bg-secondary border-0 position-absolute top-0 end-0" role="alert" aria-live="assertive" aria-atomic="true">
  <div class="d-flex">
    <div class="toast-body">
      Copied!
    </div>
  </div>
</div>

---
Primary Category: cs.CV  
Categories: cs-CV, cs.CV  
Keyword Score: 10  
Keywords: Fairness  
<a type="button" class="btn btn-outline-primary" href="http://arxiv.org/abs/2402.06353v1" target="_blank" >Paper Link</a>
<button type="button" class="btn btn-outline-primary download-pdf" url="https://arxiv.org/pdf/2402.06353v1.pdf" filename="2402.06353v1.pdf">Download PDF</button>

---


**ABSTRACT**  
Medical imaging datasets are fundamental to artificial intelligence (AI) in healthcare. The accuracy, robustness and <b>fairness</b> of diagnostic algorithms depend on the data (and its quality) on which the models are trained and evaluated. Medical imaging datasets have become increasingly available to the public, and are often hosted on Community-Contributed Platforms (CCP), including private companies like Kaggle or HuggingFace. While open data is important to enhance the redistribution of data's public value, we find that the current CCP governance model fails to uphold the quality needed and recommended practices for sharing, documenting, and evaluating datasets. In this paper we investigate medical imaging datasets on CCPs and how they are documented, shared, and maintained. We first highlight some differences between medical imaging and computer vision, particularly in the potentially harmful downstream effects due to poor adoption of recommended dataset management practices. We then analyze 20 (10 medical and 10 computer vision) popular datasets on CCPs and find vague licenses, lack of persistent identifiers and storage, duplicates and missing metadata, with differences between the platforms. We present "actionability" as a conceptual metric to reveal the data quality gap between characteristics of data on CCPs and the desired characteristics of data for AI in healthcare. Finally, we propose a commons-based stewardship model for documenting, sharing and maintaining datasets on CCPs and end with a discussion of limitations and open questions.

{{</citation>}}


### (56/145) Insomnia Identification via Electroencephalography (Olviya Udeshika et al., 2024)

{{<citation>}}

Olviya Udeshika, Dilshan Lakshitha, Nilantha Premakumara, Surangani Bandara. (2024)  
**Insomnia Identification via Electroencephalography**
<br/>
<button class="copy-to-clipboard" title="Insomnia Identification via Electroencephalography" index=56>
  <span class="copy-to-clipboard-item">Copy Title<span>
</button>
<div class="toast toast-copied toast-index-56 align-items-center text-bg-secondary border-0 position-absolute top-0 end-0" role="alert" aria-live="assertive" aria-atomic="true">
  <div class="d-flex">
    <div class="toast-body">
      Copied!
    </div>
  </div>
</div>

---
Primary Category: cs.CV  
Categories: cs-CV, cs.CV  
Keyword Score: 10  
Keywords: Convolutional Neural Network  
<a type="button" class="btn btn-outline-primary" href="http://arxiv.org/abs/2402.06251v1" target="_blank" >Paper Link</a>
<button type="button" class="btn btn-outline-primary download-pdf" url="https://arxiv.org/pdf/2402.06251v1.pdf" filename="2402.06251v1.pdf">Download PDF</button>

---


**ABSTRACT**  
Insomnia is a serious sleep disorder caused by abnormal or excessive neural activity in the brain. An estimated 50 million people worldwide are thought to be affected by this condition, which is the second most severe neurological disease after stroke. In order to ensure a quick recovery, an early and accurate diagnosis of insomnia enables more effective drug and treatment administration. This study proposes a method that uses deep learning to automatically identify patients with insomnia. A set of optimal features are extracted from spectral and temporal domains, including the relative power of {\sigma}, \b{eta} and {\gamma} bands, the total power, the absolute slow wave power, the power ratios of {\theta}, {\alpha}, {\gamma}, \b{eta}, {\theta}/{\alpha}, {\theta}/\b{eta}, {\alpha}/{\gamma} and {\alpha}/\b{eta}, mean, zero crossing rate, mobility, complexity, sleep efficiency and total sleep time, to accurately quantify the differences between insomnia patients and healthy subjects and develops a 1D <b>CNN</b> model for the classification process. With the experiments use Fp2 and C4 EEG channels with 50 insomnia patients and 50 healthy subjects, the proposed model arrives 99.34% accuracy without sleep stage annotation. Using the features only from a single channel, the study proposes a smart solution for insomnia patients which allows machine learning to be to simplify current sleep monitoring hardware and improve in-home ambulatory monitoring.

{{</citation>}}


### (57/145) TETRIS: Towards Exploring the Robustness of Interactive Segmentation (Andrey Moskalenko et al., 2024)

{{<citation>}}

Andrey Moskalenko, Vlad Shakhuro, Anna Vorontsova, Anton Konushin, Anton Antonov, Alexander Krapukhin, Denis Shepelev, Konstantin Soshin. (2024)  
**TETRIS: Towards Exploring the Robustness of Interactive Segmentation**
<br/>
<button class="copy-to-clipboard" title="TETRIS: Towards Exploring the Robustness of Interactive Segmentation" index=57>
  <span class="copy-to-clipboard-item">Copy Title<span>
</button>
<div class="toast toast-copied toast-index-57 align-items-center text-bg-secondary border-0 position-absolute top-0 end-0" role="alert" aria-live="assertive" aria-atomic="true">
  <div class="d-flex">
    <div class="toast-body">
      Copied!
    </div>
  </div>
</div>

---
Primary Category: cs.CV  
Categories: 68T45, I-4-6, cs-CV, cs-HC, cs.CV  
Keyword Score: 10  
Keywords: Adversarial Attack  
<a type="button" class="btn btn-outline-primary" href="http://arxiv.org/abs/2402.06132v1" target="_blank" >Paper Link</a>
<button type="button" class="btn btn-outline-primary download-pdf" url="https://arxiv.org/pdf/2402.06132v1.pdf" filename="2402.06132v1.pdf">Download PDF</button>

---


**ABSTRACT**  
Interactive segmentation methods rely on user inputs to iteratively update the selection mask. A click specifying the object of interest is arguably the most simple and intuitive interaction type, and thereby the most common choice for interactive segmentation. However, user clicking patterns in the interactive segmentation context remain unexplored. Accordingly, interactive segmentation evaluation strategies rely more on intuition and common sense rather than empirical studies (e.g., assuming that users tend to click in the center of the area with the largest error). In this work, we conduct a real user study to investigate real user clicking patterns. This study reveals that the intuitive assumption made in the common evaluation strategy may not hold. As a result, interactive segmentation models may show high scores in the standard benchmarks, but it does not imply that they would perform well in a real world scenario. To assess the applicability of interactive segmentation methods, we propose a novel evaluation strategy providing a more comprehensive analysis of a model's performance. To this end, we propose a methodology for finding extreme user inputs by a direct optimization in a white-box <b>adversarial</b> <b>attack</b> on the interactive segmentation model. Based on the performance with such <b>adversarial</b> <b>user</b> inputs, we assess the robustness of interactive segmentation models w.r.t click positions. Besides, we introduce a novel benchmark for measuring the robustness of interactive segmentation, and report the results of an extensive evaluation of dozens of models.

{{</citation>}}


### (58/145) Spatially-Attentive Patch-Hierarchical Network with Adaptive Sampling for Motion Deblurring (Maitreya Suin et al., 2024)

{{<citation>}}

Maitreya Suin, Kuldeep Purohit, A. N. Rajagopalan. (2024)  
**Spatially-Attentive Patch-Hierarchical Network with Adaptive Sampling for Motion Deblurring**
<br/>
<button class="copy-to-clipboard" title="Spatially-Attentive Patch-Hierarchical Network with Adaptive Sampling for Motion Deblurring" index=58>
  <span class="copy-to-clipboard-item">Copy Title<span>
</button>
<div class="toast toast-copied toast-index-58 align-items-center text-bg-secondary border-0 position-absolute top-0 end-0" role="alert" aria-live="assertive" aria-atomic="true">
  <div class="d-flex">
    <div class="toast-body">
      Copied!
    </div>
  </div>
</div>

---
Primary Category: cs.CV  
Categories: cs-CV, cs.CV  
Keyword Score: 10  
Keywords: Convolution  
<a type="button" class="btn btn-outline-primary" href="http://arxiv.org/abs/2402.06117v1" target="_blank" >Paper Link</a>
<button type="button" class="btn btn-outline-primary download-pdf" url="https://arxiv.org/pdf/2402.06117v1.pdf" filename="2402.06117v1.pdf">Download PDF</button>

---


**ABSTRACT**  
This paper tackles the problem of motion deblurring of dynamic scenes. Although end-to-end fully <b>convolutional</b> designs have recently advanced the state-of-the-art in non-uniform motion deblurring, their performance-complexity trade-off is still sub-optimal. Most existing approaches achieve a large receptive field by increasing the number of generic <b>convolution</b> layers and kernel size. In this work, we propose a pixel adaptive and feature attentive design for handling large blur variations across different spatial locations and process each test image adaptively. We design a content-aware global-local filtering module that significantly improves performance by considering not only global dependencies but also by dynamically exploiting neighboring pixel information. We further introduce a pixel-adaptive non-uniform sampling strategy that implicitly discovers the difficult-to-restore regions present in the image and, in turn, performs fine-grained refinement in a progressive manner. Extensive qualitative and quantitative comparisons with prior art on deblurring benchmarks demonstrate that our approach performs favorably against the state-of-the-art deblurring algorithms.

{{</citation>}}


## stat.ML (3)



### (59/145) Flexible infinite-width graph convolutional networks and the importance of representation learning (Ben Anson et al., 2024)

{{<citation>}}

Ben Anson, Edward Milsom, Laurence Aitchison. (2024)  
**Flexible infinite-width graph convolutional networks and the importance of representation learning**
<br/>
<button class="copy-to-clipboard" title="Flexible infinite-width graph convolutional networks and the importance of representation learning" index=59>
  <span class="copy-to-clipboard-item">Copy Title<span>
</button>
<div class="toast toast-copied toast-index-59 align-items-center text-bg-secondary border-0 position-absolute top-0 end-0" role="alert" aria-live="assertive" aria-atomic="true">
  <div class="d-flex">
    <div class="toast-body">
      Copied!
    </div>
  </div>
</div>

---
Primary Category: stat.ML  
Categories: cs-LG, stat-ML, stat.ML  
Keyword Score: 60  
Keywords: Graph Convolutional Network, Graph Classification, Node Classification, Convolution, Convolutional Neural Network, Gaussian Process  
<a type="button" class="btn btn-outline-primary" href="http://arxiv.org/abs/2402.06525v1" target="_blank" >Paper Link</a>
<button type="button" class="btn btn-outline-primary download-pdf" url="https://arxiv.org/pdf/2402.06525v1.pdf" filename="2402.06525v1.pdf">Download PDF</button>

---


**ABSTRACT**  
A common theoretical approach to understanding neural networks is to take an infinite-width limit, at which point the outputs become <b>Gaussian</b> <b>process</b> (GP) distributed. This is known as a neural network <b>Gaussian</b> <b>process</b> (NNGP). However, the NNGP kernel is fixed, and tunable only through a small number of hyperparameters, eliminating any possibility of representation learning. This contrasts with finite-width NNs, which are often believed to perform well precisely because they are able to learn representations. Thus in simplifying NNs to make them theoretically tractable, NNGPs may eliminate precisely what makes them work well (representation learning). This motivated us to understand whether representation learning is necessary in a range of <b>graph</b> <b>classification</b> <b>tasks.</b> We develop a precise tool for this task, the <b>graph</b> <b>convolutional</b> <b>deep</b> kernel machine. This is very similar to an NNGP, in that it is an infinite width limit and uses kernels, but comes with a `knob' to control the amount of representation learning. We found that representation learning is necessary (in the sense that it gives dramatic performance improvements) in <b>graph</b> <b>classification</b> <b>tasks</b> and heterophilous <b>node</b> <b>classification</b> tasks, but not in homophilous <b>node</b> <b>classification</b> tasks.

{{</citation>}}


### (60/145) On the Convergence Rate of the Stochastic Gradient Descent (SGD) and application to a modified policy gradient for the Multi Armed Bandit (Stefana Anita et al., 2024)

{{<citation>}}

Stefana Anita, Gabriel Turinici. (2024)  
**On the Convergence Rate of the Stochastic Gradient Descent (SGD) and application to a modified policy gradient for the Multi Armed Bandit**
<br/>
<button class="copy-to-clipboard" title="On the Convergence Rate of the Stochastic Gradient Descent (SGD) and application to a modified policy gradient for the Multi Armed Bandit" index=60>
  <span class="copy-to-clipboard-item">Copy Title<span>
</button>
<div class="toast toast-copied toast-index-60 align-items-center text-bg-secondary border-0 position-absolute top-0 end-0" role="alert" aria-live="assertive" aria-atomic="true">
  <div class="d-flex">
    <div class="toast-body">
      Copied!
    </div>
  </div>
</div>

---
Primary Category: stat.ML  
Categories: cs-AI, cs-DS, cs-LG, cs-NA, math-NA, stat-ML, stat.ML  
Keyword Score: 30  
Keywords: Bandit Algorithm, Stochastic Gradient Descent, Stochastic Gradient Descent  
<a type="button" class="btn btn-outline-primary" href="http://arxiv.org/abs/2402.06388v1" target="_blank" >Paper Link</a>
<button type="button" class="btn btn-outline-primary download-pdf" url="https://arxiv.org/pdf/2402.06388v1.pdf" filename="2402.06388v1.pdf">Download PDF</button>

---


**ABSTRACT**  
We present a self-contained proof of the convergence rate of the <b>Stochastic</b> <b>Gradient</b> <b>Descent</b> <b>(SGD)</b> when the learning rate follows an inverse time decays schedule; we next apply the results to the convergence of a modified form of policy gradient Multi-Armed <b>Bandit</b> (MAB) with $L2$ regularization.

{{</citation>}}


### (61/145) POTEC: Off-Policy Learning for Large Action Spaces via Two-Stage Policy Decomposition (Yuta Saito et al., 2024)

{{<citation>}}

Yuta Saito, Jihan Yao, Thorsten Joachims. (2024)  
**POTEC: Off-Policy Learning for Large Action Spaces via Two-Stage Policy Decomposition**
<br/>
<button class="copy-to-clipboard" title="POTEC: Off-Policy Learning for Large Action Spaces via Two-Stage Policy Decomposition" index=61>
  <span class="copy-to-clipboard-item">Copy Title<span>
</button>
<div class="toast toast-copied toast-index-61 align-items-center text-bg-secondary border-0 position-absolute top-0 end-0" role="alert" aria-live="assertive" aria-atomic="true">
  <div class="d-flex">
    <div class="toast-body">
      Copied!
    </div>
  </div>
</div>

---
Primary Category: stat.ML  
Categories: cs-LG, stat-ML, stat.ML  
Keyword Score: 10  
Keywords: Bandit Algorithm  
<a type="button" class="btn btn-outline-primary" href="http://arxiv.org/abs/2402.06151v1" target="_blank" >Paper Link</a>
<button type="button" class="btn btn-outline-primary download-pdf" url="https://arxiv.org/pdf/2402.06151v1.pdf" filename="2402.06151v1.pdf">Download PDF</button>

---


**ABSTRACT**  
We study off-policy learning (OPL) of contextual <b>bandit</b> policies in large discrete action spaces where existing methods -- most of which rely crucially on reward-regression models or importance-weighted policy gradients -- fail due to excessive bias or variance. To overcome these issues in OPL, we propose a novel two-stage algorithm, called Policy Optimization via Two-Stage Policy Decomposition (POTEC). It leverages clustering in the action space and learns two different policies via policy- and regression-based approaches, respectively. In particular, we derive a novel low-variance gradient estimator that enables to learn a first-stage policy for cluster selection efficiently via a policy-based approach. To select a specific action within the cluster sampled by the first-stage policy, POTEC uses a second-stage policy derived from a regression-based approach within each cluster. We show that a local correctness condition, which only requires that the regression model preserves the relative expected reward differences of the actions within each cluster, ensures that our policy-gradient estimator is unbiased and the second-stage policy is optimal. We also show that POTEC provides a strict generalization of policy- and regression-based approaches and their associated assumptions. Comprehensive experiments demonstrate that POTEC provides substantial improvements in OPL effectiveness particularly in large and structured action spaces.

{{</citation>}}


## cs.CR (1)



### (62/145) StruQ: Defending Against Prompt Injection with Structured Queries (Sizhe Chen et al., 2024)

{{<citation>}}

Sizhe Chen, Julien Piet, Chawin Sitawarin, David Wagner. (2024)  
**StruQ: Defending Against Prompt Injection with Structured Queries**
<br/>
<button class="copy-to-clipboard" title="StruQ: Defending Against Prompt Injection with Structured Queries" index=62>
  <span class="copy-to-clipboard-item">Copy Title<span>
</button>
<div class="toast toast-copied toast-index-62 align-items-center text-bg-secondary border-0 position-absolute top-0 end-0" role="alert" aria-live="assertive" aria-atomic="true">
  <div class="d-flex">
    <div class="toast-body">
      Copied!
    </div>
  </div>
</div>

---
Primary Category: cs.CR  
Categories: cs-CR, cs.CR  
Keyword Score: 60  
Keywords: Fine-tuning, Fine-tuning, Instruction Tuning, Large Language Model, Large Language Model, Prompt  
<a type="button" class="btn btn-outline-primary" href="http://arxiv.org/abs/2402.06363v1" target="_blank" >Paper Link</a>
<button type="button" class="btn btn-outline-primary download-pdf" url="https://arxiv.org/pdf/2402.06363v1.pdf" filename="2402.06363v1.pdf">Download PDF</button>

---


**ABSTRACT**  
Recent advances in <b>Large</b> <b>Language</b> <b>Models</b> <b>(LLMs)</b> enable exciting <b>LLM-integrated</b> applications, which perform text-based tasks by utilizing their advanced language understanding capabilities. However, as <b>LLMs</b> have improved, so have the attacks against them. <b>Prompt</b> injection attacks are an important threat: they trick the model to deviate from the original application's <b>instructions</b> <b>and</b> instead follow user directives. These attacks rely on the <b>LLM's</b> ability to follow <b>instructions</b> <b>and</b> inability to separate the <b>prompts</b> and user data. We introduce structured queries, a general approach to tackle this problem. Structured queries separate <b>prompts</b> and data into two channels. We implement a system that supports structured queries. This system is made of (1) a secure front-end that formats a <b>prompt</b> and user data into a special format, and (2) a specially trained <b>LLM</b> that can produce high-quality outputs from these inputs. The <b>LLM</b> is trained using a novel <b>fine-tuning</b> strategy: we convert a base (non-instruction-tuned) <b>LLM</b> to a structured <b>instruction-tuned</b> <b>model</b> that will only follow <b>instructions</b> <b>in</b> the <b>prompt</b> portion of a query. To do so, we augment standard <b>instruction</b> <b>tuning</b> datasets with examples that also include <b>instructions</b> <b>in</b> the data portion of the query, and <b>fine-tune</b> the model to ignore these. Our system significantly improves resistance to <b>prompt</b> injection attacks, with little or no impact on utility. Our code is released at https://github.com/Sizhe-Chen/PromptInjectionDefense.

{{</citation>}}


## cs.SE (4)



### (63/145) Delving into Parameter-Efficient Fine-Tuning in Code Change Learning: An Empirical Study (Shuo Liu et al., 2024)

{{<citation>}}

Shuo Liu, Jacky Keung, Zhen Yang, Fang Liu, Qilin Zhou, Yihan Liao. (2024)  
**Delving into Parameter-Efficient Fine-Tuning in Code Change Learning: An Empirical Study**
<br/>
<button class="copy-to-clipboard" title="Delving into Parameter-Efficient Fine-Tuning in Code Change Learning: An Empirical Study" index=63>
  <span class="copy-to-clipboard-item">Copy Title<span>
</button>
<div class="toast toast-copied toast-index-63 align-items-center text-bg-secondary border-0 position-absolute top-0 end-0" role="alert" aria-live="assertive" aria-atomic="true">
  <div class="d-flex">
    <div class="toast-body">
      Copied!
    </div>
  </div>
</div>

---
Primary Category: cs.SE  
Categories: cs-SE, cs.SE  
Keyword Score: 60  
Keywords: Fine-tuning, Knowledge Transfer, Low-Resource, Pre-trained Language Model, Pre-trained Language Model, Summarization  
<a type="button" class="btn btn-outline-primary" href="http://arxiv.org/abs/2402.06247v1" target="_blank" >Paper Link</a>
<button type="button" class="btn btn-outline-primary download-pdf" url="https://arxiv.org/pdf/2402.06247v1.pdf" filename="2402.06247v1.pdf">Download PDF</button>

---


**ABSTRACT**  
Compared to Full-Model <b>Fine-Tuning</b> (FMFT), Parameter Efficient <b>Fine-Tuning</b> (PEFT) has demonstrated superior performance and lower computational overhead in several code understanding tasks, such as code <b>summarization</b> and code search. This advantage can be attributed to PEFT's ability to alleviate the catastrophic forgetting issue of <b>Pre-trained</b> <b>Language</b> <b>Models</b> <b>(PLMs)</b> by updating only a small number of parameters. As a result, PEFT effectively harnesses the <b>pre-trained</b> <b>general-purpose</b> <b>knowledge</b> <b>for</b> downstream tasks. However, existing studies primarily involve static code comprehension, aligning with the pre-training paradigm of recent <b>PLMs</b> and facilitating <b>knowledge</b> <b>transfer,</b> but they do not account for dynamic code changes. Thus, it remains unclear whether PEFT outperforms FMFT in task-specific adaptation for code-change-related tasks. To address this question, we examine two prevalent PEFT methods, namely Adapter Tuning (AT) and Low-Rank Adaptation (LoRA), and compare their performance with FMFT on five popular <b>PLMs.</b> Specifically, we evaluate their performance on two widely-studied code-change-related tasks: Just-In-Time Defect Prediction (JIT-DP) and Commit Message Generation (CMG). The results demonstrate that both AT and LoRA achieve state-of-the-art (SOTA) results in JIT-DP and exhibit comparable performances in CMG when compared to FMFT and other SOTA approaches. Furthermore, AT and LoRA exhibit superiority in cross-lingual and <b>low-resource</b> scenarios. We also conduct three probing tasks to explain the efficacy of PEFT techniques on JIT-DP and CMG tasks from both static and dynamic perspectives. The study indicates that PEFT, particularly through the use of AT and LoRA, offers promising advantages in code-change-related tasks, surpassing FMFT in certain aspects.

{{</citation>}}


### (64/145) CigaR: Cost-efficient Program Repair with LLMs (DÃ¡vid HidvÃ©gi et al., 2024)

{{<citation>}}

DÃ¡vid HidvÃ©gi, Khashayar Etemadi, Sofia Bobadilla, Martin Monperrus. (2024)  
**CigaR: Cost-efficient Program Repair with LLMs**
<br/>
<button class="copy-to-clipboard" title="CigaR: Cost-efficient Program Repair with LLMs" index=64>
  <span class="copy-to-clipboard-item">Copy Title<span>
</button>
<div class="toast toast-copied toast-index-64 align-items-center text-bg-secondary border-0 position-absolute top-0 end-0" role="alert" aria-live="assertive" aria-atomic="true">
  <div class="d-flex">
    <div class="toast-body">
      Copied!
    </div>
  </div>
</div>

---
Primary Category: cs.SE  
Categories: cs-SE, cs.SE  
Keyword Score: 30  
Keywords: Large Language Model, Large Language Model, Prompt  
<a type="button" class="btn btn-outline-primary" href="http://arxiv.org/abs/2402.06598v1" target="_blank" >Paper Link</a>
<button type="button" class="btn btn-outline-primary download-pdf" url="https://arxiv.org/pdf/2402.06598v1.pdf" filename="2402.06598v1.pdf">Download PDF</button>

---


**ABSTRACT**  
<b>Large</b> <b>language</b> <b>models</b> <b>(LLM)</b> have proven to be effective at automated program repair (APR). However, using <b>LLMs</b> can be highly costly, with companies invoicing users by the number of tokens. In this paper, we propose CigaR, the first <b>LLM-based</b> APR tool that focuses on minimizing the repair cost. CigaR works in two major steps: generating a plausible patch and multiplying plausible patches. CigaR optimizes the <b>prompts</b> and the <b>prompt</b> setting to maximize the information given to <b>LLMs</b> in the smallest possible number of tokens. Our experiments on 267 bugs from the widely used Defects4J dataset shows that CigaR reduces the token cost by 62. On average, CigaR spends 171k tokens per bug while the baseline uses 451k tokens. On the subset of bugs that are fixed by both, CigaR spends 20k per bug while the baseline uses 695k tokens, a cost saving of 97. Our extensive experiments show that CigaR is a cost-effective <b>LLM-based</b> program repair tool that uses a low number of tokens to generate automatic patches.

{{</citation>}}


### (65/145) Empirically Exploring How Novices Write Software Models in Alloy (Ana Jovanovic et al., 2024)

{{<citation>}}

Ana Jovanovic, Allison Sullivan. (2024)  
**Empirically Exploring How Novices Write Software Models in Alloy**
<br/>
<button class="copy-to-clipboard" title="Empirically Exploring How Novices Write Software Models in Alloy" index=65>
  <span class="copy-to-clipboard-item">Copy Title<span>
</button>
<div class="toast toast-copied toast-index-65 align-items-center text-bg-secondary border-0 position-absolute top-0 end-0" role="alert" aria-live="assertive" aria-atomic="true">
  <div class="d-flex">
    <div class="toast-body">
      Copied!
    </div>
  </div>
</div>

---
Primary Category: cs.SE  
Categories: cs-SE, cs.SE  
Keyword Score: 10  
Keywords: Reasoning  
<a type="button" class="btn btn-outline-primary" href="http://arxiv.org/abs/2402.06624v1" target="_blank" >Paper Link</a>
<button type="button" class="btn btn-outline-primary download-pdf" url="https://arxiv.org/pdf/2402.06624v1.pdf" filename="2402.06624v1.pdf">Download PDF</button>

---


**ABSTRACT**  
Writing declarative models has numerous benefits, ranging from automated <b>reasoning</b> and correction of design-level properties before systems are built, to automated testing and debugging of their implementations after they are built. Alloy is a declarative modeling language that is well-suited for verifying system designs. A key strength of Alloy is its scenario-finding toolset, the Analyzer, which allows users to explore all valid scenarios that adhere to the model's constraints up to a user-provided scope. However, even with visualized scenarios, it is difficult to write correct Alloy models. To address this, a growing body of work explores different techniques for debugging Alloy models. In order to develop and evaluate these techniques in an effective manor, this paper presents an empirical study of over 97,000 models written by novice users trying to learn Alloy. We investigate how users write both correct and incorrect models in order to produce a comprehensive benchmark for future use as well as a series of observations to guide debugging and educational efforts for Alloy model development.

{{</citation>}}


### (66/145) SWITCH: An Exemplar for Evaluating Self-Adaptive ML-Enabled Systems (Arya Marda et al., 2024)

{{<citation>}}

Arya Marda, Shubham Kulkarni, Karthik Vaidhyanathan. (2024)  
**SWITCH: An Exemplar for Evaluating Self-Adaptive ML-Enabled Systems**
<br/>
<button class="copy-to-clipboard" title="SWITCH: An Exemplar for Evaluating Self-Adaptive ML-Enabled Systems" index=66>
  <span class="copy-to-clipboard-item">Copy Title<span>
</button>
<div class="toast toast-copied toast-index-66 align-items-center text-bg-secondary border-0 position-absolute top-0 end-0" role="alert" aria-live="assertive" aria-atomic="true">
  <div class="d-flex">
    <div class="toast-body">
      Copied!
    </div>
  </div>
</div>

---
Primary Category: cs.SE  
Categories: cs-SE, cs.SE  
Keyword Score: 10  
Keywords: Object Detection  
<a type="button" class="btn btn-outline-primary" href="http://arxiv.org/abs/2402.06351v1" target="_blank" >Paper Link</a>
<button type="button" class="btn btn-outline-primary download-pdf" url="https://arxiv.org/pdf/2402.06351v1.pdf" filename="2402.06351v1.pdf">Download PDF</button>

---


**ABSTRACT**  
Addressing runtime uncertainties in Machine Learning-Enabled Systems (MLS) is crucial for maintaining Quality of Service (QoS). The Machine Learning Model Balancer is a concept that addresses these uncertainties by facilitating dynamic ML model switching, showing promise in improving QoS in MLS. Leveraging this concept, this paper introduces SWITCH, an exemplar developed to enhance self-adaptive capabilities in such systems through dynamic model switching in runtime. SWITCH is designed as a comprehensive web service catering to a broad range of ML scenarios, with its implementation demonstrated through an <b>object</b> <b>detection</b> use case. SWITCH provides researchers with a flexible platform to apply and evaluate their ML model switching strategies, aiming to enhance QoS in MLS. SWITCH features advanced input handling, real-time data processing, and logging for adaptation metrics supplemented with an interactive real-time dashboard for enhancing system observability. This paper details SWITCH's architecture, self-adaptation strategies through ML model switching, and its empirical validation through a case study, illustrating its potential to improve QoS in MLS. By enabling a hands-on approach to explore adaptive behaviors in ML systems, SWITCH contributes a valuable tool to the SEAMS community for research into self-adaptive mechanisms for MLS and their practical applications.

{{</citation>}}


## cs.LG (29)



### (67/145) RQP-SGD: Differential Private Machine Learning through Noisy SGD and Randomized Quantization (Ce Feng et al., 2024)

{{<citation>}}

Ce Feng, Parv Venkitasubramaniam. (2024)  
**RQP-SGD: Differential Private Machine Learning through Noisy SGD and Randomized Quantization**
<br/>
<button class="copy-to-clipboard" title="RQP-SGD: Differential Private Machine Learning through Noisy SGD and Randomized Quantization" index=67>
  <span class="copy-to-clipboard-item">Copy Title<span>
</button>
<div class="toast toast-copied toast-index-67 align-items-center text-bg-secondary border-0 position-absolute top-0 end-0" role="alert" aria-live="assertive" aria-atomic="true">
  <div class="d-flex">
    <div class="toast-body">
      Copied!
    </div>
  </div>
</div>

---
Primary Category: cs.LG  
Categories: cs-AI, cs-CR, cs-LG, cs.LG  
Keyword Score: 50  
Keywords: Quantization, Quantization, Stochastic Gradient Descent, Stochastic Gradient Descent, Prompt  
<a type="button" class="btn btn-outline-primary" href="http://arxiv.org/abs/2402.06606v1" target="_blank" >Paper Link</a>
<button type="button" class="btn btn-outline-primary download-pdf" url="https://arxiv.org/pdf/2402.06606v1.pdf" filename="2402.06606v1.pdf">Download PDF</button>

---


**ABSTRACT**  
The rise of IoT devices has <b>prompted</b> the demand for deploying machine learning at-the-edge with real-time, efficient, and secure data processing. In this context, implementing machine learning (ML) models with real-valued weight parameters can prove to be impractical particularly for large models, and there is a need to train models with <b>quantized</b> discrete weights. At the same time, these low-dimensional models also need to preserve privacy of the underlying dataset. In this work, we present RQP-SGD, a new approach for privacy-preserving <b>quantization</b> to train machine learning models for low-memory ML-at-the-edge. This approach combines differentially private <b>stochastic</b> <b>gradient</b> <b>descent</b> (DP-SGD) with randomized <b>quantization,</b> providing a measurable privacy guarantee in machine learning. In particular, we study the utility convergence of implementing RQP-SGD on ML tasks with convex objectives and <b>quantization</b> constraints and demonstrate its efficacy over deterministic <b>quantization.</b> Through experiments conducted on two datasets, we show the practical effectiveness of RQP-SGD.

{{</citation>}}


### (68/145) Diffusion-ES: Gradient-free Planning with Diffusion for Autonomous Driving and Zero-Shot Instruction Following (Brian Yang et al., 2024)

{{<citation>}}

Brian Yang, Huangyuan Su, Nikolaos Gkanatsios, Tsung-Wei Ke, Ayush Jain, Jeff Schneider, Katerina Fragkiadaki. (2024)  
**Diffusion-ES: Gradient-free Planning with Diffusion for Autonomous Driving and Zero-Shot Instruction Following**
<br/>
<button class="copy-to-clipboard" title="Diffusion-ES: Gradient-free Planning with Diffusion for Autonomous Driving and Zero-Shot Instruction Following" index=68>
  <span class="copy-to-clipboard-item">Copy Title<span>
</button>
<div class="toast toast-copied toast-index-68 align-items-center text-bg-secondary border-0 position-absolute top-0 end-0" role="alert" aria-live="assertive" aria-atomic="true">
  <div class="d-flex">
    <div class="toast-body">
      Copied!
    </div>
  </div>
</div>

---
Primary Category: cs.LG  
Categories: cs-AI, cs-CL, cs-LG, cs-RO, cs.LG  
Keyword Score: 50  
Keywords: Few-shot, Zero-shot, Instruction Following, Large Language Model, Prompt  
<a type="button" class="btn btn-outline-primary" href="http://arxiv.org/abs/2402.06559v1" target="_blank" >Paper Link</a>
<button type="button" class="btn btn-outline-primary download-pdf" url="https://arxiv.org/pdf/2402.06559v1.pdf" filename="2402.06559v1.pdf">Download PDF</button>

---


**ABSTRACT**  
Diffusion models excel at modeling complex and multimodal trajectory distributions for decision-making and control. Reward-gradient guided denoising has been recently proposed to generate trajectories that maximize both a differentiable reward function and the likelihood under the data distribution captured by a diffusion model. Reward-gradient guided denoising requires a differentiable reward function fitted to both clean and noised samples, limiting its applicability as a general trajectory optimizer. In this paper, we propose DiffusionES, a method that combines gradient-free optimization with trajectory denoising to optimize black-box non-differentiable objectives while staying in the data manifold. Diffusion-ES samples trajectories during evolutionary search from a diffusion model and scores them using a black-box reward function. It mutates high-scoring trajectories using a truncated diffusion process that applies a small number of noising and denoising steps, allowing for much more efficient exploration of the solution space. We show that DiffusionES achieves state-of-the-art performance on nuPlan, an established closed-loop planning benchmark for autonomous driving. Diffusion-ES outperforms existing sampling-based planners, reactive deterministic or diffusion-based policies, and reward-gradient guidance. Additionally, we show that unlike prior guidance methods, our method can optimize non-differentiable language-shaped reward functions generated by <b>few-shot</b> <b>LLM</b> <b>prompting.</b> When guided by a human teacher that issues <b>instructions</b> <b>to</b> follow, our method can generate novel, highly complex behaviors, such as aggressive lane weaving, which are not present in the training data. This allows us to solve the hardest nuPlan scenarios which are beyond the capabilities of existing trajectory optimization methods and driving policies.

{{</citation>}}


### (69/145) V-STaR: Training Verifiers for Self-Taught Reasoners (Arian Hosseini et al., 2024)

{{<citation>}}

Arian Hosseini, Xingdi Yuan, Nikolay Malkin, Aaron Courville, Alessandro Sordoni, Rishabh Agarwal. (2024)  
**V-STaR: Training Verifiers for Self-Taught Reasoners**
<br/>
<button class="copy-to-clipboard" title="V-STaR: Training Verifiers for Self-Taught Reasoners" index=69>
  <span class="copy-to-clipboard-item">Copy Title<span>
</button>
<div class="toast toast-copied toast-index-69 align-items-center text-bg-secondary border-0 position-absolute top-0 end-0" role="alert" aria-live="assertive" aria-atomic="true">
  <div class="d-flex">
    <div class="toast-body">
      Copied!
    </div>
  </div>
</div>

---
Primary Category: cs.LG  
Categories: cs-AI, cs-CL, cs-LG, cs.LG  
Keyword Score: 50  
Keywords: Fine-tuning, Code Generation, Reasoning, Large Language Model, Large Language Model  
<a type="button" class="btn btn-outline-primary" href="http://arxiv.org/abs/2402.06457v1" target="_blank" >Paper Link</a>
<button type="button" class="btn btn-outline-primary download-pdf" url="https://arxiv.org/pdf/2402.06457v1.pdf" filename="2402.06457v1.pdf">Download PDF</button>

---


**ABSTRACT**  
Common self-improvement approaches for <b>large</b> <b>language</b> <b>models</b> <b>(LLMs),</b> such as STaR (Zelikman et al., 2022), iteratively <b>fine-tune</b> <b>LLMs</b> on self-generated solutions to improve their problem-solving ability. However, these approaches discard the <b>large</b> <b>amounts</b> <b>of</b> incorrect solutions generated during this process, potentially neglecting valuable information in such solutions. To address this shortcoming, we propose V-STaR that utilizes both the correct and incorrect solutions generated during the self-improvement process to train a verifier using DPO that judges correctness of model-generated solutions. This verifier is used at inference time to select one solution among many candidate solutions. Running V-STaR for multiple iterations results in progressively better reasoners and verifiers, delivering a 4% to 17% test accuracy improvement over existing self-improvement and verification approaches on common <b>code</b> <b>generation</b> and math <b>reasoning</b> benchmarks with LLaMA2 models.

{{</citation>}}


### (70/145) Distilling Morphology-Conditioned Hypernetworks for Efficient Universal Morphology Control (Zheng Xiong et al., 2024)

{{<citation>}}

Zheng Xiong, Risto Vuorio, Jacob Beck, Matthieu Zimmer, Kun Shao, Shimon Whiteson. (2024)  
**Distilling Morphology-Conditioned Hypernetworks for Efficient Universal Morphology Control**
<br/>
<button class="copy-to-clipboard" title="Distilling Morphology-Conditioned Hypernetworks for Efficient Universal Morphology Control" index=70>
  <span class="copy-to-clipboard-item">Copy Title<span>
</button>
<div class="toast toast-copied toast-index-70 align-items-center text-bg-secondary border-0 position-absolute top-0 end-0" role="alert" aria-live="assertive" aria-atomic="true">
  <div class="d-flex">
    <div class="toast-body">
      Copied!
    </div>
  </div>
</div>

---
Primary Category: cs.LG  
Categories: cs-LG, cs-RO, cs.LG  
Keyword Score: 40  
Keywords: Knowledge Distillation, Knowledge Distillation, Zero-shot, Transformer  
<a type="button" class="btn btn-outline-primary" href="http://arxiv.org/abs/2402.06570v1" target="_blank" >Paper Link</a>
<button type="button" class="btn btn-outline-primary download-pdf" url="https://arxiv.org/pdf/2402.06570v1.pdf" filename="2402.06570v1.pdf">Download PDF</button>

---


**ABSTRACT**  
Learning a universal policy across different robot morphologies can significantly improve learning efficiency and enable <b>zero-shot</b> generalization to unseen morphologies. However, learning a highly performant universal policy requires sophisticated architectures like <b>transformers</b> (TF) that have larger memory and computational cost than simpler multi-layer perceptrons (MLP). To achieve both good performance like TF and high efficiency like MLP at inference time, we propose HyperDistill, which consists of: (1) A morphology-conditioned hypernetwork (HN) that generates robot-wise MLP policies, and (2) A policy <b>distillation</b> approach that is essential for successful training. We show that on UNIMAL, a benchmark with hundreds of diverse morphologies, HyperDistill performs as well as a universal TF teacher policy on both training and unseen test robots, but reduces model size by 6-14 times, and computational cost by 67-160 times in different environments. Our analysis attributes the efficiency advantage of HyperDistill at inference time to knowledge decoupling, i.e., the ability to decouple inter-task and intra-task knowledge, a general principle that could also be applied to improve inference efficiency in other domains.

{{</citation>}}


### (71/145) Deceptive Path Planning via Reinforcement Learning with Graph Neural Networks (Michael Y. Fatemi et al., 2024)

{{<citation>}}

Michael Y. Fatemi, Wesley A. Suttle, Brian M. Sadler. (2024)  
**Deceptive Path Planning via Reinforcement Learning with Graph Neural Networks**
<br/>
<button class="copy-to-clipboard" title="Deceptive Path Planning via Reinforcement Learning with Graph Neural Networks" index=71>
  <span class="copy-to-clipboard-item">Copy Title<span>
</button>
<div class="toast toast-copied toast-index-71 align-items-center text-bg-secondary border-0 position-absolute top-0 end-0" role="alert" aria-live="assertive" aria-atomic="true">
  <div class="d-flex">
    <div class="toast-body">
      Copied!
    </div>
  </div>
</div>

---
Primary Category: cs.LG  
Categories: 68T05, cs-LG, cs.LG  
Keyword Score: 40  
Keywords: Graph Neural Network, Fine-tuning, Knowledge Distillation, Reinforcement Learning  
<a type="button" class="btn btn-outline-primary" href="http://arxiv.org/abs/2402.06552v1" target="_blank" >Paper Link</a>
<button type="button" class="btn btn-outline-primary download-pdf" url="https://arxiv.org/pdf/2402.06552v1.pdf" filename="2402.06552v1.pdf">Download PDF</button>

---


**ABSTRACT**  
Deceptive path planning (DPP) is the problem of designing a path that hides its true goal from an outside observer. Existing methods for DPP rely on unrealistic assumptions, such as global state observability and perfect model knowledge, and are typically problem-specific, meaning that even minor changes to a previously solved problem can force expensive computation of an entirely new solution. Given these drawbacks, such methods do not generalize to unseen problem instances, lack scalability to realistic problem sizes, and preclude both on-the-fly tunability of deception levels and real-time adaptivity to changing environments. In this paper, we propose a <b>reinforcement</b> <b>learning</b> (RL)-based scheme for training policies to perform DPP over arbitrary weighted <b>graphs</b> <b>that</b> <b>overcomes</b> these issues. The core of our approach is the introduction of a local perception model for the agent, a new state space representation <b>distilling</b> the key components of the DPP problem, the use of <b>graph</b> <b>neural</b> <b>network-based</b> policies to facilitate generalization and scaling, and the introduction of new deception bonuses that translate the deception objectives of classical methods to the RL setting. Through extensive experimentation we show that, without additional <b>fine-tuning,</b> at test time the resulting policies successfully generalize, scale, enjoy tunable levels of deception, and adapt in real-time to changes in the environment.

{{</citation>}}


### (72/145) Safe Active Learning for Time-Series Modeling with Gaussian Processes (Christoph Zimmer et al., 2024)

{{<citation>}}

Christoph Zimmer, Mona Meister, Duy Nguyen-Tuong. (2024)  
**Safe Active Learning for Time-Series Modeling with Gaussian Processes**
<br/>
<button class="copy-to-clipboard" title="Safe Active Learning for Time-Series Modeling with Gaussian Processes" index=72>
  <span class="copy-to-clipboard-item">Copy Title<span>
</button>
<div class="toast toast-copied toast-index-72 align-items-center text-bg-secondary border-0 position-absolute top-0 end-0" role="alert" aria-live="assertive" aria-atomic="true">
  <div class="d-flex">
    <div class="toast-body">
      Copied!
    </div>
  </div>
</div>

---
Primary Category: cs.LG  
Categories: cs-LG, cs.LG, stat-ML  
Keyword Score: 40  
Keywords: Active Learning, Gaussian Process, Simulation, Simulator  
<a type="button" class="btn btn-outline-primary" href="http://arxiv.org/abs/2402.06276v1" target="_blank" >Paper Link</a>
<button type="button" class="btn btn-outline-primary download-pdf" url="https://arxiv.org/pdf/2402.06276v1.pdf" filename="2402.06276v1.pdf">Download PDF</button>

---


**ABSTRACT**  
Learning time-series models is useful for many applications, such as <b>simulation</b> and forecasting. In this study, we consider the problem of actively learning time-series models while taking given safety constraints into account. For time-series modeling we employ a <b>Gaussian</b> <b>process</b> with a nonlinear exogenous input structure. The proposed approach generates data appropriate for time series model learning, i.e. input and output trajectories, by dynamically exploring the input space. The approach parametrizes the input trajectory as consecutive trajectory sections, which are determined stepwise given safety requirements and past observations. We analyze the proposed algorithm and evaluate it empirically on a technical application. The results show the effectiveness of our approach in a realistic technical use case.

{{</citation>}}


### (73/145) Studious Bob Fight Back Against Jailbreaking via Prompt Adversarial Tuning (Yichuan Mo et al., 2024)

{{<citation>}}

Yichuan Mo, Yuji Wang, Zeming Wei, Yisen Wang. (2024)  
**Studious Bob Fight Back Against Jailbreaking via Prompt Adversarial Tuning**
<br/>
<button class="copy-to-clipboard" title="Studious Bob Fight Back Against Jailbreaking via Prompt Adversarial Tuning" index=73>
  <span class="copy-to-clipboard-item">Copy Title<span>
</button>
<div class="toast toast-copied toast-index-73 align-items-center text-bg-secondary border-0 position-absolute top-0 end-0" role="alert" aria-live="assertive" aria-atomic="true">
  <div class="d-flex">
    <div class="toast-body">
      Copied!
    </div>
  </div>
</div>

---
Primary Category: cs.LG  
Categories: cs-AI, cs-CL, cs-CR, cs-LG, cs.LG  
Keyword Score: 40  
Keywords: Adversarial Learning, Large Language Model, Large Language Model, Prompt  
<a type="button" class="btn btn-outline-primary" href="http://arxiv.org/abs/2402.06255v1" target="_blank" >Paper Link</a>
<button type="button" class="btn btn-outline-primary download-pdf" url="https://arxiv.org/pdf/2402.06255v1.pdf" filename="2402.06255v1.pdf">Download PDF</button>

---


**ABSTRACT**  
Although <b>Large</b> <b>Language</b> <b>Models</b> <b>(LLMs)</b> have achieved tremendous success in various applications, they are also susceptible to certain <b>prompts</b> that can induce them to bypass built-in safety measures and provide dangerous or illegal content, a phenomenon known as jailbreak. To protect <b>LLMs</b> from producing harmful information, various defense strategies are proposed, with most focusing on content filtering or <b>adversarial</b> <b>training</b> of models. In this paper, we propose an approach named <b>Prompt</b> <b>Adversarial</b> <b>Tuning</b> (PAT) to train a defense control mechanism, which is then embedded as a prefix to user <b>prompts</b> to implement our defense strategy. We design a training process similar to <b>adversarial</b> <b>training</b> to achieve our optimized goal, alternating between updating attack and defense controls. To our knowledge, we are the first to implement defense from the perspective of <b>prompt</b> tuning. Once employed, our method will hardly impact the operational efficiency of <b>LLMs.</b> Experiments show that our method is effective in both black-box and white-box settings, reducing the success rate of advanced attacks to nearly 0 while maintaining the benign answer rate of 80% to simple benign questions. Our work might potentially chart a new perspective for future explorations in <b>LLM</b> security.

{{</citation>}}


### (74/145) Feedback Loops With Language Models Drive In-Context Reward Hacking (Alexander Pan et al., 2024)

{{<citation>}}

Alexander Pan, Erik Jones, Meena Jagadeesan, Jacob Steinhardt. (2024)  
**Feedback Loops With Language Models Drive In-Context Reward Hacking**
<br/>
<button class="copy-to-clipboard" title="Feedback Loops With Language Models Drive In-Context Reward Hacking" index=74>
  <span class="copy-to-clipboard-item">Copy Title<span>
</button>
<div class="toast toast-copied toast-index-74 align-items-center text-bg-secondary border-0 position-absolute top-0 end-0" role="alert" aria-live="assertive" aria-atomic="true">
  <div class="d-flex">
    <div class="toast-body">
      Copied!
    </div>
  </div>
</div>

---
Primary Category: cs.LG  
Categories: cs-AI, cs-CL, cs-LG, cs.LG  
Keyword Score: 30  
Keywords: Recommendation, In-context Learning, Large Language Model  
<a type="button" class="btn btn-outline-primary" href="http://arxiv.org/abs/2402.06627v1" target="_blank" >Paper Link</a>
<button type="button" class="btn btn-outline-primary download-pdf" url="https://arxiv.org/pdf/2402.06627v1.pdf" filename="2402.06627v1.pdf">Download PDF</button>

---


**ABSTRACT**  
Language models influence the external world: they query APIs that read and write to web pages, generate content that shapes human behavior, and run system commands as autonomous agents. These interactions form feedback loops: <b>LLM</b> outputs affect the world, which in turn affect subsequent <b>LLM</b> outputs. In this work, we show that feedback loops can cause <b>in-context</b> reward hacking (ICRH), where the <b>LLM</b> at test-time optimizes a (potentially implicit) objective but creates negative side effects in the process. For example, consider an <b>LLM</b> agent deployed to increase Twitter engagement; the <b>LLM</b> may retrieve its previous tweets into the context window and make them more controversial, increasing engagement but also toxicity. We identify and study two processes that lead to ICRH: output-refinement and policy-refinement. For these processes, evaluations on static datasets are insufficient -- they miss the feedback effects and thus cannot capture the most harmful behavior. In response, we provide three <b>recommendations</b> for evaluation to capture more instances of ICRH. As AI development accelerates, the effects of feedback loops will proliferate, increasing the need to understand their role in shaping <b>LLM</b> behavior.

{{</citation>}}


### (75/145) The Deep Equilibrium Algorithmic Reasoner (Dobrik Georgiev et al., 2024)

{{<citation>}}

Dobrik Georgiev, Pietro LiÃ², Davide Buffelli. (2024)  
**The Deep Equilibrium Algorithmic Reasoner**
<br/>
<button class="copy-to-clipboard" title="The Deep Equilibrium Algorithmic Reasoner" index=75>
  <span class="copy-to-clipboard-item">Copy Title<span>
</button>
<div class="toast toast-copied toast-index-75 align-items-center text-bg-secondary border-0 position-absolute top-0 end-0" role="alert" aria-live="assertive" aria-atomic="true">
  <div class="d-flex">
    <div class="toast-body">
      Copied!
    </div>
  </div>
</div>

---
Primary Category: cs.LG  
Categories: cs-LG, cs.LG  
Keyword Score: 30  
Keywords: Graph Neural Network, Graph Neural Network, Reasoning  
<a type="button" class="btn btn-outline-primary" href="http://arxiv.org/abs/2402.06445v1" target="_blank" >Paper Link</a>
<button type="button" class="btn btn-outline-primary download-pdf" url="https://arxiv.org/pdf/2402.06445v1.pdf" filename="2402.06445v1.pdf">Download PDF</button>

---


**ABSTRACT**  
Recent work on neural algorithmic <b>reasoning</b> has demonstrated that <b>graph</b> <b>neural</b> <b>networks</b> <b>(GNNs)</b> could learn to execute classical algorithms. Doing so, however, has always used a recurrent architecture, where each iteration of the <b>GNN</b> aligns with an algorithm's iteration. Since an algorithm's solution is often an equilibrium, we conjecture and empirically validate that one can train a network to solve algorithmic problems by directly finding the equilibrium. Note that this does not require matching each <b>GNN</b> iteration with a step of the algorithm.

{{</citation>}}


### (76/145) Trust the Process: Zero-Knowledge Machine Learning to Enhance Trust in Generative AI Interactions (Bianca-Mihaela Ganescu et al., 2024)

{{<citation>}}

Bianca-Mihaela Ganescu, Jonathan Passerat-Palmbach. (2024)  
**Trust the Process: Zero-Knowledge Machine Learning to Enhance Trust in Generative AI Interactions**
<br/>
<button class="copy-to-clipboard" title="Trust the Process: Zero-Knowledge Machine Learning to Enhance Trust in Generative AI Interactions" index=76>
  <span class="copy-to-clipboard-item">Copy Title<span>
</button>
<div class="toast toast-copied toast-index-76 align-items-center text-bg-secondary border-0 position-absolute top-0 end-0" role="alert" aria-live="assertive" aria-atomic="true">
  <div class="d-flex">
    <div class="toast-body">
      Copied!
    </div>
  </div>
</div>

---
Primary Category: cs.LG  
Categories: cs-CR, cs-LG, cs.LG  
Keyword Score: 30  
Keywords: Fairness, Generative AI, Transformer  
<a type="button" class="btn btn-outline-primary" href="http://arxiv.org/abs/2402.06414v1" target="_blank" >Paper Link</a>
<button type="button" class="btn btn-outline-primary download-pdf" url="https://arxiv.org/pdf/2402.06414v1.pdf" filename="2402.06414v1.pdf">Download PDF</button>

---


**ABSTRACT**  
<b>Generative</b> <b>AI,</b> exemplified by models like <b>transformers,</b> has opened up new possibilities in various domains but also raised concerns about <b>fairness,</b> transparency and reliability, especially in fields like medicine and law. This paper emphasizes the urgency of ensuring <b>fairness</b> and quality in these domains through <b>generative</b> <b>AI.</b> It explores using cryptographic techniques, particularly Zero-Knowledge Proofs (ZKPs), to address concerns regarding performance <b>fairness</b> and accuracy while protecting model privacy. Applying ZKPs to Machine Learning models, known as ZKML (Zero-Knowledge Machine Learning), enables independent validation of AI-generated content without revealing sensitive model information, promoting transparency and trust. ZKML enhances AI <b>fairness</b> by providing cryptographic audit trails for model predictions and ensuring uniform performance across users. We introduce snarkGPT, a practical ZKML implementation for <b>transformers,</b> to empower users to verify output accuracy and quality while preserving model privacy. We present a series of empirical results studying snarkGPT's scalability and performance to assess the feasibility and challenges of adopting a ZKML-powered approach to capture quality and performance <b>fairness</b> problems in <b>generative</b> <b>AI</b> models.

{{</citation>}}


### (77/145) Hierarchical Transformers are Efficient Meta-Reinforcement Learners (Gresa Shala et al., 2024)

{{<citation>}}

Gresa Shala, AndrÃ© Biedenkapp, Josif Grabocka. (2024)  
**Hierarchical Transformers are Efficient Meta-Reinforcement Learners**
<br/>
<button class="copy-to-clipboard" title="Hierarchical Transformers are Efficient Meta-Reinforcement Learners" index=77>
  <span class="copy-to-clipboard-item">Copy Title<span>
</button>
<div class="toast toast-copied toast-index-77 align-items-center text-bg-secondary border-0 position-absolute top-0 end-0" role="alert" aria-live="assertive" aria-atomic="true">
  <div class="d-flex">
    <div class="toast-body">
      Copied!
    </div>
  </div>
</div>

---
Primary Category: cs.LG  
Categories: cs-AI, cs-LG, cs.LG  
Keyword Score: 30  
Keywords: Knowledge Distillation, Reinforcement Learning, Transformer  
<a type="button" class="btn btn-outline-primary" href="http://arxiv.org/abs/2402.06402v1" target="_blank" >Paper Link</a>
<button type="button" class="btn btn-outline-primary download-pdf" url="https://arxiv.org/pdf/2402.06402v1.pdf" filename="2402.06402v1.pdf">Download PDF</button>

---


**ABSTRACT**  
We introduce Hierarchical <b>Transformers</b> for Meta-Reinforcement Learning (HTrMRL), a powerful online meta-reinforcement learning approach. HTrMRL aims to address the challenge of enabling <b>reinforcement</b> <b>learning</b> agents to perform effectively in previously unseen tasks. We demonstrate how past episodes serve as a rich source of information, which our model effectively <b>distills</b> and applies to new contexts. Our learned algorithm is capable of outperforming the previous state-of-the-art and provides more efficient meta-training while significantly improving generalization capabilities. Experimental results, obtained across various simulated tasks of the Meta-World Benchmark, indicate a significant improvement in learning efficiency and adaptability compared to the state-of-the-art on a variety of tasks. Our approach not only enhances the agent's ability to generalize from limited data but also paves the way for more robust and versatile AI systems.

{{</citation>}}


### (78/145) TEE4EHR: Transformer Event Encoder for Better Representation Learning in Electronic Health Records (Hojjat Karami et al., 2024)

{{<citation>}}

Hojjat Karami, David Atienza, Anisoara Ionescu. (2024)  
**TEE4EHR: Transformer Event Encoder for Better Representation Learning in Electronic Health Records**
<br/>
<button class="copy-to-clipboard" title="TEE4EHR: Transformer Event Encoder for Better Representation Learning in Electronic Health Records" index=78>
  <span class="copy-to-clipboard-item">Copy Title<span>
</button>
<div class="toast toast-copied toast-index-78 align-items-center text-bg-secondary border-0 position-absolute top-0 end-0" role="alert" aria-live="assertive" aria-atomic="true">
  <div class="d-flex">
    <div class="toast-body">
      Copied!
    </div>
  </div>
</div>

---
Primary Category: cs.LG  
Categories: cs-LG, cs.LG  
Keyword Score: 30  
Keywords: Self-supervised Learning, Self-supervised Learning, Transformer  
<a type="button" class="btn btn-outline-primary" href="http://arxiv.org/abs/2402.06367v1" target="_blank" >Paper Link</a>
<button type="button" class="btn btn-outline-primary download-pdf" url="https://arxiv.org/pdf/2402.06367v1.pdf" filename="2402.06367v1.pdf">Download PDF</button>

---


**ABSTRACT**  
Irregular sampling of time series in electronic health records (EHRs) is one of the main challenges for developing machine learning models. Additionally, the pattern of missing data in certain clinical variables is not at random but depends on the decisions of clinicians and the state of the patient. Point process is a mathematical framework for analyzing event sequence data that is consistent with irregular sampling patterns. Our model, TEE4EHR, is a <b>transformer</b> event encoder (TEE) with point process loss that encodes the pattern of laboratory tests in EHRs. The utility of our TEE has been investigated in a variety of benchmark event sequence datasets. Additionally, we conduct experiments on two real-world EHR databases to provide a more comprehensive evaluation of our model. Firstly, in a <b>self-supervised</b> <b>learning</b> approach, the TEE is jointly learned with an existing attention-based deep neural network which gives superior performance in negative log-likelihood and future event prediction. Besides, we propose an algorithm for aggregating attention weights that can reveal the interaction between the events. Secondly, we transfer and freeze the learned TEE to the downstream task for the outcome prediction, where it outperforms state-of-the-art models for handling irregularly sampled time series. Furthermore, our results demonstrate that our approach can improve representation learning in EHRs and can be useful for clinical prediction tasks.

{{</citation>}}


### (79/145) Premier-TACO: Pretraining Multitask Representation via Temporal Action-Driven Contrastive Loss (Ruijie Zheng et al., 2024)

{{<citation>}}

Ruijie Zheng, Yongyuan Liang, Xiyao Wang, Shuang Ma, Hal DaumÃ© III, Huazhe Xu, John Langford, Praveen Palanisamy, Kalyan Shankar Basu, Furong Huang. (2024)  
**Premier-TACO: Pretraining Multitask Representation via Temporal Action-Driven Contrastive Loss**
<br/>
<button class="copy-to-clipboard" title="Premier-TACO: Pretraining Multitask Representation via Temporal Action-Driven Contrastive Loss" index=79>
  <span class="copy-to-clipboard-item">Copy Title<span>
</button>
<div class="toast toast-copied toast-index-79 align-items-center text-bg-secondary border-0 position-absolute top-0 end-0" role="alert" aria-live="assertive" aria-atomic="true">
  <div class="d-flex">
    <div class="toast-body">
      Copied!
    </div>
  </div>
</div>

---
Primary Category: cs.LG  
Categories: cs-AI, cs-LG, cs-RO, cs.LG  
Keyword Score: 30  
Keywords: Contrastive Learning, Few-shot, Fine-tuning  
<a type="button" class="btn btn-outline-primary" href="http://arxiv.org/abs/2402.06187v1" target="_blank" >Paper Link</a>
<button type="button" class="btn btn-outline-primary download-pdf" url="https://arxiv.org/pdf/2402.06187v1.pdf" filename="2402.06187v1.pdf">Download PDF</button>

---


**ABSTRACT**  
We present Premier-TACO, a multitask feature representation learning approach designed to improve <b>few-shot</b> policy learning efficiency in sequential decision-making tasks. Premier-TACO leverages a subset of multitask offline datasets for pretraining a general feature representation, which captures critical environmental dynamics and is <b>fine-tuned</b> using minimal expert demonstrations. It advances the temporal action <b>contrastive</b> <b>learning</b> (TACO) objective, known for state-of-the-art results in visual control tasks, by incorporating a novel negative example sampling strategy. This strategy is crucial in significantly boosting TACO's computational efficiency, making large-scale multitask offline pretraining feasible. Our extensive empirical evaluation in a diverse set of continuous control benchmarks including Deepmind Control Suite, MetaWorld, and LIBERO demonstrate Premier-TACO's effectiveness in pretraining visual representations, significantly enhancing <b>few-shot</b> imitation learning of novel tasks. Our code, pretraining data, as well as pretrained model checkpoints will be released at https://github.com/PremierTACO/premier-taco.

{{</citation>}}


### (80/145) Jointly Learning Representations for Map Entities via Heterogeneous Graph Contrastive Learning (Jiawei Jiang et al., 2024)

{{<citation>}}

Jiawei Jiang, Yifan Yang, Jingyuan Wang, Junjie Wu. (2024)  
**Jointly Learning Representations for Map Entities via Heterogeneous Graph Contrastive Learning**
<br/>
<button class="copy-to-clipboard" title="Jointly Learning Representations for Map Entities via Heterogeneous Graph Contrastive Learning" index=80>
  <span class="copy-to-clipboard-item">Copy Title<span>
</button>
<div class="toast toast-copied toast-index-80 align-items-center text-bg-secondary border-0 position-absolute top-0 end-0" role="alert" aria-live="assertive" aria-atomic="true">
  <div class="d-flex">
    <div class="toast-body">
      Copied!
    </div>
  </div>
</div>

---
Primary Category: cs.LG  
Categories: cs-LG, cs.LG  
Keyword Score: 30  
Keywords: Contrastive Learning, Self-supervised Learning, Transformer  
<a type="button" class="btn btn-outline-primary" href="http://arxiv.org/abs/2402.06135v1" target="_blank" >Paper Link</a>
<button type="button" class="btn btn-outline-primary download-pdf" url="https://arxiv.org/pdf/2402.06135v1.pdf" filename="2402.06135v1.pdf">Download PDF</button>

---


**ABSTRACT**  
The electronic map plays a crucial role in geographic information systems, serving various urban managerial scenarios and daily life services. Developing effective Map Entity Representation Learning (MERL) methods is crucial to extracting embedding information from electronic maps and converting map entities into representation vectors for downstream applications. However, existing MERL methods typically focus on one specific category of map entities, such as POIs, road segments, or land parcels, which is insufficient for real-world diverse map-based applications and might lose latent structural and semantic information interacting between entities of different types. Moreover, using representations generated by separate models for different map entities can introduce inconsistencies. Motivated by this, we propose a novel method named HOME-GCL for learning representations of multiple categories of map entities. Our approach utilizes a heterogeneous map entity graph (HOME graph) that integrates both road segments and land parcels into a unified framework. A HOME encoder with parcel-segment joint feature encoding and heterogeneous graph <b>transformer</b> is then deliberately designed to convert segments and parcels into representation vectors. Moreover, we introduce two types of <b>contrastive</b> <b>learning</b> tasks, namely intra-entity and inter-entity tasks, to train the encoder in a <b>self-supervised</b> manner. Extensive experiments on three large-scale datasets covering road segment-based, land parcel-based, and trajectory-based tasks demonstrate the superiority of our approach. To the best of our knowledge, HOME-GCL is the first attempt to jointly learn representations for road segments and land parcels using a unified model.

{{</citation>}}


### (81/145) Rethinking Node-wise Propagation for Large-scale Graph Learning (Xunkai Li et al., 2024)

{{<citation>}}

Xunkai Li, Jingyuan Ma, Zhengyu Wu, Daohan Su, Wentao Zhang, Rong-Hua Li, Guoren Wang. (2024)  
**Rethinking Node-wise Propagation for Large-scale Graph Learning**
<br/>
<button class="copy-to-clipboard" title="Rethinking Node-wise Propagation for Large-scale Graph Learning" index=81>
  <span class="copy-to-clipboard-item">Copy Title<span>
</button>
<div class="toast toast-copied toast-index-81 align-items-center text-bg-secondary border-0 position-absolute top-0 end-0" role="alert" aria-live="assertive" aria-atomic="true">
  <div class="d-flex">
    <div class="toast-body">
      Copied!
    </div>
  </div>
</div>

---
Primary Category: cs.LG  
Categories: cs-AI, cs-LG, cs-SI, cs.LG  
Keyword Score: 30  
Keywords: Node Classification, Graph Neural Network, Graph Neural Network  
<a type="button" class="btn btn-outline-primary" href="http://arxiv.org/abs/2402.06128v1" target="_blank" >Paper Link</a>
<button type="button" class="btn btn-outline-primary download-pdf" url="https://arxiv.org/pdf/2402.06128v1.pdf" filename="2402.06128v1.pdf">Download PDF</button>

---


**ABSTRACT**  
Scalable <b>graph</b> <b>neural</b> <b>networks</b> <b>(GNNs)</b> have emerged as a promising technique, which exhibits superior predictive performance and high running efficiency across numerous large-scale <b>graph-based</b> <b>web</b> <b>applications.</b> However, (i) Most scalable <b>GNNs</b> tend to treat all <b>nodes</b> <b>in</b> <b>graphs</b> <b>with</b> <b>the</b> same propagation rules, neglecting their topological uniqueness; (ii) Existing <b>node-wise</b> <b>propagation</b> optimization strategies are insufficient on web-scale <b>graphs</b> <b>with</b> <b>intricate</b> topology, where a full portrayal of <b>nodes'</b> <b>local</b> properties is required. Intuitively, different <b>nodes</b> <b>in</b> web-scale <b>graphs</b> <b>possess</b> <b>distinct</b> topological roles, and therefore propagating them indiscriminately or neglect local contexts may compromise the quality of <b>node</b> <b>representations.</b> This intricate topology in web-scale <b>graphs</b> <b>cannot</b> <b>be</b> matched by small-scale scenarios. To address the above issues, we propose \textbf{A}daptive \textbf{T}opology-aware \textbf{P}ropagation (ATP), which reduces potential high-bias propagation and extracts structural patterns of each <b>node</b> <b>in</b> a scalable manner to improve running efficiency and predictive performance. Remarkably, ATP is crafted to be a plug-and-play <b>node-wise</b> <b>propagation</b> optimization strategy, allowing for offline execution independent of the <b>graph</b> <b>learning</b> <b>process</b> in a new perspective. Therefore, this approach can be seamlessly integrated into most scalable <b>GNNs</b> while remain orthogonal to existing <b>node-wise</b> <b>propagation</b> optimization strategies. Extensive experiments on 12 datasets, including the most representative large-scale ogbn-papers100M, have demonstrated the effectiveness of ATP. Specifically, ATP has proven to be efficient in improving the performance of prevalent scalable <b>GNNs</b> for semi-supervised <b>node</b> <b>classification</b> while addressing redundant computational costs.

{{</citation>}}


### (82/145) AI enhanced data assimilation and uncertainty quantification applied to Geological Carbon Storage (G. S. Seabra et al., 2024)

{{<citation>}}

G. S. Seabra, N. T. MÃ¼cke, V. L. S. Silva, D. Voskov, F. Vossepoel. (2024)  
**AI enhanced data assimilation and uncertainty quantification applied to Geological Carbon Storage**
<br/>
<button class="copy-to-clipboard" title="AI enhanced data assimilation and uncertainty quantification applied to Geological Carbon Storage" index=82>
  <span class="copy-to-clipboard-item">Copy Title<span>
</button>
<div class="toast toast-copied toast-index-82 align-items-center text-bg-secondary border-0 position-absolute top-0 end-0" role="alert" aria-live="assertive" aria-atomic="true">
  <div class="d-flex">
    <div class="toast-body">
      Copied!
    </div>
  </div>
</div>

---
Primary Category: cs.LG  
Categories: J-2, cs-LG, cs.LG  
Keyword Score: 30  
Keywords: Simulation, Simulator, Transformer  
<a type="button" class="btn btn-outline-primary" href="http://arxiv.org/abs/2402.06110v1" target="_blank" >Paper Link</a>
<button type="button" class="btn btn-outline-primary download-pdf" url="https://arxiv.org/pdf/2402.06110v1.pdf" filename="2402.06110v1.pdf">Download PDF</button>

---


**ABSTRACT**  
This study investigates the integration of machine learning (ML) and data assimilation (DA) techniques, focusing on implementing surrogate models for Geological Carbon Storage (GCS) projects while maintaining high fidelity physical results in posterior states. Initially, we evaluate the surrogate modeling capability of two distinct machine learning models, Fourier Neural Operators (FNOs) and <b>Transformer</b> UNet (T-UNet), in the context of CO$_2$ injection <b>simulations</b> within channelized reservoirs. We introduce the Surrogate-based hybrid ESMDA (SH-ESMDA), an adaptation of the traditional Ensemble Smoother with Multiple Data Assimilation (ESMDA). This method uses FNOs and T-UNet as surrogate models and has the potential to make the standard ESMDA process at least 50% faster or more, depending on the number of assimilation steps. Additionally, we introduce Surrogate-based Hybrid RML (SH-RML), a variational data assimilation approach that relies on the randomized maximum likelihood (RML) where both the FNO and the T-UNet enable the computation of gradients for the optimization of the objective function, and a high-fidelity model is employed for the computation of the posterior states. Our comparative analyses show that SH-RML offers better uncertainty quantification compared to conventional ESMDA for the case study.

{{</citation>}}


### (83/145) Fairness of Exposure in Online Restless Multi-armed Bandits (Archit Sood et al., 2024)

{{<citation>}}

Archit Sood, Shweta Jain, Sujit Gujar. (2024)  
**Fairness of Exposure in Online Restless Multi-armed Bandits**
<br/>
<button class="copy-to-clipboard" title="Fairness of Exposure in Online Restless Multi-armed Bandits" index=83>
  <span class="copy-to-clipboard-item">Copy Title<span>
</button>
<div class="toast toast-copied toast-index-83 align-items-center text-bg-secondary border-0 position-absolute top-0 end-0" role="alert" aria-live="assertive" aria-atomic="true">
  <div class="d-flex">
    <div class="toast-body">
      Copied!
    </div>
  </div>
</div>

---
Primary Category: cs.LG  
Categories: cs-LG, cs.LG, stat-ML  
Keyword Score: 20  
Keywords: Bandit Algorithm, Fairness  
<a type="button" class="btn btn-outline-primary" href="http://arxiv.org/abs/2402.06348v1" target="_blank" >Paper Link</a>
<button type="button" class="btn btn-outline-primary download-pdf" url="https://arxiv.org/pdf/2402.06348v1.pdf" filename="2402.06348v1.pdf">Download PDF</button>

---


**ABSTRACT**  
Restless multi-armed <b>bandits</b> (RMABs) generalize the multi-armed <b>bandits</b> where each arm exhibits Markovian behavior and transitions according to their transition dynamics. Solutions to RMAB exist for both offline and online cases. However, they do not consider the distribution of pulls among the arms. Studies have shown that optimal policies lead to unfairness, where some arms are not exposed enough. Existing works in <b>fairness</b> in RMABs focus heavily on the offline case, which diminishes their application in real-world scenarios where the environment is largely unknown. In the online scenario, we propose the first fair RMAB framework, where each arm receives pulls in proportion to its merit. We define the merit of an arm as a function of its stationary reward distribution. We prove that our algorithm achieves sublinear <b>fairness</b> regret in the single pull case $O(\sqrt{T\ln T})$, with $T$ being the total number of episodes. Empirically, we show that our algorithm performs well in the multi-pull scenario as well.

{{</citation>}}


### (84/145) How Uniform Random Weights Induce Non-uniform Bias: Typical Interpolating Neural Networks Generalize with Narrow Teachers (Gon Buzaglo et al., 2024)

{{<citation>}}

Gon Buzaglo, Itamar Harel, Mor Shpigel Nacson, Alon Brutzkus, Nathan Srebro, Daniel Soudry. (2024)  
**How Uniform Random Weights Induce Non-uniform Bias: Typical Interpolating Neural Networks Generalize with Narrow Teachers**
<br/>
<button class="copy-to-clipboard" title="How Uniform Random Weights Induce Non-uniform Bias: Typical Interpolating Neural Networks Generalize with Narrow Teachers" index=84>
  <span class="copy-to-clipboard-item">Copy Title<span>
</button>
<div class="toast toast-copied toast-index-84 align-items-center text-bg-secondary border-0 position-absolute top-0 end-0" role="alert" aria-live="assertive" aria-atomic="true">
  <div class="d-flex">
    <div class="toast-body">
      Copied!
    </div>
  </div>
</div>

---
Primary Category: cs.LG  
Categories: cs-LG, cs.LG, stat-ML  
Keyword Score: 20  
Keywords: Stochastic Gradient Descent, Stochastic Gradient Descent  
<a type="button" class="btn btn-outline-primary" href="http://arxiv.org/abs/2402.06323v1" target="_blank" >Paper Link</a>
<button type="button" class="btn btn-outline-primary download-pdf" url="https://arxiv.org/pdf/2402.06323v1.pdf" filename="2402.06323v1.pdf">Download PDF</button>

---


**ABSTRACT**  
Background. A main theoretical puzzle is why over-parameterized Neural Networks (NNs) generalize well when trained to zero loss (i.e., so they interpolate the data). Usually, the NN is trained with <b>Stochastic</b> <b>Gradient</b> <b>Descent</b> <b>(SGD)</b> or one of its variants. However, recent empirical work examined the generalization of a random NN that interpolates the data: the NN was sampled from a seemingly uniform prior over the parameters, conditioned on that the NN perfectly classifying the training set. Interestingly, such a NN sample typically generalized as well as <b>SGD-trained</b> NNs. Contributions. We prove that such a random NN interpolator typically generalizes well if there exists an underlying narrow ``teacher NN" that agrees with the labels. Specifically, we show that such a `flat' prior over the NN parametrization induces a rich prior over the NN functions, due to the redundancy in the NN structure. In particular, this creates a bias towards simpler functions, which require less relevant parameters to represent -- enabling learning with a sample complexity approximately proportional to the complexity of the teacher (roughly, the number of non-redundant parameters), rather than the student's.

{{</citation>}}


### (85/145) TimEHR: Image-based Time Series Generation for Electronic Health Records (Hojjat Karami et al., 2024)

{{<citation>}}

Hojjat Karami, Mary-Anne Hartley, David Atienza, Anisoara Ionescu. (2024)  
**TimEHR: Image-based Time Series Generation for Electronic Health Records**
<br/>
<button class="copy-to-clipboard" title="TimEHR: Image-based Time Series Generation for Electronic Health Records" index=85>
  <span class="copy-to-clipboard-item">Copy Title<span>
</button>
<div class="toast toast-copied toast-index-85 align-items-center text-bg-secondary border-0 position-absolute top-0 end-0" role="alert" aria-live="assertive" aria-atomic="true">
  <div class="d-flex">
    <div class="toast-body">
      Copied!
    </div>
  </div>
</div>

---
Primary Category: cs.LG  
Categories: cs-LG, cs.LG  
Keyword Score: 20  
Keywords: Generative Adversarial Network, Generative Adversarial Network  
<a type="button" class="btn btn-outline-primary" href="http://arxiv.org/abs/2402.06318v1" target="_blank" >Paper Link</a>
<button type="button" class="btn btn-outline-primary download-pdf" url="https://arxiv.org/pdf/2402.06318v1.pdf" filename="2402.06318v1.pdf">Download PDF</button>

---


**ABSTRACT**  
Time series in Electronic Health Records (EHRs) present unique challenges for <b>generative</b> <b>models,</b> <b>such</b> as irregular sampling, missing values, and high dimensionality. In this paper, we propose a novel <b>generative</b> <b>adversarial</b> <b>network</b> <b>(GAN)</b> model, TimEHR, to generate time series data from EHRs. In particular, TimEHR treats time series as images and is based on two conditional <b>GANs.</b> The first <b>GAN</b> generates missingness patterns, and the second <b>GAN</b> generates time series values based on the missingness pattern. Experimental results on three real-world EHR datasets show that TimEHR outperforms state-of-the-art methods in terms of fidelity, utility, and privacy metrics.

{{</citation>}}


### (86/145) Iterated Denoising Energy Matching for Sampling from Boltzmann Densities (Tara Akhound-Sadegh et al., 2024)

{{<citation>}}

Tara Akhound-Sadegh, Jarrid Rector-Brooks, Avishek Joey Bose, Sarthak Mittal, Pablo Lemos, Cheng-Hao Liu, Marcin Sendera, Siamak Ravanbakhsh, Gauthier Gidel, Yoshua Bengio, Nikolay Malkin, Alexander Tong. (2024)  
**Iterated Denoising Energy Matching for Sampling from Boltzmann Densities**
<br/>
<button class="copy-to-clipboard" title="Iterated Denoising Energy Matching for Sampling from Boltzmann Densities" index=86>
  <span class="copy-to-clipboard-item">Copy Title<span>
</button>
<div class="toast toast-copied toast-index-86 align-items-center text-bg-secondary border-0 position-absolute top-0 end-0" role="alert" aria-live="assertive" aria-atomic="true">
  <div class="d-flex">
    <div class="toast-body">
      Copied!
    </div>
  </div>
</div>

---
Primary Category: cs.LG  
Categories: cs-LG, cs.LG, stat-ML  
Keyword Score: 20  
Keywords: Simulation, Simulator  
<a type="button" class="btn btn-outline-primary" href="http://arxiv.org/abs/2402.06121v1" target="_blank" >Paper Link</a>
<button type="button" class="btn btn-outline-primary download-pdf" url="https://arxiv.org/pdf/2402.06121v1.pdf" filename="2402.06121v1.pdf">Download PDF</button>

---


**ABSTRACT**  
Efficiently generating statistically independent samples from an unnormalized probability distribution, such as equilibrium samples of many-body systems, is a foundational problem in science. In this paper, we propose Iterated Denoising Energy Matching (iDEM), an iterative algorithm that uses a novel stochastic score matching objective leveraging solely the energy function and its gradient -- and no data samples -- to train a diffusion-based sampler. Specifically, iDEM alternates between (I) sampling regions of high model density from a diffusion-based sampler and (II) using these samples in our stochastic matching objective to further improve the sampler. iDEM is scalable to high dimensions as the inner matching objective, is <b>simulation-free,</b> and requires no MCMC samples. Moreover, by leveraging the fast mode mixing behavior of diffusion, iDEM smooths out the energy landscape enabling efficient exploration and learning of an amortized sampler. We evaluate iDEM on a suite of tasks ranging from standard synthetic energy functions to invariant $n$-body particle systems. We show that the proposed approach achieves state-of-the-art performance on all metrics and trains $2-5\times$ faster, which allows it to be the first method to train using energy on the challenging $55$-particle Lennard-Jones system.

{{</citation>}}


### (87/145) Improved Evidential Deep Learning via a Mixture of Dirichlet Distributions (J. Jon Ryu et al., 2024)

{{<citation>}}

J. Jon Ryu, Maohao Shen, Soumya Ghosh, Yuheng Bu, Prasanna Sattigeri, Subhro Das, Gregory W. Wornell. (2024)  
**Improved Evidential Deep Learning via a Mixture of Dirichlet Distributions**
<br/>
<button class="copy-to-clipboard" title="Improved Evidential Deep Learning via a Mixture of Dirichlet Distributions" index=87>
  <span class="copy-to-clipboard-item">Copy Title<span>
</button>
<div class="toast toast-copied toast-index-87 align-items-center text-bg-secondary border-0 position-absolute top-0 end-0" role="alert" aria-live="assertive" aria-atomic="true">
  <div class="d-flex">
    <div class="toast-body">
      Copied!
    </div>
  </div>
</div>

---
Primary Category: cs.LG  
Categories: cs-LG, cs.LG, stat-ML  
Keyword Score: 13  
Keywords: Knowledge Distillation, Sample Size  
<a type="button" class="btn btn-outline-primary" href="http://arxiv.org/abs/2402.06160v1" target="_blank" >Paper Link</a>
<button type="button" class="btn btn-outline-primary download-pdf" url="https://arxiv.org/pdf/2402.06160v1.pdf" filename="2402.06160v1.pdf">Download PDF</button>

---


**ABSTRACT**  
This paper explores a modern predictive uncertainty estimation approach, called evidential deep learning (EDL), in which a single neural network model is trained to learn a meta distribution over the predictive distribution by minimizing a specific objective function. Despite their strong empirical performance, recent studies by Bengs et al. identify a fundamental pitfall of the existing methods: the learned epistemic uncertainty may not vanish even in the infinite-sample limit. We corroborate the observation by providing a unifying view of a class of widely used objectives from the literature. Our analysis reveals that the EDL methods essentially train a meta distribution by minimizing a certain divergence measure between the distribution and a <b>sample-size-independent</b> <b>target</b> distribution, resulting in spurious epistemic uncertainty. Grounded in theoretical principles, we propose learning a consistent target distribution by modeling it with a mixture of Dirichlet distributions and learning via variational inference. Afterward, a final meta distribution model <b>distills</b> the learned uncertainty from the target model. Experimental results across various uncertainty-based downstream tasks demonstrate the superiority of our proposed method, and illustrate the practical implications arising from the consistency and inconsistency of learned epistemic uncertainty.

{{</citation>}}


### (88/145) Multimodal Clinical Trial Outcome Prediction with Large Language Models (Wenhao Zheng et al., 2024)

{{<citation>}}

Wenhao Zheng, Dongsheng Peng, Hongxia Xu, Hongtu Zhu, Tianfan Fu, Huaxiu Yao. (2024)  
**Multimodal Clinical Trial Outcome Prediction with Large Language Models**
<br/>
<button class="copy-to-clipboard" title="Multimodal Clinical Trial Outcome Prediction with Large Language Models" index=88>
  <span class="copy-to-clipboard-item">Copy Title<span>
</button>
<div class="toast toast-copied toast-index-88 align-items-center text-bg-secondary border-0 position-absolute top-0 end-0" role="alert" aria-live="assertive" aria-atomic="true">
  <div class="d-flex">
    <div class="toast-body">
      Copied!
    </div>
  </div>
</div>

---
Primary Category: cs.LG  
Categories: cs-CL, cs-LG, cs.LG  
Keyword Score: 10  
Keywords: Large Language Model  
<a type="button" class="btn btn-outline-primary" href="http://arxiv.org/abs/2402.06512v1" target="_blank" >Paper Link</a>
<button type="button" class="btn btn-outline-primary download-pdf" url="https://arxiv.org/pdf/2402.06512v1.pdf" filename="2402.06512v1.pdf">Download PDF</button>

---


**ABSTRACT**  
The clinical trial is a pivotal and costly process, often spanning multiple years and requiring substantial financial resources. Therefore, the development of clinical trial outcome prediction models aims to exclude drugs likely to fail and holds the potential for significant cost savings. Recent data-driven attempts leverage deep learning methods to integrate multimodal data for predicting clinical trial outcomes. However, these approaches rely on manually designed modal-specific encoders, which limits both the extensibility to adapt new modalities and the ability to discern similar information patterns across different modalities. To address these issues, we propose a multimodal mixture-of-experts (LIFTED) approach for clinical trial outcome prediction. Specifically, LIFTED unifies different modality data by transforming them into natural language descriptions. Then, LIFTED constructs unified noise-resilient encoders to extract information from modal-specific language descriptions. Subsequently, a sparse Mixture-of-Experts framework is employed to further refine the representations, enabling LIFTED to identify similar information patterns across different modalities and extract more consistent representations from those patterns using the same expert model. Finally, a mixture-of-experts module is further employed to dynamically integrate different modality representations for prediction, which gives LIFTED the ability to automatically weigh different modalities and pay more attention to critical information. The experiments demonstrate that LIFTED significantly enhances performance in predicting clinical trial outcomes across all three phases compared to the best baseline, showcasing the effectiveness of our proposed key components.

{{</citation>}}


### (89/145) Where is the Truth? The Risk of Getting Confounded in a Continual World (Florian Peter Busch et al., 2024)

{{<citation>}}

Florian Peter Busch, Roshni Kamath, Rupert Mitchell, Wolfgang Stammer, Kristian Kersting, Martin Mundt. (2024)  
**Where is the Truth? The Risk of Getting Confounded in a Continual World**
<br/>
<button class="copy-to-clipboard" title="Where is the Truth? The Risk of Getting Confounded in a Continual World" index=89>
  <span class="copy-to-clipboard-item">Copy Title<span>
</button>
<div class="toast toast-copied toast-index-89 align-items-center text-bg-secondary border-0 position-absolute top-0 end-0" role="alert" aria-live="assertive" aria-atomic="true">
  <div class="d-flex">
    <div class="toast-body">
      Copied!
    </div>
  </div>
</div>

---
Primary Category: cs.LG  
Categories: cs-LG, cs.LG, stat-ML  
Keyword Score: 10  
Keywords: Continual Learning  
<a type="button" class="btn btn-outline-primary" href="http://arxiv.org/abs/2402.06434v1" target="_blank" >Paper Link</a>
<button type="button" class="btn btn-outline-primary download-pdf" url="https://arxiv.org/pdf/2402.06434v1.pdf" filename="2402.06434v1.pdf">Download PDF</button>

---


**ABSTRACT**  
A dataset is confounded if it is most easily solved via a spurious correlation which fails to generalize to new data. We will show that, in a <b>continual</b> <b>learning</b> setting where confounders may vary in time across tasks, the resulting challenge far exceeds the standard forgetting problem normally considered. In particular, we derive mathematically the effect of such confounders on the space of valid joint solutions to sets of confounded tasks. Interestingly, our theory predicts that for many such <b>continual</b> <b>datasets,</b> spurious correlations are easily ignored when the tasks are trained on jointly, but it is far harder to avoid confounding when they are considered sequentially. We construct such a dataset and demonstrate empirically that standard <b>continual</b> <b>learning</b> methods fail to ignore confounders, while training jointly on all tasks is successful. Our continually confounded dataset, ConCon, is based on CLEVR images and demonstrates the need for <b>continual</b> <b>learning</b> methods with more robust behavior with respect to confounding.

{{</citation>}}


### (90/145) High-Precision Geosteering via Reinforcement Learning and Particle Filters (Ressi Bonti Muhammad et al., 2024)

{{<citation>}}

Ressi Bonti Muhammad, Apoorv Srivastava, Sergey Alyaev, Reidar Brumer Bratvold, Daniel M. Tartakovsky. (2024)  
**High-Precision Geosteering via Reinforcement Learning and Particle Filters**
<br/>
<button class="copy-to-clipboard" title="High-Precision Geosteering via Reinforcement Learning and Particle Filters" index=90>
  <span class="copy-to-clipboard-item">Copy Title<span>
</button>
<div class="toast toast-copied toast-index-90 align-items-center text-bg-secondary border-0 position-absolute top-0 end-0" role="alert" aria-live="assertive" aria-atomic="true">
  <div class="d-flex">
    <div class="toast-body">
      Copied!
    </div>
  </div>
</div>

---
Primary Category: cs.LG  
Categories: cs-AI, cs-LG, cs.LG, physics-geo-ph  
Keyword Score: 10  
Keywords: Reinforcement Learning  
<a type="button" class="btn btn-outline-primary" href="http://arxiv.org/abs/2402.06377v1" target="_blank" >Paper Link</a>
<button type="button" class="btn btn-outline-primary download-pdf" url="https://arxiv.org/pdf/2402.06377v1.pdf" filename="2402.06377v1.pdf">Download PDF</button>

---


**ABSTRACT**  
Geosteering, a key component of drilling operations, traditionally involves manual interpretation of various data sources such as well-log data. This introduces subjective biases and inconsistent procedures. Academic attempts to solve geosteering decision optimization with greedy optimization and Approximate Dynamic Programming (ADP) showed promise but lacked adaptivity to realistic diverse scenarios. <b>Reinforcement</b> <b>learning</b> (RL) offers a solution to these challenges, facilitating optimal decision-making through reward-based iterative learning. State estimation methods, e.g., particle filter (PF), provide a complementary strategy for geosteering decision-making based on online information. We integrate an RL-based geosteering with PF to address realistic geosteering scenarios. Our framework deploys PF to process real-time well-log data to estimate the location of the well relative to the stratigraphic layers, which then informs the RL-based decision-making process. We compare our method's performance with that of using solely either RL or PF. Our findings indicate a synergy between RL and PF in yielding optimized geosteering decisions.

{{</citation>}}


### (91/145) Continual Learning on Graphs: A Survey (Zonggui Tian et al., 2024)

{{<citation>}}

Zonggui Tian, Du Zhang, Hong-Ning Dai. (2024)  
**Continual Learning on Graphs: A Survey**
<br/>
<button class="copy-to-clipboard" title="Continual Learning on Graphs: A Survey" index=91>
  <span class="copy-to-clipboard-item">Copy Title<span>
</button>
<div class="toast toast-copied toast-index-91 align-items-center text-bg-secondary border-0 position-absolute top-0 end-0" role="alert" aria-live="assertive" aria-atomic="true">
  <div class="d-flex">
    <div class="toast-body">
      Copied!
    </div>
  </div>
</div>

---
Primary Category: cs.LG  
Categories: cs-LG, cs.LG  
Keyword Score: 10  
Keywords: Continual Learning  
<a type="button" class="btn btn-outline-primary" href="http://arxiv.org/abs/2402.06330v1" target="_blank" >Paper Link</a>
<button type="button" class="btn btn-outline-primary download-pdf" url="https://arxiv.org/pdf/2402.06330v1.pdf" filename="2402.06330v1.pdf">Download PDF</button>

---


**ABSTRACT**  
Recently, <b>continual</b> <b>graph</b> learning has been increasingly adopted for diverse graph-structured data processing tasks in non-stationary environments. Despite its promising learning capability, current studies on <b>continual</b> <b>graph</b> learning mainly focus on mitigating the catastrophic forgetting problem while ignoring continuous performance improvement. To bridge this gap, this article aims to provide a comprehensive survey of recent efforts on <b>continual</b> <b>graph</b> learning. Specifically, we introduce a new taxonomy of <b>continual</b> <b>graph</b> learning from the perspective of overcoming catastrophic forgetting. Moreover, we systematically analyze the challenges of applying these <b>continual</b> <b>graph</b> learning methods in improving performance continuously and then discuss the possible solutions. Finally, we present open issues and future directions pertaining to the development of <b>continual</b> <b>graph</b> learning and discuss how they impact continuous performance improvement.

{{</citation>}}


### (92/145) Multimodal Interpretable Data-Driven Models for Early Prediction of Antimicrobial Multidrug Resistance Using Multivariate Time-Series (Sergio MartÃ­nez-AgÃ¼ero et al., 2024)

{{<citation>}}

Sergio MartÃ­nez-AgÃ¼ero, Antonio G. Marques, Inmaculada Mora-JimÃ©nez, JoaquÃ­n AlvÃ¡rez-RodrÃ­guez, Cristina Soguero-Ruiza. (2024)  
**Multimodal Interpretable Data-Driven Models for Early Prediction of Antimicrobial Multidrug Resistance Using Multivariate Time-Series**
<br/>
<button class="copy-to-clipboard" title="Multimodal Interpretable Data-Driven Models for Early Prediction of Antimicrobial Multidrug Resistance Using Multivariate Time-Series" index=92>
  <span class="copy-to-clipboard-item">Copy Title<span>
</button>
<div class="toast toast-copied toast-index-92 align-items-center text-bg-secondary border-0 position-absolute top-0 end-0" role="alert" aria-live="assertive" aria-atomic="true">
  <div class="d-flex">
    <div class="toast-body">
      Copied!
    </div>
  </div>
</div>

---
Primary Category: cs.LG  
Categories: cs-LG, cs.LG, q-bio-QM  
Keyword Score: 10  
Keywords: Neural Machine Translation  
<a type="button" class="btn btn-outline-primary" href="http://arxiv.org/abs/2402.06295v1" target="_blank" >Paper Link</a>
<button type="button" class="btn btn-outline-primary download-pdf" url="https://arxiv.org/pdf/2402.06295v1.pdf" filename="2402.06295v1.pdf">Download PDF</button>

---


**ABSTRACT**  
Electronic health records (EHR) is an inherently multimodal register of the patient's health status characterized by static data and multivariate time series <b>(MTS).</b> While <b>MTS</b> are a valuable tool for clinical prediction, their fusion with other data modalities can possibly result in more thorough insights and more accurate results. Deep neural networks (DNNs) have emerged as fundamental tools for identifying and defining underlying patterns in the healthcare domain. However, fundamental improvements in interpretability are needed for DNN models to be widely used in the clinical setting. In this study, we present an approach built on a collection of interpretable multimodal data-driven models that may anticipate and understand the emergence of antimicrobial multidrug resistance (AMR) germs in the intensive care unit (ICU) of the University Hospital of Fuenlabrada (Madrid, Spain). The profile and initial health status of the patient are modeled using static variables, while the evolution of the patient's health status during the ICU stay is modeled using several <b>MTS,</b> including mechanical ventilation and antibiotics intake. The multimodal DNNs models proposed in this paper include interpretable principles in addition to being effective at predicting AMR and providing an explainable prediction support system for AMR in the ICU. Furthermore, our proposed methodology based on multimodal models and interpretability schemes can be leveraged in additional clinical problems dealing with EHR data, broadening the impact and applicability of our results.

{{</citation>}}


### (93/145) Value function interference and greedy action selection in value-based multi-objective reinforcement learning (Peter Vamplew et al., 2024)

{{<citation>}}

Peter Vamplew, Cameron Foale, Richard Dazeley. (2024)  
**Value function interference and greedy action selection in value-based multi-objective reinforcement learning**
<br/>
<button class="copy-to-clipboard" title="Value function interference and greedy action selection in value-based multi-objective reinforcement learning" index=93>
  <span class="copy-to-clipboard-item">Copy Title<span>
</button>
<div class="toast toast-copied toast-index-93 align-items-center text-bg-secondary border-0 position-absolute top-0 end-0" role="alert" aria-live="assertive" aria-atomic="true">
  <div class="d-flex">
    <div class="toast-body">
      Copied!
    </div>
  </div>
</div>

---
Primary Category: cs.LG  
Categories: cs-LG, cs.LG  
Keyword Score: 10  
Keywords: Reinforcement Learning  
<a type="button" class="btn btn-outline-primary" href="http://arxiv.org/abs/2402.06266v1" target="_blank" >Paper Link</a>
<button type="button" class="btn btn-outline-primary download-pdf" url="https://arxiv.org/pdf/2402.06266v1.pdf" filename="2402.06266v1.pdf">Download PDF</button>

---


**ABSTRACT**  
Multi-objective <b>reinforcement</b> <b>learning</b> (MORL) algorithms extend conventional <b>reinforcement</b> <b>learning</b> (RL) to the more general case of problems with multiple, conflicting objectives, represented by vector-valued rewards. Widely-used scalar RL methods such as Q-learning can be modified to handle multiple objectives by (1) learning vector-valued value functions, and (2) performing action selection using a scalarisation or ordering operator which reflects the user's utility with respect to the different objectives. However, as we demonstrate here, if the user's utility function maps widely varying vector-values to similar levels of utility, this can lead to interference in the value-function learned by the agent, leading to convergence to sub-optimal policies. This will be most prevalent in stochastic environments when optimising for the Expected Scalarised Return criterion, but we present a simple example showing that interference can also arise in deterministic environments. We demonstrate empirically that avoiding the use of random tie-breaking when identifying greedy actions can ameliorate, but not fully overcome, the problems caused by value function interference.

{{</citation>}}


### (94/145) Pushing Boundaries: Mixup's Influence on Neural Collapse (Quinn Fisher et al., 2024)

{{<citation>}}

Quinn Fisher, Haoming Meng, Vardan Papyan. (2024)  
**Pushing Boundaries: Mixup's Influence on Neural Collapse**
<br/>
<button class="copy-to-clipboard" title="Pushing Boundaries: Mixup's Influence on Neural Collapse" index=94>
  <span class="copy-to-clipboard-item">Copy Title<span>
</button>
<div class="toast toast-copied toast-index-94 align-items-center text-bg-secondary border-0 position-absolute top-0 end-0" role="alert" aria-live="assertive" aria-atomic="true">
  <div class="d-flex">
    <div class="toast-body">
      Copied!
    </div>
  </div>
</div>

---
Primary Category: cs.LG  
Categories: cs-LG, cs.LG  
Keyword Score: 10  
Keywords: Data Augmentation  
<a type="button" class="btn btn-outline-primary" href="http://arxiv.org/abs/2402.06171v1" target="_blank" >Paper Link</a>
<button type="button" class="btn btn-outline-primary download-pdf" url="https://arxiv.org/pdf/2402.06171v1.pdf" filename="2402.06171v1.pdf">Download PDF</button>

---


**ABSTRACT**  
Mixup is a <b>data</b> <b>augmentation</b> strategy that employs convex combinations of training instances and their respective labels to augment the robustness and calibration of deep neural networks. Despite its widespread adoption, the nuanced mechanisms that underpin its success are not entirely understood. The observed phenomenon of Neural Collapse, where the last-layer activations and classifier of deep networks converge to a simplex equiangular tight frame (ETF), provides a compelling motivation to explore whether mixup induces alternative geometric configurations and whether those could explain its success. In this study, we delve into the last-layer activations of training <b>data</b> <b>for</b> deep networks subjected to mixup, aiming to uncover insights into its operational efficacy. Our investigation, spanning various architectures and dataset pairs, reveals that mixup's last-layer activations predominantly converge to a distinctive configuration different than one might expect. In this configuration, activations from mixed-up examples of identical classes align with the classifier, while those from different classes delineate channels along the decision boundary. Moreover, activations in earlier layers exhibit patterns, as if trained with manifold mixup. These findings are unexpected, as mixed-up features are not simple convex combinations of feature class means (as one might get, for example, by training mixup with the mean squared error loss). By analyzing this distinctive geometric configuration, we elucidate the mechanisms by which mixup enhances model calibration. To further validate our empirical observations, we conduct a theoretical analysis under the assumption of an unconstrained features model, utilizing the mixup loss. Through this, we characterize and derive the optimal last-layer features under the assumption that the classifier forms a simplex ETF.

{{</citation>}}


### (95/145) Domain Generalization with Small Data (Kecheng Chen et al., 2024)

{{<citation>}}

Kecheng Chen, Elena Gal, Hong Yan, Haoliang Li. (2024)  
**Domain Generalization with Small Data**
<br/>
<button class="copy-to-clipboard" title="Domain Generalization with Small Data" index=95>
  <span class="copy-to-clipboard-item">Copy Title<span>
</button>
<div class="toast toast-copied toast-index-95 align-items-center text-bg-secondary border-0 position-absolute top-0 end-0" role="alert" aria-live="assertive" aria-atomic="true">
  <div class="d-flex">
    <div class="toast-body">
      Copied!
    </div>
  </div>
</div>

---
Primary Category: cs.LG  
Categories: cs-CV, cs-LG, cs.LG  
Keyword Score: 10  
Keywords: Probabilistic Model  
<a type="button" class="btn btn-outline-primary" href="http://arxiv.org/abs/2402.06150v1" target="_blank" >Paper Link</a>
<button type="button" class="btn btn-outline-primary download-pdf" url="https://arxiv.org/pdf/2402.06150v1.pdf" filename="2402.06150v1.pdf">Download PDF</button>

---


**ABSTRACT**  
In this work, we propose to tackle the problem of domain generalization in the context of \textit{insufficient samples}. Instead of extracting latent feature embeddings based on deterministic models, we propose to learn a domain-invariant representation based on the <b>probabilistic</b> <b>framework</b> by mapping each data point into <b>probabilistic</b> <b>embeddings.</b> Specifically, we first extend empirical maximum mean discrepancy (MMD) to a novel <b>probabilistic</b> <b>MMD</b> that can measure the discrepancy between mixture distributions (i.e., source domains) consisting of a series of latent distributions rather than latent points. Moreover, instead of imposing the contrastive semantic alignment (CSA) loss based on pairs of latent points, a novel <b>probabilistic</b> <b>CSA</b> loss encourages positive <b>probabilistic</b> <b>embedding</b> pairs to be closer while pulling other negative ones apart. Benefiting from the learned representation captured by <b>probabilistic</b> <b>models,</b> our proposed method can marriage the measurement on the \textit{distribution over distributions} (i.e., the global perspective alignment) and the distribution-based contrastive semantic alignment (i.e., the local perspective alignment). Extensive experimental results on three challenging medical datasets show the effectiveness of our proposed method in the context of insufficient data compared with state-of-the-art methods.

{{</citation>}}


## cs.AI (9)



### (96/145) The Quantified Boolean Bayesian Network: Theory and Experiments with a Logical Graphical Model (Gregory Coppola, 2024)

{{<citation>}}

Gregory Coppola. (2024)  
**The Quantified Boolean Bayesian Network: Theory and Experiments with a Logical Graphical Model**
<br/>
<button class="copy-to-clipboard" title="The Quantified Boolean Bayesian Network: Theory and Experiments with a Logical Graphical Model" index=96>
  <span class="copy-to-clipboard-item">Copy Title<span>
</button>
<div class="toast toast-copied toast-index-96 align-items-center text-bg-secondary border-0 position-absolute top-0 end-0" role="alert" aria-live="assertive" aria-atomic="true">
  <div class="d-flex">
    <div class="toast-body">
      Copied!
    </div>
  </div>
</div>

---
Primary Category: cs.AI  
Categories: cs-AI, cs-IR, cs.AI  
Keyword Score: 50  
Keywords: Information Retrieval, Probabilistic Reasoning, Reasoning, Large Language Model, Large Language Model  
<a type="button" class="btn btn-outline-primary" href="http://arxiv.org/abs/2402.06557v1" target="_blank" >Paper Link</a>
<button type="button" class="btn btn-outline-primary download-pdf" url="https://arxiv.org/pdf/2402.06557v1.pdf" filename="2402.06557v1.pdf">Download PDF</button>

---


**ABSTRACT**  
This paper introduces the Quantified Boolean Bayesian Network (QBBN), which provides a unified view of logical and <b>probabilistic</b> <b>reasoning.</b> The QBBN is meant to address a central problem with the <b>Large</b> <b>Language</b> <b>Model</b> <b>(LLM),</b> which has become extremely popular in <b>Information</b> <b>Retrieval,</b> which is that the <b>LLM</b> hallucinates. A Bayesian Network, by construction, cannot hallucinate, because it can only return answers that it can explain. We show how a Bayesian Network over an unbounded number of boolean variables can be configured to represent the logical <b>reasoning</b> underlying human language. We do this by creating a key-value version of the First-Order Calculus, for which we can prove consistency and completeness. We show that the model is trivially trained over fully observed data, but that inference is non-trivial. Exact inference in a Bayesian Network is intractable (i.e. $\Omega(2^N)$ for $N$ variables). For inference, we investigate the use of Loopy Belief Propagation (LBP), which is not guaranteed to converge, but which has been shown to often converge in practice. Our experiments show that LBP indeed does converge very reliably, and our analysis shows that a round of LBP takes time $O(N2^n)$, where $N$ bounds the number of variables considered, and $n$ bounds the number of incoming connections to any factor, and further improvements may be possible. Our network is specifically designed to alternate between AND and OR gates in a Boolean Algebra, which connects more closely to logical <b>reasoning,</b> allowing a completeness proof for an expanded version of our network, and also allows inference to follow specific but adequate pathways, that turn out to be fast.

{{</citation>}}


### (97/145) Introspective Planning: Guiding Language-Enabled Agents to Refine Their Own Uncertainty (Kaiqu Liang et al., 2024)

{{<citation>}}

Kaiqu Liang, Zixu Zhang, Jaime FernÃ¡ndez Fisac. (2024)  
**Introspective Planning: Guiding Language-Enabled Agents to Refine Their Own Uncertainty**
<br/>
<button class="copy-to-clipboard" title="Introspective Planning: Guiding Language-Enabled Agents to Refine Their Own Uncertainty" index=97>
  <span class="copy-to-clipboard-item">Copy Title<span>
</button>
<div class="toast toast-copied toast-index-97 align-items-center text-bg-secondary border-0 position-absolute top-0 end-0" role="alert" aria-live="assertive" aria-atomic="true">
  <div class="d-flex">
    <div class="toast-body">
      Copied!
    </div>
  </div>
</div>

---
Primary Category: cs.AI  
Categories: cs-AI, cs-CL, cs-LG, cs.AI  
Keyword Score: 50  
Keywords: Fine-tuning, Grounding, Reasoning, Large Language Model, Large Language Model  
<a type="button" class="btn btn-outline-primary" href="http://arxiv.org/abs/2402.06529v1" target="_blank" >Paper Link</a>
<button type="button" class="btn btn-outline-primary download-pdf" url="https://arxiv.org/pdf/2402.06529v1.pdf" filename="2402.06529v1.pdf">Download PDF</button>

---


**ABSTRACT**  
<b>Large</b> <b>language</b> <b>models</b> <b>(LLMs)</b> exhibit advanced <b>reasoning</b> skills, enabling robots to comprehend natural language instructions and strategically plan high-level actions through proper <b>grounding.</b> However, <b>LLM</b> hallucination may result in robots confidently executing plans that are misaligned with user goals or, in extreme cases, unsafe. Additionally, inherent ambiguity in natural language instructions can induce task uncertainty, particularly in situations where multiple valid options exist. To address this issue, <b>LLMs</b> must identify such uncertainty and proactively seek clarification. This paper explores the concept of introspective planning as a systematic method for guiding <b>LLMs</b> in forming uncertainty--aware plans for robotic task execution without the need for <b>fine-tuning.</b> We investigate uncertainty quantification in task-level robot planning and demonstrate that introspection significantly improves both success rates and safety compared to state-of-the-art <b>LLM-based</b> planning approaches. Furthermore, we assess the effectiveness of introspective planning in conjunction with conformal prediction, revealing that this combination yields tighter confidence bounds, thereby maintaining statistical success guarantees with fewer superfluous user clarification queries.

{{</citation>}}


### (98/145) LLaVA-Docent: Instruction Tuning with Multimodal Large Language Model to Support Art Appreciation Education (Unggi Lee et al., 2024)

{{<citation>}}

Unggi Lee, Minji Jeon, Yunseo Lee, Gyuri Byun, Yoorim Son, Jaeyoon Shin, Hongkyu Ko, Hyeoncheol Kim. (2024)  
**LLaVA-Docent: Instruction Tuning with Multimodal Large Language Model to Support Art Appreciation Education**
<br/>
<button class="copy-to-clipboard" title="LLaVA-Docent: Instruction Tuning with Multimodal Large Language Model to Support Art Appreciation Education" index=98>
  <span class="copy-to-clipboard-item">Copy Title<span>
</button>
<div class="toast toast-copied toast-index-98 align-items-center text-bg-secondary border-0 position-absolute top-0 end-0" role="alert" aria-live="assertive" aria-atomic="true">
  <div class="d-flex">
    <div class="toast-body">
      Copied!
    </div>
  </div>
</div>

---
Primary Category: cs.AI  
Categories: cs-AI, cs-SI, cs.AI  
Keyword Score: 50  
Keywords: Few-shot, GPT, GPT-4, Instruction Tuning, Large Language Model  
<a type="button" class="btn btn-outline-primary" href="http://arxiv.org/abs/2402.06264v1" target="_blank" >Paper Link</a>
<button type="button" class="btn btn-outline-primary download-pdf" url="https://arxiv.org/pdf/2402.06264v1.pdf" filename="2402.06264v1.pdf">Download PDF</button>

---


**ABSTRACT**  
Art appreciation is vital in nurturing critical thinking and emotional intelligence among learners. However, traditional art appreciation education has often been hindered by limited access to art resources, especially for disadvantaged students, and an imbalanced emphasis on STEM subjects in mainstream education. In response to these challenges, recent technological advancements have paved the way for innovative solutions. This study explores the application of multi-modal <b>large</b> <b>language</b> <b>models</b> (MLLMs) in art appreciation education, focusing on developing LLaVA-Docent, a model that leverages these advancements. Our approach involved a comprehensive literature review and consultations with experts in the field, leading to developing a robust data framework. Utilizing this framework, we generated a virtual dialogue dataset that was leveraged by <b>GPT-4.</b> This dataset was instrumental in training the MLLM, named LLaVA-Docent. Six researchers conducted quantitative and qualitative evaluations of LLaVA-Docent to assess its effectiveness, benchmarking it against the <b>GPT-4</b> model in a <b>few-shot</b> setting. The evaluation process revealed distinct strengths and weaknesses of the LLaVA-Docent model. Our findings highlight the efficacy of LLaVA-Docent in enhancing the accessibility and engagement of art appreciation education. By harnessing the potential of MLLMs, this study makes a significant contribution to the field of art education, proposing a novel methodology that reimagines the way art appreciation is taught and experienced.

{{</citation>}}


### (99/145) ACTER: Diverse and Actionable Counterfactual Sequences for Explaining and Diagnosing RL Policies (Jasmina Gajcin et al., 2024)

{{<citation>}}

Jasmina Gajcin, Ivana Dusparic. (2024)  
**ACTER: Diverse and Actionable Counterfactual Sequences for Explaining and Diagnosing RL Policies**
<br/>
<button class="copy-to-clipboard" title="ACTER: Diverse and Actionable Counterfactual Sequences for Explaining and Diagnosing RL Policies" index=99>
  <span class="copy-to-clipboard-item">Copy Title<span>
</button>
<div class="toast toast-copied toast-index-99 align-items-center text-bg-secondary border-0 position-absolute top-0 end-0" role="alert" aria-live="assertive" aria-atomic="true">
  <div class="d-flex">
    <div class="toast-body">
      Copied!
    </div>
  </div>
</div>

---
Primary Category: cs.AI  
Categories: cs-AI, cs-LG, cs.AI  
Keyword Score: 40  
Keywords: Counter-factual, Reinforcement Learning, Counterfactual Reasoning, Reasoning  
<a type="button" class="btn btn-outline-primary" href="http://arxiv.org/abs/2402.06503v1" target="_blank" >Paper Link</a>
<button type="button" class="btn btn-outline-primary download-pdf" url="https://arxiv.org/pdf/2402.06503v1.pdf" filename="2402.06503v1.pdf">Download PDF</button>

---


**ABSTRACT**  
Understanding how failure occurs and how it can be prevented in <b>reinforcement</b> <b>learning</b> (RL) is necessary to enable debugging, maintain user trust, and develop personalized policies. <b>Counterfactual</b> <b>reasoning</b> has often been used to assign blame and understand failure by searching for the closest possible world in which the failure is avoided. However, current <b>counterfactual</b> <b>state</b> explanations in RL can only explain an outcome using just the current state features and offer no actionable recourse on how a negative outcome could have been prevented. In this work, we propose ACTER (Actionable <b>Counterfactual</b> <b>Sequences</b> for Explaining <b>Reinforcement</b> <b>Learning</b> Outcomes), an algorithm for generating <b>counterfactual</b> <b>sequences</b> that provides actionable advice on how failure can be avoided. ACTER investigates actions leading to a failure and uses the evolutionary algorithm NSGA-II to generate <b>counterfactual</b> <b>sequences</b> of actions that prevent it with minimal changes and high certainty even in stochastic environments. Additionally, ACTER generates a set of multiple diverse <b>counterfactual</b> <b>sequences</b> that enable users to correct failure in the way that best fits their preferences. We also introduce three diversity metrics that can be used for evaluating the diversity of <b>counterfactual</b> <b>sequences.</b> We evaluate ACTER in two RL environments, with both discrete and continuous actions, and show that it can generate actionable and diverse <b>counterfactual</b> <b>sequences.</b> We conduct a user study to explore how explanations generated by ACTER help users identify and correct failure.

{{</citation>}}


### (100/145) Understanding the Weakness of Large Language Model Agents within a Complex Android Environment (Mingzhe Xing et al., 2024)

{{<citation>}}

Mingzhe Xing, Rongkai Zhang, Hui Xue, Qi Chen, Fan Yang, Zhen Xiao. (2024)  
**Understanding the Weakness of Large Language Model Agents within a Complex Android Environment**
<br/>
<button class="copy-to-clipboard" title="Understanding the Weakness of Large Language Model Agents within a Complex Android Environment" index=100>
  <span class="copy-to-clipboard-item">Copy Title<span>
</button>
<div class="toast toast-copied toast-index-100 align-items-center text-bg-secondary border-0 position-absolute top-0 end-0" role="alert" aria-live="assertive" aria-atomic="true">
  <div class="d-flex">
    <div class="toast-body">
      Copied!
    </div>
  </div>
</div>

---
Primary Category: cs.AI  
Categories: cs-AI, cs-HC, cs-SE, cs.AI  
Keyword Score: 30  
Keywords: Reasoning, Large Language Model, Large Language Model  
<a type="button" class="btn btn-outline-primary" href="http://arxiv.org/abs/2402.06596v1" target="_blank" >Paper Link</a>
<button type="button" class="btn btn-outline-primary download-pdf" url="https://arxiv.org/pdf/2402.06596v1.pdf" filename="2402.06596v1.pdf">Download PDF</button>

---


**ABSTRACT**  
<b>Large</b> <b>language</b> <b>models</b> <b>(LLMs)</b> have empowered intelligent agents to execute intricate tasks within domain-specific software such as browsers and games. However, when applied to general-purpose software systems like operating systems, <b>LLM</b> agents face three primary challenges. Firstly, the action space is vast and dynamic, posing difficulties for <b>LLM</b> agents to maintain an up-to-date understanding and deliver accurate responses. Secondly, real-world tasks often require inter-application cooperation}, demanding farsighted planning from <b>LLM</b> agents. Thirdly, agents need to identify optimal solutions aligning with user constraints, such as security concerns and preferences. These challenges motivate AndroidArena, an environment and benchmark designed to evaluate <b>LLM</b> agents on a modern operating system. To address high-cost of manpower, we design a scalable and semi-automated method to construct the benchmark. In the task evaluation, AndroidArena incorporates accurate and adaptive metrics to address the issue of non-unique solutions. Our findings reveal that even state-of-the-art <b>LLM</b> agents struggle in cross-APP scenarios and adhering to specific constraints. Additionally, we identify a lack of four key capabilities, i.e., understanding, <b>reasoning,</b> exploration, and reflection, as primary reasons for the failure of <b>LLM</b> agents. Furthermore, we provide empirical analysis on the failure of reflection, and improve the success rate by 27% with our proposed exploration strategy. This work is the first to present valuable insights in understanding fine-grained weakness of <b>LLM</b> agents, and offers a path forward for future research in this area. Environment, benchmark, and evaluation code for AndroidArena are released at https://github.com/AndroidArenaAgent/AndroidArena.

{{</citation>}}


### (101/145) Prompt Learning on Temporal Interaction Graphs (Xi Chen et al., 2024)

{{<citation>}}

Xi Chen, Siwei Zhang, Yun Xiong, Xixi Wu, Jiawei Zhang, Xiangguo Sun, Yao Zhang, Yinglong Zhao, Yulin Kang. (2024)  
**Prompt Learning on Temporal Interaction Graphs**
<br/>
<button class="copy-to-clipboard" title="Prompt Learning on Temporal Interaction Graphs" index=101>
  <span class="copy-to-clipboard-item">Copy Title<span>
</button>
<div class="toast toast-copied toast-index-101 align-items-center text-bg-secondary border-0 position-absolute top-0 end-0" role="alert" aria-live="assertive" aria-atomic="true">
  <div class="d-flex">
    <div class="toast-body">
      Copied!
    </div>
  </div>
</div>

---
Primary Category: cs.AI  
Categories: cs-AI, cs-LG, cs-SI, cs.AI  
Keyword Score: 30  
Keywords: Fine-tuning, Prompt, Prompt Learning  
<a type="button" class="btn btn-outline-primary" href="http://arxiv.org/abs/2402.06326v1" target="_blank" >Paper Link</a>
<button type="button" class="btn btn-outline-primary download-pdf" url="https://arxiv.org/pdf/2402.06326v1.pdf" filename="2402.06326v1.pdf">Download PDF</button>

---


**ABSTRACT**  
Temporal Interaction Graphs (TIGs) are widely utilized to represent real-world systems. To facilitate representation learning on TIGs, researchers have proposed a series of TIG models. However, these models are still facing two tough gaps between the pre-training and downstream predictions in their ``pre-train, predict'' training paradigm. First, the temporal discrepancy between the pre-training and inference data severely undermines the models' applicability in distant future predictions on the dynamically evolving data. Second, the semantic divergence between pretext and downstream tasks hinders their practical applications, as they struggle to align with their learning and prediction capabilities across application scenarios. Recently, the ``pre-train, <b>prompt''</b> <b>paradigm</b> has emerged as a lightweight mechanism for model generalization. Applying this paradigm is a potential solution to solve the aforementioned challenges. However, the adaptation of this paradigm to TIGs is not straightforward. The application of <b>prompting</b> <b>in</b> static graph contexts falls short in temporal settings due to a lack of consideration for time-sensitive dynamics and a deficiency in expressive power. To address this issue, we introduce Temporal Interaction Graph <b>Prompting</b> <b>(TIGPrompt),</b> a versatile framework that seamlessly integrates with TIG models, bridging both the temporal and semantic gaps. In detail, we propose a temporal <b>prompt</b> <b>generator</b> to offer temporally-aware <b>prompts</b> <b>for</b> different tasks. These <b>prompts</b> <b>stand</b> out for their minimalistic design, relying solely on the tuning of the <b>prompt</b> <b>generator</b> with very little supervision data. To cater to varying computational resource demands, we propose an extended ``pre-train, <b>prompt-based</b> <b>fine-tune''</b> paradigm, offering greater flexibility. Through extensive experiments, the TIGPrompt demonstrates the SOTA performance and remarkable efficiency advantages.

{{</citation>}}


### (102/145) Human Aesthetic Preference-Based Large Text-to-Image Model Personalization: Kandinsky Generation as an Example (Aven-Le Zhou et al., 2024)

{{<citation>}}

Aven-Le Zhou, Yu-Ao Wang, Wei Wu, Kang Zhang. (2024)  
**Human Aesthetic Preference-Based Large Text-to-Image Model Personalization: Kandinsky Generation as an Example**
<br/>
<button class="copy-to-clipboard" title="Human Aesthetic Preference-Based Large Text-to-Image Model Personalization: Kandinsky Generation as an Example" index=102>
  <span class="copy-to-clipboard-item">Copy Title<span>
</button>
<div class="toast toast-copied toast-index-102 align-items-center text-bg-secondary border-0 position-absolute top-0 end-0" role="alert" aria-live="assertive" aria-atomic="true">
  <div class="d-flex">
    <div class="toast-body">
      Copied!
    </div>
  </div>
</div>

---
Primary Category: cs.AI  
Categories: cs-AI, cs-HC, cs-MM, cs.AI  
Keyword Score: 20  
Keywords: Text2image, Prompt  
<a type="button" class="btn btn-outline-primary" href="http://arxiv.org/abs/2402.06389v1" target="_blank" >Paper Link</a>
<button type="button" class="btn btn-outline-primary download-pdf" url="https://arxiv.org/pdf/2402.06389v1.pdf" filename="2402.06389v1.pdf">Download PDF</button>

---


**ABSTRACT**  
With the advancement of neural generative capabilities, the art community has actively embraced GenAI (generative artificial intelligence) for creating painterly content. Large <b>text-to-image</b> models can quickly generate aesthetically pleasing outcomes. However, the process can be non-deterministic and often involves tedious trial-and-error, as users struggle with formulating effective <b>prompts</b> to achieve their desired results. This paper introduces a <b>prompting-free</b> generative approach that empowers users to automatically generate personalized painterly content that incorporates their aesthetic preferences in a customized artistic style. This approach involves utilizing ``semantic injection'' to customize an artist model in a specific artistic style, and further leveraging a genetic algorithm to optimize the <b>prompt</b> generation process through real-time iterative human feedback. By solely relying on the user's aesthetic evaluation and preference for the artist model-generated images, this approach creates the user a personalized model that encompasses their aesthetic preferences and the customized artistic style.

{{</citation>}}


### (103/145) Predictive representations: building blocks of intelligence (Wilka Carvalho et al., 2024)

{{<citation>}}

Wilka Carvalho, Momchil S. Tomov, William de Cothi, Caswell Barry, Samuel J. Gershman. (2024)  
**Predictive representations: building blocks of intelligence**
<br/>
<button class="copy-to-clipboard" title="Predictive representations: building blocks of intelligence" index=103>
  <span class="copy-to-clipboard-item">Copy Title<span>
</button>
<div class="toast toast-copied toast-index-103 align-items-center text-bg-secondary border-0 position-absolute top-0 end-0" role="alert" aria-live="assertive" aria-atomic="true">
  <div class="d-flex">
    <div class="toast-body">
      Copied!
    </div>
  </div>
</div>

---
Primary Category: cs.AI  
Categories: cs-AI, cs-LG, cs.AI  
Keyword Score: 10  
Keywords: Reinforcement Learning  
<a type="button" class="btn btn-outline-primary" href="http://arxiv.org/abs/2402.06590v1" target="_blank" >Paper Link</a>
<button type="button" class="btn btn-outline-primary download-pdf" url="https://arxiv.org/pdf/2402.06590v1.pdf" filename="2402.06590v1.pdf">Download PDF</button>

---


**ABSTRACT**  
Adaptive behavior often requires predicting future events. The theory of <b>reinforcement</b> <b>learning</b> prescribes what kinds of predictive representations are useful and how to compute them. This paper integrates these theoretical ideas with work on cognition and neuroscience. We pay special attention to the successor representation (SR) and its generalizations, which have been widely applied both as engineering tools and models of brain function. This convergence suggests that particular kinds of predictive representations may function as versatile building blocks of intelligence.

{{</citation>}}


### (104/145) Modelling Human Values for AI Reasoning (Nardine Osman et al., 2024)

{{<citation>}}

Nardine Osman, Mark d'Inverno. (2024)  
**Modelling Human Values for AI Reasoning**
<br/>
<button class="copy-to-clipboard" title="Modelling Human Values for AI Reasoning" index=104>
  <span class="copy-to-clipboard-item">Copy Title<span>
</button>
<div class="toast toast-copied toast-index-104 align-items-center text-bg-secondary border-0 position-absolute top-0 end-0" role="alert" aria-live="assertive" aria-atomic="true">
  <div class="d-flex">
    <div class="toast-body">
      Copied!
    </div>
  </div>
</div>

---
Primary Category: cs.AI  
Categories: 68T01, I-2-4, cs-AI, cs-MA, cs.AI  
Keyword Score: 10  
Keywords: Reasoning  
<a type="button" class="btn btn-outline-primary" href="http://arxiv.org/abs/2402.06359v1" target="_blank" >Paper Link</a>
<button type="button" class="btn btn-outline-primary download-pdf" url="https://arxiv.org/pdf/2402.06359v1.pdf" filename="2402.06359v1.pdf">Download PDF</button>

---


**ABSTRACT**  
One of today's most significant societal challenges is building AI systems whose behaviour, or the behaviour it enables within communities of interacting agents (human and artificial), aligns with human values. To address this challenge, we detail a formal model of human values for their explicit computational representation. To our knowledge, this has not been attempted as yet, which is surprising given the growing volume of research integrating values within AI. Taking as our starting point the wealth of research investigating the nature of human values from social psychology over the last few decades, we set out to provide such a formal model. We show how this model can provide the foundational apparatus for AI-based <b>reasoning</b> over values, and demonstrate its applicability in real-world use cases. We illustrate how our model captures the key ideas from social psychology research and propose a roadmap for future integrated, and interdisciplinary, research into human values in AI. The ability to automatically reason over values not only helps address the value alignment problem but also facilitates the design of AI systems that can support individuals and communities in making more informed, value-aligned decisions. More and more, individuals and organisations are motivated to understand their values more explicitly and explore whether their behaviours and attitudes properly reflect them. Our work on modelling human values will enable AI systems to be designed and deployed to meet this growing need.

{{</citation>}}


## cs.HC (3)



### (105/145) Task Supportive and Personalized Human-Large Language Model Interaction: A User Study (Ben Wang et al., 2024)

{{<citation>}}

Ben Wang, Jiqun Liu, Jamshed Karimnazarov, Nicolas Thompson. (2024)  
**Task Supportive and Personalized Human-Large Language Model Interaction: A User Study**
<br/>
<button class="copy-to-clipboard" title="Task Supportive and Personalized Human-Large Language Model Interaction: A User Study" index=105>
  <span class="copy-to-clipboard-item">Copy Title<span>
</button>
<div class="toast toast-copied toast-index-105 align-items-center text-bg-secondary border-0 position-absolute top-0 end-0" role="alert" aria-live="assertive" aria-atomic="true">
  <div class="d-flex">
    <div class="toast-body">
      Copied!
    </div>
  </div>
</div>

---
Primary Category: cs.HC  
Categories: cs-HC, cs-IR, cs.HC  
Keyword Score: 50  
Keywords: ChatGPT, Information Retrieval, Large Language Model, Large Language Model, Prompt  
<a type="button" class="btn btn-outline-primary" href="http://arxiv.org/abs/2402.06170v1" target="_blank" >Paper Link</a>
<button type="button" class="btn btn-outline-primary download-pdf" url="https://arxiv.org/pdf/2402.06170v1.pdf" filename="2402.06170v1.pdf">Download PDF</button>

---


**ABSTRACT**  
<b>Large</b> <b>language</b> <b>model</b> <b>(LLM)</b> applications, such as <b>ChatGPT,</b> are a powerful tool for online <b>information-seeking</b> <b>(IS)</b> and problem-solving tasks. However, users still face challenges initializing and refining <b>prompts,</b> and their cognitive barriers and biased perceptions further impede task completion. These issues reflect broader challenges identified within the fields of IS and interactive <b>information</b> <b>retrieval</b> (IIR). To address these, our approach integrates task context and user perceptions into human-ChatGPT interactions through <b>prompt</b> engineering. We developed a <b>ChatGPT-like</b> platform integrated with supportive functions, including perception articulation, <b>prompt</b> suggestion, and conversation explanation. Our findings of a user study demonstrate that the supportive functions help users manage expectations, reduce cognitive loads, better refine <b>prompts,</b> and increase user engagement. This research enhances our comprehension of designing proactive and user-centric systems with <b>LLMs.</b> It offers insights into evaluating human-LLM interactions and emphasizes potential challenges for under served users.

{{</citation>}}


### (106/145) Exploring Interaction Patterns for Debugging: Enhancing Conversational Capabilities of AI-assistants (Bhavya Chopra et al., 2024)

{{<citation>}}

Bhavya Chopra, Yasharth Bajpai, Param Biyani, Gustavo Soares, Arjun Radhakrishna, Chris Parnin, Sumit Gulwani. (2024)  
**Exploring Interaction Patterns for Debugging: Enhancing Conversational Capabilities of AI-assistants**
<br/>
<button class="copy-to-clipboard" title="Exploring Interaction Patterns for Debugging: Enhancing Conversational Capabilities of AI-assistants" index=106>
  <span class="copy-to-clipboard-item">Copy Title<span>
</button>
<div class="toast toast-copied toast-index-106 align-items-center text-bg-secondary border-0 position-absolute top-0 end-0" role="alert" aria-live="assertive" aria-atomic="true">
  <div class="d-flex">
    <div class="toast-body">
      Copied!
    </div>
  </div>
</div>

---
Primary Category: cs.HC  
Categories: cs-AI, cs-HC, cs-SE, cs.HC  
Keyword Score: 30  
Keywords: Natural Language Explanation, Large Language Model, Large Language Model  
<a type="button" class="btn btn-outline-primary" href="http://arxiv.org/abs/2402.06229v1" target="_blank" >Paper Link</a>
<button type="button" class="btn btn-outline-primary download-pdf" url="https://arxiv.org/pdf/2402.06229v1.pdf" filename="2402.06229v1.pdf">Download PDF</button>

---


**ABSTRACT**  
The widespread availability of <b>Large</b> <b>Language</b> <b>Models</b> <b>(LLMs)</b> within Integrated Development Environments (IDEs) has led to their speedy adoption. Conversational interactions with <b>LLMs</b> enable programmers to obtain <b>natural</b> <b>language</b> <b>explanations</b> for various software development tasks. However, <b>LLMs</b> often leap to action without sufficient context, giving rise to implicit assumptions and inaccurate responses. Conversations between developers and <b>LLMs</b> are primarily structured as question-answer pairs, where the developer is responsible for asking the the right questions and sustaining conversations across multiple turns. In this paper, we draw inspiration from interaction patterns and conversation analysis -- to design Robin, an enhanced conversational AI-assistant for debugging. Through a within-subjects user study with 12 industry professionals, we find that equipping the <b>LLM</b> to -- (1) leverage the insert expansion interaction pattern, (2) facilitate turn-taking, and (3) utilize debugging workflows -- leads to lowered conversation barriers, effective fault localization, and 5x improvement in bug resolution rates.

{{</citation>}}


### (107/145) 'When He Feels Cold, He Goes to the Seahorse'-Blending Generative AI into Multimaterial Storymaking for Family Expressive Arts Therapy (Di Liu et al., 2024)

{{<citation>}}

Di Liu, Hanqing Zhou, Pengcheng An. (2024)  
**'When He Feels Cold, He Goes to the Seahorse'-Blending Generative AI into Multimaterial Storymaking for Family Expressive Arts Therapy**
<br/>
<button class="copy-to-clipboard" title="'When He Feels Cold, He Goes to the Seahorse'-Blending Generative AI into Multimaterial Storymaking for Family Expressive Arts Therapy" index=107>
  <span class="copy-to-clipboard-item">Copy Title<span>
</button>
<div class="toast toast-copied toast-index-107 align-items-center text-bg-secondary border-0 position-absolute top-0 end-0" role="alert" aria-live="assertive" aria-atomic="true">
  <div class="d-flex">
    <div class="toast-body">
      Copied!
    </div>
  </div>
</div>

---
Primary Category: cs.HC  
Categories: cs-AI, cs-HC, cs.HC  
Keyword Score: 20  
Keywords: Generative AI, Knowledge Distillation  
<a type="button" class="btn btn-outline-primary" href="http://arxiv.org/abs/2402.06472v1" target="_blank" >Paper Link</a>
<button type="button" class="btn btn-outline-primary download-pdf" url="https://arxiv.org/pdf/2402.06472v1.pdf" filename="2402.06472v1.pdf">Download PDF</button>

---


**ABSTRACT**  
Storymaking, as an integrative form of expressive arts therapy, is an effective means to foster family communication. Yet, the integration of <b>generative</b> <b>AI</b> as expressive materials in therapeutic storymaking remains underexplored. And there is a lack of HCI implications on how to support families and therapists in this context. Addressing this, our study involved five weeks of storymaking sessions with seven families guided by a professional therapist. In these sessions, the families used both traditional art-making materials and image-based <b>generative</b> <b>AI</b> to create and evolve their family stories. Via the rich empirical data and commentaries from four expert therapists, we contextualize how families creatively melded AI and traditional expressive materials to externalize their ideas and feelings. Through the lens of Expressive Therapies Continuum (ETC), we characterize the therapeutic implications of AI as expressive materials. Desirable interaction qualities to support children, parents, and therapists are <b>distilled</b> for future HCI research.

{{</citation>}}


## cs.CE (1)



### (108/145) A plastic correction algorithm for full-field elasto-plastic finite element simulations : critical assessment of predictive capabilities and improvement by machine learning (Abhishek Palchoudhary et al., 2024)

{{<citation>}}

Abhishek Palchoudhary, Simone Peter, Vincent Maurel, Cristian Ovalle, Pierre Kerfriden. (2024)  
**A plastic correction algorithm for full-field elasto-plastic finite element simulations : critical assessment of predictive capabilities and improvement by machine learning**
<br/>
<button class="copy-to-clipboard" title="A plastic correction algorithm for full-field elasto-plastic finite element simulations : critical assessment of predictive capabilities and improvement by machine learning" index=108>
  <span class="copy-to-clipboard-item">Copy Title<span>
</button>
<div class="toast toast-copied toast-index-108 align-items-center text-bg-secondary border-0 position-absolute top-0 end-0" role="alert" aria-live="assertive" aria-atomic="true">
  <div class="d-flex">
    <div class="toast-body">
      Copied!
    </div>
  </div>
</div>

---
Primary Category: cs.CE  
Categories: cs-CE, cs.CE  
Keyword Score: 40  
Keywords: Convolution, Convolutional Neural Network, Simulation, Simulator  
<a type="button" class="btn btn-outline-primary" href="http://arxiv.org/abs/2402.06313v1" target="_blank" >Paper Link</a>
<button type="button" class="btn btn-outline-primary download-pdf" url="https://arxiv.org/pdf/2402.06313v1.pdf" filename="2402.06313v1.pdf">Download PDF</button>

---


**ABSTRACT**  
This paper introduces a new local plastic correction algorithm developed to accelerate finite element <b>simulations</b> for structures with elasto-plastic constitutive laws. The proposed method belongs to the category of generalized multiaxial Neuber-type methods enabled by pointwise proportional evolution rules. The algorithm numerically integrates J2 plasticity laws as a function of the finite element elastic response of the structure, to obtain full-field 3D elasto-plastic quantities for any proportionally applied loading. Examples of the numerical capabilities of this algorithm are shown on a structure containing a distribution of pores, for monotonic and fatigue loading. The approximation errors due to the proposed local plastic correction are also investigated. As a second point of innovation, we show that the proposed local plastic correction can be accelerated when dealing with large-scale structures by employing a simple meta-model, with virtually no added errors. Finally, we develop and investigate the merits of an additional deep-learning-based corrective layer to reduce approximations errors on a subset of structures for which full elasto-plastic FE <b>simulations</b> are performed, the solutions of which are subsequently used as training set for a <b>Convolutional</b> <b>Neural</b> <b>Network</b> algorithm designed to learn the error between full FE and plastic correction approximations.

{{</citation>}}


## physics.flu-dyn (2)



### (109/145) Neural SPH: Improved Neural Modeling of Lagrangian Fluid Dynamics (Artur P. Toshev et al., 2024)

{{<citation>}}

Artur P. Toshev, Jonas A. Erbesdobler, Nikolaus A. Adams, Johannes Brandstetter. (2024)  
**Neural SPH: Improved Neural Modeling of Lagrangian Fluid Dynamics**
<br/>
<button class="copy-to-clipboard" title="Neural SPH: Improved Neural Modeling of Lagrangian Fluid Dynamics" index=109>
  <span class="copy-to-clipboard-item">Copy Title<span>
</button>
<div class="toast toast-copied toast-index-109 align-items-center text-bg-secondary border-0 position-absolute top-0 end-0" role="alert" aria-live="assertive" aria-atomic="true">
  <div class="d-flex">
    <div class="toast-body">
      Copied!
    </div>
  </div>
</div>

---
Primary Category: physics.flu-dyn  
Categories: cs-LG, physics-flu-dyn, physics.flu-dyn  
Keyword Score: 40  
Keywords: Graph Neural Network, Graph Neural Network, Simulation, Simulator  
<a type="button" class="btn btn-outline-primary" href="http://arxiv.org/abs/2402.06275v1" target="_blank" >Paper Link</a>
<button type="button" class="btn btn-outline-primary download-pdf" url="https://arxiv.org/pdf/2402.06275v1.pdf" filename="2402.06275v1.pdf">Download PDF</button>

---


**ABSTRACT**  
Smoothed particle hydrodynamics (SPH) is omnipresent in modern engineering and scientific disciplines. SPH is a class of Lagrangian schemes that discretize fluid dynamics via finite material points that are tracked through the evolving velocity field. Due to the particle-like nature of the <b>simulation,</b> <b>graph</b> <b>neural</b> <b>networks</b> <b>(GNNs)</b> have emerged as appealing and successful surrogates. However, the practical utility of such <b>GNN-based</b> simulators relies on their ability to faithfully model physics, providing accurate and stable predictions over long time horizons - which is a notoriously hard problem. In this work, we identify particle clustering originating from tensile instabilities as one of the primary pitfalls. Based on these insights, we enhance both training and rollout inference of state-of-the-art <b>GNN-based</b> simulators with varying components from standard SPH solvers, including pressure, viscous, and external force components. All neural SPH-enhanced simulators achieve better performance, often by orders of magnitude, than the baseline <b>GNNs,</b> allowing for significantly longer rollouts and significantly better physics modeling. Code available under (https://github.com/tumaer/neuralsph).

{{</citation>}}


### (110/145) Precision Air Flow Control via EHD Actuator: A Co-simulation and Control Design Case Study (Afshin Shaygani et al., 2024)

{{<citation>}}

Afshin Shaygani, Kazimierz Adamiak, Mehrdad R. Kermani. (2024)  
**Precision Air Flow Control via EHD Actuator: A Co-simulation and Control Design Case Study**
<br/>
<button class="copy-to-clipboard" title="Precision Air Flow Control via EHD Actuator: A Co-simulation and Control Design Case Study" index=110>
  <span class="copy-to-clipboard-item">Copy Title<span>
</button>
<div class="toast toast-copied toast-index-110 align-items-center text-bg-secondary border-0 position-absolute top-0 end-0" role="alert" aria-live="assertive" aria-atomic="true">
  <div class="d-flex">
    <div class="toast-body">
      Copied!
    </div>
  </div>
</div>

---
Primary Category: physics.flu-dyn  
Categories: cs-SY, eess-SY, physics-flu-dyn, physics-plasm-ph, physics.flu-dyn  
Keyword Score: 20  
Keywords: Simulation, Simulator  
<a type="button" class="btn btn-outline-primary" href="http://arxiv.org/abs/2402.06588v1" target="_blank" >Paper Link</a>
<button type="button" class="btn btn-outline-primary download-pdf" url="https://arxiv.org/pdf/2402.06588v1.pdf" filename="2402.06588v1.pdf">Download PDF</button>

---


**ABSTRACT**  
A Dielectric Barrier Discharge (DBD) plasma actuator for controlling airflow is proposed. It consists of diverging and converging nozzles, two concentric cylinders and an actuator mounted in-between the two cylinders. The actuator employs electrohydrodynamic (EHD) body force to induce an air jet within the air gap between the two cylinders, effectively creating a suction area while passing through the diverging nozzle, due to the Coanda effect. While merging with the air stream inside the inner cylinder, the Coanda jet effectively enhances amplification of the airflow. The outflow rate is measured by a velocity sensor at the outlet and controlled by the plasma actuator. The control strategy is based on the Active Disturbance Rejection Control (ADRC) and compared to the baseline PID controller. The actuator was modelled by seamlessly linking two modeling platforms for a co-simulation study. The CFD <b>simulation</b> of the plasma and airflow was carried out in the COMSOL multi-physics commercial software, and the control was implemented in the Simulink. The DBD plasma model was based on the two-species model of discharge, and the electric body force, calculated from the plasma <b>simulation,</b> was used in the Navier-Stokes equation for the turbulent flow <b>simulation.</b> The plasma-air flow system was analyzed using the input (the actuator voltage) and output (the outlet flow rate) data for the control design. Finally, the performance of the system of air flow control device was tested and discussed in the co-simulation process.

{{</citation>}}


## eess.AS (1)



### (111/145) Data-driven Joint Detection and Localization of Acoustic Reflectors (H. Nazim Bicer et al., 2024)

{{<citation>}}

H. Nazim Bicer, Cagdas Tuna, Andreas Walther, EmanuÃ«l A. P. Habets. (2024)  
**Data-driven Joint Detection and Localization of Acoustic Reflectors**
<br/>
<button class="copy-to-clipboard" title="Data-driven Joint Detection and Localization of Acoustic Reflectors" index=111>
  <span class="copy-to-clipboard-item">Copy Title<span>
</button>
<div class="toast toast-copied toast-index-111 align-items-center text-bg-secondary border-0 position-absolute top-0 end-0" role="alert" aria-live="assertive" aria-atomic="true">
  <div class="d-flex">
    <div class="toast-body">
      Copied!
    </div>
  </div>
</div>

---
Primary Category: eess.AS  
Categories: cs-SD, eess-AS, eess.AS  
Keyword Score: 40  
Keywords: Convolution, Simulation, Simulator, Recurrent Neural Network  
<a type="button" class="btn btn-outline-primary" href="http://arxiv.org/abs/2402.06246v1" target="_blank" >Paper Link</a>
<button type="button" class="btn btn-outline-primary download-pdf" url="https://arxiv.org/pdf/2402.06246v1.pdf" filename="2402.06246v1.pdf">Download PDF</button>

---


**ABSTRACT**  
Room geometry inference algorithms rely on the localization of acoustic reflectors to identify boundary surfaces of an enclosure. Rooms with highly absorptive walls or walls at large distances from the measurement setup pose challenges for such algorithms. As it is not always possible to localize all walls, we present a data-driven method to jointly detect and localize acoustic reflectors that correspond to nearby and/or reflective walls. A multi-branch <b>convolutional</b> <b>recurrent</b> <b>neural</b> <b>network</b> is employed for this purpose. The network's input consists of a time-domain acoustic beamforming map, obtained via Radon transform from multi-channel room impulse responses. A modified loss function is proposed that forces the network to pay more attention to walls that can be estimated with a small error. <b>Simulation</b> results show that the proposed method can detect nearby and/or reflective walls and improve the localization performance for the detected walls.

{{</citation>}}


## cs.RO (6)



### (112/145) LLMs for Coding and Robotics Education (Peng Shu et al., 2024)

{{<citation>}}

Peng Shu, Huaqin Zhao, Hanqi Jiang, Yiwei Li, Shaochen Xu, Yi Pan, Zihao Wu, Zhengliang Liu, Guoyu Lu, Le Guan, Gong Chen, Xianqiao Wang Tianming Liu. (2024)  
**LLMs for Coding and Robotics Education**
<br/>
<button class="copy-to-clipboard" title="LLMs for Coding and Robotics Education" index=112>
  <span class="copy-to-clipboard-item">Copy Title<span>
</button>
<div class="toast toast-copied toast-index-112 align-items-center text-bg-secondary border-0 position-absolute top-0 end-0" role="alert" aria-live="assertive" aria-atomic="true">
  <div class="d-flex">
    <div class="toast-body">
      Copied!
    </div>
  </div>
</div>

---
Primary Category: cs.RO  
Categories: cs-AI, cs-RO, cs.RO  
Keyword Score: 40  
Keywords: GPT, Code Generation, Large Language Model, Large Language Model  
<a type="button" class="btn btn-outline-primary" href="http://arxiv.org/abs/2402.06116v1" target="_blank" >Paper Link</a>
<button type="button" class="btn btn-outline-primary download-pdf" url="https://arxiv.org/pdf/2402.06116v1.pdf" filename="2402.06116v1.pdf">Download PDF</button>

---


**ABSTRACT**  
<b>Large</b> <b>language</b> <b>models</b> and multimodal <b>large</b> <b>language</b> <b>models</b> have revolutionized artificial intelligence recently. An increasing number of regions are now embracing these advanced technologies. Within this context, robot coding education is garnering increasing attention. To teach young children how to <b>code</b> <b>and</b> compete in robot challenges, <b>large</b> <b>language</b> <b>models</b> are being utilized for robot <b>code</b> <b>explanation,</b> generation, and modification. In this paper, we highlight an important trend in robot coding education. We test several mainstream <b>large</b> <b>language</b> <b>models</b> on both traditional coding tasks and the more challenging task of robot <b>code</b> <b>generation,</b> which includes block diagrams. Our results show that <b>GPT-4V</b> outperforms other models in all of our tests but struggles with generating block diagram images.

{{</citation>}}


### (113/145) Reinforcement Learning for Blind Stair Climbing with Legged and Wheeled-Legged Robots (Simon Chamorro et al., 2024)

{{<citation>}}

Simon Chamorro, Victor Klemm, Miguel de la Iglesia Valls, Christopher Pal, Roland Siegwart. (2024)  
**Reinforcement Learning for Blind Stair Climbing with Legged and Wheeled-Legged Robots**
<br/>
<button class="copy-to-clipboard" title="Reinforcement Learning for Blind Stair Climbing with Legged and Wheeled-Legged Robots" index=113>
  <span class="copy-to-clipboard-item">Copy Title<span>
</button>
<div class="toast toast-copied toast-index-113 align-items-center text-bg-secondary border-0 position-absolute top-0 end-0" role="alert" aria-live="assertive" aria-atomic="true">
  <div class="d-flex">
    <div class="toast-body">
      Copied!
    </div>
  </div>
</div>

---
Primary Category: cs.RO  
Categories: cs-RO, cs.RO  
Keyword Score: 30  
Keywords: Reinforcement Learning, Simulation, Simulator  
<a type="button" class="btn btn-outline-primary" href="http://arxiv.org/abs/2402.06143v1" target="_blank" >Paper Link</a>
<button type="button" class="btn btn-outline-primary download-pdf" url="https://arxiv.org/pdf/2402.06143v1.pdf" filename="2402.06143v1.pdf">Download PDF</button>

---


**ABSTRACT**  
In recent years, legged and wheeled-legged robots have gained prominence for tasks in environments predominantly created for humans across various domains. One significant challenge faced by many of these robots is their limited capability to navigate stairs, which hampers their functionality in multi-story environments. This study proposes a method aimed at addressing this limitation, employing <b>reinforcement</b> <b>learning</b> to develop a versatile controller applicable to a wide range of robots. In contrast to the conventional velocity-based controllers, our approach builds upon a position-based formulation of the RL task, which we show to be vital for stair climbing. Furthermore, the methodology leverages an asymmetric actor-critic structure, enabling the utilization of privileged information from simulated environments during training while eliminating the reliance on exteroceptive sensors during real-world deployment. Another key feature of the proposed approach is the incorporation of a boolean observation within the controller, enabling the activation or deactivation of a stair-climbing mode. We present our results on different quadrupeds and bipedal robots in <b>simulation</b> and showcase how our method allows the balancing robot Ascento to climb 15cm stairs in the real world, a task that was previously impossible for this robot.

{{</citation>}}


### (114/145) ASAP-MPC: An Asynchronous Update Scheme for Online Motion Planning with Nonlinear Model Predictive Control (Dries Dirckx et al., 2024)

{{<citation>}}

Dries Dirckx, Mathias Bos, Bastiaan Vandewal, Lander Vanroye, Wilm DecrÃ©, Jan Swevers. (2024)  
**ASAP-MPC: An Asynchronous Update Scheme for Online Motion Planning with Nonlinear Model Predictive Control**
<br/>
<button class="copy-to-clipboard" title="ASAP-MPC: An Asynchronous Update Scheme for Online Motion Planning with Nonlinear Model Predictive Control" index=114>
  <span class="copy-to-clipboard-item">Copy Title<span>
</button>
<div class="toast toast-copied toast-index-114 align-items-center text-bg-secondary border-0 position-absolute top-0 end-0" role="alert" aria-live="assertive" aria-atomic="true">
  <div class="d-flex">
    <div class="toast-body">
      Copied!
    </div>
  </div>
</div>

---
Primary Category: cs.RO  
Categories: cs-RO, cs.RO, math-OC  
Keyword Score: 20  
Keywords: Simulation, Simulator  
<a type="button" class="btn btn-outline-primary" href="http://arxiv.org/abs/2402.06263v1" target="_blank" >Paper Link</a>
<button type="button" class="btn btn-outline-primary download-pdf" url="https://arxiv.org/pdf/2402.06263v1.pdf" filename="2402.06263v1.pdf">Download PDF</button>

---


**ABSTRACT**  
This paper presents a Nonlinear Model Predictive Control (NMPC) scheme targeted at motion planning for mechatronic motion systems, such as drones and mobile platforms. NMPC-based motion planning typically requires low computation times to be able to provide control inputs at the required rate for system stability, disturbance rejection, and overall performance. Although there exist various ways in literature to reduce the solution times in NMPC, such times may not be low enough to allow real-time implementations. This paper presents ASAP-MPC, an approach to handle varying, sometimes restrictively large, solution times with an asynchronous update scheme, always allowing for full convergence and real-time execution. The NMPC algorithm is combined with a linear state feedback controller tracking the optimised trajectories for improved robustness against possible disturbances and plant-model mismatch. ASAP-MPC seamlessly merges trajectories, resulting from subsequent NMPC solutions, providing a smooth and continuous overall trajectory for the motion system. This frameworks applicability to embedded applications is shown on two different experiment setups where a state-of-the-art method fails: a quadcopter flying through a cluttered environment in hardware-in-the-loop <b>simulation</b> and a scale model truck-trailer manoeuvring in a structured lab environment.

{{</citation>}}


### (115/145) Virtual and Remote Robotic Laboratory Using EJS, MATLAB and LabVIEW (Dictino Chaos et al., 2024)

{{<citation>}}

Dictino Chaos, JesÃºs ChacÃ³n, Jose Antonio Lopez-Orozco, Sebastian Dormido. (2024)  
**Virtual and Remote Robotic Laboratory Using EJS, MATLAB and LabVIEW**
<br/>
<button class="copy-to-clipboard" title="Virtual and Remote Robotic Laboratory Using EJS, MATLAB and LabVIEW" index=115>
  <span class="copy-to-clipboard-item">Copy Title<span>
</button>
<div class="toast toast-copied toast-index-115 align-items-center text-bg-secondary border-0 position-absolute top-0 end-0" role="alert" aria-live="assertive" aria-atomic="true">
  <div class="d-flex">
    <div class="toast-body">
      Copied!
    </div>
  </div>
</div>

---
Primary Category: cs.RO  
Categories: cs-RO, cs-SY, cs.RO, eess-SY  
Keyword Score: 20  
Keywords: Simulation, Simulator  
<a type="button" class="btn btn-outline-primary" href="http://arxiv.org/abs/2402.06203v1" target="_blank" >Paper Link</a>
<button type="button" class="btn btn-outline-primary download-pdf" url="https://arxiv.org/pdf/2402.06203v1.pdf" filename="2402.06203v1.pdf">Download PDF</button>

---


**ABSTRACT**  
This paper describes the design and implementation of a virtual and remote laboratory based on Easy Java <b>Simulations</b> (EJS) and LabVIEW. The main application of this laboratory is to improve the study of sensors in Mobile Robotics, dealing with the problems that arise on the real world experiments. This laboratory allows the user to work from their homes, tele-operating a real robot that takes measurements from its sensors in order to obtain a map of its environment. In addition, the application allows interacting with a robot <b>simulation</b> (virtual laboratory) or with a real robot (remote laboratory), with the same simple and intuitive graphical user interface in EJS. Thus, students can develop signal processing and control algorithms for the robot in <b>simulation</b> and then deploy them on the real robot for testing purposes. Practical examples of application of the laboratory on the inter University Master of Systems Engineering and Automatic Control are presented.

{{</citation>}}


### (116/145) Dynamic Q-planning for Online UAV Path Planning in Unknown and Complex Environments (Lidia Gianne Souza da Rocha et al., 2024)

{{<citation>}}

Lidia Gianne Souza da Rocha, Kenny Anderson Queiroz Caldas, Marco Henrique Terra, Fabio Ramos, Kelen Cristiane Teixeira Vivaldini. (2024)  
**Dynamic Q-planning for Online UAV Path Planning in Unknown and Complex Environments**
<br/>
<button class="copy-to-clipboard" title="Dynamic Q-planning for Online UAV Path Planning in Unknown and Complex Environments" index=116>
  <span class="copy-to-clipboard-item">Copy Title<span>
</button>
<div class="toast toast-copied toast-index-116 align-items-center text-bg-secondary border-0 position-absolute top-0 end-0" role="alert" aria-live="assertive" aria-atomic="true">
  <div class="d-flex">
    <div class="toast-body">
      Copied!
    </div>
  </div>
</div>

---
Primary Category: cs.RO  
Categories: cs-RO, cs.RO  
Keyword Score: 10  
Keywords: Reinforcement Learning  
<a type="button" class="btn btn-outline-primary" href="http://arxiv.org/abs/2402.06297v1" target="_blank" >Paper Link</a>
<button type="button" class="btn btn-outline-primary download-pdf" url="https://arxiv.org/pdf/2402.06297v1.pdf" filename="2402.06297v1.pdf">Download PDF</button>

---


**ABSTRACT**  
Unmanned Aerial Vehicles need an online path planning capability to move in high-risk missions in unknown and complex environments to complete them safely. However, many algorithms reported in the literature may not return reliable trajectories to solve online problems in these scenarios. The Q-Learning algorithm, a <b>Reinforcement</b> <b>Learning</b> Technique, can generate trajectories in real-time and has demonstrated fast and reliable results. This technique, however, has the disadvantage of defining the iteration number. If this value is not well defined, it will take a long time or not return an optimal trajectory. Therefore, we propose a method to dynamically choose the number of iterations to obtain the best performance of Q-Learning. The proposed method is compared to the Q-Learning algorithm with a fixed number of iterations, A*, Rapid-Exploring Random Tree, and Particle Swarm Optimization. As a result, the proposed Q-learning algorithm demonstrates the efficacy and reliability of online path planning with a dynamic number of iterations to carry out online missions in unknown and complex environments.

{{</citation>}}


### (117/145) Continuous-Time Radar-Inertial and Lidar-Inertial Odometry using a Gaussian Process Motion Prior (Keenan Burnett et al., 2024)

{{<citation>}}

Keenan Burnett, Angela P. Schoellig, Timothy D. Barfoot. (2024)  
**Continuous-Time Radar-Inertial and Lidar-Inertial Odometry using a Gaussian Process Motion Prior**
<br/>
<button class="copy-to-clipboard" title="Continuous-Time Radar-Inertial and Lidar-Inertial Odometry using a Gaussian Process Motion Prior" index=117>
  <span class="copy-to-clipboard-item">Copy Title<span>
</button>
<div class="toast toast-copied toast-index-117 align-items-center text-bg-secondary border-0 position-absolute top-0 end-0" role="alert" aria-live="assertive" aria-atomic="true">
  <div class="d-flex">
    <div class="toast-body">
      Copied!
    </div>
  </div>
</div>

---
Primary Category: cs.RO  
Categories: cs-RO, cs.RO  
Keyword Score: 10  
Keywords: Gaussian Process  
<a type="button" class="btn btn-outline-primary" href="http://arxiv.org/abs/2402.06174v1" target="_blank" >Paper Link</a>
<button type="button" class="btn btn-outline-primary download-pdf" url="https://arxiv.org/pdf/2402.06174v1.pdf" filename="2402.06174v1.pdf">Download PDF</button>

---


**ABSTRACT**  
In this work, we demonstrate continuous-time radar-inertial and lidar-inertial odometry using a <b>Gaussian</b> <b>process</b> motion prior. Using a sparse prior, we demonstrate improved computational complexity during preintegration and interpolation. We use a white-noise-on-acceleration motion prior and treat the gyroscope as a direct measurement of the state while preintegrating accelerometer measurements to form relative velocity factors. Our odometry is implemented using sliding-window batch trajectory estimation. To our knowledge, our work is the first to demonstrate radar-inertial odometry with a spinning mechanical radar using both gyroscope and accelerometer measurements. We improve the performance of our radar odometry by 19\% by incorporating an IMU. Our approach is efficient and we demonstrate real-time performance. Code for this project can be found at: https://github.com/utiasASRL/steam_icp

{{</citation>}}


## cs.SD (4)



### (118/145) Exploiting spatial diversity for increasing the robustness of sound source localization systems against reverberation (Guillermo Garcia-Barrios et al., 2024)

{{<citation>}}

Guillermo Garcia-Barrios, Eduardo Latorre Iglesias, Juana M. Gutierrez-Arriola, Ruben Fraile, Nicolas Saenz-Lechon, Victor Jose Osma-Ruiz. (2024)  
**Exploiting spatial diversity for increasing the robustness of sound source localization systems against reverberation**
<br/>
<button class="copy-to-clipboard" title="Exploiting spatial diversity for increasing the robustness of sound source localization systems against reverberation" index=118>
  <span class="copy-to-clipboard-item">Copy Title<span>
</button>
<div class="toast toast-copied toast-index-118 align-items-center text-bg-secondary border-0 position-absolute top-0 end-0" role="alert" aria-live="assertive" aria-atomic="true">
  <div class="d-flex">
    <div class="toast-body">
      Copied!
    </div>
  </div>
</div>

---
Primary Category: cs.SD  
Categories: cs-SD, cs.SD, eess-AS, eess-SP  
Keyword Score: 30  
Keywords: Recommendation, Simulation, Simulator  
<a type="button" class="btn btn-outline-primary" href="http://arxiv.org/abs/2402.06411v1" target="_blank" >Paper Link</a>
<button type="button" class="btn btn-outline-primary download-pdf" url="https://arxiv.org/pdf/2402.06411v1.pdf" filename="2402.06411v1.pdf">Download PDF</button>

---


**ABSTRACT**  
Acoustic reverberation is one of the most relevant factors that hampers the localization of a sound source inside a room. To date, several approaches have been proposed to deal with it, but have not always been evaluated under realistic conditions. This paper proposes exploiting spatial diversity as an alternative approach to achieve robustness against reverberation. The theoretical arguments supporting this approach are first presented and later confirmed by means of <b>simulation</b> results and real measurements. <b>Simulations</b> are run for reverberation times up to 2 s, thus providing results with a wider range of validity than in other previous research works. It is concluded that the use of systems consisting of several, sufficiently separated, small arrays leads to the best results in reverberant environments. Some <b>recommendations</b> are given regarding the choice of the array sizes, the separation among them, and the way to combine SRP-PHAT maps obtained from diverse arrays.

{{</citation>}}


### (119/145) A New Approach to Voice Authenticity (Nicolas M. MÃ¼ller et al., 2024)

{{<citation>}}

Nicolas M. MÃ¼ller, Piotr Kawa, Shen Hu, Matthias Neu, Jennifer Williams, Philip Sperl, Konstantin BÃ¶ttinger. (2024)  
**A New Approach to Voice Authenticity**
<br/>
<button class="copy-to-clipboard" title="A New Approach to Voice Authenticity" index=119>
  <span class="copy-to-clipboard-item">Copy Title<span>
</button>
<div class="toast toast-copied toast-index-119 align-items-center text-bg-secondary border-0 position-absolute top-0 end-0" role="alert" aria-live="assertive" aria-atomic="true">
  <div class="d-flex">
    <div class="toast-body">
      Copied!
    </div>
  </div>
</div>

---
Primary Category: cs.SD  
Categories: cs-AI, cs-SD, cs.SD, eess-AS  
Keyword Score: 30  
Keywords: Text-to-speech, Text-to-speech, Summarization  
<a type="button" class="btn btn-outline-primary" href="http://arxiv.org/abs/2402.06304v1" target="_blank" >Paper Link</a>
<button type="button" class="btn btn-outline-primary download-pdf" url="https://arxiv.org/pdf/2402.06304v1.pdf" filename="2402.06304v1.pdf">Download PDF</button>

---


**ABSTRACT**  
Voice faking, driven primarily by recent advances in <b>text-to-speech</b> <b>(TTS)</b> synthesis technology, poses significant societal challenges. Currently, the prevailing assumption is that unaltered human speech can be considered genuine, while fake speech comes from <b>TTS</b> synthesis. We argue that this binary distinction is oversimplified. For instance, altered playback speeds can be used for malicious purposes, like in the 'Drunken Nancy Pelosi' incident. Similarly, editing of audio clips can be done ethically, e.g., for brevity or <b>summarization</b> in news reporting or podcasts, but editing can also create misleading narratives. In this paper, we propose a conceptual shift away from the binary paradigm of audio being either 'fake' or 'real'. Instead, our focus is on pinpointing 'voice edits', which encompass traditional modifications like filters and cuts, as well as <b>TTS</b> synthesis and VC systems. We delineate 6 categories and curate a new challenge dataset rooted in the M-AILABS corpus, for which we present baseline detection systems. And most importantly, we argue that merely categorizing audio as fake or real is a dangerous over-simplification that will fail to move the field of speech technology forward.

{{</citation>}}


### (120/145) Analytical model for the relation between signal bandwidth and spatial resolution in Steered-Response Power Phase Transform (SRP-PHAT) maps (Guillermo Garcia-Barrios et al., 2024)

{{<citation>}}

Guillermo Garcia-Barrios, Juana M. Gutierrez-Arriola, Nicolas Saenz-Lechon, Victor Jose Osma-Ruiz, Ruben Fraile. (2024)  
**Analytical model for the relation between signal bandwidth and spatial resolution in Steered-Response Power Phase Transform (SRP-PHAT) maps**
<br/>
<button class="copy-to-clipboard" title="Analytical model for the relation between signal bandwidth and spatial resolution in Steered-Response Power Phase Transform (SRP-PHAT) maps" index=120>
  <span class="copy-to-clipboard-item">Copy Title<span>
</button>
<div class="toast toast-copied toast-index-120 align-items-center text-bg-secondary border-0 position-absolute top-0 end-0" role="alert" aria-live="assertive" aria-atomic="true">
  <div class="d-flex">
    <div class="toast-body">
      Copied!
    </div>
  </div>
</div>

---
Primary Category: cs.SD  
Categories: cs-SD, cs.SD, eess-AS, eess-SP  
Keyword Score: 20  
Keywords: Simulation, Simulator  
<a type="button" class="btn btn-outline-primary" href="http://arxiv.org/abs/2402.06586v1" target="_blank" >Paper Link</a>
<button type="button" class="btn btn-outline-primary download-pdf" url="https://arxiv.org/pdf/2402.06586v1.pdf" filename="2402.06586v1.pdf">Download PDF</button>

---


**ABSTRACT**  
An analysis of the relationship between the bandwidth of acoustic signals and the required resolution of steered-response power phase transform (SRP-PHAT) maps used for sound source localization is presented. This relationship does not rely on the far-field assumption, nor does it depend on any specific array topology. The proposed analysis considers the computation of a SRP map as a process of sampling a set of generalized cross-correlation (GCC) functions, each one corresponding to a different microphone pair. From this approach, we derive a rule that relates GCC bandwidth with inter-microphone distance, resolution of the SRP map, and the potential position of the sound source relative to the array position. This rule is a sufficient condition for an aliasing-free calculation of the specified SRP-PHAT map. <b>Simulation</b> results show that limiting the bandwidth of the GCC according to such rule leads to significant reductions in sound source localization errors when sources are not in the immediate vicinity of the microphone array. These error reductions are more relevant for coarser resolutions of the SRP map, and they happen in both anechoic and reverberant environments.

{{</citation>}}


### (121/145) MusicMagus: Zero-Shot Text-to-Music Editing via Diffusion Models (Yixiao Zhang et al., 2024)

{{<citation>}}

Yixiao Zhang, Yukara Ikemiya, Gus Xia, Naoki Murata, Marco MartÃ­nez, Wei-Hsiang Liao, Yuki Mitsufuji, Simon Dixon. (2024)  
**MusicMagus: Zero-Shot Text-to-Music Editing via Diffusion Models**
<br/>
<button class="copy-to-clipboard" title="MusicMagus: Zero-Shot Text-to-Music Editing via Diffusion Models" index=121>
  <span class="copy-to-clipboard-item">Copy Title<span>
</button>
<div class="toast toast-copied toast-index-121 align-items-center text-bg-secondary border-0 position-absolute top-0 end-0" role="alert" aria-live="assertive" aria-atomic="true">
  <div class="d-flex">
    <div class="toast-body">
      Copied!
    </div>
  </div>
</div>

---
Primary Category: cs.SD  
Categories: cs-AI, cs-MM, cs-SD, cs.SD, eess-AS  
Keyword Score: 20  
Keywords: Supervised Learning, Zero-shot  
<a type="button" class="btn btn-outline-primary" href="http://arxiv.org/abs/2402.06178v1" target="_blank" >Paper Link</a>
<button type="button" class="btn btn-outline-primary download-pdf" url="https://arxiv.org/pdf/2402.06178v1.pdf" filename="2402.06178v1.pdf">Download PDF</button>

---


**ABSTRACT**  
Recent advances in text-to-music generation models have opened new avenues in musical creativity. However, music generation usually involves iterative refinements, and how to edit the generated music remains a significant challenge. This paper introduces a novel approach to the editing of music generated by such models, enabling the modification of specific attributes, such as genre, mood and instrument, while maintaining other aspects unchanged. Our method transforms text editing to \textit{latent space manipulation} while adding an extra constraint to enforce consistency. It seamlessly integrates with existing pretrained text-to-music diffusion models without requiring additional training. Experimental results demonstrate superior performance over both <b>zero-shot</b> and certain <b>supervised</b> baselines in style and timbre transfer evaluations. Additionally, we showcase the practical applicability of our approach in real-world music editing scenarios.

{{</citation>}}


## cs.DC (2)



### (122/145) Anubis: Towards Reliable Cloud AI Infrastructure via Proactive Validation (Yifan Xiong et al., 2024)

{{<citation>}}

Yifan Xiong, Yuting Jiang, Ziyue Yang, Lei Qu, Guoshuai Zhao, Shuguang Liu, Dong Zhong, Boris Pinzur, Jie Zhang, Yang Wang, Jithin Jose, Hossein Pourreza, Jeff Baxter, Kushal Datta, Prabhat Ram, Luke Melton, Joe Chau, Peng Cheng, Yongqiang Xiong, Lidong Zhou. (2024)  
**Anubis: Towards Reliable Cloud AI Infrastructure via Proactive Validation**
<br/>
<button class="copy-to-clipboard" title="Anubis: Towards Reliable Cloud AI Infrastructure via Proactive Validation" index=122>
  <span class="copy-to-clipboard-item">Copy Title<span>
</button>
<div class="toast toast-copied toast-index-122 align-items-center text-bg-secondary border-0 position-absolute top-0 end-0" role="alert" aria-live="assertive" aria-atomic="true">
  <div class="d-flex">
    <div class="toast-body">
      Copied!
    </div>
  </div>
</div>

---
Primary Category: cs.DC  
Categories: cs-DC, cs.DC  
Keyword Score: 30  
Keywords: Simulation, Simulator, Prompt  
<a type="button" class="btn btn-outline-primary" href="http://arxiv.org/abs/2402.06194v1" target="_blank" >Paper Link</a>
<button type="button" class="btn btn-outline-primary download-pdf" url="https://arxiv.org/pdf/2402.06194v1.pdf" filename="2402.06194v1.pdf">Download PDF</button>

---


**ABSTRACT**  
Reliability in cloud AI infrastructure is crucial for cloud service providers, <b>prompting</b> the widespread use of hardware redundancies. However, these redundancies can inadvertently lead to hidden degradation, so called "gray failure", for AI workloads, significantly affecting end-to-end performance and concealing performance issues, which complicates root cause analysis for failures and regressions. We introduce Anubis, a proactive validation system for AI infrastructure that mitigates hidden degradation caused by hardware redundancies and enhances overall reliability. Anubis features a comprehensive benchmark suite, capable of evaluating individual hardware components and representing most real AI workloads. It comprises a Validator which learns benchmark criteria to clearly pinpoint defective components. Additionally, Anubis incorporates a Selector to balance validation time and issue-related penalties, enabling optimal timing for validation execution with a tailored subset of benchmarks. Through testbed evaluation and <b>simulation,</b> we demonstrate that Anubis can increase the mean time between incidents by up to 22.61x. Anubis has been successfully deployed in Azure production, validating hundreds of thousands of GPUs over the last two years.

{{</citation>}}


### (123/145) Population Protocols for Exact Plurality Consensus -- How a small chance of failure helps to eliminate insignificant opinions (Gregor Bankhamer et al., 2024)

{{<citation>}}

Gregor Bankhamer, Petra Berenbrink, Felix Biermeier, Robert ElsÃ¤sser, Hamed Hosseinpour, Dominik Kaaser, Peter Kling. (2024)  
**Population Protocols for Exact Plurality Consensus -- How a small chance of failure helps to eliminate insignificant opinions**
<br/>
<button class="copy-to-clipboard" title="Population Protocols for Exact Plurality Consensus -- How a small chance of failure helps to eliminate insignificant opinions" index=123>
  <span class="copy-to-clipboard-item">Copy Title<span>
</button>
<div class="toast toast-copied toast-index-123 align-items-center text-bg-secondary border-0 position-absolute top-0 end-0" role="alert" aria-live="assertive" aria-atomic="true">
  <div class="d-flex">
    <div class="toast-body">
      Copied!
    </div>
  </div>
</div>

---
Primary Category: cs.DC  
Categories: cs-DC, cs.DC  
Keyword Score: 10  
Keywords: Pruning  
<a type="button" class="btn btn-outline-primary" href="http://arxiv.org/abs/2402.06471v1" target="_blank" >Paper Link</a>
<button type="button" class="btn btn-outline-primary download-pdf" url="https://arxiv.org/pdf/2402.06471v1.pdf" filename="2402.06471v1.pdf">Download PDF</button>

---


**ABSTRACT**  
We consider the \emph{exact plurality consensus} problem for \emph{population protocols}. Here, $n$ anonymous agents start each with one of $k$ opinions. Their goal is to agree on the initially most frequent opinion (the \emph{plurality opinion}) via random, pairwise interactions. The case of $k = 2$ opinions is known as the \emph{majority problem}. Recent breakthroughs led to an always correct, exact majority population protocol that is both time- and space-optimal, needing $O(\log n)$ states per agent and, with high probability, $O(\log n)$ time~[Doty, Eftekhari, Gasieniec, Severson, Stachowiak, and Uznanski; 2021]. We know that any always correct protocol requires $\Omega(k^2)$ states, while the currently best protocol needs $O(k^{11})$ states~[Natale and Ramezani; 2019]. For ordered opinions, this can be improved to $O(k^6)$~[Gasieniec, Hamilton, Martin, Spirakis, and Stachowiak; 2016]. We design protocols for plurality consensus that beat the quadratic lower bound by allowing a negligible failure probability. While our protocols might fail, they identify the plurality opinion with high probability even if the bias is $1$. Our first protocol achieves this via $k-1$ tournaments in time $O(k \cdot \log n)$ using $O(k + \log n)$ states. While it assumes an ordering on the opinions, we remove this restriction in our second protocol, at the cost of a slightly increased time $O(k \cdot \log n + \log^2 n)$. By efficiently <b>pruning</b> insignificant opinions, our final protocol reduces the number of tournaments at the cost of a slightly increased state complexity $O(k \cdot \log\log n + \log n)$. This improves the time to $O(n / x_{\max} \cdot \log n + \log^2 n)$, where $x_{\max}$ is the initial size of the plurality. Note that $n/x_{\max}$ is at most $k$ and can be much smaller (e.g., in case of a large bias or if there are many small opinions).

{{</citation>}}


## stat.CO (1)



### (124/145) Relative frequencies of constrained events in stochastic processes: An analytical approach (S. Rusconi et al., 2024)

{{<citation>}}

S. Rusconi, E. Akhmatskaya, D. Sokolovski, N. Ballard, J. C. de la Cal. (2024)  
**Relative frequencies of constrained events in stochastic processes: An analytical approach**
<br/>
<button class="copy-to-clipboard" title="Relative frequencies of constrained events in stochastic processes: An analytical approach" index=124>
  <span class="copy-to-clipboard-item">Copy Title<span>
</button>
<div class="toast toast-copied toast-index-124 align-items-center text-bg-secondary border-0 position-absolute top-0 end-0" role="alert" aria-live="assertive" aria-atomic="true">
  <div class="d-flex">
    <div class="toast-body">
      Copied!
    </div>
  </div>
</div>

---
Primary Category: stat.CO  
Categories: cond-mat-mtrl-sci, cond-mat-soft, cs-CE, physics-chem-ph, stat-CO, stat.CO  
Keyword Score: 23  
Keywords: Sample Size, Simulation, Simulator  
<a type="button" class="btn btn-outline-primary" href="http://arxiv.org/abs/2402.06536v1" target="_blank" >Paper Link</a>
<button type="button" class="btn btn-outline-primary download-pdf" url="https://arxiv.org/pdf/2402.06536v1.pdf" filename="2402.06536v1.pdf">Download PDF</button>

---


**ABSTRACT**  
The stochastic <b>simulation</b> algorithm (SSA) and the corresponding Monte Carlo (MC) method are among the most common approaches for studying stochastic processes. They rely on knowledge of interevent probability density functions (PDFs) and on information about dependencies between all possible events. Analytical representations of a PDF are difficult to specify in advance, in many real life applications. Knowing the shapes of PDFs, and using experimental data, different optimization schemes can be applied in order to evaluate probability density functions and, therefore, the properties of the studied system. Such methods, however, are computationally demanding, and often not feasible. We show that, in the case where experimentally accessed properties are directly related to the frequencies of events involved, it may be possible to replace the heavy Monte Carlo core of optimization schemes with an analytical solution. Such a replacement not only provides a more accurate estimation of the properties of the process, but also reduces the <b>simulation</b> time by a factor of order of the <b>sample</b> <b>size</b> (at least $\approx 10^4$). The proposed analytical approach is valid for any choice of PDF. The accuracy, computational efficiency, and advantages of the method over MC procedures are demonstrated in the exactly solvable case and in the evaluation of branching fractions in controlled radical polymerization (CRP) of acrylic monomers. This polymerization can be modeled by a constrained stochastic process. Constrained systems are quite common, and this makes the method useful for various applications.

{{</citation>}}


## eess.IV (1)



### (125/145) Cardiac ultrasound simulation for autonomous ultrasound navigation (Abdoul Aziz Amadou et al., 2024)

{{<citation>}}

Abdoul Aziz Amadou, Laura Peralta, Paul Dryburgh, Paul Klein, Kaloian Petkov, Richard James Housden, Vivek Singh, Rui Liao, Young-Ho Kim, Florin Christian Ghesu, Tommaso Mansi, Ronak Rajani, Alistair Young, Kawal Rhode. (2024)  
**Cardiac ultrasound simulation for autonomous ultrasound navigation**
<br/>
<button class="copy-to-clipboard" title="Cardiac ultrasound simulation for autonomous ultrasound navigation" index=125>
  <span class="copy-to-clipboard-item">Copy Title<span>
</button>
<div class="toast toast-copied toast-index-125 align-items-center text-bg-secondary border-0 position-absolute top-0 end-0" role="alert" aria-live="assertive" aria-atomic="true">
  <div class="d-flex">
    <div class="toast-body">
      Copied!
    </div>
  </div>
</div>

---
Primary Category: eess.IV  
Categories: I-6-0; I-5-4; J-3, cs-CV, cs-LG, eess-IV, eess.IV  
Keyword Score: 20  
Keywords: Simulation, Simulator  
<a type="button" class="btn btn-outline-primary" href="http://arxiv.org/abs/2402.06463v1" target="_blank" >Paper Link</a>
<button type="button" class="btn btn-outline-primary download-pdf" url="https://arxiv.org/pdf/2402.06463v1.pdf" filename="2402.06463v1.pdf">Download PDF</button>

---


**ABSTRACT**  
Ultrasound is well-established as an imaging modality for diagnostic and interventional purposes. However, the image quality varies with operator skills as acquiring and interpreting ultrasound images requires extensive training due to the imaging artefacts, the range of acquisition parameters and the variability of patient anatomies. Automating the image acquisition task could improve acquisition reproducibility and quality but training such an algorithm requires large amounts of navigation data, not saved in routine examinations. Thus, we propose a method to generate large amounts of ultrasound images from other modalities and from arbitrary positions, such that this pipeline can later be used by learning algorithms for navigation. We present a novel <b>simulation</b> pipeline which uses segmentations from other modalities, an optimized volumetric data representation and GPU-accelerated Monte Carlo path tracing to generate view-dependent and patient-specific ultrasound images. We extensively validate the correctness of our pipeline with a phantom experiment, where structures' sizes, contrast and speckle noise properties are assessed. Furthermore, we demonstrate its usability to train neural networks for navigation in an echocardiography view classification experiment by generating synthetic images from more than 1000 patients. Networks pre-trained with our <b>simulations</b> achieve significantly superior performance in settings where large real datasets are not available, especially for under-represented classes. The proposed approach allows for fast and accurate patient-specific ultrasound image generation, and its usability for training networks for navigation-related tasks is demonstrated.

{{</citation>}}


## eess.SP (1)



### (126/145) Outage performance of the $Î±$-Beaulieu-Xie Shadowed Fading Channel Model (Aleksey S. Gvozdarev, 2024)

{{<citation>}}

Aleksey S. Gvozdarev. (2024)  
**Outage performance of the $Î±$-Beaulieu-Xie Shadowed Fading Channel Model**
<br/>
<button class="copy-to-clipboard" title="Outage performance of the $Î±$-Beaulieu-Xie Shadowed Fading Channel Model" index=126>
  <span class="copy-to-clipboard-item">Copy Title<span>
</button>
<div class="toast toast-copied toast-index-126 align-items-center text-bg-secondary border-0 position-absolute top-0 end-0" role="alert" aria-live="assertive" aria-atomic="true">
  <div class="d-flex">
    <div class="toast-body">
      Copied!
    </div>
  </div>
</div>

---
Primary Category: eess.SP  
Categories: 94A05, 68M18, cs-IT, eess-SP, eess.SP, math-IT  
Keyword Score: 20  
Keywords: Simulation, Simulator  
<a type="button" class="btn btn-outline-primary" href="http://arxiv.org/abs/2402.06337v1" target="_blank" >Paper Link</a>
<button type="button" class="btn btn-outline-primary download-pdf" url="https://arxiv.org/pdf/2402.06337v1.pdf" filename="2402.06337v1.pdf">Download PDF</button>

---


**ABSTRACT**  
The research presents the closed-form outage analysis of the newly presented $\alpha$-modification of the shadowed Beaulieu-Xie fading model for wireless communications. For the considered channel, the closed-form analytical expressions for the outage probability (including its upper and lower bounds), raw moments, amount of fading, and channel quality estimation indicator are derived. The carried out thorough numerical <b>simulation</b> and analysis demonstrates strong agreement with the presented closed-form solutions and illustrates the relationship between the outage probability and channel parameters.

{{</citation>}}


## math.NA (2)



### (127/145) An integrated heart-torso electromechanical model for the simulation of electrophysiogical outputs accounting for myocardial deformation (Elena Zappon et al., 2024)

{{<citation>}}

Elena Zappon, Matteo Salvador, Roberto Piersanti, Francesco Regazzoni, Luca Dede', Alfio Quarteroni. (2024)  
**An integrated heart-torso electromechanical model for the simulation of electrophysiogical outputs accounting for myocardial deformation**
<br/>
<button class="copy-to-clipboard" title="An integrated heart-torso electromechanical model for the simulation of electrophysiogical outputs accounting for myocardial deformation" index=127>
  <span class="copy-to-clipboard-item">Copy Title<span>
</button>
<div class="toast toast-copied toast-index-127 align-items-center text-bg-secondary border-0 position-absolute top-0 end-0" role="alert" aria-live="assertive" aria-atomic="true">
  <div class="d-flex">
    <div class="toast-body">
      Copied!
    </div>
  </div>
</div>

---
Primary Category: math.NA  
Categories: 65Z05, 92C10, 92C50, G-1-10; I-6-5; I-6-4; J-3, cs-NA, math-NA, math.NA  
Keyword Score: 20  
Keywords: Simulation, Simulator  
<a type="button" class="btn btn-outline-primary" href="http://arxiv.org/abs/2402.06308v1" target="_blank" >Paper Link</a>
<button type="button" class="btn btn-outline-primary download-pdf" url="https://arxiv.org/pdf/2402.06308v1.pdf" filename="2402.06308v1.pdf">Download PDF</button>

---


**ABSTRACT**  
When generating in-silico clinical electrophysiological outputs, such as electrocardiograms (ECGs) and body surface potential maps (BSPMs), mathematical models have relied on single physics, i.e. of the cardiac electrophysiology (EP), neglecting the role of the heart motion. Since the heart is the most powerful source of electrical activity in the human body, its motion dynamically shifts the position of the principal electrical sources in the torso, influencing electrical potential distribution and potentially altering the EP outputs. In this work, we propose a computational model for the <b>simulation</b> of ECGs and BSPMs by coupling a cardiac electromechanical model with a model that simulates the propagation of the EP signal in the torso, thanks to a flexible numerical approach, that simulates the torso domain deformation induced by the myocardial displacement. Our model accounts for the major mechano-electrical feedbacks, along with unidirectional displacement and potential couplings from the heart to the surrounding body. For the numerical discretization, we employ a versatile intergrid transfer operator that allows for the use of different Finite Element spaces to be used in the cardiac and torso domains. Our numerical results are obtained on a realistic 3D biventricular-torso geometry, and cover both cases of sinus rhythm and ventricular tachycardia (VT), solving both the electromechanical-torso model in dynamical domains, and the classical electrophysiology-torso model in static domains. By comparing standard 12-lead ECG and BSPMs, we highlight the non-negligible effects of the myocardial contraction on the EP-outputs, especially in pathological conditions, such as the VT.

{{</citation>}}


### (128/145) Mesh-robust stability and convergence of variable-step deferred correction methods based on the BDF2 formula (Jiahe Yue et al., 2024)

{{<citation>}}

Jiahe Yue, Hong-lin Liao, Nan Liu. (2024)  
**Mesh-robust stability and convergence of variable-step deferred correction methods based on the BDF2 formula**
<br/>
<button class="copy-to-clipboard" title="Mesh-robust stability and convergence of variable-step deferred correction methods based on the BDF2 formula" index=128>
  <span class="copy-to-clipboard-item">Copy Title<span>
</button>
<div class="toast toast-copied toast-index-128 align-items-center text-bg-secondary border-0 position-absolute top-0 end-0" role="alert" aria-live="assertive" aria-atomic="true">
  <div class="d-flex">
    <div class="toast-body">
      Copied!
    </div>
  </div>
</div>

---
Primary Category: math.NA  
Categories: 65M06, 65M12, cs-NA, math-NA, math.NA  
Keyword Score: 10  
Keywords: Convolution  
<a type="button" class="btn btn-outline-primary" href="http://arxiv.org/abs/2402.06129v1" target="_blank" >Paper Link</a>
<button type="button" class="btn btn-outline-primary download-pdf" url="https://arxiv.org/pdf/2402.06129v1.pdf" filename="2402.06129v1.pdf">Download PDF</button>

---


**ABSTRACT**  
We provide a new theoretical framework for the variable-step deferred correction (DC) methods based on the well-known BDF2 formula. By using the discrete orthogonal <b>convolution</b> kernels, some high-order BDF2-DC methods are proven to be stable on arbitrary time grids according to the recent definition of stability (SINUM, 60: 2253-2272). It significantly relaxes the existing step-ratio restrictions for the BDF2-DC methods (BIT, 62: 1789-1822). The associated sharp error estimates are established by taking the numerical effects of the starting approximations into account, and they suggest that the BDF2-DC methods have no aftereffect, that is, the lower-order starting scheme for the BDF2 scheme will not cause a loss in the accuracy of the high-order BDF2-DC methods. Extensive tests on the graded and random time meshes are presented to support the new theory.

{{</citation>}}


## cs.NE (2)



### (129/145) Towards Chip-in-the-loop Spiking Neural Network Training via Metropolis-Hastings Sampling (Ali Safa et al., 2024)

{{<citation>}}

Ali Safa, Vikrant Jaltare, Samira Sebt, Kameron Gano, Johannes Leugering, Georges Gielen, Gert Cauwenberghs. (2024)  
**Towards Chip-in-the-loop Spiking Neural Network Training via Metropolis-Hastings Sampling**
<br/>
<button class="copy-to-clipboard" title="Towards Chip-in-the-loop Spiking Neural Network Training via Metropolis-Hastings Sampling" index=129>
  <span class="copy-to-clipboard-item">Copy Title<span>
</button>
<div class="toast toast-copied toast-index-129 align-items-center text-bg-secondary border-0 position-absolute top-0 end-0" role="alert" aria-live="assertive" aria-atomic="true">
  <div class="d-flex">
    <div class="toast-body">
      Copied!
    </div>
  </div>
</div>

---
Primary Category: cs.NE  
Categories: cs-CV, cs-NE, cs.NE  
Keyword Score: 20  
Keywords: Simulation, Simulator  
<a type="button" class="btn btn-outline-primary" href="http://arxiv.org/abs/2402.06284v1" target="_blank" >Paper Link</a>
<button type="button" class="btn btn-outline-primary download-pdf" url="https://arxiv.org/pdf/2402.06284v1.pdf" filename="2402.06284v1.pdf">Download PDF</button>

---


**ABSTRACT**  
This paper studies the use of Metropolis-Hastings sampling for training Spiking Neural Network (SNN) hardware subject to strong unknown non-idealities, and compares the proposed approach to the common use of the backpropagation of error (backprop) algorithm and surrogate gradients, widely used to train SNNs in literature. <b>Simulations</b> are conducted within a chip-in-the-loop training context, where an SNN subject to unknown distortion must be trained to detect cancer from measurements, within a biomedical application context. Our results show that the proposed approach strongly outperforms the use of backprop by up to $27\%$ higher accuracy when subject to strong hardware non-idealities. Furthermore, our results also show that the proposed approach outperforms backprop in terms of SNN generalization, needing $>10 \times$ less training data for achieving effective accuracy. These findings make the proposed training approach well-suited for SNN implementations in analog subthreshold circuits and other emerging technologies where unknown hardware non-idealities can jeopardize backprop.

{{</citation>}}


### (130/145) Fine-Tuning Surrogate Gradient Learning for Optimal Hardware Performance in Spiking Neural Networks (Ilkin Aliyev et al., 2024)

{{<citation>}}

Ilkin Aliyev, Tosiron Adegbija. (2024)  
**Fine-Tuning Surrogate Gradient Learning for Optimal Hardware Performance in Spiking Neural Networks**
<br/>
<button class="copy-to-clipboard" title="Fine-Tuning Surrogate Gradient Learning for Optimal Hardware Performance in Spiking Neural Networks" index=130>
  <span class="copy-to-clipboard-item">Copy Title<span>
</button>
<div class="toast toast-copied toast-index-130 align-items-center text-bg-secondary border-0 position-absolute top-0 end-0" role="alert" aria-live="assertive" aria-atomic="true">
  <div class="d-flex">
    <div class="toast-body">
      Copied!
    </div>
  </div>
</div>

---
Primary Category: cs.NE  
Categories: cs-NE, cs.NE  
Keyword Score: 20  
Keywords: Fine-tuning, Fine-tuning  
<a type="button" class="btn btn-outline-primary" href="http://arxiv.org/abs/2402.06211v1" target="_blank" >Paper Link</a>
<button type="button" class="btn btn-outline-primary download-pdf" url="https://arxiv.org/pdf/2402.06211v1.pdf" filename="2402.06211v1.pdf">Download PDF</button>

---


**ABSTRACT**  
The highly sparse activations in Spiking Neural Networks (SNNs) can provide tremendous energy efficiency benefits when carefully exploited in hardware. The behavior of sparsity in SNNs is uniquely shaped by the dataset and training hyperparameters. This work reveals novel insights into the impacts of training on hardware performance. Specifically, we explore the trade-offs between model accuracy and hardware efficiency. We focus on three key hyperparameters: surrogate gradient functions, beta, and membrane threshold. Results on an FPGA-based hardware platform show that the fast sigmoid surrogate function yields a lower firing rate with similar accuracy compared to the arctangent surrogate on the SVHN dataset. Furthermore, by cross-sweeping the beta and membrane threshold hyperparameters, we can achieve a 48% reduction in hardware-based inference latency with only 2.88% trade-off in inference accuracy compared to the default setting. Overall, this study highlights the importance of <b>fine-tuning</b> model hyperparameters as crucial for designing efficient SNN hardware accelerators, evidenced by the <b>fine-tuned</b> model achieving a 1.72x improvement in accelerator efficiency (FPS/W) compared to the most recent work.

{{</citation>}}


## eess.SY (4)



### (131/145) N-1 Reduced Optimal Power Flow Using Augmented Hierarchical Graph Neural Network (Thuan Pham et al., 2024)

{{<citation>}}

Thuan Pham, Xingpeng Li. (2024)  
**N-1 Reduced Optimal Power Flow Using Augmented Hierarchical Graph Neural Network**
<br/>
<button class="copy-to-clipboard" title="N-1 Reduced Optimal Power Flow Using Augmented Hierarchical Graph Neural Network" index=131>
  <span class="copy-to-clipboard-item">Copy Title<span>
</button>
<div class="toast toast-copied toast-index-131 align-items-center text-bg-secondary border-0 position-absolute top-0 end-0" role="alert" aria-live="assertive" aria-atomic="true">
  <div class="d-flex">
    <div class="toast-body">
      Copied!
    </div>
  </div>
</div>

---
Primary Category: eess.SY  
Categories: cs-LG, cs-SY, eess-SY, eess.SY  
Keyword Score: 20  
Keywords: Graph Neural Network, Graph Neural Network  
<a type="button" class="btn btn-outline-primary" href="http://arxiv.org/abs/2402.06226v1" target="_blank" >Paper Link</a>
<button type="button" class="btn btn-outline-primary download-pdf" url="https://arxiv.org/pdf/2402.06226v1.pdf" filename="2402.06226v1.pdf">Download PDF</button>

---


**ABSTRACT**  
Optimal power flow (OPF) is used to perform generation redispatch in power system real-time operations. N-1 OPF can ensure safe grid operations under diverse contingency scenarios. For large and intricate power networks with numerous variables and constraints, achieving an optimal solution for real-time N-1 OPF necessitates substantial computational resources. To mitigate this challenge, machine learning (ML) is introduced as an additional tool for predicting congested or heavily loaded lines dynamically. In this paper, an advanced ML model known as the augmented hierarchical <b>graph</b> <b>neural</b> <b>network</b> (AHGNN) was proposed to predict critical congested lines and create N-1 reduced OPF (N-1 ROPF). The proposed AHGNN-enabled N-1 ROPF can result in a remarkable reduction in computing time while retaining the solution quality. Several variations of <b>GNN-based</b> ML models are also implemented as benchmark to demonstrate effectiveness of the proposed AHGNN approach. Case studies prove the proposed AHGNN and the associated N-1 ROPF are highly effective in reducing computation time while preserving solution quality, highlighting the promising potential of ML, particularly <b>GNN</b> in enhancing power system operations.

{{</citation>}}


### (132/145) EJS, JIL Server, and LabVIEW: An Architecture for Rapid Development of Remote Labs (JesÃºs ChacÃ³n et al., 2024)

{{<citation>}}

JesÃºs ChacÃ³n, Hector Vargas, Gonzalo Farias, Jose SÃ¡nchez, SebastiÃ¡n Dormido. (2024)  
**EJS, JIL Server, and LabVIEW: An Architecture for Rapid Development of Remote Labs**
<br/>
<button class="copy-to-clipboard" title="EJS, JIL Server, and LabVIEW: An Architecture for Rapid Development of Remote Labs" index=132>
  <span class="copy-to-clipboard-item">Copy Title<span>
</button>
<div class="toast toast-copied toast-index-132 align-items-center text-bg-secondary border-0 position-absolute top-0 end-0" role="alert" aria-live="assertive" aria-atomic="true">
  <div class="d-flex">
    <div class="toast-body">
      Copied!
    </div>
  </div>
</div>

---
Primary Category: eess.SY  
Categories: cs-SY, eess-SY, eess.SY  
Keyword Score: 20  
Keywords: Simulation, Simulator  
<a type="button" class="btn btn-outline-primary" href="http://arxiv.org/abs/2402.06206v1" target="_blank" >Paper Link</a>
<button type="button" class="btn btn-outline-primary download-pdf" url="https://arxiv.org/pdf/2402.06206v1.pdf" filename="2402.06206v1.pdf">Download PDF</button>

---


**ABSTRACT**  
Designing and developing web-enabled remote laboratories for pedagogical purposes is not an easy task. Often, developers (generally, educators who know the subjects they teach but lack of the technical and programming skills required to build Internet-based educational applications) end up discarding the idea of exploring these new teaching and learning experiences mainly due to the technical issues that must be mastered. To tackle this problem, authors present a novel technique that allows developers to create remote labs in a quick, didactical, and straightforward way. This framework is based on the use of two well-known software tools in the scope of engineering education, Easy Java <b>Simulations</b> and LabVIEW. The development exploits a new feature of Easy Java <b>Simulations</b> known as EJS-elements that enables Java developers to create and integrate their own authoring libraries (elements) into EJS, thus increasing its application possibilities. Particularly, the EJS element here presented allows to LabVIEW programs be controlled from EJS applications through a communication network. This paper presents the element creation details and how this can be used to create web-enabled experimentation environments for educational purposes. A step by step example of development of a remote lab for automatic control education is described.

{{</citation>}}


### (133/145) Distributed Safe Navigation of Multi-Agent Systems using Control Barrier Function-Based Optimal Controllers (Pol Mestres et al., 2024)

{{<citation>}}

Pol Mestres, Carlos Nieto-Granda, Jorge CortÃ©s. (2024)  
**Distributed Safe Navigation of Multi-Agent Systems using Control Barrier Function-Based Optimal Controllers**
<br/>
<button class="copy-to-clipboard" title="Distributed Safe Navigation of Multi-Agent Systems using Control Barrier Function-Based Optimal Controllers" index=133>
  <span class="copy-to-clipboard-item">Copy Title<span>
</button>
<div class="toast toast-copied toast-index-133 align-items-center text-bg-secondary border-0 position-absolute top-0 end-0" role="alert" aria-live="assertive" aria-atomic="true">
  <div class="d-flex">
    <div class="toast-body">
      Copied!
    </div>
  </div>
</div>

---
Primary Category: eess.SY  
Categories: cs-SY, eess-SY, eess.SY  
Keyword Score: 20  
Keywords: Simulation, Simulator  
<a type="button" class="btn btn-outline-primary" href="http://arxiv.org/abs/2402.06195v1" target="_blank" >Paper Link</a>
<button type="button" class="btn btn-outline-primary download-pdf" url="https://arxiv.org/pdf/2402.06195v1.pdf" filename="2402.06195v1.pdf">Download PDF</button>

---


**ABSTRACT**  
This paper proposes a distributed controller synthesis framework for safe navigation of multi-agent systems. We leverage control barrier functions to formulate collision avoidance with obstacles and teammates as constraints on the control input for a state-dependent network optimization problem that encodes team formation and the navigation task. Our algorithmic solution is valid for general nonlinear control dynamics and optimization problems. The resulting controller is distributed, satisfies the safety constraints at all times, and is asymptotically optimal. We illustrate its performance in a team of differential-drive robots in a variety of complex environments, both in <b>simulation</b> and in hardware.

{{</citation>}}


### (134/145) Cooperative Nonlinear Guidance Strategies for Guaranteed Pursuit-Evasion (Saurabh Kumar et al., 2024)

{{<citation>}}

Saurabh Kumar, Shashi Ranjan Kumar, Abhinav Sinha. (2024)  
**Cooperative Nonlinear Guidance Strategies for Guaranteed Pursuit-Evasion**
<br/>
<button class="copy-to-clipboard" title="Cooperative Nonlinear Guidance Strategies for Guaranteed Pursuit-Evasion" index=134>
  <span class="copy-to-clipboard-item">Copy Title<span>
</button>
<div class="toast toast-copied toast-index-134 align-items-center text-bg-secondary border-0 position-absolute top-0 end-0" role="alert" aria-live="assertive" aria-atomic="true">
  <div class="d-flex">
    <div class="toast-body">
      Copied!
    </div>
  </div>
</div>

---
Primary Category: eess.SY  
Categories: cs-MA, cs-RO, cs-SY, eess-SY, eess.SY, math-DS, math-OC  
Keyword Score: 20  
Keywords: Simulation, Simulator  
<a type="button" class="btn btn-outline-primary" href="http://arxiv.org/abs/2402.06176v1" target="_blank" >Paper Link</a>
<button type="button" class="btn btn-outline-primary download-pdf" url="https://arxiv.org/pdf/2402.06176v1.pdf" filename="2402.06176v1.pdf">Download PDF</button>

---


**ABSTRACT**  
This paper addresses the pursuit-evasion problem involving three agents -- a purser, an evader, and a defender. We develop cooperative guidance laws for the evader-defender team that guarantee that the defender intercepts the pursuer before it reaches the vicinity of the evader. Unlike heuristic methods, optimal control, differential game formulation, and recently proposed time-constrained guidance techniques, we propose a geometric solution to safeguard the evader from the pursuer's incoming threat. The proposed strategy is computationally efficient and expected to be scalable as the number of agents increases. Another alluring feature of the proposed strategy is that the evader-defender team does not require the knowledge of the pursuer's strategy and that the pursuer's interception is guaranteed from arbitrary initial engagement geometries. We further show that the necessary error variables for the evader-defender team vanish within a time that can be exactly prescribed prior to the three-body engagement. Finally, we demonstrate the efficacy of the proposed cooperative defense strategy via <b>simulation</b> in diverse engagement scenarios.

{{</citation>}}


## cs.IT (1)



### (135/145) Coverage and Rate Analysis for Distributed RISs-Assisted mmWave Communications (Yuan Xu et al., 2024)

{{<citation>}}

Yuan Xu, Chongwen Huang, Wei Li, Yongxu Zhu, Zhaohui Yang, Jiguang He, Jun Yang, Zhaoyang Zhang, Chau Yuen, Merouane Debbah. (2024)  
**Coverage and Rate Analysis for Distributed RISs-Assisted mmWave Communications**
<br/>
<button class="copy-to-clipboard" title="Coverage and Rate Analysis for Distributed RISs-Assisted mmWave Communications" index=135>
  <span class="copy-to-clipboard-item">Copy Title<span>
</button>
<div class="toast toast-copied toast-index-135 align-items-center text-bg-secondary border-0 position-absolute top-0 end-0" role="alert" aria-live="assertive" aria-atomic="true">
  <div class="d-flex">
    <div class="toast-body">
      Copied!
    </div>
  </div>
</div>

---
Primary Category: cs.IT  
Categories: cs-IT, cs.IT, eess-SP, math-IT  
Keyword Score: 20  
Keywords: Simulation, Simulator  
<a type="button" class="btn btn-outline-primary" href="http://arxiv.org/abs/2402.06154v1" target="_blank" >Paper Link</a>
<button type="button" class="btn btn-outline-primary download-pdf" url="https://arxiv.org/pdf/2402.06154v1.pdf" filename="2402.06154v1.pdf">Download PDF</button>

---


**ABSTRACT**  
The millimeter wave (mmWave) has received considerable interest due to its expansive bandwidth and high frequency. However, a noteworthy challenge arises from its vulnerability to blockages, leading to reduced coverage and achievable rates. To address these limitations, a potential solution is to deploy distributed reconfigurable intelligent surfaces (RISs), which comprise many low-cost and passively reflected elements, and can facilitate the establishment of extra communication links. In this paper, we leverage stochastic geometry to investigate the ergodic coverage probability and the achievable rate in both distributed RISs-assisted single-cell and multi-cell mmWave wireless communication systems. Specifically, we first establish the system model considering the stochastically distributed blockages, RISs and users by the Poisson point process. Then we give the association criterion and derive the association probabilities, the distance distributions, and the conditional coverage probabilities for two cases of associations between base stations and users without or with RISs. Finally, we use Campbell's theorem and the total probability theorem to obtain the closed-form expressions of the ergodic coverage probability and the achievable rate. <b>Simulation</b> results verify the effectiveness of our analysis method, and demonstrate that by deploying distributed RISs, the ergodic coverage probability is significantly improved by approximately 50%, and the achievable rate is increased by more than 1.5 times.

{{</citation>}}


## cs.MA (1)



### (136/145) CityFlowER: An Efficient and Realistic Traffic Simulator with Embedded Machine Learning Models (Longchao Da et al., 2024)

{{<citation>}}

Longchao Da, Chen Chu, Weinan Zhang, Hua Wei. (2024)  
**CityFlowER: An Efficient and Realistic Traffic Simulator with Embedded Machine Learning Models**
<br/>
<button class="copy-to-clipboard" title="CityFlowER: An Efficient and Realistic Traffic Simulator with Embedded Machine Learning Models" index=136>
  <span class="copy-to-clipboard-item">Copy Title<span>
</button>
<div class="toast toast-copied toast-index-136 align-items-center text-bg-secondary border-0 position-absolute top-0 end-0" role="alert" aria-live="assertive" aria-atomic="true">
  <div class="d-flex">
    <div class="toast-body">
      Copied!
    </div>
  </div>
</div>

---
Primary Category: cs.MA  
Categories: G-3, cs-LG, cs-MA, cs.MA  
Keyword Score: 20  
Keywords: Simulation, Simulator  
<a type="button" class="btn btn-outline-primary" href="http://arxiv.org/abs/2402.06127v1" target="_blank" >Paper Link</a>
<button type="button" class="btn btn-outline-primary download-pdf" url="https://arxiv.org/pdf/2402.06127v1.pdf" filename="2402.06127v1.pdf">Download PDF</button>

---


**ABSTRACT**  
Traffic <b>simulation</b> is an essential tool for transportation infrastructure planning, intelligent traffic control policy learning, and traffic flow analysis. Its effectiveness relies heavily on the realism of the simulators used. Traditional traffic simulators, such as SUMO and CityFlow, are often limited by their reliance on rule-based models with hyperparameters that oversimplify driving behaviors, resulting in unrealistic <b>simulations.</b> To enhance realism, some simulators have provided Application Programming Interfaces (APIs) to interact with Machine Learning (ML) models, which learn from observed data and offer more sophisticated driving behavior models. However, this approach faces challenges in scalability and time efficiency as vehicle numbers increase. Addressing these limitations, we introduce CityFlowER, an advancement over the existing CityFlow simulator, designed for efficient and realistic city-wide traffic <b>simulation.</b> CityFlowER innovatively pre-embeds ML models within the simulator, eliminating the need for external API interactions and enabling faster data computation. This approach allows for a blend of rule-based and ML behavior models for individual vehicles, offering unparalleled flexibility and efficiency, particularly in large-scale <b>simulations.</b> We provide detailed comparisons with existing simulators, implementation insights, and comprehensive experiments to demonstrate CityFlowER's superiority in terms of realism, efficiency, and adaptability.

{{</citation>}}


## cs.CY (1)



### (137/145) You Still See Me: How Data Protection Supports the Architecture of ML Surveillance (Rui-Jie Yew et al., 2024)

{{<citation>}}

Rui-Jie Yew, Lucy Qin, Suresh Venkatasubramanian. (2024)  
**You Still See Me: How Data Protection Supports the Architecture of ML Surveillance**
<br/>
<button class="copy-to-clipboard" title="You Still See Me: How Data Protection Supports the Architecture of ML Surveillance" index=137>
  <span class="copy-to-clipboard-item">Copy Title<span>
</button>
<div class="toast toast-copied toast-index-137 align-items-center text-bg-secondary border-0 position-absolute top-0 end-0" role="alert" aria-live="assertive" aria-atomic="true">
  <div class="d-flex">
    <div class="toast-body">
      Copied!
    </div>
  </div>
</div>

---
Primary Category: cs.CY  
Categories: cs-CR, cs-CY, cs.CY  
Keyword Score: 10  
Keywords: Knowledge Distillation  
<a type="button" class="btn btn-outline-primary" href="http://arxiv.org/abs/2402.06609v1" target="_blank" >Paper Link</a>
<button type="button" class="btn btn-outline-primary download-pdf" url="https://arxiv.org/pdf/2402.06609v1.pdf" filename="2402.06609v1.pdf">Download PDF</button>

---


**ABSTRACT**  
Data forms the backbone of machine learning. Thus, data protection law has strong bearing on how ML systems are governed. Given that most requirements accompany the processing of personal data, organizations have an incentive to keep their data out of legal scope. Privacy-preserving techniques incentivized by data protection law -- data protection techniques -- constitute an important strategy for ML development because they are used to <b>distill</b> data until it potentially falls outside the scope of data protection laws. In this paper, we examine the impact of a rhetoric that deems data wrapped in privacy-preserving techniques as data that is "good-to-go". We show how the application of data protection techniques in the development of ML systems -- from private set intersection as part of dataset curation to homomorphic encryption and federated learning as part of model computation to the framing of the privacy-utility trade-off as part of model updating -- can further support individual monitoring and data consolidation. With data accumulation at the core of how the ML pipeline is configured, we argue that data protection techniques are often instrumentalized in ways that support infrastructures of surveillance, rather than to protect individuals associated with data. Finally, we propose technology and policy strategies to evaluate data protection techniques in light of the protections they actually confer. We conclude by highlighting the role that security technologists might play in devising policies that combat surveillance ML technologies -- recommending the adversarial mindset inherent to the profession to more precisely articulate and prevent the use of "privacy-preserving" scaffoldings that support surveillance.

{{</citation>}}


## cs.DS (2)



### (138/145) Value-based Resource Matching with Fairness Criteria: Application to Agricultural Water Trading (Abhijin Adiga et al., 2024)

{{<citation>}}

Abhijin Adiga, Yohai Trabelsi, Tanvir Ferdousi, Madhav Marathe, S. S. Ravi, Samarth Swarup, Anil Kumar Vullikanti, Mandy L. Wilson, Sarit Kraus, Reetwika Basu, Supriya Savalkar, Matthew Yourek, Michael Brady, Kirti Rajagopalan, Jonathan Yoder. (2024)  
**Value-based Resource Matching with Fairness Criteria: Application to Agricultural Water Trading**
<br/>
<button class="copy-to-clipboard" title="Value-based Resource Matching with Fairness Criteria: Application to Agricultural Water Trading" index=138>
  <span class="copy-to-clipboard-item">Copy Title<span>
</button>
<div class="toast toast-copied toast-index-138 align-items-center text-bg-secondary border-0 position-absolute top-0 end-0" role="alert" aria-live="assertive" aria-atomic="true">
  <div class="d-flex">
    <div class="toast-body">
      Copied!
    </div>
  </div>
</div>

---
Primary Category: cs.DS  
Categories: cs-DS, cs-MA, cs.DS  
Keyword Score: 10  
Keywords: Fairness  
<a type="button" class="btn btn-outline-primary" href="http://arxiv.org/abs/2402.06576v1" target="_blank" >Paper Link</a>
<button type="button" class="btn btn-outline-primary download-pdf" url="https://arxiv.org/pdf/2402.06576v1.pdf" filename="2402.06576v1.pdf">Download PDF</button>

---


**ABSTRACT**  
Optimal allocation of agricultural water in the event of droughts is an important global problem. In addressing this problem, many aspects, including the welfare of farmers, the economy, and the environment, must be considered. Under this backdrop, our work focuses on several resource-matching problems accounting for agents with multi-crop portfolios, geographic constraints, and <b>fairness.</b> First, we address a matching problem where the goal is to maximize a welfare function in two-sided markets where buyers' requirements and sellers' supplies are represented by value functions that assign prices (or costs) to specified volumes of water. For the setting where the value functions satisfy certain monotonicity properties, we present an efficient algorithm that maximizes a social welfare function. When there are minimum water requirement constraints, we present a randomized algorithm which ensures that the constraints are satisfied in expectation. For a single seller--multiple buyers setting with <b>fairness</b> constraints, we design an efficient algorithm that maximizes the minimum level of satisfaction of any buyer. We also present computational complexity results that highlight the limits on the generalizability of our results. We evaluate the algorithms developed in our work with experiments on both real-world and synthetic data sets with respect to drought severity, value functions, and seniority of agents.

{{</citation>}}


### (139/145) Assortment Planning with Sponsored Products (Shaojie Tang et al., 2024)

{{<citation>}}

Shaojie Tang, Shuzhang Cai, Jing Yuan, Kai Han. (2024)  
**Assortment Planning with Sponsored Products**
<br/>
<button class="copy-to-clipboard" title="Assortment Planning with Sponsored Products" index=139>
  <span class="copy-to-clipboard-item">Copy Title<span>
</button>
<div class="toast toast-copied toast-index-139 align-items-center text-bg-secondary border-0 position-absolute top-0 end-0" role="alert" aria-live="assertive" aria-atomic="true">
  <div class="d-flex">
    <div class="toast-body">
      Copied!
    </div>
  </div>
</div>

---
Primary Category: cs.DS  
Categories: cs-AI, cs-DS, cs-IR, cs.DS  
Keyword Score: 10  
Keywords: Recommendation  
<a type="button" class="btn btn-outline-primary" href="http://arxiv.org/abs/2402.06158v1" target="_blank" >Paper Link</a>
<button type="button" class="btn btn-outline-primary download-pdf" url="https://arxiv.org/pdf/2402.06158v1.pdf" filename="2402.06158v1.pdf">Download PDF</button>

---


**ABSTRACT**  
In the rapidly evolving landscape of retail, assortment planning plays a crucial role in determining the success of a business. With the rise of sponsored products and their increasing prominence in online marketplaces, retailers face new challenges in effectively managing their product assortment in the presence of sponsored products. Remarkably, previous research in assortment planning largely overlooks the existence of sponsored products and their potential impact on overall <b>recommendation</b> effectiveness. Instead, they commonly make the simplifying assumption that all products are either organic or non-sponsored. This research gap underscores the necessity for a more thorough investigation of the assortment planning challenge when sponsored products are in play. We formulate the assortment planning problem in the presence of sponsored products as a combinatorial optimization task. The ultimate objective is to compute an assortment plan that optimizes expected revenue while considering the specific requirements of placing sponsored products strategically.

{{</citation>}}


## math.OC (1)



### (140/145) Bandit Convex Optimisation (Tor Lattimore, 2024)

{{<citation>}}

Tor Lattimore. (2024)  
**Bandit Convex Optimisation**
<br/>
<button class="copy-to-clipboard" title="Bandit Convex Optimisation" index=140>
  <span class="copy-to-clipboard-item">Copy Title<span>
</button>
<div class="toast toast-copied toast-index-140 align-items-center text-bg-secondary border-0 position-absolute top-0 end-0" role="alert" aria-live="assertive" aria-atomic="true">
  <div class="d-flex">
    <div class="toast-body">
      Copied!
    </div>
  </div>
</div>

---
Primary Category: math.OC  
Categories: cs-LG, math-OC, math.OC, stat-ML  
Keyword Score: 10  
Keywords: Bandit Algorithm  
<a type="button" class="btn btn-outline-primary" href="http://arxiv.org/abs/2402.06535v1" target="_blank" >Paper Link</a>
<button type="button" class="btn btn-outline-primary download-pdf" url="https://arxiv.org/pdf/2402.06535v1.pdf" filename="2402.06535v1.pdf">Download PDF</button>

---


**ABSTRACT**  
<b>Bandit</b> convex optimisation is a fundamental framework for studying zeroth-order convex optimisation. These notes cover the many tools used for this problem, including cutting plane methods, interior point methods, continuous exponential weights, gradient descent and online Newton step. The nuances between the many assumptions and setups are explained. Although there is not much truly new here, some existing tools are applied in novel ways to obtain new algorithms. A few bounds are improved in minor ways.

{{</citation>}}


## cs.SI (1)



### (141/145) A new edge betweenness measure using a game theoretical approach: an application to hierarchical community detection (Daniel GÃ³mez et al., 2024)

{{<citation>}}

Daniel GÃ³mez, Javier Castro, Inmaculada GutiÃ©rrez, Rosa EspÃ­nola. (2024)  
**A new edge betweenness measure using a game theoretical approach: an application to hierarchical community detection**
<br/>
<button class="copy-to-clipboard" title="A new edge betweenness measure using a game theoretical approach: an application to hierarchical community detection" index=141>
  <span class="copy-to-clipboard-item">Copy Title<span>
</button>
<div class="toast toast-copied toast-index-141 align-items-center text-bg-secondary border-0 position-absolute top-0 end-0" role="alert" aria-live="assertive" aria-atomic="true">
  <div class="d-flex">
    <div class="toast-body">
      Copied!
    </div>
  </div>
</div>

---
Primary Category: cs.SI  
Categories: 91A, 91B82, 62, 65K, G-3, cs-SI, cs.SI, math-ST, stat-TH  
Keyword Score: 10  
Keywords: Hierarchical Clustering  
<a type="button" class="btn btn-outline-primary" href="http://arxiv.org/abs/2402.06373v1" target="_blank" >Paper Link</a>
<button type="button" class="btn btn-outline-primary download-pdf" url="https://arxiv.org/pdf/2402.06373v1.pdf" filename="2402.06373v1.pdf">Download PDF</button>

---


**ABSTRACT**  
In this paper we formally define the <b>hierarchical</b> <b>clustering</b> network problem (HCNP) as the problem to find a good <b>hierarchical</b> <b>partition</b> of a network. This new problem focuses on the dynamic process of the clustering rather than on the final picture of the clustering process. To address it, we introduce a new ierarchical clustering algorithm in networks, based on a new shortest path betweenness measure. To calculate it, the communication between each pair of nodes is weighed by he importance of the nodes that establish this communication. The weights or importance associated to each pair of nodes are calculated as the Shapley value of a game, named as the linear modularity game. This new measure, (the node-game shortest path betweenness measure), is used to obtain a <b>hierarchical</b> <b>partition</b> of the network by eliminating the link with the highest value. To evaluate the performance of our algorithm, we introduce several criteria that allow us to compare different dendrograms of a network from two point of view: modularity and homogeneity. Finally, we propose a faster algorithm based on a simplification of the node-game shortest path betweenness measure, whose order is quadratic on sparse networks. This fast version is competitive from a computational point of view with other <b>hierarchical</b> <b>fast</b> algorithms, and, in general, it provides better results.

{{</citation>}}


## physics.geo-ph (1)



### (142/145) Controllable seismic velocity synthesis using generative diffusion models (Fu Wang et al., 2024)

{{<citation>}}

Fu Wang, Xinquan Huang, Tariq Alkhalifah. (2024)  
**Controllable seismic velocity synthesis using generative diffusion models**
<br/>
<button class="copy-to-clipboard" title="Controllable seismic velocity synthesis using generative diffusion models" index=142>
  <span class="copy-to-clipboard-item">Copy Title<span>
</button>
<div class="toast toast-copied toast-index-142 align-items-center text-bg-secondary border-0 position-absolute top-0 end-0" role="alert" aria-live="assertive" aria-atomic="true">
  <div class="d-flex">
    <div class="toast-body">
      Copied!
    </div>
  </div>
</div>

---
Primary Category: physics.geo-ph  
Categories: cs-LG, physics-geo-ph, physics.geo-ph  
Keyword Score: 10  
Keywords: Out-of-distribution  
<a type="button" class="btn btn-outline-primary" href="http://arxiv.org/abs/2402.06277v1" target="_blank" >Paper Link</a>
<button type="button" class="btn btn-outline-primary download-pdf" url="https://arxiv.org/pdf/2402.06277v1.pdf" filename="2402.06277v1.pdf">Download PDF</button>

---


**ABSTRACT**  
Accurate seismic velocity estimations are vital to understanding Earth's subsurface structures, assessing natural resources, and evaluating seismic hazards. Machine learning-based inversion algorithms have shown promising performance in regional (i.e., for exploration) and global velocity estimation, while their effectiveness hinges on access to large and diverse training datasets whose distributions generally cover the target solutions. Additionally, enhancing the precision and reliability of velocity estimation also requires incorporating prior information, e.g., geological classes, well logs, and subsurface structures, but current statistical or neural network-based methods are not flexible enough to handle such multi-modal information. To address both challenges, we propose to use conditional generative diffusion models for seismic velocity synthesis, in which we readily incorporate those priors. This approach enables the generation of seismic velocities that closely match the expected target distribution, offering datasets informed by both expert knowledge and measured data to support training for data-driven geophysical methods. We demonstrate the flexibility and effectiveness of our method through training diffusion models on the OpenFWI dataset under various conditions, including class labels, well logs, reflectivity images, as well as the combination of these priors. The performance of the approach under <b>out-of-distribution</b> conditions further underscores its generalization ability, showcasing its potential to provide tailored priors for velocity inverse problems and create specific training datasets for machine learning-based geophysical applications.

{{</citation>}}


## cs.AR (2)



### (143/145) PULSE: Parametric Hardware Units for Low-power Sparsity-Aware Convolution Engine (Ilkin Aliyev et al., 2024)

{{<citation>}}

Ilkin Aliyev, Tosiron Adegbija. (2024)  
**PULSE: Parametric Hardware Units for Low-power Sparsity-Aware Convolution Engine**
<br/>
<button class="copy-to-clipboard" title="PULSE: Parametric Hardware Units for Low-power Sparsity-Aware Convolution Engine" index=143>
  <span class="copy-to-clipboard-item">Copy Title<span>
</button>
<div class="toast toast-copied toast-index-143 align-items-center text-bg-secondary border-0 position-absolute top-0 end-0" role="alert" aria-live="assertive" aria-atomic="true">
  <div class="d-flex">
    <div class="toast-body">
      Copied!
    </div>
  </div>
</div>

---
Primary Category: cs.AR  
Categories: cs-AR, cs.AR  
Keyword Score: 10  
Keywords: Convolution  
<a type="button" class="btn btn-outline-primary" href="http://arxiv.org/abs/2402.06210v1" target="_blank" >Paper Link</a>
<button type="button" class="btn btn-outline-primary download-pdf" url="https://arxiv.org/pdf/2402.06210v1.pdf" filename="2402.06210v1.pdf">Download PDF</button>

---


**ABSTRACT**  
Spiking Neural Networks (SNNs) have become popular for their more bio-realistic behavior than Artificial Neural Networks (ANNs). However, effectively leveraging the intrinsic, unstructured sparsity of SNNs in hardware is challenging, especially due to the variability in sparsity across network layers. This variability depends on several factors, including the input dataset, encoding scheme, and neuron model. Most existing SNN accelerators fail to account for the layer-specific workloads of an application (model + dataset), leading to high energy consumption. To address this, we propose a design-time parametric hardware generator that takes layer-wise sparsity and the number of processing elements as inputs and synthesizes the corresponding hardware. The proposed design compresses sparse spike trains using a priority encoder and efficiently shifts the activations across the network's layers. We demonstrate the robustness of our proposed approach by first profiling a given application's characteristics followed by performing efficient resource allocation. Results on a Xilinx Kintex FPGA (Field Programmable Gate Arrays) using MNIST, FashionMNIST, and SVHN datasets show a 3.14x improvement in accelerator efficiency (FPS/W) compared to a sparsity-oblivious systolic array-based accelerator. Compared to the most recent sparsity-aware work, our solution improves efficiency by 1.72x.

{{</citation>}}


### (144/145) Algorithm-hardware co-design for Energy-Efficient A/D conversion in ReRAM-based accelerators (Chenguang Zhang et al., 2024)

{{<citation>}}

Chenguang Zhang, Zhihang Yuan, Xingchen Li, Guangyu Sun. (2024)  
**Algorithm-hardware co-design for Energy-Efficient A/D conversion in ReRAM-based accelerators**
<br/>
<button class="copy-to-clipboard" title="Algorithm-hardware co-design for Energy-Efficient A/D conversion in ReRAM-based accelerators" index=144>
  <span class="copy-to-clipboard-item">Copy Title<span>
</button>
<div class="toast toast-copied toast-index-144 align-items-center text-bg-secondary border-0 position-absolute top-0 end-0" role="alert" aria-live="assertive" aria-atomic="true">
  <div class="d-flex">
    <div class="toast-body">
      Copied!
    </div>
  </div>
</div>

---
Primary Category: cs.AR  
Categories: cs-AR, cs.AR  
Keyword Score: 10  
Keywords: Quantization  
<a type="button" class="btn btn-outline-primary" href="http://arxiv.org/abs/2402.06164v1" target="_blank" >Paper Link</a>
<button type="button" class="btn btn-outline-primary download-pdf" url="https://arxiv.org/pdf/2402.06164v1.pdf" filename="2402.06164v1.pdf">Download PDF</button>

---


**ABSTRACT**  
Deep neural networks are widely deployed in many fields. Due to the in-situ computation (known as processing in memory) capacity of the Resistive Random Access Memory (ReRAM) crossbar, ReRAM-based accelerator shows potential in accelerating DNN with low power and high performance. However, despite power advantage, such kind of accelerators suffer from the high power consumption of peripheral circuits, especially Analog-to-Digital Converter (ADC), which account for over 60 percent of total power consumption. This problem hinders the ReRAM-based accelerator to achieve higher efficiency. Some redundant Analog-to-Digital conversion operations have no contribution to maintaining inference accuracy, and such operations can be eliminated by modifying the ADC searching logic. Based on such observations, we propose an algorithm-hardware co-design method and explore the co-design approach in both hardware design and <b>quantization</b> algorithms. Firstly, we focus on the distribution output along the crossbar's bit-lines and identify the fine-grained redundant ADC sampling bits. % of weight and To further compress ADC bits, we propose a hardware-friendly <b>quantization</b> method and coding scheme, in which different <b>quantization</b> strategy was applied to the partial results in different intervals. To support the two features above, we propose a lightweight architectural design based on SAR-ADC\@. It's worth mentioning that our method is not only more energy efficient but also retains the flexibility of the algorithm. Experiments demonstrate that our method can reduce about $1.6 \sim 2.3 \times$ ADC power reduction.

{{</citation>}}


## stat.ME (1)



### (145/145) Peeking with PEAK: Sequential, Nonparametric Composite Hypothesis Tests for Means of Multiple Data Streams (Brian Cho et al., 2024)

{{<citation>}}

Brian Cho, Kyra Gan, Nathan Kallus. (2024)  
**Peeking with PEAK: Sequential, Nonparametric Composite Hypothesis Tests for Means of Multiple Data Streams**
<br/>
<button class="copy-to-clipboard" title="Peeking with PEAK: Sequential, Nonparametric Composite Hypothesis Tests for Means of Multiple Data Streams" index=145>
  <span class="copy-to-clipboard-item">Copy Title<span>
</button>
<div class="toast toast-copied toast-index-145 align-items-center text-bg-secondary border-0 position-absolute top-0 end-0" role="alert" aria-live="assertive" aria-atomic="true">
  <div class="d-flex">
    <div class="toast-body">
      Copied!
    </div>
  </div>
</div>

---
Primary Category: stat.ME  
Categories: cs-LG, stat-ME, stat-ML, stat.ME  
Keyword Score: 10  
Keywords: Bandit Algorithm  
<a type="button" class="btn btn-outline-primary" href="http://arxiv.org/abs/2402.06122v1" target="_blank" >Paper Link</a>
<button type="button" class="btn btn-outline-primary download-pdf" url="https://arxiv.org/pdf/2402.06122v1.pdf" filename="2402.06122v1.pdf">Download PDF</button>

---


**ABSTRACT**  
We propose a novel nonparametric sequential test for composite hypotheses for means of multiple data streams. Our proposed method, \emph{peeking with expectation-based averaged capital} (PEAK), builds upon the testing-as-betting framework and provides a non-asymptotic $\alpha$-level test across any stopping time. PEAK is computationally tractable and efficiently rejects hypotheses that are incorrect across all potential distributions that satisfy our nonparametric assumption, enabling joint composite hypothesis testing on multiple streams of data. We numerically validate our theoretical findings under the best arm identification and threshold identification in the <b>bandit</b> setting, illustrating the computational efficiency of our method against state-of-the-art testing methods.

{{</citation>}}
