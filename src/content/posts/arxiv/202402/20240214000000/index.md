---
draft: false
title: "arXiv @ 2024.02.14"
date: 2024-02-14
author: "akitenkrad"
description: ""
tags: ["arXiv", "Published:2024"]
menu:
  sidebar:
    name: "arXiv @ 2024.02.14"
    identifier: arxiv_20240214
    parent: 202402_arxiv
    weight: 10
math: true
---

<figure style="border:none; width:100%; display:flex; justify-content: center">
    <iframe src="pie.html" width=900 height=620 style="border:none"></iframe>
</figure>


## Primary Categories

- [astro-ph.IM (1)](#astro-phim-1)
- [cs.AI (21)](#csai-21)
- [cs.AR (2)](#csar-2)
- [cs.CL (38)](#cscl-38)
- [cs.CR (7)](#cscr-7)
- [cs.CV (26)](#cscv-26)
- [cs.CY (4)](#cscy-4)
- [cs.DC (3)](#csdc-3)
- [cs.GT (1)](#csgt-1)
- [cs.HC (5)](#cshc-5)
- [cs.IR (7)](#csir-7)
- [cs.IT (1)](#csit-1)
- [cs.LG (55)](#cslg-55)
- [cs.MM (2)](#csmm-2)
- [cs.RO (7)](#csro-7)
- [cs.SD (2)](#cssd-2)
- [cs.SE (4)](#csse-4)
- [cs.SI (1)](#cssi-1)
- [eess.AS (3)](#eessas-3)
- [eess.IV (4)](#eessiv-4)
- [eess.SY (4)](#eesssy-4)
- [hep-ph (1)](#hep-ph-1)
- [math.OC (1)](#mathoc-1)
- [math.ST (1)](#mathst-1)
- [physics.ao-ph (1)](#physicsao-ph-1)
- [physics.comp-ph (1)](#physicscomp-ph-1)
- [q-bio.GN (1)](#q-biogn-1)
- [q-bio.QM (1)](#q-bioqm-1)
- [stat.ML (5)](#statml-5)

## Keywords

<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th>keyword</th>
      <th>cs.AI</th>
      <th>cs.CL</th>
      <th>cs.CV</th>
      <th>cs.LG</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td>Active Learning</td>
      <td></td>
      <td></td>
      <td></td>
      <td>1</td>
    </tr>
    <tr>
      <td>Adversarial Attack</td>
      <td></td>
      <td></td>
      <td>1</td>
      <td>3</td>
    </tr>
    <tr>
      <td>Adversarial Learning</td>
      <td></td>
      <td></td>
      <td></td>
      <td>1</td>
    </tr>
    <tr>
      <td>Aspect-based Sentiment Analysis</td>
      <td>1</td>
      <td></td>
      <td></td>
      <td></td>
    </tr>
    <tr>
      <td>Autoencoder</td>
      <td></td>
      <td></td>
      <td>2</td>
      <td>1</td>
    </tr>
    <tr>
      <td>Automatic Evaluation</td>
      <td></td>
      <td>1</td>
      <td></td>
      <td></td>
    </tr>
    <tr>
      <td>Automatic Speech Recognition</td>
      <td></td>
      <td>7</td>
      <td></td>
      <td></td>
    </tr>
    <tr>
      <td>BERT</td>
      <td></td>
      <td>1</td>
      <td></td>
      <td></td>
    </tr>
    <tr>
      <td>Bandit Algorithm</td>
      <td></td>
      <td></td>
      <td></td>
      <td>4</td>
    </tr>
    <tr>
      <td>ChatGPT</td>
      <td>1</td>
      <td>1</td>
      <td></td>
      <td>1</td>
    </tr>
    <tr>
      <td>Code Generation</td>
      <td>1</td>
      <td></td>
      <td></td>
      <td>1</td>
    </tr>
    <tr>
      <td>Common-sense Reasoning</td>
      <td></td>
      <td></td>
      <td></td>
      <td>1</td>
    </tr>
    <tr>
      <td>Continual Learning</td>
      <td></td>
      <td></td>
      <td>1</td>
      <td></td>
    </tr>
    <tr>
      <td>Contrastive Learning</td>
      <td>1</td>
      <td>2</td>
      <td></td>
      <td>1</td>
    </tr>
    <tr>
      <td>Convolution</td>
      <td>1</td>
      <td></td>
      <td>3</td>
      <td>7</td>
    </tr>
    <tr>
      <td>Convolutional Neural Network</td>
      <td>1</td>
      <td></td>
      <td>5</td>
      <td>7</td>
    </tr>
    <tr>
      <td>Counter-factual</td>
      <td></td>
      <td>1</td>
      <td></td>
      <td></td>
    </tr>
    <tr>
      <td>Curriculum Learning</td>
      <td></td>
      <td></td>
      <td></td>
      <td>1</td>
    </tr>
    <tr>
      <td>Data Augmentation</td>
      <td></td>
      <td>1</td>
      <td></td>
      <td>1</td>
    </tr>
    <tr>
      <td>Dependency Parsing</td>
      <td></td>
      <td>1</td>
      <td></td>
      <td></td>
    </tr>
    <tr>
      <td>Domain Adaptation</td>
      <td></td>
      <td></td>
      <td>1</td>
      <td></td>
    </tr>
    <tr>
      <td>Edge Prediction</td>
      <td></td>
      <td></td>
      <td></td>
      <td>1</td>
    </tr>
    <tr>
      <td>Fact Verification</td>
      <td></td>
      <td>1</td>
      <td></td>
      <td></td>
    </tr>
    <tr>
      <td>Fairness</td>
      <td>1</td>
      <td></td>
      <td></td>
      <td>1</td>
    </tr>
    <tr>
      <td>Fake News Detection</td>
      <td></td>
      <td>2</td>
      <td>1</td>
      <td></td>
    </tr>
    <tr>
      <td>Few-shot</td>
      <td></td>
      <td>1</td>
      <td>1</td>
      <td></td>
    </tr>
    <tr>
      <td>Fine-tuning</td>
      <td>2</td>
      <td>14</td>
      <td>4</td>
      <td>13</td>
    </tr>
    <tr>
      <td>Foundation Model</td>
      <td>1</td>
      <td></td>
      <td></td>
      <td>2</td>
    </tr>
    <tr>
      <td>GPT</td>
      <td>5</td>
      <td>6</td>
      <td></td>
      <td></td>
    </tr>
    <tr>
      <td>GPT-3</td>
      <td>2</td>
      <td>4</td>
      <td></td>
      <td></td>
    </tr>
    <tr>
      <td>GPT-3.5</td>
      <td>2</td>
      <td>4</td>
      <td></td>
      <td></td>
    </tr>
    <tr>
      <td>GPT-4</td>
      <td>3</td>
      <td>5</td>
      <td></td>
      <td></td>
    </tr>
    <tr>
      <td>Generative AI</td>
      <td>1</td>
      <td></td>
      <td></td>
      <td></td>
    </tr>
    <tr>
      <td>Graph Classification</td>
      <td></td>
      <td></td>
      <td></td>
      <td>2</td>
    </tr>
    <tr>
      <td>Graph Convolutional Network</td>
      <td></td>
      <td></td>
      <td></td>
      <td>1</td>
    </tr>
    <tr>
      <td>Graph Neural Network</td>
      <td>2</td>
      <td></td>
      <td></td>
      <td>8</td>
    </tr>
    <tr>
      <td>Grounding</td>
      <td></td>
      <td></td>
      <td></td>
      <td>2</td>
    </tr>
    <tr>
      <td>In-context Learning</td>
      <td>2</td>
      <td>5</td>
      <td></td>
      <td>8</td>
    </tr>
    <tr>
      <td>Instruction Following</td>
      <td></td>
      <td>1</td>
      <td></td>
      <td>1</td>
    </tr>
    <tr>
      <td>Instruction Tuning</td>
      <td></td>
      <td>1</td>
      <td></td>
      <td></td>
    </tr>
    <tr>
      <td>Knowledge Transfer</td>
      <td></td>
      <td>1</td>
      <td></td>
      <td></td>
    </tr>
    <tr>
      <td>LLaMA</td>
      <td></td>
      <td>3</td>
      <td></td>
      <td></td>
    </tr>
    <tr>
      <td>Language Generation</td>
      <td></td>
      <td>1</td>
      <td></td>
      <td></td>
    </tr>
    <tr>
      <td>Large Language Model</td>
      <td>21</td>
      <td>39</td>
      <td>3</td>
      <td>20</td>
    </tr>
    <tr>
      <td>Low-Resource</td>
      <td></td>
      <td>2</td>
      <td></td>
      <td></td>
    </tr>
    <tr>
      <td>Masked Language Model</td>
      <td></td>
      <td></td>
      <td></td>
      <td>1</td>
    </tr>
    <tr>
      <td>Mathematical Reasoning</td>
      <td></td>
      <td>1</td>
      <td></td>
      <td></td>
    </tr>
    <tr>
      <td>Message-Passing</td>
      <td></td>
      <td></td>
      <td></td>
      <td>3</td>
    </tr>
    <tr>
      <td>Model Compression</td>
      <td></td>
      <td></td>
      <td></td>
      <td>1</td>
    </tr>
    <tr>
      <td>Multi-modal</td>
      <td>2</td>
      <td>2</td>
      <td>8</td>
      <td>2</td>
    </tr>
    <tr>
      <td>Multiple Instance Learning</td>
      <td></td>
      <td></td>
      <td>1</td>
      <td></td>
    </tr>
    <tr>
      <td>Mutual Information</td>
      <td></td>
      <td>1</td>
      <td></td>
      <td>1</td>
    </tr>
    <tr>
      <td>Natural Language Explanation</td>
      <td></td>
      <td>1</td>
      <td></td>
      <td></td>
    </tr>
    <tr>
      <td>Natural Language Generation</td>
      <td></td>
      <td>1</td>
      <td></td>
      <td>1</td>
    </tr>
    <tr>
      <td>Neural Machine Translation</td>
      <td></td>
      <td>9</td>
      <td></td>
      <td></td>
    </tr>
    <tr>
      <td>Node Classification</td>
      <td></td>
      <td></td>
      <td></td>
      <td>2</td>
    </tr>
    <tr>
      <td>Object Detection</td>
      <td></td>
      <td></td>
      <td>3</td>
      <td>1</td>
    </tr>
    <tr>
      <td>Offline Reinforcement Learning</td>
      <td></td>
      <td></td>
      <td></td>
      <td>1</td>
    </tr>
    <tr>
      <td>Optical Character Recognition</td>
      <td></td>
      <td></td>
      <td>2</td>
      <td>1</td>
    </tr>
    <tr>
      <td>Out-of-distribution</td>
      <td>1</td>
      <td></td>
      <td>2</td>
      <td>1</td>
    </tr>
    <tr>
      <td>PaLM</td>
      <td></td>
      <td>1</td>
      <td></td>
      <td></td>
    </tr>
    <tr>
      <td>Perplexity</td>
      <td></td>
      <td>1</td>
      <td></td>
      <td></td>
    </tr>
    <tr>
      <td>Pre-trained Language Model</td>
      <td>1</td>
      <td>5</td>
      <td></td>
      <td></td>
    </tr>
    <tr>
      <td>Prompt</td>
      <td>2</td>
      <td>7</td>
      <td></td>
      <td>3</td>
    </tr>
    <tr>
      <td>Pruning</td>
      <td>1</td>
      <td>1</td>
      <td>2</td>
      <td>2</td>
    </tr>
    <tr>
      <td>Question Answering</td>
      <td>1</td>
      <td>2</td>
      <td>3</td>
      <td>1</td>
    </tr>
    <tr>
      <td>Reasoning</td>
      <td>4</td>
      <td>4</td>
      <td></td>
      <td>2</td>
    </tr>
    <tr>
      <td>Recommendation</td>
      <td>2</td>
      <td>1</td>
      <td></td>
      <td>1</td>
    </tr>
    <tr>
      <td>Reconstruction Loss</td>
      <td></td>
      <td></td>
      <td></td>
      <td>1</td>
    </tr>
    <tr>
      <td>Recurrent Neural Network</td>
      <td></td>
      <td></td>
      <td></td>
      <td>1</td>
    </tr>
    <tr>
      <td>Reinforcement Learning</td>
      <td>1</td>
      <td>1</td>
      <td></td>
      <td>9</td>
    </tr>
    <tr>
      <td>Rerank</td>
      <td>1</td>
      <td></td>
      <td></td>
      <td></td>
    </tr>
    <tr>
      <td>Scaling Law</td>
      <td></td>
      <td></td>
      <td></td>
      <td>3</td>
    </tr>
    <tr>
      <td>Self-Attention</td>
      <td></td>
      <td>1</td>
      <td></td>
      <td>3</td>
    </tr>
    <tr>
      <td>Self-supervised Learning</td>
      <td></td>
      <td>1</td>
      <td>1</td>
      <td>2</td>
    </tr>
    <tr>
      <td>Semi-Supervised Learning</td>
      <td></td>
      <td></td>
      <td>1</td>
      <td></td>
    </tr>
    <tr>
      <td>Sentiment Analysis</td>
      <td>1</td>
      <td></td>
      <td></td>
      <td></td>
    </tr>
    <tr>
      <td>Simulation</td>
      <td>2</td>
      <td>1</td>
      <td>1</td>
      <td>2</td>
    </tr>
    <tr>
      <td>Simulator</td>
      <td>2</td>
      <td>1</td>
      <td>1</td>
      <td>2</td>
    </tr>
    <tr>
      <td>Stochastic Gradient Descent</td>
      <td></td>
      <td></td>
      <td></td>
      <td>3</td>
    </tr>
    <tr>
      <td>Style Transfer</td>
      <td></td>
      <td>1</td>
      <td></td>
      <td></td>
    </tr>
    <tr>
      <td>Summarization</td>
      <td></td>
      <td>1</td>
      <td></td>
      <td></td>
    </tr>
    <tr>
      <td>Supervised Learning</td>
      <td></td>
      <td>3</td>
      <td>3</td>
      <td>8</td>
    </tr>
    <tr>
      <td>Text Classification</td>
      <td></td>
      <td>1</td>
      <td></td>
      <td>1</td>
    </tr>
    <tr>
      <td>Text Generation</td>
      <td></td>
      <td>2</td>
      <td></td>
      <td></td>
    </tr>
    <tr>
      <td>Text Understanding</td>
      <td></td>
      <td></td>
      <td>1</td>
      <td></td>
    </tr>
    <tr>
      <td>Text-to-speech</td>
      <td></td>
      <td></td>
      <td></td>
      <td>2</td>
    </tr>
    <tr>
      <td>Tokenization</td>
      <td></td>
      <td></td>
      <td></td>
      <td>1</td>
    </tr>
    <tr>
      <td>Topic Model</td>
      <td></td>
      <td>1</td>
      <td></td>
      <td></td>
    </tr>
    <tr>
      <td>Topic Modeling</td>
      <td></td>
      <td>1</td>
      <td></td>
      <td></td>
    </tr>
    <tr>
      <td>Transfer Learning</td>
      <td></td>
      <td></td>
      <td>1</td>
      <td>1</td>
    </tr>
    <tr>
      <td>Transformer</td>
      <td>1</td>
      <td>2</td>
      <td>3</td>
      <td>11</td>
    </tr>
    <tr>
      <td>Unsupervised Learning</td>
      <td></td>
      <td>2</td>
      <td>3</td>
      <td>1</td>
    </tr>
    <tr>
      <td>Vision-and-Language</td>
      <td></td>
      <td></td>
      <td>1</td>
      <td></td>
    </tr>
    <tr>
      <td>Visual Question Answering</td>
      <td></td>
      <td></td>
      <td>1</td>
      <td></td>
    </tr>
    <tr>
      <td>Weakly-supervised Learning</td>
      <td></td>
      <td></td>
      <td>2</td>
      <td></td>
    </tr>
    <tr>
      <td>Word Embedding</td>
      <td></td>
      <td>1</td>
      <td></td>
      <td></td>
    </tr>
    <tr>
      <td>Zero-shot</td>
      <td>2</td>
      <td>4</td>
      <td>2</td>
      <td>2</td>
    </tr>
    <tr>
      <td>Zero-shot Learning</td>
      <td>2</td>
      <td></td>
      <td></td>
      <td></td>
    </tr>
    <tr>
      <td>falcon</td>
      <td>1</td>
      <td></td>
      <td></td>
      <td></td>
    </tr>
  </tbody>
</table>

<script>
$(function() {
  $("table").addClass("keyword-table table-bordered border-success");
  $("table thead").addClass("sticky-top");
  $("table tbody td").css("text-align", "");
});
</script>


## cs.CL (38)



### (1/210) Addressing cognitive bias in medical language models (Samuel Schmidgall et al., 2024)

{{<citation>}}

Samuel Schmidgall, Carl Harris, Ime Essien, Daniel Olshvang, Tawsifur Rahman, Ji Woong Kim, Rojin Ziaei, Jason Eshraghian, Peter Abadir, Rama Chellappa. (2024)  
**Addressing cognitive bias in medical language models**
<br/>
<button class="copy-to-clipboard" title="Addressing cognitive bias in medical language models" index=1>
  <span class="copy-to-clipboard-item">Copy Title<span>
</button>
<div class="toast toast-copied toast-index-1 align-items-center text-bg-secondary border-0 position-absolute top-0 end-0" role="alert" aria-live="assertive" aria-atomic="true">
  <div class="d-flex">
    <div class="toast-body">
      Copied!
    </div>
  </div>
</div>

---
Primary Category: cs.CL  
Categories: cs-CL, cs-HC, cs.CL  
Keyword Score: 100  
Keywords: Simulation, Simulator, GPT, GPT-3, GPT-3.5, GPT-4, LLaMA, PaLM, Large Language Model, Large Language Model  
<a type="button" class="btn btn-outline-primary" href="http://arxiv.org/abs/2402.08113v1" target="_blank" >Paper Link</a>
<button type="button" class="btn btn-outline-primary download-pdf" url="https://arxiv.org/pdf/2402.08113v1.pdf" filename="2402.08113v1.pdf">Download PDF</button>

---


**ABSTRACT**  
The integration of <b>large</b> <b>language</b> <b>models</b> <b>(LLMs)</b> into the medical field has gained significant attention due to their promising accuracy in simulated clinical decision-making settings. However, clinical decision-making is more complex than <b>simulations</b> because physicians' decisions are shaped by many factors, including the presence of cognitive bias. However, the degree to which <b>LLMs</b> are susceptible to the same cognitive biases that affect human clinicians remains unexplored. Our hypothesis posits that when <b>LLMs</b> are confronted with clinical questions containing cognitive biases, they will yield significantly less accurate responses compared to the same questions presented without such biases.In this study, we developed BiasMedQA, a novel benchmark for evaluating cognitive biases in <b>LLMs</b> applied to medical tasks. Using BiasMedQA we evaluated six <b>LLMs,</b> namely <b>GPT-4,</b> Mixtral-8x70B, <b>GPT-3.5,</b> <b>PaLM-2,</b> <b>Llama</b> 2 70B-chat, and the medically specialized PMC <b>Llama</b> 13B. We tested these models on 1,273 questions from the US Medical Licensing Exam (USMLE) Steps 1, 2, and 3, modified to replicate common clinically-relevant cognitive biases. Our analysis revealed varying effects for biases on these <b>LLMs,</b> with <b>GPT-4</b> standing out for its resilience to bias, in contrast to <b>Llama</b> 2 70B-chat and PMC <b>Llama</b> 13B, which were disproportionately affected by cognitive bias. Our findings highlight the critical need for bias mitigation in the development of medical <b>LLMs,</b> pointing towards safer and more reliable applications in healthcare.

{{</citation>}}


### (2/210) Large Language Models 'Ad Referendum': How Good Are They at Machine Translation in the Legal Domain? (Vicent Briva-Iglesias et al., 2024)

{{<citation>}}

Vicent Briva-Iglesias, Joao Lucas Cavalheiro Camargo, Gokhan Dogru. (2024)  
**Large Language Models 'Ad Referendum': How Good Are They at Machine Translation in the Legal Domain?**
<br/>
<button class="copy-to-clipboard" title="Large Language Models 'Ad Referendum': How Good Are They at Machine Translation in the Legal Domain?" index=2>
  <span class="copy-to-clipboard-item">Copy Title<span>
</button>
<div class="toast toast-copied toast-index-2 align-items-center text-bg-secondary border-0 position-absolute top-0 end-0" role="alert" aria-live="assertive" aria-atomic="true">
  <div class="d-flex">
    <div class="toast-body">
      Copied!
    </div>
  </div>
</div>

---
Primary Category: cs.CL  
Categories: cs-AI, cs-CL, cs.CL  
Keyword Score: 90  
Keywords: Automatic Evaluation, GPT, GPT-4, Neural Machine Translation, Neural Machine Translation, Neural Machine Translation, Neural Machine Translation, Large Language Model, Large Language Model  
<a type="button" class="btn btn-outline-primary" href="http://arxiv.org/abs/2402.07681v1" target="_blank" >Paper Link</a>
<button type="button" class="btn btn-outline-primary download-pdf" url="https://arxiv.org/pdf/2402.07681v1.pdf" filename="2402.07681v1.pdf">Download PDF</button>

---


**ABSTRACT**  
This study evaluates the <b>machine</b> <b>translation</b> <b>(MT)</b> quality of two state-of-the-art <b>large</b> <b>language</b> <b>models</b> <b>(LLMs)</b> against a tradition-al <b>neural</b> <b>machine</b> <b>translation</b> <b>(NMT)</b> system across four language pairs in the legal domain. It combines <b>automatic</b> <b>evaluation</b> met-rics (AEMs) and human evaluation (HE) by professional transla-tors to assess translation ranking, fluency and adequacy. The re-sults indicate that while Google Translate generally outperforms <b>LLMs</b> in AEMs, human evaluators rate <b>LLMs,</b> especially <b>GPT-4,</b> comparably or slightly better in terms of producing contextually adequate and fluent translations. This discrepancy suggests <b>LLMs'</b> potential in handling specialized legal terminology and context, highlighting the importance of human evaluation methods in assessing <b>MT</b> quality. The study underscores the evolving capabil-ities of <b>LLMs</b> in specialized domains and calls for reevaluation of traditional AEMs to better capture the nuances of <b>LLM-generated</b> translations.

{{</citation>}}


### (3/210) Investigating the Impact of Data Contamination of Large Language Models in Text-to-SQL Translation (Federico Ranaldi et al., 2024)

{{<citation>}}

Federico Ranaldi, Elena Sofia Ruzzetti, Dario Onorati, Leonardo Ranaldi, Cristina Giannone, Andrea Favalli, Raniero Romagnoli, Fabio Massimo Zanzotto. (2024)  
**Investigating the Impact of Data Contamination of Large Language Models in Text-to-SQL Translation**
<br/>
<button class="copy-to-clipboard" title="Investigating the Impact of Data Contamination of Large Language Models in Text-to-SQL Translation" index=3>
  <span class="copy-to-clipboard-item">Copy Title<span>
</button>
<div class="toast toast-copied toast-index-3 align-items-center text-bg-secondary border-0 position-absolute top-0 end-0" role="alert" aria-live="assertive" aria-atomic="true">
  <div class="d-flex">
    <div class="toast-body">
      Copied!
    </div>
  </div>
</div>

---
Primary Category: cs.CL  
Categories: cs-CL, cs-LG, cs.CL  
Keyword Score: 70  
Keywords: Zero-shot, GPT, GPT-3, GPT-3.5, Instruction Following, Large Language Model, Large Language Model  
<a type="button" class="btn btn-outline-primary" href="http://arxiv.org/abs/2402.08100v1" target="_blank" >Paper Link</a>
<button type="button" class="btn btn-outline-primary download-pdf" url="https://arxiv.org/pdf/2402.08100v1.pdf" filename="2402.08100v1.pdf">Download PDF</button>

---


**ABSTRACT**  
Understanding textual description to generate code seems to be an achieved capability of <b>instruction-following</b> <b>Large</b> <b>Language</b> <b>Models</b> <b>(LLMs)</b> in <b>zero-shot</b> scenario. However, there is a severe possibility that this translation ability may be influenced by having seen target textual descriptions and the related code. This effect is known as Data Contamination. In this study, we investigate the impact of Data Contamination on the performance of <b>GPT-3.5</b> in the Text-to-SQL code-generating tasks. Hence, we introduce a novel method to detect Data Contamination in <b>GPTs</b> and examine <b>GPT-3.5's</b> Text-to-SQL performances using the known Spider Dataset and our new unfamiliar dataset Termite. Furthermore, we analyze <b>GPT-3.5's</b> efficacy on databases with modified information via an adversarial table disconnection (ATD) approach, complicating Text-to-SQL tasks by removing structural pieces of information from the database. Our results indicate a significant performance drop in <b>GPT-3.5</b> on the unfamiliar Termite dataset, even with ATD modifications, highlighting the effect of Data Contamination on <b>LLMs</b> in Text-to-SQL translation tasks.

{{</citation>}}


### (4/210) Suppressing Pink Elephants with Direct Principle Feedback (Louis Castricato et al., 2024)

{{<citation>}}

Louis Castricato, Nathan Lile, Suraj Anand, Hailey Schoelkopf, Siddharth Verma, Stella Biderman. (2024)  
**Suppressing Pink Elephants with Direct Principle Feedback**
<br/>
<button class="copy-to-clipboard" title="Suppressing Pink Elephants with Direct Principle Feedback" index=4>
  <span class="copy-to-clipboard-item">Copy Title<span>
</button>
<div class="toast toast-copied toast-index-4 align-items-center text-bg-secondary border-0 position-absolute top-0 end-0" role="alert" aria-live="assertive" aria-atomic="true">
  <div class="d-flex">
    <div class="toast-body">
      Copied!
    </div>
  </div>
</div>

---
Primary Category: cs.CL  
Categories: cs-CL, cs.CL  
Keyword Score: 70  
Keywords: Fine-tuning, Fine-tuning, GPT, GPT-4, LLaMA, Large Language Model, Prompt  
<a type="button" class="btn btn-outline-primary" href="http://arxiv.org/abs/2402.07896v2" target="_blank" >Paper Link</a>
<button type="button" class="btn btn-outline-primary download-pdf" url="https://arxiv.org/pdf/2402.07896v2.pdf" filename="2402.07896v2.pdf">Download PDF</button>

---


**ABSTRACT**  
Existing methods for controlling language models, such as RLHF and Constitutional AI, involve determining which <b>LLM</b> behaviors are desirable and training them into a language model. However, in many cases, it is desirable for <b>LLMs</b> to be controllable at inference time, so that they can be used in multiple contexts with diverse needs. We illustrate this with the Pink Elephant Problem: instructing an <b>LLM</b> to avoid discussing a certain entity (a ``Pink Elephant''), and instead discuss a preferred entity (``Grey Elephant''). We apply a novel simplification of Constitutional AI, Direct Principle Feedback, which skips the ranking of responses and uses DPO directly on critiques and revisions. Our results show that after DPF <b>fine-tuning</b> on our synthetic Pink Elephants dataset, our 13B <b>fine-tuned</b> <b>LLaMA</b> 2 model significantly outperforms <b>Llama-2-13B-Chat</b> and a <b>prompted</b> baseline, and performs as well as <b>GPT-4</b> in on our curated test set assessing the Pink Elephant Problem.

{{</citation>}}


### (5/210) The Sound of Healthcare: Improving Medical Transcription ASR Accuracy with Large Language Models (Ayo Adedeji et al., 2024)

{{<citation>}}

Ayo Adedeji, Sarita Joshi, Brendan Doohan. (2024)  
**The Sound of Healthcare: Improving Medical Transcription ASR Accuracy with Large Language Models**
<br/>
<button class="copy-to-clipboard" title="The Sound of Healthcare: Improving Medical Transcription ASR Accuracy with Large Language Models" index=5>
  <span class="copy-to-clipboard-item">Copy Title<span>
</button>
<div class="toast toast-copied toast-index-5 align-items-center text-bg-secondary border-0 position-absolute top-0 end-0" role="alert" aria-live="assertive" aria-atomic="true">
  <div class="d-flex">
    <div class="toast-body">
      Copied!
    </div>
  </div>
</div>

---
Primary Category: cs.CL  
Categories: cs-CL, cs-SD, cs.CL, eess-AS  
Keyword Score: 70  
Keywords: Zero-shot, Automatic Speech Recognition, Automatic Speech Recognition, Automatic Speech Recognition, Large Language Model, Large Language Model, Prompt  
<a type="button" class="btn btn-outline-primary" href="http://arxiv.org/abs/2402.07658v1" target="_blank" >Paper Link</a>
<button type="button" class="btn btn-outline-primary download-pdf" url="https://arxiv.org/pdf/2402.07658v1.pdf" filename="2402.07658v1.pdf">Download PDF</button>

---


**ABSTRACT**  
In the rapidly evolving landscape of medical documentation, transcribing clinical dialogues accurately is increasingly paramount. This study explores the potential of <b>Large</b> <b>Language</b> <b>Models</b> <b>(LLMs)</b> to enhance the accuracy of <b>Automatic</b> <b>Speech</b> <b>Recognition</b> <b>(ASR)</b> systems in medical transcription. Utilizing the PriMock57 dataset, which encompasses a diverse range of primary care consultations, we apply advanced <b>LLMs</b> to refine <b>ASR-generated</b> transcripts. Our research is multifaceted, focusing on improvements in general Word Error Rate (WER), Medical Concept WER (MC-WER) for the accurate transcription of essential medical terms, and speaker diarization accuracy. Additionally, we assess the role of <b>LLM</b> post-processing in improving semantic textual similarity, thereby preserving the contextual integrity of clinical dialogues. Through a series of experiments, we compare the efficacy of <b>zero-shot</b> and Chain-of-Thought (CoT) <b>prompting</b> techniques in enhancing diarization and correction accuracy. Our findings demonstrate that <b>LLMs,</b> particularly through CoT <b>prompting,</b> not only improve the diarization accuracy of existing <b>ASR</b> systems but also achieve state-of-the-art performance in this domain. This improvement extends to more accurately capturing medical concepts and enhancing the overall semantic coherence of the transcribed dialogues. These findings illustrate the dual role of <b>LLMs</b> in augmenting <b>ASR</b> outputs and independently excelling in transcription tasks, holding significant promise for transforming medical <b>ASR</b> systems and leading to more accurate and reliable patient records in healthcare settings.

{{</citation>}}


### (6/210) Can LLMs Produce Faithful Explanations For Fact-checking? Towards Faithful Explainable Fact-Checking via Multi-Agent Debate (Kyungha Kim et al., 2024)

{{<citation>}}

Kyungha Kim, Sangyun Lee, Kung-Hsiang Huang, Hou Pong Chan, Manling Li, Heng Ji. (2024)  
**Can LLMs Produce Faithful Explanations For Fact-checking? Towards Faithful Explainable Fact-Checking via Multi-Agent Debate**
<br/>
<button class="copy-to-clipboard" title="Can LLMs Produce Faithful Explanations For Fact-checking? Towards Faithful Explainable Fact-Checking via Multi-Agent Debate" index=6>
  <span class="copy-to-clipboard-item">Copy Title<span>
</button>
<div class="toast toast-copied toast-index-6 align-items-center text-bg-secondary border-0 position-absolute top-0 end-0" role="alert" aria-live="assertive" aria-atomic="true">
  <div class="d-flex">
    <div class="toast-body">
      Copied!
    </div>
  </div>
</div>

---
Primary Category: cs.CL  
Categories: cs-CL, cs.CL  
Keyword Score: 70  
Keywords: Zero-shot, Fact Verification, Natural Language Explanation, Text Generation, Large Language Model, Large Language Model, Prompt  
<a type="button" class="btn btn-outline-primary" href="http://arxiv.org/abs/2402.07401v1" target="_blank" >Paper Link</a>
<button type="button" class="btn btn-outline-primary download-pdf" url="https://arxiv.org/pdf/2402.07401v1.pdf" filename="2402.07401v1.pdf">Download PDF</button>

---


**ABSTRACT**  
<b>Fact-checking</b> <b>research</b> has extensively explored verification but less so the generation of <b>natural-language</b> <b>explanations,</b> <b>crucial</b> for user trust. While <b>Large</b> <b>Language</b> <b>Models</b> <b>(LLMs)</b> excel in <b>text</b> <b>generation,</b> their capability for producing faithful explanations in <b>fact-checking</b> <b>remains</b> underexamined. Our study investigates <b>LLMs'</b> ability to generate such explanations, finding that <b>zero-shot</b> <b>prompts</b> often result in unfaithfulness. To address these challenges, we propose the Multi-Agent Debate Refinement (MADR) framework, leveraging multiple <b>LLMs</b> as agents with diverse roles in an iterative refining process aimed at enhancing faithfulness in generated explanations. MADR ensures that the final explanation undergoes rigorous validation, significantly reducing the likelihood of unfaithful elements and aligning closely with the provided evidence. Experimental results demonstrate that MADR significantly improves the faithfulness of <b>LLM-generated</b> explanations to the evidence, advancing the credibility and trustworthiness of these explanations.

{{</citation>}}


### (7/210) Enhancing Amharic-LLaMA: Integrating Task Specific and Generative Datasets (Israel Abebe Azime et al., 2024)

{{<citation>}}

Israel Abebe Azime, Mitiku Yohannes Fuge, Atnafu Lambebo Tonja, Tadesse Destaw Belay, Aman Kassahun Wassie, Eyasu Shiferaw Jada, Yonas Chanie, Walelign Tewabe Sewunetie, Seid Muhie Yimam. (2024)  
**Enhancing Amharic-LLaMA: Integrating Task Specific and Generative Datasets**
<br/>
<button class="copy-to-clipboard" title="Enhancing Amharic-LLaMA: Integrating Task Specific and Generative Datasets" index=7>
  <span class="copy-to-clipboard-item">Copy Title<span>
</button>
<div class="toast toast-copied toast-index-7 align-items-center text-bg-secondary border-0 position-absolute top-0 end-0" role="alert" aria-live="assertive" aria-atomic="true">
  <div class="d-flex">
    <div class="toast-body">
      Copied!
    </div>
  </div>
</div>

---
Primary Category: cs.CL  
Categories: cs-CL, cs.CL  
Keyword Score: 60  
Keywords: Fine-tuning, Fine-tuning, Low-Resource, LLaMA, Large Language Model, Large Language Model  
<a type="button" class="btn btn-outline-primary" href="http://arxiv.org/abs/2402.08015v1" target="_blank" >Paper Link</a>
<button type="button" class="btn btn-outline-primary download-pdf" url="https://arxiv.org/pdf/2402.08015v1.pdf" filename="2402.08015v1.pdf">Download PDF</button>

---


**ABSTRACT**  
<b>Large</b> <b>language</b> <b>models</b> <b>(LLMs)</b> have received a lot of attention in natural language processing (NLP) research because of their exceptional performance in understanding and generating human languages. However, <b>low-resource</b> languages are left behind due to the unavailability of resources. In this work, we focus on enhancing the <b>LLaMA-2-Amharic</b> model by integrating task-specific and generative datasets to improve language model performance for Amharic. We compile an Amharic instruction <b>fine-tuning</b> dataset and <b>fine-tuned</b> <b>LLaMA-2-Amharic</b> model. The <b>fine-tuned</b> model shows promising results in different NLP tasks. We open-source our dataset creation pipeline, instruction datasets, trained models, and evaluation outputs to promote language-specific studies on these models.

{{</citation>}}


### (8/210) Lissard: Long and Simple Sequential Reasoning Datasets (Mirelle Bueno et al., 2024)

{{<citation>}}

Mirelle Bueno, Roberto Lotufo, Rodrigo Nogueira. (2024)  
**Lissard: Long and Simple Sequential Reasoning Datasets**
<br/>
<button class="copy-to-clipboard" title="Lissard: Long and Simple Sequential Reasoning Datasets" index=8>
  <span class="copy-to-clipboard-item">Copy Title<span>
</button>
<div class="toast toast-copied toast-index-8 align-items-center text-bg-secondary border-0 position-absolute top-0 end-0" role="alert" aria-live="assertive" aria-atomic="true">
  <div class="d-flex">
    <div class="toast-body">
      Copied!
    </div>
  </div>
</div>

---
Primary Category: cs.CL  
Categories: cs-AI, cs-CL, cs.CL  
Keyword Score: 60  
Keywords: GPT, GPT-3, GPT-3.5, GPT-4, Reasoning, Large Language Model  
<a type="button" class="btn btn-outline-primary" href="http://arxiv.org/abs/2402.07859v1" target="_blank" >Paper Link</a>
<button type="button" class="btn btn-outline-primary download-pdf" url="https://arxiv.org/pdf/2402.07859v1.pdf" filename="2402.07859v1.pdf">Download PDF</button>

---


**ABSTRACT**  
Language models are now capable of solving tasks that require dealing with long sequences consisting of hundreds of thousands of tokens. However, they often fail on tasks that require repetitive use of simple rules, even on sequences that are much shorter than those seen during training. For example, state-of-the-art <b>LLMs</b> can find common items in two lists with up to 20 items but fail when lists have 80 items. In this paper, we introduce Lissard, a benchmark comprising seven tasks whose goal is to assess the ability of models to process and generate wide-range sequence lengths, requiring repetitive procedural execution. Our evaluation of open-source (Mistral-7B and Mixtral-8x7B) and proprietary models <b>(GPT-3.5</b> and <b>GPT-4)</b> show a consistent decline in performance across all models as the complexity of the sequence increases. The datasets and code are available at https://github.com/unicamp-dl/Lissard

{{</citation>}}


### (9/210) Injecting Wiktionary to improve token-level contextual representations using contrastive learning (Anna Mosolova et al., 2024)

{{<citation>}}

Anna Mosolova, Marie Candito, Carlos Ramisch. (2024)  
**Injecting Wiktionary to improve token-level contextual representations using contrastive learning**
<br/>
<button class="copy-to-clipboard" title="Injecting Wiktionary to improve token-level contextual representations using contrastive learning" index=9>
  <span class="copy-to-clipboard-item">Copy Title<span>
</button>
<div class="toast toast-copied toast-index-9 align-items-center text-bg-secondary border-0 position-absolute top-0 end-0" role="alert" aria-live="assertive" aria-atomic="true">
  <div class="d-flex">
    <div class="toast-body">
      Copied!
    </div>
  </div>
</div>

---
Primary Category: cs.CL  
Categories: cs-CL, cs.CL  
Keyword Score: 60  
Keywords: Contrastive Learning, Fine-tuning, Unsupervised Learning, Pre-trained Language Model, Pre-trained Language Model, Word Embedding  
<a type="button" class="btn btn-outline-primary" href="http://arxiv.org/abs/2402.07817v1" target="_blank" >Paper Link</a>
<button type="button" class="btn btn-outline-primary download-pdf" url="https://arxiv.org/pdf/2402.07817v1.pdf" filename="2402.07817v1.pdf">Download PDF</button>

---


**ABSTRACT**  
While static <b>word</b> <b>embeddings</b> are blind to context, for lexical semantics tasks context is rather too present in contextual <b>word</b> <b>embeddings,</b> vectors of same-meaning occurrences being too different (Ethayarajh, 2019). <b>Fine-tuning</b> <b>pre-trained</b> <b>language</b> <b>models</b> <b>(PLMs)</b> using <b>contrastive</b> <b>learning</b> was proposed, leveraging automatically self-augmented examples (Liu et al., 2021b). In this paper, we investigate how to inject a lexicon as an alternative source of supervision, using the English Wiktionary. We also test how dimensionality reduction impacts the resulting contextual <b>word</b> <b>embeddings.</b> We evaluate our approach on the <b>Word-In-Context</b> <b>(WiC)</b> task, in the <b>unsupervised</b> setting (not using the training set). We achieve new SoTA result on the original WiC test set. We also propose two new WiC test sets for which we show that our <b>fine-tuning</b> method achieves substantial improvements. We also observe improvements, although modest, for the semantic frame induction task. Although we experimented on English to allow comparison with related work, our method is adaptable to the many languages for which large Wiktionaries exist.

{{</citation>}}


### (10/210) Dólares or Dollars? Unraveling the Bilingual Prowess of Financial LLMs Between Spanish and English (Xiao Zhang et al., 2024)

{{<citation>}}

Xiao Zhang, Ruoyu Xiang, Chenhan Yuan, Duanyu Feng, Weiguang Han, Alejandro Lopez-Lira, Xiao-Yang Liu, Sophia Ananiadou, Min Peng, Jimin Huang, Qianqian Xie. (2024)  
**Dólares or Dollars? Unraveling the Bilingual Prowess of Financial LLMs Between Spanish and English**
<br/>
<button class="copy-to-clipboard" title="Dólares or Dollars? Unraveling the Bilingual Prowess of Financial LLMs Between Spanish and English" index=10>
  <span class="copy-to-clipboard-item">Copy Title<span>
</button>
<div class="toast toast-copied toast-index-10 align-items-center text-bg-secondary border-0 position-absolute top-0 end-0" role="alert" aria-live="assertive" aria-atomic="true">
  <div class="d-flex">
    <div class="toast-body">
      Copied!
    </div>
  </div>
</div>

---
Primary Category: cs.CL  
Categories: cs-CL, cs.CL  
Keyword Score: 60  
Keywords: Fine-tuning, GPT, GPT-4, Instruction Tuning, Large Language Model, Large Language Model  
<a type="button" class="btn btn-outline-primary" href="http://arxiv.org/abs/2402.07405v1" target="_blank" >Paper Link</a>
<button type="button" class="btn btn-outline-primary download-pdf" url="https://arxiv.org/pdf/2402.07405v1.pdf" filename="2402.07405v1.pdf">Download PDF</button>

---


**ABSTRACT**  
Despite Spanish's pivotal role in the global finance industry, a pronounced gap exists in Spanish financial natural language processing (NLP) and application studies compared to English, especially in the era of <b>large</b> <b>language</b> <b>models</b> <b>(LLMs).</b> To bridge this gap, we unveil Tois\'on de Oro, the first bilingual framework that establishes <b>instruction</b> <b>datasets,</b> <b>finetuned</b> <b>LLMs,</b> and evaluation benchmark for financial <b>LLMs</b> in Spanish joint with English. We construct a rigorously curated bilingual <b>instruction</b> <b>dataset</b> including over 144K Spanish and English samples from 15 datasets covering 7 tasks. Harnessing this, we introduce FinMA-ES, an <b>LLM</b> designed for bilingual financial applications. We evaluate our model and existing <b>LLMs</b> using FLARE-ES, the first comprehensive bilingual evaluation benchmark with 21 datasets covering 9 tasks. The FLARE-ES benchmark results reveal a significant multilingual performance gap and bias in existing <b>LLMs.</b> FinMA-ES models surpass SOTA <b>LLMs</b> such as <b>GPT-4</b> in Spanish financial tasks, due to strategic <b>instruction</b> <b>tuning</b> and leveraging data from diverse linguistic resources, highlighting the positive impact of cross-linguistic transfer. All our datasets, models, and benchmarks have been released.

{{</citation>}}


### (11/210) Chain-of-Layer: Iteratively Prompting Large Language Models for Taxonomy Induction from Limited Examples (Qingkai Zeng et al., 2024)

{{<citation>}}

Qingkai Zeng, Yuyang Bai, Zhaoxuan Tan, Shangbin Feng, Zhenwen Liang, Zhihan Zhang, Meng Jiang. (2024)  
**Chain-of-Layer: Iteratively Prompting Large Language Models for Taxonomy Induction from Limited Examples**
<br/>
<button class="copy-to-clipboard" title="Chain-of-Layer: Iteratively Prompting Large Language Models for Taxonomy Induction from Limited Examples" index=11>
  <span class="copy-to-clipboard-item">Copy Title<span>
</button>
<div class="toast toast-copied toast-index-11 align-items-center text-bg-secondary border-0 position-absolute top-0 end-0" role="alert" aria-live="assertive" aria-atomic="true">
  <div class="d-flex">
    <div class="toast-body">
      Copied!
    </div>
  </div>
</div>

---
Primary Category: cs.CL  
Categories: cs-CL, cs.CL  
Keyword Score: 60  
Keywords: Recommendation, Question Answering, In-context Learning, In-context Learning, Large Language Model, Prompt  
<a type="button" class="btn btn-outline-primary" href="http://arxiv.org/abs/2402.07386v1" target="_blank" >Paper Link</a>
<button type="button" class="btn btn-outline-primary download-pdf" url="https://arxiv.org/pdf/2402.07386v1.pdf" filename="2402.07386v1.pdf">Download PDF</button>

---


**ABSTRACT**  
Automatic taxonomy induction is crucial for web search, <b>recommendation</b> systems, and <b>question</b> <b>answering.</b> Manual curation of taxonomies is expensive in terms of human effort, making automatic taxonomy construction highly desirable. In this work, we introduce Chain-of-Layer which is an <b>in-context</b> <b>learning</b> framework designed to induct taxonomies from a given set of entities. Chain-of-Layer breaks down the task into selecting relevant candidate entities in each layer and gradually building the taxonomy from top to bottom. To minimize errors, we introduce the Ensemble-based Ranking Filter to reduce the hallucinated content generated at each iteration. Through extensive experiments, we demonstrate that Chain-of-Layer achieves state-of-the-art performance on four real-world benchmarks.

{{</citation>}}


### (12/210) Large Language Models as Agents in Two-Player Games (Yang Liu et al., 2024)

{{<citation>}}

Yang Liu, Peng Sun, Hang Li. (2024)  
**Large Language Models as Agents in Two-Player Games**
<br/>
<button class="copy-to-clipboard" title="Large Language Models as Agents in Two-Player Games" index=12>
  <span class="copy-to-clipboard-item">Copy Title<span>
</button>
<div class="toast toast-copied toast-index-12 align-items-center text-bg-secondary border-0 position-absolute top-0 end-0" role="alert" aria-live="assertive" aria-atomic="true">
  <div class="d-flex">
    <div class="toast-body">
      Copied!
    </div>
  </div>
</div>

---
Primary Category: cs.CL  
Categories: cs-CL, cs-LG, cs.CL  
Keyword Score: 50  
Keywords: Fine-tuning, Reinforcement Learning, Supervised Learning, Large Language Model, Large Language Model  
<a type="button" class="btn btn-outline-primary" href="http://arxiv.org/abs/2402.08078v1" target="_blank" >Paper Link</a>
<button type="button" class="btn btn-outline-primary download-pdf" url="https://arxiv.org/pdf/2402.08078v1.pdf" filename="2402.08078v1.pdf">Download PDF</button>

---


**ABSTRACT**  
By formally defining the training processes of <b>large</b> <b>language</b> <b>models</b> <b>(LLMs),</b> which usually encompasses pre-training, <b>supervised</b> <b>fine-tuning,</b> and <b>reinforcement</b> <b>learning</b> with human feedback, within a single and unified machine learning paradigm, we can glean pivotal insights for advancing <b>LLM</b> technologies. This position paper delineates the parallels between the training methods of <b>LLMs</b> and the strategies employed for the development of agents in two-player games, as studied in game theory, <b>reinforcement</b> <b>learning,</b> and multi-agent systems. We propose a re-conceptualization of <b>LLM</b> learning processes in terms of agent learning in language-based games. This framework unveils innovative perspectives on the successes and challenges in <b>LLM</b> development, offering a fresh understanding of addressing alignment issues among other strategic considerations. Furthermore, our two-player game approach sheds light on novel data preparation and machine learning techniques for training <b>LLMs.</b>

{{</citation>}}


### (13/210) Aya Model: An Instruction Finetuned Open-Access Multilingual Language Model (Ahmet Üstün et al., 2024)

{{<citation>}}

Ahmet Üstün, Viraat Aryabumi, Zheng-Xin Yong, Wei-Yin Ko, Daniel D'souza, Gbemileke Onilude, Neel Bhandari, Shivalika Singh, Hui-Lee Ooi, Amr Kayid, Freddie Vargus, Phil Blunsom, Shayne Longpre, Niklas Muennighoff, Marzieh Fadaee, Julia Kreutzer, Sara Hooker. (2024)  
**Aya Model: An Instruction Finetuned Open-Access Multilingual Language Model**
<br/>
<button class="copy-to-clipboard" title="Aya Model: An Instruction Finetuned Open-Access Multilingual Language Model" index=13>
  <span class="copy-to-clipboard-item">Copy Title<span>
</button>
<div class="toast toast-copied toast-index-13 align-items-center text-bg-secondary border-0 position-absolute top-0 end-0" role="alert" aria-live="assertive" aria-atomic="true">
  <div class="d-flex">
    <div class="toast-body">
      Copied!
    </div>
  </div>
</div>

---
Primary Category: cs.CL  
Categories: cs-CL, cs.CL  
Keyword Score: 50  
Keywords: Fine-tuning, Fine-tuning, Pruning, Large Language Model, Large Language Model  
<a type="button" class="btn btn-outline-primary" href="http://arxiv.org/abs/2402.07827v1" target="_blank" >Paper Link</a>
<button type="button" class="btn btn-outline-primary download-pdf" url="https://arxiv.org/pdf/2402.07827v1.pdf" filename="2402.07827v1.pdf">Download PDF</button>

---


**ABSTRACT**  
Recent breakthroughs in <b>large</b> <b>language</b> <b>models</b> <b>(LLMs)</b> have centered around a handful of data-rich languages. What does it take to broaden access to breakthroughs beyond first-class citizen languages? Our work introduces Aya, a massively multilingual generative language model that follows instructions in 101 languages of which over 50% are considered as lower-resourced. Aya outperforms mT0 and BLOOMZ on the majority of tasks while covering double the number of languages. We introduce extensive new evaluation suites that broaden the state-of-art for multilingual eval across 99 languages -- including discriminative and generative tasks, human evaluation, and simulated win rates that cover both held-out tasks and in-distribution performance. Furthermore, we conduct detailed investigations on the optimal <b>finetuning</b> mixture composition, data <b>pruning,</b> as well as the toxicity, bias, and safety of our models. We open-source our instruction datasets and our model at https://hf.co/CohereForAI/aya-101

{{</citation>}}


### (14/210) TELLER: A Trustworthy Framework for Explainable, Generalizable and Controllable Fake News Detection (Hui Liu et al., 2024)

{{<citation>}}

Hui Liu, Wenya Wang, Haoru Li, Haoliang Li. (2024)  
**TELLER: A Trustworthy Framework for Explainable, Generalizable and Controllable Fake News Detection**
<br/>
<button class="copy-to-clipboard" title="TELLER: A Trustworthy Framework for Explainable, Generalizable and Controllable Fake News Detection" index=14>
  <span class="copy-to-clipboard-item">Copy Title<span>
</button>
<div class="toast toast-copied toast-index-14 align-items-center text-bg-secondary border-0 position-absolute top-0 end-0" role="alert" aria-live="assertive" aria-atomic="true">
  <div class="d-flex">
    <div class="toast-body">
      Copied!
    </div>
  </div>
</div>

---
Primary Category: cs.CL  
Categories: cs-CL, cs.CL  
Keyword Score: 50  
Keywords: Fake News Detection, Reasoning, Fake News Detection, Large Language Model, Large Language Model  
<a type="button" class="btn btn-outline-primary" href="http://arxiv.org/abs/2402.07776v1" target="_blank" >Paper Link</a>
<button type="button" class="btn btn-outline-primary download-pdf" url="https://arxiv.org/pdf/2402.07776v1.pdf" filename="2402.07776v1.pdf">Download PDF</button>

---


**ABSTRACT**  
The proliferation of <b>fake</b> <b>news</b> <b>has</b> emerged as a severe societal problem, raising significant interest from industry and academia. While existing deep-learning based methods have made progress in detecting <b>fake</b> <b>news</b> <b>accurately,</b> their reliability may be compromised caused by the non-transparent <b>reasoning</b> processes, poor generalization abilities and inherent risks of integration with <b>large</b> <b>language</b> <b>models</b> <b>(LLMs).</b> To address this challenge, we propose {\methodname}, a novel framework for trustworthy <b>fake</b> <b>news</b> <b>detection</b> that prioritizes explainability, generalizability and controllability of models. This is achieved via a dual-system framework that integrates cognition and decision systems, adhering to the principles above. The cognition system harnesses human expertise to generate logical predicates, which guide <b>LLMs</b> in generating human-readable logic atoms. Meanwhile, the decision system deduces generalizable logic rules to aggregate these atoms, enabling the identification of the truthfulness of the input news across diverse domains and enhancing transparency in the decision-making process. Finally, we present comprehensive evaluation results on four datasets, demonstrating the feasibility and trustworthiness of our proposed framework. Our implementation is available at \url{https://github.com/less-and-less-bugs/Trust_TELLER}.

{{</citation>}}


### (15/210) Detecting the Clinical Features of Difficult-to-Treat Depression using Synthetic Data from Large Language Models (Isabelle Lorge et al., 2024)

{{<citation>}}

Isabelle Lorge, Dan W. Joyce, Niall Taylor, Alejo Nevado-Holgado, Andrea Cipriani, Andrey Kormilitzin. (2024)  
**Detecting the Clinical Features of Difficult-to-Treat Depression using Synthetic Data from Large Language Models**
<br/>
<button class="copy-to-clipboard" title="Detecting the Clinical Features of Difficult-to-Treat Depression using Synthetic Data from Large Language Models" index=15>
  <span class="copy-to-clipboard-item">Copy Title<span>
</button>
<div class="toast toast-copied toast-index-15 align-items-center text-bg-secondary border-0 position-absolute top-0 end-0" role="alert" aria-live="assertive" aria-atomic="true">
  <div class="d-flex">
    <div class="toast-body">
      Copied!
    </div>
  </div>
</div>

---
Primary Category: cs.CL  
Categories: cs-CL, cs.CL  
Keyword Score: 50  
Keywords: BERT, GPT-3, GPT-3.5, Large Language Model, Large Language Model  
<a type="button" class="btn btn-outline-primary" href="http://arxiv.org/abs/2402.07645v1" target="_blank" >Paper Link</a>
<button type="button" class="btn btn-outline-primary download-pdf" url="https://arxiv.org/pdf/2402.07645v1.pdf" filename="2402.07645v1.pdf">Download PDF</button>

---


**ABSTRACT**  
Difficult-to-treat depression (DTD) has been proposed as a broader and more clinically comprehensive perspective on a person's depressive disorder where despite treatment, they continue to experience significant burden. We sought to develop a <b>Large</b> <b>Language</b> <b>Model</b> <b>(LLM)-based</b> tool capable of interrogating routinely-collected, narrative (free-text) electronic health record (EHR) data to locate published prognostic factors that capture the clinical syndrome of DTD. In this work, we use <b>LLM-generated</b> synthetic data <b>(GPT3.5)</b> and a Non-Maximum Suppression (NMS) algorithm to train a <b>BERT-based</b> span extraction model. The resulting model is then able to extract and label spans related to a variety of relevant positive and negative factors in real clinical data (i.e. spans of text that increase or decrease the likelihood of a patient matching the DTD syndrome). We show it is possible to obtain good overall performance (0.70 F1 across polarity) on real clinical data on a set of as many as 20 different factors, and high performance (0.85 F1 with 0.95 precision) on a subset of important DTD factors such as history of abuse, family history of affective disorder, illness severity and suicidality by training the model exclusively on synthetic data. Our results show promise for future healthcare applications especially in applications where traditionally, highly confidential medical data and human-expert annotation would normally be required.

{{</citation>}}


### (16/210) AutoMathText: Autonomous Data Selection with Language Models for Mathematical Texts (Yifan Zhang et al., 2024)

{{<citation>}}

Yifan Zhang, Yifan Luo, Yang Yuan, Andrew Chi-Chih Yao. (2024)  
**AutoMathText: Autonomous Data Selection with Language Models for Mathematical Texts**
<br/>
<button class="copy-to-clipboard" title="AutoMathText: Autonomous Data Selection with Language Models for Mathematical Texts" index=16>
  <span class="copy-to-clipboard-item">Copy Title<span>
</button>
<div class="toast toast-copied toast-index-16 align-items-center text-bg-secondary border-0 position-absolute top-0 end-0" role="alert" aria-live="assertive" aria-atomic="true">
  <div class="d-flex">
    <div class="toast-body">
      Copied!
    </div>
  </div>
</div>

---
Primary Category: cs.CL  
Categories: cs-AI, cs-CL, cs-LG, cs.CL  
Keyword Score: 50  
Keywords: Fine-tuning, Supervised Learning, Zero-shot, Mathematical Reasoning, Reasoning  
<a type="button" class="btn btn-outline-primary" href="http://arxiv.org/abs/2402.07625v1" target="_blank" >Paper Link</a>
<button type="button" class="btn btn-outline-primary download-pdf" url="https://arxiv.org/pdf/2402.07625v1.pdf" filename="2402.07625v1.pdf">Download PDF</button>

---


**ABSTRACT**  
To improve language models' proficiency in <b>mathematical</b> <b>reasoning</b> via continual pretraining, we introduce a novel strategy that leverages base language models for autonomous data selection. Departing from conventional <b>supervised</b> <b>fine-tuning</b> or trained classifiers with human-annotated data, our approach utilizes meta-prompted language models as <b>zero-shot</b> verifiers to autonomously evaluate and select high-quality <b>mathematical</b> <b>content,</b> and we release the curated open-source AutoMathText dataset encompassing over 200GB of data. To demonstrate the efficacy of our method, we continuously pretrained a 7B-parameter Mistral language model on the AutoMathText dataset, achieving substantial improvements in downstream performance on the MATH dataset with a token amount reduced by orders of magnitude compared to previous continuous pretraining works. Our method showcases a 2 times increase in pretraining token efficiency compared to baselines, underscoring the potential of our approach in enhancing models' <b>mathematical</b> <b>reasoning</b> capabilities. The AutoMathText dataset is available at https://huggingface.co/datasets/math-ai/AutoMathText. The code is available at https://github.com/yifanzhang-pro/AutoMathText.

{{</citation>}}


### (17/210) Step-On-Feet Tuning: Scaling Self-Alignment of LLMs via Bootstrapping (Haoyu Wang et al., 2024)

{{<citation>}}

Haoyu Wang, Guozheng Ma, Ziqiao Meng, Zeyu Qin, Li Shen, Zhong Zhang, Bingzhe Wu, Liu Liu, Yatao Bian, Tingyang Xu, Xueqian Wang, Peilin Zhao. (2024)  
**Step-On-Feet Tuning: Scaling Self-Alignment of LLMs via Bootstrapping**
<br/>
<button class="copy-to-clipboard" title="Step-On-Feet Tuning: Scaling Self-Alignment of LLMs via Bootstrapping" index=17>
  <span class="copy-to-clipboard-item">Copy Title<span>
</button>
<div class="toast toast-copied toast-index-17 align-items-center text-bg-secondary border-0 position-absolute top-0 end-0" role="alert" aria-live="assertive" aria-atomic="true">
  <div class="d-flex">
    <div class="toast-body">
      Copied!
    </div>
  </div>
</div>

---
Primary Category: cs.CL  
Categories: cs-AI, cs-CL, cs.CL  
Keyword Score: 50  
Keywords: Few-shot, In-context Learning, In-context Learning, Large Language Model, Large Language Model  
<a type="button" class="btn btn-outline-primary" href="http://arxiv.org/abs/2402.07610v1" target="_blank" >Paper Link</a>
<button type="button" class="btn btn-outline-primary download-pdf" url="https://arxiv.org/pdf/2402.07610v1.pdf" filename="2402.07610v1.pdf">Download PDF</button>

---


**ABSTRACT**  
Self-alignment is an effective way to reduce the cost of human annotation while ensuring promising model capability. However, most current methods complete the data collection and training steps in a single round, which may overlook the continuously improving ability of self-aligned models. This gives rise to a key query: What if we do multi-time bootstrapping self-alignment? Does this strategy enhance model performance or lead to rapid degradation? In this paper, our pioneering exploration delves into the impact of bootstrapping self-alignment on <b>large</b> <b>language</b> <b>models.</b> Our findings reveal that bootstrapping self-alignment markedly surpasses the single-round approach, by guaranteeing data diversity from <b>in-context</b> <b>learning.</b> To further exploit the capabilities of bootstrapping, we investigate and adjust the training order of data, which yields improved performance of the model. Drawing on these findings, we propose Step-On-Feet Tuning (SOFT) which leverages model's continuously enhanced <b>few-shot</b> ability to boost zero or one-shot performance. Based on easy-to-hard training recipe, we propose SOFT+ which further boost self-alignment's performance. Our experiments demonstrate the efficiency of SOFT (SOFT+) across various classification and generation tasks, highlighting the potential of bootstrapping self-alignment on continually enhancing model alignment performance.

{{</citation>}}


### (18/210) MAFIA: Multi-Adapter Fused Inclusive LanguAge Models (Prachi Jain et al., 2024)

{{<citation>}}

Prachi Jain, Ashutosh Sathe, Varun Gumma, Kabir Ahuja, Sunayana Sitaram. (2024)  
**MAFIA: Multi-Adapter Fused Inclusive LanguAge Models**
<br/>
<button class="copy-to-clipboard" title="MAFIA: Multi-Adapter Fused Inclusive LanguAge Models" index=18>
  <span class="copy-to-clipboard-item">Copy Title<span>
</button>
<div class="toast toast-copied toast-index-18 align-items-center text-bg-secondary border-0 position-absolute top-0 end-0" role="alert" aria-live="assertive" aria-atomic="true">
  <div class="d-flex">
    <div class="toast-body">
      Copied!
    </div>
  </div>
</div>

---
Primary Category: cs.CL  
Categories: cs-CL, cs-CY, cs.CL  
Keyword Score: 50  
Keywords: Counter-factual, Data Augmentation, Fine-tuning, Pre-trained Language Model, Pre-trained Language Model  
<a type="button" class="btn btn-outline-primary" href="http://arxiv.org/abs/2402.07519v1" target="_blank" >Paper Link</a>
<button type="button" class="btn btn-outline-primary download-pdf" url="https://arxiv.org/pdf/2402.07519v1.pdf" filename="2402.07519v1.pdf">Download PDF</button>

---


**ABSTRACT**  
<b>Pretrained</b> <b>Language</b> <b>Models</b> <b>(PLMs)</b> are widely used in NLP for various tasks. Recent studies have identified various biases that such models exhibit and have proposed methods to correct these biases. However, most of the works address a limited set of bias dimensions independently such as gender, race, or religion. Moreover, the methods typically involve <b>finetuning</b> the full model to maintain the performance on the downstream task. In this work, we aim to modularly debias a <b>pretrained</b> <b>language</b> <b>model</b> across multiple dimensions. Previous works extensively explored debiasing <b>PLMs</b> using limited US-centric <b>counterfactual</b> <b>data</b> <b>augmentation</b> (CDA). We use structured knowledge and a large generative model to build a diverse CDA across multiple bias dimensions in a semi-automated way. We highlight how existing debiasing methods do not consider interactions between multiple societal biases and propose a debiasing model that exploits the synergy amongst various societal biases and enables multi-bias debiasing simultaneously. An extensive evaluation on multiple tasks and languages demonstrates the efficacy of our approach.

{{</citation>}}


### (19/210) Pushing The Limit of LLM Capacity for Text Classification (Yazhou Zhang et al., 2024)

{{<citation>}}

Yazhou Zhang, Mengyao Wang, Chenyu Ren, Qiuchi Li, Prayag Tiwari, Benyou Wang, Jing Qin. (2024)  
**Pushing The Limit of LLM Capacity for Text Classification**
<br/>
<button class="copy-to-clipboard" title="Pushing The Limit of LLM Capacity for Text Classification" index=19>
  <span class="copy-to-clipboard-item">Copy Title<span>
</button>
<div class="toast toast-copied toast-index-19 align-items-center text-bg-secondary border-0 position-absolute top-0 end-0" role="alert" aria-live="assertive" aria-atomic="true">
  <div class="d-flex">
    <div class="toast-body">
      Copied!
    </div>
  </div>
</div>

---
Primary Category: cs.CL  
Categories: cs-CL, cs.CL  
Keyword Score: 50  
Keywords: Fine-tuning, Text Classification, Large Language Model, Large Language Model, Pre-trained Language Model  
<a type="button" class="btn btn-outline-primary" href="http://arxiv.org/abs/2402.07470v1" target="_blank" >Paper Link</a>
<button type="button" class="btn btn-outline-primary download-pdf" url="https://arxiv.org/pdf/2402.07470v1.pdf" filename="2402.07470v1.pdf">Download PDF</button>

---


**ABSTRACT**  
The value of <b>text</b> <b>classification's</b> future research has encountered challenges and uncertainties, due to the extraordinary efficacy demonstrated by <b>large</b> <b>language</b> <b>models</b> <b>(LLMs)</b> across numerous downstream NLP tasks. In this era of open-ended language modeling, where task boundaries are gradually fading, an urgent question emerges: have we made significant advances in <b>text</b> <b>classification</b> under the full benefit of LLMs? To answer this question, we propose RGPT, an adaptive boosting framework tailored to produce a specialized <b>text</b> <b>classification</b> <b>LLM</b> by recurrently ensembling a pool of strong base learners. The base learners are constructed by adaptively adjusting the distribution of training samples and iteratively <b>fine-tuning</b> <b>LLMs</b> with them. Such base learners are then ensembled to be a specialized <b>text</b> <b>classification</b> <b>LLM,</b> by recurrently incorporating the historical predictions from the previous learners. Through a comprehensive empirical comparison, we show that RGPT significantly outperforms 8 SOTA <b>PLMs</b> and 7 SOTA <b>LLMs</b> on four benchmarks by 1.36% on average. Further evaluation experiments show a clear surpassing of RGPT over human classification.

{{</citation>}}


### (20/210) Retrieval-Augmented Thought Process as Sequential Decision Making (Thomas Pouplin et al., 2024)

{{<citation>}}

Thomas Pouplin, Hao Sun, Samuel Holt, Mihaela van der Schaar. (2024)  
**Retrieval-Augmented Thought Process as Sequential Decision Making**
<br/>
<button class="copy-to-clipboard" title="Retrieval-Augmented Thought Process as Sequential Decision Making" index=20>
  <span class="copy-to-clipboard-item">Copy Title<span>
</button>
<div class="toast toast-copied toast-index-20 align-items-center text-bg-secondary border-0 position-absolute top-0 end-0" role="alert" aria-live="assertive" aria-atomic="true">
  <div class="d-flex">
    <div class="toast-body">
      Copied!
    </div>
  </div>
</div>

---
Primary Category: cs.CL  
Categories: H-3-3; I-2-6; I-2-7; I-2-8, cs-AI, cs-CL, cs-IR, cs-LG, cs.CL  
Keyword Score: 40  
Keywords: Question Answering, In-context Learning, Large Language Model, Large Language Model  
<a type="button" class="btn btn-outline-primary" href="http://arxiv.org/abs/2402.07812v1" target="_blank" >Paper Link</a>
<button type="button" class="btn btn-outline-primary download-pdf" url="https://arxiv.org/pdf/2402.07812v1.pdf" filename="2402.07812v1.pdf">Download PDF</button>

---


**ABSTRACT**  
<b>Large</b> <b>Language</b> <b>Models</b> <b>(LLMs)</b> have demonstrated their strong ability to assist people and show "sparks of intelligence". However, several open challenges hinder their wider application: such as concerns over privacy, tendencies to produce hallucinations, and difficulties in handling long contexts. In this work, we address those challenges by introducing the Retrieval-Augmented Thought Process (RATP). Given access to external knowledge, RATP formulates the thought generation of <b>LLMs</b> as a multiple-step decision process. To optimize such a thought process, RATP leverages Monte-Carlo Tree Search, and learns a Q-value estimator that permits cost-efficient inference. In addressing the task of <b>question-answering</b> <b>with</b> private data, where ethical and security concerns limit <b>LLM</b> training methods, RATP achieves a 50% improvement over existing <b>in-context</b> retrieval-augmented language models.

{{</citation>}}


### (21/210) Unsupervised Sign Language Translation and Generation (Zhengsheng Guo et al., 2024)

{{<citation>}}

Zhengsheng Guo, Zhiwei He, Wenxiang Jiao, Xing Wang, Rui Wang, Kehai Chen, Zhaopeng Tu, Yong Xu, Min Zhang. (2024)  
**Unsupervised Sign Language Translation and Generation**
<br/>
<button class="copy-to-clipboard" title="Unsupervised Sign Language Translation and Generation" index=21>
  <span class="copy-to-clipboard-item">Copy Title<span>
</button>
<div class="toast toast-copied toast-index-21 align-items-center text-bg-secondary border-0 position-absolute top-0 end-0" role="alert" aria-live="assertive" aria-atomic="true">
  <div class="d-flex">
    <div class="toast-body">
      Copied!
    </div>
  </div>
</div>

---
Primary Category: cs.CL  
Categories: cs-CL, cs.CL  
Keyword Score: 40  
Keywords: Supervised Learning, Unsupervised Learning, Neural Machine Translation, Neural Machine Translation  
<a type="button" class="btn btn-outline-primary" href="http://arxiv.org/abs/2402.07726v1" target="_blank" >Paper Link</a>
<button type="button" class="btn btn-outline-primary download-pdf" url="https://arxiv.org/pdf/2402.07726v1.pdf" filename="2402.07726v1.pdf">Download PDF</button>

---


**ABSTRACT**  
Motivated by the success of <b>unsupervised</b> <b>neural</b> <b>machine</b> <b>translation</b> (UNMT), we introduce an <b>unsupervised</b> sign language translation and generation network (USLNet), which learns from abundant single-modality (text and video) data without parallel sign language data. USLNet comprises two main components: single-modality reconstruction modules (text and video) that rebuild the input from its noisy version in the same modality and cross-modality back-translation modules (text-video-text and video-text-video) that reconstruct the input from its noisy version in the different modality using back-translation procedure.Unlike the single-modality back-translation procedure in text-based UNMT, USLNet faces the cross-modality discrepancy in feature representation, in which the length and the feature dimension mismatch between text and video sequences. We propose a sliding window method to address the issues of aligning variable-length text with video sequences. To our knowledge, USLNet is the first <b>unsupervised</b> sign language translation and generation model capable of generating both natural language text and sign language video in a unified manner. Experimental results on the BBC-Oxford Sign Language dataset (BOBSL) and Open-Domain American Sign Language dataset (OpenASL) reveal that USLNet achieves competitive results compared to <b>supervised</b> baseline models, indicating its effectiveness in sign language translation and generation.

{{</citation>}}


### (22/210) Anchor-based Large Language Models (Jianhui Pang et al., 2024)

{{<citation>}}

Jianhui Pang, Fanghua Ye, Derek F. Wong, Longyue Wang. (2024)  
**Anchor-based Large Language Models**
<br/>
<button class="copy-to-clipboard" title="Anchor-based Large Language Models" index=22>
  <span class="copy-to-clipboard-item">Copy Title<span>
</button>
<div class="toast toast-copied toast-index-22 align-items-center text-bg-secondary border-0 position-absolute top-0 end-0" role="alert" aria-live="assertive" aria-atomic="true">
  <div class="d-flex">
    <div class="toast-body">
      Copied!
    </div>
  </div>
</div>

---
Primary Category: cs.CL  
Categories: cs-AI, cs-CL, cs.CL  
Keyword Score: 40  
Keywords: Transformer, Large Language Model, Large Language Model, Self-Attention  
<a type="button" class="btn btn-outline-primary" href="http://arxiv.org/abs/2402.07616v1" target="_blank" >Paper Link</a>
<button type="button" class="btn btn-outline-primary download-pdf" url="https://arxiv.org/pdf/2402.07616v1.pdf" filename="2402.07616v1.pdf">Download PDF</button>

---


**ABSTRACT**  
<b>Large</b> <b>language</b> <b>models</b> <b>(LLMs)</b> predominantly employ decoder-only <b>transformer</b> architectures, necessitating the retention of keys/values information for historical tokens to provide contextual information and avoid redundant computation. However, the substantial size and parameter volume of these <b>LLMs</b> require massive GPU memory. This memory demand increases with the length of the input text, leading to an urgent need for more efficient methods of information storage and processing. This study introduces the Anchor-based <b>LLM</b> (AnLLM), which utilizes an innovative anchor-based <b>self-attention</b> network (AnSAN) and also an anchor-based inference strategy. This approach enables <b>LLMs</b> to compress sequence information into an anchor token, reducing the keys/values cache and enhancing inference efficiency. Experiments show that the AnLLM maintains comparable accuracy with up to 99% keys/values cache reduction and up to 3.5 times faster inference. Despite a minor compromise in accuracy, the AnLLM significantly improves computational efficiency and resource utilization, demonstrating the potential of the anchor-based attention approach in the context of <b>LLMs</b> for real-time inference in practical applications.

{{</citation>}}


### (23/210) Topic Modeling as Multi-Objective Contrastive Optimization (Thong Nguyen et al., 2024)

{{<citation>}}

Thong Nguyen, Xiaobao Wu, Xinshuai Dong, Cong-Duy T Nguyen, See-Kiong Ng, Anh Tuan Luu. (2024)  
**Topic Modeling as Multi-Objective Contrastive Optimization**
<br/>
<button class="copy-to-clipboard" title="Topic Modeling as Multi-Objective Contrastive Optimization" index=23>
  <span class="copy-to-clipboard-item">Copy Title<span>
</button>
<div class="toast toast-copied toast-index-23 align-items-center text-bg-secondary border-0 position-absolute top-0 end-0" role="alert" aria-live="assertive" aria-atomic="true">
  <div class="d-flex">
    <div class="toast-body">
      Copied!
    </div>
  </div>
</div>

---
Primary Category: cs.CL  
Categories: cs-CL, cs.CL  
Keyword Score: 40  
Keywords: Contrastive Learning, Mutual Information, Topic Model, Topic Modeling  
<a type="button" class="btn btn-outline-primary" href="http://arxiv.org/abs/2402.07577v1" target="_blank" >Paper Link</a>
<button type="button" class="btn btn-outline-primary download-pdf" url="https://arxiv.org/pdf/2402.07577v1.pdf" filename="2402.07577v1.pdf">Download PDF</button>

---


**ABSTRACT**  
Recent representation learning approaches enhance neural <b>topic</b> <b>models</b> by optimizing the weighted linear combination of the evidence lower bound (ELBO) of the log-likelihood and the <b>contrastive</b> <b>learning</b> objective that contrasts pairs of input documents. However, document-level <b>contrastive</b> <b>learning</b> might capture low-level <b>mutual</b> <b>information,</b> such as word ratio, which disturbs <b>topic</b> <b>modeling.</b> Moreover, there is a potential conflict between the ELBO loss that memorizes input details for better reconstruction quality, and the <b>contrastive</b> <b>loss</b> which attempts to learn <b>topic</b> <b>representations</b> that generalize among input documents. To address these issues, we first introduce a novel <b>contrastive</b> <b>learning</b> method oriented towards sets of <b>topic</b> <b>vectors</b> to capture useful semantics that are shared among a set of input documents. Secondly, we explicitly cast <b>contrastive</b> <b>topic</b> <b>modeling</b> as a gradient-based multi-objective optimization problem, with the goal of achieving a Pareto stationary solution that balances the trade-off between the ELBO and the <b>contrastive</b> <b>objective.</b> Extensive experiments demonstrate that our framework consistently produces higher-performing neural <b>topic</b> <b>models</b> in terms of <b>topic</b> <b>coherence,</b> <b>topic</b> <b>diversity,</b> and downstream performance.

{{</citation>}}


### (24/210) Quality Does Matter: A Detailed Look at the Quality and Utility of Web-Mined Parallel Corpora (Surangika Ranathunga et al., 2024)

{{<citation>}}

Surangika Ranathunga, Nisansa de Silva, Menan Velayuthan, Aloka Fernando, Charitha Rathnayake. (2024)  
**Quality Does Matter: A Detailed Look at the Quality and Utility of Web-Mined Parallel Corpora**
<br/>
<button class="copy-to-clipboard" title="Quality Does Matter: A Detailed Look at the Quality and Utility of Web-Mined Parallel Corpora" index=24>
  <span class="copy-to-clipboard-item">Copy Title<span>
</button>
<div class="toast toast-copied toast-index-24 align-items-center text-bg-secondary border-0 position-absolute top-0 end-0" role="alert" aria-live="assertive" aria-atomic="true">
  <div class="d-flex">
    <div class="toast-body">
      Copied!
    </div>
  </div>
</div>

---
Primary Category: cs.CL  
Categories: cs-CL, cs.CL  
Keyword Score: 40  
Keywords: Low-Resource, Neural Machine Translation, Neural Machine Translation, Neural Machine Translation  
<a type="button" class="btn btn-outline-primary" href="http://arxiv.org/abs/2402.07446v2" target="_blank" >Paper Link</a>
<button type="button" class="btn btn-outline-primary download-pdf" url="https://arxiv.org/pdf/2402.07446v2.pdf" filename="2402.07446v2.pdf">Download PDF</button>

---


**ABSTRACT**  
We conducted a detailed analysis on the quality of web-mined corpora for two <b>low-resource</b> languages (making three language pairs, English-Sinhala, English-Tamil and Sinhala-Tamil). We ranked each corpus according to a similarity measure and carried out an intrinsic and extrinsic evaluation on different portions of this ranked corpus. We show that there are significant quality differences between different portions of web-mined corpora and that the quality varies across languages and datasets. We also show that, for some web-mined datasets, <b>Neural</b> <b>Machine</b> <b>Translation</b> <b>(NMT)</b> models trained with their highest-ranked 25k portion can be on par with human-curated datasets.

{{</citation>}}


### (25/210) Refined Direct Preference Optimization with Synthetic Data for Behavioral Alignment of LLMs (Víctor Gallego, 2024)

{{<citation>}}

Víctor Gallego. (2024)  
**Refined Direct Preference Optimization with Synthetic Data for Behavioral Alignment of LLMs**
<br/>
<button class="copy-to-clipboard" title="Refined Direct Preference Optimization with Synthetic Data for Behavioral Alignment of LLMs" index=25>
  <span class="copy-to-clipboard-item">Copy Title<span>
</button>
<div class="toast toast-copied toast-index-25 align-items-center text-bg-secondary border-0 position-absolute top-0 end-0" role="alert" aria-live="assertive" aria-atomic="true">
  <div class="d-flex">
    <div class="toast-body">
      Copied!
    </div>
  </div>
</div>

---
Primary Category: cs.CL  
Categories: cs-CL, cs-LG, cs.CL  
Keyword Score: 30  
Keywords: Large Language Model, Large Language Model, Prompt  
<a type="button" class="btn btn-outline-primary" href="http://arxiv.org/abs/2402.08005v1" target="_blank" >Paper Link</a>
<button type="button" class="btn btn-outline-primary download-pdf" url="https://arxiv.org/pdf/2402.08005v1.pdf" filename="2402.08005v1.pdf">Download PDF</button>

---


**ABSTRACT**  
In this paper, we introduce \emph{refined Direct Preference Optimization} (rDPO), a method for improving the behavioral alignment of <b>Large</b> <b>Language</b> <b>Models</b> <b>(LLMs)</b> without the need for human-annotated data. The method involves creating synthetic data using self-critique <b>prompting</b> by a teacher <b>LLM</b> and then utilising a generalized DPO loss function to distil to a student <b>LLM.</b> The loss function incorporates an additional external reward model to improve the quality of synthetic data, making rDPO robust to potential noise in the synthetic dataset. rDPO is shown to be effective in a diverse set of behavioural alignment tasks, such as improved safety, robustness against role-playing, and reduced sycophancy. Code to be released at https://github.com/vicgalle/refined-dpo.

{{</citation>}}


### (26/210) Show Me How It's Done: The Role of Explanations in Fine-Tuning Language Models (Mohamad Ballout et al., 2024)

{{<citation>}}

Mohamad Ballout, Ulf Krumnack, Gunther Heidemann, Kai-Uwe Kuehnberger. (2024)  
**Show Me How It's Done: The Role of Explanations in Fine-Tuning Language Models**
<br/>
<button class="copy-to-clipboard" title="Show Me How It's Done: The Role of Explanations in Fine-Tuning Language Models" index=26>
  <span class="copy-to-clipboard-item">Copy Title<span>
</button>
<div class="toast toast-copied toast-index-26 align-items-center text-bg-secondary border-0 position-absolute top-0 end-0" role="alert" aria-live="assertive" aria-atomic="true">
  <div class="d-flex">
    <div class="toast-body">
      Copied!
    </div>
  </div>
</div>

---
Primary Category: cs.CL  
Categories: cs-AI, cs-CL, cs-LG, cs.CL  
Keyword Score: 30  
Keywords: Fine-tuning, Large Language Model, Prompt  
<a type="button" class="btn btn-outline-primary" href="http://arxiv.org/abs/2402.07543v1" target="_blank" >Paper Link</a>
<button type="button" class="btn btn-outline-primary download-pdf" url="https://arxiv.org/pdf/2402.07543v1.pdf" filename="2402.07543v1.pdf">Download PDF</button>

---


**ABSTRACT**  
Our research demonstrates the significant benefits of using <b>fine-tuning</b> with explanations to enhance the performance of language models. Unlike <b>prompting,</b> which maintains the model's parameters, <b>fine-tuning</b> allows the model to learn and update its parameters during a training phase. In this study, we applied <b>fine-tuning</b> to various sized language models using data that contained explanations of the output rather than merely presenting the answers. We found that even smaller language models with as few as 60 million parameters benefited substantially from this approach. Interestingly, our results indicated that the detailed explanations were more beneficial to smaller models than larger ones, with the latter gaining nearly the same advantage from any form of explanation, irrespective of its length. Additionally, we demonstrate that the inclusion of explanations enables the models to solve tasks that they were not able to solve without explanations. Lastly, we argue that despite the challenging nature of adding explanations, samples that contain explanations not only reduce the volume of data required for training but also promote a more effective generalization by the model. In essence, our findings suggest that <b>fine-tuning</b> with explanations significantly bolsters the performance of <b>large</b> <b>language</b> <b>models.</b>

{{</citation>}}


### (27/210) The Balancing Act: Unmasking and Alleviating ASR Biases in Portuguese (Ajinkya Kulkarni et al., 2024)

{{<citation>}}

Ajinkya Kulkarni, Anna Tokareva, Rameez Qureshi, Miguel Couceiro. (2024)  
**The Balancing Act: Unmasking and Alleviating ASR Biases in Portuguese**
<br/>
<button class="copy-to-clipboard" title="The Balancing Act: Unmasking and Alleviating ASR Biases in Portuguese" index=27>
  <span class="copy-to-clipboard-item">Copy Title<span>
</button>
<div class="toast toast-copied toast-index-27 align-items-center text-bg-secondary border-0 position-absolute top-0 end-0" role="alert" aria-live="assertive" aria-atomic="true">
  <div class="d-flex">
    <div class="toast-body">
      Copied!
    </div>
  </div>
</div>

---
Primary Category: cs.CL  
Categories: cs-AI, cs-CL, cs-CY, cs.CL  
Keyword Score: 30  
Keywords: Automatic Speech Recognition, Automatic Speech Recognition, Automatic Speech Recognition  
<a type="button" class="btn btn-outline-primary" href="http://arxiv.org/abs/2402.07513v1" target="_blank" >Paper Link</a>
<button type="button" class="btn btn-outline-primary download-pdf" url="https://arxiv.org/pdf/2402.07513v1.pdf" filename="2402.07513v1.pdf">Download PDF</button>

---


**ABSTRACT**  
In the field of spoken language understanding, systems like Whisper and Multilingual Massive <b>Speech</b> <b>(MMS)</b> have shown state-of-the-art performances. This study is dedicated to a comprehensive exploration of the Whisper and MMS systems, with a focus on assessing biases in <b>automatic</b> <b>speech</b> <b>recognition</b> <b>(ASR)</b> inherent to casual conversation <b>speech</b> <b>specific</b> to the Portuguese language. Our investigation encompasses various categories, including gender, age, skin tone color, and geo-location. Alongside traditional <b>ASR</b> evaluation metrics such as Word Error Rate (WER), we have incorporated p-value statistical significance for gender bias analysis. Furthermore, we extensively examine the impact of data distribution and empirically show that oversampling techniques alleviate such stereotypical biases. This research represents a pioneering effort in quantifying biases in the Portuguese language context through the application of MMS and Whisper, contributing to a better understanding of <b>ASR</b> systems' performance in multilingual settings.

{{</citation>}}


### (28/210) Asking Multimodal Clarifying Questions in Mixed-Initiative Conversational Search (Yifei Yuan et al., 2024)

{{<citation>}}

Yifei Yuan, Clemencia Siro, Mohammad Aliannejadi, Maarten de Rijke, Wai Lam. (2024)  
**Asking Multimodal Clarifying Questions in Mixed-Initiative Conversational Search**
<br/>
<button class="copy-to-clipboard" title="Asking Multimodal Clarifying Questions in Mixed-Initiative Conversational Search" index=28>
  <span class="copy-to-clipboard-item">Copy Title<span>
</button>
<div class="toast toast-copied toast-index-28 align-items-center text-bg-secondary border-0 position-absolute top-0 end-0" role="alert" aria-live="assertive" aria-atomic="true">
  <div class="d-flex">
    <div class="toast-body">
      Copied!
    </div>
  </div>
</div>

---
Primary Category: cs.CL  
Categories: cs-CL, cs-CV, cs.CL  
Keyword Score: 26  
Keywords: Fine-tuning, Multi-modal, Multi-modal, Prompt  
<a type="button" class="btn btn-outline-primary" href="http://arxiv.org/abs/2402.07742v1" target="_blank" >Paper Link</a>
<button type="button" class="btn btn-outline-primary download-pdf" url="https://arxiv.org/pdf/2402.07742v1.pdf" filename="2402.07742v1.pdf">Download PDF</button>

---


**ABSTRACT**  
In mixed-initiative conversational search systems, clarifying questions are used to help users who struggle to express their intentions in a single query. These questions aim to uncover user's information needs and resolve query ambiguities. We hypothesize that in scenarios where <b>multimodal</b> information is pertinent, the clarification process can be improved by using non-textual information. Therefore, we propose to add images to clarifying questions and formulate the novel task of asking <b>multimodal</b> clarifying questions in open-domain, mixed-initiative conversational search systems. To facilitate research into this task, we collect a dataset named Melon that contains over 4k <b>multimodal</b> clarifying questions, enriched with over 14k images. We also propose a <b>multimodal</b> query clarification model named Marto and adopt a <b>prompt-based,</b> generative <b>fine-tuning</b> strategy to perform the training of different stages with different <b>prompts.</b> Several analyses are conducted to understand the importance of <b>multimodal</b> contents during the query clarification phase. Experimental results indicate that the addition of images leads to significant improvements of up to 90% in retrieval performance when selecting the relevant images. Extensive analyses are also performed to show the superiority of Marto compared with discriminative baselines in terms of effectiveness and efficiency.

{{</citation>}}


### (29/210) Do Membership Inference Attacks Work on Large Language Models? (Michael Duan et al., 2024)

{{<citation>}}

Michael Duan, Anshuman Suri, Niloofar Mireshghallah, Sewon Min, Weijia Shi, Luke Zettlemoyer, Yulia Tsvetkov, Yejin Choi, David Evans, Hannaneh Hajishirzi. (2024)  
**Do Membership Inference Attacks Work on Large Language Models?**
<br/>
<button class="copy-to-clipboard" title="Do Membership Inference Attacks Work on Large Language Models?" index=29>
  <span class="copy-to-clipboard-item">Copy Title<span>
</button>
<div class="toast toast-copied toast-index-29 align-items-center text-bg-secondary border-0 position-absolute top-0 end-0" role="alert" aria-live="assertive" aria-atomic="true">
  <div class="d-flex">
    <div class="toast-body">
      Copied!
    </div>
  </div>
</div>

---
Primary Category: cs.CL  
Categories: cs-CL, cs.CL  
Keyword Score: 20  
Keywords: Large Language Model, Large Language Model  
<a type="button" class="btn btn-outline-primary" href="http://arxiv.org/abs/2402.07841v1" target="_blank" >Paper Link</a>
<button type="button" class="btn btn-outline-primary download-pdf" url="https://arxiv.org/pdf/2402.07841v1.pdf" filename="2402.07841v1.pdf">Download PDF</button>

---


**ABSTRACT**  
Membership inference attacks (MIAs) attempt to predict whether a particular datapoint is a member of a target model's training data. Despite extensive research on traditional machine learning models, there has been limited work studying MIA on the pre-training data of <b>large</b> <b>language</b> <b>models</b> <b>(LLMs).</b> We perform a <b>large-scale</b> <b>evaluation</b> <b>of</b> MIAs over a suite of language models (LMs) trained on the Pile, ranging from 160M to 12B parameters. We find that MIAs barely outperform random guessing for most settings across varying <b>LLM</b> sizes and domains. Our further analyses reveal that this poor performance can be attributed to (1) the combination of a <b>large</b> <b>dataset</b> <b>and</b> few training iterations, and (2) an inherently fuzzy boundary between members and non-members. We identify specific settings where <b>LLMs</b> have been shown to be vulnerable to membership inference and show that the apparent success in such settings can be attributed to a distribution shift, such as when members and non-members are drawn from the seemingly identical domain but with different temporal ranges. We release our code and data as a unified benchmark package that includes all existing MIAs, supporting future work.

{{</citation>}}


### (30/210) Multi-Intent Attribute-Aware Text Matching in Searching (Mingzhe Li et al., 2024)

{{<citation>}}

Mingzhe Li, Xiuying Chen, Jing Xiang, Qishen Zhang, Changsheng Ma, Chenchen Dai, Jinxiong Chang, Zhongyi Liu, Guannan Zhang. (2024)  
**Multi-Intent Attribute-Aware Text Matching in Searching**
<br/>
<button class="copy-to-clipboard" title="Multi-Intent Attribute-Aware Text Matching in Searching" index=30>
  <span class="copy-to-clipboard-item">Copy Title<span>
</button>
<div class="toast toast-copied toast-index-30 align-items-center text-bg-secondary border-0 position-absolute top-0 end-0" role="alert" aria-live="assertive" aria-atomic="true">
  <div class="d-flex">
    <div class="toast-body">
      Copied!
    </div>
  </div>
</div>

---
Primary Category: cs.CL  
Categories: cs-CL, cs.CL  
Keyword Score: 20  
Keywords: Self-supervised Learning, Summarization  
<a type="button" class="btn btn-outline-primary" href="http://arxiv.org/abs/2402.07788v1" target="_blank" >Paper Link</a>
<button type="button" class="btn btn-outline-primary download-pdf" url="https://arxiv.org/pdf/2402.07788v1.pdf" filename="2402.07788v1.pdf">Download PDF</button>

---


**ABSTRACT**  
Text matching systems have become a fundamental service in most searching platforms. For instance, they are responsible for matching user queries to relevant candidate items, or rewriting the user-input query to a pre-selected high-performing one for a better search experience. In practice, both the queries and items often contain multiple attributes, such as the category of the item and the location mentioned in the query, which represent condensed key information that is helpful for matching. However, most of the existing works downplay the effectiveness of attributes by integrating them into text representations as supplementary information. Hence, in this work, we focus on exploring the relationship between the attributes from two sides. Since attributes from two ends are often not aligned in terms of number and type, we propose to exploit the benefit of attributes by multiple-intent modeling. The intents extracted from attributes <b>summarize</b> the diverse needs of queries and provide rich content of items, which are more refined and abstract, and can be aligned for paired inputs. Concretely, we propose a multi-intent attribute-aware matching model (MIM), which consists of three main components: attribute-aware encoder, multi-intent modeling, and intent-aware matching. In the attribute-aware encoder, the text and attributes are weighted and processed through a scaled attention mechanism with regard to the attributes' importance. Afterward, the multi-intent modeling extracts intents from two ends and aligns them. Herein, we come up with a distribution loss to ensure the learned intents are diverse but concentrated, and a kullback-leibler divergence loss that aligns the learned intents. Finally, in the intent-aware matching, the intents are evaluated by a <b>self-supervised</b> masking task, and then incorporated to output the final matching result.

{{</citation>}}


### (31/210) Text Detoxification as Style Transfer in English and Hindi (Sourabrata Mukherjee et al., 2024)

{{<citation>}}

Sourabrata Mukherjee, Akanksha Bansal, Atul Kr. Ojha, John P. McCrae, Ondřej Dušek. (2024)  
**Text Detoxification as Style Transfer in English and Hindi**
<br/>
<button class="copy-to-clipboard" title="Text Detoxification as Style Transfer in English and Hindi" index=31>
  <span class="copy-to-clipboard-item">Copy Title<span>
</button>
<div class="toast toast-copied toast-index-31 align-items-center text-bg-secondary border-0 position-absolute top-0 end-0" role="alert" aria-live="assertive" aria-atomic="true">
  <div class="d-flex">
    <div class="toast-body">
      Copied!
    </div>
  </div>
</div>

---
Primary Category: cs.CL  
Categories: cs-CL, cs.CL  
Keyword Score: 20  
Keywords: Knowledge Transfer, Style Transfer  
<a type="button" class="btn btn-outline-primary" href="http://arxiv.org/abs/2402.07767v1" target="_blank" >Paper Link</a>
<button type="button" class="btn btn-outline-primary download-pdf" url="https://arxiv.org/pdf/2402.07767v1.pdf" filename="2402.07767v1.pdf">Download PDF</button>

---


**ABSTRACT**  
This paper focuses on text detoxification, i.e., automatically converting toxic text into non-toxic text. This task contributes to safer and more respectful online communication and can be considered a Text <b>Style</b> <b>Transfer</b> (TST) task, where the text <b>style</b> <b>changes</b> while its content is preserved. We present three approaches: <b>knowledge</b> <b>transfer</b> from a similar task, multi-task learning approach, combining sequence-to-sequence modeling with various toxicity classification tasks, and, delete and reconstruct approach. To support our research, we utilize a dataset provided by Dementieva et al.(2021), which contains multiple versions of detoxified texts corresponding to toxic texts. In our experiments, we selected the best variants through expert human annotators, creating a dataset where each toxic sentence is paired with a single, appropriate detoxified version. Additionally, we introduced a small Hindi parallel dataset, aligning with a part of the English dataset, suitable for evaluation purposes. Our results demonstrate that our approach effectively balances text detoxication while preserving the actual content and maintaining fluency.

{{</citation>}}


### (32/210) Auxiliary Tasks to Boost Biaffine Semantic Dependency Parsing (Marie Candito, 2024)

{{<citation>}}

Marie Candito. (2024)  
**Auxiliary Tasks to Boost Biaffine Semantic Dependency Parsing**
<br/>
<button class="copy-to-clipboard" title="Auxiliary Tasks to Boost Biaffine Semantic Dependency Parsing" index=32>
  <span class="copy-to-clipboard-item">Copy Title<span>
</button>
<div class="toast toast-copied toast-index-32 align-items-center text-bg-secondary border-0 position-absolute top-0 end-0" role="alert" aria-live="assertive" aria-atomic="true">
  <div class="d-flex">
    <div class="toast-body">
      Copied!
    </div>
  </div>
</div>

---
Primary Category: cs.CL  
Categories: cs-CL, cs.CL  
Keyword Score: 20  
Keywords: Transformer, Dependency Parsing  
<a type="button" class="btn btn-outline-primary" href="http://arxiv.org/abs/2402.07682v1" target="_blank" >Paper Link</a>
<button type="button" class="btn btn-outline-primary download-pdf" url="https://arxiv.org/pdf/2402.07682v1.pdf" filename="2402.07682v1.pdf">Download PDF</button>

---


**ABSTRACT**  
The biaffine parser of Dozat and Manning (2017) was successfully extended to semantic <b>dependency</b> <b>parsing</b> (SDP) (Dozat and Manning, 2018). Its performance on graphs is surprisingly high given that, without the constraint of producing a tree, all arcs for a given sentence are predicted independently from each other (modulo a shared representation of tokens). To circumvent such an independence of decision, while retaining the O(n^2) complexity and highly parallelizable architecture, we propose to use simple auxiliary tasks that introduce some form of interdependence between arcs. Experiments on the three English acyclic datasets of SemEval 2015 task 18 (Oepen et al., 2015), and on French deep syntactic cyclic graphs (Ribeyre et al., 2014) show modest but systematic performance gains on a near state-of-the-art baseline using <b>transformer-based</b> contextualized representations. This provides a simple and robust method to boost SDP performance.

{{</citation>}}


### (33/210) Intrinsic Task-based Evaluation for Referring Expression Generation (Guanyi Chen et al., 2024)

{{<citation>}}

Guanyi Chen, Fahime Same, Kees van Deemter. (2024)  
**Intrinsic Task-based Evaluation for Referring Expression Generation**
<br/>
<button class="copy-to-clipboard" title="Intrinsic Task-based Evaluation for Referring Expression Generation" index=33>
  <span class="copy-to-clipboard-item">Copy Title<span>
</button>
<div class="toast toast-copied toast-index-33 align-items-center text-bg-secondary border-0 position-absolute top-0 end-0" role="alert" aria-live="assertive" aria-atomic="true">
  <div class="d-flex">
    <div class="toast-body">
      Copied!
    </div>
  </div>
</div>

---
Primary Category: cs.CL  
Categories: cs-CL, cs.CL  
Keyword Score: 20  
Keywords: Language Generation, Natural Language Generation  
<a type="button" class="btn btn-outline-primary" href="http://arxiv.org/abs/2402.07432v1" target="_blank" >Paper Link</a>
<button type="button" class="btn btn-outline-primary download-pdf" url="https://arxiv.org/pdf/2402.07432v1.pdf" filename="2402.07432v1.pdf">Download PDF</button>

---


**ABSTRACT**  
Recently, a human evaluation study of Referring Expression Generation (REG) models had an unexpected conclusion: on \textsc{webnlg}, Referring Expressions (REs) generated by the state-of-the-art neural models were not only indistinguishable from the REs in \textsc{webnlg} but also from the REs generated by a simple rule-based system. Here, we argue that this limitation could stem from the use of a purely ratings-based human evaluation (which is a common practice in <b>Natural</b> <b>Language</b> <b>Generation).</b> To investigate these issues, we propose an intrinsic task-based evaluation for REG models, in which, in addition to rating the quality of REs, participants were asked to accomplish two meta-level tasks. One of these tasks concerns the referential success of each RE; the other task asks participants to suggest a better alternative for each RE. The outcomes suggest that, in comparison to previous evaluations, the new evaluation protocol assesses the performance of each REG model more comprehensively and makes the participants' ratings more reliable and discriminable.

{{</citation>}}


### (34/210) SALAD: Smart AI Language Assistant Daily (Ragib Amin Nihal et al., 2024)

{{<citation>}}

Ragib Amin Nihal, Tran Dong Huu Quoc, Lin Zirui, Xu Yimimg, Liu Haoran, An Zhaoyi, Kyou Ma. (2024)  
**SALAD: Smart AI Language Assistant Daily**
<br/>
<button class="copy-to-clipboard" title="SALAD: Smart AI Language Assistant Daily" index=34>
  <span class="copy-to-clipboard-item">Copy Title<span>
</button>
<div class="toast toast-copied toast-index-34 align-items-center text-bg-secondary border-0 position-absolute top-0 end-0" role="alert" aria-live="assertive" aria-atomic="true">
  <div class="d-flex">
    <div class="toast-body">
      Copied!
    </div>
  </div>
</div>

---
Primary Category: cs.CL  
Categories: cs-CL, cs-CY, cs.CL  
Keyword Score: 20  
Keywords: Automatic Speech Recognition, Large Language Model  
<a type="button" class="btn btn-outline-primary" href="http://arxiv.org/abs/2402.07431v2" target="_blank" >Paper Link</a>
<button type="button" class="btn btn-outline-primary download-pdf" url="https://arxiv.org/pdf/2402.07431v2.pdf" filename="2402.07431v2.pdf">Download PDF</button>

---


**ABSTRACT**  
SALAD is an AI-driven language-learning application designed to help foreigners learn Japanese. It offers translations in Kanji-Kana-Romaji, <b>speech</b> <b>recognition,</b> translated audio, vocabulary tracking, grammar explanations, and songs generated from newly learned words. The app targets beginners and intermediate learners, aiming to make language acquisition more accessible and enjoyable. SALAD uses daily translations to enhance fluency and comfort in communication with native speakers. The primary objectives include effective Japanese language learning, user engagement, and progress tracking. A survey by us found that 39% of foreigners in Japan face discomfort in conversations with Japanese speakers. Over 60% of foreigners expressed confidence in SALAD's ability to enhance their Japanese language skills. The app uses <b>large</b> <b>language</b> <b>models,</b> <b>speech</b> <b>recognition,</b> and diffusion models to bridge the language gap and foster a more inclusive community in Japan.

{{</citation>}}


### (35/210) Label-Efficient Model Selection for Text Generation (Shir Ashury-Tahan et al., 2024)

{{<citation>}}

Shir Ashury-Tahan, Benjamin Sznajder, Leshem Choshen, Liat Ein-Dor, Eyal Shnarch, Ariel Gera. (2024)  
**Label-Efficient Model Selection for Text Generation**
<br/>
<button class="copy-to-clipboard" title="Label-Efficient Model Selection for Text Generation" index=35>
  <span class="copy-to-clipboard-item">Copy Title<span>
</button>
<div class="toast toast-copied toast-index-35 align-items-center text-bg-secondary border-0 position-absolute top-0 end-0" role="alert" aria-live="assertive" aria-atomic="true">
  <div class="d-flex">
    <div class="toast-body">
      Copied!
    </div>
  </div>
</div>

---
Primary Category: cs.CL  
Categories: cs-CL, cs-LG, cs.CL  
Keyword Score: 10  
Keywords: Text Generation  
<a type="button" class="btn btn-outline-primary" href="http://arxiv.org/abs/2402.07891v1" target="_blank" >Paper Link</a>
<button type="button" class="btn btn-outline-primary download-pdf" url="https://arxiv.org/pdf/2402.07891v1.pdf" filename="2402.07891v1.pdf">Download PDF</button>

---


**ABSTRACT**  
Model selection for a given target task can be costly, as it may entail extensive annotation of the quality of outputs of different models. We introduce DiffUse, an efficient method to make an informed decision between candidate <b>text</b> <b>generation</b> models. DiffUse reduces the required amount of preference annotations, thus saving valuable time and resources in performing evaluation. DiffUse intelligently selects instances by clustering embeddings that represent the semantic differences between model outputs. Thus, it is able to identify a subset of examples that are more informative for preference decisions. Our method is model-agnostic, and can be applied to any <b>text</b> <b>generation</b> model. Moreover, we propose a practical iterative approach for dynamically determining how many instances to annotate. In a series of experiments over hundreds of model pairs, we demonstrate that DiffUse can dramatically reduce the required number of annotations -- by up to 75% -- while maintaining high evaluation reliability.

{{</citation>}}


### (36/210) Diffusion of Thoughts: Chain-of-Thought Reasoning in Diffusion Language Models (Jiacheng Ye et al., 2024)

{{<citation>}}

Jiacheng Ye, Shansan Gong, Liheng Chen, Lin Zheng, Jiahui Gao, Han Shi, Chuan Wu, Zhenguo Li, Wei Bi, Lingpeng Kong. (2024)  
**Diffusion of Thoughts: Chain-of-Thought Reasoning in Diffusion Language Models**
<br/>
<button class="copy-to-clipboard" title="Diffusion of Thoughts: Chain-of-Thought Reasoning in Diffusion Language Models" index=36>
  <span class="copy-to-clipboard-item">Copy Title<span>
</button>
<div class="toast toast-copied toast-index-36 align-items-center text-bg-secondary border-0 position-absolute top-0 end-0" role="alert" aria-live="assertive" aria-atomic="true">
  <div class="d-flex">
    <div class="toast-body">
      Copied!
    </div>
  </div>
</div>

---
Primary Category: cs.CL  
Categories: cs-AI, cs-CL, cs-LG, cs.CL  
Keyword Score: 10  
Keywords: Reasoning  
<a type="button" class="btn btn-outline-primary" href="http://arxiv.org/abs/2402.07754v1" target="_blank" >Paper Link</a>
<button type="button" class="btn btn-outline-primary download-pdf" url="https://arxiv.org/pdf/2402.07754v1.pdf" filename="2402.07754v1.pdf">Download PDF</button>

---


**ABSTRACT**  
Diffusion models have gained attention in text processing, offering many potential advantages over traditional autoregressive models. This work explores the integration of diffusion models and Chain-of-Thought (CoT), a well-established technique to improve the <b>reasoning</b> ability in autoregressive language models. We propose Diffusion-of-Thought (DoT), allowing <b>reasoning</b> steps to diffuse over time through the diffusion process. In contrast to traditional autoregressive language models that make decisions in a left-to-right, token-by-token manner, DoT offers more flexibility in the trade-off between computation and <b>reasoning</b> performance. Our experimental results demonstrate the effectiveness of DoT in multi-digit multiplication and grade school math problems. Additionally, DoT showcases promising self-correction abilities and benefits from existing <b>reasoning-enhancing</b> techniques like self-consistency decoding. Our findings contribute to the understanding and development of <b>reasoning</b> capabilities in diffusion language models.

{{</citation>}}


### (37/210) OrderBkd: Textual backdoor attack through repositioning (Irina Alekseevskaia et al., 2024)

{{<citation>}}

Irina Alekseevskaia, Konstantin Arkhipenko. (2024)  
**OrderBkd: Textual backdoor attack through repositioning**
<br/>
<button class="copy-to-clipboard" title="OrderBkd: Textual backdoor attack through repositioning" index=37>
  <span class="copy-to-clipboard-item">Copy Title<span>
</button>
<div class="toast toast-copied toast-index-37 align-items-center text-bg-secondary border-0 position-absolute top-0 end-0" role="alert" aria-live="assertive" aria-atomic="true">
  <div class="d-flex">
    <div class="toast-body">
      Copied!
    </div>
  </div>
</div>

---
Primary Category: cs.CL  
Categories: cs-AI, cs-CL, cs.CL  
Keyword Score: 10  
Keywords: Perplexity  
<a type="button" class="btn btn-outline-primary" href="http://arxiv.org/abs/2402.07689v1" target="_blank" >Paper Link</a>
<button type="button" class="btn btn-outline-primary download-pdf" url="https://arxiv.org/pdf/2402.07689v1.pdf" filename="2402.07689v1.pdf">Download PDF</button>

---


**ABSTRACT**  
The use of third-party datasets and pre-trained machine learning models poses a threat to NLP systems due to possibility of hidden backdoor attacks. Existing attacks involve poisoning the data samples such as insertion of tokens or sentence paraphrasing, which either alter the semantics of the original texts or can be detected. Our main difference from the previous work is that we use the reposition of a two words in a sentence as a trigger. By designing and applying specific part-of-speech (POS) based rules for selecting these tokens, we maintain high attack success rate on SST-2 and AG classification datasets while outperforming existing attacks in terms of <b>perplexity</b> and semantic similarity to the clean samples. In addition, we show the robustness of our attack to the ONION defense method. All the code and data for the paper can be obtained at https://github.com/alekseevskaia/OrderBkd.

{{</citation>}}


### (38/210) AraSpider: Democratizing Arabic-to-SQL (Ahmed Heakl et al., 2024)

{{<citation>}}

Ahmed Heakl, Youssef Mohamed, Ahmed B. Zaky. (2024)  
**AraSpider: Democratizing Arabic-to-SQL**
<br/>
<button class="copy-to-clipboard" title="AraSpider: Democratizing Arabic-to-SQL" index=38>
  <span class="copy-to-clipboard-item">Copy Title<span>
</button>
<div class="toast toast-copied toast-index-38 align-items-center text-bg-secondary border-0 position-absolute top-0 end-0" role="alert" aria-live="assertive" aria-atomic="true">
  <div class="d-flex">
    <div class="toast-body">
      Copied!
    </div>
  </div>
</div>

---
Primary Category: cs.CL  
Categories: cs-AI, cs-CL, cs-DB, cs-IR, cs-LG, cs.CL  
Keyword Score: 10  
Keywords: ChatGPT  
<a type="button" class="btn btn-outline-primary" href="http://arxiv.org/abs/2402.07448v1" target="_blank" >Paper Link</a>
<button type="button" class="btn btn-outline-primary download-pdf" url="https://arxiv.org/pdf/2402.07448v1.pdf" filename="2402.07448v1.pdf">Download PDF</button>

---


**ABSTRACT**  
This study presents AraSpider, the first Arabic version of the Spider dataset, aimed at improving natural language processing (NLP) in the Arabic-speaking community. Four multilingual translation models were tested for their effectiveness in translating English to Arabic. Additionally, two models were assessed for their ability to generate SQL queries from Arabic text. The results showed that using back translation significantly improved the performance of both <b>ChatGPT</b> 3.5 and SQLCoder models, which are considered top performers on the Spider dataset. Notably, <b>ChatGPT</b> 3.5 demonstrated high-quality translation, while SQLCoder excelled in text-to-SQL tasks. The study underscores the importance of incorporating contextual schema and employing back translation strategies to enhance model performance in Arabic NLP tasks. Moreover, the provision of detailed methodologies for reproducibility and translation of the dataset into other languages highlights the research's commitment to promoting transparency and collaborative knowledge sharing in the field. Overall, these contributions advance NLP research, empower Arabic-speaking researchers, and enrich the global discourse on language comprehension and database interrogation.

{{</citation>}}


## cs.RO (7)



### (39/210) PIVOT: Iterative Visual Prompting Elicits Actionable Knowledge for VLMs (Soroush Nasiriany et al., 2024)

{{<citation>}}

Soroush Nasiriany, Fei Xia, Wenhao Yu, Ted Xiao, Jacky Liang, Ishita Dasgupta, Annie Xie, Danny Driess, Ayzaan Wahid, Zhuo Xu, Quan Vuong, Tingnan Zhang, Tsang-Wei Edward Lee, Kuang-Huei Lee, Peng Xu, Sean Kirmani, Yuke Zhu, Andy Zeng, Karol Hausman, Nicolas Heess, Chelsea Finn, Sergey Levine, Brian Ichter. (2024)  
**PIVOT: Iterative Visual Prompting Elicits Actionable Knowledge for VLMs**
<br/>
<button class="copy-to-clipboard" title="PIVOT: Iterative Visual Prompting Elicits Actionable Knowledge for VLMs" index=39>
  <span class="copy-to-clipboard-item">Copy Title<span>
</button>
<div class="toast toast-copied toast-index-39 align-items-center text-bg-secondary border-0 position-absolute top-0 end-0" role="alert" aria-live="assertive" aria-atomic="true">
  <div class="d-flex">
    <div class="toast-body">
      Copied!
    </div>
  </div>
</div>

---
Primary Category: cs.RO  
Categories: cs-CL, cs-CV, cs-LG, cs-RO, cs.RO  
Keyword Score: 100  
Keywords: Fine-tuning, Simulation, Simulator, Zero-shot, Instruction Following, Question Answering, Reasoning, Visual Question Answering, Prompt, Vision-and-Language  
<a type="button" class="btn btn-outline-primary" href="http://arxiv.org/abs/2402.07872v1" target="_blank" >Paper Link</a>
<button type="button" class="btn btn-outline-primary download-pdf" url="https://arxiv.org/pdf/2402.07872v1.pdf" filename="2402.07872v1.pdf">Download PDF</button>

---


**ABSTRACT**  
Vision language models (VLMs) have shown impressive capabilities across a variety of tasks, from logical <b>reasoning</b> to <b>visual</b> <b>understanding.</b> <b>This</b> opens the door to richer interaction with the world, for example robotic control. However, VLMs produce only textual outputs, while robotic control and other spatial tasks require outputting continuous coordinates, actions, or trajectories. How can we enable VLMs to handle such settings without <b>fine-tuning</b> on task-specific data? In this paper, we propose a novel <b>visual</b> <b>prompting</b> <b>approach</b> for VLMs that we call <b>Prompting</b> with Iterative <b>Visual</b> <b>Optimization</b> <b>(PIVOT),</b> which casts tasks as iterative <b>visual</b> <b>question</b> <b>answering.</b> In each iteration, the image is annotated with a <b>visual</b> <b>representation</b> <b>of</b> proposals that the VLM can refer to (e.g., candidate robot actions, localizations, or trajectories). The VLM then selects the best ones for the task. These proposals are iteratively refined, allowing the VLM to eventually zero in on the best available answer. We investigate PIVOT on real-world robotic navigation, real-world manipulation from images, <b>instruction</b> <b>following</b> in <b>simulation,</b> and additional spatial inference tasks such as localization. We find, perhaps surprisingly, that our approach enables <b>zero-shot</b> control of robotic systems without any robot training data, navigation in a variety of environments, and other capabilities. Although current performance is far from perfect, our work highlights potentials and limitations of this new regime and shows a promising approach for Internet-Scale VLMs in robotic and spatial <b>reasoning</b> domains. Website: pivot-prompt.github.io and HuggingFace: https://huggingface.co/spaces/pivot-prompt/pivot-prompt-demo.

{{</citation>}}


### (40/210) Customizable Perturbation Synthesis for Robust SLAM Benchmarking (Xiaohao Xu et al., 2024)

{{<citation>}}

Xiaohao Xu, Tianyi Zhang, Sibo Wang, Xiang Li, Yongqi Chen, Ye Li, Bhiksha Raj, Matthew Johnson-Roberson, Xiaonan Huang. (2024)  
**Customizable Perturbation Synthesis for Robust SLAM Benchmarking**
<br/>
<button class="copy-to-clipboard" title="Customizable Perturbation Synthesis for Robust SLAM Benchmarking" index=40>
  <span class="copy-to-clipboard-item">Copy Title<span>
</button>
<div class="toast toast-copied toast-index-40 align-items-center text-bg-secondary border-0 position-absolute top-0 end-0" role="alert" aria-live="assertive" aria-atomic="true">
  <div class="d-flex">
    <div class="toast-body">
      Copied!
    </div>
  </div>
</div>

---
Primary Category: cs.RO  
Categories: cs-AI, cs-CV, cs-MM, cs-RO, cs.RO  
Keyword Score: 23  
Keywords: Multi-modal, Simulation, Simulator  
<a type="button" class="btn btn-outline-primary" href="http://arxiv.org/abs/2402.08125v1" target="_blank" >Paper Link</a>
<button type="button" class="btn btn-outline-primary download-pdf" url="https://arxiv.org/pdf/2402.08125v1.pdf" filename="2402.08125v1.pdf">Download PDF</button>

---


**ABSTRACT**  
Robustness is a crucial factor for the successful deployment of robots in unstructured environments, particularly in the domain of Simultaneous Localization and Mapping (SLAM). <b>Simulation-based</b> benchmarks have emerged as a highly scalable approach for robustness evaluation compared to real-world data collection. However, crafting a challenging and controllable noisy world with diverse perturbations remains relatively under-explored. To this end, we propose a novel, customizable pipeline for noisy data synthesis, aimed at assessing the resilience of <b>multi-modal</b> SLAM models against various perturbations. This pipeline incorporates customizable hardware setups, software components, and perturbed environments. In particular, we introduce comprehensive perturbation taxonomy along with a perturbation composition toolbox, allowing the transformation of clean <b>simulations</b> into challenging noisy environments. Utilizing the pipeline, we instantiate the Robust-SLAM benchmark, which includes diverse perturbation types, to evaluate the risk tolerance of existing advanced <b>multi-modal</b> SLAM models. Our extensive analysis uncovers the susceptibilities of existing SLAM models to real-world disturbance, despite their demonstrated accuracy in standard benchmarks. Our perturbation synthesis toolbox, SLAM robustness evaluation pipeline, and Robust-SLAM benchmark will be made publicly available at https://github.com/Xiaohao-Xu/SLAM-under-Perturbation/.

{{</citation>}}


### (41/210) DeformNet: Latent Space Modeling and Dynamics Prediction for Deformable Object Manipulation (Chenchang Li et al., 2024)

{{<citation>}}

Chenchang Li, Zihao Ai, Tong Wu, Xiaosa Li, Wenbo Ding, Huazhe Xu. (2024)  
**DeformNet: Latent Space Modeling and Dynamics Prediction for Deformable Object Manipulation**
<br/>
<button class="copy-to-clipboard" title="DeformNet: Latent Space Modeling and Dynamics Prediction for Deformable Object Manipulation" index=41>
  <span class="copy-to-clipboard-item">Copy Title<span>
</button>
<div class="toast toast-copied toast-index-41 align-items-center text-bg-secondary border-0 position-absolute top-0 end-0" role="alert" aria-live="assertive" aria-atomic="true">
  <div class="d-flex">
    <div class="toast-body">
      Copied!
    </div>
  </div>
</div>

---
Primary Category: cs.RO  
Categories: cs-RO, cs.RO  
Keyword Score: 20  
Keywords: Simulation, Simulator  
<a type="button" class="btn btn-outline-primary" href="http://arxiv.org/abs/2402.07648v1" target="_blank" >Paper Link</a>
<button type="button" class="btn btn-outline-primary download-pdf" url="https://arxiv.org/pdf/2402.07648v1.pdf" filename="2402.07648v1.pdf">Download PDF</button>

---


**ABSTRACT**  
Manipulating deformable objects is a ubiquitous task in household environments, demanding adequate representation and accurate dynamics prediction due to the objects' infinite degrees of freedom. This work proposes DeformNet, which utilizes latent space modeling with a learned 3D representation model to tackle these challenges effectively. The proposed representation model combines a PointNet encoder and a conditional neural radiance field (NeRF), facilitating a thorough acquisition of object deformations and variations in lighting conditions. To model the complex dynamics, we employ a recurrent state-space model (RSSM) that accurately predicts the transformation of the latent representation over time. Extensive <b>simulation</b> experiments with diverse objectives demonstrate the generalization capabilities of DeformNet for various deformable object manipulation tasks, even in the presence of previously unseen goals. Finally, we deploy DeformNet on an actual UR5 robotic arm to demonstrate its capability in real-world scenarios.

{{</citation>}}


### (42/210) DART: A Compact Platform For Autonomous Driving Research (Lorenzo Lyons et al., 2024)

{{<citation>}}

Lorenzo Lyons, Thijs Niesten, Laura Ferranti. (2024)  
**DART: A Compact Platform For Autonomous Driving Research**
<br/>
<button class="copy-to-clipboard" title="DART: A Compact Platform For Autonomous Driving Research" index=42>
  <span class="copy-to-clipboard-item">Copy Title<span>
</button>
<div class="toast toast-copied toast-index-42 align-items-center text-bg-secondary border-0 position-absolute top-0 end-0" role="alert" aria-live="assertive" aria-atomic="true">
  <div class="d-flex">
    <div class="toast-body">
      Copied!
    </div>
  </div>
</div>

---
Primary Category: cs.RO  
Categories: cs-RO, cs.RO  
Keyword Score: 20  
Keywords: Simulation, Simulator  
<a type="button" class="btn btn-outline-primary" href="http://arxiv.org/abs/2402.07602v1" target="_blank" >Paper Link</a>
<button type="button" class="btn btn-outline-primary download-pdf" url="https://arxiv.org/pdf/2402.07602v1.pdf" filename="2402.07602v1.pdf">Download PDF</button>

---


**ABSTRACT**  
This paper presents the design of a research platform for autonomous driving applications, the Delft's Autonomous-driving Robotic Testbed (DART). Our goal was to design a small-scale car-like robot equipped with all the hardware needed for on-board navigation and control while keeping it cost-effective and easy to replicate. To develop DART, we built on an existing off-the-shelf model and augmented its sensor suite to improve its capabilities for control and motion planning tasks. We detail the hardware setup and the system identification challenges to derive the vehicle's models. Furthermore, we present some use cases where we used DART to test different motion planning applications to show the versatility of the platform. Finally, we provide a git repository with all the details to replicate DART, complete with a <b>simulation</b> environment and the data used for system identification.

{{</citation>}}


### (43/210) Digital Twins Below the Surface: Enhancing Underwater Teleoperation (Favour O. Adetunji et al., 2024)

{{<citation>}}

Favour O. Adetunji, Niamh Ellis, Maria Koskinopoulou, Ignacio Carlucho, Yvan R. Petillot. (2024)  
**Digital Twins Below the Surface: Enhancing Underwater Teleoperation**
<br/>
<button class="copy-to-clipboard" title="Digital Twins Below the Surface: Enhancing Underwater Teleoperation" index=43>
  <span class="copy-to-clipboard-item">Copy Title<span>
</button>
<div class="toast toast-copied toast-index-43 align-items-center text-bg-secondary border-0 position-absolute top-0 end-0" role="alert" aria-live="assertive" aria-atomic="true">
  <div class="d-flex">
    <div class="toast-body">
      Copied!
    </div>
  </div>
</div>

---
Primary Category: cs.RO  
Categories: cs-RO, cs.RO  
Keyword Score: 20  
Keywords: Simulation, Simulator  
<a type="button" class="btn btn-outline-primary" href="http://arxiv.org/abs/2402.07556v1" target="_blank" >Paper Link</a>
<button type="button" class="btn btn-outline-primary download-pdf" url="https://arxiv.org/pdf/2402.07556v1.pdf" filename="2402.07556v1.pdf">Download PDF</button>

---


**ABSTRACT**  
Subsea exploration, inspection, and intervention operations heavily rely on remotely operated vehicles (ROVs). However, the inherent complexity of the underwater environment presents significant challenges to the operators of these vehicles. This paper delves into the challenges associated with navigation and maneuvering tasks in the teleoperation of ROVs, such as reduced situational awareness and heightened teleoperator workload. To address these challenges, we introduce an underwater Digital Twin (DT) system designed to enhance underwater teleoperation, enable autonomous navigation, support system monitoring, and facilitate system testing through <b>simulation.</b> Our approach involves a dynamic representation of the underwater robot and its environment using desktop virtual reality, as well as the integration of mapping, localization, path planning and <b>simulation</b> capabilities within the DT system. Our research demonstrates the system's adaptability, versatility and feasibility, highlighting significant challenges and, in turn, improving the teleoperators' situational awareness and reducing their workload.

{{</citation>}}


### (44/210) Extending 3D body pose estimation for robotic-assistive therapies of autistic children (Laura Santos et al., 2024)

{{<citation>}}

Laura Santos, Bernardo Carvalho, Catarina Barata, José Santos-Victor. (2024)  
**Extending 3D body pose estimation for robotic-assistive therapies of autistic children**
<br/>
<button class="copy-to-clipboard" title="Extending 3D body pose estimation for robotic-assistive therapies of autistic children" index=44>
  <span class="copy-to-clipboard-item">Copy Title<span>
</button>
<div class="toast toast-copied toast-index-44 align-items-center text-bg-secondary border-0 position-absolute top-0 end-0" role="alert" aria-live="assertive" aria-atomic="true">
  <div class="d-flex">
    <div class="toast-body">
      Copied!
    </div>
  </div>
</div>

---
Primary Category: cs.RO  
Categories: cs-CV, cs-HC, cs-RO, cs.RO  
Keyword Score: 10  
Keywords: Fine-tuning  
<a type="button" class="btn btn-outline-primary" href="http://arxiv.org/abs/2402.08006v1" target="_blank" >Paper Link</a>
<button type="button" class="btn btn-outline-primary download-pdf" url="https://arxiv.org/pdf/2402.08006v1.pdf" filename="2402.08006v1.pdf">Download PDF</button>

---


**ABSTRACT**  
Robotic-assistive therapy has demonstrated very encouraging results for children with Autism. Accurate estimation of the child's pose is essential both for human-robot interaction and for therapy assessment purposes. Non-intrusive methods are the sole viable option since these children are sensitive to touch. While depth cameras have been used extensively, existing methods face two major limitations: (i) they are usually trained with adult-only data and do not correctly estimate a child's pose, and (ii) they fail in scenarios with a high number of occlusions. Therefore, our goal was to develop a 3D pose estimator for children, by adapting an existing state-of-the-art 3D body modelling method and incorporating a linear regression model to <b>fine-tune</b> one of its inputs, thereby correcting the pose of children's 3D meshes. In controlled settings, our method has an error below $0.3m$, which is considered acceptable for this kind of application and lower than current state-of-the-art methods. In real-world settings, the proposed model performs similarly to a Kinect depth camera and manages to successfully estimate the 3D body poses in a much higher number of frames.

{{</citation>}}


### (45/210) Evaluation of a Smart Mobile Robotic System for Industrial Plant Inspection and Supervision (Georg K. J. Fischer et al., 2024)

{{<citation>}}

Georg K. J. Fischer, Max Bergau, D. Adriana Gómez-Rosal, Andreas Wachaja, Johannes Gräter, Matthias Odenweller, Uwe Piechottka, Fabian Hoeflinger, Nikhil Gosala, Niklas Wetzel, Daniel Büscher, Abhinav Valada, Wolfram Burgard. (2024)  
**Evaluation of a Smart Mobile Robotic System for Industrial Plant Inspection and Supervision**
<br/>
<button class="copy-to-clipboard" title="Evaluation of a Smart Mobile Robotic System for Industrial Plant Inspection and Supervision" index=45>
  <span class="copy-to-clipboard-item">Copy Title<span>
</button>
<div class="toast toast-copied toast-index-45 align-items-center text-bg-secondary border-0 position-absolute top-0 end-0" role="alert" aria-live="assertive" aria-atomic="true">
  <div class="d-flex">
    <div class="toast-body">
      Copied!
    </div>
  </div>
</div>

---
Primary Category: cs.RO  
Categories: cs-RO, cs.RO  
Keyword Score: 10  
Keywords: Object Detection  
<a type="button" class="btn btn-outline-primary" href="http://arxiv.org/abs/2402.07691v1" target="_blank" >Paper Link</a>
<button type="button" class="btn btn-outline-primary download-pdf" url="https://arxiv.org/pdf/2402.07691v1.pdf" filename="2402.07691v1.pdf">Download PDF</button>

---


**ABSTRACT**  
Automated and autonomous industrial inspection is a longstanding research field, driven by the necessity to enhance safety and efficiency within industrial settings. In addressing this need, we introduce an autonomously navigating robotic system designed for comprehensive plant inspection. This innovative system comprises a robotic platform equipped with a diverse array of sensors integrated to facilitate the detection of various process and infrastructure parameters. These sensors encompass optical (LiDAR, Stereo, UV/IR/RGB cameras), olfactory (electronic nose), and acoustic (microphone array) capabilities, enabling the identification of factors such as methane leaks, flow rates, and infrastructural anomalies. The proposed system underwent individual evaluation at a wastewater treatment site within a chemical plant, providing a practical and challenging environment for testing. The evaluation process encompassed key aspects such as <b>object</b> <b>detection,</b> 3D localization, and path planning. Furthermore, specific evaluations were conducted for optical methane leak detection and localization, as well as acoustic assessments focusing on pump equipment and gas leak localization.

{{</citation>}}


## cs.LG (55)



### (46/210) G-Retriever: Retrieval-Augmented Generation for Textual Graph Understanding and Question Answering (Xiaoxin He et al., 2024)

{{<citation>}}

Xiaoxin He, Yijun Tian, Yifei Sun, Nitesh V. Chawla, Thomas Laurent, Yann LeCun, Xavier Bresson, Bryan Hooi. (2024)  
**G-Retriever: Retrieval-Augmented Generation for Textual Graph Understanding and Question Answering**
<br/>
<button class="copy-to-clipboard" title="G-Retriever: Retrieval-Augmented Generation for Textual Graph Understanding and Question Answering" index=46>
  <span class="copy-to-clipboard-item">Copy Title<span>
</button>
<div class="toast toast-copied toast-index-46 align-items-center text-bg-secondary border-0 position-absolute top-0 end-0" role="alert" aria-live="assertive" aria-atomic="true">
  <div class="d-flex">
    <div class="toast-body">
      Copied!
    </div>
  </div>
</div>

---
Primary Category: cs.LG  
Categories: cs-LG, cs.LG  
Keyword Score: 100  
Keywords: Graph Classification, Graph Neural Network, Graph Neural Network, Fine-tuning, Common-sense Reasoning, Question Answering, Reasoning, Large Language Model, Large Language Model, Prompt  
<a type="button" class="btn btn-outline-primary" href="http://arxiv.org/abs/2402.07630v1" target="_blank" >Paper Link</a>
<button type="button" class="btn btn-outline-primary download-pdf" url="https://arxiv.org/pdf/2402.07630v1.pdf" filename="2402.07630v1.pdf">Download PDF</button>

---


**ABSTRACT**  
Given a <b>graph</b> <b>with</b> <b>textual</b> attributes, we enable users to `chat with their <b>graph':</b> <b>that</b> <b>is,</b> to ask <b>questions</b> <b>about</b> the <b>graph</b> <b>using</b> <b>a</b> conversational interface. In response to a user's <b>questions,</b> <b>our</b> method provides textual replies and highlights the relevant parts of the <b>graph.</b> <b>While</b> <b>existing</b> works integrate <b>large</b> <b>language</b> <b>models</b> <b>(LLMs)</b> and <b>graph</b> <b>neural</b> <b>networks</b> <b>(GNNs)</b> in various ways, they mostly focus on either conventional <b>graph</b> <b>tasks</b> <b>(such</b> as node, edge, and <b>graph</b> <b>classification),</b> <b>or</b> on answering simple <b>graph</b> <b>queries</b> <b>on</b> small or synthetic <b>graphs.</b> <b>In</b> <b>contrast,</b> we develop a flexible <b>question-answering</b> <b>framework</b> targeting real-world textual <b>graphs,</b> <b>applicable</b> <b>to</b> multiple applications including scene <b>graph</b> <b>understanding,</b> <b>common</b> sense <b>reasoning,</b> and knowledge <b>graph</b> <b>reasoning.</b> <b>Toward</b> this goal, we first develop our <b>Graph</b> <b>Question</b> <b>Answering</b> (GraphQA) benchmark with data collected from different tasks. Then, we propose our G-Retriever approach, which integrates the strengths of <b>GNNs,</b> <b>LLMs,</b> and Retrieval-Augmented Generation (RAG), and can be <b>fine-tuned</b> to enhance <b>graph</b> <b>understanding</b> <b>via</b> soft <b>prompting.</b> To resist hallucination and to allow for textual <b>graphs</b> <b>that</b> <b>greatly</b> exceed the <b>LLM's</b> context window size, G-Retriever performs RAG over a <b>graph</b> <b>by</b> <b>formulating</b> this task as a Prize-Collecting Steiner Tree optimization problem. Empirical evaluations show that our method outperforms baselines on textual <b>graph</b> <b>tasks</b> <b>from</b> multiple domains, scales well with larger <b>graph</b> <b>sizes,</b> <b>and</b> resists hallucination. (Our codes and datasets are available at: https://github.com/XiaoxinHe/G-Retriever.)

{{</citation>}}


### (47/210) BASE TTS: Lessons from building a billion-parameter Text-to-Speech model on 100K hours of data (Mateusz Łajszczak et al., 2024)

{{<citation>}}

Mateusz Łajszczak, Guillermo Cámbara, Yang Li, Fatih Beyhan, Arent van Korlaar, Fan Yang, Arnaud Joly, Álvaro Martín-Cortinas, Ammar Abbas, Adam Michalski, Alexis Moinet, Sri Karlapati, Ewa Muszyńska, Haohan Guo, Bartosz Putrycz, Soledad López Gambino, Kayeon Yoo, Elena Sokolova, Thomas Drugman. (2024)  
**BASE TTS: Lessons from building a billion-parameter Text-to-Speech model on 100K hours of data**
<br/>
<button class="copy-to-clipboard" title="BASE TTS: Lessons from building a billion-parameter Text-to-Speech model on 100K hours of data" index=47>
  <span class="copy-to-clipboard-item">Copy Title<span>
</button>
<div class="toast toast-copied toast-index-47 align-items-center text-bg-secondary border-0 position-absolute top-0 end-0" role="alert" aria-live="assertive" aria-atomic="true">
  <div class="d-flex">
    <div class="toast-body">
      Copied!
    </div>
  </div>
</div>

---
Primary Category: cs.LG  
Categories: cs-CL, cs-LG, cs.LG, eess-AS  
Keyword Score: 60  
Keywords: Convolution, Transformer, Text-to-speech, Text-to-speech, Tokenization, Large Language Model  
<a type="button" class="btn btn-outline-primary" href="http://arxiv.org/abs/2402.08093v1" target="_blank" >Paper Link</a>
<button type="button" class="btn btn-outline-primary download-pdf" url="https://arxiv.org/pdf/2402.08093v1.pdf" filename="2402.08093v1.pdf">Download PDF</button>

---


**ABSTRACT**  
We introduce a <b>text-to-speech</b> <b>(TTS)</b> model called BASE <b>TTS,</b> which stands for $\textbf{B}$ig $\textbf{A}$daptive $\textbf{S}$treamable <b>TTS</b> with $\textbf{E}$mergent abilities. BASE <b>TTS</b> is the largest <b>TTS</b> model to-date, trained on 100K hours of public domain speech data, achieving a new state-of-the-art in speech naturalness. It deploys a 1-billion-parameter autoregressive <b>Transformer</b> that converts raw texts into discrete codes ("speechcodes") followed by a <b>convolution-based</b> decoder which converts these speechcodes into waveforms in an incremental, streamable manner. Further, our speechcodes are built using a novel speech <b>tokenization</b> technique that features speaker ID disentanglement and compression with byte-pair encoding. Echoing the widely-reported "emergent abilities" of <b>large</b> <b>language</b> <b>models</b> when trained on increasing volume of data, we show that BASE <b>TTS</b> variants built with 10K+ hours and 500M+ parameters begin to demonstrate natural prosody on textually complex sentences. We design and share a specialized dataset to measure these emergent abilities for <b>text-to-speech.</b> We showcase state-of-the-art naturalness of BASE <b>TTS</b> by evaluating against baselines that include publicly available <b>large-scale</b> <b>text-to-speech</b> <b>systems:</b> YourTTS, Bark and TortoiseTTS. Audio samples generated by the model can be heard at https://amazon-ltts-paper.com/.

{{</citation>}}


### (48/210) Grounding Data Science Code Generation with Input-Output Specifications (Yeming Wen et al., 2024)

{{<citation>}}

Yeming Wen, Pengcheng Yin, Kensen Shi, Henryk Michalewski, Swarat Chaudhuri, Alex Polozov. (2024)  
**Grounding Data Science Code Generation with Input-Output Specifications**
<br/>
<button class="copy-to-clipboard" title="Grounding Data Science Code Generation with Input-Output Specifications" index=48>
  <span class="copy-to-clipboard-item">Copy Title<span>
</button>
<div class="toast toast-copied toast-index-48 align-items-center text-bg-secondary border-0 position-absolute top-0 end-0" role="alert" aria-live="assertive" aria-atomic="true">
  <div class="d-flex">
    <div class="toast-body">
      Copied!
    </div>
  </div>
</div>

---
Primary Category: cs.LG  
Categories: cs-LG, cs-PL, cs-SE, cs.LG  
Keyword Score: 60  
Keywords: Fine-tuning, Code Generation, Grounding, Large Language Model, Large Language Model, Prompt  
<a type="button" class="btn btn-outline-primary" href="http://arxiv.org/abs/2402.08073v1" target="_blank" >Paper Link</a>
<button type="button" class="btn btn-outline-primary download-pdf" url="https://arxiv.org/pdf/2402.08073v1.pdf" filename="2402.08073v1.pdf">Download PDF</button>

---


**ABSTRACT**  
<b>Large</b> <b>language</b> <b>models</b> <b>(LLMs)</b> have recently demonstrated a remarkable ability to generate <b>code</b> <b>from</b> natural language (NL) <b>prompts.</b> However, in the real world, NL is often too ambiguous to capture the true intent behind programming problems, requiring additional input-output (I/O) specifications. Unfortunately, <b>LLMs</b> can have difficulty aligning their outputs with both the NL <b>prompt</b> and the I/O specification. In this paper, we give a way to mitigate this issue in the context of data science programming, where tasks require explicit I/O specifications for clarity. Specifically, we propose GIFT4Code, a novel approach for the instruction <b>fine-tuning</b> of <b>LLMs</b> with respect to I/O specifications. Our method leverages synthetic data produced by the <b>LLM</b> itself and utilizes execution-derived feedback as a key learning signal. This feedback, in the form of program I/O specifications, is provided to the <b>LLM</b> to facilitate instruction <b>fine-tuning.</b> We evaluated our approach on two challenging data science benchmarks, Arcade and DS-1000. The results demonstrate a significant improvement in the <b>LLM's</b> ability to generate <b>code</b> <b>that</b> is not only executable but also accurately aligned with user specifications, substantially improving the quality of <b>code</b> <b>generation</b> for complex data science tasks.

{{</citation>}}


### (49/210) Differentially Private Zeroth-Order Methods for Scalable Large Language Model Finetuning (Z Liu et al., 2024)

{{<citation>}}

Z Liu, J Lou, W Bao, Z Qin, K Ren. (2024)  
**Differentially Private Zeroth-Order Methods for Scalable Large Language Model Finetuning**
<br/>
<button class="copy-to-clipboard" title="Differentially Private Zeroth-Order Methods for Scalable Large Language Model Finetuning" index=49>
  <span class="copy-to-clipboard-item">Copy Title<span>
</button>
<div class="toast toast-copied toast-index-49 align-items-center text-bg-secondary border-0 position-absolute top-0 end-0" role="alert" aria-live="assertive" aria-atomic="true">
  <div class="d-flex">
    <div class="toast-body">
      Copied!
    </div>
  </div>
</div>

---
Primary Category: cs.LG  
Categories: cs-AI, cs-CL, cs-LG, cs.LG  
Keyword Score: 60  
Keywords: Fine-tuning, Pruning, Stochastic Gradient Descent, Large Language Model, Large Language Model, Masked Language Model  
<a type="button" class="btn btn-outline-primary" href="http://arxiv.org/abs/2402.07818v1" target="_blank" >Paper Link</a>
<button type="button" class="btn btn-outline-primary download-pdf" url="https://arxiv.org/pdf/2402.07818v1.pdf" filename="2402.07818v1.pdf">Download PDF</button>

---


**ABSTRACT**  
<b>Finetuning</b> on task-specific datasets is a widely-embraced paradigm of harnessing the powerful capability of pretrained <b>LLMs</b> for various downstream tasks. Due to the popularity of <b>LLMs</b> <b>finetuning</b> and its accompanying privacy concerns, differentially private (DP) <b>finetuning</b> of pretrained <b>LLMs</b> has garnered increasing attention to safeguarding the privacy of task-specific datasets. Lying at the design core of DP <b>LLM</b> <b>finetuning</b> methods is the satisfactory tradeoff between privacy, utility, and scalability. Most existing methods build upon the seminal work of DP-SGD. Despite pushing the scalability of DP-SGD to its limit, DP-SGD-based <b>finetuning</b> methods are unfortunately limited by the inherent inefficiency of <b>SGD.</b> In this paper, we investigate the potential of DP zeroth-order methods for <b>LLM</b> pretraining, which avoids the scalability bottleneck of <b>SGD</b> by approximating the gradient with the more efficient zeroth-order gradient. Rather than treating the zeroth-order method as a drop-in replacement for <b>SGD,</b> this paper presents a comprehensive study both theoretically and empirically. First, we propose the stagewise DP zeroth-order method that dynamically schedules key hyperparameters. This design is grounded on the synergy between DP random perturbation and the gradient approximation error of the zeroth-order method, and its effect on <b>finetuning</b> trajectory. Second, we further enhance the scalability by reducing the trainable parameters that are identified by repurposing a data-free <b>pruning</b> technique requiring no additional data or extra privacy budget. We provide theoretical analysis for both proposed methods. We conduct extensive empirical analysis on both encoder-only <b>masked</b> <b>language</b> <b>model</b> and decoder-only autoregressive language model, achieving impressive results in terms of scalability and utility.

{{</citation>}}


### (50/210) Text-centric Alignment for Multi-Modality Learning (Yun-Da Tsai et al., 2024)

{{<citation>}}

Yun-Da Tsai, Ting-Yu Yen, Pei-Fu Guo, Zhe-Yan Li, Shou-De Lin. (2024)  
**Text-centric Alignment for Multi-Modality Learning**
<br/>
<button class="copy-to-clipboard" title="Text-centric Alignment for Multi-Modality Learning" index=50>
  <span class="copy-to-clipboard-item">Copy Title<span>
</button>
<div class="toast toast-copied toast-index-50 align-items-center text-bg-secondary border-0 position-absolute top-0 end-0" role="alert" aria-live="assertive" aria-atomic="true">
  <div class="d-flex">
    <div class="toast-body">
      Copied!
    </div>
  </div>
</div>

---
Primary Category: cs.LG  
Categories: cs-CL, cs-CV, cs-LG, cs.LG  
Keyword Score: 56  
Keywords: Foundation Model, Multi-modal, Multi-modal, In-context Learning, In-context Learning, Large Language Model, Large Language Model  
<a type="button" class="btn btn-outline-primary" href="http://arxiv.org/abs/2402.08086v1" target="_blank" >Paper Link</a>
<button type="button" class="btn btn-outline-primary download-pdf" url="https://arxiv.org/pdf/2402.08086v1.pdf" filename="2402.08086v1.pdf">Download PDF</button>

---


**ABSTRACT**  
This research paper addresses the challenge of modality mismatch in <b>multimodal</b> learning, where the modalities available during inference differ from those available at training. We propose the Text-centric Alignment for Multi-Modality Learning (TAMML) approach, an innovative method that utilizes <b>Large</b> <b>Language</b> <b>Models</b> <b>(LLMs)</b> with <b>in-context</b> <b>learning</b> and <b>foundation</b> <b>models</b> to enhance the generalizability of <b>multimodal</b> systems under these conditions. By leveraging the unique properties of text as a unified semantic space, TAMML demonstrates significant improvements in handling unseen, diverse, and unpredictable modality combinations. TAMML not only adapts to varying modalities but also maintains robust performance, showcasing the potential of <b>foundation</b> <b>models</b> in overcoming the limitations of traditional fixed-modality frameworks in embedding representations. This study contributes to the field by offering a flexible, effective solution for real-world applications where modality availability is dynamic and uncertain.

{{</citation>}}


### (51/210) Active Preference Learning for Large Language Models (William Muldrew et al., 2024)

{{<citation>}}

William Muldrew, Peter Hayes, Mingtian Zhang, David Barber. (2024)  
**Active Preference Learning for Large Language Models**
<br/>
<button class="copy-to-clipboard" title="Active Preference Learning for Large Language Models" index=51>
  <span class="copy-to-clipboard-item">Copy Title<span>
</button>
<div class="toast toast-copied toast-index-51 align-items-center text-bg-secondary border-0 position-absolute top-0 end-0" role="alert" aria-live="assertive" aria-atomic="true">
  <div class="d-flex">
    <div class="toast-body">
      Copied!
    </div>
  </div>
</div>

---
Primary Category: cs.LG  
Categories: cs-AI, cs-CL, cs-LG, cs.LG  
Keyword Score: 50  
Keywords: Active Learning, Fine-tuning, Reinforcement Learning, Large Language Model, Large Language Model  
<a type="button" class="btn btn-outline-primary" href="http://arxiv.org/abs/2402.08114v1" target="_blank" >Paper Link</a>
<button type="button" class="btn btn-outline-primary download-pdf" url="https://arxiv.org/pdf/2402.08114v1.pdf" filename="2402.08114v1.pdf">Download PDF</button>

---


**ABSTRACT**  
As <b>large</b> <b>language</b> <b>models</b> <b>(LLMs)</b> become more capable, <b>fine-tuning</b> techniques for aligning with human intent are increasingly important. A key consideration for aligning these models is how to most effectively use human resources, or model resources in the case where <b>LLMs</b> themselves are used as oracles. <b>Reinforcement</b> <b>learning</b> from Human or AI preferences (RLHF/RLAIF) is the most prominent example of such a technique, but is complex and often unstable. Direct Preference Optimization (DPO) has recently been proposed as a simpler and more stable alternative. In this work, we develop an <b>active</b> <b>learning</b> strategy for DPO to make better use of preference labels. We propose a practical acquisition function for prompt/completion pairs based on the predictive entropy of the language model and a measure of certainty of the implicit preference model optimized by DPO. We demonstrate how our approach improves both the rate of learning and final performance of <b>fine-tuning</b> on pairwise preference data.

{{</citation>}}


### (52/210) Message Detouring: A Simple Yet Effective Cycle Representation for Expressive Graph Learning (Ziquan Wei et al., 2024)

{{<citation>}}

Ziquan Wei, Tingting Dan, Guorong Wu. (2024)  
**Message Detouring: A Simple Yet Effective Cycle Representation for Expressive Graph Learning**
<br/>
<button class="copy-to-clipboard" title="Message Detouring: A Simple Yet Effective Cycle Representation for Expressive Graph Learning" index=52>
  <span class="copy-to-clipboard-item">Copy Title<span>
</button>
<div class="toast toast-copied toast-index-52 align-items-center text-bg-secondary border-0 position-absolute top-0 end-0" role="alert" aria-live="assertive" aria-atomic="true">
  <div class="d-flex">
    <div class="toast-body">
      Copied!
    </div>
  </div>
</div>

---
Primary Category: cs.LG  
Categories: cs-AI, cs-CG, cs-LG, cs.LG  
Keyword Score: 50  
Keywords: Message-Passing, Edge Prediction, Graph Classification, Node Classification, Transformer  
<a type="button" class="btn btn-outline-primary" href="http://arxiv.org/abs/2402.08085v1" target="_blank" >Paper Link</a>
<button type="button" class="btn btn-outline-primary download-pdf" url="https://arxiv.org/pdf/2402.08085v1.pdf" filename="2402.08085v1.pdf">Download PDF</button>

---


**ABSTRACT**  
<b>Graph</b> <b>learning</b> is crucial in the fields of bioinformatics, social networks, and chemicals. Although high-order graphlets, such as cycles, are critical to achieving an informative <b>graph</b> <b>representation</b> for <b>node</b> <b>classification,</b> <b>edge</b> <b>prediction,</b> and <b>graph</b> <b>recognition,</b> modeling high-order topological characteristics poses significant computational challenges, restricting its widespread applications in machine learning. To address this limitation, we introduce the concept of \textit{message detouring} to hierarchically characterize cycle representation throughout the entire <b>graph,</b> <b>which</b> capitalizes on the contrast between the shortest and longest pathways within a range of local topologies associated with each <b>graph</b> <b>node.</b> <b>The</b> topological feature representations derived from our message detouring landscape demonstrate comparable expressive power to high-order \textit{Weisfeiler-Lehman} (WL) tests but much less computational demands. In addition to the integration with <b>graph</b> <b>kernel</b> and message passing neural networks, we present a novel message detouring neural network, which uses <b>Transformer</b> backbone to integrate cycle representations across <b>nodes</b> <b>and</b> <b>edges.</b> <b>Aside</b> from theoretical results, experimental results on expressiveness, <b>graph</b> <b>classification,</b> and <b>node</b> <b>classification</b> show message detouring can significantly outperform current counterpart approaches on various benchmark datasets.

{{</citation>}}


### (53/210) Foundational Inference Models for Dynamical Systems (Patrick Seifner et al., 2024)

{{<citation>}}

Patrick Seifner, Kostadin Cvejoski, Ramses J. Sanchez. (2024)  
**Foundational Inference Models for Dynamical Systems**
<br/>
<button class="copy-to-clipboard" title="Foundational Inference Models for Dynamical Systems" index=53>
  <span class="copy-to-clipboard-item">Copy Title<span>
</button>
<div class="toast toast-copied toast-index-53 align-items-center text-bg-secondary border-0 position-absolute top-0 end-0" role="alert" aria-live="assertive" aria-atomic="true">
  <div class="d-flex">
    <div class="toast-body">
      Copied!
    </div>
  </div>
</div>

---
Primary Category: cs.LG  
Categories: cs-LG, cs.LG, math-DS  
Keyword Score: 50  
Keywords: Fine-tuning, Fine-tuning, Supervised Learning, Supervised Learning, Zero-shot  
<a type="button" class="btn btn-outline-primary" href="http://arxiv.org/abs/2402.07594v1" target="_blank" >Paper Link</a>
<button type="button" class="btn btn-outline-primary download-pdf" url="https://arxiv.org/pdf/2402.07594v1.pdf" filename="2402.07594v1.pdf">Download PDF</button>

---


**ABSTRACT**  
Ordinary differential equations (ODEs) underlie dynamical systems which serve as models for a vast number of natural and social phenomena. Yet inferring the ODE that best describes a set of noisy observations on one such phenomenon can be remarkably challenging, and the models available to achieve it tend to be highly specialized and complex too. In this work we propose a novel <b>supervised</b> <b>learning</b> framework for <b>zero-shot</b> inference of ODEs from noisy data. We first generate large datasets of one-dimensional ODEs, by sampling distributions over the space of initial conditions, and the space of vector fields defining them. We then learn neural maps between noisy observations on the solutions of these equations, and their corresponding initial condition and vector fields. The resulting models, which we call foundational inference models (FIM), can be (i) copied and matched along the time dimension to increase their resolution; and (ii) copied and composed to build inference models of any dimensionality, without the need of any <b>finetuning.</b> We use FIM to model both ground-truth dynamical systems of different dimensionalities and empirical time series data in a <b>zero-shot</b> fashion, and outperform state-of-the-art models which are <b>finetuned</b> to these systems. Our (pretrained) FIMs are available online

{{</citation>}}


### (54/210) Only the Curve Shape Matters: Training Foundation Models for Zero-Shot Multivariate Time Series Forecasting through Next Curve Shape Prediction (Cheng Feng et al., 2024)

{{<citation>}}

Cheng Feng, Long Huang, Denis Krompass. (2024)  
**Only the Curve Shape Matters: Training Foundation Models for Zero-Shot Multivariate Time Series Forecasting through Next Curve Shape Prediction**
<br/>
<button class="copy-to-clipboard" title="Only the Curve Shape Matters: Training Foundation Models for Zero-Shot Multivariate Time Series Forecasting through Next Curve Shape Prediction" index=54>
  <span class="copy-to-clipboard-item">Copy Title<span>
</button>
<div class="toast toast-copied toast-index-54 align-items-center text-bg-secondary border-0 position-absolute top-0 end-0" role="alert" aria-live="assertive" aria-atomic="true">
  <div class="d-flex">
    <div class="toast-body">
      Copied!
    </div>
  </div>
</div>

---
Primary Category: cs.LG  
Categories: cs-AI, cs-LG, cs.LG  
Keyword Score: 50  
Keywords: Foundation Model, Supervised Learning, Zero-shot, Transformer, Scaling Law  
<a type="button" class="btn btn-outline-primary" href="http://arxiv.org/abs/2402.07570v1" target="_blank" >Paper Link</a>
<button type="button" class="btn btn-outline-primary download-pdf" url="https://arxiv.org/pdf/2402.07570v1.pdf" filename="2402.07570v1.pdf">Download PDF</button>

---


**ABSTRACT**  
We present General Time <b>Transformer</b> (GTT), an encoder-only style <b>foundation</b> <b>model</b> for <b>zero-shot</b> multivariate time series forecasting. GTT is pretrained on a large dataset of 200M high-quality time series samples spanning diverse domains. In our proposed framework, the task of multivariate time series forecasting is formulated as a channel-wise next curve shape prediction problem, where each time series sample is represented as a sequence of non-overlapping curve shapes with a unified numerical magnitude. GTT is trained to predict the next curve shape based on a window of past curve shapes in a channel-wise manner. Experimental results demonstrate that GTT exhibits superior <b>zero-shot</b> multivariate forecasting capabilities on unseen time series datasets, even surpassing state-of-the-art <b>supervised</b> baselines. Additionally, we investigate the impact of varying GTT model parameters and training dataset scales, observing that the <b>scaling</b> <b>law</b> also holds in the context of <b>zero-shot</b> multivariate time series forecasting.

{{</citation>}}


### (55/210) TransAxx: Efficient Transformers with Approximate Computing (Dimitrios Danopoulos et al., 2024)

{{<citation>}}

Dimitrios Danopoulos, Georgios Zervakis, Dimitrios Soudris, Jörg Henkel. (2024)  
**TransAxx: Efficient Transformers with Approximate Computing**
<br/>
<button class="copy-to-clipboard" title="TransAxx: Efficient Transformers with Approximate Computing" index=55>
  <span class="copy-to-clipboard-item">Copy Title<span>
</button>
<div class="toast toast-copied toast-index-55 align-items-center text-bg-secondary border-0 position-absolute top-0 end-0" role="alert" aria-live="assertive" aria-atomic="true">
  <div class="d-flex">
    <div class="toast-body">
      Copied!
    </div>
  </div>
</div>

---
Primary Category: cs.LG  
Categories: cs-AR, cs-LG, cs.LG  
Keyword Score: 50  
Keywords: Convolution, Convolutional Neural Network, Convolutional Neural Network, Fine-tuning, Transformer  
<a type="button" class="btn btn-outline-primary" href="http://arxiv.org/abs/2402.07545v1" target="_blank" >Paper Link</a>
<button type="button" class="btn btn-outline-primary download-pdf" url="https://arxiv.org/pdf/2402.07545v1.pdf" filename="2402.07545v1.pdf">Download PDF</button>

---


**ABSTRACT**  
Vision <b>Transformer</b> (ViT) models which were recently introduced by the <b>transformer</b> architecture have shown to be very competitive and often become a popular alternative to <b>Convolutional</b> <b>Neural</b> <b>Networks</b> <b>(CNNs).</b> However, the high computational requirements of these models limit their practical applicability especially on low-power devices. Current state-of-the-art employs approximate multipliers to address the highly increased compute demands of DNN accelerators but no prior research has explored their use on ViT models. In this work we propose TransAxx, a framework based on the popular PyTorch library that enables fast inherent support for approximate arithmetic to seamlessly evaluate the impact of approximate computing on DNNs such as ViT models. Using TransAxx we analyze the sensitivity of <b>transformer</b> models on the ImageNet dataset to approximate multiplications and perform approximate-aware <b>finetuning</b> to regain accuracy. Furthermore, we propose a methodology to generate approximate accelerators for ViT models. Our approach uses a Monte Carlo Tree Search (MCTS) algorithm to efficiently search the space of possible configurations using a hardware-driven hand-crafted policy. Our evaluation demonstrates the efficacy of our methodology in achieving significant trade-offs between accuracy and power, resulting in substantial gains without compromising on performance.

{{</citation>}}


### (56/210) On the Resurgence of Recurrent Models for Long Sequences: Survey and Research Opportunities in the Transformer Era (Matteo Tiezzi et al., 2024)

{{<citation>}}

Matteo Tiezzi, Michele Casoni, Alessandro Betti, Tommaso Guidi, Marco Gori, Stefano Melacci. (2024)  
**On the Resurgence of Recurrent Models for Long Sequences: Survey and Research Opportunities in the Transformer Era**
<br/>
<button class="copy-to-clipboard" title="On the Resurgence of Recurrent Models for Long Sequences: Survey and Research Opportunities in the Transformer Era" index=56>
  <span class="copy-to-clipboard-item">Copy Title<span>
</button>
<div class="toast toast-copied toast-index-56 align-items-center text-bg-secondary border-0 position-absolute top-0 end-0" role="alert" aria-live="assertive" aria-atomic="true">
  <div class="d-flex">
    <div class="toast-body">
      Copied!
    </div>
  </div>
</div>

---
Primary Category: cs.LG  
Categories: cs-LG, cs.LG  
Keyword Score: 40  
Keywords: Recurrent Neural Network, Transformer, Large Language Model, Self-Attention  
<a type="button" class="btn btn-outline-primary" href="http://arxiv.org/abs/2402.08132v1" target="_blank" >Paper Link</a>
<button type="button" class="btn btn-outline-primary download-pdf" url="https://arxiv.org/pdf/2402.08132v1.pdf" filename="2402.08132v1.pdf">Download PDF</button>

---


**ABSTRACT**  
A longstanding challenge for the Machine Learning community is the one of developing models that are capable of processing and learning from very long sequences of data. The outstanding results of <b>Transformers-based</b> networks (e.g., <b>Large</b> <b>Language</b> <b>Models)</b> promotes the idea of parallel attention as the key to succeed in such a challenge, obfuscating the role of classic sequential processing of <b>Recurrent</b> <b>Models.</b> <b>However,</b> in the last few years, researchers who were concerned by the quadratic complexity of <b>self-attention</b> have been proposing a novel wave of neural models, which gets the best from the two worlds, i.e., <b>Transformers</b> and <b>Recurrent</b> <b>Nets.</b> <b>Meanwhile,</b> Deep Space-State Models emerged as robust approaches to function approximation over time, thus opening a new perspective in learning from sequential data, followed by many people in the field and exploited to implement a special class of (linear) <b>Recurrent</b> <b>Neural</b> <b>Networks.</b> This survey is aimed at providing an overview of these trends framed under the unifying umbrella of Recurrence. Moreover, it emphasizes novel research opportunities that become prominent when abandoning the idea of processing long sequences whose length is known-in-advance for the more realistic setting of potentially infinite-length sequences, thus intersecting the field of lifelong-online learning from streamed data.

{{</citation>}}


### (57/210) UGMAE: A Unified Framework for Graph Masked Autoencoders (Yijun Tian et al., 2024)

{{<citation>}}

Yijun Tian, Chuxu Zhang, Ziyi Kou, Zheyuan Liu, Xiangliang Zhang, Nitesh V. Chawla. (2024)  
**UGMAE: A Unified Framework for Graph Masked Autoencoders**
<br/>
<button class="copy-to-clipboard" title="UGMAE: A Unified Framework for Graph Masked Autoencoders" index=57>
  <span class="copy-to-clipboard-item">Copy Title<span>
</button>
<div class="toast toast-copied toast-index-57 align-items-center text-bg-secondary border-0 position-absolute top-0 end-0" role="alert" aria-live="assertive" aria-atomic="true">
  <div class="d-flex">
    <div class="toast-body">
      Copied!
    </div>
  </div>
</div>

---
Primary Category: cs.LG  
Categories: cs-AI, cs-LG, cs.LG  
Keyword Score: 40  
Keywords: Autoencoder, Reconstruction Loss, Self-supervised Learning, Self-supervised Learning  
<a type="button" class="btn btn-outline-primary" href="http://arxiv.org/abs/2402.08023v1" target="_blank" >Paper Link</a>
<button type="button" class="btn btn-outline-primary download-pdf" url="https://arxiv.org/pdf/2402.08023v1.pdf" filename="2402.08023v1.pdf">Download PDF</button>

---


**ABSTRACT**  
Generative <b>self-supervised</b> <b>learning</b> on graphs, particularly graph masked <b>autoencoders,</b> has emerged as a popular learning paradigm and demonstrated its efficacy in handling non-Euclidean data. However, several remaining issues limit the capability of existing methods: 1) the disregard of uneven node significance in masking, 2) the underutilization of holistic graph information, 3) the ignorance of semantic knowledge in the representation space due to the exclusive use of <b>reconstruction</b> <b>loss</b> in the output space, and 4) the unstable <b>reconstructions</b> <b>caused</b> by the large volume of masked contents. In light of this, we propose UGMAE, a unified framework for graph masked <b>autoencoders</b> to address these issues from the perspectives of adaptivity, integrity, complementarity, and consistency. Specifically, we first develop an adaptive feature mask generator to account for the unique significance of nodes and sample informative masks (adaptivity). We then design a ranking-based structure <b>reconstruction</b> <b>objective</b> joint with feature <b>reconstruction</b> <b>to</b> capture holistic graph information and emphasize the topological proximity between neighbors (integrity). After that, we present a bootstrapping-based similarity module to encode the high-level semantic knowledge in the representation space, complementary to the low-level <b>reconstruction</b> <b>in</b> the output space (complementarity). Finally, we build a consistency assurance module to provide <b>reconstruction</b> <b>objectives</b> with extra stabilized consistency targets (consistency). Extensive experiments demonstrate that UGMAE outperforms both contrastive and generative state-of-the-art baselines on several tasks across multiple datasets.

{{</citation>}}


### (58/210) Policy Improvement using Language Feedback Models (Victor Zhong et al., 2024)

{{<citation>}}

Victor Zhong, Dipendra Misra, Xingdi Yuan, Marc-Alexandre Côté. (2024)  
**Policy Improvement using Language Feedback Models**
<br/>
<button class="copy-to-clipboard" title="Policy Improvement using Language Feedback Models" index=58>
  <span class="copy-to-clipboard-item">Copy Title<span>
</button>
<div class="toast toast-copied toast-index-58 align-items-center text-bg-secondary border-0 position-absolute top-0 end-0" role="alert" aria-live="assertive" aria-atomic="true">
  <div class="d-flex">
    <div class="toast-body">
      Copied!
    </div>
  </div>
</div>

---
Primary Category: cs.LG  
Categories: cs-AI, cs-CL, cs-LG, cs.LG  
Keyword Score: 40  
Keywords: Grounding, Instruction Following, Large Language Model, Large Language Model  
<a type="button" class="btn btn-outline-primary" href="http://arxiv.org/abs/2402.07876v1" target="_blank" >Paper Link</a>
<button type="button" class="btn btn-outline-primary download-pdf" url="https://arxiv.org/pdf/2402.07876v1.pdf" filename="2402.07876v1.pdf">Download PDF</button>

---


**ABSTRACT**  
We introduce Language Feedback Models (LFMs) that identify desirable behaviour - actions that help achieve tasks specified in the <b>instruction</b> <b>-</b> for imitation learning in <b>instruction</b> <b>following.</b> To train LFMs, we obtain feedback from <b>Large</b> <b>Language</b> <b>Models</b> <b>(LLMs)</b> on visual trajectories verbalized to language descriptions. First, by using LFMs to identify desirable behaviour to imitate, we improve in task-completion rate over strong behavioural cloning baselines on three distinct language <b>grounding</b> environments (Touchdown, ScienceWorld, and ALFWorld). Second, LFMs outperform using <b>LLMs</b> as experts to directly predict actions, when controlling for the number of <b>LLM</b> output tokens. Third, LFMs generalize to unseen environments, improving task-completion rate by 3.5-12.0% through one round of adaptation. Finally, LFM can be modified to provide human-interpretable feedback without performance loss, allowing human verification of desirable behaviour for imitation learning.

{{</citation>}}


### (59/210) Empowering Federated Learning for Massive Models with NVIDIA FLARE (Holger R. Roth et al., 2024)

{{<citation>}}

Holger R. Roth, Ziyue Xu, Yuan-Ting Hsieh, Adithya Renduchintala, Isaac Yang, Zhihong Zhang, Yuhong Wen, Sean Yang, Kevin Lu, Kristopher Kersten, Camir Ricketts, Daguang Xu, Chester Chen, Yan Cheng, Andrew Feng. (2024)  
**Empowering Federated Learning for Massive Models with NVIDIA FLARE**
<br/>
<button class="copy-to-clipboard" title="Empowering Federated Learning for Massive Models with NVIDIA FLARE" index=59>
  <span class="copy-to-clipboard-item">Copy Title<span>
</button>
<div class="toast toast-copied toast-index-59 align-items-center text-bg-secondary border-0 position-absolute top-0 end-0" role="alert" aria-live="assertive" aria-atomic="true">
  <div class="d-flex">
    <div class="toast-body">
      Copied!
    </div>
  </div>
</div>

---
Primary Category: cs.LG  
Categories: cs-DC, cs-LG, cs.LG  
Keyword Score: 40  
Keywords: Fine-tuning, Supervised Learning, Large Language Model, Large Language Model  
<a type="button" class="btn btn-outline-primary" href="http://arxiv.org/abs/2402.07792v1" target="_blank" >Paper Link</a>
<button type="button" class="btn btn-outline-primary download-pdf" url="https://arxiv.org/pdf/2402.07792v1.pdf" filename="2402.07792v1.pdf">Download PDF</button>

---


**ABSTRACT**  
In the ever-evolving landscape of artificial intelligence (AI) and <b>large</b> <b>language</b> <b>models</b> <b>(LLMs),</b> handling and leveraging data effectively has become a critical challenge. Most state-of-the-art machine learning algorithms are data-centric. However, as the lifeblood of model performance, necessary data cannot always be centralized due to various factors such as privacy, regulation, geopolitics, copyright issues, and the sheer effort required to move vast datasets. In this paper, we explore how federated learning enabled by NVIDIA FLARE can address these challenges with easy and scalable integration capabilities, enabling parameter-efficient and full <b>supervised</b> <b>fine-tuning</b> of <b>LLMs</b> for natural language processing and biopharmaceutical applications to enhance their accuracy and robustness.

{{</citation>}}


### (60/210) Universal link predictor by In-context Learning (Kaiwen Dong et al., 2024)

{{<citation>}}

Kaiwen Dong, Haitao Mao, Zhichun Guo, Nitesh V. Chawla. (2024)  
**Universal link predictor by In-context Learning**
<br/>
<button class="copy-to-clipboard" title="Universal link predictor by In-context Learning" index=60>
  <span class="copy-to-clipboard-item">Copy Title<span>
</button>
<div class="toast toast-copied toast-index-60 align-items-center text-bg-secondary border-0 position-absolute top-0 end-0" role="alert" aria-live="assertive" aria-atomic="true">
  <div class="d-flex">
    <div class="toast-body">
      Copied!
    </div>
  </div>
</div>

---
Primary Category: cs.LG  
Categories: cs-LG, cs.LG  
Keyword Score: 40  
Keywords: Fine-tuning, In-context Learning, In-context Learning, In-context Learning  
<a type="button" class="btn btn-outline-primary" href="http://arxiv.org/abs/2402.07738v1" target="_blank" >Paper Link</a>
<button type="button" class="btn btn-outline-primary download-pdf" url="https://arxiv.org/pdf/2402.07738v1.pdf" filename="2402.07738v1.pdf">Download PDF</button>

---


**ABSTRACT**  
Link prediction is a crucial task in graph machine learning, where the goal is to infer missing or future links within a graph. Traditional approaches leverage heuristic methods based on widely observed connectivity patterns, offering broad applicability and generalizability without the need for model training. Despite their utility, these methods are limited by their reliance on human-derived heuristics and lack the adaptability of data-driven approaches. Conversely, parametric link predictors excel in automatically learning the connectivity patterns from data and achieving state-of-the-art but fail short to directly transfer across different graphs. Instead, it requires the cost of extensive training and hyperparameter optimization to adapt to the target graph. In this work, we introduce the Universal Link Predictor (UniLP), a novel model that combines the generalizability of heuristic approaches with the pattern learning capabilities of parametric models. UniLP is designed to autonomously identify connectivity patterns across diverse graphs, ready for immediate application to any unseen graph dataset without targeted training. We address the challenge of conflicting connectivity patterns-arising from the unique distributions of different graphs-through the implementation of <b>In-context</b> <b>Learning</b> <b>(ICL).</b> This approach allows UniLP to dynamically adjust to various target graphs based on contextual demonstrations, thereby avoiding negative transfer. Through rigorous experimentation, we demonstrate UniLP's effectiveness in adapting to new, unseen graphs at test time, showcasing its ability to perform comparably or even outperform parametric models that have been <b>finetuned</b> for specific datasets. Our findings highlight UniLP's potential to set a new standard in link prediction, combining the strengths of heuristic and parametric methods in a single, versatile framework.

{{</citation>}}


### (61/210) Assessing Generalization for Subpopulation Representative Modeling via In-Context Learning (Gabriel Simmons et al., 2024)

{{<citation>}}

Gabriel Simmons, Vladislav Savinov. (2024)  
**Assessing Generalization for Subpopulation Representative Modeling via In-Context Learning**
<br/>
<button class="copy-to-clipboard" title="Assessing Generalization for Subpopulation Representative Modeling via In-Context Learning" index=61>
  <span class="copy-to-clipboard-item">Copy Title<span>
</button>
<div class="toast toast-copied toast-index-61 align-items-center text-bg-secondary border-0 position-absolute top-0 end-0" role="alert" aria-live="assertive" aria-atomic="true">
  <div class="d-flex">
    <div class="toast-body">
      Copied!
    </div>
  </div>
</div>

---
Primary Category: cs.LG  
Categories: cs-AI, cs-CL, cs-CY, cs-LG, cs.LG  
Keyword Score: 40  
Keywords: In-context Learning, In-context Learning, Large Language Model, Large Language Model  
<a type="button" class="btn btn-outline-primary" href="http://arxiv.org/abs/2402.07368v1" target="_blank" >Paper Link</a>
<button type="button" class="btn btn-outline-primary download-pdf" url="https://arxiv.org/pdf/2402.07368v1.pdf" filename="2402.07368v1.pdf">Download PDF</button>

---


**ABSTRACT**  
This study evaluates the ability of <b>Large</b> <b>Language</b> <b>Model</b> <b>(LLM)-based</b> Subpopulation Representative Models (SRMs) to generalize from empirical data, utilizing <b>in-context</b> <b>learning</b> with data from the 2016 and 2020 American National Election Studies. We explore generalization across response variables and demographic subgroups. While conditioning with empirical data improves performance on the whole, the benefit of <b>in-context</b> <b>learning</b> varies considerably across demographics, sometimes hurting performance for one demographic while helping performance for others. The inequitable benefits of <b>in-context</b> <b>learning</b> for SRM present a challenge for practitioners implementing SRMs, and for decision-makers who might come to rely on them. Our work highlights a need for fine-grained benchmarks captured from diverse subpopulations that test not only fidelity but generalization.

{{</citation>}}


### (62/210) Bayesian Federated Learning Via Expectation Maximization and Turbo Deep Approximate Message Passing (Wei Xu et al., 2024)

{{<citation>}}

Wei Xu, An Liu, Yiting Zhang, Vincent Lau. (2024)  
**Bayesian Federated Learning Via Expectation Maximization and Turbo Deep Approximate Message Passing**
<br/>
<button class="copy-to-clipboard" title="Bayesian Federated Learning Via Expectation Maximization and Turbo Deep Approximate Message Passing" index=62>
  <span class="copy-to-clipboard-item">Copy Title<span>
</button>
<div class="toast toast-copied toast-index-62 align-items-center text-bg-secondary border-0 position-absolute top-0 end-0" role="alert" aria-live="assertive" aria-atomic="true">
  <div class="d-flex">
    <div class="toast-body">
      Copied!
    </div>
  </div>
</div>

---
Primary Category: cs.LG  
Categories: cs-AI, cs-LG, cs.LG  
Keyword Score: 40  
Keywords: Message-Passing, Model Compression, Stochastic Gradient Descent, Stochastic Gradient Descent  
<a type="button" class="btn btn-outline-primary" href="http://arxiv.org/abs/2402.07366v1" target="_blank" >Paper Link</a>
<button type="button" class="btn btn-outline-primary download-pdf" url="https://arxiv.org/pdf/2402.07366v1.pdf" filename="2402.07366v1.pdf">Download PDF</button>

---


**ABSTRACT**  
Federated learning (FL) is a machine learning paradigm where the clients possess decentralized training data and the central server handles aggregation and scheduling. Typically, FL algorithms involve clients training their local <b>models</b> <b>using</b> <b>stochastic</b> <b>gradient</b> <b>descent</b> <b>(SGD),</b> which carries drawbacks such as slow convergence and being prone to getting stuck in suboptimal solutions. In this work, we propose a message passing based Bayesian federated learning (BFL) framework to avoid these drawbacks.Specifically, we formulate the problem of deep neural network (DNN) learning and compression and as a sparse Bayesian inference problem, in which group sparse prior is employed to achieve structured <b>model</b> <b>compression.</b> Then, we propose an efficient BFL algorithm called EMTDAMP, where expectation maximization (EM) and turbo deep approximate message passing (TDAMP) are combined to achieve distributed learning and compression. The central server aggregates local posterior distributions to update global posterior distributions and update hyperparameters based on EM to accelerate convergence. The clients perform TDAMP to achieve efficient approximate message passing over DNN with joint prior distribution. We detail the application of EMTDAMP to Boston housing price prediction and handwriting recognition, and present extensive numerical results to demonstrate the advantages of EMTDAMP.

{{</citation>}}


### (63/210) Accuracy of TextFooler black box adversarial attacks on 01 loss sign activation neural network ensemble (Yunzhe Xue et al., 2024)

{{<citation>}}

Yunzhe Xue, Usman Roshan. (2024)  
**Accuracy of TextFooler black box adversarial attacks on 01 loss sign activation neural network ensemble**
<br/>
<button class="copy-to-clipboard" title="Accuracy of TextFooler black box adversarial attacks on 01 loss sign activation neural network ensemble" index=63>
  <span class="copy-to-clipboard-item">Copy Title<span>
</button>
<div class="toast toast-copied toast-index-63 align-items-center text-bg-secondary border-0 position-absolute top-0 end-0" role="alert" aria-live="assertive" aria-atomic="true">
  <div class="d-flex">
    <div class="toast-body">
      Copied!
    </div>
  </div>
</div>

---
Primary Category: cs.LG  
Categories: cs-AI, cs-CR, cs-LG, cs.LG  
Keyword Score: 40  
Keywords: Convolution, Convolutional Neural Network, Text Classification, Adversarial Attack  
<a type="button" class="btn btn-outline-primary" href="http://arxiv.org/abs/2402.07347v1" target="_blank" >Paper Link</a>
<button type="button" class="btn btn-outline-primary download-pdf" url="https://arxiv.org/pdf/2402.07347v1.pdf" filename="2402.07347v1.pdf">Download PDF</button>

---


**ABSTRACT**  
Recent work has shown the defense of 01 loss sign activation neural networks against image classification <b>adversarial</b> <b>attacks.</b> A public challenge to attack the models on CIFAR10 dataset remains undefeated. We ask the following question in this study: are 01 loss sign activation neural networks hard to deceive with a popular black box <b>text</b> <b>adversarial</b> <b>attack</b> program called TextFooler? We study this question on four popular <b>text</b> <b>classification</b> datasets: IMDB reviews, Yelp reviews, MR sentiment classification, and AG news classification. We find that our 01 loss sign activation network is much harder to attack with TextFooler compared to sigmoid activation cross entropy and binary neural networks. We also study a 01 loss sign activation <b>convolutional</b> <b>neural</b> <b>network</b> with a novel global pooling step specific to sign activation networks. With this new variation we see a significant gain in <b>adversarial</b> <b>accuracy</b> rendering TextFooler practically useless against it. We make our code freely available at \url{https://github.com/zero-one-loss/wordcnn01} and \url{https://github.com/xyzacademic/mlp01example}. Our work here suggests that 01 loss sign activation networks could be further developed to create fool proof models against <b>text</b> <b>adversarial</b> <b>attacks.</b>

{{</citation>}}


### (64/210) A Competition Winning Deep Reinforcement Learning Agent in microRTS (Scott Goodfriend, 2024)

{{<citation>}}

Scott Goodfriend. (2024)  
**A Competition Winning Deep Reinforcement Learning Agent in microRTS**
<br/>
<button class="copy-to-clipboard" title="A Competition Winning Deep Reinforcement Learning Agent in microRTS" index=64>
  <span class="copy-to-clipboard-item">Copy Title<span>
</button>
<div class="toast toast-copied toast-index-64 align-items-center text-bg-secondary border-0 position-absolute top-0 end-0" role="alert" aria-live="assertive" aria-atomic="true">
  <div class="d-flex">
    <div class="toast-body">
      Copied!
    </div>
  </div>
</div>

---
Primary Category: cs.LG  
Categories: cs-AI, cs-LG, cs.LG  
Keyword Score: 30  
Keywords: Fine-tuning, Reinforcement Learning, Transfer Learning  
<a type="button" class="btn btn-outline-primary" href="http://arxiv.org/abs/2402.08112v1" target="_blank" >Paper Link</a>
<button type="button" class="btn btn-outline-primary download-pdf" url="https://arxiv.org/pdf/2402.08112v1.pdf" filename="2402.08112v1.pdf">Download PDF</button>

---


**ABSTRACT**  
Scripted agents have predominantly won the five previous iterations of the IEEE microRTS ($\mu$RTS) competitions hosted at CIG and CoG. Despite Deep <b>Reinforcement</b> <b>Learning</b> (DRL) algorithms making significant strides in real-time strategy (RTS) games, their adoption in this primarily academic competition has been limited due to the considerable training resources required and the complexity inherent in creating and debugging such agents. RAISocketAI is the first DRL agent to win the IEEE microRTS competition. In a benchmark without performance constraints, RAISocketAI regularly defeated the two prior competition winners. This first competition-winning DRL submission can be a benchmark for future microRTS competitions and a starting point for future DRL research. Iteratively <b>fine-tuning</b> the base policy and <b>transfer</b> <b>learning</b> to specific maps were critical to RAISocketAI's winning performance. These strategies can be used to economically train future DRL agents. Further work in Imitation Learning using Behavior Cloning and <b>fine-tuning</b> these models with DRL has proven promising as an efficient way to bootstrap models with demonstrated, competitive behaviors.

{{</citation>}}


### (65/210) NetInfoF Framework: Measuring and Exploiting Network Usable Information (Meng-Chieh Lee et al., 2024)

{{<citation>}}

Meng-Chieh Lee, Haiyang Yu, Jian Zhang, Vassilis N. Ioannidis, Xiang Song, Soji Adeshina, Da Zheng, Christos Faloutsos. (2024)  
**NetInfoF Framework: Measuring and Exploiting Network Usable Information**
<br/>
<button class="copy-to-clipboard" title="NetInfoF Framework: Measuring and Exploiting Network Usable Information" index=65>
  <span class="copy-to-clipboard-item">Copy Title<span>
</button>
<div class="toast toast-copied toast-index-65 align-items-center text-bg-secondary border-0 position-absolute top-0 end-0" role="alert" aria-live="assertive" aria-atomic="true">
  <div class="d-flex">
    <div class="toast-body">
      Copied!
    </div>
  </div>
</div>

---
Primary Category: cs.LG  
Categories: cs-LG, cs-SI, cs.LG  
Keyword Score: 30  
Keywords: Node Classification, Graph Neural Network, Graph Neural Network  
<a type="button" class="btn btn-outline-primary" href="http://arxiv.org/abs/2402.07999v1" target="_blank" >Paper Link</a>
<button type="button" class="btn btn-outline-primary download-pdf" url="https://arxiv.org/pdf/2402.07999v1.pdf" filename="2402.07999v1.pdf">Download PDF</button>

---


**ABSTRACT**  
Given a <b>node-attributed</b> <b>graph,</b> <b>and</b> <b>a</b> <b>graph</b> <b>task</b> <b>(link</b> prediction or <b>node</b> <b>classification),</b> can we tell if a <b>graph</b> <b>neural</b> <b>network</b> <b>(GNN)</b> will perform well? More specifically, do the <b>graph</b> <b>structure</b> <b>and</b> the <b>node</b> <b>features</b> carry enough usable information for the task? Our goals are (1) to develop a fast tool to measure how much information is in the <b>graph</b> <b>structure</b> <b>and</b> in the <b>node</b> <b>features,</b> and (2) to exploit the information to solve the task, if there is enough. We propose NetInfoF, a framework including NetInfoF_Probe and NetInfoF_Act, for the measurement and the exploitation of network usable information (NUI), respectively. Given a <b>graph</b> <b>data,</b> <b>NetInfoF_Probe</b> measures NUI without any model training, and NetInfoF_Act solves link prediction and <b>node</b> <b>classification,</b> while two modules share the same backbone. In summary, NetInfoF has following notable advantages: (a) General, handling both link prediction and <b>node</b> <b>classification;</b> (b) Principled, with theoretical guarantee and closed-form solution; (c) Effective, thanks to the proposed adjustment to <b>node</b> <b>similarity;</b> (d) Scalable, scaling linearly with the input size. In our carefully designed synthetic datasets, NetInfoF correctly identifies the ground truth of NUI and is the only method being robust to all <b>graph</b> <b>scenarios.</b> <b>Applied</b> on real-world datasets, NetInfoF wins in 11 out of 12 times on link prediction compared to general <b>GNN</b> baselines.

{{</citation>}}


### (66/210) Implicit Bias of Policy Gradient in Linear Quadratic Control: Extrapolation to Unseen Initial States (Noam Razin et al., 2024)

{{<citation>}}

Noam Razin, Yotam Alexander, Edo Cohen-Karlik, Raja Giryes, Amir Globerson, Nadav Cohen. (2024)  
**Implicit Bias of Policy Gradient in Linear Quadratic Control: Extrapolation to Unseen Initial States**
<br/>
<button class="copy-to-clipboard" title="Implicit Bias of Policy Gradient in Linear Quadratic Control: Extrapolation to Unseen Initial States" index=66>
  <span class="copy-to-clipboard-item">Copy Title<span>
</button>
<div class="toast toast-copied toast-index-66 align-items-center text-bg-secondary border-0 position-absolute top-0 end-0" role="alert" aria-live="assertive" aria-atomic="true">
  <div class="d-flex">
    <div class="toast-body">
      Copied!
    </div>
  </div>
</div>

---
Primary Category: cs.LG  
Categories: cs-AI, cs-LG, cs-SY, cs.LG, eess-SY, stat-ML  
Keyword Score: 30  
Keywords: Reinforcement Learning, Supervised Learning, Supervised Learning  
<a type="button" class="btn btn-outline-primary" href="http://arxiv.org/abs/2402.07875v1" target="_blank" >Paper Link</a>
<button type="button" class="btn btn-outline-primary download-pdf" url="https://arxiv.org/pdf/2402.07875v1.pdf" filename="2402.07875v1.pdf">Download PDF</button>

---


**ABSTRACT**  
In modern machine learning, models can often fit training data in numerous ways, some of which perform well on unseen (test) data, while others do not. Remarkably, in such cases gradient descent frequently exhibits an implicit bias that leads to excellent performance on unseen data. This implicit bias was extensively studied in <b>supervised</b> <b>learning,</b> but is far less understood in optimal control <b>(reinforcement</b> <b>learning).</b> There, learning a controller applied to a system via gradient descent is known as policy gradient, and a question of prime importance is the extent to which a learned controller extrapolates to unseen initial states. This paper theoretically studies the implicit bias of policy gradient in terms of extrapolation to unseen initial states. Focusing on the fundamental Linear Quadratic Regulator (LQR) problem, we establish that the extent of extrapolation depends on the degree of exploration induced by the system when commencing from initial states included in training. Experiments corroborate our theory, and demonstrate its conclusions on problems beyond LQR, where systems are non-linear and controllers are neural networks. We hypothesize that real-world optimal control may be greatly improved by developing methods for informed selection of initial states to train on.

{{</citation>}}


### (67/210) Scaling Laws for Fine-Grained Mixture of Experts (Jakub Krajewski et al., 2024)

{{<citation>}}

Jakub Krajewski, Jan Ludziejewski, Kamil Adamczewski, Maciej Pióro, Michał Krutul, Szymon Antoniak, Kamil Ciebiera, Krystian Król, Tomasz Odrzygóźdź, Piotr Sankowski, Marek Cygan, Sebastian Jaszczur. (2024)  
**Scaling Laws for Fine-Grained Mixture of Experts**
<br/>
<button class="copy-to-clipboard" title="Scaling Laws for Fine-Grained Mixture of Experts" index=67>
  <span class="copy-to-clipboard-item">Copy Title<span>
</button>
<div class="toast toast-copied toast-index-67 align-items-center text-bg-secondary border-0 position-absolute top-0 end-0" role="alert" aria-live="assertive" aria-atomic="true">
  <div class="d-flex">
    <div class="toast-body">
      Copied!
    </div>
  </div>
</div>

---
Primary Category: cs.LG  
Categories: cs-AI, cs-CL, cs-LG, cs.LG  
Keyword Score: 30  
Keywords: Transformer, Large Language Model, Scaling Law  
<a type="button" class="btn btn-outline-primary" href="http://arxiv.org/abs/2402.07871v1" target="_blank" >Paper Link</a>
<button type="button" class="btn btn-outline-primary download-pdf" url="https://arxiv.org/pdf/2402.07871v1.pdf" filename="2402.07871v1.pdf">Download PDF</button>

---


**ABSTRACT**  
Mixture of Experts (MoE) models have emerged as a primary solution for reducing the computational cost of <b>Large</b> <b>Language</b> <b>Models.</b> In this work, we analyze their <b>scaling</b> <b>properties,</b> incorporating an expanded range of variables. Specifically, we introduce a new hyperparameter, granularity, whose adjustment enables precise control over the size of the experts. Building on this, we establish <b>scaling</b> <b>laws</b> for fine-grained MoE, taking into account the number of training tokens, model size, and granularity. Leveraging these laws, we derive the optimal training configuration for a given computational budget. Our findings not only show that MoE models consistently outperform dense <b>Transformers</b> but also highlight that the efficiency gap between dense and MoE models widens as we scale up the model size and training budget. Furthermore, we demonstrate that the common practice of setting the size of experts in MoE to mirror the feed-forward layer is not optimal at almost any computational budget.

{{</citation>}}


### (68/210) An Investigation into Using Unsupervised Metrics to Optimise GNNs for Node Clustering (William Leeney et al., 2024)

{{<citation>}}

William Leeney, Ryan McConville. (2024)  
**An Investigation into Using Unsupervised Metrics to Optimise GNNs for Node Clustering**
<br/>
<button class="copy-to-clipboard" title="An Investigation into Using Unsupervised Metrics to Optimise GNNs for Node Clustering" index=68>
  <span class="copy-to-clipboard-item">Copy Title<span>
</button>
<div class="toast toast-copied toast-index-68 align-items-center text-bg-secondary border-0 position-absolute top-0 end-0" role="alert" aria-live="assertive" aria-atomic="true">
  <div class="d-flex">
    <div class="toast-body">
      Copied!
    </div>
  </div>
</div>

---
Primary Category: cs.LG  
Categories: cs-AI, cs-LG, cs.LG  
Keyword Score: 30  
Keywords: Graph Neural Network, Graph Neural Network, Unsupervised Learning  
<a type="button" class="btn btn-outline-primary" href="http://arxiv.org/abs/2402.07845v1" target="_blank" >Paper Link</a>
<button type="button" class="btn btn-outline-primary download-pdf" url="https://arxiv.org/pdf/2402.07845v1.pdf" filename="2402.07845v1.pdf">Download PDF</button>

---


**ABSTRACT**  
<b>Graph</b> <b>Neural</b> <b>Networks</b> <b>(GNNs)</b> can be trained to detect communities within a <b>graph</b> <b>by</b> <b>learning</b> from the duality of feature and connectivity information. Currently, the common approach for optimisation of <b>GNNs</b> is to use comparisons to ground-truth for hyperparameter tuning and model selection. In this work, we show that nodes can be clustered into communities with <b>GNNs</b> by solely optimising for modularity, without any comparison to ground-truth. Although modularity is a <b>graph</b> <b>partitioning</b> <b>quality</b> metric, we show that this can be used to optimise <b>GNNs</b> that also encode features without a drop in performance. We take it a step further and also study whether the <b>unsupervised</b> metric performance can predict ground-truth performance. To investigate why modularity can be used to optimise <b>GNNs,</b> we design synthetic experiments that show the limitations of this approach. The synthetic <b>graphs</b> <b>are</b> <b>created</b> to highlight current capabilities in distinct, random and zero information space partitions in attributed <b>graphs.</b> <b>We</b> <b>conclude</b> that modularity can be used for hyperparameter optimisation and model selection on real-world datasets as well as being a suitable proxy for predicting ground-truth performance, however, <b>GNNs</b> fail to balance the information duality when the spaces contain conflicting signals.

{{</citation>}}


### (69/210) Towards an Understanding of Stepwise Inference in Transformers: A Synthetic Graph Navigation Model (Mikail Khona et al., 2024)

{{<citation>}}

Mikail Khona, Maya Okawa, Jan Hula, Rahul Ramesh, Kento Nishi, Robert Dick, Ekdeep Singh Lubana, Hidenori Tanaka. (2024)  
**Towards an Understanding of Stepwise Inference in Transformers: A Synthetic Graph Navigation Model**
<br/>
<button class="copy-to-clipboard" title="Towards an Understanding of Stepwise Inference in Transformers: A Synthetic Graph Navigation Model" index=69>
  <span class="copy-to-clipboard-item">Copy Title<span>
</button>
<div class="toast toast-copied toast-index-69 align-items-center text-bg-secondary border-0 position-absolute top-0 end-0" role="alert" aria-live="assertive" aria-atomic="true">
  <div class="d-flex">
    <div class="toast-body">
      Copied!
    </div>
  </div>
</div>

---
Primary Category: cs.LG  
Categories: cs-AI, cs-LG, cs.LG  
Keyword Score: 30  
Keywords: Transformer, Reasoning, In-context Learning  
<a type="button" class="btn btn-outline-primary" href="http://arxiv.org/abs/2402.07757v1" target="_blank" >Paper Link</a>
<button type="button" class="btn btn-outline-primary download-pdf" url="https://arxiv.org/pdf/2402.07757v1.pdf" filename="2402.07757v1.pdf">Download PDF</button>

---


**ABSTRACT**  
Stepwise inference protocols, such as scratchpads and chain-of-thought, help language models solve complex problems by decomposing them into a sequence of simpler subproblems. Despite the significant gain in performance achieved via these protocols, the underlying mechanisms of stepwise inference have remained elusive. To address this, we propose to study autoregressive <b>Transformer</b> models on a synthetic task that embodies the multi-step nature of problems where stepwise inference is generally most useful. Specifically, we define a graph navigation problem wherein a model is tasked with traversing a path from a start to a goal node on the graph. Despite is simplicity, we find we can empirically reproduce and analyze several phenomena observed at scale: (i) the stepwise inference <b>reasoning</b> gap, the cause of which we find in the structure of the training data; (ii) a diversity-accuracy tradeoff in model generations as sampling temperature varies; (iii) a simplicity bias in the model's output; and (iv) compositional generalization and a primacy bias with <b>in-context</b> exemplars. Overall, our work introduces a grounded, synthetic framework for studying stepwise inference and offers mechanistic hypotheses that can lay the foundation for a deeper understanding of this phenomenon.

{{</citation>}}


### (70/210) LoRA-drop: Efficient LoRA Parameter Pruning based on Output Evaluation (Hongyun Zhou et al., 2024)

{{<citation>}}

Hongyun Zhou, Xiangyu Lu, Wang Xu, Conghui Zhu, Tiejun Zhao. (2024)  
**LoRA-drop: Efficient LoRA Parameter Pruning based on Output Evaluation**
<br/>
<button class="copy-to-clipboard" title="LoRA-drop: Efficient LoRA Parameter Pruning based on Output Evaluation" index=70>
  <span class="copy-to-clipboard-item">Copy Title<span>
</button>
<div class="toast toast-copied toast-index-70 align-items-center text-bg-secondary border-0 position-absolute top-0 end-0" role="alert" aria-live="assertive" aria-atomic="true">
  <div class="d-flex">
    <div class="toast-body">
      Copied!
    </div>
  </div>
</div>

---
Primary Category: cs.LG  
Categories: cs-CL, cs-LG, cs.LG  
Keyword Score: 30  
Keywords: Fine-tuning, Pruning, Natural Language Generation  
<a type="button" class="btn btn-outline-primary" href="http://arxiv.org/abs/2402.07721v1" target="_blank" >Paper Link</a>
<button type="button" class="btn btn-outline-primary download-pdf" url="https://arxiv.org/pdf/2402.07721v1.pdf" filename="2402.07721v1.pdf">Download PDF</button>

---


**ABSTRACT**  
Low-Rank Adaptation (LoRA) introduces auxiliary parameters for each layer to <b>fine-tune</b> the pre-trained model under limited computing resources. But it still faces challenges of resource consumption when scaling up to larger models. Previous studies employ <b>pruning</b> techniques by evaluating the importance of LoRA parameters for different layers to address the problem. However, these efforts only analyzed parameter features to evaluate their importance. Indeed, the output of LoRA related to the parameters and data is the factor that directly impacts the frozen model. To this end, we propose LoRA-drop which evaluates the importance of the parameters by analyzing the LoRA output. We retain LoRA for important layers and the LoRA of the other layers share the same parameters. Abundant experiments on NLU and <b>NLG</b> tasks demonstrate the effectiveness of LoRA-drop.

{{</citation>}}


### (71/210) Model Collapse Demystified: The Case of Regression (Elvis Dohmatob et al., 2024)

{{<citation>}}

Elvis Dohmatob, Yunzhen Feng, Julia Kempe. (2024)  
**Model Collapse Demystified: The Case of Regression**
<br/>
<button class="copy-to-clipboard" title="Model Collapse Demystified: The Case of Regression" index=71>
  <span class="copy-to-clipboard-item">Copy Title<span>
</button>
<div class="toast toast-copied toast-index-71 align-items-center text-bg-secondary border-0 position-absolute top-0 end-0" role="alert" aria-live="assertive" aria-atomic="true">
  <div class="d-flex">
    <div class="toast-body">
      Copied!
    </div>
  </div>
</div>

---
Primary Category: cs.LG  
Categories: cs-AI, cs-LG, cs.LG, stat-ML  
Keyword Score: 30  
Keywords: ChatGPT, Large Language Model, Scaling Law  
<a type="button" class="btn btn-outline-primary" href="http://arxiv.org/abs/2402.07712v1" target="_blank" >Paper Link</a>
<button type="button" class="btn btn-outline-primary download-pdf" url="https://arxiv.org/pdf/2402.07712v1.pdf" filename="2402.07712v1.pdf">Download PDF</button>

---


**ABSTRACT**  
In the era of <b>large</b> <b>language</b> <b>models</b> like <b>ChatGPT,</b> the phenomenon of "model collapse" refers to the situation whereby as a model is trained recursively on data generated from previous generations of itself over time, its performance degrades until the model eventually becomes completely useless, i.e the model collapses. In this work, we study this phenomenon in the simplified setting of kernel regression and obtain results which show a clear crossover between where the model can cope with fake data, and a regime where the model's performance completely collapses. Under polynomial decaying spectral and source conditions, we obtain modified <b>scaling</b> <b>laws</b> which exhibit new crossover phenomena from fast to slow rates. We also propose a simple strategy based on adaptive regularization to mitigate model collapse. Our theoretical results are validated with experiments.

{{</citation>}}


### (72/210) Optimization of Sparse Convolution for 3D-Point Cloud on GPUs with CUDA (Chester Luo et al., 2024)

{{<citation>}}

Chester Luo, Kevin Lai. (2024)  
**Optimization of Sparse Convolution for 3D-Point Cloud on GPUs with CUDA**
<br/>
<button class="copy-to-clipboard" title="Optimization of Sparse Convolution for 3D-Point Cloud on GPUs with CUDA" index=72>
  <span class="copy-to-clipboard-item">Copy Title<span>
</button>
<div class="toast toast-copied toast-index-72 align-items-center text-bg-secondary border-0 position-absolute top-0 end-0" role="alert" aria-live="assertive" aria-atomic="true">
  <div class="d-flex">
    <div class="toast-body">
      Copied!
    </div>
  </div>
</div>

---
Primary Category: cs.LG  
Categories: cs-CV, cs-LG, cs.LG  
Keyword Score: 30  
Keywords: Convolution, Convolutional Neural Network, Convolutional Neural Network  
<a type="button" class="btn btn-outline-primary" href="http://arxiv.org/abs/2402.07710v1" target="_blank" >Paper Link</a>
<button type="button" class="btn btn-outline-primary download-pdf" url="https://arxiv.org/pdf/2402.07710v1.pdf" filename="2402.07710v1.pdf">Download PDF</button>

---


**ABSTRACT**  
In recent years, there has been a significant increase in the utilization of deep learning methods, particularly <b>convolutional</b> <b>neural</b> <b>networks</b> <b>(CNNs),</b> which have emerged as the dominant approach in various domains that involve structured grid data, such as picture analysis and processing. Nevertheless, the exponential growth in the utilization of LiDAR and 3D sensors across many domains has resulted in an increased need for the analysis of 3D point clouds. The utilization of 3D point clouds is crucial in various applications, including object recognition and segmentation, as they offer a spatial depiction of things within a three-dimensional environment. In contrast to photos, point clouds exhibit sparsity and lack a regular grid, hence posing distinct processing and computational issues.

{{</citation>}}


### (73/210) ClusterTabNet: Supervised clustering method for table detection and table structure recognition (Marek Polewczyk et al., 2024)

{{<citation>}}

Marek Polewczyk, Marco Spinaci. (2024)  
**ClusterTabNet: Supervised clustering method for table detection and table structure recognition**
<br/>
<button class="copy-to-clipboard" title="ClusterTabNet: Supervised clustering method for table detection and table structure recognition" index=73>
  <span class="copy-to-clipboard-item">Copy Title<span>
</button>
<div class="toast toast-copied toast-index-73 align-items-center text-bg-secondary border-0 position-absolute top-0 end-0" role="alert" aria-live="assertive" aria-atomic="true">
  <div class="d-flex">
    <div class="toast-body">
      Copied!
    </div>
  </div>
</div>

---
Primary Category: cs.LG  
Categories: cs-CV, cs-LG, cs.LG  
Keyword Score: 30  
Keywords: Optical Character Recognition, Supervised Learning, Transformer  
<a type="button" class="btn btn-outline-primary" href="http://arxiv.org/abs/2402.07502v1" target="_blank" >Paper Link</a>
<button type="button" class="btn btn-outline-primary download-pdf" url="https://arxiv.org/pdf/2402.07502v1.pdf" filename="2402.07502v1.pdf">Download PDF</button>

---


**ABSTRACT**  
We present a novel deep-learning-based method to cluster words in documents which we apply to detect and recognize tables given the <b>OCR</b> output. We interpret table structure bottom-up as a graph of relations between pairs of words (belonging to the same row, column, header, as well as to the same table) and use a <b>transformer</b> encoder model to predict its adjacency matrix. We demonstrate the performance of our method on the PubTables-1M dataset as well as PubTabNet and FinTabNet datasets. Compared to the current state-of-the-art detection methods such as DETR and Faster R-CNN, our method achieves similar or better accuracy, while requiring a significantly smaller model.

{{</citation>}}


### (74/210) One Train for Two Tasks: An Encrypted Traffic Classification Framework Using Supervised Contrastive Learning (Haozhen Zhang et al., 2024)

{{<citation>}}

Haozhen Zhang, Xi Xiao, Le Yu, Qing Li, Zhen Ling, Ye Zhang. (2024)  
**One Train for Two Tasks: An Encrypted Traffic Classification Framework Using Supervised Contrastive Learning**
<br/>
<button class="copy-to-clipboard" title="One Train for Two Tasks: An Encrypted Traffic Classification Framework Using Supervised Contrastive Learning" index=74>
  <span class="copy-to-clipboard-item">Copy Title<span>
</button>
<div class="toast toast-copied toast-index-74 align-items-center text-bg-secondary border-0 position-absolute top-0 end-0" role="alert" aria-live="assertive" aria-atomic="true">
  <div class="d-flex">
    <div class="toast-body">
      Copied!
    </div>
  </div>
</div>

---
Primary Category: cs.LG  
Categories: cs-AI, cs-LG, cs.LG  
Keyword Score: 30  
Keywords: Contrastive Learning, Data Augmentation, Supervised Learning  
<a type="button" class="btn btn-outline-primary" href="http://arxiv.org/abs/2402.07501v1" target="_blank" >Paper Link</a>
<button type="button" class="btn btn-outline-primary download-pdf" url="https://arxiv.org/pdf/2402.07501v1.pdf" filename="2402.07501v1.pdf">Download PDF</button>

---


**ABSTRACT**  
As network security receives widespread attention, encrypted traffic classification has become the current research focus. However, existing methods conduct traffic classification without sufficiently considering the common characteristics between <b>data</b> <b>samples,</b> leading to suboptimal performance. Moreover, they train the packet-level and flow-level classification tasks independently, which is redundant because the packet representations learned in the packet-level task can be exploited by the flow-level task. Therefore, in this paper, we propose an effective model named a <b>Contrastive</b> <b>Learning</b> Enhanced Temporal Fusion Encoder (CLE-TFE). In particular, we utilize <b>supervised</b> <b>contrastive</b> <b>learning</b> to enhance the packet-level and flow-level representations and perform graph <b>data</b> <b>augmentation</b> on the byte-level traffic graph so that the fine-grained semantic-invariant characteristics between bytes can be captured through <b>contrastive</b> <b>learning.</b> We also propose cross-level multi-task learning, which simultaneously accomplishes the packet-level and flow-level classification tasks in the same model with one training. Further experiments show that CLE-TFE achieves the best overall performance on the two tasks, while its computational overhead (i.e., floating point operations, FLOPs) is only about 1/14 of the pre-trained model (e.g., ET-BERT). We release the code at https://github.com/ViktorAxelsen/CLE-TFE

{{</citation>}}


### (75/210) Topological safeguard for evasion attack interpreting the neural networks' behavior (Xabier Echeberria-Barrio et al., 2024)

{{<citation>}}

Xabier Echeberria-Barrio, Amaia Gil-Lerchundi, Iñigo Mendialdua, Raul Orduna-Urrutia. (2024)  
**Topological safeguard for evasion attack interpreting the neural networks' behavior**
<br/>
<button class="copy-to-clipboard" title="Topological safeguard for evasion attack interpreting the neural networks' behavior" index=75>
  <span class="copy-to-clipboard-item">Copy Title<span>
</button>
<div class="toast toast-copied toast-index-75 align-items-center text-bg-secondary border-0 position-absolute top-0 end-0" role="alert" aria-live="assertive" aria-atomic="true">
  <div class="d-flex">
    <div class="toast-body">
      Copied!
    </div>
  </div>
</div>

---
Primary Category: cs.LG  
Categories: cs-LG, cs.LG  
Keyword Score: 30  
Keywords: Graph Convolutional Network, Convolution, Convolutional Neural Network  
<a type="button" class="btn btn-outline-primary" href="http://arxiv.org/abs/2402.07480v2" target="_blank" >Paper Link</a>
<button type="button" class="btn btn-outline-primary download-pdf" url="https://arxiv.org/pdf/2402.07480v2.pdf" filename="2402.07480v2.pdf">Download PDF</button>

---


**ABSTRACT**  
In the last years, Deep Learning technology has been proposed in different fields, bringing many advances in each of them, but identifying new threats in these solutions regarding cybersecurity. Those implemented models have brought several vulnerabilities associated with Deep Learning technology. Moreover, those allow taking advantage of the implemented model, obtaining private information, and even modifying the model's decision-making. Therefore, interest in studying those vulnerabilities/attacks and designing defenses to avoid or fight them is gaining prominence among researchers. In particular, the widely known evasion attack is being analyzed by researchers; thus, several defenses to avoid such a threat can be found in the literature. Since the presentation of the L-BFG algorithm, this threat concerns the research community. However, it continues developing new and ingenious countermeasures since there is no perfect defense for all the known evasion algorithms. In this work, a novel detector of evasion attacks is developed. It focuses on the information of the activations of the neurons given by the model when an input sample is injected. Moreover, it puts attention to the topology of the targeted deep learning model to analyze the activations according to which neurons are connecting. This approach has been decided because the literature shows that the targeted model's topology contains essential information about if the evasion attack occurs. For this purpose, a huge data preprocessing is required to introduce all this information in the detector, which uses the Graph <b>Convolutional</b> <b>Neural</b> <b>Network</b> <b>(GCN)</b> technology. Thus, it understands the topology of the target model, obtaining promising results and improving the outcomes presented in the literature related to similar defenses.

{{</citation>}}


### (76/210) Contextual Multinomial Logit Bandits with General Value Functions (Mengxiao Zhang et al., 2024)

{{<citation>}}

Mengxiao Zhang, Haipeng Luo. (2024)  
**Contextual Multinomial Logit Bandits with General Value Functions**
<br/>
<button class="copy-to-clipboard" title="Contextual Multinomial Logit Bandits with General Value Functions" index=76>
  <span class="copy-to-clipboard-item">Copy Title<span>
</button>
<div class="toast toast-copied toast-index-76 align-items-center text-bg-secondary border-0 position-absolute top-0 end-0" role="alert" aria-live="assertive" aria-atomic="true">
  <div class="d-flex">
    <div class="toast-body">
      Copied!
    </div>
  </div>
</div>

---
Primary Category: cs.LG  
Categories: cs-LG, cs.LG  
Keyword Score: 20  
Keywords: Bandit Algorithm, Recommendation  
<a type="button" class="btn btn-outline-primary" href="http://arxiv.org/abs/2402.08126v1" target="_blank" >Paper Link</a>
<button type="button" class="btn btn-outline-primary download-pdf" url="https://arxiv.org/pdf/2402.08126v1.pdf" filename="2402.08126v1.pdf">Download PDF</button>

---


**ABSTRACT**  
Contextual multinomial logit (MNL) <b>bandits</b> capture many real-world assortment <b>recommendation</b> problems such as online retailing/advertising. However, prior work has only considered (generalized) linear value functions, which greatly limits its applicability. Motivated by this fact, in this work, we consider contextual MNL <b>bandits</b> with a general value function class that contains the ground truth, borrowing ideas from a recent trend of studies on contextual <b>bandits.</b> Specifically, we consider both the stochastic and the adversarial settings, and propose a suite of algorithms, each with different computation-regret trade-off. When applied to the linear case, our results not only are the first ones with no dependence on a certain problem-dependent constant that can be exponentially large, but also enjoy other advantages such as computational efficiency, dimension-free regret bounds, or the ability to handle completely adversarial contexts and rewards.

{{</citation>}}


### (77/210) Which Pretrain Samples to Rehearse when Finetuning Pretrained Models? (Andrew Bai et al., 2024)

{{<citation>}}

Andrew Bai, Chih-Kuan Yeh, Cho-Jui Hsieh, Ankur Taly. (2024)  
**Which Pretrain Samples to Rehearse when Finetuning Pretrained Models?**
<br/>
<button class="copy-to-clipboard" title="Which Pretrain Samples to Rehearse when Finetuning Pretrained Models?" index=77>
  <span class="copy-to-clipboard-item">Copy Title<span>
</button>
<div class="toast toast-copied toast-index-77 align-items-center text-bg-secondary border-0 position-absolute top-0 end-0" role="alert" aria-live="assertive" aria-atomic="true">
  <div class="d-flex">
    <div class="toast-body">
      Copied!
    </div>
  </div>
</div>

---
Primary Category: cs.LG  
Categories: cs-LG, cs.LG  
Keyword Score: 20  
Keywords: Fine-tuning, Fine-tuning  
<a type="button" class="btn btn-outline-primary" href="http://arxiv.org/abs/2402.08096v1" target="_blank" >Paper Link</a>
<button type="button" class="btn btn-outline-primary download-pdf" url="https://arxiv.org/pdf/2402.08096v1.pdf" filename="2402.08096v1.pdf">Download PDF</button>

---


**ABSTRACT**  
<b>Fine-tuning</b> pretrained foundational models on specific tasks is now the de facto approach for text and vision tasks. A known pitfall of this approach is the forgetting of pretraining knowledge that happens during <b>finetuning.</b> Rehearsing samples randomly from the pretrain dataset is a common approach to alleviate such forgetting. However, we find that random mixing unintentionally includes samples which are not (yet) forgotten or unlearnable by the model. We propose a novel sampling scheme, mix-cd, that identifies and prioritizes samples that actually face forgetting, which we call collateral damage. Since directly identifying collateral damage samples is computationally expensive, we propose a procedure to estimate the distribution of such samples by tracking the statistics of <b>finetuned</b> samples. Our approach is lightweight, easy to implement, and can be seamlessly integrated into existing models, offering an effective means to retain pretrain performance without additional computational costs.

{{</citation>}}


### (78/210) Avoiding Catastrophe in Continuous Spaces by Asking for Help (Benjamin Plaut et al., 2024)

{{<citation>}}

Benjamin Plaut, Hanlin Zhu, Stuart Russell. (2024)  
**Avoiding Catastrophe in Continuous Spaces by Asking for Help**
<br/>
<button class="copy-to-clipboard" title="Avoiding Catastrophe in Continuous Spaces by Asking for Help" index=78>
  <span class="copy-to-clipboard-item">Copy Title<span>
</button>
<div class="toast toast-copied toast-index-78 align-items-center text-bg-secondary border-0 position-absolute top-0 end-0" role="alert" aria-live="assertive" aria-atomic="true">
  <div class="d-flex">
    <div class="toast-body">
      Copied!
    </div>
  </div>
</div>

---
Primary Category: cs.LG  
Categories: cs-AI, cs-LG, cs.LG  
Keyword Score: 20  
Keywords: Bandit Algorithm, Reinforcement Learning  
<a type="button" class="btn btn-outline-primary" href="http://arxiv.org/abs/2402.08062v1" target="_blank" >Paper Link</a>
<button type="button" class="btn btn-outline-primary download-pdf" url="https://arxiv.org/pdf/2402.08062v1.pdf" filename="2402.08062v1.pdf">Download PDF</button>

---


**ABSTRACT**  
Most <b>reinforcement</b> <b>learning</b> algorithms with formal regret guarantees assume all mistakes are reversible and rely on essentially trying all possible options. This approach leads to poor outcomes when some mistakes are irreparable or even catastrophic. We propose a variant of the contextual <b>bandit</b> problem where the goal is to minimize the chance of catastrophe. Specifically, we assume that the payoff each round represents the chance of avoiding catastrophe that round, and try to maximize the product of payoffs (the overall chance of avoiding catastrophe). To give the agent some chance of success, we allow a limited number of queries to a mentor and assume a Lipschitz continuous payoff function. We present an algorithm whose regret and rate of querying the mentor both approach 0 as the time horizon grows, assuming a continuous 1D state space and a relatively "simple" payoff function. We also provide a matching lower bound: without the simplicity assumption: any algorithm either constantly asks for help or is nearly guaranteed to cause catastrophe. Finally, we identify the key obstacle to generalizing our algorithm to a multi-dimensional state space.

{{</citation>}}


### (79/210) Which Frequencies do CNNs Need? Emergent Bottleneck Structure in Feature Learning (Yuxiao Wen et al., 2024)

{{<citation>}}

Yuxiao Wen, Arthur Jacot. (2024)  
**Which Frequencies do CNNs Need? Emergent Bottleneck Structure in Feature Learning**
<br/>
<button class="copy-to-clipboard" title="Which Frequencies do CNNs Need? Emergent Bottleneck Structure in Feature Learning" index=79>
  <span class="copy-to-clipboard-item">Copy Title<span>
</button>
<div class="toast toast-copied toast-index-79 align-items-center text-bg-secondary border-0 position-absolute top-0 end-0" role="alert" aria-live="assertive" aria-atomic="true">
  <div class="d-flex">
    <div class="toast-body">
      Copied!
    </div>
  </div>
</div>

---
Primary Category: cs.LG  
Categories: cs-AI, cs-LG, cs.LG, stat-ML  
Keyword Score: 20  
Keywords: Convolution, Convolutional Neural Network  
<a type="button" class="btn btn-outline-primary" href="http://arxiv.org/abs/2402.08010v1" target="_blank" >Paper Link</a>
<button type="button" class="btn btn-outline-primary download-pdf" url="https://arxiv.org/pdf/2402.08010v1.pdf" filename="2402.08010v1.pdf">Download PDF</button>

---


**ABSTRACT**  
We describe the emergence of a <b>Convolution</b> Bottleneck (CBN) structure in <b>CNNs,</b> where the network uses its first few layers to transform the input representation into a representation that is supported only along a few frequencies and channels, before using the last few layers to map back to the outputs. We define the CBN rank, which describes the number and type of frequencies that are kept inside the bottleneck, and partially prove that the parameter norm required to represent a function $f$ scales as depth times the CBN rank $f$. We also show that the parameter norm depends at next order on the regularity of $f$. We show that any network with almost optimal parameter norm will exhibit a CBN structure in both the weights and - under the assumption that the network is stable under large learning rate - the activations, which motivates the common practice of down-sampling; and we verify that the CBN results still hold with down-sampling. Finally we use the CBN structure to interpret the functions learned by <b>CNNs</b> on a number of tasks.

{{</citation>}}


### (80/210) FAST: Factorizable Attention for Speeding up Transformers (Armin Gerami et al., 2024)

{{<citation>}}

Armin Gerami, Monte Hoover, Pranav S. Dulepet, Ramani Duraiswami. (2024)  
**FAST: Factorizable Attention for Speeding up Transformers**
<br/>
<button class="copy-to-clipboard" title="FAST: Factorizable Attention for Speeding up Transformers" index=80>
  <span class="copy-to-clipboard-item">Copy Title<span>
</button>
<div class="toast toast-copied toast-index-80 align-items-center text-bg-secondary border-0 position-absolute top-0 end-0" role="alert" aria-live="assertive" aria-atomic="true">
  <div class="d-flex">
    <div class="toast-body">
      Copied!
    </div>
  </div>
</div>

---
Primary Category: cs.LG  
Categories: cs-AI, cs-LG, cs-NA, cs.LG, math-NA  
Keyword Score: 20  
Keywords: Transformer, Self-Attention  
<a type="button" class="btn btn-outline-primary" href="http://arxiv.org/abs/2402.07901v1" target="_blank" >Paper Link</a>
<button type="button" class="btn btn-outline-primary download-pdf" url="https://arxiv.org/pdf/2402.07901v1.pdf" filename="2402.07901v1.pdf">Download PDF</button>

---


**ABSTRACT**  
Motivated by the factorization inherent in the original fast multipole method and the improved fast Gauss transform we introduce a factorable form of attention that operates efficiently in high dimensions. This approach reduces the computational and memory complexity of the attention mechanism in <b>transformers</b> from $O(N^2)$ to $O(N)$. In comparison to previous attempts, our work presents a linearly scaled attention mechanism that maintains the full representation of the attention matrix without compromising on sparsification and incorporates the all-to-all relationship between tokens. We explore the properties of our new attention metric and conduct tests in various standard settings. Results indicate that our attention mechanism has a robust performance and holds significant promise for diverse applications where <b>self-attention</b> is used.

{{</citation>}}


### (81/210) Sourcerer: Sample-based Maximum Entropy Source Distribution Estimation (Julius Vetter et al., 2024)

{{<citation>}}

Julius Vetter, Guy Moss, Cornelius Schröder, Richard Gao, Jakob H. Macke. (2024)  
**Sourcerer: Sample-based Maximum Entropy Source Distribution Estimation**
<br/>
<button class="copy-to-clipboard" title="Sourcerer: Sample-based Maximum Entropy Source Distribution Estimation" index=81>
  <span class="copy-to-clipboard-item">Copy Title<span>
</button>
<div class="toast toast-copied toast-index-81 align-items-center text-bg-secondary border-0 position-absolute top-0 end-0" role="alert" aria-live="assertive" aria-atomic="true">
  <div class="d-flex">
    <div class="toast-body">
      Copied!
    </div>
  </div>
</div>

---
Primary Category: cs.LG  
Categories: cs-LG, cs.LG  
Keyword Score: 20  
Keywords: Simulation, Simulator  
<a type="button" class="btn btn-outline-primary" href="http://arxiv.org/abs/2402.07808v1" target="_blank" >Paper Link</a>
<button type="button" class="btn btn-outline-primary download-pdf" url="https://arxiv.org/pdf/2402.07808v1.pdf" filename="2402.07808v1.pdf">Download PDF</button>

---


**ABSTRACT**  
Scientific modeling applications often require estimating a distribution of parameters consistent with a dataset of observations - an inference task also known as source distribution estimation. This problem can be ill-posed, however, since many different source distributions might produce the same distribution of data-consistent <b>simulations.</b> To make a principled choice among many equally valid sources, we propose an approach which targets the maximum entropy distribution, i.e., prioritizes retaining as much uncertainty as possible. Our method is purely sample-based - leveraging the Sliced-Wasserstein distance to measure the discrepancy between the dataset and <b>simulations</b> - and thus suitable for simulators with intractable likelihoods. We benchmark our method on several tasks, and show that it can recover source distributions with substantially higher entropy without sacrificing the fidelity of the <b>simulations.</b> Finally, to demonstrate the utility of our approach, we infer source distributions for parameters of the Hodgkin-Huxley neuron model from experimental datasets with thousands of measurements. In summary, we propose a principled framework for inferring unique source distributions of scientific simulator parameters while retaining as much uncertainty as possible.

{{</citation>}}


### (82/210) Tighter Bounds on the Information Bottleneck with Application to Deep Learning (Nir Weingarten et al., 2024)

{{<citation>}}

Nir Weingarten, Zohar Yakhini, Moshe Butman, Ran Gilad-Bachrach. (2024)  
**Tighter Bounds on the Information Bottleneck with Application to Deep Learning**
<br/>
<button class="copy-to-clipboard" title="Tighter Bounds on the Information Bottleneck with Application to Deep Learning" index=82>
  <span class="copy-to-clipboard-item">Copy Title<span>
</button>
<div class="toast toast-copied toast-index-82 align-items-center text-bg-secondary border-0 position-absolute top-0 end-0" role="alert" aria-live="assertive" aria-atomic="true">
  <div class="d-flex">
    <div class="toast-body">
      Copied!
    </div>
  </div>
</div>

---
Primary Category: cs.LG  
Categories: 94A08, 94A10, 94A11, 68T06, 62B04, 62B08, I-2; E-4; I-4; I-7, cs-AI, cs-IT, cs-LG, cs.LG, math-IT  
Keyword Score: 20  
Keywords: Mutual Information, Adversarial Attack  
<a type="button" class="btn btn-outline-primary" href="http://arxiv.org/abs/2402.07639v1" target="_blank" >Paper Link</a>
<button type="button" class="btn btn-outline-primary download-pdf" url="https://arxiv.org/pdf/2402.07639v1.pdf" filename="2402.07639v1.pdf">Download PDF</button>

---


**ABSTRACT**  
Deep Neural Nets (DNNs) learn latent representations induced by their downstream task, objective function, and other parameters. The quality of the learned representations impacts the DNN's generalization ability and the coherence of the emerging latent space. The Information Bottleneck (IB) provides a hypothetically optimal framework for data modeling, yet it is often intractable. Recent efforts combined DNNs with the IB by applying VAE-inspired variational methods to approximate bounds on <b>mutual</b> <b>information,</b> resulting in improved robustness to <b>adversarial</b> <b>attacks.</b> This work introduces a new and tighter variational bound for the IB, improving performance of previous IB-inspired DNNs. These advancements strengthen the case for the IB and its variational approximations as a data modeling framework, and provide a simple method to significantly enhance the <b>adversarial</b> <b>robustness</b> of classifier DNNs.

{{</citation>}}


### (83/210) Unveiling Group-Specific Distributed Concept Drift: A Fairness Imperative in Federated Learning (Teresa Salazar et al., 2024)

{{<citation>}}

Teresa Salazar, João Gama, Helder Araújo, Pedro Henriques Abreu. (2024)  
**Unveiling Group-Specific Distributed Concept Drift: A Fairness Imperative in Federated Learning**
<br/>
<button class="copy-to-clipboard" title="Unveiling Group-Specific Distributed Concept Drift: A Fairness Imperative in Federated Learning" index=83>
  <span class="copy-to-clipboard-item">Copy Title<span>
</button>
<div class="toast toast-copied toast-index-83 align-items-center text-bg-secondary border-0 position-absolute top-0 end-0" role="alert" aria-live="assertive" aria-atomic="true">
  <div class="d-flex">
    <div class="toast-body">
      Copied!
    </div>
  </div>
</div>

---
Primary Category: cs.LG  
Categories: 68T01, I-2-m, cs-LG, cs.LG  
Keyword Score: 20  
Keywords: Fairness, Prompt  
<a type="button" class="btn btn-outline-primary" href="http://arxiv.org/abs/2402.07586v1" target="_blank" >Paper Link</a>
<button type="button" class="btn btn-outline-primary download-pdf" url="https://arxiv.org/pdf/2402.07586v1.pdf" filename="2402.07586v1.pdf">Download PDF</button>

---


**ABSTRACT**  
In the evolving field of machine learning, ensuring <b>fairness</b> has become a critical concern, <b>prompting</b> the development of algorithms designed to mitigate discriminatory outcomes in decision-making processes. However, achieving <b>fairness</b> in the presence of group-specific concept drift remains an unexplored frontier, and our research represents pioneering efforts in this regard. Group-specific concept drift refers to situations where one group experiences concept drift over time while another does not, leading to a decrease in <b>fairness</b> even if accuracy remains fairly stable. Within the framework of federated learning, where clients collaboratively train models, its distributed nature further amplifies these challenges since each client can experience group-specific concept drift independently while still sharing the same underlying concept, creating a complex and dynamic environment for maintaining <b>fairness.</b> One of the significant contributions of our research is the formalization and introduction of the problem of group-specific concept drift and its distributed counterpart, shedding light on its critical importance in the realm of <b>fairness.</b> In addition, leveraging insights from prior research, we adapt an existing distributed concept drift adaptation algorithm to tackle group-specific distributed concept drift which utilizes a multi-model approach, a local group-specific drift detection mechanism, and continuous clustering of models over time. The findings from our experiments highlight the importance of addressing group-specific concept drift and its distributed counterpart to advance <b>fairness</b> in machine learning.

{{</citation>}}


### (84/210) Weisfeiler-Leman at the margin: When more expressivity matters (Billy J. Franks et al., 2024)

{{<citation>}}

Billy J. Franks, Christopher Morris, Ameya Velingker, Floris Geerts. (2024)  
**Weisfeiler-Leman at the margin: When more expressivity matters**
<br/>
<button class="copy-to-clipboard" title="Weisfeiler-Leman at the margin: When more expressivity matters" index=84>
  <span class="copy-to-clipboard-item">Copy Title<span>
</button>
<div class="toast toast-copied toast-index-84 align-items-center text-bg-secondary border-0 position-absolute top-0 end-0" role="alert" aria-live="assertive" aria-atomic="true">
  <div class="d-flex">
    <div class="toast-body">
      Copied!
    </div>
  </div>
</div>

---
Primary Category: cs.LG  
Categories: cs-DM, cs-LG, cs-NE, cs.LG, stat-ML  
Keyword Score: 20  
Keywords: Message-Passing, Graph Neural Network  
<a type="button" class="btn btn-outline-primary" href="http://arxiv.org/abs/2402.07568v1" target="_blank" >Paper Link</a>
<button type="button" class="btn btn-outline-primary download-pdf" url="https://arxiv.org/pdf/2402.07568v1.pdf" filename="2402.07568v1.pdf">Download PDF</button>

---


**ABSTRACT**  
The Weisfeiler-Leman algorithm ($1$-WL) is a well-studied heuristic for the <b>graph</b> <b>isomorphism</b> <b>problem.</b> Recently, the algorithm has played a prominent role in understanding the expressive power of <b>message-passing</b> <b>graph</b> <b>neural</b> <b>networks</b> (MPNNs) and being effective as a <b>graph</b> <b>kernel.</b> <b>Despite</b> its success, $1$-WL faces challenges in distinguishing non-isomorphic <b>graphs,</b> <b>leading</b> <b>to</b> the development of more expressive MPNN and kernel architectures. However, the relationship between enhanced expressivity and improved generalization performance remains unclear. Here, we show that an architecture's expressivity offers limited insights into its generalization performance when viewed through <b>graph</b> <b>isomorphism.</b> <b>Moreover,</b> we focus on augmenting $1$-WL and MPNNs with subgraph information and employ classical margin theory to investigate the conditions under which an architecture's increased expressivity aligns with improved generalization performance. In addition, we show that gradient flow pushes the MPNN's weights toward the maximum margin solution. Further, we introduce variations of expressive $1$-WL-based kernel and MPNN architectures with provable generalization properties. Our empirical study confirms the validity of our theoretical findings.

{{</citation>}}


### (85/210) Understanding Deep Learning defenses Against Adversarial Examples Through Visualizations for Dynamic Risk Assessment (Xabier Echeberria-Barrio et al., 2024)

{{<citation>}}

Xabier Echeberria-Barrio, Amaia Gil-Lerchundi, Jon Egana-Zubia, Raul Orduna-Urrutia. (2024)  
**Understanding Deep Learning defenses Against Adversarial Examples Through Visualizations for Dynamic Risk Assessment**
<br/>
<button class="copy-to-clipboard" title="Understanding Deep Learning defenses Against Adversarial Examples Through Visualizations for Dynamic Risk Assessment" index=85>
  <span class="copy-to-clipboard-item">Copy Title<span>
</button>
<div class="toast toast-copied toast-index-85 align-items-center text-bg-secondary border-0 position-absolute top-0 end-0" role="alert" aria-live="assertive" aria-atomic="true">
  <div class="d-flex">
    <div class="toast-body">
      Copied!
    </div>
  </div>
</div>

---
Primary Category: cs.LG  
Categories: cs-CR, cs-LG, cs.LG  
Keyword Score: 20  
Keywords: Adversarial Learning, Convolution  
<a type="button" class="btn btn-outline-primary" href="http://arxiv.org/abs/2402.07496v1" target="_blank" >Paper Link</a>
<button type="button" class="btn btn-outline-primary download-pdf" url="https://arxiv.org/pdf/2402.07496v1.pdf" filename="2402.07496v1.pdf">Download PDF</button>

---


**ABSTRACT**  
In recent years, Deep Neural Network models have been developed in different fields, where they have brought many advances. However, they have also started to be used in tasks where risk is critical. A misdiagnosis of these models can lead to serious accidents or even death. This concern has led to an interest among researchers to study possible attacks on these models, discovering a long list of vulnerabilities, from which every model should be defended. The <b>adversarial</b> <b>example</b> attack is a widely known attack among researchers, who have developed several defenses to avoid such a threat. However, these defenses are as opaque as a deep neural network model, how they work is still unknown. This is why visualizing how they change the behavior of the target model is interesting in order to understand more precisely how the performance of the defended model is being modified. For this work, some defenses, against <b>adversarial</b> <b>example</b> attack, have been selected in order to visualize the behavior modification of each of them in the defended model. <b>Adversarial</b> <b>training,</b> dimensionality reduction and prediction similarity were the selected defenses, which have been developed using a model composed by <b>convolution</b> neural network layers and dense neural network layers. In each defense, the behavior of the original model has been compared with the behavior of the defended model, representing the target model by a graph in a visualization.

{{</citation>}}


### (86/210) Score-Based Physics-Informed Neural Networks for High-Dimensional Fokker-Planck Equations (Zheyuan Hu et al., 2024)

{{<citation>}}

Zheyuan Hu, Zhongqiang Zhang, George Em Karniadakis, Kenji Kawaguchi. (2024)  
**Score-Based Physics-Informed Neural Networks for High-Dimensional Fokker-Planck Equations**
<br/>
<button class="copy-to-clipboard" title="Score-Based Physics-Informed Neural Networks for High-Dimensional Fokker-Planck Equations" index=86>
  <span class="copy-to-clipboard-item">Copy Title<span>
</button>
<div class="toast toast-copied toast-index-86 align-items-center text-bg-secondary border-0 position-absolute top-0 end-0" role="alert" aria-live="assertive" aria-atomic="true">
  <div class="d-flex">
    <div class="toast-body">
      Copied!
    </div>
  </div>
</div>

---
Primary Category: cs.LG  
Categories: 14J60, cs-AI, cs-LG, cs-NA, cs.LG, math-DS, math-NA, stat-ML  
Keyword Score: 20  
Keywords: Simulation, Simulator  
<a type="button" class="btn btn-outline-primary" href="http://arxiv.org/abs/2402.07465v1" target="_blank" >Paper Link</a>
<button type="button" class="btn btn-outline-primary download-pdf" url="https://arxiv.org/pdf/2402.07465v1.pdf" filename="2402.07465v1.pdf">Download PDF</button>

---


**ABSTRACT**  
The Fokker-Planck (FP) equation is a foundational PDE in stochastic processes. However, curse of dimensionality (CoD) poses challenge when dealing with high-dimensional FP PDEs. Although Monte Carlo and vanilla Physics-Informed Neural Networks (PINNs) have shown the potential to tackle CoD, both methods exhibit numerical errors in high dimensions when dealing with the probability density function (PDF) associated with Brownian motion. The point-wise PDF values tend to decrease exponentially as dimension increases, surpassing the precision of numerical <b>simulations</b> and resulting in substantial errors. Moreover, due to its massive sampling, Monte Carlo fails to offer fast sampling. Modeling the logarithm likelihood (LL) via vanilla PINNs transforms the FP equation into a difficult HJB equation, whose error grows rapidly with dimension. To this end, we propose a novel approach utilizing a score-based solver to fit the score function in SDEs. The score function, defined as the gradient of the LL, plays a fundamental role in inferring LL and PDF and enables fast SDE sampling. Three fitting methods, Score Matching (SM), Sliced SM (SSM), and Score-PINN, are introduced. The proposed score-based SDE solver operates in two stages: first, employing SM, SSM, or Score-PINN to acquire the score; and second, solving the LL via an ODE using the obtained score. Comparative evaluations across these methods showcase varying trade-offs. The proposed method is evaluated across diverse SDEs, including anisotropic OU processes, geometric Brownian, and Brownian with varying eigenspace. We also test various distributions, including Gaussian, Log-normal, Laplace, and Cauchy. The numerical results demonstrate the score-based SDE solver's stability, speed, and performance across different settings, solidifying its potential as a solution to CoD for high-dimensional FP equations.

{{</citation>}}


### (87/210) The I/O Complexity of Attention, or How Optimal is Flash Attention? (Barna Saha et al., 2024)

{{<citation>}}

Barna Saha, Christopher Ye. (2024)  
**The I/O Complexity of Attention, or How Optimal is Flash Attention?**
<br/>
<button class="copy-to-clipboard" title="The I/O Complexity of Attention, or How Optimal is Flash Attention?" index=87>
  <span class="copy-to-clipboard-item">Copy Title<span>
</button>
<div class="toast toast-copied toast-index-87 align-items-center text-bg-secondary border-0 position-absolute top-0 end-0" role="alert" aria-live="assertive" aria-atomic="true">
  <div class="d-flex">
    <div class="toast-body">
      Copied!
    </div>
  </div>
</div>

---
Primary Category: cs.LG  
Categories: cs-CC, cs-DS, cs-IT, cs-LG, cs.LG, math-IT  
Keyword Score: 20  
Keywords: Transformer, Self-Attention  
<a type="button" class="btn btn-outline-primary" href="http://arxiv.org/abs/2402.07443v1" target="_blank" >Paper Link</a>
<button type="button" class="btn btn-outline-primary download-pdf" url="https://arxiv.org/pdf/2402.07443v1.pdf" filename="2402.07443v1.pdf">Download PDF</button>

---


**ABSTRACT**  
<b>Self-attention</b> is at the heart of the popular <b>Transformer</b> architecture, yet suffers from quadratic time and memory complexity. The breakthrough FlashAttention algorithm revealed I/O complexity as the true bottleneck in scaling <b>Transformers.</b> Given two levels of memory hierarchy, a fast cache (e.g. GPU on-chip SRAM) and a slow memory (e.g. GPU high-bandwidth memory), the I/O complexity measures the number of accesses to memory. FlashAttention computes attention using $\frac{N^2d^2}{M}$ I/O operations where $N$ is the dimension of the attention matrix, $d$ the head-dimension and $M$ the cache size. However, is this I/O complexity optimal? The known lower bound only rules out an I/O complexity of $o(Nd)$ when $M=\Theta(Nd)$, since the output that needs to be written to slow memory is $\Omega(Nd)$. This leads to the main question of our work: Is FlashAttention I/O optimal for all values of $M$? We resolve the above question in its full generality by showing an I/O complexity lower bound that matches the upper bound provided by FlashAttention for any values of $M \geq d^2$ within any constant factors. Further, we give a better algorithm with lower I/O complexity for $M < d^2$, and show that it is optimal as well. Moreover, our lower bounds do not rely on using combinatorial matrix multiplication for computing the attention matrix. We show even if one uses fast matrix multiplication, the above I/O complexity bounds cannot be improved. We do so by introducing a new communication complexity protocol for matrix compression, and connecting communication complexity to I/O complexity. To the best of our knowledge, this is the first work to establish a connection between communication complexity and I/O complexity, and we believe this connection could be of independent interest and will find many more applications in proving I/O complexity lower bounds in the future.

{{</citation>}}


### (88/210) Measurement Scheduling for ICU Patients with Offline Reinforcement Learning (Zongliang Ji et al., 2024)

{{<citation>}}

Zongliang Ji, Anna Goldenberg, Rahul G. Krishnan. (2024)  
**Measurement Scheduling for ICU Patients with Offline Reinforcement Learning**
<br/>
<button class="copy-to-clipboard" title="Measurement Scheduling for ICU Patients with Offline Reinforcement Learning" index=88>
  <span class="copy-to-clipboard-item">Copy Title<span>
</button>
<div class="toast toast-copied toast-index-88 align-items-center text-bg-secondary border-0 position-absolute top-0 end-0" role="alert" aria-live="assertive" aria-atomic="true">
  <div class="d-flex">
    <div class="toast-body">
      Copied!
    </div>
  </div>
</div>

---
Primary Category: cs.LG  
Categories: cs-AI, cs-LG, cs.LG  
Keyword Score: 20  
Keywords: Offline Reinforcement Learning, Reinforcement Learning  
<a type="button" class="btn btn-outline-primary" href="http://arxiv.org/abs/2402.07344v1" target="_blank" >Paper Link</a>
<button type="button" class="btn btn-outline-primary download-pdf" url="https://arxiv.org/pdf/2402.07344v1.pdf" filename="2402.07344v1.pdf">Download PDF</button>

---


**ABSTRACT**  
Scheduling laboratory tests for ICU patients presents a significant challenge. Studies show that 20-40% of lab tests ordered in the ICU are redundant and could be eliminated without compromising patient safety. Prior work has leveraged <b>offline</b> <b>reinforcement</b> <b>learning</b> <b>(Offline-RL)</b> <b>to</b> <b>find</b> optimal policies for ordering lab tests based on patient information. However, new ICU patient datasets have since been released, and various advancements have been made in <b>Offline-RL</b> <b>methods.</b> <b>In</b> this study, we first introduce a preprocessing pipeline for the newly-released MIMIC-IV dataset geared toward time-series tasks. We then explore the efficacy of state-of-the-art <b>Offline-RL</b> <b>methods</b> <b>in</b> identifying better policies for ICU patient lab test scheduling. Besides assessing methodological performance, we also discuss the overall suitability and practicality of using <b>Offline-RL</b> <b>frameworks</b> <b>for</b> scheduling laboratory tests in ICU settings.

{{</citation>}}


### (89/210) Efficient Contextual Bandits with Uninformed Feedback Graphs (Mengxiao Zhang et al., 2024)

{{<citation>}}

Mengxiao Zhang, Yuheng Zhang, Haipeng Luo, Paul Mineiro. (2024)  
**Efficient Contextual Bandits with Uninformed Feedback Graphs**
<br/>
<button class="copy-to-clipboard" title="Efficient Contextual Bandits with Uninformed Feedback Graphs" index=89>
  <span class="copy-to-clipboard-item">Copy Title<span>
</button>
<div class="toast toast-copied toast-index-89 align-items-center text-bg-secondary border-0 position-absolute top-0 end-0" role="alert" aria-live="assertive" aria-atomic="true">
  <div class="d-flex">
    <div class="toast-body">
      Copied!
    </div>
  </div>
</div>

---
Primary Category: cs.LG  
Categories: cs-LG, cs.LG  
Keyword Score: 10  
Keywords: Bandit Algorithm  
<a type="button" class="btn btn-outline-primary" href="http://arxiv.org/abs/2402.08127v1" target="_blank" >Paper Link</a>
<button type="button" class="btn btn-outline-primary download-pdf" url="https://arxiv.org/pdf/2402.08127v1.pdf" filename="2402.08127v1.pdf">Download PDF</button>

---


**ABSTRACT**  
<b>Bandits</b> with feedback graphs are powerful online learning models that interpolate between the full information and classic <b>bandit</b> problems, capturing many real-life applications. A recent work by Zhang et al. (2023) studies the contextual version of this problem and proposes an efficient and optimal algorithm via a reduction to online regression. However, their algorithm crucially relies on seeing the feedback graph before making each decision, while in many applications, the feedback graph is uninformed, meaning that it is either only revealed after the learner makes her decision or even never fully revealed at all. This work develops the first contextual algorithm for such uninformed settings, via an efficient reduction to online regression over both the losses and the graphs. Importantly, we show that it is critical to learn the graphs using log loss instead of squared loss to obtain favorable regret guarantees. We also demonstrate the empirical effectiveness of our algorithm on a bidding application using both synthetic and real-world data.

{{</citation>}}


### (90/210) Leveraging Digital Cousins for Ensemble Q-Learning in Large-Scale Wireless Networks (Talha Bozkus et al., 2024)

{{<citation>}}

Talha Bozkus, Urbashi Mitra. (2024)  
**Leveraging Digital Cousins for Ensemble Q-Learning in Large-Scale Wireless Networks**
<br/>
<button class="copy-to-clipboard" title="Leveraging Digital Cousins for Ensemble Q-Learning in Large-Scale Wireless Networks" index=90>
  <span class="copy-to-clipboard-item">Copy Title<span>
</button>
<div class="toast toast-copied toast-index-90 align-items-center text-bg-secondary border-0 position-absolute top-0 end-0" role="alert" aria-live="assertive" aria-atomic="true">
  <div class="d-flex">
    <div class="toast-body">
      Copied!
    </div>
  </div>
</div>

---
Primary Category: cs.LG  
Categories: cs-LG, cs-NI, cs.LG, eess-SP  
Keyword Score: 10  
Keywords: Reinforcement Learning  
<a type="button" class="btn btn-outline-primary" href="http://arxiv.org/abs/2402.08022v1" target="_blank" >Paper Link</a>
<button type="button" class="btn btn-outline-primary download-pdf" url="https://arxiv.org/pdf/2402.08022v1.pdf" filename="2402.08022v1.pdf">Download PDF</button>

---


**ABSTRACT**  
Optimizing large-scale wireless networks, including optimal resource management, power allocation, and throughput maximization, is inherently challenging due to their non-observable system dynamics and heterogeneous and complex nature. Herein, a novel ensemble Q-learning algorithm that addresses the performance and complexity challenges of the traditional Q-learning algorithm for optimizing wireless networks is presented. Ensemble learning with synthetic Markov Decision Processes is tailored to wireless networks via new models for approximating large state-space observable wireless networks. In particular, digital cousins are proposed as an extension of the traditional digital twin concept wherein multiple Q-learning algorithms on multiple synthetic Markovian environments are run in parallel and their outputs are fused into a single Q-function. Convergence analyses of key statistics and Q-functions and derivations of upper bounds on the estimation bias and variance are provided. Numerical results across a variety of real-world wireless networks show that the proposed algorithm can achieve up to 50% less average policy error with up to 40% less runtime complexity than the state-of-the-art <b>reinforcement</b> <b>learning</b> algorithms. It is also shown that theoretical results properly predict trends in the experimental results.

{{</citation>}}


### (91/210) Comparing skill of historical rainfall data based monsoon rainfall prediction in India with NCEP-NWP forecasts (Apoorva Narula et al., 2024)

{{<citation>}}

Apoorva Narula, Aastha Jain, Jatin Batra, Sandeep Juneja. (2024)  
**Comparing skill of historical rainfall data based monsoon rainfall prediction in India with NCEP-NWP forecasts**
<br/>
<button class="copy-to-clipboard" title="Comparing skill of historical rainfall data based monsoon rainfall prediction in India with NCEP-NWP forecasts" index=91>
  <span class="copy-to-clipboard-item">Copy Title<span>
</button>
<div class="toast toast-copied toast-index-91 align-items-center text-bg-secondary border-0 position-absolute top-0 end-0" role="alert" aria-live="assertive" aria-atomic="true">
  <div class="d-flex">
    <div class="toast-body">
      Copied!
    </div>
  </div>
</div>

---
Primary Category: cs.LG  
Categories: cs-LG, cs.LG  
Keyword Score: 10  
Keywords: Transformer  
<a type="button" class="btn btn-outline-primary" href="http://arxiv.org/abs/2402.07851v1" target="_blank" >Paper Link</a>
<button type="button" class="btn btn-outline-primary download-pdf" url="https://arxiv.org/pdf/2402.07851v1.pdf" filename="2402.07851v1.pdf">Download PDF</button>

---


**ABSTRACT**  
In this draft we consider the problem of forecasting rainfall across India during the four monsoon months, one day as well as three days in advance. We train neural networks using historical daily gridded precipitation data for India obtained from IMD for the time period $1901- 2022$, at a spatial resolution of $1^{\circ} \times 1^{\circ}$. This is compared with the numerical weather prediction (NWP) forecasts obtained from NCEP (National Centre for Environmental Prediction) available for the period 2011-2022. We conduct a detailed country wide analysis and separately analyze some of the most populated cities in India. Our conclusion is that forecasts obtained by applying deep learning to historical rainfall data are more accurate compared to NWP forecasts as well as predictions based on persistence. On average, compared to our predictions, forecasts from NCEP-NWP model have about 34% higher error for a single day prediction, and over 68% higher error for a three day prediction. Similarly, persistence estimates report a 29% higher error in a single day forecast, and over 54% error in a three day forecast. We further observe that data up to 20 days in the past is useful in reducing errors of one and three day forecasts, when a <b>transformer</b> based learning architecture, and to a lesser extent when an LSTM is used. A key conclusion suggested by our preliminary analysis is that NWP forecasts can be substantially improved upon through more and diverse data relevant to monsoon prediction combined with carefully selected neural network architecture.

{{</citation>}}


### (92/210) HYPO: Hyperspherical Out-of-Distribution Generalization (Haoyue Bai et al., 2024)

{{<citation>}}

Haoyue Bai, Yifei Ming, Julian Katz-Samuels, Yixuan Li. (2024)  
**HYPO: Hyperspherical Out-of-Distribution Generalization**
<br/>
<button class="copy-to-clipboard" title="HYPO: Hyperspherical Out-of-Distribution Generalization" index=92>
  <span class="copy-to-clipboard-item">Copy Title<span>
</button>
<div class="toast toast-copied toast-index-92 align-items-center text-bg-secondary border-0 position-absolute top-0 end-0" role="alert" aria-live="assertive" aria-atomic="true">
  <div class="d-flex">
    <div class="toast-body">
      Copied!
    </div>
  </div>
</div>

---
Primary Category: cs.LG  
Categories: cs-LG, cs.LG  
Keyword Score: 10  
Keywords: Out-of-distribution  
<a type="button" class="btn btn-outline-primary" href="http://arxiv.org/abs/2402.07785v1" target="_blank" >Paper Link</a>
<button type="button" class="btn btn-outline-primary download-pdf" url="https://arxiv.org/pdf/2402.07785v1.pdf" filename="2402.07785v1.pdf">Download PDF</button>

---


**ABSTRACT**  
<b>Out-of-distribution</b> (OOD) generalization is critical for machine learning models deployed in the real world. However, achieving this can be fundamentally challenging, as it requires the ability to learn invariant features across different domains or environments. In this paper, we propose a novel framework HYPO (HYPerspherical OOD generalization) that provably learns domain-invariant representations in a hyperspherical space. In particular, our hyperspherical learning algorithm is guided by intra-class variation and inter-class separation principles -- ensuring that features from the same class (across different training domains) are closely aligned with their class prototypes, while different class prototypes are maximally separated. We further provide theoretical justifications on how our prototypical learning objective improves the OOD generalization bound. Through extensive experiments on challenging OOD benchmarks, we demonstrate that our approach outperforms competitive baselines and achieves superior performance. Code is available at https://github.com/deeplearning-wisc/hypo.

{{</citation>}}


### (93/210) Near-Minimax-Optimal Distributional Reinforcement Learning with a Generative Model (Mark Rowland et al., 2024)

{{<citation>}}

Mark Rowland, Li Kevin Wenliang, Rémi Munos, Clare Lyle, Yunhao Tang, Will Dabney. (2024)  
**Near-Minimax-Optimal Distributional Reinforcement Learning with a Generative Model**
<br/>
<button class="copy-to-clipboard" title="Near-Minimax-Optimal Distributional Reinforcement Learning with a Generative Model" index=93>
  <span class="copy-to-clipboard-item">Copy Title<span>
</button>
<div class="toast toast-copied toast-index-93 align-items-center text-bg-secondary border-0 position-absolute top-0 end-0" role="alert" aria-live="assertive" aria-atomic="true">
  <div class="d-flex">
    <div class="toast-body">
      Copied!
    </div>
  </div>
</div>

---
Primary Category: cs.LG  
Categories: cs-LG, cs.LG, stat-ML  
Keyword Score: 10  
Keywords: Reinforcement Learning  
<a type="button" class="btn btn-outline-primary" href="http://arxiv.org/abs/2402.07598v1" target="_blank" >Paper Link</a>
<button type="button" class="btn btn-outline-primary download-pdf" url="https://arxiv.org/pdf/2402.07598v1.pdf" filename="2402.07598v1.pdf">Download PDF</button>

---


**ABSTRACT**  
We propose a new algorithm for model-based distributional <b>reinforcement</b> <b>learning</b> (RL), and prove that it is minimax-optimal for approximating return distributions with a generative model (up to logarithmic factors), resolving an open question of Zhang et al. (2023). Our analysis provides new theoretical results on categorical approaches to distributional RL, and also introduces a new distributional Bellman equation, the stochastic categorical CDF Bellman equation, which we expect to be of independent interest. We also provide an experimental study comparing several model-based distributional RL algorithms, with several takeaways for practitioners.

{{</citation>}}


### (94/210) Accelerated Smoothing: A Scalable Approach to Randomized Smoothing (Devansh Bhardwaj et al., 2024)

{{<citation>}}

Devansh Bhardwaj, Kshitiz Kaushik, Sarthak Gupta. (2024)  
**Accelerated Smoothing: A Scalable Approach to Randomized Smoothing**
<br/>
<button class="copy-to-clipboard" title="Accelerated Smoothing: A Scalable Approach to Randomized Smoothing" index=94>
  <span class="copy-to-clipboard-item">Copy Title<span>
</button>
<div class="toast toast-copied toast-index-94 align-items-center text-bg-secondary border-0 position-absolute top-0 end-0" role="alert" aria-live="assertive" aria-atomic="true">
  <div class="d-flex">
    <div class="toast-body">
      Copied!
    </div>
  </div>
</div>

---
Primary Category: cs.LG  
Categories: cs-LG, cs.LG  
Keyword Score: 10  
Keywords: Adversarial Attack  
<a type="button" class="btn btn-outline-primary" href="http://arxiv.org/abs/2402.07498v1" target="_blank" >Paper Link</a>
<button type="button" class="btn btn-outline-primary download-pdf" url="https://arxiv.org/pdf/2402.07498v1.pdf" filename="2402.07498v1.pdf">Download PDF</button>

---


**ABSTRACT**  
Randomized smoothing has emerged as a potent certifiable defense against <b>adversarial</b> <b>attacks</b> by employing smoothing noises from specific distributions to ensure the robustness of a smoothed classifier. However, the utilization of Monte Carlo sampling in this process introduces a compute-intensive element, which constrains the practicality of randomized smoothing on a larger scale. To address this limitation, we propose a novel approach that replaces Monte Carlo sampling with the training of a surrogate neural network. Through extensive experimentation in various settings, we demonstrate the efficacy of our approach in approximating the smoothed classifier with remarkable precision. Furthermore, we demonstrate that our approach significantly accelerates the robust radius certification process, providing nearly $600$X improvement in computation time, overcoming the computational bottlenecks associated with traditional randomized smoothing.

{{</citation>}}


### (95/210) Score-based Diffusion Models via Stochastic Differential Equations -- a Technical Tutorial (Wenpin Tang et al., 2024)

{{<citation>}}

Wenpin Tang, Hanyang Zhao. (2024)  
**Score-based Diffusion Models via Stochastic Differential Equations -- a Technical Tutorial**
<br/>
<button class="copy-to-clipboard" title="Score-based Diffusion Models via Stochastic Differential Equations -- a Technical Tutorial" index=95>
  <span class="copy-to-clipboard-item">Copy Title<span>
</button>
<div class="toast toast-copied toast-index-95 align-items-center text-bg-secondary border-0 position-absolute top-0 end-0" role="alert" aria-live="assertive" aria-atomic="true">
  <div class="d-flex">
    <div class="toast-body">
      Copied!
    </div>
  </div>
</div>

---
Primary Category: cs.LG  
Categories: cs-LG, cs.LG, math-HO  
Keyword Score: 10  
Keywords: Reinforcement Learning  
<a type="button" class="btn btn-outline-primary" href="http://arxiv.org/abs/2402.07487v1" target="_blank" >Paper Link</a>
<button type="button" class="btn btn-outline-primary download-pdf" url="https://arxiv.org/pdf/2402.07487v1.pdf" filename="2402.07487v1.pdf">Download PDF</button>

---


**ABSTRACT**  
This is an expository article on the score-based diffusion models, with a particular focus on the formulation via stochastic differential equations (SDE). After a gentle introduction, we discuss the two pillars in the diffusion modeling -- sampling and score matching, which encompass the SDE/ODE sampling, score matching efficiency, the consistency model, and <b>reinforcement</b> <b>learning.</b> Short proofs are given to illustrate the main idea of the stated results. The article is primarily for introducing the beginners to the field, and practitioners may also find some analysis useful in designing new models or algorithms.

{{</citation>}}


### (96/210) Bandit-Feedback Online Multiclass Classification: Variants and Tradeoffs (Yuval Filmus et al., 2024)

{{<citation>}}

Yuval Filmus, Steve Hanneke, Idan Mehalel, Shay Moran. (2024)  
**Bandit-Feedback Online Multiclass Classification: Variants and Tradeoffs**
<br/>
<button class="copy-to-clipboard" title="Bandit-Feedback Online Multiclass Classification: Variants and Tradeoffs" index=96>
  <span class="copy-to-clipboard-item">Copy Title<span>
</button>
<div class="toast toast-copied toast-index-96 align-items-center text-bg-secondary border-0 position-absolute top-0 end-0" role="alert" aria-live="assertive" aria-atomic="true">
  <div class="d-flex">
    <div class="toast-body">
      Copied!
    </div>
  </div>
</div>

---
Primary Category: cs.LG  
Categories: cs-LG, cs.LG, stat-ML  
Keyword Score: 10  
Keywords: Bandit Algorithm  
<a type="button" class="btn btn-outline-primary" href="http://arxiv.org/abs/2402.07453v1" target="_blank" >Paper Link</a>
<button type="button" class="btn btn-outline-primary download-pdf" url="https://arxiv.org/pdf/2402.07453v1.pdf" filename="2402.07453v1.pdf">Download PDF</button>

---


**ABSTRACT**  
Consider the domain of multiclass classification within the adversarial online setting. What is the price of relying on <b>bandit</b> feedback as opposed to full information? To what extent can an adaptive adversary amplify the loss compared to an oblivious one? To what extent can a randomized learner reduce the loss compared to a deterministic one? We study these questions in the mistake bound model and provide nearly tight answers. We demonstrate that the optimal mistake bound under <b>bandit</b> feedback is at most $O(k)$ times higher than the optimal mistake bound in the full information case, where $k$ represents the number of labels. This bound is tight and provides an answer to an open question previously posed and studied by Daniely and Helbertal ['13] and by Long ['17, '20], who focused on deterministic learners. Moreover, we present nearly optimal bounds of $\tilde{\Theta}(k)$ on the gap between randomized and deterministic learners, as well as between adaptive and oblivious adversaries in the <b>bandit</b> feedback setting. This stands in contrast to the full information scenario, where adaptive and oblivious adversaries are equivalent, and the gap in mistake bounds between randomized and deterministic learners is a constant multiplicative factor of $2$. In addition, our results imply that in some cases the optimal randomized mistake bound is approximately the square-root of its deterministic parallel. Previous results show that this is essentially the smallest it can get.

{{</citation>}}


### (97/210) Context-aware Multi-Model Object Detection for Diversely Heterogeneous Compute Systems (Justin Davis et al., 2024)

{{<citation>}}

Justin Davis, Mehmet E. Belviranli. (2024)  
**Context-aware Multi-Model Object Detection for Diversely Heterogeneous Compute Systems**
<br/>
<button class="copy-to-clipboard" title="Context-aware Multi-Model Object Detection for Diversely Heterogeneous Compute Systems" index=97>
  <span class="copy-to-clipboard-item">Copy Title<span>
</button>
<div class="toast toast-copied toast-index-97 align-items-center text-bg-secondary border-0 position-absolute top-0 end-0" role="alert" aria-live="assertive" aria-atomic="true">
  <div class="d-flex">
    <div class="toast-body">
      Copied!
    </div>
  </div>
</div>

---
Primary Category: cs.LG  
Categories: cs-CV, cs-LG, cs-RO, cs.LG  
Keyword Score: 10  
Keywords: Object Detection  
<a type="button" class="btn btn-outline-primary" href="http://arxiv.org/abs/2402.07415v1" target="_blank" >Paper Link</a>
<button type="button" class="btn btn-outline-primary download-pdf" url="https://arxiv.org/pdf/2402.07415v1.pdf" filename="2402.07415v1.pdf">Download PDF</button>

---


**ABSTRACT**  
In recent years, deep neural networks (DNNs) have gained widespread adoption for continuous mobile <b>object</b> <b>detection</b> (OD) tasks, particularly in autonomous systems. However, a prevalent issue in their deployment is the one-size-fits-all approach, where a single DNN is used, resulting in inefficient utilization of computational resources. This inefficiency is particularly detrimental in energy-constrained systems, as it degrades overall system efficiency. We identify that, the contextual information embedded in the input data stream (e.g. the frames in the camera feed that the OD models are run on) could be exploited to allow a more efficient multi-model-based OD process. In this paper, we propose SHIFT which continuously selects from a variety of DNN-based OD models depending on the dynamically changing contextual information and computational constraints. During this selection, SHIFT uniquely considers multi-accelerator execution to better optimize the energy-efficiency while satisfying the latency constraints. Our proposed methodology results in improvements of up to 7.5x in energy usage and 2.8x in latency compared to state-of-the-art GPU-based single model OD approaches.

{{</citation>}}


### (98/210) Auxiliary Reward Generation with Transition Distance Representation Learning (Siyuan Li et al., 2024)

{{<citation>}}

Siyuan Li, Shijie Han, Yingnan Zhao, By Liang, Peng Liu. (2024)  
**Auxiliary Reward Generation with Transition Distance Representation Learning**
<br/>
<button class="copy-to-clipboard" title="Auxiliary Reward Generation with Transition Distance Representation Learning" index=98>
  <span class="copy-to-clipboard-item">Copy Title<span>
</button>
<div class="toast toast-copied toast-index-98 align-items-center text-bg-secondary border-0 position-absolute top-0 end-0" role="alert" aria-live="assertive" aria-atomic="true">
  <div class="d-flex">
    <div class="toast-body">
      Copied!
    </div>
  </div>
</div>

---
Primary Category: cs.LG  
Categories: cs-AI, cs-LG, cs.LG  
Keyword Score: 10  
Keywords: Reinforcement Learning  
<a type="button" class="btn btn-outline-primary" href="http://arxiv.org/abs/2402.07412v1" target="_blank" >Paper Link</a>
<button type="button" class="btn btn-outline-primary download-pdf" url="https://arxiv.org/pdf/2402.07412v1.pdf" filename="2402.07412v1.pdf">Download PDF</button>

---


**ABSTRACT**  
<b>Reinforcement</b> <b>learning</b> (RL) has shown its strength in challenging sequential decision-making problems. The reward function in RL is crucial to the learning performance, as it serves as a measure of the task completion degree. In real-world problems, the rewards are predominantly human-designed, which requires laborious tuning, and is easily affected by human cognitive biases. To achieve automatic auxiliary reward generation, we propose a novel representation learning approach that can measure the ``transition distance'' between states. Building upon these representations, we introduce an auxiliary reward generation technique for both single-task and skill-chaining scenarios without the need for human knowledge. The proposed approach is evaluated in a wide range of manipulation tasks. The experiment results demonstrate the effectiveness of measuring the transition distance between states and the induced improvement by auxiliary rewards, which not only promotes better learning efficiency but also increases convergent stability.

{{</citation>}}


### (99/210) Data Distribution-based Curriculum Learning (Shonal Chaudhry et al., 2024)

{{<citation>}}

Shonal Chaudhry, Anuraganand Sharma. (2024)  
**Data Distribution-based Curriculum Learning**
<br/>
<button class="copy-to-clipboard" title="Data Distribution-based Curriculum Learning" index=99>
  <span class="copy-to-clipboard-item">Copy Title<span>
</button>
<div class="toast toast-copied toast-index-99 align-items-center text-bg-secondary border-0 position-absolute top-0 end-0" role="alert" aria-live="assertive" aria-atomic="true">
  <div class="d-flex">
    <div class="toast-body">
      Copied!
    </div>
  </div>
</div>

---
Primary Category: cs.LG  
Categories: cs-LG, cs.LG  
Keyword Score: 10  
Keywords: Curriculum Learning  
<a type="button" class="btn btn-outline-primary" href="http://arxiv.org/abs/2402.07352v1" target="_blank" >Paper Link</a>
<button type="button" class="btn btn-outline-primary download-pdf" url="https://arxiv.org/pdf/2402.07352v1.pdf" filename="2402.07352v1.pdf">Download PDF</button>

---


**ABSTRACT**  
The order of training samples can have a significant impact on the performance of a classifier. <b>Curriculum</b> <b>learning</b> is a method of ordering training samples from easy to hard. This paper proposes the novel idea of a <b>curriculum</b> <b>learning</b> approach called Data Distribution-based <b>Curriculum</b> <b>Learning</b> (DDCL). DDCL uses the data distribution of a dataset to build a <b>curriculum</b> <b>based</b> on the order of samples. Two types of scoring methods known as DDCL (Density) and DDCL (Point) are used to score training samples thus determining their training order. DDCL (Density) uses the sample density to assign scores while DDCL (Point) utilises the Euclidean distance for scoring. We evaluate the proposed DDCL approach by conducting experiments on multiple datasets using a neural network, support vector machine and random forest classifier. Evaluation results show that the application of DDCL improves the average classification accuracy for all datasets compared to standard evaluation without any <b>curriculum.</b> <b>Moreover,</b> analysis of the error losses for a single training epoch reveals that convergence is faster when using DDCL over the no <b>curriculum</b> <b>method.</b>

{{</citation>}}


### (100/210) Random Geometric Graph Alignment with Graph Neural Networks (Suqi Liu et al., 2024)

{{<citation>}}

Suqi Liu, Morgane Austern. (2024)  
**Random Geometric Graph Alignment with Graph Neural Networks**
<br/>
<button class="copy-to-clipboard" title="Random Geometric Graph Alignment with Graph Neural Networks" index=100>
  <span class="copy-to-clipboard-item">Copy Title<span>
</button>
<div class="toast toast-copied toast-index-100 align-items-center text-bg-secondary border-0 position-absolute top-0 end-0" role="alert" aria-live="assertive" aria-atomic="true">
  <div class="d-flex">
    <div class="toast-body">
      Copied!
    </div>
  </div>
</div>

---
Primary Category: cs.LG  
Categories: cs-IT, cs-LG, cs-SI, cs.LG, math-IT, math-PR, math-ST, stat-ML, stat-TH  
Keyword Score: 10  
Keywords: Graph Neural Network  
<a type="button" class="btn btn-outline-primary" href="http://arxiv.org/abs/2402.07340v1" target="_blank" >Paper Link</a>
<button type="button" class="btn btn-outline-primary download-pdf" url="https://arxiv.org/pdf/2402.07340v1.pdf" filename="2402.07340v1.pdf">Download PDF</button>

---


**ABSTRACT**  
We characterize the performance of <b>graph</b> <b>neural</b> <b>networks</b> for <b>graph</b> <b>alignment</b> <b>problems</b> in the presence of vertex feature information. More specifically, given two <b>graphs</b> <b>that</b> <b>are</b> independent perturbations of a single random geometric <b>graph</b> <b>with</b> <b>noisy</b> sparse features, the task is to recover an unknown one-to-one mapping between the vertices of the two <b>graphs.</b> <b>We</b> <b>show</b> under certain conditions on the sparsity and noise level of the feature vectors, a carefully designed one-layer <b>graph</b> <b>neural</b> <b>network</b> can with high probability recover the correct alignment between the vertices with the help of the <b>graph</b> <b>structure.</b> <b>We</b> also prove that our conditions on the noise level are tight up to logarithmic factors. Finally we compare the performance of the <b>graph</b> <b>neural</b> <b>network</b> to directly solving an assignment problem on the noisy vertex features. We demonstrate that when the noise level is at least constant this direct matching fails to have perfect recovery while the <b>graph</b> <b>neural</b> <b>network</b> can tolerate noise level growing as fast as a power of the size of the graph.

{{</citation>}}


## cs.AR (2)



### (101/210) IR-Aware ECO Timing Optimization Using Reinforcement Learning (Vidya A. Chhabria et al., 2024)

{{<citation>}}

Vidya A. Chhabria, Wenjing Jiang, Sachin S. Sapatnekar. (2024)  
**IR-Aware ECO Timing Optimization Using Reinforcement Learning**
<br/>
<button class="copy-to-clipboard" title="IR-Aware ECO Timing Optimization Using Reinforcement Learning" index=101>
  <span class="copy-to-clipboard-item">Copy Title<span>
</button>
<div class="toast toast-copied toast-index-101 align-items-center text-bg-secondary border-0 position-absolute top-0 end-0" role="alert" aria-live="assertive" aria-atomic="true">
  <div class="d-flex">
    <div class="toast-body">
      Copied!
    </div>
  </div>
</div>

---
Primary Category: cs.AR  
Categories: cs-AR, cs-LG, cs.AR  
Keyword Score: 70  
Keywords: Graph Convolutional Network, Convolution, Convolutional Neural Network, Fine-tuning, Reinforcement Learning, Zero-shot, Zero-shot Learning  
<a type="button" class="btn btn-outline-primary" href="http://arxiv.org/abs/2402.07781v1" target="_blank" >Paper Link</a>
<button type="button" class="btn btn-outline-primary download-pdf" url="https://arxiv.org/pdf/2402.07781v1.pdf" filename="2402.07781v1.pdf">Download PDF</button>

---


**ABSTRACT**  
Engineering change orders (ECOs) in late stages make minimal design fixes to recover from timing shifts due to excessive IR drops. This paper integrates IR-drop-aware timing analysis and ECO timing optimization using <b>reinforcement</b> <b>learning</b> (RL). The method operates after physical design and power grid synthesis, and rectifies IR-drop-induced timing degradation through gate sizing. It incorporates the Lagrangian relaxation (LR) technique into a novel RL framework, which trains a relational <b>graph</b> <b>convolutional</b> <b>network</b> (R-GCN) agent to sequentially size gates to fix timing violations. The R-GCN agent outperforms a classical LR-only algorithm: in an open 45nm technology, it (a) moves the Pareto front of the delay-area tradeoff curve to the left and (b) saves runtime over the classical method by running fast inference using trained models at iso-quality. The RL model is transferable across timing specifications, and transferable to unseen designs with <b>zero-shot</b> <b>learning</b> or fine tuning.

{{</citation>}}


### (102/210) LFOC+: A Fair OS-level Cache-Clustering Policy for Commodity Multicore Systems (Juan Carlos Saez et al., 2024)

{{<citation>}}

Juan Carlos Saez, Fernando Castro, Graziano Fanizzi, Manuel Prieto-Matias. (2024)  
**LFOC+: A Fair OS-level Cache-Clustering Policy for Commodity Multicore Systems**
<br/>
<button class="copy-to-clipboard" title="LFOC+: A Fair OS-level Cache-Clustering Policy for Commodity Multicore Systems" index=102>
  <span class="copy-to-clipboard-item">Copy Title<span>
</button>
<div class="toast toast-copied toast-index-102 align-items-center text-bg-secondary border-0 position-absolute top-0 end-0" role="alert" aria-live="assertive" aria-atomic="true">
  <div class="d-flex">
    <div class="toast-body">
      Copied!
    </div>
  </div>
</div>

---
Primary Category: cs.AR  
Categories: cs-AR, cs.AR  
Keyword Score: 30  
Keywords: Fairness, Simulation, Simulator  
<a type="button" class="btn btn-outline-primary" href="http://arxiv.org/abs/2402.07693v1" target="_blank" >Paper Link</a>
<button type="button" class="btn btn-outline-primary download-pdf" url="https://arxiv.org/pdf/2402.07693v1.pdf" filename="2402.07693v1.pdf">Download PDF</button>

---


**ABSTRACT**  
Commodity multicore systems are increasingly adopting hardware support that enables the system software to partition the last-level cache (LLC). This support makes it possible for the operating system (OS) or the Virtual Machine Monitor (VMM) to mitigate shared-resource contention effects on multicores by assigning different co-running applications to various cache partitions. Recently cache-clustering (or partition-sharing) strategies have emerged as a way to improve system throughput and <b>fairness</b> on new platforms with cache-partitioning support. As opposed to strict cache-partitioning, which allocates separate cache partitions to each application, cache-clustering allows partitions to be shared by a group of applications. In this article we propose LFOC+, a <b>fairness-aware</b> OS-level cache-clustering policy for commodity multicore systems. LFOC+ tries to mimic the behavior of the optimal cache-clustering solution for <b>fairness,</b> which we could obtain for different workload scenarios by using a <b>simulation</b> tool. Our dynamic cache-clustering strategy continuously gathers data from performance monitoring counters to classify applications at runtime based on the degree of cache sensitivity and contentiousness, and effectively separates cache-sensitive applications from aggressor programs to improve <b>fairness,</b> while providing acceptable system throughput. We implemented LFOC+ in the Linux kernel and evaluated it on a real system featuring an Intel Skylake processor, where we compare its effectiveness to that of four previously proposed cache-clustering policies. Our experimental analysis reveals that LFOC+ constitutes a lightweight OS-level policy and improves <b>fairness</b> relative to two other state-of-the-art <b>fairness-aware</b> strategies --Dunn and LFOC--, by up to 22\% and up to 20.6\%, respectively, and by 9\% and 4.9\% on average.

{{</citation>}}


## cs.CR (7)



### (103/210) Large Language Models are Few-shot Generators: Proposing Hybrid Prompt Algorithm To Generate Webshell Escape Samples (Mingrui Ma et al., 2024)

{{<citation>}}

Mingrui Ma, Lansheng Han, Chunjie Zhou. (2024)  
**Large Language Models are Few-shot Generators: Proposing Hybrid Prompt Algorithm To Generate Webshell Escape Samples**
<br/>
<button class="copy-to-clipboard" title="Large Language Models are Few-shot Generators: Proposing Hybrid Prompt Algorithm To Generate Webshell Escape Samples" index=103>
  <span class="copy-to-clipboard-item">Copy Title<span>
</button>
<div class="toast toast-copied toast-index-103 align-items-center text-bg-secondary border-0 position-absolute top-0 end-0" role="alert" aria-live="assertive" aria-atomic="true">
  <div class="d-flex">
    <div class="toast-body">
      Copied!
    </div>
  </div>
</div>

---
Primary Category: cs.CR  
Categories: cs-AI, cs-CR, cs.CR  
Keyword Score: 70  
Keywords: Few-shot, GPT, GPT-4, Reasoning, Large Language Model, Large Language Model, Prompt  
<a type="button" class="btn btn-outline-primary" href="http://arxiv.org/abs/2402.07408v1" target="_blank" >Paper Link</a>
<button type="button" class="btn btn-outline-primary download-pdf" url="https://arxiv.org/pdf/2402.07408v1.pdf" filename="2402.07408v1.pdf">Download PDF</button>

---


**ABSTRACT**  
The frequent occurrence of cyber-attacks has made webshell attacks and defense gradually become a research hotspot in the field of network security. However, the lack of publicly available benchmark datasets and the over-reliance on manually defined rules for webshell escape sample generation have slowed down the progress of research related to webshell escape sample generation strategies and artificial intelligence-based webshell detection algorithms. To address the drawbacks of weak webshell sample escape capabilities, the lack of webshell datasets with complex malicious features, and to promote the development of webshell detection technology, we propose the Hybrid <b>Prompt</b> algorithm for webshell escape sample generation with the help of <b>large</b> <b>language</b> <b>models.</b> As a <b>prompt</b> algorithm specifically developed for webshell sample generation, the Hybrid <b>Prompt</b> algorithm not only combines various <b>prompt</b> ideas including Chain of Thought, Tree of Thought, but also incorporates various components such as webshell hierarchical module and <b>few-shot</b> example to facilitate the <b>LLM</b> in learning and <b>reasoning</b> webshell escape strategies. Experimental results show that the Hybrid <b>Prompt</b> algorithm can work with multiple <b>LLMs</b> with excellent code <b>reasoning</b> ability to generate high-quality webshell samples with high Escape Rate (88.61% with <b>GPT-4</b> model on VIRUSTOTAL detection engine) and Survival Rate (54.98% with <b>GPT-4</b> model).

{{</citation>}}


### (104/210) Resilient Watermarking for LLM-Generated Codes (Boquan Li et al., 2024)

{{<citation>}}

Boquan Li, Mengdi Zhang, Peixin Zhang, Jun Sun, Xingmei Wang. (2024)  
**Resilient Watermarking for LLM-Generated Codes**
<br/>
<button class="copy-to-clipboard" title="Resilient Watermarking for LLM-Generated Codes" index=104>
  <span class="copy-to-clipboard-item">Copy Title<span>
</button>
<div class="toast toast-copied toast-index-104 align-items-center text-bg-secondary border-0 position-absolute top-0 end-0" role="alert" aria-live="assertive" aria-atomic="true">
  <div class="d-flex">
    <div class="toast-body">
      Copied!
    </div>
  </div>
</div>

---
Primary Category: cs.CR  
Categories: cs-CR, cs.CR  
Keyword Score: 50  
Keywords: Fine-tuning, ChatGPT, Code Generation, Large Language Model, Large Language Model  
<a type="button" class="btn btn-outline-primary" href="http://arxiv.org/abs/2402.07518v1" target="_blank" >Paper Link</a>
<button type="button" class="btn btn-outline-primary download-pdf" url="https://arxiv.org/pdf/2402.07518v1.pdf" filename="2402.07518v1.pdf">Download PDF</button>

---


**ABSTRACT**  
With the development of <b>large</b> <b>language</b> <b>models,</b> multiple AIs are now made available for <b>code</b> <b>generation</b> (such as <b>ChatGPT</b> and StarCoder) and are adopted widely. It is often desirable to know whether a piece of <b>code</b> <b>is</b> generated by AI, and furthermore, which AI is the author. For instance, if a certain version of AI is known to generate vulnerable <b>code,</b> <b>it</b> is particularly important to know the creator. Existing approaches are not satisfactory as watermarking <b>codes</b> <b>are</b> challenging compared with watermarking text data, as <b>codes</b> <b>can</b> be altered with relative ease via widely-used <b>code</b> <b>refactoring</b> methods. In this work, we propose ACW (AI <b>Code</b> <b>Watermarking),</b> a novel method for watermarking AI-generated <b>codes.</b> <b>ACW</b> is efficient as it requires no training or <b>fine-tuning</b> and works in a black-box manner. It is resilient as the watermark cannot be easily removed or tampered through common <b>code</b> <b>refactoring</b> methods. The key idea of ACW is to selectively apply a set of carefully-designed semantic-preserving, idempotent <b>code</b> <b>transformations,</b> whose presence (or absence) allows us to determine the existence of the watermark. Our experimental results show that ACW is effective (i.e., achieving high accuracy, true positive rates and false positive rates), resilient and efficient, significantly outperforming existing approaches.

{{</citation>}}


### (105/210) Adaptive Artificial Immune Networks for Mitigating DoS flooding Attacks (Jorge Maestre Vidal et al., 2024)

{{<citation>}}

Jorge Maestre Vidal, Ana Lucila Sandoval Orozco, Luis Javier García Villalba. (2024)  
**Adaptive Artificial Immune Networks for Mitigating DoS flooding Attacks**
<br/>
<button class="copy-to-clipboard" title="Adaptive Artificial Immune Networks for Mitigating DoS flooding Attacks" index=105>
  <span class="copy-to-clipboard-item">Copy Title<span>
</button>
<div class="toast toast-copied toast-index-105 align-items-center text-bg-secondary border-0 position-absolute top-0 end-0" role="alert" aria-live="assertive" aria-atomic="true">
  <div class="d-flex">
    <div class="toast-body">
      Copied!
    </div>
  </div>
</div>

---
Primary Category: cs.CR  
Categories: cs-CR, cs.CR  
Keyword Score: 30  
Keywords: Knowledge Distillation, Simulation, Simulator  
<a type="button" class="btn btn-outline-primary" href="http://arxiv.org/abs/2402.07714v1" target="_blank" >Paper Link</a>
<button type="button" class="btn btn-outline-primary download-pdf" url="https://arxiv.org/pdf/2402.07714v1.pdf" filename="2402.07714v1.pdf">Download PDF</button>

---


**ABSTRACT**  
Denial of service attacks pose a threat in constant growth. This is mainly due to their tendency to gain in sophistication, ease of implementation, obfuscation and the recent improvements in occultation of fingerprints. On the other hand, progress towards self-organizing networks, and the different techniques involved in their development, such as software-defined networking, network-function virtualization, artificial intelligence or cloud computing, facilitates the design of new defensive strategies, more complete, consistent and able to adapt the defensive deployment to the current status of the network. In order to contribute to their development, in this paper, the use of artificial immune systems to mitigate denial of service attacks is proposed. The approach is based on building networks of distributed sensors suited to the requirements of the monitored environment. These components are capable of identifying threats and reacting according to the behavior of the biological defense mechanisms in human beings. It is accomplished by emulating the different immune reactions, the establishment of quarantine areas and the construction of immune memory. For their assessment, experiments with public domain datasets <b>(KDD'99,</b> CAIDA'07 and CAIDA'08) and <b>simulations</b> on various network configurations based on traffic samples gathered by the University Complutense of Madrid and flooding attacks generated by the tool DDoSIM were performed.

{{</citation>}}


### (106/210) PoisonedRAG: Knowledge Poisoning Attacks to Retrieval-Augmented Generation of Large Language Models (Wei Zou et al., 2024)

{{<citation>}}

Wei Zou, Runpeng Geng, Binghui Wang, Jinyuan Jia. (2024)  
**PoisonedRAG: Knowledge Poisoning Attacks to Retrieval-Augmented Generation of Large Language Models**
<br/>
<button class="copy-to-clipboard" title="PoisonedRAG: Knowledge Poisoning Attacks to Retrieval-Augmented Generation of Large Language Models" index=106>
  <span class="copy-to-clipboard-item">Copy Title<span>
</button>
<div class="toast toast-copied toast-index-106 align-items-center text-bg-secondary border-0 position-absolute top-0 end-0" role="alert" aria-live="assertive" aria-atomic="true">
  <div class="d-flex">
    <div class="toast-body">
      Copied!
    </div>
  </div>
</div>

---
Primary Category: cs.CR  
Categories: cs-CR, cs-LG, cs.CR  
Keyword Score: 20  
Keywords: Large Language Model, Large Language Model  
<a type="button" class="btn btn-outline-primary" href="http://arxiv.org/abs/2402.07867v1" target="_blank" >Paper Link</a>
<button type="button" class="btn btn-outline-primary download-pdf" url="https://arxiv.org/pdf/2402.07867v1.pdf" filename="2402.07867v1.pdf">Download PDF</button>

---


**ABSTRACT**  
<b>Large</b> <b>language</b> <b>models</b> <b>(LLMs)</b> have achieved remarkable success due to their exceptional generative capabilities. Despite their success, they also have inherent limitations such as a lack of up-to-date knowledge and hallucination. Retrieval-Augmented Generation (RAG) is a state-of-the-art technique to mitigate those limitations. In particular, given a question, RAG retrieves relevant knowledge from a knowledge database to augment the input of the <b>LLM.</b> For instance, the retrieved knowledge could be a set of top-k texts that are most semantically similar to the given question when the knowledge database contains millions of texts collected from Wikipedia. As a result, the <b>LLM</b> could utilize the retrieved knowledge as the context to generate an answer for the given question. Existing studies mainly focus on improving the accuracy or efficiency of RAG, leaving its security largely unexplored. We aim to bridge the gap in this work. Particularly, we propose PoisonedRAG , a set of knowledge poisoning attacks to RAG, where an attacker could inject a few poisoned texts into the knowledge database such that the <b>LLM</b> generates an attacker-chosen target answer for an attacker-chosen target question. We formulate knowledge poisoning attacks as an optimization problem, whose solution is a set of poisoned texts. Depending on the background knowledge (e.g., black-box and white-box settings) of an attacker on the RAG, we propose two solutions to solve the optimization problem, respectively. Our results on multiple benchmark datasets and <b>LLMs</b> show our attacks could achieve 90% attack success rates when injecting 5 poisoned texts for each target question into a database with millions of texts. We also evaluate recent defenses and our results show they are insufficient to defend against our attacks, highlighting the need for new defenses.

{{</citation>}}


### (107/210) Utilizing Large LanguageModels to Detect Privacy Leaks in Mini-App Code (Liming Jiang, 2024)

{{<citation>}}

Liming Jiang. (2024)  
**Utilizing Large LanguageModels to Detect Privacy Leaks in Mini-App Code**
<br/>
<button class="copy-to-clipboard" title="Utilizing Large LanguageModels to Detect Privacy Leaks in Mini-App Code" index=107>
  <span class="copy-to-clipboard-item">Copy Title<span>
</button>
<div class="toast toast-copied toast-index-107 align-items-center text-bg-secondary border-0 position-absolute top-0 end-0" role="alert" aria-live="assertive" aria-atomic="true">
  <div class="d-flex">
    <div class="toast-body">
      Copied!
    </div>
  </div>
</div>

---
Primary Category: cs.CR  
Categories: cs-CR, cs.CR  
Keyword Score: 20  
Keywords: Large Language Model, Large Language Model  
<a type="button" class="btn btn-outline-primary" href="http://arxiv.org/abs/2402.07367v1" target="_blank" >Paper Link</a>
<button type="button" class="btn btn-outline-primary download-pdf" url="https://arxiv.org/pdf/2402.07367v1.pdf" filename="2402.07367v1.pdf">Download PDF</button>

---


**ABSTRACT**  
Mini-applications, commonly referred to as mini-apps, are compact software programs embedded within larger applications or platforms, offering targeted functionality without the need for separate installations. Typically web-based or cloud-hosted, these mini-apps streamline user experiences by providing focused services accessible through web browsers or mobile apps. Their simplicity, speed, and integration capabilities make them valuable additions to messaging platforms, social media networks, e-commerce sites, and various digital environments. WeChat Mini Programs, a prominent feature of China's leading messaging app, exemplify this trend, offering users a seamless array of services without additional downloads. Leveraging WeChat's extensive user base and payment infrastructure, Mini Programs facilitate efficient transactions and bridge online and offline experiences, shaping China's digital landscape significantly. This paper investigates the potential of employing <b>Large</b> <b>Language</b> <b>Models</b> <b>(LLMs)</b> to detect privacy breaches within WeChat Mini Programs. Given the widespread use of Mini Programs and growing concerns about data privacy, this research seeks to determine if <b>LLMs</b> can effectively identify instances of privacy leakage within this ecosystem. Through meticulous analysis and experimentation, we aim to highlight the efficacy of <b>LLMs</b> in safeguarding user privacy and security within the WeChat Mini Program environment, thereby contributing to a more secure digital landscape.

{{</citation>}}


### (108/210) Discovering Universal Semantic Triggers for Text-to-Image Synthesis (Shengfang Zhai et al., 2024)

{{<citation>}}

Shengfang Zhai, Weilong Wang, Jiajun Li, Yinpeng Dong, Hang Su, Qingni Shen. (2024)  
**Discovering Universal Semantic Triggers for Text-to-Image Synthesis**
<br/>
<button class="copy-to-clipboard" title="Discovering Universal Semantic Triggers for Text-to-Image Synthesis" index=108>
  <span class="copy-to-clipboard-item">Copy Title<span>
</button>
<div class="toast toast-copied toast-index-108 align-items-center text-bg-secondary border-0 position-absolute top-0 end-0" role="alert" aria-live="assertive" aria-atomic="true">
  <div class="d-flex">
    <div class="toast-body">
      Copied!
    </div>
  </div>
</div>

---
Primary Category: cs.CR  
Categories: cs-AI, cs-CR, cs.CR  
Keyword Score: 10  
Keywords: Text2image  
<a type="button" class="btn btn-outline-primary" href="http://arxiv.org/abs/2402.07562v1" target="_blank" >Paper Link</a>
<button type="button" class="btn btn-outline-primary download-pdf" url="https://arxiv.org/pdf/2402.07562v1.pdf" filename="2402.07562v1.pdf">Download PDF</button>

---


**ABSTRACT**  
Recently <b>text-to-image</b> models have gained widespread attention in the community due to their controllable and high-quality generation ability. However, the robustness of such models and their potential ethical issues have not been fully explored. In this paper, we introduce Universal Semantic Trigger, a meaningless token sequence that can be added at any location within the input text yet can induce generated images towards a preset semantic target.To thoroughly investigate it, we propose Semantic Gradient-based Search (SGS) framework. SGS automatically discovers the potential universal semantic triggers based on the given semantic targets. Furthermore, we design evaluation metrics to comprehensively evaluate semantic shift of images caused by these triggers. And our empirical analyses reveal that the mainstream open-source <b>text-to-image</b> models are vulnerable to our triggers, which could pose significant ethical threats. Our work contributes to a further understanding of <b>text-to-image</b> synthesis and helps users to automatically auditing their models before deployment.

{{</citation>}}


### (109/210) Malicious Package Detection using Metadata Information (S. Halder et al., 2024)

{{<citation>}}

S. Halder, M. Bewong, A. Mahboubi, Y. Jiang, R. Islam, Z. Islam, R. Ip, E. Ahmed, G. Ramachandran, A. Babar. (2024)  
**Malicious Package Detection using Metadata Information**
<br/>
<button class="copy-to-clipboard" title="Malicious Package Detection using Metadata Information" index=109>
  <span class="copy-to-clipboard-item">Copy Title<span>
</button>
<div class="toast toast-copied toast-index-109 align-items-center text-bg-secondary border-0 position-absolute top-0 end-0" role="alert" aria-live="assertive" aria-atomic="true">
  <div class="d-flex">
    <div class="toast-body">
      Copied!
    </div>
  </div>
</div>

---
Primary Category: cs.CR  
Categories: cs-CR, cs.CR  
Keyword Score: 10  
Keywords: Adversarial Attack  
<a type="button" class="btn btn-outline-primary" href="http://arxiv.org/abs/2402.07444v1" target="_blank" >Paper Link</a>
<button type="button" class="btn btn-outline-primary download-pdf" url="https://arxiv.org/pdf/2402.07444v1.pdf" filename="2402.07444v1.pdf">Download PDF</button>

---


**ABSTRACT**  
Protecting software supply chains from malicious packages is paramount in the evolving landscape of software development. Attacks on the software supply chain involve attackers injecting harmful software into commonly used packages or libraries in a software repository. For instance, JavaScript uses Node Package Manager (NPM), and Python uses Python Package Index (PyPi) as their respective package repositories. In the past, NPM has had vulnerabilities such as the event-stream incident, where a malicious package was introduced into a popular NPM package, potentially impacting a wide range of projects. As the integration of third-party packages becomes increasingly ubiquitous in modern software development, accelerating the creation and deployment of applications, the need for a robust detection mechanism has become critical. On the other hand, due to the sheer volume of new packages being released daily, the task of identifying malicious packages presents a significant challenge. To address this issue, in this paper, we introduce a metadata-based malicious package detection model, MeMPtec. This model extracts a set of features from package metadata information. These extracted features are classified as either easy-to-manipulate (ETM) or difficult-to-manipulate (DTM) features based on monotonicity and restricted control properties. By utilising these metadata features, not only do we improve the effectiveness of detecting malicious packages, but also we demonstrate its resistance to <b>adversarial</b> <b>attacks</b> in comparison with existing state-of-the-art. Our experiments indicate a significant reduction in both false positives (up to 97.56%) and false negatives (up to 91.86%).

{{</citation>}}


## cs.AI (21)



### (110/210) SemTra: A Semantic Skill Translator for Cross-Domain Zero-Shot Policy Adaptation (Sangwoo Shin et al., 2024)

{{<citation>}}

Sangwoo Shin, Minjong Yoo, Jeongwoo Lee, Honguk Woo. (2024)  
**SemTra: A Semantic Skill Translator for Cross-Domain Zero-Shot Policy Adaptation**
<br/>
<button class="copy-to-clipboard" title="SemTra: A Semantic Skill Translator for Cross-Domain Zero-Shot Policy Adaptation" index=110>
  <span class="copy-to-clipboard-item">Copy Title<span>
</button>
<div class="toast toast-copied toast-index-110 align-items-center text-bg-secondary border-0 position-absolute top-0 end-0" role="alert" aria-live="assertive" aria-atomic="true">
  <div class="d-flex">
    <div class="toast-body">
      Copied!
    </div>
  </div>
</div>

---
Primary Category: cs.AI  
Categories: cs-AI, cs.AI  
Keyword Score: 63  
Keywords: Contrastive Learning, Multi-modal, Zero-shot, Reasoning, Pre-trained Language Model, Prompt, Zero-shot Learning  
<a type="button" class="btn btn-outline-primary" href="http://arxiv.org/abs/2402.07418v1" target="_blank" >Paper Link</a>
<button type="button" class="btn btn-outline-primary download-pdf" url="https://arxiv.org/pdf/2402.07418v1.pdf" filename="2402.07418v1.pdf">Download PDF</button>

---


**ABSTRACT**  
This work explores the <b>zero-shot</b> <b>adaptation</b> capability of semantic skills, semantically interpretable experts' behavior patterns, in cross-domain settings, where a user input in interleaved <b>multi-modal</b> snippets can <b>prompt</b> a new long-horizon task for different domains. In these cross-domain settings, we present a semantic skill translator framework SemTra which utilizes a set of <b>multi-modal</b> models to extract skills from the snippets, and leverages the <b>reasoning</b> capabilities of a <b>pretrained</b> <b>language</b> <b>model</b> to adapt these extracted skills to the target domain. The framework employs a two-level hierarchy for adaptation: task adaptation and skill adaptation. During task adaptation, seq-to-seq translation by the language model transforms the extracted skills into a semantic skill sequence, which is tailored to fit the cross-domain contexts. Skill adaptation focuses on optimizing each semantic skill for the target domain context, through parametric instantiations that are facilitated by language <b>prompting</b> and <b>contrastive</b> <b>learning-based</b> context inferences. This hierarchical adaptation empowers the framework to not only infer a complex task specification in one-shot from the interleaved <b>multi-modal</b> snippets, but also adapt it to new domains with <b>zero-shot</b> <b>learning</b> abilities. We evaluate our framework with Meta-World, Franka Kitchen, RLBench, and CARLA environments. The results clarify the framework's superiority in performing long-horizon tasks and adapting to different domains, showing its broad applicability in practical use cases, such as cognitive robots interpreting abstract instructions and autonomous vehicles operating under varied configurations.

{{</citation>}}


### (111/210) On the Self-Verification Limitations of Large Language Models on Reasoning and Planning Tasks (Kaya Stechly et al., 2024)

{{<citation>}}

Kaya Stechly, Karthik Valmeekam, Subbarao Kambhampati. (2024)  
**On the Self-Verification Limitations of Large Language Models on Reasoning and Planning Tasks**
<br/>
<button class="copy-to-clipboard" title="On the Self-Verification Limitations of Large Language Models on Reasoning and Planning Tasks" index=111>
  <span class="copy-to-clipboard-item">Copy Title<span>
</button>
<div class="toast toast-copied toast-index-111 align-items-center text-bg-secondary border-0 position-absolute top-0 end-0" role="alert" aria-live="assertive" aria-atomic="true">
  <div class="d-flex">
    <div class="toast-body">
      Copied!
    </div>
  </div>
</div>

---
Primary Category: cs.AI  
Categories: cs-AI, cs.AI  
Keyword Score: 60  
Keywords: GPT, GPT-4, Reasoning, Large Language Model, Large Language Model, Prompt  
<a type="button" class="btn btn-outline-primary" href="http://arxiv.org/abs/2402.08115v1" target="_blank" >Paper Link</a>
<button type="button" class="btn btn-outline-primary download-pdf" url="https://arxiv.org/pdf/2402.08115v1.pdf" filename="2402.08115v1.pdf">Download PDF</button>

---


**ABSTRACT**  
There has been considerable divergence of opinion on the <b>reasoning</b> abilities of <b>Large</b> <b>Language</b> <b>Models</b> <b>(LLMs).</b> While the initial optimism that <b>reasoning</b> might emerge automatically with scale has been tempered thanks to a slew of counterexamples--ranging from multiplication to simple planning--there persists a wide spread belief that <b>LLMs</b> can self-critique and improve their own solutions in an iterative fashion. This belief seemingly rests on the assumption that verification of correctness should be easier than generation--a rather classical argument from computational complexity--which should be irrelevant to <b>LLMs</b> to the extent that what they are doing is approximate retrieval. In this paper, we set out to systematically investigate the effectiveness of iterative <b>prompting</b> in the context of <b>reasoning</b> and planning. We present a principled empirical study of the performance of <b>GPT-4</b> in three domains: Game of 24, Graph Coloring, and STRIPS planning. We experiment both with the model critiquing its own answers and with an external correct reasoner verifying proposed solutions. In each case, we analyze whether the content of criticisms actually affects bottom line performance, and whether we can ablate elements of the augmented system without losing performance. We observe significant performance collapse with self-critique, significant performance gains with sound external verification, but that the content of critique doesn't matter to the performance of the system. In fact, merely re-prompting with a sound verifier maintains most of the benefits of more involved setups.

{{</citation>}}


### (112/210) CyberMetric: A Benchmark Dataset for Evaluating Large Language Models Knowledge in Cybersecurity (Norbert Tihanyi et al., 2024)

{{<citation>}}

Norbert Tihanyi, Mohamed Amine Ferrag, Ridhi Jain, Merouane Debbah. (2024)  
**CyberMetric: A Benchmark Dataset for Evaluating Large Language Models Knowledge in Cybersecurity**
<br/>
<button class="copy-to-clipboard" title="CyberMetric: A Benchmark Dataset for Evaluating Large Language Models Knowledge in Cybersecurity" index=112>
  <span class="copy-to-clipboard-item">Copy Title<span>
</button>
<div class="toast toast-copied toast-index-112 align-items-center text-bg-secondary border-0 position-absolute top-0 end-0" role="alert" aria-live="assertive" aria-atomic="true">
  <div class="d-flex">
    <div class="toast-body">
      Copied!
    </div>
  </div>
</div>

---
Primary Category: cs.AI  
Categories: cs-AI, cs-CR, cs.AI  
Keyword Score: 60  
Keywords: GPT, GPT-3, GPT-3.5, falcon, Large Language Model, Large Language Model  
<a type="button" class="btn btn-outline-primary" href="http://arxiv.org/abs/2402.07688v1" target="_blank" >Paper Link</a>
<button type="button" class="btn btn-outline-primary download-pdf" url="https://arxiv.org/pdf/2402.07688v1.pdf" filename="2402.07688v1.pdf">Download PDF</button>

---


**ABSTRACT**  
<b>Large</b> <b>Language</b> <b>Models</b> <b>(LLMs)</b> excel across various domains, from computer vision to medical diagnostics. However, understanding the diverse landscape of cybersecurity, encompassing cryptography, reverse engineering, and managerial facets like risk assessment, presents a challenge, even for human experts. In this paper, we introduce CyberMetric, a benchmark dataset comprising 10,000 questions sourced from standards, certifications, research papers, books, and other publications in the cybersecurity domain. The questions are created through a collaborative process, i.e., merging expert knowledge with <b>LLMs,</b> including <b>GPT-3.5</b> and <b>Falcon-180B.</b> Human experts spent over 200 hours verifying their accuracy and relevance. Beyond assessing <b>LLMs'</b> knowledge, the dataset's main goal is to facilitate a fair comparison between humans and different <b>LLMs</b> in cybersecurity. To achieve this, we carefully selected 80 questions covering a wide range of topics within cybersecurity and involved 30 participants of diverse expertise levels, facilitating a comprehensive comparison between human and machine intelligence in this area. The findings revealed that <b>LLMs</b> outperformed humans in almost every aspect of cybersecurity.

{{</citation>}}


### (113/210) BreakGPT: A Large Language Model with Multi-stage Structure for Financial Breakout Detection (Kang Zhang et al., 2024)

{{<citation>}}

Kang Zhang, Osamu Yoshie, Weiran Huang. (2024)  
**BreakGPT: A Large Language Model with Multi-stage Structure for Financial Breakout Detection**
<br/>
<button class="copy-to-clipboard" title="BreakGPT: A Large Language Model with Multi-stage Structure for Financial Breakout Detection" index=113>
  <span class="copy-to-clipboard-item">Copy Title<span>
</button>
<div class="toast toast-copied toast-index-113 align-items-center text-bg-secondary border-0 position-absolute top-0 end-0" role="alert" aria-live="assertive" aria-atomic="true">
  <div class="d-flex">
    <div class="toast-body">
      Copied!
    </div>
  </div>
</div>

---
Primary Category: cs.AI  
Categories: cs-AI, cs-CL, cs.AI  
Keyword Score: 50  
Keywords: ChatGPT, GPT, GPT-3, GPT-3.5, Large Language Model  
<a type="button" class="btn btn-outline-primary" href="http://arxiv.org/abs/2402.07536v1" target="_blank" >Paper Link</a>
<button type="button" class="btn btn-outline-primary download-pdf" url="https://arxiv.org/pdf/2402.07536v1.pdf" filename="2402.07536v1.pdf">Download PDF</button>

---


**ABSTRACT**  
Trading range breakout (TRB) is a key method in the technical analysis of financial trading, widely employed by traders in financial markets such as stocks, futures, and foreign exchange. However, distinguishing between true and false breakout and providing the correct rationale cause significant challenges to investors. Recently, <b>large</b> <b>language</b> <b>models</b> have achieved success in various downstream applications, but their effectiveness in the domain of financial breakout detection has been subpar. The reason is that the unique data and specific knowledge are required in breakout detection. To address these issues, we introduce BreakGPT, the first <b>large</b> <b>language</b> <b>model</b> for financial breakout detection. Furthermore, we have developed a novel framework for <b>large</b> <b>language</b> <b>models,</b> namely multi-stage structure, effectively reducing mistakes in downstream applications. Experimental results indicate that compared to <b>GPT-3.5,</b> BreakGPT improves the accuracy of answers and rational by 44%, with the multi-stage structure contributing 17.6% to the improvement. Additionally, it outperforms <b>ChatGPT-4</b> by 42.07%. Our Code is publicly available: https://github.com/Neviim96/BreakGPT

{{</citation>}}


### (114/210) Secret Collusion Among Generative AI Agents (Sumeet Ramesh Motwani et al., 2024)

{{<citation>}}

Sumeet Ramesh Motwani, Mikhail Baranchuk, Martin Strohmeier, Vijay Bolina, Philip H. S. Torr, Lewis Hammond, Christian Schroeder de Witt. (2024)  
**Secret Collusion Among Generative AI Agents**
<br/>
<button class="copy-to-clipboard" title="Secret Collusion Among Generative AI Agents" index=114>
  <span class="copy-to-clipboard-item">Copy Title<span>
</button>
<div class="toast toast-copied toast-index-114 align-items-center text-bg-secondary border-0 position-absolute top-0 end-0" role="alert" aria-live="assertive" aria-atomic="true">
  <div class="d-flex">
    <div class="toast-body">
      Copied!
    </div>
  </div>
</div>

---
Primary Category: cs.AI  
Categories: cs-AI, cs-CR, cs.AI  
Keyword Score: 50  
Keywords: Generative AI, GPT, GPT-4, Large Language Model, Large Language Model  
<a type="button" class="btn btn-outline-primary" href="http://arxiv.org/abs/2402.07510v1" target="_blank" >Paper Link</a>
<button type="button" class="btn btn-outline-primary download-pdf" url="https://arxiv.org/pdf/2402.07510v1.pdf" filename="2402.07510v1.pdf">Download PDF</button>

---


**ABSTRACT**  
Recent capability increases in <b>large</b> <b>language</b> <b>models</b> <b>(LLMs)</b> open up applications in which teams of communicating <b>generative</b> <b>AI</b> agents solve joint tasks. This poses privacy and security challenges concerning the unauthorised sharing of information, or other unwanted forms of agent coordination. Modern steganographic techniques could render such dynamics hard to detect. In this paper, we comprehensively formalise the problem of secret collusion in systems of <b>generative</b> <b>AI</b> agents by drawing on relevant concepts from both the AI and security literature. We study incentives for the use of steganography, and propose a variety of mitigation measures. Our investigations result in a model evaluation framework that systematically tests capabilities required for various forms of secret collusion. We provide extensive empirical results across a range of contemporary <b>LLMs.</b> While the steganographic capabilities of current models remain limited, <b>GPT-4</b> displays a capability jump suggesting the need for continuous monitoring of steganographic frontier model capabilities. We conclude by laying out a comprehensive research program to mitigate future risks of collusion between <b>generative</b> <b>AI</b> models.

{{</citation>}}


### (115/210) T-RAG: Lessons from the LLM Trenches (Masoomali Fatehkia et al., 2024)

{{<citation>}}

Masoomali Fatehkia, Ji Kim Lucas, Sanjay Chawla. (2024)  
**T-RAG: Lessons from the LLM Trenches**
<br/>
<button class="copy-to-clipboard" title="T-RAG: Lessons from the LLM Trenches" index=115>
  <span class="copy-to-clipboard-item">Copy Title<span>
</button>
<div class="toast toast-copied toast-index-115 align-items-center text-bg-secondary border-0 position-absolute top-0 end-0" role="alert" aria-live="assertive" aria-atomic="true">
  <div class="d-flex">
    <div class="toast-body">
      Copied!
    </div>
  </div>
</div>

---
Primary Category: cs.AI  
Categories: cs-AI, cs-CL, cs.AI  
Keyword Score: 50  
Keywords: Fine-tuning, Fine-tuning, Question Answering, Large Language Model, Large Language Model  
<a type="button" class="btn btn-outline-primary" href="http://arxiv.org/abs/2402.07483v1" target="_blank" >Paper Link</a>
<button type="button" class="btn btn-outline-primary download-pdf" url="https://arxiv.org/pdf/2402.07483v1.pdf" filename="2402.07483v1.pdf">Download PDF</button>

---


**ABSTRACT**  
<b>Large</b> <b>Language</b> <b>Models</b> <b>(LLM)</b> have shown remarkable language capabilities fueling attempts to integrate them into applications across a wide range of domains. An important application area is <b>question</b> <b>answering</b> over private enterprise documents where the main considerations are data security, which necessitates applications that can be deployed on-prem, limited computational resources and the need for a robust application that correctly responds to queries. Retrieval-Augmented Generation (RAG) has emerged as the most prominent framework for building <b>LLM-based</b> applications. While building a RAG is relatively straightforward, making it robust and a reliable application requires extensive customization and relatively deep knowledge of the application domain. We share our experiences building and deploying an <b>LLM</b> application for <b>question</b> <b>answering</b> over private organizational documents. Our application combines the use of RAG with a <b>finetuned</b> open-source <b>LLM.</b> Additionally, our system, which we call Tree-RAG (T-RAG), uses a tree structure to represent entity hierarchies within the organization. This is used to generate a textual description to augment the context when responding to user queries pertaining to entities within the organization's hierarchy. Our evaluations show that this combination performs better than a simple RAG or <b>finetuning</b> implementation. Finally, we share some lessons learned based on our experiences building an <b>LLM</b> application for real-world use.

{{</citation>}}


### (116/210) Enhancing Multi-Criteria Decision Analysis with AI: Integrating Analytic Hierarchy Process and GPT-4 for Automated Decision Support (Igor Svoboda et al., 2024)

{{<citation>}}

Igor Svoboda, Dmytro Lande. (2024)  
**Enhancing Multi-Criteria Decision Analysis with AI: Integrating Analytic Hierarchy Process and GPT-4 for Automated Decision Support**
<br/>
<button class="copy-to-clipboard" title="Enhancing Multi-Criteria Decision Analysis with AI: Integrating Analytic Hierarchy Process and GPT-4 for Automated Decision Support" index=116>
  <span class="copy-to-clipboard-item">Copy Title<span>
</button>
<div class="toast toast-copied toast-index-116 align-items-center text-bg-secondary border-0 position-absolute top-0 end-0" role="alert" aria-live="assertive" aria-atomic="true">
  <div class="d-flex">
    <div class="toast-body">
      Copied!
    </div>
  </div>
</div>

---
Primary Category: cs.AI  
Categories: I-2-1; I-2-8; H-1-1, cs-AI, cs-CR, cs-MA, cs.AI  
Keyword Score: 50  
Keywords: GPT, GPT-4, Transformer, Large Language Model, Large Language Model  
<a type="button" class="btn btn-outline-primary" href="http://arxiv.org/abs/2402.07404v1" target="_blank" >Paper Link</a>
<button type="button" class="btn btn-outline-primary download-pdf" url="https://arxiv.org/pdf/2402.07404v1.pdf" filename="2402.07404v1.pdf">Download PDF</button>

---


**ABSTRACT**  
Our study presents a new framework that incorporates the Analytic Hierarchy Process (AHP) and Generative Pre-trained <b>Transformer</b> 4 <b>(GPT-4)</b> <b>large</b> <b>language</b> <b>model</b> <b>(LLM),</b> bringing novel approaches to cybersecurity Multiple-criteria Decision Making (MCDA). By utilizing the capabilities of <b>GPT-4</b> autonomous agents as virtual experts, we automate the decision-making process, enhancing both efficiency and reliability. This new approach focuses on leveraging <b>LLMs</b> for sophisticated decision analysis, highlighting the synergy between traditional decision-making models and cutting-edge AI technologies. Our innovative methodology demonstrates significant advancements in using AI-driven agents for complex decision-making scenarios, highlighting the importance of AI in strategic cybersecurity applications. The findings reveal the transformative potential of combining AHP and <b>LLMs,</b> establishing a new paradigm for intelligent decision support systems in cybersecurity and beyond.

{{</citation>}}


### (117/210) VisLingInstruct: Elevating Zero-Shot Learning in Multi-Modal Language Models with Autonomous Instruction Optimization (Dongsheng Zhu et al., 2024)

{{<citation>}}

Dongsheng Zhu, Xunzhu Tang, Weidong Han, Jinghui Lu, Yukun Zhao, Guoliang Xing, Junfeng Wang, Dawei Yin. (2024)  
**VisLingInstruct: Elevating Zero-Shot Learning in Multi-Modal Language Models with Autonomous Instruction Optimization**
<br/>
<button class="copy-to-clipboard" title="VisLingInstruct: Elevating Zero-Shot Learning in Multi-Modal Language Models with Autonomous Instruction Optimization" index=117>
  <span class="copy-to-clipboard-item">Copy Title<span>
</button>
<div class="toast toast-copied toast-index-117 align-items-center text-bg-secondary border-0 position-absolute top-0 end-0" role="alert" aria-live="assertive" aria-atomic="true">
  <div class="d-flex">
    <div class="toast-body">
      Copied!
    </div>
  </div>
</div>

---
Primary Category: cs.AI  
Categories: cs-AI, cs.AI  
Keyword Score: 43  
Keywords: Multi-modal, Zero-shot, In-context Learning, In-context Learning, Zero-shot Learning  
<a type="button" class="btn btn-outline-primary" href="http://arxiv.org/abs/2402.07398v1" target="_blank" >Paper Link</a>
<button type="button" class="btn btn-outline-primary download-pdf" url="https://arxiv.org/pdf/2402.07398v1.pdf" filename="2402.07398v1.pdf">Download PDF</button>

---


**ABSTRACT**  
This paper presents VisLingInstruct, a novel approach to advancing <b>Multi-Modal</b> Language Models (MMLMs) in <b>zero-shot</b> <b>learning.</b> Current MMLMs show impressive <b>zero-shot</b> <b>abilities</b> in <b>multi-modal</b> tasks, but their performance depends heavily on the quality of instructions. VisLingInstruct tackles this by autonomously evaluating and optimizing instructional texts through <b>In-Context</b> <b>Learning,</b> improving the synergy between visual perception and linguistic expression in MMLMs. Alongside this instructional advancement, we have also optimized the visual feature extraction modules in MMLMs, further augmenting their responsiveness to textual cues. Our comprehensive experiments on MMLMs, based on FlanT5 and Vicuna, show that VisLingInstruct significantly improves <b>zero-shot</b> <b>performance</b> in visual <b>multi-modal</b> tasks. Notably, it achieves a 13.1% and 9% increase in accuracy over the prior state-of-the-art on the TextVQA and HatefulMemes datasets.

{{</citation>}}


### (118/210) Extensible Multi-Granularity Fusion Network for Aspect-based Sentiment Analysis (Xiaowei Zhao et al., 2024)

{{<citation>}}

Xiaowei Zhao, Yong Zhou, Xiujuan Xu, Yu Liu. (2024)  
**Extensible Multi-Granularity Fusion Network for Aspect-based Sentiment Analysis**
<br/>
<button class="copy-to-clipboard" title="Extensible Multi-Granularity Fusion Network for Aspect-based Sentiment Analysis" index=118>
  <span class="copy-to-clipboard-item">Copy Title<span>
</button>
<div class="toast toast-copied toast-index-118 align-items-center text-bg-secondary border-0 position-absolute top-0 end-0" role="alert" aria-live="assertive" aria-atomic="true">
  <div class="d-flex">
    <div class="toast-body">
      Copied!
    </div>
  </div>
</div>

---
Primary Category: cs.AI  
Categories: cs-AI, cs-CL, cs.AI  
Keyword Score: 40  
Keywords: Graph Neural Network, Graph Neural Network, Aspect-based Sentiment Analysis, Sentiment Analysis  
<a type="button" class="btn btn-outline-primary" href="http://arxiv.org/abs/2402.07787v2" target="_blank" >Paper Link</a>
<button type="button" class="btn btn-outline-primary download-pdf" url="https://arxiv.org/pdf/2402.07787v2.pdf" filename="2402.07787v2.pdf">Download PDF</button>

---


**ABSTRACT**  
<b>Aspect-based</b> <b>Sentiment</b> <b>Analysis</b> (ABSA) evaluates <b>sentiment</b> <b>expressions</b> within a text to comprehend <b>sentiment</b> <b>information.</b> Previous studies integrated external knowledge, such as knowledge <b>graphs,</b> <b>to</b> <b>enhance</b> the semantic features in ABSA models. Recent research has examined the use of <b>Graph</b> <b>Neural</b> <b>Networks</b> <b>(GNNs)</b> on dependency and constituent trees for syntactic analysis. With the ongoing development of ABSA, more innovative linguistic and structural features are being incorporated (e.g. latent <b>graph),</b> <b>but</b> <b>this</b> also introduces complexity and confusion. As of now, a scalable framework for integrating diverse linguistic and structural features into ABSA does not exist. This paper presents the Extensible Multi-Granularity Fusion (EMGF) network, which integrates information from dependency and constituent syntactic, attention semantic , and external knowledge <b>graphs.</b> <b>EMGF,</b> <b>equipped</b> with multi-anchor triplet learning and orthogonal projection, efficiently harnesses the combined potential of each granularity feature and their synergistic interactions, resulting in a cumulative effect without additional computational expenses. Experimental findings on SemEval 2014 and Twitter datasets confirm EMGF's superiority over existing ABSA methods.

{{</citation>}}


### (119/210) Out-of-Distribution Detection and Data Drift Monitoring using Statistical Process Control (Ghada Zamzmi et al., 2024)

{{<citation>}}

Ghada Zamzmi, Kesavan Venkatesh, Brandon Nelson, Smriti Prathapan, Paul H. Yi, Berkman Sahiner, Jana G. Delfino. (2024)  
**Out-of-Distribution Detection and Data Drift Monitoring using Statistical Process Control**
<br/>
<button class="copy-to-clipboard" title="Out-of-Distribution Detection and Data Drift Monitoring using Statistical Process Control" index=119>
  <span class="copy-to-clipboard-item">Copy Title<span>
</button>
<div class="toast toast-copied toast-index-119 align-items-center text-bg-secondary border-0 position-absolute top-0 end-0" role="alert" aria-live="assertive" aria-atomic="true">
  <div class="d-flex">
    <div class="toast-body">
      Copied!
    </div>
  </div>
</div>

---
Primary Category: cs.AI  
Categories: cs-AI, cs-LG, cs.AI, eess-IV  
Keyword Score: 30  
Keywords: Out-of-distribution, Simulation, Simulator  
<a type="button" class="btn btn-outline-primary" href="http://arxiv.org/abs/2402.08088v1" target="_blank" >Paper Link</a>
<button type="button" class="btn btn-outline-primary download-pdf" url="https://arxiv.org/pdf/2402.08088v1.pdf" filename="2402.08088v1.pdf">Download PDF</button>

---


**ABSTRACT**  
Background: Machine learning (ML) methods often fail with data that deviates from their training distribution. This is a significant concern for ML-enabled devices in clinical settings, where data drift may cause unexpected performance that jeopardizes patient safety. Method: We propose a ML-enabled Statistical Process Control (SPC) framework for <b>out-of-distribution</b> (OOD) detection and drift monitoring. SPC is advantageous as it visually and statistically highlights deviations from the expected distribution. To demonstrate the utility of the proposed framework for monitoring data drift in radiological images, we investigated different design choices, including methods for extracting feature representations, drift quantification, and SPC parameter selection. Results: We demonstrate the effectiveness of our framework for two tasks: 1) differentiating axial vs. non-axial computed tomography (CT) images and 2) separating chest x-ray (CXR) from other modalities. For both tasks, we achieved high accuracy in detecting OOD inputs, with 0.913 in CT and 0.995 in CXR, and sensitivity of 0.980 in CT and 0.984 in CXR. Our framework was also adept at monitoring data streams and identifying the time a drift occurred. In a <b>simulation</b> with 100 daily CXR cases, we detected a drift in OOD input percentage from 0-1% to 3-5% within two days, maintaining a low false-positive rate. Through additional experimental results, we demonstrate the framework's data-agnostic nature and independence from the underlying model's structure. Conclusion: We propose a framework for OOD detection and drift monitoring that is agnostic to data, modality, and model. The framework is customizable and can be adapted for specific applications.

{{</citation>}}


### (120/210) Beyond LLMs: Advancing the Landscape of Complex Reasoning (Jennifer Chu-Carroll et al., 2024)

{{<citation>}}

Jennifer Chu-Carroll, Andrew Beck, Greg Burnham, David OS Melville, David Nachman, A. Erdem Özcan, David Ferrucci. (2024)  
**Beyond LLMs: Advancing the Landscape of Complex Reasoning**
<br/>
<button class="copy-to-clipboard" title="Beyond LLMs: Advancing the Landscape of Complex Reasoning" index=120>
  <span class="copy-to-clipboard-item">Copy Title<span>
</button>
<div class="toast toast-copied toast-index-120 align-items-center text-bg-secondary border-0 position-absolute top-0 end-0" role="alert" aria-live="assertive" aria-atomic="true">
  <div class="d-flex">
    <div class="toast-body">
      Copied!
    </div>
  </div>
</div>

---
Primary Category: cs.AI  
Categories: cs-AI, cs-CL, cs.AI  
Keyword Score: 30  
Keywords: Reasoning, Large Language Model, Large Language Model  
<a type="button" class="btn btn-outline-primary" href="http://arxiv.org/abs/2402.08064v1" target="_blank" >Paper Link</a>
<button type="button" class="btn btn-outline-primary download-pdf" url="https://arxiv.org/pdf/2402.08064v1.pdf" filename="2402.08064v1.pdf">Download PDF</button>

---


**ABSTRACT**  
Since the advent of <b>Large</b> <b>Language</b> <b>Models</b> a few years ago, they have often been considered the de facto solution for many AI problems. However, in addition to the many deficiencies of <b>LLMs</b> that prevent them from broad industry adoption, such as reliability, cost, and speed, there is a whole class of common real world problems that <b>Large</b> <b>Language</b> <b>Models</b> perform poorly on, namely, constraint satisfaction and optimization problems. These problems are ubiquitous and current solutions are highly specialized and expensive to implement. At Elemental Cognition, we developed our EC AI platform which takes a neuro-symbolic approach to solving constraint satisfaction and optimization problems. The platform employs, at its core, a precise and high performance logical <b>reasoning</b> engine, and leverages <b>LLMs</b> for knowledge acquisition and user interaction. This platform supports developers in specifying application logic in natural and concise language while generating application user interfaces to interact with users effectively. We evaluated <b>LLMs</b> against systems built on the EC AI platform in three domains and found the EC AI systems to significantly outperform <b>LLMs</b> on constructing valid and optimal solutions, on validating proposed solutions, and on repairing invalid solutions.

{{</citation>}}


### (121/210) MAIDCRL: Semi-centralized Multi-Agent Influence Dense-CNN Reinforcement Learning (Ayesha Siddika Nipu et al., 2024)

{{<citation>}}

Ayesha Siddika Nipu, Siming Liu, Anthony Harris. (2024)  
**MAIDCRL: Semi-centralized Multi-Agent Influence Dense-CNN Reinforcement Learning**
<br/>
<button class="copy-to-clipboard" title="MAIDCRL: Semi-centralized Multi-Agent Influence Dense-CNN Reinforcement Learning" index=121>
  <span class="copy-to-clipboard-item">Copy Title<span>
</button>
<div class="toast toast-copied toast-index-121 align-items-center text-bg-secondary border-0 position-absolute top-0 end-0" role="alert" aria-live="assertive" aria-atomic="true">
  <div class="d-flex">
    <div class="toast-body">
      Copied!
    </div>
  </div>
</div>

---
Primary Category: cs.AI  
Categories: cs-AI, cs-LG, cs.AI  
Keyword Score: 30  
Keywords: Convolution, Convolutional Neural Network, Reinforcement Learning  
<a type="button" class="btn btn-outline-primary" href="http://arxiv.org/abs/2402.07890v1" target="_blank" >Paper Link</a>
<button type="button" class="btn btn-outline-primary download-pdf" url="https://arxiv.org/pdf/2402.07890v1.pdf" filename="2402.07890v1.pdf">Download PDF</button>

---


**ABSTRACT**  
Distributed decision-making in multi-agent systems presents difficult challenges for interactive behavior learning in both cooperative and competitive systems. To mitigate this complexity, MAIDRL presents a semi-centralized Dense <b>Reinforcement</b> <b>Learning</b> algorithm enhanced by agent influence maps (AIMs), for learning effective multi-agent control on StarCraft Multi-Agent Challenge (SMAC) scenarios. In this paper, we extend the DenseNet in MAIDRL and introduce semi-centralized Multi-Agent Dense-CNN <b>Reinforcement</b> <b>Learning,</b> MAIDCRL, by incorporating <b>convolutional</b> layers into the deep model architecture, and evaluate the performance on both homogeneous and heterogeneous scenarios. The results show that the <b>CNN-enabled</b> MAIDCRL significantly improved the learning performance and achieved a faster learning rate compared to the existing MAIDRL, especially on more complicated heterogeneous SMAC scenarios. We further investigate the stability and robustness of our model. The statistics reflect that our model not only achieves higher winning rate in all the given scenarios but also boosts the agent's learning process in fine-grained decision-making.

{{</citation>}}


### (122/210) Towards Unified Alignment Between Agents, Humans, and Environment (Zonghan Yang et al., 2024)

{{<citation>}}

Zonghan Yang, An Liu, Zijun Liu, Kaiming Liu, Fangzhou Xiong, Yile Wang, Zeyuan Yang, Qingyuan Hu, Xinrui Chen, Zhenhe Zhang, Fuwen Luo, Zhicheng Guo, Peng Li, Yang Liu. (2024)  
**Towards Unified Alignment Between Agents, Humans, and Environment**
<br/>
<button class="copy-to-clipboard" title="Towards Unified Alignment Between Agents, Humans, and Environment" index=122>
  <span class="copy-to-clipboard-item">Copy Title<span>
</button>
<div class="toast toast-copied toast-index-122 align-items-center text-bg-secondary border-0 position-absolute top-0 end-0" role="alert" aria-live="assertive" aria-atomic="true">
  <div class="d-flex">
    <div class="toast-body">
      Copied!
    </div>
  </div>
</div>

---
Primary Category: cs.AI  
Categories: cs-AI, cs-CL, cs-LG, cs.AI  
Keyword Score: 30  
Keywords: Foundation Model, Rerank, Reasoning  
<a type="button" class="btn btn-outline-primary" href="http://arxiv.org/abs/2402.07744v1" target="_blank" >Paper Link</a>
<button type="button" class="btn btn-outline-primary download-pdf" url="https://arxiv.org/pdf/2402.07744v1.pdf" filename="2402.07744v1.pdf">Download PDF</button>

---


**ABSTRACT**  
The rapid progress of <b>foundation</b> <b>models</b> has led to the prosperity of autonomous agents, which leverage the universal capabilities of <b>foundation</b> <b>models</b> to conduct <b>reasoning,</b> decision-making, and environmental interaction. However, the efficacy of agents remains limited when operating in intricate, realistic environments. In this work, we introduce the principles of $\mathbf{U}$nified $\mathbf{A}$lignment for $\mathbf{A}$gents ($\mathbf{UA}^2$), which advocate for the simultaneous alignment of agents with human intentions, environmental dynamics, and self-constraints such as the limitation of monetary budgets. From the perspective of $\mathbf{UA}^2$, we review the current agent research and highlight the neglected factors in existing agent benchmarks and method candidates. We also conduct proof-of-concept studies by introducing realistic features to WebShop, including user profiles to demonstrate intentions, personalized <b>reranking</b> for complex environmental dynamics, and runtime cost statistics to reflect self-constraints. We then follow the principles of $\mathbf{UA}^2$ to propose an initial design of our agent, and benchmark its performance with several candidate baselines in the retrofitted WebShop. The extensive experimental results further prove the importance of the principles of $\mathbf{UA}^2$. Our research sheds light on the next steps of autonomous agent research with improved general problem-solving abilities.

{{</citation>}}


### (123/210) Food Recommendation as Language Processing (F-RLP): A Personalized and Contextual Paradigm (Ali Rostami et al., 2024)

{{<citation>}}

Ali Rostami, Ramesh Jain, Amir M. Rahmani. (2024)  
**Food Recommendation as Language Processing (F-RLP): A Personalized and Contextual Paradigm**
<br/>
<button class="copy-to-clipboard" title="Food Recommendation as Language Processing (F-RLP): A Personalized and Contextual Paradigm" index=123>
  <span class="copy-to-clipboard-item">Copy Title<span>
</button>
<div class="toast toast-copied toast-index-123 align-items-center text-bg-secondary border-0 position-absolute top-0 end-0" role="alert" aria-live="assertive" aria-atomic="true">
  <div class="d-flex">
    <div class="toast-body">
      Copied!
    </div>
  </div>
</div>

---
Primary Category: cs.AI  
Categories: cs-AI, cs.AI  
Keyword Score: 30  
Keywords: Recommendation, Large Language Model, Large Language Model  
<a type="button" class="btn btn-outline-primary" href="http://arxiv.org/abs/2402.07477v1" target="_blank" >Paper Link</a>
<button type="button" class="btn btn-outline-primary download-pdf" url="https://arxiv.org/pdf/2402.07477v1.pdf" filename="2402.07477v1.pdf">Download PDF</button>

---


**ABSTRACT**  
State-of-the-art rule-based and classification-based food <b>recommendation</b> systems face significant challenges in becoming practical and useful. This difficulty arises primarily because most machine learning models struggle with problems characterized by an almost infinite number of classes and a limited number of samples within an unbalanced dataset. Conversely, the emergence of <b>Large</b> <b>Language</b> <b>Models</b> <b>(LLMs)</b> as <b>recommendation</b> engines offers a promising avenue. However, a general-purpose <b>Recommendation</b> as Language Processing (RLP) approach lacks the critical components necessary for effective food <b>recommendations.</b> To address this gap, we introduce Food <b>Recommendation</b> as Language Processing (F-RLP), a novel framework that offers a food-specific, tailored infrastructure. F-RLP leverages the capabilities of <b>LLMs</b> to maximize their potential, thereby paving the way for more accurate, personalized food <b>recommendations.</b>

{{</citation>}}


### (124/210) Game Agent Driven by Free-Form Text Command: Using LLM-based Code Generation and Behavior Branch (Ray Ito et al., 2024)

{{<citation>}}

Ray Ito, Junichiro Takahashi. (2024)  
**Game Agent Driven by Free-Form Text Command: Using LLM-based Code Generation and Behavior Branch**
<br/>
<button class="copy-to-clipboard" title="Game Agent Driven by Free-Form Text Command: Using LLM-based Code Generation and Behavior Branch" index=124>
  <span class="copy-to-clipboard-item">Copy Title<span>
</button>
<div class="toast toast-copied toast-index-124 align-items-center text-bg-secondary border-0 position-absolute top-0 end-0" role="alert" aria-live="assertive" aria-atomic="true">
  <div class="d-flex">
    <div class="toast-body">
      Copied!
    </div>
  </div>
</div>

---
Primary Category: cs.AI  
Categories: cs-AI, cs.AI  
Keyword Score: 30  
Keywords: Code Generation, Large Language Model, Large Language Model  
<a type="button" class="btn btn-outline-primary" href="http://arxiv.org/abs/2402.07442v1" target="_blank" >Paper Link</a>
<button type="button" class="btn btn-outline-primary download-pdf" url="https://arxiv.org/pdf/2402.07442v1.pdf" filename="2402.07442v1.pdf">Download PDF</button>

---


**ABSTRACT**  
Several attempts have been made to implement text command control for game agents. However, current technologies are limited to processing predefined format commands. This paper proposes a pioneering text command control system for a game agent that can understand natural language commands expressed in free-form. The proposed system uses a <b>large</b> <b>language</b> <b>model</b> <b>(LLM)</b> for <b>code</b> <b>generation</b> to interpret and transform natural language commands into behavior branch, a proposed knowledge expression based on behavior trees, which facilitates execution by the game agent. This study conducted empirical validation within a game environment that simulates a Pok\'emon game and involved multiple participants. The results confirmed the system's ability to understand and carry out natural language commands, representing a noteworthy in the realm of real-time language interactive game agents. Notice for the use of this material. The copyright of this material is retained by the Japanese Society for Artificial Intelligence (JSAI). This material is published here with the agreement of JSAI. Please be complied with Copyright Law of Japan if any users wish to reproduce, make derivative work, distribute or make available to the public any part or whole thereof. All Rights Reserved, Copyright (C) The Japanese Society for Artificial Intelligence.

{{</citation>}}


### (125/210) Recursive Joint Simulation in Games (Vojtech Kovarik et al., 2024)

{{<citation>}}

Vojtech Kovarik, Caspar Oesterheld, Vincent Conitzer. (2024)  
**Recursive Joint Simulation in Games**
<br/>
<button class="copy-to-clipboard" title="Recursive Joint Simulation in Games" index=125>
  <span class="copy-to-clipboard-item">Copy Title<span>
</button>
<div class="toast toast-copied toast-index-125 align-items-center text-bg-secondary border-0 position-absolute top-0 end-0" role="alert" aria-live="assertive" aria-atomic="true">
  <div class="d-flex">
    <div class="toast-body">
      Copied!
    </div>
  </div>
</div>

---
Primary Category: cs.AI  
Categories: cs-AI, cs-GT, cs.AI  
Keyword Score: 20  
Keywords: Simulation, Simulator  
<a type="button" class="btn btn-outline-primary" href="http://arxiv.org/abs/2402.08128v1" target="_blank" >Paper Link</a>
<button type="button" class="btn btn-outline-primary download-pdf" url="https://arxiv.org/pdf/2402.08128v1.pdf" filename="2402.08128v1.pdf">Download PDF</button>

---


**ABSTRACT**  
Game-theoretic dynamics between AI agents could differ from traditional human-human interactions in various ways. One such difference is that it may be possible to accurately simulate an AI agent, for example because its source code is known. Our aim is to explore ways of leveraging this possibility to achieve more cooperative outcomes in strategic settings. In this paper, we study an interaction between AI agents where the agents run a recursive joint <b>simulation.</b> That is, the agents first jointly observe a <b>simulation</b> of the situation they face. This <b>simulation</b> in turn recursively includes additional <b>simulations</b> (with a small chance of failure, to avoid infinite recursion), and the results of all these nested <b>simulations</b> are observed before an action is chosen. We show that the resulting interaction is strategically equivalent to an infinitely repeated version of the original game, allowing a direct transfer of existing results such as the various folk theorems.

{{</citation>}}


### (126/210) WildfireGPT: Tailored Large Language Model for Wildfire Analysis (Yangxinyu Xie et al., 2024)

{{<citation>}}

Yangxinyu Xie, Tanwi Mallick, Joshua David Bergerson, John K. Hutchison, Duane R. Verner, Jordan Branham, M. Ross Alexander, Robert B. Ross, Yan Feng, Leslie-Anne Levy, Weijie Su. (2024)  
**WildfireGPT: Tailored Large Language Model for Wildfire Analysis**
<br/>
<button class="copy-to-clipboard" title="WildfireGPT: Tailored Large Language Model for Wildfire Analysis" index=126>
  <span class="copy-to-clipboard-item">Copy Title<span>
</button>
<div class="toast toast-copied toast-index-126 align-items-center text-bg-secondary border-0 position-absolute top-0 end-0" role="alert" aria-live="assertive" aria-atomic="true">
  <div class="d-flex">
    <div class="toast-body">
      Copied!
    </div>
  </div>
</div>

---
Primary Category: cs.AI  
Categories: cs-AI, cs.AI  
Keyword Score: 20  
Keywords: Large Language Model, Large Language Model  
<a type="button" class="btn btn-outline-primary" href="http://arxiv.org/abs/2402.07877v1" target="_blank" >Paper Link</a>
<button type="button" class="btn btn-outline-primary download-pdf" url="https://arxiv.org/pdf/2402.07877v1.pdf" filename="2402.07877v1.pdf">Download PDF</button>

---


**ABSTRACT**  
The recent advancement of <b>large</b> <b>language</b> <b>models</b> <b>(LLMs)</b> represents a transformational capability at the frontier of artificial intelligence (AI) and machine learning (ML). However, <b>LLMs</b> are generalized models, trained on extensive text corpus, and often struggle to provide context-specific information, particularly in areas requiring specialized knowledge such as wildfire details within the broader context of climate change. For decision-makers and policymakers focused on wildfire resilience and adaptation, it is crucial to obtain responses that are not only precise but also domain-specific, rather than generic. To that end, we developed WildfireGPT, a prototype <b>LLM</b> agent designed to transform user queries into actionable insights on wildfire risks. We enrich WildfireGPT by providing additional context such as climate projections and scientific literature to ensure its information is current, relevant, and scientifically accurate. This enables WildfireGPT to be an effective tool for delivering detailed, user-specific insights on wildfire risks to support a diverse set of end users, including researchers, engineers, urban planners, emergency managers, and infrastructure operators.

{{</citation>}}


### (127/210) OS-Copilot: Towards Generalist Computer Agents with Self-Improvement (Zhiyong Wu et al., 2024)

{{<citation>}}

Zhiyong Wu, Chengcheng Han, Zichen Ding, Zhenmin Weng, Zhoumianze Liu, Shunyu Yao, Tao Yu, Lingpeng Kong. (2024)  
**OS-Copilot: Towards Generalist Computer Agents with Self-Improvement**
<br/>
<button class="copy-to-clipboard" title="OS-Copilot: Towards Generalist Computer Agents with Self-Improvement" index=127>
  <span class="copy-to-clipboard-item">Copy Title<span>
</button>
<div class="toast toast-copied toast-index-127 align-items-center text-bg-secondary border-0 position-absolute top-0 end-0" role="alert" aria-live="assertive" aria-atomic="true">
  <div class="d-flex">
    <div class="toast-body">
      Copied!
    </div>
  </div>
</div>

---
Primary Category: cs.AI  
Categories: cs-AI, cs.AI  
Keyword Score: 20  
Keywords: Large Language Model, Large Language Model  
<a type="button" class="btn btn-outline-primary" href="http://arxiv.org/abs/2402.07456v1" target="_blank" >Paper Link</a>
<button type="button" class="btn btn-outline-primary download-pdf" url="https://arxiv.org/pdf/2402.07456v1.pdf" filename="2402.07456v1.pdf">Download PDF</button>

---


**ABSTRACT**  
Autonomous interaction with the computer has been a longstanding challenge with great potential, and the recent proliferation of <b>large</b> <b>language</b> <b>models</b> <b>(LLMs)</b> has markedly accelerated progress in building digital agents. However, most of these agents are designed to interact with a narrow domain, such as a specific software or website. This narrow focus constrains their applicability for general computer tasks. To this end, we introduce OS-Copilot, a framework to build generalist agents capable of interfacing with comprehensive elements in an operating system (OS), including the web, code terminals, files, multimedia, and various third-party applications. We use OS-Copilot to create FRIDAY, a self-improving embodied agent for automating general computer tasks. On GAIA, a general AI assistants benchmark, FRIDAY outperforms previous methods by 35%, showcasing strong generalization to unseen applications via accumulated skills from previous tasks. We also present numerical and quantitative evidence that FRIDAY learns to control and self-improve on Excel and Powerpoint with minimal supervision. Our OS-Copilot framework and empirical findings provide infrastructure and insights for future research toward more capable and general-purpose computer agents.

{{</citation>}}


### (128/210) Generalising Planning Environment Redesign (Alberto Pozanco et al., 2024)

{{<citation>}}

Alberto Pozanco, Ramon Fraga Pereira, Daniel Borrajo. (2024)  
**Generalising Planning Environment Redesign**
<br/>
<button class="copy-to-clipboard" title="Generalising Planning Environment Redesign" index=128>
  <span class="copy-to-clipboard-item">Copy Title<span>
</button>
<div class="toast toast-copied toast-index-128 align-items-center text-bg-secondary border-0 position-absolute top-0 end-0" role="alert" aria-live="assertive" aria-atomic="true">
  <div class="d-flex">
    <div class="toast-body">
      Copied!
    </div>
  </div>
</div>

---
Primary Category: cs.AI  
Categories: cs-AI, cs.AI  
Keyword Score: 10  
Keywords: Pruning  
<a type="button" class="btn btn-outline-primary" href="http://arxiv.org/abs/2402.07799v1" target="_blank" >Paper Link</a>
<button type="button" class="btn btn-outline-primary download-pdf" url="https://arxiv.org/pdf/2402.07799v1.pdf" filename="2402.07799v1.pdf">Download PDF</button>

---


**ABSTRACT**  
In Environment Design, one interested party seeks to affect another agent's decisions by applying changes to the environment. Most research on planning environment (re)design assumes the interested party's objective is to facilitate the recognition of goals and plans, and search over the space of environment modifications to find the minimal set of changes that simplify those tasks and optimise a particular metric. This search space is usually intractable, so existing approaches devise metric-dependent <b>pruning</b> techniques for performing search more efficiently. This results in approaches that are not able to generalise across different objectives and/or metrics. In this paper, we argue that the interested party could have objectives and metrics that are not necessarily related to recognising agents' goals or plans. Thus, to generalise the task of Planning Environment Redesign, we develop a general environment redesign approach that is metric-agnostic and leverages recent research on top-quality planning to efficiently redesign planning environments according to any interested party's objective and metric. Experiments over a set of environment redesign benchmarks show that our general approach outperforms existing approaches when using well-known metrics, such as facilitating the recognition of goals, as well as its effectiveness when solving environment redesign tasks that optimise a novel set of different metrics.

{{</citation>}}


### (129/210) End-to-End Learning for Fair Multiobjective Optimization Under Uncertainty (My H Dinh et al., 2024)

{{<citation>}}

My H Dinh, James Kotary, Ferdinando Fioretto. (2024)  
**End-to-End Learning for Fair Multiobjective Optimization Under Uncertainty**
<br/>
<button class="copy-to-clipboard" title="End-to-End Learning for Fair Multiobjective Optimization Under Uncertainty" index=129>
  <span class="copy-to-clipboard-item">Copy Title<span>
</button>
<div class="toast toast-copied toast-index-129 align-items-center text-bg-secondary border-0 position-absolute top-0 end-0" role="alert" aria-live="assertive" aria-atomic="true">
  <div class="d-flex">
    <div class="toast-body">
      Copied!
    </div>
  </div>
</div>

---
Primary Category: cs.AI  
Categories: cs-AI, cs.AI  
Keyword Score: 10  
Keywords: Fairness  
<a type="button" class="btn btn-outline-primary" href="http://arxiv.org/abs/2402.07772v1" target="_blank" >Paper Link</a>
<button type="button" class="btn btn-outline-primary download-pdf" url="https://arxiv.org/pdf/2402.07772v1.pdf" filename="2402.07772v1.pdf">Download PDF</button>

---


**ABSTRACT**  
Many decision processes in artificial intelligence and operations research are modeled by parametric optimization problems whose defining parameters are unknown and must be inferred from observable data. The Predict-Then-Optimize (PtO) paradigm in machine learning aims to maximize downstream decision quality by training the parametric inference model end-to-end with the subsequent constrained optimization. This requires backpropagation through the optimization problem using approximation techniques specific to the problem's form, especially for nondifferentiable linear and mixed-integer programs. This paper extends the PtO methodology to optimization problems with nondifferentiable Ordered Weighted Averaging (OWA) objectives, known for their ability to ensure properties of <b>fairness</b> and robustness in decision models. Through a collection of training techniques and proposed application settings, it shows how optimization of OWA functions can be effectively integrated with parametric prediction for fair and robust optimization under uncertainty.

{{</citation>}}


### (130/210) News Recommendation with Attention Mechanism (Tianrui Liu et al., 2024)

{{<citation>}}

Tianrui Liu, Changxin Xu, Yuxin Qiao, Chufeng Jiang, Weisheng Chen. (2024)  
**News Recommendation with Attention Mechanism**
<br/>
<button class="copy-to-clipboard" title="News Recommendation with Attention Mechanism" index=130>
  <span class="copy-to-clipboard-item">Copy Title<span>
</button>
<div class="toast toast-copied toast-index-130 align-items-center text-bg-secondary border-0 position-absolute top-0 end-0" role="alert" aria-live="assertive" aria-atomic="true">
  <div class="d-flex">
    <div class="toast-body">
      Copied!
    </div>
  </div>
</div>

---
Primary Category: cs.AI  
Categories: cs-AI, cs.AI  
Keyword Score: 10  
Keywords: Recommendation  
<a type="button" class="btn btn-outline-primary" href="http://arxiv.org/abs/2402.07422v1" target="_blank" >Paper Link</a>
<button type="button" class="btn btn-outline-primary download-pdf" url="https://arxiv.org/pdf/2402.07422v1.pdf" filename="2402.07422v1.pdf">Download PDF</button>

---


**ABSTRACT**  
This paper explores the area of news <b>recommendation,</b> a key component of online information sharing. Initially, we provide a clear introduction to news <b>recommendation,</b> defining the core problem and summarizing current methods and notable recent algorithms. We then present our work on implementing the NRAM (News <b>Recommendation</b> with Attention Mechanism), an attention-based approach for news <b>recommendation,</b> and assess its effectiveness. Our evaluation shows that NRAM has the potential to significantly improve how news content is personalized for users on digital news platforms.

{{</citation>}}


## eess.AS (3)



### (131/210) AIR-Bench: Benchmarking Large Audio-Language Models via Generative Comprehension (Qian Yang et al., 2024)

{{<citation>}}

Qian Yang, Jin Xu, Wenrui Liu, Yunfei Chu, Ziyue Jiang, Xiaohuan Zhou, Yichong Leng, Yuanjun Lv, Zhou Zhao, Chang Zhou, Jingren Zhou. (2024)  
**AIR-Bench: Benchmarking Large Audio-Language Models via Generative Comprehension**
<br/>
<button class="copy-to-clipboard" title="AIR-Bench: Benchmarking Large Audio-Language Models via Generative Comprehension" index=131>
  <span class="copy-to-clipboard-item">Copy Title<span>
</button>
<div class="toast toast-copied toast-index-131 align-items-center text-bg-secondary border-0 position-absolute top-0 end-0" role="alert" aria-live="assertive" aria-atomic="true">
  <div class="d-flex">
    <div class="toast-body">
      Copied!
    </div>
  </div>
</div>

---
Primary Category: eess.AS  
Categories: cs-CL, cs-LG, cs-SD, eess-AS, eess.AS  
Keyword Score: 60  
Keywords: GPT, GPT-4, Automatic Speech Recognition, Automatic Speech Recognition, Automatic Speech Recognition, Instruction Following  
<a type="button" class="btn btn-outline-primary" href="http://arxiv.org/abs/2402.07729v1" target="_blank" >Paper Link</a>
<button type="button" class="btn btn-outline-primary download-pdf" url="https://arxiv.org/pdf/2402.07729v1.pdf" filename="2402.07729v1.pdf">Download PDF</button>

---


**ABSTRACT**  
Recently, <b>instruction-following</b> <b>audio-language</b> models have received broad attention for human-audio interaction. However, the absence of benchmarks capable of evaluating audio-centric interaction capabilities has impeded advancements in this field. Previous models primarily focus on assessing different fundamental tasks, such as <b>Automatic</b> <b>Speech</b> <b>Recognition</b> <b>(ASR),</b> and lack an assessment of the open-ended generative capabilities centered around audio. Thus, it is challenging to track the progression in the Large Audio-Language Models (LALMs) domain and to provide guidance for future improvement. In this paper, we introduce AIR-Bench (\textbf{A}udio \textbf{I}nst\textbf{R}uction \textbf{Bench}mark), the first benchmark designed to evaluate the ability of LALMs to understand various types of audio signals (including human <b>speech,</b> <b>natural</b> sounds, and music), and furthermore, to interact with humans in the textual format. AIR-Bench encompasses two dimensions: \textit{foundation} and \textit{chat} benchmarks. The former consists of 19 tasks with approximately 19k single-choice questions, intending to inspect the basic single-task ability of LALMs. The latter one contains 2k instances of open-ended question-and-answer data, directly assessing the comprehension of the model on complex audio and its capacity to follow <b>instructions.</b> <b>Both</b> benchmarks require the model to generate hypotheses directly. We design a unified framework that leverages advanced language models, such as <b>GPT-4,</b> to evaluate the scores of generated hypotheses given the meta-information of the audio. Experimental results demonstrate a high level of consistency between <b>GPT-4-based</b> evaluation and human evaluation. By revealing the limitations of existing LALMs through evaluation results, AIR-Bench can provide insights into the direction of future research.

{{</citation>}}


### (132/210) Making Flow-Matching-Based Zero-Shot Text-to-Speech Laugh as You Like (Naoyuki Kanda et al., 2024)

{{<citation>}}

Naoyuki Kanda, Xiaofei Wang, Sefik Emre Eskimez, Manthan Thakker, Hemin Yang, Zirun Zhu, Min Tang, Canrun Li, Steven Tsai, Zhen Xiao, Yufei Xia, Jinzhu Li, Yanqing Liu, Sheng Zhao, Michael Zeng. (2024)  
**Making Flow-Matching-Based Zero-Shot Text-to-Speech Laugh as You Like**
<br/>
<button class="copy-to-clipboard" title="Making Flow-Matching-Based Zero-Shot Text-to-Speech Laugh as You Like" index=132>
  <span class="copy-to-clipboard-item">Copy Title<span>
</button>
<div class="toast toast-copied toast-index-132 align-items-center text-bg-secondary border-0 position-absolute top-0 end-0" role="alert" aria-live="assertive" aria-atomic="true">
  <div class="d-flex">
    <div class="toast-body">
      Copied!
    </div>
  </div>
</div>

---
Primary Category: eess.AS  
Categories: cs-CL, cs-LG, cs-SD, eess-AS, eess.AS  
Keyword Score: 50  
Keywords: Fine-tuning, Zero-shot, Text-to-speech, Text-to-speech, Prompt  
<a type="button" class="btn btn-outline-primary" href="http://arxiv.org/abs/2402.07383v1" target="_blank" >Paper Link</a>
<button type="button" class="btn btn-outline-primary download-pdf" url="https://arxiv.org/pdf/2402.07383v1.pdf" filename="2402.07383v1.pdf">Download PDF</button>

---


**ABSTRACT**  
Laughter is one of the most expressive and natural aspects of human speech, conveying emotions, social cues, and humor. However, most <b>text-to-speech</b> <b>(TTS)</b> systems lack the ability to produce realistic and appropriate laughter sounds, limiting their applications and user experience. While there have been prior works to generate natural laughter, they fell short in terms of controlling the timing and variety of the laughter to be generated. In this work, we propose ELaTE, a <b>zero-shot</b> <b>TTS</b> that can generate natural laughing speech of any speaker based on a short audio <b>prompt</b> with precise control of laughter timing and expression. Specifically, ELaTE works on the audio <b>prompt</b> to mimic the voice characteristic, the text <b>prompt</b> to indicate the contents of the generated speech, and the input to control the laughter expression, which can be either the start and end times of laughter, or the additional audio <b>prompt</b> that contains laughter to be mimicked. We develop our model based on the foundation of conditional flow-matching-based <b>zero-shot</b> <b>TTS,</b> and <b>fine-tune</b> it with frame-level representation from a laughter detector as additional conditioning. With a simple scheme to mix small-scale laughter-conditioned data with large-scale pre-training data, we demonstrate that a pre-trained <b>zero-shot</b> <b>TTS</b> model can be readily <b>fine-tuned</b> to generate natural laughter with precise controllability, without losing any quality of the pre-trained <b>zero-shot</b> <b>TTS</b> model. Through the evaluations, we show that ELaTE can generate laughing speech with significantly higher quality and controllability compared to conventional models. See https://aka.ms/elate/ for demo samples.

{{</citation>}}


### (133/210) Interactive singing melody extraction based on active adaptation (Kavya Ranjan Saxena et al., 2024)

{{<citation>}}

Kavya Ranjan Saxena, Vipul Arora. (2024)  
**Interactive singing melody extraction based on active adaptation**
<br/>
<button class="copy-to-clipboard" title="Interactive singing melody extraction based on active adaptation" index=133>
  <span class="copy-to-clipboard-item">Copy Title<span>
</button>
<div class="toast toast-copied toast-index-133 align-items-center text-bg-secondary border-0 position-absolute top-0 end-0" role="alert" aria-live="assertive" aria-atomic="true">
  <div class="d-flex">
    <div class="toast-body">
      Copied!
    </div>
  </div>
</div>

---
Primary Category: eess.AS  
Categories: cs-SD, eess-AS, eess.AS  
Keyword Score: 20  
Keywords: Meta Learning, Information Retrieval  
<a type="button" class="btn btn-outline-primary" href="http://arxiv.org/abs/2402.07599v1" target="_blank" >Paper Link</a>
<button type="button" class="btn btn-outline-primary download-pdf" url="https://arxiv.org/pdf/2402.07599v1.pdf" filename="2402.07599v1.pdf">Download PDF</button>

---


**ABSTRACT**  
Extraction of predominant pitch from polyphonic audio is one of the fundamental tasks in the field of music <b>information</b> <b>retrieval</b> and computational musicology. To accomplish this task using machine learning, a large amount of labeled audio data is required to train the model. However, a classical model pre-trained on data from one domain (source), e.g., songs of a particular singer or genre, may not perform comparatively well in extracting melody from other domains (target). The performance of such models can be boosted by adapting the model using very little annotated data from the target domain. In this work, we propose an efficient interactive melody adaptation method. Our method selects the regions in the target audio that require human annotation using a confidence criterion based on normalized true class probability. The annotations are used by the model to adapt itself to the target domain using <b>meta-learning.</b> <b>Our</b> method also provides a novel <b>meta-learning</b> <b>approach</b> that handles class imbalance, i.e., a few representative samples from a few classes are available for adaptation in the target domain. Experimental results show that the proposed method outperforms other adaptive melody extraction baselines. The proposed method is model-agnostic and hence can be applied to other non-adaptive melody extraction models to boost their performance. Also, we released a Hindustani Alankaar and Raga (HAR) dataset containing 523 audio files of about 6.86 hours of duration intended for singing melody extraction tasks.

{{</citation>}}


## cs.MM (2)



### (134/210) BDIQA: A New Dataset for Video Question Answering to Explore Cognitive Reasoning through Theory of Mind (Yuanyuan Mao et al., 2024)

{{<citation>}}

Yuanyuan Mao, Xin Lin, Qin Ni, Liang He. (2024)  
**BDIQA: A New Dataset for Video Question Answering to Explore Cognitive Reasoning through Theory of Mind**
<br/>
<button class="copy-to-clipboard" title="BDIQA: A New Dataset for Video Question Answering to Explore Cognitive Reasoning through Theory of Mind" index=134>
  <span class="copy-to-clipboard-item">Copy Title<span>
</button>
<div class="toast toast-copied toast-index-134 align-items-center text-bg-secondary border-0 position-absolute top-0 end-0" role="alert" aria-live="assertive" aria-atomic="true">
  <div class="d-flex">
    <div class="toast-body">
      Copied!
    </div>
  </div>
</div>

---
Primary Category: cs.MM  
Categories: cs-AI, cs-MM, cs.MM  
Keyword Score: 60  
Keywords: Few-shot, Supervised Learning, Supervised Learning, Zero-shot, Question Answering, Reasoning  
<a type="button" class="btn btn-outline-primary" href="http://arxiv.org/abs/2402.07402v1" target="_blank" >Paper Link</a>
<button type="button" class="btn btn-outline-primary download-pdf" url="https://arxiv.org/pdf/2402.07402v1.pdf" filename="2402.07402v1.pdf">Download PDF</button>

---


**ABSTRACT**  
As a foundational component of cognitive intelligence, theory of mind (ToM) can make AI more closely resemble human thought processes, thereby enhancing their interaction and collaboration with human. In particular, it can significantly improve a model's comprehension of videos in complex scenes. However, current video <b>question</b> <b>answer</b> (VideoQA) datasets focus on studying causal <b>reasoning</b> within events few of them genuinely incorporating human ToM. Consequently, there is a lack of development in ToM <b>reasoning</b> tasks within the area of VideoQA. This paper presents BDIQA, the first benchmark to explore the cognitive <b>reasoning</b> capabilities of VideoQA models in the context of ToM. BDIQA is inspired by the cognitive development of children's ToM and addresses the current deficiencies in machine ToM within datasets and tasks. Specifically, it offers tasks at two difficulty levels, assessing Belief, Desire and Intention (BDI) <b>reasoning</b> in both simple and complex scenarios. We conduct evaluations on several mainstream methods of VideoQA and diagnose their capabilities with zero shot, few shot and <b>supervised</b> <b>learning.</b> We find that the performance of pre-trained models on cognitive <b>reasoning</b> tasks remains unsatisfactory. To counter this challenge, we undertake thorough analysis and experimentation, ultimately presenting two guidelines to enhance cognitive <b>reasoning</b> derived from ablation analysis.

{{</citation>}}


### (135/210) Synthesizing Sentiment-Controlled Feedback For Multimodal Text and Image Data (Puneet Kumar et al., 2024)

{{<citation>}}

Puneet Kumar, Sarthak Malik, Balasubramanian Raman, Xiaobai Li. (2024)  
**Synthesizing Sentiment-Controlled Feedback For Multimodal Text and Image Data**
<br/>
<button class="copy-to-clipboard" title="Synthesizing Sentiment-Controlled Feedback For Multimodal Text and Image Data" index=135>
  <span class="copy-to-clipboard-item">Copy Title<span>
</button>
<div class="toast toast-copied toast-index-135 align-items-center text-bg-secondary border-0 position-absolute top-0 end-0" role="alert" aria-live="assertive" aria-atomic="true">
  <div class="d-flex">
    <div class="toast-body">
      Copied!
    </div>
  </div>
</div>

---
Primary Category: cs.MM  
Categories: cs-AI, cs-MM, cs.MM  
Keyword Score: 16  
Keywords: Multi-modal, Multi-modal, Transformer  
<a type="button" class="btn btn-outline-primary" href="http://arxiv.org/abs/2402.07640v1" target="_blank" >Paper Link</a>
<button type="button" class="btn btn-outline-primary download-pdf" url="https://arxiv.org/pdf/2402.07640v1.pdf" filename="2402.07640v1.pdf">Download PDF</button>

---


**ABSTRACT**  
The ability to generate sentiment-controlled feedback in response to <b>multimodal</b> inputs, comprising both text and images, addresses a critical gap in human-computer interaction by enabling systems to provide empathetic, accurate, and engaging responses. This capability has profound applications in healthcare, marketing, and education. To this end, we construct a large-scale Controllable <b>Multimodal</b> Feedback Synthesis (CMFeed) dataset and propose a controllable feedback synthesis system. The proposed system includes an encoder, decoder, and controllability block for textual and visual inputs. It extracts textual and visual features using a <b>transformer</b> and Faster R-CNN networks and combines them to generate feedback. The CMFeed dataset encompasses images, text, reactions to the post, human comments with relevance scores, and reactions to the comments. The reactions to the post and comments are utilized to train the proposed model to produce feedback with a particular (positive or negative) sentiment. A sentiment classification accuracy of 77.23% has been achieved, 18.82% higher than the accuracy without using the controllability. Moreover, the system incorporates a similarity module for assessing feedback relevance through rank-based metrics. It implements an interpretability technique to analyze the contribution of textual and visual features during the generation of uncontrolled and controlled feedback.

{{</citation>}}


## cs.IR (7)



### (136/210) GRILLBot In Practice: Lessons and Tradeoffs Deploying Large Language Models for Adaptable Conversational Task Assistants (Sophie Fischer et al., 2024)

{{<citation>}}

Sophie Fischer, Carlos Gemmell, Niklas Tecklenburg, Iain Mackie, Federico Rossetto, Jeffrey Dalton. (2024)  
**GRILLBot In Practice: Lessons and Tradeoffs Deploying Large Language Models for Adaptable Conversational Task Assistants**
<br/>
<button class="copy-to-clipboard" title="GRILLBot In Practice: Lessons and Tradeoffs Deploying Large Language Models for Adaptable Conversational Task Assistants" index=136>
  <span class="copy-to-clipboard-item">Copy Title<span>
</button>
<div class="toast toast-copied toast-index-136 align-items-center text-bg-secondary border-0 position-absolute top-0 end-0" role="alert" aria-live="assertive" aria-atomic="true">
  <div class="d-flex">
    <div class="toast-body">
      Copied!
    </div>
  </div>
</div>

---
Primary Category: cs.IR  
Categories: cs-IR, cs.IR  
Keyword Score: 56  
Keywords: Multi-modal, Multi-modal, Code Generation, Question Answering, Reasoning, Large Language Model, Large Language Model  
<a type="button" class="btn btn-outline-primary" href="http://arxiv.org/abs/2402.07647v1" target="_blank" >Paper Link</a>
<button type="button" class="btn btn-outline-primary download-pdf" url="https://arxiv.org/pdf/2402.07647v1.pdf" filename="2402.07647v1.pdf">Download PDF</button>

---


**ABSTRACT**  
We tackle the challenge of building real-world <b>multimodal</b> assistants for complex real-world tasks. We describe the practicalities and challenges of developing and deploying GRILLBot, a leading (first and second prize winning in 2022 and 2023) system deployed in the Alexa Prize TaskBot Challenge. Building on our Open Assistant Toolkit (OAT) framework, we propose a hybrid architecture that leverages <b>Large</b> <b>Language</b> <b>Models</b> <b>(LLMs)</b> and specialised models tuned for specific subtasks requiring very low latency. OAT allows us to define when, how and which <b>LLMs</b> should be used in a structured and deployable manner. For knowledge-grounded <b>question</b> <b>answering</b> and live task adaptations, we show that <b>LLM</b> <b>reasoning</b> abilities over task context and world knowledge outweigh latency concerns. For dialogue state management, we implement a <b>code</b> <b>generation</b> approach and show that specialised smaller models have 84% effectiveness with 100x lower latency. Overall, we provide insights and discuss tradeoffs for deploying both traditional models and <b>LLMs</b> to users in complex real-world <b>multimodal</b> environments in the Alexa TaskBot challenge. These experiences will continue to evolve as <b>LLMs</b> become more capable and efficient -- fundamentally reshaping OAT and future assistant architectures.

{{</citation>}}


### (137/210) Multi-Behavior Collaborative Filtering with Partial Order Graph Convolutional Networks (Yijie Zhang et al., 2024)

{{<citation>}}

Yijie Zhang, Yuanchen Bei, Hao Chen, Qijie Shen, Zheng Yuan, Huan Gong, Senzhang Wang, Feiran Huang, Xiao Huang. (2024)  
**Multi-Behavior Collaborative Filtering with Partial Order Graph Convolutional Networks**
<br/>
<button class="copy-to-clipboard" title="Multi-Behavior Collaborative Filtering with Partial Order Graph Convolutional Networks" index=137>
  <span class="copy-to-clipboard-item">Copy Title<span>
</button>
<div class="toast toast-copied toast-index-137 align-items-center text-bg-secondary border-0 position-absolute top-0 end-0" role="alert" aria-live="assertive" aria-atomic="true">
  <div class="d-flex">
    <div class="toast-body">
      Copied!
    </div>
  </div>
</div>

---
Primary Category: cs.IR  
Categories: cs-IR, cs.IR  
Keyword Score: 50  
Keywords: Graph Convolutional Network, Convolution, Convolutional Neural Network, Recommendation, Recommender System  
<a type="button" class="btn btn-outline-primary" href="http://arxiv.org/abs/2402.07659v1" target="_blank" >Paper Link</a>
<button type="button" class="btn btn-outline-primary download-pdf" url="https://arxiv.org/pdf/2402.07659v1.pdf" filename="2402.07659v1.pdf">Download PDF</button>

---


**ABSTRACT**  
Representing the information of multiple behaviors in the single <b>graph</b> <b>collaborative</b> <b>filtering</b> (CF) vector has been a long-standing challenge. This is because different behaviors naturally form separate behavior <b>graphs</b> <b>and</b> <b>learn</b> separate CF embeddings. Existing models merge the separate embeddings by appointing the CF embeddings for some behaviors as the primary embedding and utilizing other auxiliaries to enhance the primary embedding. However, this approach often results in the joint embedding performing well on the main tasks but poorly on the auxiliary ones. To address the problem arising from the separate behavior <b>graphs,</b> <b>we</b> <b>propose</b> the concept of Partial Order <b>Graphs</b> <b>(POG).</b> <b>POG</b> defines the partial order relation of multiple behaviors and models behavior combinations as weighted edges to merge separate behavior <b>graphs</b> <b>into</b> <b>a</b> joint POG. Theoretical proof verifies that POG can be generalized to any given set of multiple behaviors. Based on POG, we propose the tailored Partial Order <b>Graph</b> <b>Convolutional</b> <b>Networks</b> (POGCN) that convolute neighbors' information while considering the behavior relations between users and items. POGCN also introduces a partial-order BPR sampling strategy for efficient and effective multiple-behavior CF training. POGCN has been successfully deployed on the homepage of Alibaba for two months, providing <b>recommendation</b> services for over one billion users. Extensive offline experiments conducted on three public benchmark datasets demonstrate that POGCN outperforms state-of-the-art multi-behavior baselines across all types of behaviors. Furthermore, online A/B tests confirm the superiority of POGCN in billion-scale <b>recommender</b> <b>systems.</b>

{{</citation>}}


### (138/210) Quantitative knowledge retrieval from large language models (David Selby et al., 2024)

{{<citation>}}

David Selby, Kai Spriestersbach, Yuichiro Iwashita, Dennis Bappert, Archana Warrier, Sumantrak Mukherjee, Muhammad Nabeel Asim, Koichi Kise, Sebastian Vollmer. (2024)  
**Quantitative knowledge retrieval from large language models**
<br/>
<button class="copy-to-clipboard" title="Quantitative knowledge retrieval from large language models" index=138>
  <span class="copy-to-clipboard-item">Copy Title<span>
</button>
<div class="toast toast-copied toast-index-138 align-items-center text-bg-secondary border-0 position-absolute top-0 end-0" role="alert" aria-live="assertive" aria-atomic="true">
  <div class="d-flex">
    <div class="toast-body">
      Copied!
    </div>
  </div>
</div>

---
Primary Category: cs.IR  
Categories: cs-CL, cs-IR, cs.IR, stat-AP  
Keyword Score: 40  
Keywords: Information Retrieval, Large Language Model, Large Language Model, Prompt  
<a type="button" class="btn btn-outline-primary" href="http://arxiv.org/abs/2402.07770v1" target="_blank" >Paper Link</a>
<button type="button" class="btn btn-outline-primary download-pdf" url="https://arxiv.org/pdf/2402.07770v1.pdf" filename="2402.07770v1.pdf">Download PDF</button>

---


**ABSTRACT**  
<b>Large</b> <b>language</b> <b>models</b> <b>(LLMs)</b> have been extensively studied for their abilities to generate convincing natural language sequences, however their utility for quantitative <b>information</b> <b>retrieval</b> is less well understood. In this paper we explore the feasibility of <b>LLMs</b> as a mechanism for quantitative knowledge retrieval to aid data analysis tasks such as elicitation of prior distributions for Bayesian models and imputation of missing data. We present a <b>prompt</b> engineering framework, treating an <b>LLM</b> as an interface to a latent space of scientific literature, comparing responses in different contexts and domains against more established approaches. Implications and challenges of using <b>LLMs</b> as 'experts' are discussed.

{{</citation>}}


### (139/210) VCR: Video representation for Contextual Retrieval (Oron Nir et al., 2024)

{{<citation>}}

Oron Nir, Idan Vidra, Avi Neeman, Barak Kinarti, Ariel Shamir. (2024)  
**VCR: Video representation for Contextual Retrieval**
<br/>
<button class="copy-to-clipboard" title="VCR: Video representation for Contextual Retrieval" index=139>
  <span class="copy-to-clipboard-item">Copy Title<span>
</button>
<div class="toast toast-copied toast-index-139 align-items-center text-bg-secondary border-0 position-absolute top-0 end-0" role="alert" aria-live="assertive" aria-atomic="true">
  <div class="d-flex">
    <div class="toast-body">
      Copied!
    </div>
  </div>
</div>

---
Primary Category: cs.IR  
Categories: cs-IR, cs-MM, cs.IR  
Keyword Score: 30  
Keywords: Recommendation, GPT, GPT-4  
<a type="button" class="btn btn-outline-primary" href="http://arxiv.org/abs/2402.07466v1" target="_blank" >Paper Link</a>
<button type="button" class="btn btn-outline-primary download-pdf" url="https://arxiv.org/pdf/2402.07466v1.pdf" filename="2402.07466v1.pdf">Download PDF</button>

---


**ABSTRACT**  
Streamlining content discovery within media archives requires integrating advanced data representations and effective visualization techniques for clear communication of video topics to users. The proposed system addresses the challenge of efficiently navigating large video collections by exploiting a fusion of visual, audio, and textual features to accurately index and categorize video content through a text-based method. Additionally, semantic embeddings are employed to provide contextually relevant information and <b>recommendations</b> to users, resulting in an intuitive and engaging exploratory experience over our topics ontology map using OpenAI <b>GPT-4.</b>

{{</citation>}}


### (140/210) Benchmarking and Building Long-Context Retrieval Models with LoCo and M2-BERT (Jon Saad-Falcon et al., 2024)

{{<citation>}}

Jon Saad-Falcon, Daniel Y. Fu, Simran Arora, Neel Guha, Christopher Ré. (2024)  
**Benchmarking and Building Long-Context Retrieval Models with LoCo and M2-BERT**
<br/>
<button class="copy-to-clipboard" title="Benchmarking and Building Long-Context Retrieval Models with LoCo and M2-BERT" index=140>
  <span class="copy-to-clipboard-item">Copy Title<span>
</button>
<div class="toast toast-copied toast-index-140 align-items-center text-bg-secondary border-0 position-absolute top-0 end-0" role="alert" aria-live="assertive" aria-atomic="true">
  <div class="d-flex">
    <div class="toast-body">
      Copied!
    </div>
  </div>
</div>

---
Primary Category: cs.IR  
Categories: cs-IR, cs-LG, cs.IR  
Keyword Score: 20  
Keywords: Fine-tuning, Fine-tuning  
<a type="button" class="btn btn-outline-primary" href="http://arxiv.org/abs/2402.07440v1" target="_blank" >Paper Link</a>
<button type="button" class="btn btn-outline-primary download-pdf" url="https://arxiv.org/pdf/2402.07440v1.pdf" filename="2402.07440v1.pdf">Download PDF</button>

---


**ABSTRACT**  
Retrieval pipelines-an integral component of many machine learning systems-perform poorly in domains where documents are long (e.g., 10K tokens or more) and where identifying the relevant document requires synthesizing information across the entire text. Developing long-context retrieval encoders suitable for these domains raises three challenges: (1) how to evaluate long-context retrieval performance, (2) how to pretrain a base language model to represent both short contexts (corresponding to queries) and long contexts (corresponding to documents), and (3) how to <b>fine-tune</b> this model for retrieval under the batch size limitations imposed by GPU memory constraints. To address these challenges, we first introduce LoCoV1, a novel 12 task benchmark constructed to measure long-context retrieval where chunking is not possible or not effective. We next present the M2-BERT retrieval encoder, an 80M parameter state-space encoder model built from the Monarch Mixer architecture, capable of scaling to documents up to 32K tokens long. We describe a pretraining data mixture which allows this encoder to process both short and long context sequences, and a <b>finetuning</b> approach that adapts this base model to retrieval with only single-sample batches. Finally, we validate the M2-BERT retrieval encoder on LoCoV1, finding that it outperforms competitive baselines by up to 23.3 points, despite containing 5-90x fewer parameters.

{{</citation>}}


### (141/210) Debiasing Recommendation with Personal Popularity (Wentao Ning et al., 2024)

{{<citation>}}

Wentao Ning, Reynold Cheng, Xiao Yan, Ben Kao, Nan Huo, Nur AI Hasan Haldar, Bo Tang. (2024)  
**Debiasing Recommendation with Personal Popularity**
<br/>
<button class="copy-to-clipboard" title="Debiasing Recommendation with Personal Popularity" index=141>
  <span class="copy-to-clipboard-item">Copy Title<span>
</button>
<div class="toast toast-copied toast-index-141 align-items-center text-bg-secondary border-0 position-absolute top-0 end-0" role="alert" aria-live="assertive" aria-atomic="true">
  <div class="d-flex">
    <div class="toast-body">
      Copied!
    </div>
  </div>
</div>

---
Primary Category: cs.IR  
Categories: cs-IR, cs.IR  
Keyword Score: 20  
Keywords: Counter-factual, Recommendation  
<a type="button" class="btn btn-outline-primary" href="http://arxiv.org/abs/2402.07425v1" target="_blank" >Paper Link</a>
<button type="button" class="btn btn-outline-primary download-pdf" url="https://arxiv.org/pdf/2402.07425v1.pdf" filename="2402.07425v1.pdf">Download PDF</button>

---


**ABSTRACT**  
Global popularity (GP) bias is the phenomenon that popular items are recommended much more frequently than they should be, which goes against the goal of providing personalized <b>recommendations</b> and harms user experience and <b>recommendation</b> accuracy. Many methods have been proposed to reduce GP bias but they fail to notice the fundamental problem of GP, i.e., it considers popularity from a \textit{global} perspective of \textit{all users} and uses a single set of popular items, and thus cannot capture the interests of individual users. As such, we propose a user-aware version of item popularity named \textit{personal popularity} (PP), which identifies different popular items for each user by considering the users that share similar interests. As PP models the preferences of individual users, it naturally helps to produce personalized <b>recommendations</b> and mitigate GP bias. To integrate PP into <b>recommendation,</b> we design a general \textit{personal popularity aware counterfactual} (PPAC) framework, which adapts easily to existing <b>recommendation</b> models. In particular, PPAC recognizes that PP and GP have both direct and indirect effects on <b>recommendations</b> and controls direct effects with <b>counterfactual</b> inference techniques for unbiased <b>recommendations.</b> All codes and datasets are available at \url{https://github.com/Stevenn9981/PPAC}.

{{</citation>}}


### (142/210) Multimodal Learned Sparse Retrieval for Image Suggestion (Thong Nguyen et al., 2024)

{{<citation>}}

Thong Nguyen, Mariya Hendriksen, Andrew Yates. (2024)  
**Multimodal Learned Sparse Retrieval for Image Suggestion**
<br/>
<button class="copy-to-clipboard" title="Multimodal Learned Sparse Retrieval for Image Suggestion" index=142>
  <span class="copy-to-clipboard-item">Copy Title<span>
</button>
<div class="toast toast-copied toast-index-142 align-items-center text-bg-secondary border-0 position-absolute top-0 end-0" role="alert" aria-live="assertive" aria-atomic="true">
  <div class="d-flex">
    <div class="toast-body">
      Copied!
    </div>
  </div>
</div>

---
Primary Category: cs.IR  
Categories: cs-IR, cs-MM, cs.IR  
Keyword Score: 6  
Keywords: Multi-modal, Multi-modal  
<a type="button" class="btn btn-outline-primary" href="http://arxiv.org/abs/2402.07736v1" target="_blank" >Paper Link</a>
<button type="button" class="btn btn-outline-primary download-pdf" url="https://arxiv.org/pdf/2402.07736v1.pdf" filename="2402.07736v1.pdf">Download PDF</button>

---


**ABSTRACT**  
Learned Sparse Retrieval (LSR) is a group of neural methods designed to encode queries and documents into sparse lexical vectors. These vectors can be efficiently indexed and retrieved using an inverted index. While LSR has shown promise in text retrieval, its potential in <b>multi-modal</b> retrieval remains largely unexplored. Motivated by this, in this work, we explore the application of LSR in the <b>multi-modal</b> domain, i.e., we focus on <b>Multi-Modal</b> Learned Sparse Retrieval (MLSR). We conduct experiments using several MLSR model configurations and evaluate the performance on the image suggestion task. We find that solving the task solely based on the image content is challenging. Enriching the image content with its caption improves the model performance significantly, implying the importance of image captions to provide fine-grained concepts and context information of images. Our approach presents a practical and effective solution for training LSR retrieval models in <b>multi-modal</b> settings.

{{</citation>}}


## cs.CV (26)



### (143/210) Multi-Attribute Vision Transformers are Efficient and Robust Learners (Hanan Gani et al., 2024)

{{<citation>}}

Hanan Gani, Nada Saadi, Noor Hussein, Karthik Nandakumar. (2024)  
**Multi-Attribute Vision Transformers are Efficient and Robust Learners**
<br/>
<button class="copy-to-clipboard" title="Multi-Attribute Vision Transformers are Efficient and Robust Learners" index=143>
  <span class="copy-to-clipboard-item">Copy Title<span>
</button>
<div class="toast toast-copied toast-index-143 align-items-center text-bg-secondary border-0 position-absolute top-0 end-0" role="alert" aria-live="assertive" aria-atomic="true">
  <div class="d-flex">
    <div class="toast-body">
      Copied!
    </div>
  </div>
</div>

---
Primary Category: cs.CV  
Categories: cs-CV, cs.CV  
Keyword Score: 50  
Keywords: Convolution, Convolutional Neural Network, Convolutional Neural Network, Transformer, Adversarial Attack  
<a type="button" class="btn btn-outline-primary" href="http://arxiv.org/abs/2402.08070v1" target="_blank" >Paper Link</a>
<button type="button" class="btn btn-outline-primary download-pdf" url="https://arxiv.org/pdf/2402.08070v1.pdf" filename="2402.08070v1.pdf">Download PDF</button>

---


**ABSTRACT**  
Since their inception, Vision <b>Transformers</b> (ViTs) have emerged as a compelling alternative to <b>Convolutional</b> <b>Neural</b> <b>Networks</b> <b>(CNNs)</b> across a wide spectrum of tasks. ViTs exhibit notable characteristics, including global attention, resilience against occlusions, and adaptability to distribution shifts. One underexplored aspect of ViTs is their potential for multi-attribute learning, referring to their ability to simultaneously grasp multiple attribute-related tasks. In this paper, we delve into the multi-attribute learning capability of ViTs, presenting a straightforward yet effective strategy for training various attributes through a single ViT network as distinct tasks. We assess the resilience of multi-attribute ViTs against <b>adversarial</b> <b>attacks</b> and compare their performance against ViTs designed for single attributes. Moreover, we further evaluate the robustness of multi-attribute ViTs against a recent <b>transformer</b> based attack called Patch-Fool. Our empirical findings on the CelebA dataset provide validation for our assertion.

{{</citation>}}


### (144/210) Lumos : Empowering Multimodal LLMs with Scene Text Recognition (Ashish Shenoy et al., 2024)

{{<citation>}}

Ashish Shenoy, Yichao Lu, Srihari Jayakumar, Debojeet Chatterjee, Mohsen Moslehpour, Pierce Chuang, Abhay Harpale, Vikas Bhardwaj, Di Xu, Shicong Zhao, Longfang Zhao, Ankit Ramchandani, Xin Luna Dong, Anuj Kumar. (2024)  
**Lumos : Empowering Multimodal LLMs with Scene Text Recognition**
<br/>
<button class="copy-to-clipboard" title="Lumos : Empowering Multimodal LLMs with Scene Text Recognition" index=144>
  <span class="copy-to-clipboard-item">Copy Title<span>
</button>
<div class="toast toast-copied toast-index-144 align-items-center text-bg-secondary border-0 position-absolute top-0 end-0" role="alert" aria-live="assertive" aria-atomic="true">
  <div class="d-flex">
    <div class="toast-body">
      Copied!
    </div>
  </div>
</div>

---
Primary Category: cs.CV  
Categories: cs-CL, cs-CV, cs-LG, cs.CV  
Keyword Score: 46  
Keywords: Multi-modal, Multi-modal, Question Answering, Large Language Model, Large Language Model, Text Understanding  
<a type="button" class="btn btn-outline-primary" href="http://arxiv.org/abs/2402.08017v1" target="_blank" >Paper Link</a>
<button type="button" class="btn btn-outline-primary download-pdf" url="https://arxiv.org/pdf/2402.08017v1.pdf" filename="2402.08017v1.pdf">Download PDF</button>

---


**ABSTRACT**  
We introduce Lumos, the first end-to-end <b>multimodal</b> <b>question-answering</b> <b>system</b> with <b>text</b> <b>understanding</b> capabilities. At the core of Lumos is a Scene <b>Text</b> <b>Recognition</b> (STR) component that extracts <b>text</b> <b>from</b> first person point-of-view images, the output of which is used to augment input to a <b>Multimodal</b> <b>Large</b> <b>Language</b> <b>Model</b> (MM-LLM). While building Lumos, we encountered numerous challenges related to STR quality, overall latency, and model inference. In this paper, we delve into those challenges, and discuss the system architecture, design choices, and modeling techniques employed to overcome these obstacles. We also provide a comprehensive evaluation for each component, showcasing high quality and efficiency.

{{</citation>}}


### (145/210) MODIPHY: Multimodal Obscured Detection for IoT using PHantom Convolution-Enabled Faster YOLO (Shubhabrata Mukherjee et al., 2024)

{{<citation>}}

Shubhabrata Mukherjee, Cory Beard, Zhu Li. (2024)  
**MODIPHY: Multimodal Obscured Detection for IoT using PHantom Convolution-Enabled Faster YOLO**
<br/>
<button class="copy-to-clipboard" title="MODIPHY: Multimodal Obscured Detection for IoT using PHantom Convolution-Enabled Faster YOLO" index=145>
  <span class="copy-to-clipboard-item">Copy Title<span>
</button>
<div class="toast toast-copied toast-index-145 align-items-center text-bg-secondary border-0 position-absolute top-0 end-0" role="alert" aria-live="assertive" aria-atomic="true">
  <div class="d-flex">
    <div class="toast-body">
      Copied!
    </div>
  </div>
</div>

---
Primary Category: cs.CV  
Categories: cs-CV, cs.CV  
Keyword Score: 36  
Keywords: Object Detection, Convolution, Multi-modal, Multi-modal, Transfer Learning  
<a type="button" class="btn btn-outline-primary" href="http://arxiv.org/abs/2402.07894v1" target="_blank" >Paper Link</a>
<button type="button" class="btn btn-outline-primary download-pdf" url="https://arxiv.org/pdf/2402.07894v1.pdf" filename="2402.07894v1.pdf">Download PDF</button>

---


**ABSTRACT**  
Low-light conditions and occluded scenarios impede <b>object</b> <b>detection</b> in real-world Internet of Things (IoT) applications like autonomous vehicles and security systems. While advanced machine learning models strive for accuracy, their computational demands clash with the limitations of resource-constrained devices, hampering real-time performance. In our current research, we tackle this challenge, by introducing "YOLO Phantom", one of the smallest YOLO models ever conceived. YOLO Phantom utilizes the novel Phantom <b>Convolution</b> block, achieving comparable accuracy to the latest YOLOv8n model while simultaneously reducing both parameters and model size by 43%, resulting in a significant 19% reduction in Giga Floating Point Operations (GFLOPs). YOLO Phantom leverages <b>transfer</b> <b>learning</b> on our <b>multimodal</b> RGB-infrared dataset to address low-light and occlusion issues, equipping it with robust vision under adverse conditions. Its real-world efficacy is demonstrated on an IoT platform with advanced low-light and RGB cameras, seamlessly connecting to an AWS-based notification endpoint for efficient real-time <b>object</b> <b>detection.</b> Benchmarks reveal a substantial boost of 17% and 14% in frames per second (FPS) for thermal and RGB detection, respectively, compared to the baseline YOLOv8n model. For community contribution, both the code and the <b>multimodal</b> dataset are available on GitHub.

{{</citation>}}


### (146/210) Unmasking honey adulteration : a breakthrough in quality assurance through cutting-edge convolutional neural network analysis of thermal images (Ilias Boulbarj et al., 2024)

{{<citation>}}

Ilias Boulbarj, Bouklouze Abdelaziz, Yousra El Alami, Douzi Samira, Douzi Hassan. (2024)  
**Unmasking honey adulteration : a breakthrough in quality assurance through cutting-edge convolutional neural network analysis of thermal images**
<br/>
<button class="copy-to-clipboard" title="Unmasking honey adulteration : a breakthrough in quality assurance through cutting-edge convolutional neural network analysis of thermal images" index=146>
  <span class="copy-to-clipboard-item">Copy Title<span>
</button>
<div class="toast toast-copied toast-index-146 align-items-center text-bg-secondary border-0 position-absolute top-0 end-0" role="alert" aria-live="assertive" aria-atomic="true">
  <div class="d-flex">
    <div class="toast-body">
      Copied!
    </div>
  </div>
</div>

---
Primary Category: cs.CV  
Categories: cs-CV, cs.CV  
Keyword Score: 30  
Keywords: Convolution, Convolutional Neural Network, Convolutional Neural Network  
<a type="button" class="btn btn-outline-primary" href="http://arxiv.org/abs/2402.08122v1" target="_blank" >Paper Link</a>
<button type="button" class="btn btn-outline-primary download-pdf" url="https://arxiv.org/pdf/2402.08122v1.pdf" filename="2402.08122v1.pdf">Download PDF</button>

---


**ABSTRACT**  
Honey, a natural product generated from organic sources, is widely recognized for its revered reputation. Nevertheless, honey is susceptible to adulteration, a situation that has substantial consequences for both the well-being of the general population and the financial well-being of a country. Conventional approaches for detecting honey adulteration are often associated with extensive time requirements and restricted sensitivity. This paper presents a novel approach to address the aforementioned issue by employing <b>Convolutional</b> <b>Neural</b> <b>Networks</b> <b>(CNNs)</b> for the classification of honey samples based on thermal images. The use of thermal imaging technique offers a significant advantage in detecting adulterants, as it can reveal differences in temperature in honey samples caused by variations in sugar composition, moisture levels, and other substances used for adulteration. To establish a meticulous approach to categorizing honey, a thorough dataset comprising thermal images of authentic and tainted honey samples was collected. Several state-of-the-art <b>Convolutional</b> <b>Neural</b> <b>Network</b> <b>(CNN)</b> models were trained and optimized using the dataset that was gathered. Within this set of models, there exist pre-trained models such as InceptionV3, Xception, VGG19, and ResNet that have exhibited exceptional performance, achieving classification accuracies ranging from 88% to 98%. Furthermore, we have implemented a more streamlined and less complex <b>convolutional</b> <b>neural</b> <b>network</b> <b>(CNN)</b> model, outperforming comparable models with an outstanding accuracy rate of 99%. This simplification offers not only the sole advantage of the model, but it also concurrently offers a more efficient solution in terms of resources and time. This approach offers a viable way to implement quality control measures in the honey business, so guaranteeing the genuineness and safety of this valuable organic commodity.

{{</citation>}}


### (147/210) Beyond the Mud: Datasets and Benchmarks for Computer Vision in Off-Road Racing (Jacob Tyo et al., 2024)

{{<citation>}}

Jacob Tyo, Motolani Olarinre, Youngseog Chung, Zachary C. Lipton. (2024)  
**Beyond the Mud: Datasets and Benchmarks for Computer Vision in Off-Road Racing**
<br/>
<button class="copy-to-clipboard" title="Beyond the Mud: Datasets and Benchmarks for Computer Vision in Off-Road Racing" index=147>
  <span class="copy-to-clipboard-item">Copy Title<span>
</button>
<div class="toast toast-copied toast-index-147 align-items-center text-bg-secondary border-0 position-absolute top-0 end-0" role="alert" aria-live="assertive" aria-atomic="true">
  <div class="d-flex">
    <div class="toast-body">
      Copied!
    </div>
  </div>
</div>

---
Primary Category: cs.CV  
Categories: cs-CV, cs.CV  
Keyword Score: 30  
Keywords: Optical Character Recognition, Optical Character Recognition, Fine-tuning  
<a type="button" class="btn btn-outline-primary" href="http://arxiv.org/abs/2402.08025v1" target="_blank" >Paper Link</a>
<button type="button" class="btn btn-outline-primary download-pdf" url="https://arxiv.org/pdf/2402.08025v1.pdf" filename="2402.08025v1.pdf">Download PDF</button>

---


**ABSTRACT**  
Despite significant progress in <b>optical</b> <b>character</b> <b>recognition</b> <b>(OCR)</b> and computer vision systems, robustly recognizing text and identifying people in images taken in unconstrained \emph{in-the-wild} environments remain an ongoing challenge. However, such obstacles must be overcome in practical applications of vision systems, such as identifying racers in photos taken during off-road racing events. To this end, we introduce two new challenging real-world datasets - the off-road motorcycle Racer Number Dataset (RND) and the Muddy Racer re-iDentification Dataset (MUDD) - to highlight the shortcomings of current methods and drive advances in <b>OCR</b> and person re-identification (ReID) under extreme conditions. These two datasets feature over 6,300 images taken during off-road competitions which exhibit a variety of factors that undermine even modern vision systems, namely mud, complex poses, and motion blur. We establish benchmark performance on both datasets using state-of-the-art models. Off-the-shelf models transfer poorly, reaching only 15% end-to-end (E2E) F1 score on text spotting, and 33% rank-1 accuracy on ReID. <b>Fine-tuning</b> yields major improvements, bringing model performance to 53% F1 score for E2E text spotting and 79% rank-1 accuracy on ReID, but still falls short of good performance. Our analysis exposes open problems in real-world <b>OCR</b> and ReID that necessitate domain-targeted techniques. With these datasets and analysis of model limitations, we aim to foster innovations in handling real-world conditions like mud and complex poses to drive progress in robust computer vision. All data was sourced from PerformancePhoto.co, a website used by professional motorsports photographers, racers, and fans. The top-performing text spotting and ReID models are deployed on this platform to power real-time race photo search.

{{</citation>}}


### (148/210) Contrastive Multiple Instance Learning for Weakly Supervised Person ReID (Jacob Tyo et al., 2024)

{{<citation>}}

Jacob Tyo, Zachary C. Lipton. (2024)  
**Contrastive Multiple Instance Learning for Weakly Supervised Person ReID**
<br/>
<button class="copy-to-clipboard" title="Contrastive Multiple Instance Learning for Weakly Supervised Person ReID" index=148>
  <span class="copy-to-clipboard-item">Copy Title<span>
</button>
<div class="toast toast-copied toast-index-148 align-items-center text-bg-secondary border-0 position-absolute top-0 end-0" role="alert" aria-live="assertive" aria-atomic="true">
  <div class="d-flex">
    <div class="toast-body">
      Copied!
    </div>
  </div>
</div>

---
Primary Category: cs.CV  
Categories: cs-CV, cs-LG, cs.CV  
Keyword Score: 30  
Keywords: Multiple Instance Learning, Supervised Learning, Weakly-supervised Learning  
<a type="button" class="btn btn-outline-primary" href="http://arxiv.org/abs/2402.07685v1" target="_blank" >Paper Link</a>
<button type="button" class="btn btn-outline-primary download-pdf" url="https://arxiv.org/pdf/2402.07685v1.pdf" filename="2402.07685v1.pdf">Download PDF</button>

---


**ABSTRACT**  
The acquisition of large-scale, precisely labeled datasets for person re-identification (ReID) poses a significant challenge. Weakly <b>supervised</b> ReID has begun to address this issue, although its performance lags behind fully <b>supervised</b> methods. In response, we introduce Contrastive <b>Multiple</b> <b>Instance</b> <b>Learning</b> (CMIL), a novel framework tailored for more effective weakly <b>supervised</b> ReID. CMIL distinguishes itself by requiring only a single model and no pseudo labels while leveraging contrastive losses -- a technique that has significantly enhanced traditional ReID performance yet is absent in all prior MIL-based approaches. Through extensive experiments and analysis across three datasets, CMIL not only matches state-of-the-art performance on the large-scale SYSU-30k dataset with fewer assumptions but also consistently outperforms all baselines on the WL-market1501 and Weakly Labeled MUddy racer re-iDentification dataset (WL-MUDD) datasets. We introduce and release the WL-MUDD dataset, an extension of the MUDD dataset featuring naturally occurring weak labels from the real-world application at PerformancePhoto.co. All our code and data are accessible at https://drive.google.com/file/d/1rjMbWB6m-apHF3Wg_cfqc8QqKgQ21AsT/view?usp=drive_link.

{{</citation>}}


### (149/210) AYDIV: Adaptable Yielding 3D Object Detection via Integrated Contextual Vision Transformer (Tanmoy Dam et al., 2024)

{{<citation>}}

Tanmoy Dam, Sanjay Bhargav Dharavath, Sameer Alam, Nimrod Lilith, Supriyo Chakraborty, Mir Feroskhan. (2024)  
**AYDIV: Adaptable Yielding 3D Object Detection via Integrated Contextual Vision Transformer**
<br/>
<button class="copy-to-clipboard" title="AYDIV: Adaptable Yielding 3D Object Detection via Integrated Contextual Vision Transformer" index=149>
  <span class="copy-to-clipboard-item">Copy Title<span>
</button>
<div class="toast toast-copied toast-index-149 align-items-center text-bg-secondary border-0 position-absolute top-0 end-0" role="alert" aria-live="assertive" aria-atomic="true">
  <div class="d-flex">
    <div class="toast-body">
      Copied!
    </div>
  </div>
</div>

---
Primary Category: cs.CV  
Categories: cs-AI, cs-CV, cs-RO, cs.CV  
Keyword Score: 30  
Keywords: Object Detection, Fine-tuning, Transformer  
<a type="button" class="btn btn-outline-primary" href="http://arxiv.org/abs/2402.07680v1" target="_blank" >Paper Link</a>
<button type="button" class="btn btn-outline-primary download-pdf" url="https://arxiv.org/pdf/2402.07680v1.pdf" filename="2402.07680v1.pdf">Download PDF</button>

---


**ABSTRACT**  
Combining LiDAR and camera data has shown potential in enhancing short-distance <b>object</b> <b>detection</b> in autonomous driving systems. Yet, the fusion encounters difficulties with extended distance detection due to the contrast between LiDAR's sparse data and the dense resolution of cameras. Besides, discrepancies in the two data representations further complicate fusion methods. We introduce AYDIV, a novel framework integrating a tri-phase alignment process specifically designed to enhance long-distance detection even amidst data discrepancies. AYDIV consists of the Global Contextual Fusion Alignment <b>Transformer</b> (GCFAT), which improves the extraction of camera features and provides a deeper understanding of large-scale patterns; the Sparse Fused Feature Attention (SFFA), which <b>fine-tunes</b> the fusion of LiDAR and camera details; and the Volumetric Grid Attention (VGA) for a comprehensive spatial data fusion. AYDIV's performance on the Waymo Open Dataset (WOD) with an improvement of 1.24% in mAPH value(L2 difficulty) and the Argoverse2 Dataset with a performance improvement of 7.40% in AP value demonstrates its efficacy in comparison to other existing fusion-based methods. Our code is publicly available at https://github.com/sanjay-810/AYDIV2

{{</citation>}}


### (150/210) Unsupervised Discovery of Object-Centric Neural Fields (Rundong Luo et al., 2024)

{{<citation>}}

Rundong Luo, Hong-Xing Yu, Jiajun Wu. (2024)  
**Unsupervised Discovery of Object-Centric Neural Fields**
<br/>
<button class="copy-to-clipboard" title="Unsupervised Discovery of Object-Centric Neural Fields" index=150>
  <span class="copy-to-clipboard-item">Copy Title<span>
</button>
<div class="toast toast-copied toast-index-150 align-items-center text-bg-secondary border-0 position-absolute top-0 end-0" role="alert" aria-live="assertive" aria-atomic="true">
  <div class="d-flex">
    <div class="toast-body">
      Copied!
    </div>
  </div>
</div>

---
Primary Category: cs.CV  
Categories: cs-CV, cs.CV  
Keyword Score: 30  
Keywords: Unsupervised Learning, Unsupervised Learning, Zero-shot  
<a type="button" class="btn btn-outline-primary" href="http://arxiv.org/abs/2402.07376v1" target="_blank" >Paper Link</a>
<button type="button" class="btn btn-outline-primary download-pdf" url="https://arxiv.org/pdf/2402.07376v1.pdf" filename="2402.07376v1.pdf">Download PDF</button>

---


**ABSTRACT**  
We study inferring 3D object-centric scene representations from a single image. While recent methods have shown potential in <b>unsupervised</b> <b>3D</b> object discovery from simple synthetic images, they fail to generalize to real-world scenes with visually rich and diverse objects. This limitation stems from their object representations, which entangle objects' intrinsic attributes like shape and appearance with extrinsic, viewer-centric properties such as their 3D location. To address this bottleneck, we propose <b>Unsupervised</b> <b>discovery</b> of Object-Centric neural Fields (uOCF). uOCF focuses on learning the intrinsics of objects and models the extrinsics separately. Our approach significantly improves systematic generalization, thus enabling <b>unsupervised</b> <b>learning</b> of high-fidelity object-centric scene representations from sparse real-world images. To evaluate our approach, we collect three new datasets, including two real kitchen environments. Extensive experiments show that uOCF enables <b>unsupervised</b> <b>discovery</b> of visually rich objects from a single real image, allowing applications such as 3D object segmentation and scene manipulation. Notably, uOCF demonstrates <b>zero-shot</b> generalization to unseen objects from a single real image. Project page: https://red-fairy.github.io/uOCF/

{{</citation>}}


### (151/210) Real-World Atmospheric Turbulence Correction via Domain Adaptation (Xijun Wang et al., 2024)

{{<citation>}}

Xijun Wang, Santiago López-Tapia, Aggelos K. Katsaggelos. (2024)  
**Real-World Atmospheric Turbulence Correction via Domain Adaptation**
<br/>
<button class="copy-to-clipboard" title="Real-World Atmospheric Turbulence Correction via Domain Adaptation" index=151>
  <span class="copy-to-clipboard-item">Copy Title<span>
</button>
<div class="toast toast-copied toast-index-151 align-items-center text-bg-secondary border-0 position-absolute top-0 end-0" role="alert" aria-live="assertive" aria-atomic="true">
  <div class="d-flex">
    <div class="toast-body">
      Copied!
    </div>
  </div>
</div>

---
Primary Category: cs.CV  
Categories: cs-CV, cs.CV, eess-IV  
Keyword Score: 30  
Keywords: Supervised Learning, Unsupervised Learning, Domain Adaptation  
<a type="button" class="btn btn-outline-primary" href="http://arxiv.org/abs/2402.07371v1" target="_blank" >Paper Link</a>
<button type="button" class="btn btn-outline-primary download-pdf" url="https://arxiv.org/pdf/2402.07371v1.pdf" filename="2402.07371v1.pdf">Download PDF</button>

---


**ABSTRACT**  
Atmospheric turbulence, a common phenomenon in daily life, is primarily caused by the uneven heating of the Earth's surface. This phenomenon results in distorted and blurred acquired images or videos and can significantly impact downstream vision tasks, particularly those that rely on capturing clear, stable images or videos from outdoor environments, such as accurately detecting or recognizing objects. Therefore, people have proposed ways to simulate atmospheric turbulence and designed effective deep learning-based methods to remove the atmospheric turbulence effect. However, these synthesized turbulent images can not cover all the range of real-world turbulence effects. Though the models have achieved great performance for synthetic scenarios, there always exists a performance drop when applied to real-world cases. Moreover, reducing real-world turbulence is a more challenging task as there are no clean ground truth counterparts provided to the models during training. In this paper, we propose a real-world atmospheric turbulence mitigation model under a <b>domain</b> <b>adaptation</b> framework, which links the <b>supervised</b> simulated atmospheric turbulence correction with the <b>unsupervised</b> real-world atmospheric turbulence correction. We will show our proposed method enhances performance in real-world atmospheric turbulence scenarios, improving both image quality and downstream vision tasks.

{{</citation>}}


### (152/210) Multiple Random Masking Autoencoder Ensembles for Robust Multimodal Semi-supervised Learning (Alexandru-Raul Todoran et al., 2024)

{{<citation>}}

Alexandru-Raul Todoran, Marius Leordeanu. (2024)  
**Multiple Random Masking Autoencoder Ensembles for Robust Multimodal Semi-supervised Learning**
<br/>
<button class="copy-to-clipboard" title="Multiple Random Masking Autoencoder Ensembles for Robust Multimodal Semi-supervised Learning" index=152>
  <span class="copy-to-clipboard-item">Copy Title<span>
</button>
<div class="toast toast-copied toast-index-152 align-items-center text-bg-secondary border-0 position-absolute top-0 end-0" role="alert" aria-live="assertive" aria-atomic="true">
  <div class="d-flex">
    <div class="toast-body">
      Copied!
    </div>
  </div>
</div>

---
Primary Category: cs.CV  
Categories: cs-CV, cs.CV  
Keyword Score: 26  
Keywords: Autoencoder, Multi-modal, Multi-modal, Semi-Supervised Learning  
<a type="button" class="btn btn-outline-primary" href="http://arxiv.org/abs/2402.08035v1" target="_blank" >Paper Link</a>
<button type="button" class="btn btn-outline-primary download-pdf" url="https://arxiv.org/pdf/2402.08035v1.pdf" filename="2402.08035v1.pdf">Download PDF</button>

---


**ABSTRACT**  
There is an increasing number of real-world problems in computer vision and machine learning requiring to take into consideration multiple interpretation layers (modalities or views) of the world and learn how they relate to each other. For example, in the case of Earth Observations from satellite data, it is important to be able to predict one observation layer (e.g. vegetation index) from other layers (e.g. water vapor, snow cover, temperature etc), in order to best understand how the Earth System functions and also be able to reliably predict information for one layer when the data is missing (e.g. due to measurement failure or error).

{{</citation>}}


### (153/210) Exploring Perceptual Limitation of Multimodal Large Language Models (Jiarui Zhang et al., 2024)

{{<citation>}}

Jiarui Zhang, Jinyi Hu, Mahyar Khayatkhoei, Filip Ilievski, Maosong Sun. (2024)  
**Exploring Perceptual Limitation of Multimodal Large Language Models**
<br/>
<button class="copy-to-clipboard" title="Exploring Perceptual Limitation of Multimodal Large Language Models" index=153>
  <span class="copy-to-clipboard-item">Copy Title<span>
</button>
<div class="toast toast-copied toast-index-153 align-items-center text-bg-secondary border-0 position-absolute top-0 end-0" role="alert" aria-live="assertive" aria-atomic="true">
  <div class="d-flex">
    <div class="toast-body">
      Copied!
    </div>
  </div>
</div>

---
Primary Category: cs.CV  
Categories: cs-AI, cs-CV, cs-LG, cs.CV  
Keyword Score: 26  
Keywords: Multi-modal, Multi-modal, Question Answering, Large Language Model  
<a type="button" class="btn btn-outline-primary" href="http://arxiv.org/abs/2402.07384v1" target="_blank" >Paper Link</a>
<button type="button" class="btn btn-outline-primary download-pdf" url="https://arxiv.org/pdf/2402.07384v1.pdf" filename="2402.07384v1.pdf">Download PDF</button>

---


**ABSTRACT**  
<b>Multimodal</b> <b>Large</b> <b>Language</b> <b>Models</b> (MLLMs) have recently shown remarkable perceptual capability in answering visual <b>questions,</b> <b>however,</b> little is known about the limits of their perception. In particular, while prior works have provided anecdotal evidence of MLLMs' sensitivity to object size, this phenomenon and its underlying causes have not been explored comprehensively. In this work, we quantitatively study the perception of small visual objects in several state-of-the-art MLLMs and reveal a pervasive limitation in answering <b>questions</b> <b>about</b> small objects in images. Next, we identify four independent factors that can contribute to this limitation -- object quality, size, distractors, and location -- and conduct controlled intervention studies to measure the effect of each factor on MLLMs' perception. In particular, we find that lower object quality and smaller object size can both independently reduce MLLMs' ability to answer visual <b>questions.</b> <b>More</b> surprisingly, we find that the location of the object in the image and the presence of visual distractors can also significantly reduce MLLMs' <b>question</b> <b>answering</b> accuracy. Our study provides a better understanding of the perceptual limitation of MLLMs and contributes new evaluation protocols for analyzing the perception of future MLLMs. To facilitate further investigations, we release our code and data.

{{</citation>}}


### (154/210) Wavefront Randomization Improves Deconvolution (Amit Kohli et al., 2024)

{{<citation>}}

Amit Kohli, Anastasios N. Angelopoulos, Laura Waller. (2024)  
**Wavefront Randomization Improves Deconvolution**
<br/>
<button class="copy-to-clipboard" title="Wavefront Randomization Improves Deconvolution" index=154>
  <span class="copy-to-clipboard-item">Copy Title<span>
</button>
<div class="toast toast-copied toast-index-154 align-items-center text-bg-secondary border-0 position-absolute top-0 end-0" role="alert" aria-live="assertive" aria-atomic="true">
  <div class="d-flex">
    <div class="toast-body">
      Copied!
    </div>
  </div>
</div>

---
Primary Category: cs.CV  
Categories: I-4-4, cs-CV, cs.CV, eess-IV, physics-optics  
Keyword Score: 20  
Keywords: Simulation, Simulator  
<a type="button" class="btn btn-outline-primary" href="http://arxiv.org/abs/2402.07900v2" target="_blank" >Paper Link</a>
<button type="button" class="btn btn-outline-primary download-pdf" url="https://arxiv.org/pdf/2402.07900v2.pdf" filename="2402.07900v2.pdf">Download PDF</button>

---


**ABSTRACT**  
The performance of an imaging system is limited by optical aberrations, which cause blurriness in the resulting image. Digital correction techniques, such as deconvolution, have limited ability to correct the blur, since some spatial frequencies in the scene are not measured adequately (i.e., 'zeros' of the system transfer function). We prove that the addition of a random mask to an imaging system removes its dependence on aberrations, reducing the likelihood of zeros in the transfer function and consequently decreasing the sensitivity to noise during deconvolution. In <b>simulation,</b> we show that this strategy improves image quality over a range of aberration types, aberration strengths, and signal-to-noise ratios.

{{</citation>}}


### (155/210) Prismatic VLMs: Investigating the Design Space of Visually-Conditioned Language Models (Siddharth Karamcheti et al., 2024)

{{<citation>}}

Siddharth Karamcheti, Suraj Nair, Ashwin Balakrishna, Percy Liang, Thomas Kollar, Dorsa Sadigh. (2024)  
**Prismatic VLMs: Investigating the Design Space of Visually-Conditioned Language Models**
<br/>
<button class="copy-to-clipboard" title="Prismatic VLMs: Investigating the Design Space of Visually-Conditioned Language Models" index=155>
  <span class="copy-to-clipboard-item">Copy Title<span>
</button>
<div class="toast toast-copied toast-index-155 align-items-center text-bg-secondary border-0 position-absolute top-0 end-0" role="alert" aria-live="assertive" aria-atomic="true">
  <div class="d-flex">
    <div class="toast-body">
      Copied!
    </div>
  </div>
</div>

---
Primary Category: cs.CV  
Categories: cs-AI, cs-CL, cs-CV, cs-LG, cs.CV  
Keyword Score: 20  
Keywords: Question Answering, Visual Question Answering  
<a type="button" class="btn btn-outline-primary" href="http://arxiv.org/abs/2402.07865v1" target="_blank" >Paper Link</a>
<button type="button" class="btn btn-outline-primary download-pdf" url="https://arxiv.org/pdf/2402.07865v1.pdf" filename="2402.07865v1.pdf">Download PDF</button>

---


**ABSTRACT**  
Visually-conditioned language models (VLMs) have seen growing adoption in applications such as <b>visual</b> <b>dialogue,</b> <b>scene</b> understanding, and robotic task planning; adoption that has fueled a wealth of new models such as LLaVa, InstructBLIP, and PaLI-3. Despite the volume of new releases, key design decisions around image preprocessing, architecture, and optimization are under-explored, making it challenging to understand what factors account for model performance $-$ a challenge further complicated by the lack of objective, consistent evaluations. To address these gaps, we first compile a suite of standardized evaluations spanning <b>visual</b> <b>question</b> <b>answering,</b> object localization from language, and targeted challenge sets that probe properties such as hallucination; evaluations that provide calibrated, fine-grained insight into a VLM's capabilities. Second, we rigorously investigate VLMs along key design axes, including pretrained <b>visual</b> <b>representations</b> <b>and</b> quantifying the tradeoffs of using base vs. instruct-tuned language models, amongst others. We couple our analysis with three resource contributions: (1) a unified framework for evaluating VLMs, (2) optimized, flexible code for VLM training, and (3) checkpoints for all models, including a family of VLMs at the 7-13B scale that strictly outperform InstructBLIP and LLaVa v1.5, the state-of-the-art in open-source VLMs.

{{</citation>}}


### (156/210) Towards Meta-Pruning via Optimal Transport (Alexander Theus et al., 2024)

{{<citation>}}

Alexander Theus, Olin Geimer, Friedrich Wicke, Thomas Hofmann, Sotiris Anagnostidis, Sidak Pal Singh. (2024)  
**Towards Meta-Pruning via Optimal Transport**
<br/>
<button class="copy-to-clipboard" title="Towards Meta-Pruning via Optimal Transport" index=156>
  <span class="copy-to-clipboard-item">Copy Title<span>
</button>
<div class="toast toast-copied toast-index-156 align-items-center text-bg-secondary border-0 position-absolute top-0 end-0" role="alert" aria-live="assertive" aria-atomic="true">
  <div class="d-flex">
    <div class="toast-body">
      Copied!
    </div>
  </div>
</div>

---
Primary Category: cs.CV  
Categories: cs-CV, cs-LG, cs.CV  
Keyword Score: 20  
Keywords: Fine-tuning, Pruning  
<a type="button" class="btn btn-outline-primary" href="http://arxiv.org/abs/2402.07839v2" target="_blank" >Paper Link</a>
<button type="button" class="btn btn-outline-primary download-pdf" url="https://arxiv.org/pdf/2402.07839v2.pdf" filename="2402.07839v2.pdf">Download PDF</button>

---


**ABSTRACT**  
Structural <b>pruning</b> of neural networks conventionally relies on identifying and discarding less important neurons, a practice often resulting in significant accuracy loss that necessitates subsequent <b>fine-tuning</b> efforts. This paper introduces a novel approach named Intra-Fusion, challenging this prevailing <b>pruning</b> paradigm. Unlike existing methods that focus on designing meaningful neuron importance metrics, Intra-Fusion redefines the overlying <b>pruning</b> procedure. Through utilizing the concepts of model fusion and Optimal Transport, we leverage an agnostically given importance metric to arrive at a more effective sparse model representation. Notably, our approach achieves substantial accuracy recovery without the need for resource-intensive <b>fine-tuning,</b> making it an efficient and promising tool for neural network compression. Additionally, we explore how fusion can be added to the <b>pruning</b> process to significantly decrease the training time while maintaining competitive performance. We benchmark our results for various networks on commonly used datasets such as CIFAR-10, CIFAR-100, and ImageNet. More broadly, we hope that the proposed Intra-Fusion approach invigorates exploration into a fresh alternative to the predominant compression approaches. Our code is available here: https://github.com/alexandertheus/Intra-Fusion.

{{</citation>}}


### (157/210) A Benchmark Grocery Dataset of Realworld Point Clouds From Single View (Shivanand Venkanna Sheshappanavar et al., 2024)

{{<citation>}}

Shivanand Venkanna Sheshappanavar, Tejas Anvekar, Shivanand Kundargi, Yufan Wang, Chandra Kambhamettu. (2024)  
**A Benchmark Grocery Dataset of Realworld Point Clouds From Single View**
<br/>
<button class="copy-to-clipboard" title="A Benchmark Grocery Dataset of Realworld Point Clouds From Single View" index=157>
  <span class="copy-to-clipboard-item">Copy Title<span>
</button>
<div class="toast toast-copied toast-index-157 align-items-center text-bg-secondary border-0 position-absolute top-0 end-0" role="alert" aria-live="assertive" aria-atomic="true">
  <div class="d-flex">
    <div class="toast-body">
      Copied!
    </div>
  </div>
</div>

---
Primary Category: cs.CV  
Categories: cs-CV, cs.CV  
Keyword Score: 20  
Keywords: Continual Learning, Few-shot  
<a type="button" class="btn btn-outline-primary" href="http://arxiv.org/abs/2402.07819v1" target="_blank" >Paper Link</a>
<button type="button" class="btn btn-outline-primary download-pdf" url="https://arxiv.org/pdf/2402.07819v1.pdf" filename="2402.07819v1.pdf">Download PDF</button>

---


**ABSTRACT**  
Fine-grained grocery object recognition is an important computer vision problem with broad applications in automatic checkout, in-store robotic navigation, and assistive technologies for the visually impaired. Existing datasets on groceries are mainly 2D images. Models trained on these datasets are limited to learning features from the regular 2D grids. While portable 3D sensors such as Kinect were commonly available for mobile phones, sensors such as LiDAR and TrueDepth, have recently been integrated into mobile phones. Despite the availability of mobile 3D sensors, there are currently no dedicated real-world large-scale benchmark 3D datasets for grocery. In addition, existing 3D datasets lack fine-grained grocery categories and have limited training samples. Furthermore, collecting data by going around the object versus the traditional photo capture makes data collection cumbersome. Thus, we introduce a large-scale grocery dataset called 3DGrocery100. It constitutes 100 classes, with a total of 87,898 3D point clouds created from 10,755 RGB-D single-view images. We benchmark our dataset on six recent state-of-the-art 3D point cloud classification models. Additionally, we also benchmark the dataset on <b>few-shot</b> and <b>continual</b> <b>learning</b> point cloud classification tasks. Project Page: https://bigdatavision.org/3DGrocery100/.

{{</citation>}}


### (158/210) Complete Instances Mining for Weakly Supervised Instance Segmentation (Zecheng Li et al., 2024)

{{<citation>}}

Zecheng Li, Zening Zeng, Yuqi Liang, Jin-Gang Yu. (2024)  
**Complete Instances Mining for Weakly Supervised Instance Segmentation**
<br/>
<button class="copy-to-clipboard" title="Complete Instances Mining for Weakly Supervised Instance Segmentation" index=158>
  <span class="copy-to-clipboard-item">Copy Title<span>
</button>
<div class="toast toast-copied toast-index-158 align-items-center text-bg-secondary border-0 position-absolute top-0 end-0" role="alert" aria-live="assertive" aria-atomic="true">
  <div class="d-flex">
    <div class="toast-body">
      Copied!
    </div>
  </div>
</div>

---
Primary Category: cs.CV  
Categories: cs-CV, cs.CV  
Keyword Score: 20  
Keywords: Supervised Learning, Weakly-supervised Learning  
<a type="button" class="btn btn-outline-primary" href="http://arxiv.org/abs/2402.07633v1" target="_blank" >Paper Link</a>
<button type="button" class="btn btn-outline-primary download-pdf" url="https://arxiv.org/pdf/2402.07633v1.pdf" filename="2402.07633v1.pdf">Download PDF</button>

---


**ABSTRACT**  
Weakly <b>supervised</b> instance segmentation (WSIS) using only image-level labels is a challenging task due to the difficulty of aligning coarse annotations with the finer task. However, with the advancement of deep neural networks (DNNs), WSIS has garnered significant attention. Following a proposal-based paradigm, we encounter a redundant segmentation problem resulting from a single instance being represented by multiple proposals. For example, we feed a picture of a dog and proposals into the network and expect to output only one proposal containing a dog, but the network outputs multiple proposals. To address this problem, we propose a novel approach for WSIS that focuses on the online refinement of complete instances through the use of MaskIoU heads to predict the integrity scores of proposals and a Complete Instances Mining (CIM) strategy to explicitly model the redundant segmentation problem and generate refined pseudo labels. Our approach allows the network to become aware of multiple instances and complete instances, and we further improve its robustness through the incorporation of an Anti-noise strategy. Empirical evaluations on the PASCAL VOC 2012 and MS COCO datasets demonstrate that our method achieves state-of-the-art performance with a notable margin. Our implementation will be made available at https://github.com/ZechengLi19/CIM.

{{</citation>}}


### (159/210) An Empirical Study Into What Matters for Calibrating Vision-Language Models (Weijie Tu et al., 2024)

{{<citation>}}

Weijie Tu, Weijian Deng, Dylan Campbell, Stephen Gould, Tom Gedeon. (2024)  
**An Empirical Study Into What Matters for Calibrating Vision-Language Models**
<br/>
<button class="copy-to-clipboard" title="An Empirical Study Into What Matters for Calibrating Vision-Language Models" index=159>
  <span class="copy-to-clipboard-item">Copy Title<span>
</button>
<div class="toast toast-copied toast-index-159 align-items-center text-bg-secondary border-0 position-absolute top-0 end-0" role="alert" aria-live="assertive" aria-atomic="true">
  <div class="d-flex">
    <div class="toast-body">
      Copied!
    </div>
  </div>
</div>

---
Primary Category: cs.CV  
Categories: cs-CV, cs-LG, cs.CV  
Keyword Score: 20  
Keywords: Zero-shot, Vision-and-Language  
<a type="button" class="btn btn-outline-primary" href="http://arxiv.org/abs/2402.07417v1" target="_blank" >Paper Link</a>
<button type="button" class="btn btn-outline-primary download-pdf" url="https://arxiv.org/pdf/2402.07417v1.pdf" filename="2402.07417v1.pdf">Download PDF</button>

---


**ABSTRACT**  
<b>Vision--Language</b> Models (VLMs) have emerged as the dominant approach for <b>zero-shot</b> recognition, adept at handling diverse scenarios and significant distribution changes. However, their deployment in risk-sensitive areas requires a deeper understanding of their uncertainty estimation capabilities, a relatively uncharted area. In this study, we explore the calibration properties of VLMs across different architectures, datasets, and training strategies. In particular, we analyze the uncertainty estimation performance of VLMs when calibrated in one domain, label set or hierarchy level, and tested in a different one. Our findings reveal that while VLMs are not inherently calibrated for uncertainty, temperature scaling significantly and consistently improves calibration, even across shifts in distribution and changes in label set. Moreover, VLMs can be calibrated with a very small set of examples. Through detailed experimentation, we highlight the potential applications and importance of our insights, aiming for more reliable and effective use of VLMs in critical, real-world scenarios.

{{</citation>}}


### (160/210) SelfSwapper: Self-Supervised Face Swapping via Shape Agnostic Masked AutoEncoder (Jaeseong Lee et al., 2024)

{{<citation>}}

Jaeseong Lee, Junha Hyung, Sohyun Jeong, Jaegul Choo. (2024)  
**SelfSwapper: Self-Supervised Face Swapping via Shape Agnostic Masked AutoEncoder**
<br/>
<button class="copy-to-clipboard" title="SelfSwapper: Self-Supervised Face Swapping via Shape Agnostic Masked AutoEncoder" index=160>
  <span class="copy-to-clipboard-item">Copy Title<span>
</button>
<div class="toast toast-copied toast-index-160 align-items-center text-bg-secondary border-0 position-absolute top-0 end-0" role="alert" aria-live="assertive" aria-atomic="true">
  <div class="d-flex">
    <div class="toast-body">
      Copied!
    </div>
  </div>
</div>

---
Primary Category: cs.CV  
Categories: cs-AI, cs-CV, cs.CV  
Keyword Score: 20  
Keywords: Autoencoder, Self-supervised Learning  
<a type="button" class="btn btn-outline-primary" href="http://arxiv.org/abs/2402.07370v1" target="_blank" >Paper Link</a>
<button type="button" class="btn btn-outline-primary download-pdf" url="https://arxiv.org/pdf/2402.07370v1.pdf" filename="2402.07370v1.pdf">Download PDF</button>

---


**ABSTRACT**  
Face swapping has gained significant attention for its varied applications. The majority of previous face swapping approaches have relied on the seesaw game training scheme, which often leads to the instability of the model training and results in undesired samples with blended identities due to the target identity leakage problem. This paper introduces the Shape Agnostic Masked <b>AutoEncoder</b> (SAMAE) training scheme, a novel <b>self-supervised</b> approach designed to enhance face swapping model training. Our training scheme addresses the limitations of traditional training methods by circumventing the conventional seesaw game and introducing clear ground truth through its self-reconstruction training regime. It effectively mitigates identity leakage by masking facial regions of the input images and utilizing learned disentangled identity and non-identity features. Additionally, we tackle the shape misalignment problem with new techniques including perforation confusion and random mesh scaling, and establishes a new state-of-the-art, surpassing other baseline methods, preserving both identity and non-identity attributes, without sacrificing on either aspect.

{{</citation>}}


### (161/210) Detection of Spider Mites on Labrador Beans through Machine Learning Approaches Using Custom Datasets (Violet Liu et al., 2024)

{{<citation>}}

Violet Liu, Jason Chen, Ans Qureshi, Mahla Nejati. (2024)  
**Detection of Spider Mites on Labrador Beans through Machine Learning Approaches Using Custom Datasets**
<br/>
<button class="copy-to-clipboard" title="Detection of Spider Mites on Labrador Beans through Machine Learning Approaches Using Custom Datasets" index=161>
  <span class="copy-to-clipboard-item">Copy Title<span>
</button>
<div class="toast toast-copied toast-index-161 align-items-center text-bg-secondary border-0 position-absolute top-0 end-0" role="alert" aria-live="assertive" aria-atomic="true">
  <div class="d-flex">
    <div class="toast-body">
      Copied!
    </div>
  </div>
</div>

---
Primary Category: cs.CV  
Categories: cs-AI, cs-CV, cs-RO, cs.CV  
Keyword Score: 10  
Keywords: Convolutional Neural Network  
<a type="button" class="btn btn-outline-primary" href="http://arxiv.org/abs/2402.07895v1" target="_blank" >Paper Link</a>
<button type="button" class="btn btn-outline-primary download-pdf" url="https://arxiv.org/pdf/2402.07895v1.pdf" filename="2402.07895v1.pdf">Download PDF</button>

---


**ABSTRACT**  
Amidst growing food production demands, early plant disease detection is essential to safeguard crops; this study proposes a visual machine learning approach for plant disease detection, harnessing RGB and NIR data collected in real-world conditions through a JAI FS-1600D-10GE camera to build an RGBN dataset. A two-stage early plant disease detection model with YOLOv8 and a sequential <b>CNN</b> was used to train on a dataset with partial labels, which showed a 3.6% increase in mAP compared to a single-stage end-to-end segmentation model. The sequential <b>CNN</b> model achieved 90.62% validation accuracy utilising RGBN data. An average of 6.25% validation accuracy increase is found using RGBN in classification compared to RGB using ResNet15 and the sequential <b>CNN</b> models. Further research and dataset improvements are needed to meet food production demands.

{{</citation>}}


### (162/210) Task-conditioned adaptation of visual features in multi-task policy learning (Pierre Marza et al., 2024)

{{<citation>}}

Pierre Marza, Laetitia Matignon, Olivier Simonin, Christian Wolf. (2024)  
**Task-conditioned adaptation of visual features in multi-task policy learning**
<br/>
<button class="copy-to-clipboard" title="Task-conditioned adaptation of visual features in multi-task policy learning" index=162>
  <span class="copy-to-clipboard-item">Copy Title<span>
</button>
<div class="toast toast-copied toast-index-162 align-items-center text-bg-secondary border-0 position-absolute top-0 end-0" role="alert" aria-live="assertive" aria-atomic="true">
  <div class="d-flex">
    <div class="toast-body">
      Copied!
    </div>
  </div>
</div>

---
Primary Category: cs.CV  
Categories: cs-CV, cs-LG, cs-RO, cs.CV  
Keyword Score: 10  
Keywords: Fine-tuning  
<a type="button" class="btn btn-outline-primary" href="http://arxiv.org/abs/2402.07739v1" target="_blank" >Paper Link</a>
<button type="button" class="btn btn-outline-primary download-pdf" url="https://arxiv.org/pdf/2402.07739v1.pdf" filename="2402.07739v1.pdf">Download PDF</button>

---


**ABSTRACT**  
Successfully addressing a wide variety of tasks is a core ability of autonomous agents, which requires flexibly adapting the underlying decision-making strategies and, as we argue in this work, also adapting the underlying perception modules. An analogical argument would be the human visual system, which uses top-down signals to focus attention determined by the current task. Similarly, in this work, we adapt pre-trained large vision models conditioned on specific downstream tasks in the context of multi-task policy learning. We introduce task-conditioned adapters that do not require <b>finetuning</b> any pre-trained weights, combined with a single policy trained with behavior cloning and capable of addressing multiple tasks. We condition the policy and visual adapters on task embeddings, which can be selected at inference if the task is known, or alternatively inferred from a set of example demonstrations. To this end, we propose a new optimization-based estimator. We evaluate the method on a wide variety of tasks of the CortexBench benchmark and show that, compared to existing work, it can be addressed with a single policy. In particular, we demonstrate that adapting visual features is a key design choice and that the method generalizes to unseen tasks given visual demonstrations.

{{</citation>}}


### (163/210) A Flow-based Credibility Metric for Safety-critical Pedestrian Detection (Maria Lyssenko et al., 2024)

{{<citation>}}

Maria Lyssenko, Christoph Gladisch, Christian Heinzemann, Matthias Woehrle, Rudolph Triebel. (2024)  
**A Flow-based Credibility Metric for Safety-critical Pedestrian Detection**
<br/>
<button class="copy-to-clipboard" title="A Flow-based Credibility Metric for Safety-critical Pedestrian Detection" index=163>
  <span class="copy-to-clipboard-item">Copy Title<span>
</button>
<div class="toast toast-copied toast-index-163 align-items-center text-bg-secondary border-0 position-absolute top-0 end-0" role="alert" aria-live="assertive" aria-atomic="true">
  <div class="d-flex">
    <div class="toast-body">
      Copied!
    </div>
  </div>
</div>

---
Primary Category: cs.CV  
Categories: cs-CV, cs-LG, cs.CV  
Keyword Score: 10  
Keywords: Object Detection  
<a type="button" class="btn btn-outline-primary" href="http://arxiv.org/abs/2402.07642v1" target="_blank" >Paper Link</a>
<button type="button" class="btn btn-outline-primary download-pdf" url="https://arxiv.org/pdf/2402.07642v1.pdf" filename="2402.07642v1.pdf">Download PDF</button>

---


**ABSTRACT**  
Safety is of utmost importance for perception in automated driving (AD). However, a prime safety concern in state-of-the art <b>object</b> <b>detection</b> is that standard evaluation schemes utilize safety-agnostic metrics to argue sufficient detection performance. Hence, it is imperative to leverage supplementary domain knowledge to accentuate safety-critical misdetections during evaluation tasks. To tackle the underspecification, this paper introduces a novel credibility metric, called c-flow, for pedestrian bounding boxes. To this end, c-flow relies on a complementary optical flow signal from image sequences and enhances the analyses of safety-critical misdetections without requiring additional labels. We implement and evaluate c-flow with a state-of-the-art pedestrian detector on a large AD dataset. Our analysis demonstrates that c-flow allows developers to identify safety-critical misdetections.

{{</citation>}}


### (164/210) Sheet Music Transformer: End-To-End Optical Music Recognition Beyond Monophonic Transcription (Antonio Ríos-Vila et al., 2024)

{{<citation>}}

Antonio Ríos-Vila, Jorge Calvo-Zaragoza, Thierry Paquet. (2024)  
**Sheet Music Transformer: End-To-End Optical Music Recognition Beyond Monophonic Transcription**
<br/>
<button class="copy-to-clipboard" title="Sheet Music Transformer: End-To-End Optical Music Recognition Beyond Monophonic Transcription" index=164>
  <span class="copy-to-clipboard-item">Copy Title<span>
</button>
<div class="toast toast-copied toast-index-164 align-items-center text-bg-secondary border-0 position-absolute top-0 end-0" role="alert" aria-live="assertive" aria-atomic="true">
  <div class="d-flex">
    <div class="toast-body">
      Copied!
    </div>
  </div>
</div>

---
Primary Category: cs.CV  
Categories: cs-CV, cs-SD, cs.CV, eess-AS  
Keyword Score: 10  
Keywords: Transformer  
<a type="button" class="btn btn-outline-primary" href="http://arxiv.org/abs/2402.07596v1" target="_blank" >Paper Link</a>
<button type="button" class="btn btn-outline-primary download-pdf" url="https://arxiv.org/pdf/2402.07596v1.pdf" filename="2402.07596v1.pdf">Download PDF</button>

---


**ABSTRACT**  
State-of-the-art end-to-end Optical Music Recognition (OMR) has, to date, primarily been carried out using monophonic transcription techniques to handle complex score layouts, such as polyphony, often by resorting to simplifications or specific adaptations. Despite their efficacy, these approaches imply challenges related to scalability and limitations. This paper presents the Sheet Music <b>Transformer,</b> the first end-to-end OMR model designed to transcribe complex musical scores without relying solely on monophonic strategies. Our model employs a <b>Transformer-based</b> image-to-sequence framework that predicts score transcriptions in a standard digital music encoding format from input images. Our model has been tested on two polyphonic music datasets and has proven capable of handling these intricate music structures effectively. The experimental outcomes not only indicate the competence of the model, but also show that it is better than the state-of-the-art methods, thus contributing to advancements in end-to-end OMR transcription.

{{</citation>}}


### (165/210) TriAug: Out-of-Distribution Detection for Robust Classification of Imbalanced Breast Lesion in Ultrasound (Yinyu Ye et al., 2024)

{{<citation>}}

Yinyu Ye, Shijing Chen, Dong Ni, Ruobing Huang. (2024)  
**TriAug: Out-of-Distribution Detection for Robust Classification of Imbalanced Breast Lesion in Ultrasound**
<br/>
<button class="copy-to-clipboard" title="TriAug: Out-of-Distribution Detection for Robust Classification of Imbalanced Breast Lesion in Ultrasound" index=165>
  <span class="copy-to-clipboard-item">Copy Title<span>
</button>
<div class="toast toast-copied toast-index-165 align-items-center text-bg-secondary border-0 position-absolute top-0 end-0" role="alert" aria-live="assertive" aria-atomic="true">
  <div class="d-flex">
    <div class="toast-body">
      Copied!
    </div>
  </div>
</div>

---
Primary Category: cs.CV  
Categories: cs-AI, cs-CV, cs-LG, cs.CV  
Keyword Score: 10  
Keywords: Out-of-distribution  
<a type="button" class="btn btn-outline-primary" href="http://arxiv.org/abs/2402.07452v1" target="_blank" >Paper Link</a>
<button type="button" class="btn btn-outline-primary download-pdf" url="https://arxiv.org/pdf/2402.07452v1.pdf" filename="2402.07452v1.pdf">Download PDF</button>

---


**ABSTRACT**  
Different diseases, such as histological subtypes of breast lesions, have severely varying incidence rates. Even trained with substantial amount of in-distribution (ID) data, models often encounter <b>out-of-distribution</b> (OOD) samples belonging to unseen classes in clinical reality. To address this, we propose a novel framework built upon a long-tailed OOD detection task for breast ultrasound images. It is equipped with a triplet state augmentation (TriAug) which improves ID classification accuracy while maintaining a promising OOD detection performance. Meanwhile, we designed a balanced sphere loss to handle the class imbalanced problem.

{{</citation>}}


### (166/210) A Closer Look at the Robustness of Contrastive Language-Image Pre-Training (CLIP) (Weijie Tu et al., 2024)

{{<citation>}}

Weijie Tu, Weijian Deng, Tom Gedeon. (2024)  
**A Closer Look at the Robustness of Contrastive Language-Image Pre-Training (CLIP)**
<br/>
<button class="copy-to-clipboard" title="A Closer Look at the Robustness of Contrastive Language-Image Pre-Training (CLIP)" index=166>
  <span class="copy-to-clipboard-item">Copy Title<span>
</button>
<div class="toast toast-copied toast-index-166 align-items-center text-bg-secondary border-0 position-absolute top-0 end-0" role="alert" aria-live="assertive" aria-atomic="true">
  <div class="d-flex">
    <div class="toast-body">
      Copied!
    </div>
  </div>
</div>

---
Primary Category: cs.CV  
Categories: cs-CV, cs-LG, cs.CV  
Keyword Score: 10  
Keywords: Out-of-distribution  
<a type="button" class="btn btn-outline-primary" href="http://arxiv.org/abs/2402.07410v1" target="_blank" >Paper Link</a>
<button type="button" class="btn btn-outline-primary download-pdf" url="https://arxiv.org/pdf/2402.07410v1.pdf" filename="2402.07410v1.pdf">Download PDF</button>

---


**ABSTRACT**  
Contrastive Language-Image Pre-training (CLIP) models have demonstrated remarkable generalization capabilities across multiple challenging distribution shifts. However, there is still much to be explored in terms of their robustness to the variations of specific visual factors. In real-world applications, reliable and safe systems must consider other safety objectives beyond classification accuracy, such as predictive uncertainty. Yet, the effectiveness of CLIP models on such safety-related features is less-explored. Driven by the above, this work comprehensively investigates the safety objectives of CLIP models, specifically focusing on three key properties: resilience to visual factor variations, calibrated uncertainty estimations, and the ability to detect anomalous inputs. To this end, we study 83 CLIP models and 127 ImageNet classifiers. They are diverse in architecture, (pre)training distribution and training strategies. We consider 10 visual factors (e.g., shape and pattern), 5 types of <b>out-of-distribution</b> data, and 8 natural and challenging test conditions with different shift types, such as texture, style, and perturbation shifts. Our study has unveiled several previously unknown insights into CLIP models. For instance, they are not consistently more calibrated than other ImageNet models, which contradicts existing findings. Additionally, our analysis underscores the significance of training source design by showcasing its profound influence on the three safety-related properties. We believe our comprehensive study can shed light on and help guide the development of more robust and reliable CLIP models.

{{</citation>}}


### (167/210) Make it more specific: A novel uncertainty based airway segmentation application on 3D U-Net and its variants (Shiyi Wang et al., 2024)

{{<citation>}}

Shiyi Wang, Yang Nan, Felder Federico N, Sheng Zhang, Walsh Simon L F, Guang Yang. (2024)  
**Make it more specific: A novel uncertainty based airway segmentation application on 3D U-Net and its variants**
<br/>
<button class="copy-to-clipboard" title="Make it more specific: A novel uncertainty based airway segmentation application on 3D U-Net and its variants" index=167>
  <span class="copy-to-clipboard-item">Copy Title<span>
</button>
<div class="toast toast-copied toast-index-167 align-items-center text-bg-secondary border-0 position-absolute top-0 end-0" role="alert" aria-live="assertive" aria-atomic="true">
  <div class="d-flex">
    <div class="toast-body">
      Copied!
    </div>
  </div>
</div>

---
Primary Category: cs.CV  
Categories: cs-CV, cs.CV, eess-IV  
Keyword Score: 10  
Keywords: Pruning  
<a type="button" class="btn btn-outline-primary" href="http://arxiv.org/abs/2402.07403v1" target="_blank" >Paper Link</a>
<button type="button" class="btn btn-outline-primary download-pdf" url="https://arxiv.org/pdf/2402.07403v1.pdf" filename="2402.07403v1.pdf">Download PDF</button>

---


**ABSTRACT**  
Each medical segmentation task should be considered with a specific AI algorithm based on its scenario so that the most accurate prediction model can be obtained. The most popular algorithms in medical segmentation, 3D U-Net and its variants, can directly implement the task of lung trachea segmentation, but its failure to consider the special tree-like structure of the trachea suggests that there is much room for improvement in its segmentation accuracy. Therefore, a research gap exists because a great amount of state-of-the-art DL algorithms are vanilla 3D U-Net structures, which do not introduce the various performance-enhancing modules that come with special natural image modality in lung airway segmentation. In this paper, we proposed two different network structures Branch-Level U-Net (B-UNet) and Branch-Level CE-UNet (B-CE-UNet) which are based on U-Net structure and compared the prediction results with the same dataset. Specially, both of the two networks add branch loss and central line loss to learn the feature of fine branch endings of the airways. Uncertainty estimation algorithms are also included to attain confident predictions and thereby, increase the overall trustworthiness of our whole model. In addition, predictions of the lung trachea based on the maximum connectivity rate were calculated and extracted during post-processing for segmentation refinement and <b>pruning.</b>

{{</citation>}}


### (168/210) Exploring Saliency Bias in Manipulation Detection (Joshua Krinsky et al., 2024)

{{<citation>}}

Joshua Krinsky, Alan Bettis, Qiuyu Tang, Daniel Moreira, Aparna Bharati. (2024)  
**Exploring Saliency Bias in Manipulation Detection**
<br/>
<button class="copy-to-clipboard" title="Exploring Saliency Bias in Manipulation Detection" index=168>
  <span class="copy-to-clipboard-item">Copy Title<span>
</button>
<div class="toast toast-copied toast-index-168 align-items-center text-bg-secondary border-0 position-absolute top-0 end-0" role="alert" aria-live="assertive" aria-atomic="true">
  <div class="d-flex">
    <div class="toast-body">
      Copied!
    </div>
  </div>
</div>

---
Primary Category: cs.CV  
Categories: cs-CV, cs.CV  
Keyword Score: 10  
Keywords: Fake News Detection  
<a type="button" class="btn btn-outline-primary" href="http://arxiv.org/abs/2402.07338v1" target="_blank" >Paper Link</a>
<button type="button" class="btn btn-outline-primary download-pdf" url="https://arxiv.org/pdf/2402.07338v1.pdf" filename="2402.07338v1.pdf">Download PDF</button>

---


**ABSTRACT**  
The social media-fuelled explosion of <b>fake</b> <b>news</b> and misinformation supported by tampered images has led to growth in the development of models and datasets for image manipulation detection. However, existing detection methods mostly treat media objects in isolation, without considering the impact of specific manipulations on viewer perception. Forensic datasets are usually analyzed based on the manipulation operations and corresponding pixel-based masks, but not on the semantics of the manipulation, i.e., type of scene, objects, and viewers' attention to scene content. The semantics of the manipulation play an important role in spreading misinformation through manipulated images. In an attempt to encourage further development of semantic-aware forensic approaches to understand visual misinformation, we propose a framework to analyze the trends of visual and semantic saliency in popular image manipulation datasets and their impact on detection.

{{</citation>}}


## cs.CY (4)



### (169/210) AI-Augmented Predictions: LLM Assistants Improve Human Forecasting Accuracy (Philipp Schoenegger et al., 2024)

{{<citation>}}

Philipp Schoenegger, Peter S. Park, Ezra Karger, Philip E. Tetlock. (2024)  
**AI-Augmented Predictions: LLM Assistants Improve Human Forecasting Accuracy**
<br/>
<button class="copy-to-clipboard" title="AI-Augmented Predictions: LLM Assistants Improve Human Forecasting Accuracy" index=169>
  <span class="copy-to-clipboard-item">Copy Title<span>
</button>
<div class="toast toast-copied toast-index-169 align-items-center text-bg-secondary border-0 position-absolute top-0 end-0" role="alert" aria-live="assertive" aria-atomic="true">
  <div class="d-flex">
    <div class="toast-body">
      Copied!
    </div>
  </div>
</div>

---
Primary Category: cs.CY  
Categories: cs-AI, cs-CL, cs-CY, cs-LG, cs.CY  
Keyword Score: 50  
Keywords: GPT, GPT-4, GPT-4 turbo, Large Language Model, Large Language Model  
<a type="button" class="btn btn-outline-primary" href="http://arxiv.org/abs/2402.07862v1" target="_blank" >Paper Link</a>
<button type="button" class="btn btn-outline-primary download-pdf" url="https://arxiv.org/pdf/2402.07862v1.pdf" filename="2402.07862v1.pdf">Download PDF</button>

---


**ABSTRACT**  
<b>Large</b> <b>language</b> <b>models</b> <b>(LLMs)</b> show impressive capabilities, matching and sometimes exceeding human performance in many domains. This study explores the potential of <b>LLMs</b> to augment judgement in forecasting tasks. We evaluated the impact on forecasting accuracy of two <b>GPT-4-Turbo</b> <b>assistants:</b> one designed to provide high-quality advice ('superforecasting'), and the other designed to be overconfident and base-rate-neglecting. Participants (N = 991) had the option to consult their assigned <b>LLM</b> assistant throughout the study, in contrast to a control group that used a less advanced model (DaVinci-003) without direct forecasting support. Our preregistered analyses reveal that <b>LLM</b> augmentation significantly enhances forecasting accuracy by 23% across both types of assistants, compared to the control group. This improvement occurs despite the superforecasting assistant's higher accuracy in predictions, indicating the augmentation's benefit is not solely due to model prediction accuracy. Exploratory analyses showed a pronounced effect in one forecasting item, without which we find that the superforecasting assistant increased accuracy by 43%, compared with 28% for the biased assistant. We further examine whether <b>LLM</b> augmentation disproportionately benefits less skilled forecasters, degrades the wisdom-of-the-crowd by reducing prediction diversity, or varies in effectiveness with question difficulty. Our findings do not consistently support these hypotheses. Our results suggest that access to an <b>LLM</b> assistant, even a biased one, can be a helpful decision aid in cognitively demanding tasks where the answer is not known at the time of interaction.

{{</citation>}}


### (170/210) Leveraging AI to Advance Science and Computing Education across Africa: Progress, Challenges, and Opportunities (George Boateng, 2024)

{{<citation>}}

George Boateng. (2024)  
**Leveraging AI to Advance Science and Computing Education across Africa: Progress, Challenges, and Opportunities**
<br/>
<button class="copy-to-clipboard" title="Leveraging AI to Advance Science and Computing Education across Africa: Progress, Challenges, and Opportunities" index=170>
  <span class="copy-to-clipboard-item">Copy Title<span>
</button>
<div class="toast toast-copied toast-index-170 align-items-center text-bg-secondary border-0 position-absolute top-0 end-0" role="alert" aria-live="assertive" aria-atomic="true">
  <div class="d-flex">
    <div class="toast-body">
      Copied!
    </div>
  </div>
</div>

---
Primary Category: cs.CY  
Categories: cs-CL, cs-CY, cs-HC, cs.CY  
Keyword Score: 30  
Keywords: BERT, GPT, GPT-4  
<a type="button" class="btn btn-outline-primary" href="http://arxiv.org/abs/2402.07397v1" target="_blank" >Paper Link</a>
<button type="button" class="btn btn-outline-primary download-pdf" url="https://arxiv.org/pdf/2402.07397v1.pdf" filename="2402.07397v1.pdf">Download PDF</button>

---


**ABSTRACT**  
Across the African continent, students grapple with various educational challenges, including limited access to essential resources such as computers, internet connectivity, reliable electricity, and a shortage of qualified teachers. Despite these challenges, recent advances in AI such as <b>BERT,</b> and <b>GPT-4</b> have demonstrated their potential for advancing education. Yet, these AI tools tend to be deployed and evaluated predominantly within the context of Western educational settings, with limited attention directed towards the unique needs and challenges faced by students in Africa. In this book chapter, we describe our works developing and deploying AI in Education tools in Africa: (1) SuaCode, an AI-powered app that enables Africans to learn to code using their smartphones, (2) AutoGrad, an automated grading, and feedback tool for graphical and interactive coding assignments, (3) a tool for code plagiarism detection that shows visual evidence of plagiarism, (4) Kwame, a bilingual AI teaching assistant for coding courses, (5) Kwame for Science, a web-based AI teaching assistant that provides instant answers to students' science questions and (6) Brilla AI, an AI contestant for the National Science and Maths Quiz competition. We discuss challenges and potential opportunities to use AI to advance science and computing education across Africa.

{{</citation>}}


### (171/210) Auditing Work: Exploring the New York City algorithmic bias audit regime (Lara Groves et al., 2024)

{{<citation>}}

Lara Groves, Jacob Metcalf, Alayna Kennedy, Briana Vecchione, Andrew Strait. (2024)  
**Auditing Work: Exploring the New York City algorithmic bias audit regime**
<br/>
<button class="copy-to-clipboard" title="Auditing Work: Exploring the New York City algorithmic bias audit regime" index=171>
  <span class="copy-to-clipboard-item">Copy Title<span>
</button>
<div class="toast toast-copied toast-index-171 align-items-center text-bg-secondary border-0 position-absolute top-0 end-0" role="alert" aria-live="assertive" aria-atomic="true">
  <div class="d-flex">
    <div class="toast-body">
      Copied!
    </div>
  </div>
</div>

---
Primary Category: cs.CY  
Categories: cs-CY, cs.CY  
Keyword Score: 10  
Keywords: Recommendation  
<a type="button" class="btn btn-outline-primary" href="http://arxiv.org/abs/2402.08101v1" target="_blank" >Paper Link</a>
<button type="button" class="btn btn-outline-primary download-pdf" url="https://arxiv.org/pdf/2402.08101v1.pdf" filename="2402.08101v1.pdf">Download PDF</button>

---


**ABSTRACT**  
In July 2023, New York City (NYC) initiated the first algorithm auditing system for commercial machine-learning systems. Local Law 144 (LL 144) mandates NYC-based employers using automated employment decision-making tools (AEDTs) in hiring to undergo annual bias audits conducted by an independent auditor. This paper examines lessons from LL 144 for other national algorithm auditing attempts. Through qualitative interviews with 16 experts and practitioners within the regime, we find that LL 144 has not effectively established an auditing regime. The law fails to clearly define key aspects, such as AEDTs and independent auditors, leading auditors, AEDT vendors, and companies using AEDTs to define the law's practical implementation in ways that failed to protect job applicants. Contributing factors include the law's flawed transparency-driven theory of change, industry lobbying narrowing the definition of AEDTs, practical and cultural challenges faced by auditors in accessing data, and wide disagreement over what constitutes a legitimate auditor, resulting in four distinct 'auditor roles.' We conclude with four <b>recommendations</b> for policymakers seeking to create similar bias auditing regimes, emphasizing clearer definitions, metrics, and increased accountability. By exploring LL 144 through the lens of auditors, our paper advances the evidence base around audit as an accountability mechanism, providing guidance for policymakers seeking to create similar regimes.

{{</citation>}}


### (172/210) Algorithmic Fairness and Color-blind Racism: Navigating the Intersection (Jamelle Watson-Daniels, 2024)

{{<citation>}}

Jamelle Watson-Daniels. (2024)  
**Algorithmic Fairness and Color-blind Racism: Navigating the Intersection**
<br/>
<button class="copy-to-clipboard" title="Algorithmic Fairness and Color-blind Racism: Navigating the Intersection" index=172>
  <span class="copy-to-clipboard-item">Copy Title<span>
</button>
<div class="toast toast-copied toast-index-172 align-items-center text-bg-secondary border-0 position-absolute top-0 end-0" role="alert" aria-live="assertive" aria-atomic="true">
  <div class="d-flex">
    <div class="toast-body">
      Copied!
    </div>
  </div>
</div>

---
Primary Category: cs.CY  
Categories: cs-CY, cs.CY  
Keyword Score: 10  
Keywords: Fairness  
<a type="button" class="btn btn-outline-primary" href="http://arxiv.org/abs/2402.07778v1" target="_blank" >Paper Link</a>
<button type="button" class="btn btn-outline-primary download-pdf" url="https://arxiv.org/pdf/2402.07778v1.pdf" filename="2402.07778v1.pdf">Download PDF</button>

---


**ABSTRACT**  
Our focus lies at the intersection between two broader research perspectives: (1) the scientific study of algorithms and (2) the scholarship on race and racism. Many streams of research related to algorithmic <b>fairness</b> have been born out of interest at this intersection. We think about this intersection as the product of work derived from both sides. From (1) algorithms to (2) racism, the starting place might be an algorithmic question or method connected to a conceptualization of racism. On the other hand, from (2) racism to (1) algorithms, the starting place could be recognizing a setting where a legacy of racism is known to persist and drawing connections between that legacy and the introduction of algorithms into this setting. In either direction, meaningful disconnection can occur when conducting research at the intersection of racism and algorithms. The present paper urges collective reflection on research directions at this intersection. Despite being primarily motivated by instances of racial bias, research in algorithmic <b>fairness</b> remains mostly disconnected from scholarship on racism. In particular, there has not been an examination connecting algorithmic <b>fairness</b> discussions directly to the ideology of color-blind racism; we aim to fill this gap. We begin with a review of an essential account of color-blind racism then we review racial discourse within algorithmic <b>fairness</b> research and underline significant patterns, shifts and disconnects. Ultimately, we argue that researchers can improve the navigation of the landscape at the intersection by recognizing ideological shifts as such and iteratively re-orienting towards maintaining meaningful connections across interdisciplinary lines.

{{</citation>}}


## cs.HC (5)



### (173/210) Enhancing Programming Error Messages in Real Time with Generative AI (Bailey Kimmel et al., 2024)

{{<citation>}}

Bailey Kimmel, Austin Geisert, Lily Yaro, Brendan Gipson, Taylor Hotchkiss, Sidney Osae-Asante, Hunter Vaught, Grant Wininger, Chase Yamaguchi. (2024)  
**Enhancing Programming Error Messages in Real Time with Generative AI**
<br/>
<button class="copy-to-clipboard" title="Enhancing Programming Error Messages in Real Time with Generative AI" index=173>
  <span class="copy-to-clipboard-item">Copy Title<span>
</button>
<div class="toast toast-copied toast-index-173 align-items-center text-bg-secondary border-0 position-absolute top-0 end-0" role="alert" aria-live="assertive" aria-atomic="true">
  <div class="d-flex">
    <div class="toast-body">
      Copied!
    </div>
  </div>
</div>

---
Primary Category: cs.HC  
Categories: cs-AI, cs-HC, cs.HC  
Keyword Score: 40  
Keywords: Generative AI, ChatGPT, GPT, GPT-4  
<a type="button" class="btn btn-outline-primary" href="http://arxiv.org/abs/2402.08072v1" target="_blank" >Paper Link</a>
<button type="button" class="btn btn-outline-primary download-pdf" url="https://arxiv.org/pdf/2402.08072v1.pdf" filename="2402.08072v1.pdf">Download PDF</button>

---


**ABSTRACT**  
<b>Generative</b> <b>AI</b> is changing the way that many disciplines are taught, including computer science. Researchers have shown that <b>generative</b> <b>AI</b> tools are capable of solving programming problems, writing extensive blocks of code, and explaining complex code in simple terms. Particular promise has been shown in using <b>generative</b> <b>AI</b> to enhance programming error messages. Both students and instructors have complained for decades that these messages are often cryptic and difficult to understand. Yet recent work has shown that students make fewer repeated errors when enhanced via <b>GPT-4.</b> We extend this work by implementing feedback from <b>ChatGPT</b> for all programs submitted to our automated assessment tool, Athene, providing help for compiler, run-time, and logic errors. Our results indicate that adding <b>generative</b> <b>AI</b> to an automated assessment tool does not necessarily make it better and that design of the interface matters greatly to the usability of the feedback that <b>GPT-4</b> provided.

{{</citation>}}


### (174/210) Why and When LLM-Based Assistants Can Go Wrong: Investigating the Effectiveness of Prompt-Based Interactions for Software Help-Seeking (Anjali Khurana et al., 2024)

{{<citation>}}

Anjali Khurana, Hari Subramonyam, Parmit K Chilana. (2024)  
**Why and When LLM-Based Assistants Can Go Wrong: Investigating the Effectiveness of Prompt-Based Interactions for Software Help-Seeking**
<br/>
<button class="copy-to-clipboard" title="Why and When LLM-Based Assistants Can Go Wrong: Investigating the Effectiveness of Prompt-Based Interactions for Software Help-Seeking" index=174>
  <span class="copy-to-clipboard-item">Copy Title<span>
</button>
<div class="toast toast-copied toast-index-174 align-items-center text-bg-secondary border-0 position-absolute top-0 end-0" role="alert" aria-live="assertive" aria-atomic="true">
  <div class="d-flex">
    <div class="toast-body">
      Copied!
    </div>
  </div>
</div>

---
Primary Category: cs.HC  
Categories: cs-AI, cs-HC, cs-LG, cs.HC  
Keyword Score: 40  
Keywords: ChatGPT, Large Language Model, Large Language Model, Prompt  
<a type="button" class="btn btn-outline-primary" href="http://arxiv.org/abs/2402.08030v1" target="_blank" >Paper Link</a>
<button type="button" class="btn btn-outline-primary download-pdf" url="https://arxiv.org/pdf/2402.08030v1.pdf" filename="2402.08030v1.pdf">Download PDF</button>

---


**ABSTRACT**  
<b>Large</b> <b>Language</b> <b>Model</b> <b>(LLM)</b> assistants, such as <b>ChatGPT,</b> have emerged as potential alternatives to search methods for helping users navigate complex, feature-rich software. <b>LLMs</b> use vast training data from domain-specific texts, software manuals, and code repositories to mimic human-like interactions, offering tailored assistance, including step-by-step instructions. In this work, we investigated <b>LLM-generated</b> software guidance through a within-subject experiment with 16 participants and follow-up interviews. We compared a baseline <b>LLM</b> assistant with an <b>LLM</b> optimized for particular software contexts, SoftAIBot, which also offered guidelines for constructing appropriate <b>prompts.</b> We assessed task completion, perceived accuracy, relevance, and trust. Surprisingly, although SoftAIBot outperformed the baseline <b>LLM,</b> our results revealed no significant difference in <b>LLM</b> usage and user perceptions with or without <b>prompt</b> guidelines and the integration of domain context. Most users struggled to understand how the <b>prompt's</b> text related to the <b>LLM's</b> responses and often followed the <b>LLM's</b> suggestions verbatim, even if they were incorrect. This resulted in difficulties when using the <b>LLM's</b> advice for software tasks, leading to low task completion rates. Our detailed analysis also revealed that users remained unaware of inaccuracies in the <b>LLM's</b> responses, indicating a gap between their lack of software expertise and their ability to evaluate the <b>LLM's</b> assistance. With the growing push for designing domain-specific <b>LLM</b> assistants, we emphasize the importance of incorporating explainable, context-aware cues into <b>LLMs</b> to help users understand <b>prompt-based</b> interactions, identify biases, and maximize the utility of <b>LLM</b> assistants.

{{</citation>}}


### (175/210) Imagining a Future of Designing with AI: Dynamic Grounding, Constructive Negotiation, and Sustainable Motivation (Priyan Vaithilingam et al., 2024)

{{<citation>}}

Priyan Vaithilingam, Ian Arawjo, Elena L. Glassman. (2024)  
**Imagining a Future of Designing with AI: Dynamic Grounding, Constructive Negotiation, and Sustainable Motivation**
<br/>
<button class="copy-to-clipboard" title="Imagining a Future of Designing with AI: Dynamic Grounding, Constructive Negotiation, and Sustainable Motivation" index=175>
  <span class="copy-to-clipboard-item">Copy Title<span>
</button>
<div class="toast toast-copied toast-index-175 align-items-center text-bg-secondary border-0 position-absolute top-0 end-0" role="alert" aria-live="assertive" aria-atomic="true">
  <div class="d-flex">
    <div class="toast-body">
      Copied!
    </div>
  </div>
</div>

---
Primary Category: cs.HC  
Categories: J-6; I-2-0; H-5-2, cs-AI, cs-HC, cs.HC  
Keyword Score: 30  
Keywords: Foundation Model, Grounding, Summarization  
<a type="button" class="btn btn-outline-primary" href="http://arxiv.org/abs/2402.07342v1" target="_blank" >Paper Link</a>
<button type="button" class="btn btn-outline-primary download-pdf" url="https://arxiv.org/pdf/2402.07342v1.pdf" filename="2402.07342v1.pdf">Download PDF</button>

---


**ABSTRACT**  
We ideate a future design workflow that involves AI technology. Drawing from activity and communication theory, we attempt to isolate the new value large AI models can provide design compared to past technologies. We arrive at three affordances -- dynamic <b>grounding,</b> constructive negotiation, and sustainable motivation -- that <b>summarize</b> latent qualities of natural language-enabled <b>foundation</b> <b>models</b> that, if explicitly designed for, can support the process of design. Through design fiction, we then imagine a future interface as a diegetic prototype, the story of Squirrel Game, that demonstrates each of our three affordances in a realistic usage scenario. Our design process, terminology, and diagrams aim to contribute to future discussions about the relative affordances of AI technology with regard to collaborating with human designers.

{{</citation>}}


### (176/210) Portobello: Extending Driving Simulation from the Lab to the Road (Fanjun Bu et al., 2024)

{{<citation>}}

Fanjun Bu, Stacey Li, David Goedicke, Mark Colley, Gyanendra Sharma, Hiroshi Yasuda, Wendy Ju. (2024)  
**Portobello: Extending Driving Simulation from the Lab to the Road**
<br/>
<button class="copy-to-clipboard" title="Portobello: Extending Driving Simulation from the Lab to the Road" index=176>
  <span class="copy-to-clipboard-item">Copy Title<span>
</button>
<div class="toast toast-copied toast-index-176 align-items-center text-bg-secondary border-0 position-absolute top-0 end-0" role="alert" aria-live="assertive" aria-atomic="true">
  <div class="d-flex">
    <div class="toast-body">
      Copied!
    </div>
  </div>
</div>

---
Primary Category: cs.HC  
Categories: cs-HC, cs.HC  
Keyword Score: 20  
Keywords: Simulation, Simulator  
<a type="button" class="btn btn-outline-primary" href="http://arxiv.org/abs/2402.08061v1" target="_blank" >Paper Link</a>
<button type="button" class="btn btn-outline-primary download-pdf" url="https://arxiv.org/pdf/2402.08061v1.pdf" filename="2402.08061v1.pdf">Download PDF</button>

---


**ABSTRACT**  
In automotive user interface design, testing often starts with lab-based driving simulators and migrates toward on-road studies to mitigate risks. Mixed reality (XR) helps translate virtual study designs to the real road to increase ecological validity. However, researchers rarely run the same study in both in-lab and on-road simulators due to the challenges of replicating studies in both physical and virtual worlds. To provide a common infrastructure to port in-lab study designs on-road, we built a platform-portable infrastructure, Portobello, to enable us to run twinned physical-virtual studies. As a proof-of-concept, we extended the on-road simulator XR-OOM with Portobello. We ran a within-subjects, autonomous-vehicle crosswalk cooperation study (N=32) both in-lab and on-road to investigate study design portability and platform-driven influences on study outcomes. To our knowledge, this is the first system that enables the twinning of studies originally designed for in-lab simulators to be carried out in an on-road platform.

{{</citation>}}


### (177/210) ReNeLiB: Real-time Neural Listening Behavior Generation for Socially Interactive Agents (Daksitha Withanage Don et al., 2024)

{{<citation>}}

Daksitha Withanage Don, Philipp Müller, Fabrizio Nunnari, Elisabeth André, Patrick Gebhard. (2024)  
**ReNeLiB: Real-time Neural Listening Behavior Generation for Socially Interactive Agents**
<br/>
<button class="copy-to-clipboard" title="ReNeLiB: Real-time Neural Listening Behavior Generation for Socially Interactive Agents" index=177>
  <span class="copy-to-clipboard-item">Copy Title<span>
</button>
<div class="toast toast-copied toast-index-177 align-items-center text-bg-secondary border-0 position-absolute top-0 end-0" role="alert" aria-live="assertive" aria-atomic="true">
  <div class="d-flex">
    <div class="toast-body">
      Copied!
    </div>
  </div>
</div>

---
Primary Category: cs.HC  
Categories: cs-HC, cs.HC  
Keyword Score: 3  
Keywords: Multi-modal  
<a type="button" class="btn btn-outline-primary" href="http://arxiv.org/abs/2402.08079v1" target="_blank" >Paper Link</a>
<button type="button" class="btn btn-outline-primary download-pdf" url="https://arxiv.org/pdf/2402.08079v1.pdf" filename="2402.08079v1.pdf">Download PDF</button>

---


**ABSTRACT**  
Flexible and natural nonverbal reactions to human behavior remain a challenge for socially interactive agents (SIAs) that are predominantly animated using hand-crafted rules. While recently proposed machine learning based approaches to conversational behavior generation are a promising way to address this challenge, they have not yet been employed in SIAs. The primary reason for this is the lack of a software toolkit integrating such approaches with SIA frameworks that conforms to the challenging real-time requirements of human-agent interaction scenarios. In our work, we for the first time present such a toolkit consisting of three main components: (1) real-time feature extraction capturing <b>multi-modal</b> social cues from the user; (2) behavior generation based on a recent state-of-the-art neural network approach; (3) visualization of the generated behavior supporting both FLAME-based and Apple ARKit-based interactive agents. We comprehensively evaluate the real-time performance of the whole framework and its components. In addition, we introduce pre-trained behavioral generation models derived from psychotherapy sessions for domain-specific listening behaviors. Our software toolkit, pivotal for deploying and assessing SIAs' listening behavior in real-time, is publicly available. Resources, including code, behavioural <b>multi-modal</b> features extracted from therapeutic interactions, are hosted at https://daksitha.github.io/ReNeLib

{{</citation>}}


## cs.SD (2)



### (178/210) Developing a Multi-variate Prediction Model For COVID-19 From Crowd-sourced Respiratory Voice Data (Yuyang Yan et al., 2024)

{{<citation>}}

Yuyang Yan, Wafaa Aljbawi, Sami O. Simons, Visara Urovi. (2024)  
**Developing a Multi-variate Prediction Model For COVID-19 From Crowd-sourced Respiratory Voice Data**
<br/>
<button class="copy-to-clipboard" title="Developing a Multi-variate Prediction Model For COVID-19 From Crowd-sourced Respiratory Voice Data" index=178>
  <span class="copy-to-clipboard-item">Copy Title<span>
</button>
<div class="toast toast-copied toast-index-178 align-items-center text-bg-secondary border-0 position-absolute top-0 end-0" role="alert" aria-live="assertive" aria-atomic="true">
  <div class="d-flex">
    <div class="toast-body">
      Copied!
    </div>
  </div>
</div>

---
Primary Category: cs.SD  
Categories: cs-AI, cs-SD, cs.SD, eess-AS  
Keyword Score: 40  
Keywords: Convolution, Convolutional Neural Network, Convolutional Neural Network, BERT  
<a type="button" class="btn btn-outline-primary" href="http://arxiv.org/abs/2402.07619v1" target="_blank" >Paper Link</a>
<button type="button" class="btn btn-outline-primary download-pdf" url="https://arxiv.org/pdf/2402.07619v1.pdf" filename="2402.07619v1.pdf">Download PDF</button>

---


**ABSTRACT**  
COVID-19 has affected more than 223 countries worldwide and in the Post-COVID Era, there is a pressing need for non-invasive, low-cost, and highly scalable solutions to detect COVID-19. We develop a deep learning model to identify COVID-19 from voice recording data. The novelty of this work is in the development of deep learning models for COVID-19 identification from only voice recordings. We use the Cambridge COVID-19 Sound database which contains 893 speech samples, crowd-sourced from 4352 participants via a COVID-19 Sounds app. Voice features including Mel-spectrograms and Mel-frequency cepstral coefficients (MFCC) and <b>CNN</b> Encoder features are extracted. Based on the voice data, we develop deep learning classification models to detect COVID-19 cases. These models include Long Short-Term Memory (LSTM) and <b>Convolutional</b> <b>Neural</b> <b>Network</b> <b>(CNN)</b> and Hidden-Unit <b>BERT</b> (HuBERT). We compare their predictive power to baseline machine learning models. HuBERT achieves the highest accuracy of 86\% and the highest AUC of 0.93. The results achieved with the proposed models suggest promising results in COVID-19 diagnosis from voice recordings when compared to the results obtained from the state-of-the-art.

{{</citation>}}


### (179/210) SLIT: Boosting Audio-Text Pre-Training via Multi-Stage Learning and Instruction Tuning (Hang Zhao et al., 2024)

{{<citation>}}

Hang Zhao, Yifei Xin, Zhesong Yu, Bilei Zhu, Lu Lu, Zejun Ma. (2024)  
**SLIT: Boosting Audio-Text Pre-Training via Multi-Stage Learning and Instruction Tuning**
<br/>
<button class="copy-to-clipboard" title="SLIT: Boosting Audio-Text Pre-Training via Multi-Stage Learning and Instruction Tuning" index=179>
  <span class="copy-to-clipboard-item">Copy Title<span>
</button>
<div class="toast toast-copied toast-index-179 align-items-center text-bg-secondary border-0 position-absolute top-0 end-0" role="alert" aria-live="assertive" aria-atomic="true">
  <div class="d-flex">
    <div class="toast-body">
      Copied!
    </div>
  </div>
</div>

---
Primary Category: cs.SD  
Categories: cs-SD, cs.SD, eess-AS  
Keyword Score: 30  
Keywords: Zero-shot, Instruction Tuning, Large Language Model  
<a type="button" class="btn btn-outline-primary" href="http://arxiv.org/abs/2402.07485v1" target="_blank" >Paper Link</a>
<button type="button" class="btn btn-outline-primary download-pdf" url="https://arxiv.org/pdf/2402.07485v1.pdf" filename="2402.07485v1.pdf">Download PDF</button>

---


**ABSTRACT**  
Audio-text pre-training (ATP) has witnessed remarkable strides across a variety of downstream tasks. Yet, most existing pretrained audio models only specialize in either discriminative tasks or generative tasks. In this study, we develop SLIT, a novel ATP framework which transfers flexibly to both audio-text understanding and generation tasks, bootstrapping audio-text pre-training from frozen pretrained audio encoders and <b>large</b> <b>language</b> <b>models.</b> To bridge the modality gap during pre-training, we leverage Q-Former, which undergoes a multi-stage pre-training process. The first stage enhances audio-text representation learning from a frozen audio encoder, while the second stage boosts audio-to-text generative learning with a frozen language model. Furthermore, we introduce an ATP <b>instruction</b> <b>tuning</b> strategy, which enables flexible and informative feature extraction tailered to the given <b>instructions</b> <b>for</b> different tasks. Experiments show that SLIT achieves superior performances on a variety of audio-text understanding and generation tasks, and even demonstrates strong generalization capabilities when directly applied to <b>zero-shot</b> scenarios.

{{</citation>}}


## q-bio.GN (1)



### (180/210) Efficient and Scalable Fine-Tune of Language Models for Genome Understanding (Huixin Zhan et al., 2024)

{{<citation>}}

Huixin Zhan, Ying Nian Wu, Zijun Zhang. (2024)  
**Efficient and Scalable Fine-Tune of Language Models for Genome Understanding**
<br/>
<button class="copy-to-clipboard" title="Efficient and Scalable Fine-Tune of Language Models for Genome Understanding" index=180>
  <span class="copy-to-clipboard-item">Copy Title<span>
</button>
<div class="toast toast-copied toast-index-180 align-items-center text-bg-secondary border-0 position-absolute top-0 end-0" role="alert" aria-live="assertive" aria-atomic="true">
  <div class="d-flex">
    <div class="toast-body">
      Copied!
    </div>
  </div>
</div>

---
Primary Category: q-bio.GN  
Categories: cs-AI, cs-LG, q-bio-GN, q-bio.GN  
Keyword Score: 30  
Keywords: Fine-tuning, Fine-tuning, Foundation Model  
<a type="button" class="btn btn-outline-primary" href="http://arxiv.org/abs/2402.08075v1" target="_blank" >Paper Link</a>
<button type="button" class="btn btn-outline-primary download-pdf" url="https://arxiv.org/pdf/2402.08075v1.pdf" filename="2402.08075v1.pdf">Download PDF</button>

---


**ABSTRACT**  
Although DNA <b>foundation</b> <b>models</b> have advanced the understanding of genomes, they still face significant challenges in the limited scale and diversity of genomic data. This limitation starkly contrasts with the success of natural language <b>foundation</b> <b>models,</b> which thrive on substantially larger scales. Furthermore, genome understanding involves numerous downstream genome annotation tasks with inherent data heterogeneity, thereby necessitating more efficient and robust <b>fine-tuning</b> methods tailored for genomics. Here, we present \textsc{Lingo}: \textsc{L}anguage prefix f\textsc{In}e-tuning for \textsc{G}en\textsc{O}mes. Unlike DNA <b>foundation</b> <b>models,</b> \textsc{Lingo} strategically leverages natural language <b>foundation</b> <b>models'</b> contextual cues, recalibrating their linguistic knowledge to genomic sequences. \textsc{Lingo} further accommodates numerous, heterogeneous downstream <b>fine-tune</b> tasks by an adaptive rank sampling method that prunes and stochastically reintroduces pruned singular vectors within small computational budgets. Adaptive rank sampling outperformed existing <b>fine-tuning</b> methods on all benchmarked 14 genome understanding tasks, while requiring fewer than 2\% of trainable parameters as genomic-specific adapters. Impressively, applying these adapters on natural language <b>foundation</b> <b>models</b> matched or even exceeded the performance of DNA <b>foundation</b> <b>models.</b> \textsc{Lingo} presents a new paradigm of efficient and scalable genome understanding via genomic-specific adapters on language models.

{{</citation>}}


## stat.ML (5)



### (181/210) Graph Structure Inference with BAM: Introducing the Bilinear Attention Mechanism (Philipp Froehlich et al., 2024)

{{<citation>}}

Philipp Froehlich, Heinz Koeppl. (2024)  
**Graph Structure Inference with BAM: Introducing the Bilinear Attention Mechanism**
<br/>
<button class="copy-to-clipboard" title="Graph Structure Inference with BAM: Introducing the Bilinear Attention Mechanism" index=181>
  <span class="copy-to-clipboard-item">Copy Title<span>
</button>
<div class="toast toast-copied toast-index-181 align-items-center text-bg-secondary border-0 position-absolute top-0 end-0" role="alert" aria-live="assertive" aria-atomic="true">
  <div class="d-flex">
    <div class="toast-body">
      Copied!
    </div>
  </div>
</div>

---
Primary Category: stat.ML  
Categories: cs-LG, stat-ML, stat.ML  
Keyword Score: 30  
Keywords: Simulation, Simulator, Supervised Learning  
<a type="button" class="btn btn-outline-primary" href="http://arxiv.org/abs/2402.07735v2" target="_blank" >Paper Link</a>
<button type="button" class="btn btn-outline-primary download-pdf" url="https://arxiv.org/pdf/2402.07735v2.pdf" filename="2402.07735v2.pdf">Download PDF</button>

---


**ABSTRACT**  
In statistics and machine learning, detecting dependencies in datasets is a central challenge. We propose a novel neural network model for <b>supervised</b> graph structure learning, i.e., the process of learning a mapping between observational data and their underlying dependence structure. The model is trained with variably shaped and coupled simulated input data and requires only a single forward pass through the trained network for inference. By leveraging structural equation models and employing randomly generated multivariate Chebyshev polynomials for the <b>simulation</b> of training data, our method demonstrates robust generalizability across both linear and various types of non-linear dependencies. We introduce a novel bilinear attention mechanism (BAM) for explicit processing of dependency information, which operates on the level of covariance matrices of transformed data and respects the geometry of the manifold of symmetric positive definite matrices. Empirical evaluation demonstrates the robustness of our method in detecting a wide range of dependencies, excelling in undirected graph estimation and proving competitive in completed partially directed acyclic graph estimation through a novel two-step approach.

{{</citation>}}


### (182/210) Stochastic Gradient Flow Dynamics of Test Risk and its Exact Solution for Weak Features (Rodrigo Veiga et al., 2024)

{{<citation>}}

Rodrigo Veiga, Anastasia Remizova, Nicolas Macris. (2024)  
**Stochastic Gradient Flow Dynamics of Test Risk and its Exact Solution for Weak Features**
<br/>
<button class="copy-to-clipboard" title="Stochastic Gradient Flow Dynamics of Test Risk and its Exact Solution for Weak Features" index=182>
  <span class="copy-to-clipboard-item">Copy Title<span>
</button>
<div class="toast toast-copied toast-index-182 align-items-center text-bg-secondary border-0 position-absolute top-0 end-0" role="alert" aria-live="assertive" aria-atomic="true">
  <div class="d-flex">
    <div class="toast-body">
      Copied!
    </div>
  </div>
</div>

---
Primary Category: stat.ML  
Categories: cond-mat-dis-nn, cs-LG, stat-ML, stat.ML  
Keyword Score: 30  
Keywords: Simulation, Simulator, Stochastic Gradient Descent  
<a type="button" class="btn btn-outline-primary" href="http://arxiv.org/abs/2402.07626v1" target="_blank" >Paper Link</a>
<button type="button" class="btn btn-outline-primary download-pdf" url="https://arxiv.org/pdf/2402.07626v1.pdf" filename="2402.07626v1.pdf">Download PDF</button>

---


**ABSTRACT**  
We investigate the test risk of continuous-time <b>stochastic</b> <b>gradient</b> <b>flow</b> dynamics in learning theory. Using a path integral formulation we provide, in the regime of a small learning rate, a general formula for computing the difference between test risk curves of pure gradient and <b>stochastic</b> <b>gradient</b> <b>flows.</b> We apply the general theory to a simple model of weak features, which displays the double descent phenomenon, and explicitly compute the corrections brought about by the added <b>stochastic</b> <b>term</b> <b>in</b> the dynamics, as a function of time and model parameters. The analytical results are compared to <b>simulations</b> of discrete-time <b>stochastic</b> <b>gradient</b> <b>descent</b> and show good agreement.

{{</citation>}}


### (183/210) Diffeomorphic Measure Matching with Kernels for Generative Modeling (Biraj Pandey et al., 2024)

{{<citation>}}

Biraj Pandey, Bamdad Hosseini, Pau Batlle, Houman Owhadi. (2024)  
**Diffeomorphic Measure Matching with Kernels for Generative Modeling**
<br/>
<button class="copy-to-clipboard" title="Diffeomorphic Measure Matching with Kernels for Generative Modeling" index=183>
  <span class="copy-to-clipboard-item">Copy Title<span>
</button>
<div class="toast toast-copied toast-index-183 align-items-center text-bg-secondary border-0 position-absolute top-0 end-0" role="alert" aria-live="assertive" aria-atomic="true">
  <div class="d-flex">
    <div class="toast-body">
      Copied!
    </div>
  </div>
</div>

---
Primary Category: stat.ML  
Categories: 35Q68 49Q22 62F15 68T07 62R07, cs-LG, math-DS, stat-CO, stat-ML, stat.ML  
Keyword Score: 20  
Keywords: Simulation, Simulator  
<a type="button" class="btn btn-outline-primary" href="http://arxiv.org/abs/2402.08077v1" target="_blank" >Paper Link</a>
<button type="button" class="btn btn-outline-primary download-pdf" url="https://arxiv.org/pdf/2402.08077v1.pdf" filename="2402.08077v1.pdf">Download PDF</button>

---


**ABSTRACT**  
This article presents a general framework for the transport of probability measures towards minimum divergence generative modeling and sampling using ordinary differential equations (ODEs) and Reproducing Kernel Hilbert Spaces (RKHSs), inspired by ideas from diffeomorphic matching and image registration. A theoretical analysis of the proposed method is presented, giving a priori error bounds in terms of the complexity of the model, the number of samples in the training set, and model misspecification. An extensive suite of numerical experiments further highlights the properties, strengths, and weaknesses of the method and extends its applicability to other tasks, such as conditional <b>simulation</b> and inference.

{{</citation>}}


### (184/210) Noise-Adaptive Confidence Sets for Linear Bandits and Application to Bayesian Optimization (Kwang-Sung Jun et al., 2024)

{{<citation>}}

Kwang-Sung Jun, Jungtaek Kim. (2024)  
**Noise-Adaptive Confidence Sets for Linear Bandits and Application to Bayesian Optimization**
<br/>
<button class="copy-to-clipboard" title="Noise-Adaptive Confidence Sets for Linear Bandits and Application to Bayesian Optimization" index=184>
  <span class="copy-to-clipboard-item">Copy Title<span>
</button>
<div class="toast toast-copied toast-index-184 align-items-center text-bg-secondary border-0 position-absolute top-0 end-0" role="alert" aria-live="assertive" aria-atomic="true">
  <div class="d-flex">
    <div class="toast-body">
      Copied!
    </div>
  </div>
</div>

---
Primary Category: stat.ML  
Categories: cs-LG, stat-ML, stat.ML  
Keyword Score: 20  
Keywords: Bandit Algorithm, Bandit Algorithm  
<a type="button" class="btn btn-outline-primary" href="http://arxiv.org/abs/2402.07341v1" target="_blank" >Paper Link</a>
<button type="button" class="btn btn-outline-primary download-pdf" url="https://arxiv.org/pdf/2402.07341v1.pdf" filename="2402.07341v1.pdf">Download PDF</button>

---


**ABSTRACT**  
Adapting to a priori unknown noise level is a very important but challenging problem in sequential decision-making as efficient exploration typically requires knowledge of the noise level, which is often loosely specified. We report significant progress in addressing this issue in linear <b>bandits</b> <b>in</b> two respects. First, we propose a novel confidence set that is `semi-adaptive' to the unknown sub-Gaussian parameter $\sigma_*^2$ in the sense that the (normalized) confidence width scales with $\sqrt{d\sigma_*^2 + \sigma_0^2}$ where $d$ is the dimension and $\sigma_0^2$ is the specified sub-Gaussian parameter (known) that can be much larger than $\sigma_*^2$. This is a significant improvement over $\sqrt{d\sigma_0^2}$ of the standard confidence set of Abbasi-Yadkori et al. (2011), especially when $d$ is large. We show that this leads to an improved regret bound in linear <b>bandits.</b> <b>Second,</b> for bounded rewards, we propose a novel variance-adaptive confidence set that has a much improved numerical performance upon prior art. We then apply this confidence set to develop, as we claim, the first practical variance-adaptive linear <b>bandit</b> <b>algorithm</b> via an optimistic approach, which is enabled by our novel regret analysis technique. Both of our confidence sets rely critically on `regret equality' from online learning. Our empirical evaluation in Bayesian optimization tasks shows that our algorithms demonstrate better or comparable performance compared to existing methods.

{{</citation>}}


### (185/210) Replicability is Asymptotically Free in Multi-armed Bandits (Junpei Komiyama et al., 2024)

{{<citation>}}

Junpei Komiyama, Shinji Ito, Yuichi Yoshida, Souta Koshino. (2024)  
**Replicability is Asymptotically Free in Multi-armed Bandits**
<br/>
<button class="copy-to-clipboard" title="Replicability is Asymptotically Free in Multi-armed Bandits" index=185>
  <span class="copy-to-clipboard-item">Copy Title<span>
</button>
<div class="toast toast-copied toast-index-185 align-items-center text-bg-secondary border-0 position-absolute top-0 end-0" role="alert" aria-live="assertive" aria-atomic="true">
  <div class="d-flex">
    <div class="toast-body">
      Copied!
    </div>
  </div>
</div>

---
Primary Category: stat.ML  
Categories: cs-LG, stat-ML, stat.ML  
Keyword Score: 10  
Keywords: Bandit Algorithm  
<a type="button" class="btn btn-outline-primary" href="http://arxiv.org/abs/2402.07391v1" target="_blank" >Paper Link</a>
<button type="button" class="btn btn-outline-primary download-pdf" url="https://arxiv.org/pdf/2402.07391v1.pdf" filename="2402.07391v1.pdf">Download PDF</button>

---


**ABSTRACT**  
This work is motivated by the growing demand for reproducible machine learning. We study the stochastic multi-armed <b>bandit</b> problem. In particular, we consider a replicable algorithm that ensures, with high probability, that the algorithm's sequence of actions is not affected by the randomness inherent in the dataset. We observe that existing algorithms require $O(1/\rho^2)$ times more regret than nonreplicable algorithms, where $\rho$ is the level of nonreplication. However, we demonstrate that this additional cost is unnecessary when the time horizon $T$ is sufficiently large for a given $\rho$, provided that the magnitude of the confidence bounds is chosen carefully. We introduce an explore-then-commit algorithm that draws arms uniformly before committing to a single arm. Additionally, we examine a successive elimination algorithm that eliminates suboptimal arms at the end of each phase. To ensure the replicability of these algorithms, we incorporate randomness into their decision-making processes. We extend the use of successive elimination to the linear <b>bandit</b> problem as well. For the analysis of these algorithms, we propose a principled approach to limiting the probability of nonreplication. This approach elucidates the steps that existing research has implicitly followed. Furthermore, we derive the first lower bound for the two-armed replicable <b>bandit</b> problem, which implies the optimality of the proposed algorithms up to a $\log\log T$ factor for the two-armed case.

{{</citation>}}


## cs.SI (1)



### (186/210) Comparing the willingness to share for human-generated vs. AI-generated fake news (Amirsiavosh Bashardoust et al., 2024)

{{<citation>}}

Amirsiavosh Bashardoust, Stefan Feuerriegel, Yash Raj Shrestha. (2024)  
**Comparing the willingness to share for human-generated vs. AI-generated fake news**
<br/>
<button class="copy-to-clipboard" title="Comparing the willingness to share for human-generated vs. AI-generated fake news" index=186>
  <span class="copy-to-clipboard-item">Copy Title<span>
</button>
<div class="toast toast-copied toast-index-186 align-items-center text-bg-secondary border-0 position-absolute top-0 end-0" role="alert" aria-live="assertive" aria-atomic="true">
  <div class="d-flex">
    <div class="toast-body">
      Copied!
    </div>
  </div>
</div>

---
Primary Category: cs.SI  
Categories: cs-SI, cs.SI  
Keyword Score: 30  
Keywords: GPT, GPT-4, Fake News Detection  
<a type="button" class="btn btn-outline-primary" href="http://arxiv.org/abs/2402.07395v1" target="_blank" >Paper Link</a>
<button type="button" class="btn btn-outline-primary download-pdf" url="https://arxiv.org/pdf/2402.07395v1.pdf" filename="2402.07395v1.pdf">Download PDF</button>

---


**ABSTRACT**  
Generative artificial intelligence (AI) presents large risks for society when it is used to create <b>fake</b> <b>news.</b> A crucial factor for <b>fake</b> <b>news</b> to go viral on social media is that users share such content. Here, we aim to shed light on the sharing behavior of users across human-generated vs. AI-generated <b>fake</b> <b>news.</b> Specifically, we study: (1) What is the perceived veracity of human-generated <b>fake</b> <b>news</b> vs. AI-generated <b>fake</b> <b>news?</b> (2) What is the user's willingness to share human-generated <b>fake</b> <b>news</b> vs. AI-generated <b>fake</b> <b>news</b> on social media? (3) What socio-economic characteristics let users fall for AI-generated <b>fake</b> <b>news?</b> To this end, we conducted a pre-registered, online experiment with $N=$ 988 subjects and 20 <b>fake</b> <b>news</b> from the COVID-19 pandemic generated by <b>GPT-4</b> vs. humans. Our findings show that AI-generated <b>fake</b> <b>news</b> is perceived as less accurate than human-generated <b>fake</b> <b>news,</b> but both tend to be shared equally. Further, several socio-economic factors explain who falls for AI-generated <b>fake</b> <b>news.</b>

{{</citation>}}


## eess.IV (4)



### (187/210) Automated Classification of Body MRI Sequence Type Using Convolutional Neural Networks (Kimberly Helm et al., 2024)

{{<citation>}}

Kimberly Helm, Tejas Sudharshan Mathai, Boah Kim, Pritam Mukherjee, Jianfei Liu, Ronald M. Summers. (2024)  
**Automated Classification of Body MRI Sequence Type Using Convolutional Neural Networks**
<br/>
<button class="copy-to-clipboard" title="Automated Classification of Body MRI Sequence Type Using Convolutional Neural Networks" index=187>
  <span class="copy-to-clipboard-item">Copy Title<span>
</button>
<div class="toast toast-copied toast-index-187 align-items-center text-bg-secondary border-0 position-absolute top-0 end-0" role="alert" aria-live="assertive" aria-atomic="true">
  <div class="d-flex">
    <div class="toast-body">
      Copied!
    </div>
  </div>
</div>

---
Primary Category: eess.IV  
Categories: cs-CV, eess-IV, eess.IV  
Keyword Score: 20  
Keywords: Convolution, Convolutional Neural Network  
<a type="button" class="btn btn-outline-primary" href="http://arxiv.org/abs/2402.08098v1" target="_blank" >Paper Link</a>
<button type="button" class="btn btn-outline-primary download-pdf" url="https://arxiv.org/pdf/2402.08098v1.pdf" filename="2402.08098v1.pdf">Download PDF</button>

---


**ABSTRACT**  
Multi-parametric MRI of the body is routinely acquired for the identification of abnormalities and diagnosis of diseases. However, a standard naming convention for the MRI protocols and associated sequences does not exist due to wide variations in imaging practice at institutions and myriad MRI scanners from various manufacturers being used for imaging. The intensity distributions of MRI sequences differ widely as a result, and there also exists information conflicts related to the sequence type in the DICOM headers. At present, clinician oversight is necessary to ensure that the correct sequence is being read and used for diagnosis. This poses a challenge when specific series need to be considered for building a cohort for a large clinical study or for developing AI algorithms. In order to reduce clinician oversight and ensure the validity of the DICOM headers, we propose an automated method to classify the 3D MRI sequence acquired at the levels of the chest, abdomen, and pelvis. In our pilot work, our 3D DenseNet-121 model achieved an F1 score of 99.5% at differentiating 5 common MRI sequences obtained by three Siemens scanners (Aera, Verio, Biograph mMR). To the best of our knowledge, we are the first to develop an automated method for the 3D classification of MRI sequences in the chest, abdomen, and pelvis, and our work has outperformed the previous state-of-the-art MRI series classifiers.

{{</citation>}}


### (188/210) Minimally Interactive Segmentation of Soft-Tissue Tumors on CT and MRI using Deep Learning (Douwe J. Spaanderman et al., 2024)

{{<citation>}}

Douwe J. Spaanderman, Martijn P. A. Starmans, Gonnie C. M. van Erp, David F. Hanff, Judith H. Sluijter, Anne-Rose W. Schut, Geert J. L. H. van Leenders, Cornelis Verhoef, Dirk J. Grunhagen, Wiro J. Niessen, Jacob J. Visser, Stefan Klein. (2024)  
**Minimally Interactive Segmentation of Soft-Tissue Tumors on CT and MRI using Deep Learning**
<br/>
<button class="copy-to-clipboard" title="Minimally Interactive Segmentation of Soft-Tissue Tumors on CT and MRI using Deep Learning" index=188>
  <span class="copy-to-clipboard-item">Copy Title<span>
</button>
<div class="toast toast-copied toast-index-188 align-items-center text-bg-secondary border-0 position-absolute top-0 end-0" role="alert" aria-live="assertive" aria-atomic="true">
  <div class="d-flex">
    <div class="toast-body">
      Copied!
    </div>
  </div>
</div>

---
Primary Category: eess.IV  
Categories: cs-CV, eess-IV, eess.IV  
Keyword Score: 20  
Keywords: Convolution, Convolutional Neural Network  
<a type="button" class="btn btn-outline-primary" href="http://arxiv.org/abs/2402.07746v1" target="_blank" >Paper Link</a>
<button type="button" class="btn btn-outline-primary download-pdf" url="https://arxiv.org/pdf/2402.07746v1.pdf" filename="2402.07746v1.pdf">Download PDF</button>

---


**ABSTRACT**  
Segmentations are crucial in medical imaging to obtain morphological, volumetric, and radiomics biomarkers. Manual segmentation is accurate but not feasible in the radiologist's clinical workflow, while automatic segmentation generally obtains sub-par performance. We therefore developed a minimally interactive deep learning-based segmentation method for soft-tissue tumors (STTs) on CT and MRI. The method requires the user to click six points near the tumor's extreme boundaries. These six points are transformed into a distance map and serve, with the image, as input for a <b>Convolutional</b> <b>Neural</b> <b>Network.</b> For training and validation, a multicenter dataset containing 514 patients and nine STT types in seven anatomical locations was used, resulting in a Dice Similarity Coefficient (DSC) of 0.85$\pm$0.11 (mean $\pm$ standard deviation (SD)) for CT and 0.84$\pm$0.12 for T1-weighted MRI, when compared to manual segmentations made by expert radiologists. Next, the method was externally validated on a dataset including five unseen STT phenotypes in extremities, achieving 0.81$\pm$0.08 for CT, 0.84$\pm$0.09 for T1-weighted MRI, and 0.88\pm0.08 for previously unseen T2-weighted fat-saturated (FS) MRI. In conclusion, our minimally interactive segmentation method effectively segments different types of STTs on CT and MRI, with robust generalization to previously unseen phenotypes and imaging modalities.

{{</citation>}}


### (189/210) Comparative Analysis of ImageNet Pre-Trained Deep Learning Models and DINOv2 in Medical Imaging Classification (Yuning Huang et al., 2024)

{{<citation>}}

Yuning Huang, Jingchen Zou, Lanxi Meng, Xin Yue, Qing Zhao, Jianqiang Li, Changwei Song, Gabriel Jimenez, Shaowu Li, Guanghui Fu. (2024)  
**Comparative Analysis of ImageNet Pre-Trained Deep Learning Models and DINOv2 in Medical Imaging Classification**
<br/>
<button class="copy-to-clipboard" title="Comparative Analysis of ImageNet Pre-Trained Deep Learning Models and DINOv2 in Medical Imaging Classification" index=189>
  <span class="copy-to-clipboard-item">Copy Title<span>
</button>
<div class="toast toast-copied toast-index-189 align-items-center text-bg-secondary border-0 position-absolute top-0 end-0" role="alert" aria-live="assertive" aria-atomic="true">
  <div class="d-flex">
    <div class="toast-body">
      Copied!
    </div>
  </div>
</div>

---
Primary Category: eess.IV  
Categories: cs-LG, eess-IV, eess.IV  
Keyword Score: 20  
Keywords: Transfer Learning, Transformer  
<a type="button" class="btn btn-outline-primary" href="http://arxiv.org/abs/2402.07595v2" target="_blank" >Paper Link</a>
<button type="button" class="btn btn-outline-primary download-pdf" url="https://arxiv.org/pdf/2402.07595v2.pdf" filename="2402.07595v2.pdf">Download PDF</button>

---


**ABSTRACT**  
Medical image analysis frequently encounters data scarcity challenges. <b>Transfer</b> <b>learning</b> has been effective in addressing this issue while conserving computational resources. The recent advent of foundational models like the DINOv2, which uses the vision <b>transformer</b> architecture, has opened new opportunities in the field and gathered significant interest. However, DINOv2's performance on clinical data still needs to be verified. In this paper, we performed a glioma grading task using three clinical modalities of brain MRI data. We compared the performance of various pre-trained deep learning models, including those based on ImageNet and DINOv2, in a <b>transfer</b> <b>learning</b> context. Our focus was on understanding the impact of the freezing mechanism on performance. We also validated our findings on three other types of public datasets: chest radiography, fundus radiography, and dermoscopy. Our findings indicate that in our clinical dataset, DINOv2's performance was not as strong as ImageNet-based pre-trained models, whereas in public datasets, DINOv2 generally outperformed other models, especially when using the frozen mechanism. Similar performance was observed with various sizes of DINOv2 models across different tasks. In summary, DINOv2 is viable for medical image classification tasks, particularly with data resembling natural images. However, its effectiveness may vary with data that significantly differs from natural images such as MRI. In addition, employing smaller versions of the model can be adequate for medical task, offering resource-saving benefits. Our codes are available at https://github.com/GuanghuiFU/medical_DINOv2_eval.

{{</citation>}}


### (190/210) Re-DiffiNet: Modeling discrepancies in tumor segmentation using diffusion (Tianyi Ren et al., 2024)

{{<citation>}}

Tianyi Ren, Abhishek Sharma, Juampablo Heras Rivera, Harshitha Rebala, Ethan Honey, Agamdeep Chopra, Mehmet Kurt. (2024)  
**Re-DiffiNet: Modeling discrepancies in tumor segmentation using diffusion**
<br/>
<button class="copy-to-clipboard" title="Re-DiffiNet: Modeling discrepancies in tumor segmentation using diffusion" index=190>
  <span class="copy-to-clipboard-item">Copy Title<span>
</button>
<div class="toast toast-copied toast-index-190 align-items-center text-bg-secondary border-0 position-absolute top-0 end-0" role="alert" aria-live="assertive" aria-atomic="true">
  <div class="d-flex">
    <div class="toast-body">
      Copied!
    </div>
  </div>
</div>

---
Primary Category: eess.IV  
Categories: cs-CV, eess-IV, eess.IV  
Keyword Score: 20  
Keywords: Generative Adversarial Network, Generative Adversarial Network  
<a type="button" class="btn btn-outline-primary" href="http://arxiv.org/abs/2402.07354v1" target="_blank" >Paper Link</a>
<button type="button" class="btn btn-outline-primary download-pdf" url="https://arxiv.org/pdf/2402.07354v1.pdf" filename="2402.07354v1.pdf">Download PDF</button>

---


**ABSTRACT**  
Identification of tumor margins is essential for surgical decision-making for glioblastoma patients and provides reliable assistance for neurosurgeons. Despite improvements in deep learning architectures for tumor segmentation over the years, creating a fully autonomous system suitable for clinical floors remains a formidable challenge because the model predictions have not yet reached the desired level of accuracy and generalizability for clinical applications. <b>Generative</b> <b>modeling</b> <b>techniques</b> have seen significant improvements in recent times. Specifically, <b>Generative</b> <b>Adversarial</b> <b>Networks</b> <b>(GANs)</b> and Denoising-diffusion-based models (DDPMs) have been used to generate higher-quality images with fewer artifacts and finer attributes. In this work, we introduce a framework called Re-Diffinet for modeling the discrepancy between the outputs of a segmentation model like U-Net and the ground truth, using DDPMs. By explicitly modeling the discrepancy, the results show an average improvement of 0.55\% in the Dice score and 16.28\% in HD95 from cross-validation over 5-folds, compared to the state-of-the-art U-Net segmentation model.

{{</citation>}}


## eess.SY (4)



### (191/210) On the Stability of Undesirable Equilibria in the Quadratic Program Framework for Safety-Critical Control (Matheus F. Reis et al., 2024)

{{<citation>}}

Matheus F. Reis, A. Pedro Aguiar. (2024)  
**On the Stability of Undesirable Equilibria in the Quadratic Program Framework for Safety-Critical Control**
<br/>
<button class="copy-to-clipboard" title="On the Stability of Undesirable Equilibria in the Quadratic Program Framework for Safety-Critical Control" index=191>
  <span class="copy-to-clipboard-item">Copy Title<span>
</button>
<div class="toast toast-copied toast-index-191 align-items-center text-bg-secondary border-0 position-absolute top-0 end-0" role="alert" aria-live="assertive" aria-atomic="true">
  <div class="d-flex">
    <div class="toast-body">
      Copied!
    </div>
  </div>
</div>

---
Primary Category: eess.SY  
Categories: cs-SY, eess-SY, eess.SY  
Keyword Score: 20  
Keywords: Simulation, Simulator  
<a type="button" class="btn btn-outline-primary" href="http://arxiv.org/abs/2402.08027v1" target="_blank" >Paper Link</a>
<button type="button" class="btn btn-outline-primary download-pdf" url="https://arxiv.org/pdf/2402.08027v1.pdf" filename="2402.08027v1.pdf">Download PDF</button>

---


**ABSTRACT**  
Control Lyapunov functions (CLFs) and Control Barrier Functions (CBFs) have been used to develop provably safe controllers by means of quadratic programs (QPs). This framework guarantees safety in the form of trajectory invariance with respect to a given set, but it can introduce undesirable equilibrium points to the closed loop system, which can be asymptotically stable. In this work, we present a detailed study of the formation and stability of equilibrium points with the QP framework for a class of nonlinear systems. We introduce the useful concept of compatibility between a CLF and a family of CBFs, regarding the number of stable equilibrium points other than the CLF minimum. Using this concept, we derive a set of compatibility conditions on the parameters of a quadratic CLF and a family of quadratic CBFs that guarantee that all undesirable equilibrium points are not attractive. Furthermore, we propose an extension to the QP-based controller that dynamically modifies the CLF geometry in order to satisfy the compatibility conditions, guaranteeing safety and quasi-global convergence of the system state to the CLF minimum. Numeric <b>simulations</b> illustrate the applicability of the proposed method for safety-critical, deadlock-free robotic navigation tasks.

{{</citation>}}


### (192/210) Distributed Anomaly Detection in Modern Power Systems: A Penalty-based Mitigation Approach (Erfan Mehdipour Abadi et al., 2024)

{{<citation>}}

Erfan Mehdipour Abadi, Masoud H. Nazari. (2024)  
**Distributed Anomaly Detection in Modern Power Systems: A Penalty-based Mitigation Approach**
<br/>
<button class="copy-to-clipboard" title="Distributed Anomaly Detection in Modern Power Systems: A Penalty-based Mitigation Approach" index=192>
  <span class="copy-to-clipboard-item">Copy Title<span>
</button>
<div class="toast toast-copied toast-index-192 align-items-center text-bg-secondary border-0 position-absolute top-0 end-0" role="alert" aria-live="assertive" aria-atomic="true">
  <div class="d-flex">
    <div class="toast-body">
      Copied!
    </div>
  </div>
</div>

---
Primary Category: eess.SY  
Categories: cs-SY, eess-SY, eess.SY  
Keyword Score: 20  
Keywords: Simulation, Simulator  
<a type="button" class="btn btn-outline-primary" href="http://arxiv.org/abs/2402.07884v1" target="_blank" >Paper Link</a>
<button type="button" class="btn btn-outline-primary download-pdf" url="https://arxiv.org/pdf/2402.07884v1.pdf" filename="2402.07884v1.pdf">Download PDF</button>

---


**ABSTRACT**  
The evolving landscape of electric power networks, influenced by the integration of distributed energy resources require the development of novel power system monitoring and control architectures. This paper develops algorithm to monitor and detect anomalies of different parts of a power system that cannot be measured directly, by applying neighboring measurements and a dynamic probing technique in a distributed fashion. Additionally, the proposed method accurately assesses the severity of the anomaly. A decision-making algorithm is introduced to effectively penalize anomalous agents, ensuring vigilant oversight of the entire power system's functioning. <b>Simulation</b> results show the efficacy of algorithms in distributed anomaly detection and mitigation.

{{</citation>}}


### (193/210) Correctness Verification of Neural Networks Approximating Differential Equations (Petros Ellinas et al., 2024)

{{<citation>}}

Petros Ellinas, Rahul Nellikath, Ignasi Ventura, Jochen Stiasny, Spyros Chatzivasileiadis. (2024)  
**Correctness Verification of Neural Networks Approximating Differential Equations**
<br/>
<button class="copy-to-clipboard" title="Correctness Verification of Neural Networks Approximating Differential Equations" index=193>
  <span class="copy-to-clipboard-item">Copy Title<span>
</button>
<div class="toast toast-copied toast-index-193 align-items-center text-bg-secondary border-0 position-absolute top-0 end-0" role="alert" aria-live="assertive" aria-atomic="true">
  <div class="d-flex">
    <div class="toast-body">
      Copied!
    </div>
  </div>
</div>

---
Primary Category: eess.SY  
Categories: cs-LG, cs-SY, eess-SY, eess.SY  
Keyword Score: 20  
Keywords: Simulation, Simulator  
<a type="button" class="btn btn-outline-primary" href="http://arxiv.org/abs/2402.07621v1" target="_blank" >Paper Link</a>
<button type="button" class="btn btn-outline-primary download-pdf" url="https://arxiv.org/pdf/2402.07621v1.pdf" filename="2402.07621v1.pdf">Download PDF</button>

---


**ABSTRACT**  
Verification of Neural Networks (NNs) that approximate the solution of Partial Differential Equations (PDEs) is a major milestone towards enhancing their trustworthiness and accelerating their deployment, especially for safety-critical systems. If successful, such NNs can become integral parts of <b>simulation</b> software tools which can accelerate the <b>simulation</b> of complex dynamic systems more than 100 times. However, the verification of these functions poses major challenges; it is not straightforward how to efficiently bound them or how to represent the derivative of the NN. This work addresses both these problems. First, we define the NN derivative as a finite difference approximation. Then, we formulate the PDE residual bounding problem alongside the Initial Value Problem's error propagation. Finally, for the first time, we tackle the problem of bounding an NN function without a priori knowledge of the output domain. For this, we build a parallel branching algorithm that combines the incomplete CROWN solver and Gradient Attack for termination and domain rejection conditions. We demonstrate the strengths and weaknesses of the proposed framework, and we suggest further work to enhance its efficiency.

{{</citation>}}


### (194/210) Joint User and Beam Selection in Millimeter Wave Networks (Santosh Kumar Singh et al., 2024)

{{<citation>}}

Santosh Kumar Singh, Satyabrata Sahu, Ayushi Thawait, Prasanna Chaporkar, Gaurav S. Kasbekar. (2024)  
**Joint User and Beam Selection in Millimeter Wave Networks**
<br/>
<button class="copy-to-clipboard" title="Joint User and Beam Selection in Millimeter Wave Networks" index=194>
  <span class="copy-to-clipboard-item">Copy Title<span>
</button>
<div class="toast toast-copied toast-index-194 align-items-center text-bg-secondary border-0 position-absolute top-0 end-0" role="alert" aria-live="assertive" aria-atomic="true">
  <div class="d-flex">
    <div class="toast-body">
      Copied!
    </div>
  </div>
</div>

---
Primary Category: eess.SY  
Categories: cs-SY, eess-SP, eess-SY, eess.SY  
Keyword Score: 20  
Keywords: Simulation, Simulator  
<a type="button" class="btn btn-outline-primary" href="http://arxiv.org/abs/2402.07563v1" target="_blank" >Paper Link</a>
<button type="button" class="btn btn-outline-primary download-pdf" url="https://arxiv.org/pdf/2402.07563v1.pdf" filename="2402.07563v1.pdf">Download PDF</button>

---


**ABSTRACT**  
We study the problem of selecting a user equipment (UE) and a beam for each access point (AP) for concurrent transmissions in a millimeter wave (mmWave) network, such that the sum of weighted rates of UEs is maximized. We prove that this problem is NP-complete. We propose two algorithms -- Markov Chain Monte Carlo (MCMC) based and local interaction game (LIG) based UE and beam selection -- and prove that both of them asymptotically achieve the optimal solution. Also, we propose two fast greedy algorithms -- NGUB1 and NGUB2 -- for UE and beam selection. Through extensive <b>simulations,</b> we show that our proposed greedy algorithms outperform the most relevant algorithms proposed in prior work and perform close to the asymptotically optimal algorithms.

{{</citation>}}


## cs.SE (4)



### (195/210) Mercury: An Efficiency Benchmark for LLM Code Synthesis (Mingzhe Du et al., 2024)

{{<citation>}}

Mingzhe Du, Anh Tuan Luu, Bin Ji, See-Kiong Ng. (2024)  
**Mercury: An Efficiency Benchmark for LLM Code Synthesis**
<br/>
<button class="copy-to-clipboard" title="Mercury: An Efficiency Benchmark for LLM Code Synthesis" index=195>
  <span class="copy-to-clipboard-item">Copy Title<span>
</button>
<div class="toast toast-copied toast-index-195 align-items-center text-bg-secondary border-0 position-absolute top-0 end-0" role="alert" aria-live="assertive" aria-atomic="true">
  <div class="d-flex">
    <div class="toast-body">
      Copied!
    </div>
  </div>
</div>

---
Primary Category: cs.SE  
Categories: cs-CL, cs-SE, cs.SE  
Keyword Score: 20  
Keywords: Large Language Model, Large Language Model  
<a type="button" class="btn btn-outline-primary" href="http://arxiv.org/abs/2402.07844v1" target="_blank" >Paper Link</a>
<button type="button" class="btn btn-outline-primary download-pdf" url="https://arxiv.org/pdf/2402.07844v1.pdf" filename="2402.07844v1.pdf">Download PDF</button>

---


**ABSTRACT**  
Despite advancements in evaluating <b>Large</b> <b>Language</b> <b>Models</b> <b>(LLMs)</b> for code synthesis, benchmarks have predominantly focused on functional correctness, overlooking the importance of code efficiency. We present Mercury, the first benchmark designated for assessing the code efficiency of <b>LLM</b> code synthesis tasks. Mercury consists of 1,889 programming tasks covering diverse difficulty levels alongside test case generators generating unlimited cases for comprehensive evaluation. Unlike existing benchmarks, Mercury integrates a novel metric Beyond@K to measure normalized code efficiency based on historical submissions, leading to a new evaluation indicator for code synthesis, which encourages generating functionally correct and computationally efficient code, mirroring the real-world software development standard. Our findings reveal that while <b>LLMs</b> demonstrate the remarkable capability to generate functionally correct code, there still exists a substantial gap in their efficiency output, underscoring a new frontier for <b>LLM</b> research and development.

{{</citation>}}


### (196/210) Continuous Assurance of Autonomous Vehicle Behavior Through Machine Learned Correctness Properties (Matthew Litton et al., 2024)

{{<citation>}}

Matthew Litton, Doron Drusinsky, James Bret Michael. (2024)  
**Continuous Assurance of Autonomous Vehicle Behavior Through Machine Learned Correctness Properties**
<br/>
<button class="copy-to-clipboard" title="Continuous Assurance of Autonomous Vehicle Behavior Through Machine Learned Correctness Properties" index=196>
  <span class="copy-to-clipboard-item">Copy Title<span>
</button>
<div class="toast toast-copied toast-index-196 align-items-center text-bg-secondary border-0 position-absolute top-0 end-0" role="alert" aria-live="assertive" aria-atomic="true">
  <div class="d-flex">
    <div class="toast-body">
      Copied!
    </div>
  </div>
</div>

---
Primary Category: cs.SE  
Categories: cs-SE, cs.SE  
Keyword Score: 20  
Keywords: Simulation, Simulator  
<a type="button" class="btn btn-outline-primary" href="http://arxiv.org/abs/2402.07791v1" target="_blank" >Paper Link</a>
<button type="button" class="btn btn-outline-primary download-pdf" url="https://arxiv.org/pdf/2402.07791v1.pdf" filename="2402.07791v1.pdf">Download PDF</button>

---


**ABSTRACT**  
Correctness properties are critical to conducting verification and validation on software systems, especially those cyberphysical systems whose functionality changes frequently due to software updates, changes in the operating environment, or newly learned behaviors. We detail a novel method to automatically construct expressive, executable correctness properties in the form of machine-learned correctness properties which can be used to ensure that a system's behavior is correct with respect to its design and operating requirements. We propose a method to bootstrap the creation of these correctness properties using a novel <b>simulation-based</b> generation of training and testing data using multiple extensions to the Cross Entropy algorithm for search-based optimization. Then, we apply this method to a software-in-the-loop evaluation of an autonomous vehicle to demonstrate that such models can assert about important properties of multi-agent cyberphysical systems. We demonstrate that this process brings the task of developing robust correctness properties from the realm of formal methods experts into the domain of system developers and engineers, and that machine-learned correctness properties are expressive enough to capture the correct behavior of cyberphysical systems in their complex environments. This advancement can provide evidence of dependability to system designers and users, enhancing trust in the deployment of autonomous vehicles and other intelligent transportation systems.

{{</citation>}}


### (197/210) Interaction-Based Driving Scenario Classification and Labeling (Cheng Chang et al., 2024)

{{<citation>}}

Cheng Chang, Jiawei Zhang, Jingwei Ge, Zuo Zhang, Junqing Wei, Li Li. (2024)  
**Interaction-Based Driving Scenario Classification and Labeling**
<br/>
<button class="copy-to-clipboard" title="Interaction-Based Driving Scenario Classification and Labeling" index=197>
  <span class="copy-to-clipboard-item">Copy Title<span>
</button>
<div class="toast toast-copied toast-index-197 align-items-center text-bg-secondary border-0 position-absolute top-0 end-0" role="alert" aria-live="assertive" aria-atomic="true">
  <div class="d-flex">
    <div class="toast-body">
      Copied!
    </div>
  </div>
</div>

---
Primary Category: cs.SE  
Categories: cs-SE, cs.SE  
Keyword Score: 10  
Keywords: Summarization  
<a type="button" class="btn btn-outline-primary" href="http://arxiv.org/abs/2402.07720v1" target="_blank" >Paper Link</a>
<button type="button" class="btn btn-outline-primary download-pdf" url="https://arxiv.org/pdf/2402.07720v1.pdf" filename="2402.07720v1.pdf">Download PDF</button>

---


**ABSTRACT**  
Scenario data play a vital role in autonomous driving related researches, and it is essential to obtain refined descriptions and labels to extract and index scenarios with different types of interactions. However, existing methods cannot cope well with the problem of scenario classification and comparison with vehicle interactions as the core. In this paper, we propose a framework for interaction-based refined scenario classification and labeling. Based on the <b>summarized</b> basic types of vehicle interactions, we slice scenario data stream into a series of scenario segments via spatiotemporal scenario evolution tree. The scenario segment statistics of many published scenario datasets are further analyzed. We also propose the scenario metric Graph-DTW based on Graph Computation Tree and Dynamic Time Warping to conduct refined scenario comparison and labeling. The extreme interactive scenarios and corner cases can be efficiently filtered and extracted. Moreover, testing examples on trajectory prediction model demonstrate the effectiveness and advantages of scenario labeling and the proposed metric. The overall framework can provide solid support for the usage and indexing of scenario data.

{{</citation>}}


### (198/210) Using Ensemble Inference to Improve Recall of Clone Detection (Gul Aftab Ahmed et al., 2024)

{{<citation>}}

Gul Aftab Ahmed, James Vincent Patten, Yuanhua Han, Guoxian Lu, David Gregg, Jim Buckley, Muslim Chochlov. (2024)  
**Using Ensemble Inference to Improve Recall of Clone Detection**
<br/>
<button class="copy-to-clipboard" title="Using Ensemble Inference to Improve Recall of Clone Detection" index=198>
  <span class="copy-to-clipboard-item">Copy Title<span>
</button>
<div class="toast toast-copied toast-index-198 align-items-center text-bg-secondary border-0 position-absolute top-0 end-0" role="alert" aria-live="assertive" aria-atomic="true">
  <div class="d-flex">
    <div class="toast-body">
      Copied!
    </div>
  </div>
</div>

---
Primary Category: cs.SE  
Categories: cs-SE, cs.SE  
Keyword Score: 10  
Keywords: ChatGPT  
<a type="button" class="btn btn-outline-primary" href="http://arxiv.org/abs/2402.07523v1" target="_blank" >Paper Link</a>
<button type="button" class="btn btn-outline-primary download-pdf" url="https://arxiv.org/pdf/2402.07523v1.pdf" filename="2402.07523v1.pdf">Download PDF</button>

---


**ABSTRACT**  
Large-scale source-code clone detection is a challenging task. In our previous work, we proposed an approach (SSCD) that leverages artificial neural networks and approximates nearest neighbour search to effectively and efficiently locate clones in large-scale bodies of code, in a time-efficient manner. However, our literature review suggests that the relative efficacy of differing neural network models has not been assessed in the context of large-scale clone detection approaches. In this work, we aim to assess several such models individually, in terms of their potential to maximize recall, while preserving a high level of precision during clone detection. We investigate if ensemble inference (in this case, using the results of more than one of these neural network models in combination) can further assist in this task. To assess this, we employed four state-of-the-art neural network models and evaluated them individually/in combination. The results, on an illustrative dataset of approximately 500K lines of C/C++ code, suggest that ensemble inference outperforms individual models in all trialled cases, when recall is concerned. Of individual models, the ADA model (belonging to the <b>ChatGPT</b> family of models) has the best performance. However commercial companies may not be prepared to hand their proprietary source code over to the cloud, as required by that approach. Consequently, they may be more interested in an ensemble-combination of CodeBERT-based and CodeT5 models, resulting in similar (if slightly lesser) recall and precision results.

{{</citation>}}


## math.OC (1)



### (199/210) Tuning-Free Stochastic Optimization (Ahmed Khaled et al., 2024)

{{<citation>}}

Ahmed Khaled, Chi Jin. (2024)  
**Tuning-Free Stochastic Optimization**
<br/>
<button class="copy-to-clipboard" title="Tuning-Free Stochastic Optimization" index=199>
  <span class="copy-to-clipboard-item">Copy Title<span>
</button>
<div class="toast toast-copied toast-index-199 align-items-center text-bg-secondary border-0 position-absolute top-0 end-0" role="alert" aria-live="assertive" aria-atomic="true">
  <div class="d-flex">
    <div class="toast-body">
      Copied!
    </div>
  </div>
</div>

---
Primary Category: math.OC  
Categories: cs-LG, math-OC, math.OC, stat-ML  
Keyword Score: 20  
Keywords: Stochastic Gradient Descent, Stochastic Gradient Descent  
<a type="button" class="btn btn-outline-primary" href="http://arxiv.org/abs/2402.07793v1" target="_blank" >Paper Link</a>
<button type="button" class="btn btn-outline-primary download-pdf" url="https://arxiv.org/pdf/2402.07793v1.pdf" filename="2402.07793v1.pdf">Download PDF</button>

---


**ABSTRACT**  
Large-scale machine learning problems make the cost of hyperparameter tuning ever more prohibitive. This creates a need for algorithms that can tune themselves on-the-fly. We formalize the notion of "tuning-free" algorithms that can match the performance of optimally-tuned optimization algorithms up to polylogarithmic factors given only loose hints on the relevant problem parameters. We consider in particular algorithms that can match optimally-tuned <b>Stochastic</b> <b>Gradient</b> <b>Descent</b> <b>(SGD).</b> When the domain of optimization is bounded, we show tuning-free matching of <b>SGD</b> is possible and achieved by several existing algorithms. We prove that for the task of minimizing a convex and smooth or Lipschitz function over an unbounded domain, tuning-free optimization is impossible. We discuss conditions under which tuning-free optimization is possible even over unbounded domains. In particular, we show that the recently proposed DoG and DoWG algorithms are tuning-free when the noise distribution is sufficiently well-behaved. For the task of finding a stationary point of a smooth and potentially nonconvex function, we give a variant of <b>SGD</b> that matches the best-known high-probability convergence rate for tuned <b>SGD</b> at only an additional polylogarithmic cost. However, we also give an impossibility result that shows no algorithm can hope to match the optimal expected convergence rate for tuned <b>SGD</b> with high probability.

{{</citation>}}


## physics.ao-ph (1)



### (200/210) Robust and accurate simulations of flows over orography using non-conforming meshes (Giuseppe Orlando et al., 2024)

{{<citation>}}

Giuseppe Orlando, Tommaso Benacchio, Luca Bonaventura. (2024)  
**Robust and accurate simulations of flows over orography using non-conforming meshes**
<br/>
<button class="copy-to-clipboard" title="Robust and accurate simulations of flows over orography using non-conforming meshes" index=200>
  <span class="copy-to-clipboard-item">Copy Title<span>
</button>
<div class="toast toast-copied toast-index-200 align-items-center text-bg-secondary border-0 position-absolute top-0 end-0" role="alert" aria-live="assertive" aria-atomic="true">
  <div class="d-flex">
    <div class="toast-body">
      Copied!
    </div>
  </div>
</div>

---
Primary Category: physics.ao-ph  
Categories: cs-NA, math-NA, physics-ao-ph, physics-flu-dyn, physics.ao-ph  
Keyword Score: 20  
Keywords: Simulation, Simulator  
<a type="button" class="btn btn-outline-primary" href="http://arxiv.org/abs/2402.07759v1" target="_blank" >Paper Link</a>
<button type="button" class="btn btn-outline-primary download-pdf" url="https://arxiv.org/pdf/2402.07759v1.pdf" filename="2402.07759v1.pdf">Download PDF</button>

---


**ABSTRACT**  
We systematically validate the static local mesh refinement capabilities of a recently proposed IMEX-DG scheme implemented in the framework of the deal.II library. Non-conforming meshes are employed in atmospheric flow <b>simulations</b> to increase the resolution around complex orography. A number of numerical experiments based on classical benchmarks with idealized as well as real orography profiles demonstrate that <b>simulations</b> with the refined mesh are stable for long lead times and no spurious effects arise at the interfaces of mesh regions with different resolutions. Moreover, correct values of the momentum flux are retrieved and the correct large-scale orographic response is established. Hence, large-scale orography-driven flow features can be simulated without loss of accuracy using a much lower total amount of degrees of freedom. In a context of spatial resolutions approaching the hectometric scale in numerical weather prediction models, these results support the use of locally refined, non-conforming meshes as a reliable and effective tool to greatly reduce the dependence of atmospheric models on orographic wave drag parametrizations.

{{</citation>}}


## q-bio.QM (1)



### (201/210) Towards a Foundation Model for Brain Age Prediction using coVariance Neural Networks (Saurabh Sihag et al., 2024)

{{<citation>}}

Saurabh Sihag, Gonzalo Mateos, Alejandro Ribeiro. (2024)  
**Towards a Foundation Model for Brain Age Prediction using coVariance Neural Networks**
<br/>
<button class="copy-to-clipboard" title="Towards a Foundation Model for Brain Age Prediction using coVariance Neural Networks" index=201>
  <span class="copy-to-clipboard-item">Copy Title<span>
</button>
<div class="toast toast-copied toast-index-201 align-items-center text-bg-secondary border-0 position-absolute top-0 end-0" role="alert" aria-live="assertive" aria-atomic="true">
  <div class="d-flex">
    <div class="toast-body">
      Copied!
    </div>
  </div>
</div>

---
Primary Category: q-bio.QM  
Categories: cs-LG, q-bio-QM, q-bio.QM, stat-AP  
Keyword Score: 20  
Keywords: Fine-tuning, Foundation Model  
<a type="button" class="btn btn-outline-primary" href="http://arxiv.org/abs/2402.07684v1" target="_blank" >Paper Link</a>
<button type="button" class="btn btn-outline-primary download-pdf" url="https://arxiv.org/pdf/2402.07684v1.pdf" filename="2402.07684v1.pdf">Download PDF</button>

---


**ABSTRACT**  
Brain age is the estimate of biological age derived from neuroimaging datasets using machine learning algorithms. Increasing brain age with respect to chronological age can reflect increased vulnerability to neurodegeneration and cognitive decline. In this paper, we study NeuroVNN, based on coVariance neural networks, as a paradigm for <b>foundation</b> <b>model</b> for the brain age prediction application. NeuroVNN is pre-trained as a regression model on healthy population to predict chronological age using cortical thickness features and <b>fine-tuned</b> to estimate brain age in different neurological contexts. Importantly, NeuroVNN adds anatomical interpretability to brain age and has a `scale-free' characteristic that allows its transference to datasets curated according to any arbitrary brain atlas. Our results demonstrate that NeuroVNN can extract biologically plausible brain age estimates in different populations, as well as transfer successfully to datasets of dimensionalities distinct from that for the dataset used to train NeuroVNN.

{{</citation>}}


## cs.GT (1)



### (202/210) Rethinking Scaling Laws for Learning in Strategic Environments (Tinashe Handina et al., 2024)

{{<citation>}}

Tinashe Handina, Eric Mazumdar. (2024)  
**Rethinking Scaling Laws for Learning in Strategic Environments**
<br/>
<button class="copy-to-clipboard" title="Rethinking Scaling Laws for Learning in Strategic Environments" index=202>
  <span class="copy-to-clipboard-item">Copy Title<span>
</button>
<div class="toast toast-copied toast-index-202 align-items-center text-bg-secondary border-0 position-absolute top-0 end-0" role="alert" aria-live="assertive" aria-atomic="true">
  <div class="d-flex">
    <div class="toast-body">
      Copied!
    </div>
  </div>
</div>

---
Primary Category: cs.GT  
Categories: cs-GT, cs-LG, cs.GT, stat-ML  
Keyword Score: 20  
Keywords: Reinforcement Learning, Scaling Law  
<a type="button" class="btn btn-outline-primary" href="http://arxiv.org/abs/2402.07588v1" target="_blank" >Paper Link</a>
<button type="button" class="btn btn-outline-primary download-pdf" url="https://arxiv.org/pdf/2402.07588v1.pdf" filename="2402.07588v1.pdf">Download PDF</button>

---


**ABSTRACT**  
The deployment of ever-larger machine learning models reflects a growing consensus that the more expressive the model$\unicode{x2013}$and the more data one has access to$\unicode{x2013}$the more one can improve performance. As models get deployed in a variety of real world scenarios, they inevitably face strategic environments. In this work, we consider the natural question of how the interplay of models and strategic interactions affects <b>scaling</b> <b>laws.</b> We find that strategic interactions can break the conventional view of <b>scaling</b> <b>laws$\unicode{x2013}$meaning</b> that performance does not necessarily monotonically improve as models get larger and/ or more expressive (even with infinite data). We show the implications of this phenomenon in several contexts including strategic regression, strategic classification, and multi-agent <b>reinforcement</b> <b>learning</b> through examples of strategic environments in which$\unicode{x2013}$by simply restricting the expressivity of one's model or policy class$\unicode{x2013}$one can achieve strictly better equilibrium outcomes. Motivated by these examples, we then propose a new paradigm for model-selection in games wherein an agent seeks to choose amongst different model classes to use as their action set in a game.

{{</citation>}}


## astro-ph.IM (1)



### (203/210) Convolutional Neural Networks for signal detection in real LIGO data (Ondřej Zelenka et al., 2024)

{{<citation>}}

Ondřej Zelenka, Bernd Brügmann, Frank Ohme. (2024)  
**Convolutional Neural Networks for signal detection in real LIGO data**
<br/>
<button class="copy-to-clipboard" title="Convolutional Neural Networks for signal detection in real LIGO data" index=203>
  <span class="copy-to-clipboard-item">Copy Title<span>
</button>
<div class="toast toast-copied toast-index-203 align-items-center text-bg-secondary border-0 position-absolute top-0 end-0" role="alert" aria-live="assertive" aria-atomic="true">
  <div class="d-flex">
    <div class="toast-body">
      Copied!
    </div>
  </div>
</div>

---
Primary Category: astro-ph.IM  
Categories: astro-ph-IM, astro-ph.IM, cs-LG, gr-qc  
Keyword Score: 20  
Keywords: Convolution, Convolutional Neural Network  
<a type="button" class="btn btn-outline-primary" href="http://arxiv.org/abs/2402.07492v1" target="_blank" >Paper Link</a>
<button type="button" class="btn btn-outline-primary download-pdf" url="https://arxiv.org/pdf/2402.07492v1.pdf" filename="2402.07492v1.pdf">Download PDF</button>

---


**ABSTRACT**  
Searching the data of gravitational-wave detectors for signals from compact binary mergers is a computationally demanding task. Recently, machine learning algorithms have been proposed to address current and future challenges. However, the results of these publications often differ greatly due to differing choices in the evaluation procedure. The Machine Learning Gravitational-Wave Search Challenge was organized to resolve these issues and produce a unified framework for machine-learning search evaluation. Six teams submitted contributions, four of which are based on machine learning methods and two are state-of-the-art production analyses. This paper describes the submission from the team TPI FSU Jena and its updated variant. We also apply our algorithm to real O3b data and recover the relevant events of the GWTC-3 catalog.

{{</citation>}}


## cs.DC (3)



### (204/210) From Data to Decisions: The Transformational Power of Machine Learning in Business Recommendations (Kapilya Gangadharan et al., 2024)

{{<citation>}}

Kapilya Gangadharan, K. Malathi, Anoop Purandaran, Barathi Subramanian, Rathinaraja Jeyaraj. (2024)  
**From Data to Decisions: The Transformational Power of Machine Learning in Business Recommendations**
<br/>
<button class="copy-to-clipboard" title="From Data to Decisions: The Transformational Power of Machine Learning in Business Recommendations" index=204>
  <span class="copy-to-clipboard-item">Copy Title<span>
</button>
<div class="toast toast-copied toast-index-204 align-items-center text-bg-secondary border-0 position-absolute top-0 end-0" role="alert" aria-live="assertive" aria-atomic="true">
  <div class="d-flex">
    <div class="toast-body">
      Copied!
    </div>
  </div>
</div>

---
Primary Category: cs.DC  
Categories: cs-DC, cs-IR, cs-LG, cs.DC  
Keyword Score: 10  
Keywords: Recommendation  
<a type="button" class="btn btn-outline-primary" href="http://arxiv.org/abs/2402.08109v1" target="_blank" >Paper Link</a>
<button type="button" class="btn btn-outline-primary download-pdf" url="https://arxiv.org/pdf/2402.08109v1.pdf" filename="2402.08109v1.pdf">Download PDF</button>

---


**ABSTRACT**  
This research aims to explore the impact of Machine Learning (ML) on the evolution and efficacy of <b>Recommendation</b> Systems (RS), particularly in the context of their growing significance in commercial business environments. Methodologically, the study delves into the role of ML in crafting and refining these systems, focusing on aspects such as data sourcing, feature engineering, and the importance of evaluation metrics, thereby highlighting the iterative nature of enhancing <b>recommendation</b> algorithms. The deployment of <b>Recommendation</b> Engines (RE), driven by advanced algorithms and data analytics, is explored across various domains, showcasing their significant impact on user experience and decision-making processes. These engines not only streamline information discovery and enhance collaboration but also accelerate knowledge acquisition, proving vital in navigating the digital landscape for businesses. They contribute significantly to sales, revenue, and the competitive edge of enterprises by offering improved <b>recommendations</b> that align with individual customer needs. The research identifies the increasing expectation of users for a seamless, intuitive online experience, where content is personalized and dynamically adapted to changing preferences. Future research directions include exploring advancements in deep learning models, ethical considerations in the deployment of RS, and addressing scalability challenges. This study emphasizes the indispensability of comprehending and leveraging ML in RS for researchers and practitioners, to tap into the full potential of personalized <b>recommendation</b> in commercial business prospects.

{{</citation>}}


### (205/210) LFOC: A Lightweight Fairness-Oriented Cache Clustering Policy for Commodity Multicores (Adrián García-García et al., 2024)

{{<citation>}}

Adrián García-García, Juan Carlos Sáez, Fernando Castro, Manuel Prieto-Matías. (2024)  
**LFOC: A Lightweight Fairness-Oriented Cache Clustering Policy for Commodity Multicores**
<br/>
<button class="copy-to-clipboard" title="LFOC: A Lightweight Fairness-Oriented Cache Clustering Policy for Commodity Multicores" index=205>
  <span class="copy-to-clipboard-item">Copy Title<span>
</button>
<div class="toast toast-copied toast-index-205 align-items-center text-bg-secondary border-0 position-absolute top-0 end-0" role="alert" aria-live="assertive" aria-atomic="true">
  <div class="d-flex">
    <div class="toast-body">
      Copied!
    </div>
  </div>
</div>

---
Primary Category: cs.DC  
Categories: cs-AR, cs-DC, cs.DC  
Keyword Score: 10  
Keywords: Fairness  
<a type="button" class="btn btn-outline-primary" href="http://arxiv.org/abs/2402.07578v1" target="_blank" >Paper Link</a>
<button type="button" class="btn btn-outline-primary download-pdf" url="https://arxiv.org/pdf/2402.07578v1.pdf" filename="2402.07578v1.pdf">Download PDF</button>

---


**ABSTRACT**  
Multicore processors constitute the main architecture choice for modern computing systems in different market segments. Despite their benefits, the contention that naturally appears when multiple applications compete for the use of shared resources among cores, such as the last-level cache (LLC), may lead to substantial performance degradation. This may have a negative impact on key system aspects such as throughput and <b>fairness.</b> Assigning the various applications in the workload to separate LLC partitions with possibly different sizes, has been proven effective to mitigate shared-resource contention effects. In this article we propose LFOC, a clustering-based cache partitioning scheme that strives to deliver <b>fairness</b> while providing acceptable system throughput. LFOC leverages the Intel Cache Allocation Technology (CAT), which enables the system software to divide the LLC into different partitions. To accomplish its goals, LFOC tries to mimic the behavior of the optimal cache-clustering solution, which we could approximate by means of a simulator in different scenarios. To this end, LFOC effectively identifies streaming aggressor programs and cache sensitive applications, which are then assigned to separate cache partitions. We implemented LFOC in the Linux kernel and evaluated it on a real system featuring an Intel Skylake processor, where we compare its effectiveness to that of two state-of-the-art policies that optimize <b>fairness</b> and throughput, respectively. Our experimental analysis reveals that LFOC is able to bring a higher reduction in unfairness by leveraging a lightweight algorithm suitable for adoption in a real OS.

{{</citation>}}


### (206/210) Accelerating Distributed Deep Learning using Lossless Homomorphic Compression (Haoyu Li et al., 2024)

{{<citation>}}

Haoyu Li, Yuchen Xu, Jiayi Chen, Rohit Dwivedula, Wenfei Wu, Keqiang He, Aditya Akella, Daehyeok Kim. (2024)  
**Accelerating Distributed Deep Learning using Lossless Homomorphic Compression**
<br/>
<button class="copy-to-clipboard" title="Accelerating Distributed Deep Learning using Lossless Homomorphic Compression" index=206>
  <span class="copy-to-clipboard-item">Copy Title<span>
</button>
<div class="toast toast-copied toast-index-206 align-items-center text-bg-secondary border-0 position-absolute top-0 end-0" role="alert" aria-live="assertive" aria-atomic="true">
  <div class="d-flex">
    <div class="toast-body">
      Copied!
    </div>
  </div>
</div>

---
Primary Category: cs.DC  
Categories: cs-DC, cs-DS, cs-LG, cs-NI, cs.DC  
Keyword Score: 10  
Keywords: BERT  
<a type="button" class="btn btn-outline-primary" href="http://arxiv.org/abs/2402.07529v1" target="_blank" >Paper Link</a>
<button type="button" class="btn btn-outline-primary download-pdf" url="https://arxiv.org/pdf/2402.07529v1.pdf" filename="2402.07529v1.pdf">Download PDF</button>

---


**ABSTRACT**  
As deep neural networks (DNNs) grow in complexity and size, the resultant increase in communication overhead during distributed training has become a significant bottleneck, challenging the scalability of distributed training systems. Existing solutions, while aiming to mitigate this bottleneck through worker-level compression and in-network aggregation, fall short due to their inability to efficiently reconcile the trade-offs between compression effectiveness and computational overhead, hindering overall performance and scalability. In this paper, we introduce a novel compression algorithm that effectively merges worker-level compression with in-network aggregation. Our solution is both homomorphic, allowing for efficient in-network aggregation without CPU/GPU processing, and lossless, ensuring no compromise on training accuracy. Theoretically optimal in compression and computational efficiency, our approach is empirically validated across diverse DNN models such as NCF, LSTM, VGG19, and <b>BERT-base,</b> showing up to a 6.33$\times$ improvement in aggregation throughput and a 3.74$\times$ increase in per-iteration training speed.

{{</citation>}}


## hep-ph (1)



### (207/210) Improvement and generalization of ABCD method with Bayesian inference (Ezequiel Alvarez et al., 2024)

{{<citation>}}

Ezequiel Alvarez, Leandro Da Rold, Manuel Szewc, Alejandro Szynkman, Santiago A. Tanco, Tatiana Tarutina. (2024)  
**Improvement and generalization of ABCD method with Bayesian inference**
<br/>
<button class="copy-to-clipboard" title="Improvement and generalization of ABCD method with Bayesian inference" index=207>
  <span class="copy-to-clipboard-item">Copy Title<span>
</button>
<div class="toast toast-copied toast-index-207 align-items-center text-bg-secondary border-0 position-absolute top-0 end-0" role="alert" aria-live="assertive" aria-atomic="true">
  <div class="d-flex">
    <div class="toast-body">
      Copied!
    </div>
  </div>
</div>

---
Primary Category: hep-ph  
Categories: cs-LG, hep-ex, hep-ph, hep-ph  
Keyword Score: 10  
Keywords: Mutual Information  
<a type="button" class="btn btn-outline-primary" href="http://arxiv.org/abs/2402.08001v1" target="_blank" >Paper Link</a>
<button type="button" class="btn btn-outline-primary download-pdf" url="https://arxiv.org/pdf/2402.08001v1.pdf" filename="2402.08001v1.pdf">Download PDF</button>

---


**ABSTRACT**  
To find New Physics or to refine our knowledge of the Standard Model at the LHC is an enterprise that involves many factors. We focus on taking advantage of available information and pour our effort in re-thinking the usual data-driven ABCD method to improve it and to generalize it using Bayesian Machine Learning tools. We propose that a dataset consisting of a signal and many backgrounds is well described through a mixture model. Signal, backgrounds and their relative fractions in the sample can be well extracted by exploiting the prior knowledge and the dependence between the different observables at the event-by-event level with Bayesian tools. We show how, in contrast to the ABCD method, one can take advantage of understanding some properties of the different backgrounds and of having more than two independent observables to measure in each event. In addition, instead of regions defined through hard cuts, the Bayesian framework uses the information of continuous distribution to obtain soft-assignments of the events which are statistically more robust. To compare both methods we use a toy problem inspired by $pp\to hh\to b\bar b b \bar b$, selecting a reduced and simplified number of processes and analysing the flavor of the four jets and the invariant mass of the jet-pairs, modeled with simplified distributions. Taking advantage of all this information, and starting from a combination of biased and agnostic priors, leads us to a very good posterior once we use the Bayesian framework to exploit the data and the <b>mutual</b> <b>information</b> of the observables at the event-by-event level. We show how, in this simplified model, the Bayesian framework outperforms the ABCD method sensitivity in obtaining the signal fraction in scenarios with $1\%$ and $0.5\%$ true signal fractions in the dataset. We also show that the method is robust against the absence of signal.

{{</citation>}}


## cs.IT (1)



### (208/210) A Lattice-Reduction Aided Vector Perturbation Precoder Relying on Quantum Annealing (Samuel Winter et al., 2024)

{{<citation>}}

Samuel Winter, Yangyishi Zhang, Gan Zheng, Lajos Hanzo. (2024)  
**A Lattice-Reduction Aided Vector Perturbation Precoder Relying on Quantum Annealing**
<br/>
<button class="copy-to-clipboard" title="A Lattice-Reduction Aided Vector Perturbation Precoder Relying on Quantum Annealing" index=208>
  <span class="copy-to-clipboard-item">Copy Title<span>
</button>
<div class="toast toast-copied toast-index-208 align-items-center text-bg-secondary border-0 position-absolute top-0 end-0" role="alert" aria-live="assertive" aria-atomic="true">
  <div class="d-flex">
    <div class="toast-body">
      Copied!
    </div>
  </div>
</div>

---
Primary Category: cs.IT  
Categories: cs-IT, cs.IT, math-IT  
Keyword Score: 10  
Keywords: Question Answering  
<a type="button" class="btn btn-outline-primary" href="http://arxiv.org/abs/2402.07643v1" target="_blank" >Paper Link</a>
<button type="button" class="btn btn-outline-primary download-pdf" url="https://arxiv.org/pdf/2402.07643v1.pdf" filename="2402.07643v1.pdf">Download PDF</button>

---


**ABSTRACT**  
Quantum annealing <b>(QA)</b> is proposed for vector perturbation precoding (VPP) in multiple input multiple output (MIMO) communications systems. The mathematical framework of VPP is presented, outlining the problem formulation and the benefits of lattice reduction algorithms. Lattice reduction aided quantum vector perturbation (LRAQVP) is designed by harnessing physical quantum hardware, and the optimization of hardware parameters is discussed. We observe a 5dB gain over lattice reduction zero forcing precoding (LRZFP), which behaves similarly to a quantum annealing algorithm operating without a lattice reduction stage. The proposed algorithm is also shown to approach the performance of a sphere encoder, which exhibits an exponentially escalating complexity.

{{</citation>}}


## physics.comp-ph (1)



### (209/210) Cartesian atomic cluster expansion for machine learning interatomic potentials (Bingqing Cheng, 2024)

{{<citation>}}

Bingqing Cheng. (2024)  
**Cartesian atomic cluster expansion for machine learning interatomic potentials**
<br/>
<button class="copy-to-clipboard" title="Cartesian atomic cluster expansion for machine learning interatomic potentials" index=209>
  <span class="copy-to-clipboard-item">Copy Title<span>
</button>
<div class="toast toast-copied toast-index-209 align-items-center text-bg-secondary border-0 position-absolute top-0 end-0" role="alert" aria-live="assertive" aria-atomic="true">
  <div class="d-flex">
    <div class="toast-body">
      Copied!
    </div>
  </div>
</div>

---
Primary Category: physics.comp-ph  
Categories: cs-LG, physics-chem-ph, physics-comp-ph, physics.comp-ph  
Keyword Score: 10  
Keywords: Message-Passing  
<a type="button" class="btn btn-outline-primary" href="http://arxiv.org/abs/2402.07472v1" target="_blank" >Paper Link</a>
<button type="button" class="btn btn-outline-primary download-pdf" url="https://arxiv.org/pdf/2402.07472v1.pdf" filename="2402.07472v1.pdf">Download PDF</button>

---


**ABSTRACT**  
Machine learning interatomic potentials are revolutionizing large-scale, accurate atomistic modelling in material science and chemistry. These potentials often use atomic cluster expansion or equivariant message passing with spherical harmonics as basis functions. However, the dependence on Clebsch-Gordan coefficients for maintaining rotational symmetry leads to computational inefficiencies and redundancies. We propose an alternative: a Cartesian-coordinates-based atomic density expansion. This approach provides a complete description of atomic environments while maintaining interaction body orders. Additionally, we integrate low-dimensional embeddings of various chemical elements and inter-atomic message passing. The resulting potential, named Cartesian Atomic Cluster Expansion (CACE), exhibits good accuracy, stability, and generalizability. We validate its performance in diverse systems, including bulk water, small molecules, and 25-element high-entropy alloys.

{{</citation>}}


## math.ST (1)



### (210/210) The Limits of Assumption-free Tests for Algorithm Performance (Yuetian Luo et al., 2024)

{{<citation>}}

Yuetian Luo, Rina Foygel Barber. (2024)  
**The Limits of Assumption-free Tests for Algorithm Performance**
<br/>
<button class="copy-to-clipboard" title="The Limits of Assumption-free Tests for Algorithm Performance" index=210>
  <span class="copy-to-clipboard-item">Copy Title<span>
</button>
<div class="toast toast-copied toast-index-210 align-items-center text-bg-secondary border-0 position-absolute top-0 end-0" role="alert" aria-live="assertive" aria-atomic="true">
  <div class="d-flex">
    <div class="toast-body">
      Copied!
    </div>
  </div>
</div>

---
Primary Category: math.ST  
Categories: cs-LG, math-ST, math.ST, stat-ML, stat-TH  
Keyword Score: 3  
Keywords: Sample Size  
<a type="button" class="btn btn-outline-primary" href="http://arxiv.org/abs/2402.07388v1" target="_blank" >Paper Link</a>
<button type="button" class="btn btn-outline-primary download-pdf" url="https://arxiv.org/pdf/2402.07388v1.pdf" filename="2402.07388v1.pdf">Download PDF</button>

---


**ABSTRACT**  
Algorithm evaluation and comparison are fundamental questions in machine learning and statistics -- how well does an algorithm perform at a given modeling task, and which algorithm performs best? Many methods have been developed to assess algorithm performance, often based around cross-validation type strategies, retraining the algorithm of interest on different subsets of the data and assessing its performance on the held-out data points. Despite the broad use of such procedures, the theoretical properties of these methods are not yet fully understood. In this work, we explore some fundamental limits for answering these questions with limited amounts of data. In particular, we make a distinction between two questions: how good is an algorithm $A$ at the problem of learning from a training set of size $n$, versus, how good is a particular fitted model produced by running $A$ on a particular training data set of size $n$? Our main results prove that, for any test that treats the algorithm $A$ as a ``black box'' (i.e., we can only study the behavior of $A$ empirically), there is a fundamental limit on our ability to carry out inference on the performance of $A$, unless the number of available data points $N$ is many times larger than the <b>sample</b> <b>size</b> $n$ of interest. (On the other hand, evaluating the performance of a particular fitted model is easy as long as a holdout data set is available -- that is, as long as $N-n$ is not too small.) We also ask whether an assumption of algorithmic stability might be sufficient to circumvent this hardness result. Surprisingly, we find that this is not the case: the same hardness result still holds for the problem of evaluating the performance of $A$, aside from a high-stability regime where fitted models are essentially nonrandom. Finally, we also establish similar hardness results for the problem of comparing multiple algorithms.

{{</citation>}}
