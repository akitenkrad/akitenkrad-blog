---
draft: false
title: "arXiv @ 2024.01.30"
date: 2024-01-30
author: "akitenkrad"
description: ""
tags: ["arXiv", "Published:2024"]
menu:
  sidebar:
    name: "arXiv @ 2024.01.30"
    identifier: arxiv_20240130
    parent: 202401_arxiv
    weight: 10
math: true
---

<figure style="border:none; width:100%; display:flex; justify-content: center">
    <iframe src="pie.html" width=900 height=620 style="border:none"></iframe>
</figure>


## Primary Categories

- [cs.CL (12)](#cscl-12)
- [cs.NI (1)](#csni-1)
- [cs.RO (1)](#csro-1)
- [cs.LG (6)](#cslg-6)
- [cs.CV (12)](#cscv-12)
- [eess.SP (1)](#eesssp-1)
- [cs.AR (1)](#csar-1)
- [cs.IR (3)](#csir-3)
- [cs.CE (3)](#csce-3)
- [cs.HC (4)](#cshc-4)
- [stat.CO (1)](#statco-1)
- [astro-ph.HE (1)](#astro-phhe-1)
- [cs.CR (1)](#cscr-1)
- [cs.AI (1)](#csai-1)
- [cs.SE (1)](#csse-1)
- [cs.DC (1)](#csdc-1)

## cs.CL (12)



### (1/50) UnMASKed: Quantifying Gender Biases in Masked Language Models through Linguistically Informed Job Market Prompts (Iñigo Parra, 2024)

{{<citation>}}

Iñigo Parra. (2024)  
**UnMASKed: Quantifying Gender Biases in Masked Language Models through Linguistically Informed Job Market Prompts**  

---
Primary Category: cs.CL  
Categories: cs-CL, cs.CL  
Keywords: BERT, Bias, Language Model  
[Paper Link](http://arxiv.org/abs/2401.15798v1)  

---


**ABSTRACT**  
Language models (LMs) have become pivotal in the realm of technological advancements. While their capabilities are vast and transformative, they often include societal biases encoded in the human-produced datasets used for their training. This research delves into the inherent biases present in masked language models (MLMs), with a specific focus on gender biases. This study evaluated six prominent models: BERT, RoBERTa, DistilBERT, BERT-multilingual, XLM-RoBERTa, and DistilBERT-multilingual. The methodology employed a novel dataset, bifurcated into two subsets: one containing prompts that encouraged models to generate subject pronouns in English, and the other requiring models to return the probabilities of verbs, adverbs, and adjectives linked to the prompts' gender pronouns. The analysis reveals stereotypical gender alignment of all models, with multilingual variants showing comparatively reduced biases.

{{</citation>}}


### (2/50) Fine-Tuned Large Language Models for Symptom Recognition from Spanish Clinical Text (Mai A. Shaaban et al., 2024)

{{<citation>}}

Mai A. Shaaban, Abbas Akkasi, Adnan Khan, Majid Komeili, Mohammad Yaqub. (2024)  
**Fine-Tuned Large Language Models for Symptom Recognition from Spanish Clinical Text**  

---
Primary Category: cs.CL  
Categories: cs-CL, cs-LG, cs.CL  
Keywords: Clinical, Language Model  
[Paper Link](http://arxiv.org/abs/2401.15780v1)  

---


**ABSTRACT**  
The accurate recognition of symptoms in clinical reports is significantly important in the fields of healthcare and biomedical natural language processing. These entities serve as essential building blocks for clinical information extraction, enabling retrieval of critical medical insights from vast amounts of textual data. Furthermore, the ability to identify and categorize these entities is fundamental for developing advanced clinical decision support systems, aiding healthcare professionals in diagnosis and treatment planning. In this study, we participated in SympTEMIST, a shared task on the detection of symptoms, signs and findings in Spanish medical documents. We combine a set of large language models fine-tuned with the data released by the organizers.

{{</citation>}}


### (3/50) PILOT: Legal Case Outcome Prediction with Case Law (Lang Cao et al., 2024)

{{<citation>}}

Lang Cao, Zifeng Wang, Cao Xiao, Jimeng Sun. (2024)  
**PILOT: Legal Case Outcome Prediction with Case Law**  

---
Primary Category: cs.CL  
Categories: cs-CL, cs.CL  
Keywords: Legal  
[Paper Link](http://arxiv.org/abs/2401.15770v1)  

---


**ABSTRACT**  
Machine learning shows promise in predicting the outcome of legal cases, but most research has concentrated on civil law cases rather than case law systems. We identified two unique challenges in making legal case outcome predictions with case law. First, it is crucial to identify relevant precedent cases that serve as fundamental evidence for judges during decision-making. Second, it is necessary to consider the evolution of legal principles over time, as early cases may adhere to different legal contexts.   In this paper, we proposed a new model named PILOT (PredictIng Legal case OuTcome) for case outcome prediction. It comprises two modules for relevant case retrieval and temporal pattern handling, respectively. To benchmark the performance of existing legal case outcome prediction models, we curated a dataset from a large-scale case law database. We demonstrate the importance of accurately identifying precedent cases and mitigating the temporal shift when making predictions for case law, as our method shows a significant improvement over the prior methods that focus on civil law case outcome predictions.

{{</citation>}}


### (4/50) RE-GAINS & EnCHANT: Intelligent Tool Manipulation Systems For Enhanced Query Responses (Sahil Girhepuje et al., 2024)

{{<citation>}}

Sahil Girhepuje, Siva Sankar Sajeev, Purvam Jain, Arya Sikder, Adithya Rama Varma, Ryan George, Akshay Govind Srinivasan, Mahendra Kurup, Ashmit Sinha, Sudip Mondal. (2024)  
**RE-GAINS & EnCHANT: Intelligent Tool Manipulation Systems For Enhanced Query Responses**  

---
Primary Category: cs.CL  
Categories: cs-CL, cs.CL  
Keywords: AI  
[Paper Link](http://arxiv.org/abs/2401.15724v1)  

---


**ABSTRACT**  
Despite the remarkable success of LLMs, they still suffer from tool invocation and tool chaining due to inadequate input queries and/or tool argument descriptions. We propose two novel frameworks, RE-GAINS and EnCHANT, enabling LLMs to tackle tool manipulation for solving complex user queries by making API calls. EnCHANT is an open-source solution that makes use of an LLM format enforcer, an LLM(OpenChat 3.5) and a retriever(ToolBench's API Retriever). RE-GAINS is based on OpenAI models and embeddings using a special prompt based on the RAP paper. Both solutions cost less than $0.01 per query with minimal latency, therefore showcasing the usefulness of the frameworks.

{{</citation>}}


### (5/50) Check News in One Click: NLP-Empowered Pro-Kremlin Propaganda Detection (Veronika Solopova et al., 2024)

{{<citation>}}

Veronika Solopova, Viktoriia Herman, Christoph Benzmüller, Tim Landgraf. (2024)  
**Check News in One Click: NLP-Empowered Pro-Kremlin Propaganda Detection**  

---
Primary Category: cs.CL  
Categories: cs-CL, cs.CL  
Keywords: NLP  
[Paper Link](http://arxiv.org/abs/2401.15717v1)  

---


**ABSTRACT**  
Many European citizens become targets of the Kremlin propaganda campaigns, aiming to minimise public support for Ukraine, foster a climate of mistrust and disunity, and shape elections (Meister, 2022). To address this challenge, we developed ''Check News in 1 Click'', the first NLP-empowered pro-Kremlin propaganda detection application available in 7 languages, which provides the lay user with feedback on their news, and explains manipulative linguistic features and keywords. We conducted a user study, analysed user entries and models' behaviour paired with questionnaire answers, and investigated the advantages and disadvantages of the proposed interpretative solution.

{{</citation>}}


### (6/50) YODA: Teacher-Student Progressive Learning for Language Models (Jianqiao Lu et al., 2024)

{{<citation>}}

Jianqiao Lu, Wanjun Zhong, Yufei Wang, Zhijiang Guo, Qi Zhu, Wenyong Huang, Yanlin Wang, Fei Mi, Baojun Wang, Yasheng Wang, Lifeng Shang, Xin Jiang, Qun Liu. (2024)  
**YODA: Teacher-Student Progressive Learning for Language Models**  

---
Primary Category: cs.CL  
Categories: cs-AI, cs-CL, cs-LG, cs.CL  
Keywords: LLaMA, Language Model  
[Paper Link](http://arxiv.org/abs/2401.15670v1)  

---


**ABSTRACT**  
Although large language models (LLMs) have demonstrated adeptness in a range of tasks, they still lag behind human learning efficiency. This disparity is often linked to the inherent human capacity to learn from basic examples, gradually generalize and handle more complex problems, and refine their skills with continuous feedback. Inspired by this, this paper introduces YODA, a novel teacher-student progressive learning framework that emulates the teacher-student education process to improve the efficacy of model fine-tuning. The framework operates on an interactive \textit{basic-generalized-harder} loop. The teacher agent provides tailored feedback on the student's answers, and systematically organizes the education process. This process unfolds by teaching the student basic examples, reinforcing understanding through generalized questions, and then enhancing learning by posing questions with progressively enhanced complexity. With the teacher's guidance, the student learns to iteratively refine its answer with feedback, and forms a robust and comprehensive understanding of the posed questions. The systematic procedural data, which reflects the progressive learning process of humans, is then utilized for model training. Taking math reasoning as a testbed, experiments show that training LLaMA2 with data from YODA improves SFT with significant performance gain (+17.01\% on GSM8K and +9.98\% on MATH). In addition, we find that training with curriculum learning further improves learning robustness.

{{</citation>}}


### (7/50) LLsM: Generative Linguistic Steganography with Large Language Model (Yihao Wang et al., 2024)

{{<citation>}}

Yihao Wang, Ruiqi Song, Ru Zhang, Jianyi Liu, Lingxiao Li. (2024)  
**LLsM: Generative Linguistic Steganography with Large Language Model**  

---
Primary Category: cs.CL  
Categories: cs-CL, cs.CL  
Keywords: LLaMA, Language Model  
[Paper Link](http://arxiv.org/abs/2401.15656v1)  

---


**ABSTRACT**  
Linguistic Steganography (LS) tasks aim to generate steganographic texts (stego) based on secret information. Only authorized recipients can perceive the existence of secret information in the texts and accurately extract it, thereby preserving privacy. However, the controllability of the stego generated by existing schemes is poor, and the generated stego is difficult to contain specific discourse characteristics such as style, genre, and theme. As a result, the stego are often easily detectable, compromising covert communication. To address these problems, this paper proposes a novel scheme named LLsM, a generative LS based on a Large Language Model (LLM). We fine-tuned the LLM LLaMA2 with a large-scale constructed dataset encompassing rich discourse characteristics, which enables the fine-tuned LLM to generate texts with specific discourse in a controllable manner. Then the discourse characteristics are used as guiding information and inputted into the fine-tuned LLM in the form of Prompt together with secret information. The candidate pool, derived from sampling and truncation, undergoes range encoding to ensure the stego imitate natural text distribution. Experiments demonstrate that LLsM performs superior to prevalent baselines regarding text quality, statistical analysis, discourse matching, and anti-steganalysis. In particular, LLsM's MAUVE surpasses that of some baselines by 70%-80%, and its anti-steganalysis performance is 30%-40% higher. Notably, we also present the long stego generated by LLsM, showing its potential superiority in long LS tasks.

{{</citation>}}


### (8/50) TA&AT: Enhancing Task-Oriented Dialog with Turn-Level Auxiliary Tasks and Action-Tree Based Scheduled Sampling (Longxiang Liu et al., 2024)

{{<citation>}}

Longxiang Liu, Xiuxing Li, Yang Feng. (2024)  
**TA&AT: Enhancing Task-Oriented Dialog with Turn-Level Auxiliary Tasks and Action-Tree Based Scheduled Sampling**  

---
Primary Category: cs.CL  
Categories: cs-AI, cs-CL, cs.CL  
Keywords: Dialog  
[Paper Link](http://arxiv.org/abs/2401.15626v1)  

---


**ABSTRACT**  
Task-oriented dialog systems have witnessed substantial progress due to conversational pre-training techniques. Yet, two significant challenges persist. First, most systems primarily utilize the latest turn's state label for the generator. This practice overlooks the comprehensive value of state labels in boosting the model's understanding for future generations. Second, an overreliance on generated policy often leads to error accumulation, resulting in suboptimal responses when adhering to incorrect actions. To combat these challenges, we propose turn-level multi-task objectives for the encoder. With the guidance of essential information from labeled intermediate states, we establish a more robust representation for both understanding and generation. For the decoder, we introduce an action tree-based scheduled sampling technique. Specifically, we model the hierarchical policy as trees and utilize the similarity between trees to sample negative policy based on scheduled sampling, hoping the model to generate invariant responses under perturbations. This method simulates potential pitfalls by sampling similar negative policy, bridging the gap between task-oriented dialog training and inference. Among methods without continual pre-training, our approach achieved state-of-the-art (SOTA) performance on the MultiWOZ dataset series and was also competitive with pre-trained SOTA methods.

{{</citation>}}


### (9/50) Evaluating Gender Bias in Large Language Models via Chain-of-Thought Prompting (Masahiro Kaneko et al., 2024)

{{<citation>}}

Masahiro Kaneko, Danushka Bollegala, Naoaki Okazaki, Timothy Baldwin. (2024)  
**Evaluating Gender Bias in Large Language Models via Chain-of-Thought Prompting**  

---
Primary Category: cs.CL  
Categories: cs-CL, cs.CL  
Keywords: Bias, Language Model  
[Paper Link](http://arxiv.org/abs/2401.15585v1)  

---


**ABSTRACT**  
There exist both scalable tasks, like reading comprehension and fact-checking, where model performance improves with model size, and unscalable tasks, like arithmetic reasoning and symbolic reasoning, where model performance does not necessarily improve with model size. Large language models (LLMs) equipped with Chain-of-Thought (CoT) prompting are able to make accurate incremental predictions even on unscalable tasks. Unfortunately, despite their exceptional reasoning abilities, LLMs tend to internalize and reproduce discriminatory societal biases. Whether CoT can provide discriminatory or egalitarian rationalizations for the implicit information in unscalable tasks remains an open question.   In this study, we examine the impact of LLMs' step-by-step predictions on gender bias in unscalable tasks. For this purpose, we construct a benchmark for an unscalable task where the LLM is given a list of words comprising feminine, masculine, and gendered occupational words, and is required to count the number of feminine and masculine words. In our CoT prompts, we require the LLM to explicitly indicate whether each word in the word list is a feminine or masculine before making the final predictions. With counting and handling the meaning of words, this benchmark has characteristics of both arithmetic reasoning and symbolic reasoning. Experimental results in English show that without step-by-step prediction, most LLMs make socially biased predictions, despite the task being as simple as counting words. Interestingly, CoT prompting reduces this unconscious social bias in LLMs and encourages fair predictions.

{{</citation>}}


### (10/50) Efficient Tuning and Inference for Large Language Models on Textual Graphs (Yun Zhu et al., 2024)

{{<citation>}}

Yun Zhu, Yaoke Wang, Haizhou Shi, Siliang Tang. (2024)  
**Efficient Tuning and Inference for Large Language Models on Textual Graphs**  

---
Primary Category: cs.CL  
Categories: cs-CL, cs.CL  
Keywords: GNN, Language Model  
[Paper Link](http://arxiv.org/abs/2401.15569v1)  

---


**ABSTRACT**  
Rich textual and topological information of textual graphs need to be modeled in real-world applications such as webpages, e-commerce, and academic articles. Practitioners have been long following the path of adopting a shallow text encoder and a subsequent graph neural network (GNN) to solve this problem. In light of recent advancements in large language models (LLMs), it is apparent that integrating LLMs for enhanced textual encoding can substantially improve the performance of textual graphs. Nevertheless, the efficiency of these methods poses a significant challenge. In this paper, we propose ENGINE, a parameter- and memory-efficient fine-tuning method for textual graphs with an LLM encoder. The key insight is to combine the LLMs and GNNs through a tunable side structure, which significantly reduces the training complexity without impairing the joint model's capacity. Extensive experiments on textual graphs demonstrate our method's effectiveness by achieving the best model performance, meanwhile having the lowest training cost compared to previous methods. Moreover, we introduce two variants with caching and dynamic early exit to further enhance training and inference speed. Specifically, caching accelerates ENGINE's training by 12x, and dynamic early exit achieves up to 5x faster inference with a negligible performance drop (at maximum 1.17% relevant drop across 7 datasets).

{{</citation>}}


### (11/50) Augment before You Try: Knowledge-Enhanced Table Question Answering via Table Expansion (Yujian Liu et al., 2024)

{{<citation>}}

Yujian Liu, Jiabao Ji, Tong Yu, Ryan Rossi, Sungchul Kim, Handong Zhao, Ritwik Sinha, Yang Zhang, Shiyu Chang. (2024)  
**Augment before You Try: Knowledge-Enhanced Table Question Answering via Table Expansion**  

---
Primary Category: cs.CL  
Categories: cs-CL, cs.CL  
Keywords: NLP, QA, Question Answering  
[Paper Link](http://arxiv.org/abs/2401.15555v1)  

---


**ABSTRACT**  
Table question answering is a popular task that assesses a model's ability to understand and interact with structured data. However, the given table often does not contain sufficient information for answering the question, necessitating the integration of external knowledge. Existing methods either convert both the table and external knowledge into text, which neglects the structured nature of the table; or they embed queries for external sources in the interaction with the table, which complicates the process. In this paper, we propose a simple yet effective method to integrate external information in a given table. Our method first constructs an augmenting table containing the missing information and then generates a SQL query over the two tables to answer the question. Experiments show that our method outperforms strong baselines on three table QA benchmarks. Our code is publicly available at https://github.com/UCSB-NLP-Chang/Augment_tableQA.

{{</citation>}}


### (12/50) Byte Pair Encoding Is All You Need For Automatic Bengali Speech Recognition (Ahnaf Mozib Samin, 2024)

{{<citation>}}

Ahnaf Mozib Samin. (2024)  
**Byte Pair Encoding Is All You Need For Automatic Bengali Speech Recognition**  

---
Primary Category: cs.CL  
Categories: cs-CL, cs-SD, cs.CL, eess-AS  
Keywords: Speech Recognition  
[Paper Link](http://arxiv.org/abs/2401.15532v1)  

---


**ABSTRACT**  
Byte pair encoding (BPE) emerges as an effective tokenization method for tackling the out-of-vocabulary (OOV) challenge in various natural language and speech processing tasks. Recent research highlights the dependency of BPE subword tokenization's efficacy on the morphological nature of the language, particularly in languages rich in inflectional morphology, where fewer BPE merges suffice for generating highly productive tokens. Motivated by this, our study empirically identifies the optimal number of BPE tokens for Bengali, a language known for its morphological complexity, thus enhancing out-of-distribution automatic speech recognition (ASR) performance. Experimental evaluation reveals that an excessively high number of BPE tokens can lead to overfitting, while approximately 500-1000 tokens result in superior OOV performance. Furthermore, we conduct a comparative analysis of BPE with character-based and unigram-based tokenization methods. By introducing BPE tokenization to Bengali ASR, we achieve a substantial reduction in the word error rate (WER) from 66.44% in our character-based baseline system to 63.80% on the LB-ASRTD eval set and from 46.34% to 42.80% on the SHRUTI eval set, both of which include out-of-distribution data.

{{</citation>}}


## cs.NI (1)



### (13/50) A Centralized Reinforcement Learning Framework for Adaptive Clustering with Low Control Overhead in IoT Networks (F. Fernando Jurado-Lasso et al., 2024)

{{<citation>}}

F. Fernando Jurado-Lasso, J. F. Jurado, Xenofon Fafoutis. (2024)  
**A Centralized Reinforcement Learning Framework for Adaptive Clustering with Low Control Overhead in IoT Networks**  

---
Primary Category: cs.NI  
Categories: cs-LG, cs-NI, cs.NI  
Keywords: Reinforcement Learning  
[Paper Link](http://arxiv.org/abs/2401.15767v1)  

---


**ABSTRACT**  
Wireless Sensor Networks (WSNs) play a pivotal role in enabling Internet of Things (IoT) devices with sensing and actuation capabilities. Operating in remote and resource-constrained environments, these IoT devices face challenges related to energy consumption, crucial for network longevity. Clustering protocols have emerged as an effective solution to alleviate energy burdens on IoT devices. This paper introduces Low-Energy Adaptive Clustering Hierarchy with Reinforcement Learning-based Controller (LEACH-RLC), a novel clustering protocol that employs a Mixed Integer Linear Programming (MILP) for strategic selection of cluster heads (CHs) and node-to-cluster assignments. Additionally, it integrates a Reinforcement Learning (RL) agent to minimize control overhead by learning optimal timings for generating new clusters. Addressing key research questions, LEACH-RLC seeks to balance control overhead reduction without compromising overall network performance. Through extensive simulations, this paper investigates the frequency and opportune moments for generating new clustering solutions. Results demonstrate the superior performance of LEACH-RLC over conventional LEACH and LEACH-C, showcasing enhanced network lifetime, reduced average energy consumption, and minimized control overhead. The proposed protocol contributes to advancing the efficiency and adaptability of WSNs, addressing critical challenges in IoT deployments.

{{</citation>}}


## cs.RO (1)



### (14/50) HRI Challenges Influencing Low Usage of Robotic Systems in Disaster Response and Rescue Operations (Shahinul Hoque et al., 2024)

{{<citation>}}

Shahinul Hoque, Farhin Farhad Riya, Jinyuan Sun. (2024)  
**HRI Challenges Influencing Low Usage of Robotic Systems in Disaster Response and Rescue Operations**  

---
Primary Category: cs.RO  
Categories: cs-HC, cs-RO, cs.RO  
Keywords: AI  
[Paper Link](http://arxiv.org/abs/2401.15760v1)  

---


**ABSTRACT**  
The breakthrough in AI and Machine Learning has brought a new revolution in robotics, resulting in the construction of more sophisticated robotic systems. Not only can these robotic systems benefit all domains, but also can accomplish tasks that seemed to be unimaginable a few years ago. From swarms of autonomous small robots working together to more very heavy and large objects, to seemingly indestructible robots capable of going to the harshest environments, we can see robotic systems designed for every task imaginable. Among them, a key scenario where robotic systems can benefit is in disaster response scenarios and rescue operations. Robotic systems are capable of successfully conducting tasks such as removing heavy materials, utilizing multiple advanced sensors for finding objects of interest, moving through debris and various inhospitable environments, and not the least have flying capabilities. Even with so much potential, we rarely see the utilization of robotic systems in disaster response scenarios and rescue missions. Many factors could be responsible for the low utilization of robotic systems in such scenarios. One of the key factors involve challenges related to Human-Robot Interaction (HRI) issues. Therefore, in this paper, we try to understand the HRI challenges involving the utilization of robotic systems in disaster response and rescue operations. Furthermore, we go through some of the proposed robotic systems designed for disaster response scenarios and identify the HRI challenges of those systems. Finally, we try to address the challenges by introducing ideas from various proposed research works.

{{</citation>}}


## cs.LG (6)



### (15/50) AI in Energy Digital Twining: A Reinforcement Learning-based Adaptive Digital Twin Model for Green Cities (Lal Verda Cakir et al., 2024)

{{<citation>}}

Lal Verda Cakir, Kubra Duran, Craig Thomson, Matthew Broadbent, Berk Canberk. (2024)  
**AI in Energy Digital Twining: A Reinforcement Learning-based Adaptive Digital Twin Model for Green Cities**  

---
Primary Category: cs.LG  
Categories: cs-LG, cs.LG  
Keywords: AI, Reinforcement Learning  
[Paper Link](http://arxiv.org/abs/2401.16449v1)  

---


**ABSTRACT**  
Digital Twins (DT) have become crucial to achieve sustainable and effective smart urban solutions. However, current DT modelling techniques cannot support the dynamicity of these smart city environments. This is caused by the lack of right-time data capturing in traditional approaches, resulting in inaccurate modelling and high resource and energy consumption challenges. To fill this gap, we explore spatiotemporal graphs and propose the Reinforcement Learning-based Adaptive Twining (RL-AT) mechanism with Deep Q Networks (DQN). By doing so, our study contributes to advancing Green Cities and showcases tangible benefits in accuracy, synchronisation, resource optimization, and energy efficiency. As a result, we note the spatiotemporal graphs are able to offer a consistent accuracy and 55% higher querying performance when implemented using graph databases. In addition, our model demonstrates right-time data capturing with 20% lower overhead and 25% lower energy consumption.

{{</citation>}}


### (16/50) Contrastive Learning and Mixture of Experts Enables Precise Vector Embeddings (Rohan Kapur et al., 2024)

{{<citation>}}

Rohan Kapur, Logan Hallee, Arjun Patel, Bohdan Khomtchouk. (2024)  
**Contrastive Learning and Mixture of Experts Enables Precise Vector Embeddings**  

---
Primary Category: cs.LG  
Categories: cs-AI, cs-CL, cs-LG, cs.LG  
Keywords: Contrastive Learning, Embedding  
[Paper Link](http://arxiv.org/abs/2401.15713v1)  

---


**ABSTRACT**  
The advancement of transformer neural networks has significantly elevated the capabilities of sentence similarity models, particularly in creating effective vector representations of natural language inputs. However, these models face notable challenges in domain-specific contexts, especially in highly specialized scientific sub-fields. Traditional methods often struggle in this regime, either overgeneralizing similarities within a niche or being overly sensitive to minor differences, resulting in inaccurate text classification and subpar vector representation. In an era where retrieval augmentation and search are increasingly crucial, precise and concise numerical representations are essential. In this paper, we target this issue by assembling niche datasets using co-citations as a similarity metric, focusing on biomedical domains. We employ two key strategies for fine-tuning state-of-the-art models: 1. Domain-specific Fine-Tuning, which tailors pretrained models to a single domain, and 2. Universal Applicability with Mixture of Experts (MoE), adapting pretrained models with enforced routing for multiple domains simultaneously. Our training approach emphasizes the use of abstracts for faster training, incorporating Multiple Negative Rankings loss for efficient contrastive learning. Notably, our MoE variants, equipped with $N$ experts, achieve the efficacy of $N$ individual models, heralding a new era of versatile, One-Size-Fits-All transformer networks for various tasks. This methodology marks significant advancements in scientific text classification metrics and holds promise for enhancing vector database search and compilation.

{{</citation>}}


### (17/50) Addressing Noise and Efficiency Issues in Graph-Based Machine Learning Models From the Perspective of Adversarial Attack (Yongyu Wang, 2024)

{{<citation>}}

Yongyu Wang. (2024)  
**Addressing Noise and Efficiency Issues in Graph-Based Machine Learning Models From the Perspective of Adversarial Attack**  

---
Primary Category: cs.LG  
Categories: cs-CR, cs-CV, cs-LG, cs.LG  
Keywords: Adversarial Attack  
[Paper Link](http://arxiv.org/abs/2401.15615v1)  

---


**ABSTRACT**  
Given that no existing graph construction method can generate a perfect graph for a given dataset, graph-based algorithms are invariably affected by the plethora of redundant and erroneous edges present within the constructed graphs. In this paper, we propose treating these noisy edges as adversarial attack and use a spectral adversarial robustness evaluation method to diminish the impact of noisy edges on the performance of graph algorithms. Our method identifies those points that are less vulnerable to noisy edges and leverages only these robust points to perform graph-based algorithms. Our experiments with spectral clustering, one of the most representative and widely utilized graph algorithms, reveal that our methodology not only substantially elevates the precision of the algorithm but also greatly accelerates its computational efficiency by leveraging only a select number of robust data points.

{{</citation>}}


### (18/50) Improving Expressive Power of Spectral Graph Neural Networks with Eigenvalue Correction (Kangkang Lu et al., 2024)

{{<citation>}}

Kangkang Lu, Yanhua Yu, Hao Fei, Xuan Li, Zixuan Yang, Zirui Guo, Meiyu Liang, Mengran Yin, Tat-Seng Chua. (2024)  
**Improving Expressive Power of Spectral Graph Neural Networks with Eigenvalue Correction**  

---
Primary Category: cs.LG  
Categories: cs-LG, cs-SI, cs.LG  
Keywords: Graph Neural Network, Graph Neural Networks  
[Paper Link](http://arxiv.org/abs/2401.15603v1)  

---


**ABSTRACT**  
In recent years, spectral graph neural networks, characterized by polynomial filters, have garnered increasing attention and have achieved remarkable performance in tasks such as node classification. These models typically assume that eigenvalues for the normalized Laplacian matrix are distinct from each other, thus expecting a polynomial filter to have a high fitting ability. However, this paper empirically observes that normalized Laplacian matrices frequently possess repeated eigenvalues. Moreover, we theoretically establish that the number of distinguishable eigenvalues plays a pivotal role in determining the expressive power of spectral graph neural networks. In light of this observation, we propose an eigenvalue correction strategy that can free polynomial filters from the constraints of repeated eigenvalue inputs. Concretely, the proposed eigenvalue correction strategy enhances the uniform distribution of eigenvalues, thus mitigating repeated eigenvalues, and improving the fitting capacity and expressive power of polynomial filters. Extensive experimental results on both synthetic and real-world datasets demonstrate the superiority of our method.

{{</citation>}}


### (19/50) DGNN: Decoupled Graph Neural Networks with Structural Consistency between Attribute and Graph Embedding Representations (Jinlu Wang et al., 2024)

{{<citation>}}

Jinlu Wang, Jipeng Guo, Yanfeng Sun, Junbin Gao, Shaofan Wang, Yachao Yang, Baocai Yin. (2024)  
**DGNN: Decoupled Graph Neural Networks with Structural Consistency between Attribute and Graph Embedding Representations**  

---
Primary Category: cs.LG  
Categories: cs-LG, cs.LG  
Keywords: Embedding, GNN, Graph Neural Network, Graph Neural Networks  
[Paper Link](http://arxiv.org/abs/2401.15584v1)  

---


**ABSTRACT**  
Graph neural networks (GNNs) demonstrate a robust capability for representation learning on graphs with complex structures, showcasing superior performance in various applications. The majority of existing GNNs employ a graph convolution operation by using both attribute and structure information through coupled learning. In essence, GNNs, from an optimization perspective, seek to learn a consensus and compromise embedding representation that balances attribute and graph information, selectively exploring and retaining valid information. To obtain a more comprehensive embedding representation of nodes, a novel GNNs framework, dubbed Decoupled Graph Neural Networks (DGNN), is introduced. DGNN explores distinctive embedding representations from the attribute and graph spaces by decoupled terms. Considering that semantic graph, constructed from attribute feature space, consists of different node connection information and provides enhancement for the topological graph, both topological and semantic graphs are combined for the embedding representation learning. Further, structural consistency among attribute embedding and graph embeddings is promoted to effectively remove redundant information and establish soft connection. This involves promoting factor sharing for adjacency reconstruction matrices, facilitating the exploration of a consensus and high-level correlation. Finally, a more powerful and complete representation is achieved through the concatenation of these embeddings. Experimental results conducted on several graph benchmark datasets verify its superiority in node classification task.

{{</citation>}}


### (20/50) Anomaly Detection of Particle Orbit in Accelerator using LSTM Deep Learning Technology (Zhiyuan Chen et al., 2024)

{{<citation>}}

Zhiyuan Chen, Wei Lu, Radhika Bhong, Yimin Hu, Brian Freeman, Adam Carpenter. (2024)  
**Anomaly Detection of Particle Orbit in Accelerator using LSTM Deep Learning Technology**  

---
Primary Category: cs.LG  
Categories: I-5-4, cs-LG, cs.LG, physics-acc-ph  
Keywords: Anomaly Detection, LSTM  
[Paper Link](http://arxiv.org/abs/2401.15543v1)  

---


**ABSTRACT**  
A stable, reliable, and controllable orbit lock system is crucial to an electron (or ion) accelerator because the beam orbit and beam energy instability strongly affect the quality of the beam delivered to experimental halls. Currently, when the orbit lock system fails operators must manually intervene. This paper develops a Machine Learning based fault detection methodology to identify orbit lock anomalies and notify accelerator operations staff of the off-normal behavior. Our method is unsupervised, so it does not require labeled data. It uses Long-Short Memory Networks (LSTM) Auto Encoder to capture normal patterns and predict future values of monitoring sensors in the orbit lock system. Anomalies are detected when the prediction error exceeds a threshold. We conducted experiments using monitoring data from Jefferson Lab's Continuous Electron Beam Accelerator Facility (CEBAF). The results are promising: the percentage of real anomalies identified by our solution is 68.6%-89.3% using monitoring data of a single component in the orbit lock control system. The accuracy can be as high as 82%.

{{</citation>}}


## cs.CV (12)



### (21/50) An objective comparison of methods for augmented reality in laparoscopic liver resection by preoperative-to-intraoperative image fusion (Sharib Ali et al., 2024)

{{<citation>}}

Sharib Ali, Yamid Espinel, Yueming Jin, Peng Liu, Bianca Güttner, Xukun Zhang, Lihua Zhang, Tom Dowrick, Matthew J. Clarkson, Shiting Xiao, Yifan Wu, Yijun Yang, Lei Zhu, Dai Sun, Lan Li, Micha Pfeiffer, Shahid Farid, Lena Maier-Hein, Emmanuel Buc, Adrien Bartoli. (2024)  
**An objective comparison of methods for augmented reality in laparoscopic liver resection by preoperative-to-intraoperative image fusion**  

---
Primary Category: cs.CV  
Categories: cs-AI, cs-CV, cs-GR, cs-LG, cs.CV  
Keywords: AI  
[Paper Link](http://arxiv.org/abs/2401.15753v1)  

---


**ABSTRACT**  
Augmented reality for laparoscopic liver resection is a visualisation mode that allows a surgeon to localise tumours and vessels embedded within the liver by projecting them on top of a laparoscopic image. Preoperative 3D models extracted from CT or MRI data are registered to the intraoperative laparoscopic images during this process. In terms of 3D-2D fusion, most of the algorithms make use of anatomical landmarks to guide registration. These landmarks include the liver's inferior ridge, the falciform ligament, and the occluding contours. They are usually marked by hand in both the laparoscopic image and the 3D model, which is time-consuming and may contain errors if done by a non-experienced user. Therefore, there is a need to automate this process so that augmented reality can be used effectively in the operating room. We present the Preoperative-to-Intraoperative Laparoscopic Fusion Challenge (P2ILF), held during the Medical Imaging and Computer Assisted Interventions (MICCAI 2022) conference, which investigates the possibilities of detecting these landmarks automatically and using them in registration. The challenge was divided into two tasks: 1) A 2D and 3D landmark detection task and 2) a 3D-2D registration task. The teams were provided with training data consisting of 167 laparoscopic images and 9 preoperative 3D models from 9 patients, with the corresponding 2D and 3D landmark annotations. A total of 6 teams from 4 countries participated, whose proposed methods were evaluated on 16 images and two preoperative 3D models from two patients. All the teams proposed deep learning-based methods for the 2D and 3D landmark segmentation tasks and differentiable rendering-based methods for the registration task. Based on the experimental outcomes, we propose three key hypotheses that determine current limitations and future directions for research in this domain.

{{</citation>}}


### (22/50) SERNet-Former: Semantic Segmentation by Efficient Residual Network with Attention-Boosting Gates and Attention-Fusion Networks (Serdar Erisen, 2024)

{{<citation>}}

Serdar Erisen. (2024)  
**SERNet-Former: Semantic Segmentation by Efficient Residual Network with Attention-Boosting Gates and Attention-Fusion Networks**  

---
Primary Category: cs.CV  
Categories: cs-AI, cs-CV, cs.CV  
Keywords: Attention, Semantic Segmentation  
[Paper Link](http://arxiv.org/abs/2401.15741v1)  

---


**ABSTRACT**  
Improving the efficiency of state-of-the-art methods in semantic segmentation requires overcoming the increasing computational cost as well as issues such as fusing semantic information from global and local contexts. Based on the recent success and problems that convolutional neural networks (CNNs) encounter in semantic segmentation, this research proposes an encoder-decoder architecture with a unique efficient residual network. Attention-boosting gates (AbGs) and attention-boosting modules (AbMs) are deployed by aiming to fuse the feature-based semantic information with the global context of the efficient residual network in the encoder. Respectively, the decoder network is developed with the additional attention-fusion networks (AfNs) inspired by AbM. AfNs are designed to improve the efficiency in the one-to-one conversion of the semantic information by deploying additional convolution layers in the decoder part. Our network is tested on the challenging CamVid and Cityscapes datasets, and the proposed methods reveal significant improvements on the existing baselines, such as ResNet-50. To the best of our knowledge, the developed network, SERNet-Former, achieves state-of-the-art results (84.62 % mean IoU) on CamVid dataset and challenging results (87.35 % mean IoU) on Cityscapes validation dataset.

{{</citation>}}


### (23/50) A Study of Acquisition Functions for Medical Imaging Deep Active Learning (Bonaventure F. P. Dossou, 2024)

{{<citation>}}

Bonaventure F. P. Dossou. (2024)  
**A Study of Acquisition Functions for Medical Imaging Deep Active Learning**  

---
Primary Category: cs.CV  
Categories: cs-AI, cs-CV, cs-HC, cs-LG, cs.CV  
Keywords: Active Learning  
[Paper Link](http://arxiv.org/abs/2401.15721v1)  

---


**ABSTRACT**  
The Deep Learning revolution has enabled groundbreaking achievements in recent years. From breast cancer detection to protein folding, deep learning algorithms have been at the core of very important advancements. However, these modern advancements are becoming more and more data-hungry, especially on labeled data whose availability is scarce: this is even more prevalent in the medical context. In this work, we show how active learning could be very effective in data scarcity situations, where obtaining labeled data (or annotation budget is very limited). We compare several selection criteria (BALD, MeanSTD, and MaxEntropy) on the ISIC 2016 dataset. We also explored the effect of acquired pool size on the model's performance. Our results suggest that uncertainty is useful to the Melanoma detection task, and confirms the hypotheses of the author of the paper of interest, that \textit{bald} performs on average better than other acquisition functions. Our extended analyses however revealed that all acquisition functions perform badly on the positive (cancerous) samples, suggesting exploitation of class unbalance, which could be crucial in real-world settings. We finish by suggesting future work directions that would be useful to improve this current work. The code of our implementation is open-sourced at \url{https://github.com/bonaventuredossou/ece526_course_project}

{{</citation>}}


### (24/50) Object-Driven One-Shot Fine-tuning of Text-to-Image Diffusion with Prototypical Embedding (Jianxiang Lu et al., 2024)

{{<citation>}}

Jianxiang Lu, Cong Xie, Hui Guo. (2024)  
**Object-Driven One-Shot Fine-tuning of Text-to-Image Diffusion with Prototypical Embedding**  

---
Primary Category: cs.CV  
Categories: cs-CV, cs.CV  
Keywords: Embedding  
[Paper Link](http://arxiv.org/abs/2401.15708v1)  

---


**ABSTRACT**  
As large-scale text-to-image generation models have made remarkable progress in the field of text-to-image generation, many fine-tuning methods have been proposed. However, these models often struggle with novel objects, especially with one-shot scenarios. Our proposed method aims to address the challenges of generalizability and fidelity in an object-driven way, using only a single input image and the object-specific regions of interest. To improve generalizability and mitigate overfitting, in our paradigm, a prototypical embedding is initialized based on the object's appearance and its class, before fine-tuning the diffusion model. And during fine-tuning, we propose a class-characterizing regularization to preserve prior knowledge of object classes. To further improve fidelity, we introduce object-specific loss, which can also use to implant multiple objects. Overall, our proposed object-driven method for implanting new objects can integrate seamlessly with existing concepts as well as with high fidelity and generalization. Our method outperforms several existing works. The code will be released.

{{</citation>}}


### (25/50) Divide and Conquer: Language Models can Plan and Self-Correct for Compositional Text-to-Image Generation (Zhenyu Wang et al., 2024)

{{<citation>}}

Zhenyu Wang, Enze Xie, Aoxue Li, Zhongdao Wang, Xihui Liu, Zhenguo Li. (2024)  
**Divide and Conquer: Language Models can Plan and Self-Correct for Compositional Text-to-Image Generation**  

---
Primary Category: cs.CV  
Categories: cs-CV, cs.CV  
Keywords: Language Model  
[Paper Link](http://arxiv.org/abs/2401.15688v2)  

---


**ABSTRACT**  
Despite significant advancements in text-to-image models for generating high-quality images, these methods still struggle to ensure the controllability of text prompts over images in the context of complex text prompts, especially when it comes to retaining object attributes and relationships. In this paper, we propose CompAgent, a training-free approach for compositional text-to-image generation, with a large language model (LLM) agent as its core. The fundamental idea underlying CompAgent is premised on a divide-and-conquer methodology. Given a complex text prompt containing multiple concepts including objects, attributes, and relationships, the LLM agent initially decomposes it, which entails the extraction of individual objects, their associated attributes, and the prediction of a coherent scene layout. These individual objects can then be independently conquered. Subsequently, the agent performs reasoning by analyzing the text, plans and employs the tools to compose these isolated objects. The verification and human feedback mechanism is finally incorporated into our agent to further correct the potential attribute errors and refine the generated images. Guided by the LLM agent, we propose a tuning-free multi-concept customization model and a layout-to-image generation model as the tools for concept composition, and a local image editing method as the tool to interact with the agent for verification. The scene layout controls the image generation process among these tools to prevent confusion among multiple objects. Extensive experiments demonstrate the superiority of our approach for compositional text-to-image generation: CompAgent achieves more than 10\% improvement on T2I-CompBench, a comprehensive benchmark for open-world compositional T2I generation. The extension to various related tasks also illustrates the flexibility of our CompAgent for potential applications.

{{</citation>}}


### (26/50) Assessment of Autism and ADHD: A Comparative Analysis of Drawing Velocity Profiles and the NEPSY Test (S. Fortea-Sevilla et al., 2024)

{{<citation>}}

S. Fortea-Sevilla, A. Garcia-Sosa., P. Morales-Almeida, C. Carmona-Duarte. (2024)  
**Assessment of Autism and ADHD: A Comparative Analysis of Drawing Velocity Profiles and the NEPSY Test**  

---
Primary Category: cs.CV  
Categories: cs-CV, cs.CV  
Keywords: Attention  
[Paper Link](http://arxiv.org/abs/2401.15685v1)  

---


**ABSTRACT**  
The increasing prevalence of Autism Spectrum Disorder and Attention-Deficit/ Hyperactivity Disorder among students highlights the need to improve evaluation and diagnostic techniques, as well as effective tools to mitigate the negative consequences associated with these disorders. With the widespread use of touchscreen mobile devices, there is an opportunity to gather comprehensive data beyond visual cues. These devices enable the collection and visualization of information on velocity profiles and the time taken to complete drawing and handwriting tasks. These data can be leveraged to develop new neuropsychological tests based on the velocity profile that assists in distinguishing between challenging cases of ASD and ADHD that are difficult to differentiate in clinical practice. In this paper, we present a proof of concept that compares and combines the results obtained from standardized tasks in the NEPSY-II assessment with a proposed observational scale based on the visual analysis of the velocity profile collected using digital tablets.

{{</citation>}}


### (27/50) Data-Free Generalized Zero-Shot Learning (Bowen Tang et al., 2024)

{{<citation>}}

Bowen Tang, Long Yan, Jing Zhang, Qian Yu, Lu Sheng, Dong Xu. (2024)  
**Data-Free Generalized Zero-Shot Learning**  

---
Primary Category: cs.CV  
Categories: cs-CV, cs.CV  
Keywords: Zero-Shot  
[Paper Link](http://arxiv.org/abs/2401.15657v1)  

---


**ABSTRACT**  
Deep learning models have the ability to extract rich knowledge from large-scale datasets. However, the sharing of data has become increasingly challenging due to concerns regarding data copyright and privacy. Consequently, this hampers the effective transfer of knowledge from existing data to novel downstream tasks and concepts. Zero-shot learning (ZSL) approaches aim to recognize new classes by transferring semantic knowledge learned from base classes. However, traditional generative ZSL methods often require access to real images from base classes and rely on manually annotated attributes, which presents challenges in terms of data restrictions and model scalability. To this end, this paper tackles a challenging and practical problem dubbed as data-free zero-shot learning (DFZSL), where only the CLIP-based base classes data pre-trained classifier is available for zero-shot classification. Specifically, we propose a generic framework for DFZSL, which consists of three main components. Firstly, to recover the virtual features of the base data, we model the CLIP features of base class images as samples from a von Mises-Fisher (vMF) distribution based on the pre-trained classifier. Secondly, we leverage the text features of CLIP as low-cost semantic information and propose a feature-language prompt tuning (FLPT) method to further align the virtual image features and textual features. Thirdly, we train a conditional generative model using the well-aligned virtual image features and corresponding semantic text features, enabling the generation of new classes features and achieve better zero-shot generalization. Our framework has been evaluated on five commonly used benchmarks for generalized ZSL, as well as 11 benchmarks for the base-to-new ZSL. The results demonstrate the superiority and effectiveness of our approach. Our code is available in https://github.com/ylong4/DFZSL

{{</citation>}}


### (28/50) Improving Data Augmentation for Robust Visual Question Answering with Effective Curriculum Learning (Yuhang Zheng et al., 2024)

{{<citation>}}

Yuhang Zheng, Zhen Wang, Long Chen. (2024)  
**Improving Data Augmentation for Robust Visual Question Answering with Effective Curriculum Learning**  

---
Primary Category: cs.CV  
Categories: cs-CV, cs.CV  
Keywords: Augmentation, QA, Question Answering  
[Paper Link](http://arxiv.org/abs/2401.15646v1)  

---


**ABSTRACT**  
Being widely used in learning unbiased visual question answering (VQA) models, Data Augmentation (DA) helps mitigate language biases by generating extra training samples beyond the original samples. While today's DA methods can generate robust samples, the augmented training set, significantly larger than the original dataset, often exhibits redundancy in terms of difficulty or content repetition, leading to inefficient model training and even compromising the model performance. To this end, we design an Effective Curriculum Learning strategy ECL to enhance DA-based VQA methods. Intuitively, ECL trains VQA models on relatively ``easy'' samples first, and then gradually changes to ``harder'' samples, and less-valuable samples are dynamically removed. Compared to training on the entire augmented dataset, our ECL strategy can further enhance VQA models' performance with fewer training samples. Extensive ablations have demonstrated the effectiveness of ECL on various methods.

{{</citation>}}


### (29/50) FreeStyle: Free Lunch for Text-guided Style Transfer using Diffusion Models (Feihong He et al., 2024)

{{<citation>}}

Feihong He, Gang Li, Mengyuan Zhang, Leilei Yan, Lingyu Si, Fanzhang Li. (2024)  
**FreeStyle: Free Lunch for Text-guided Style Transfer using Diffusion Models**  

---
Primary Category: cs.CV  
Categories: cs-CV, cs.CV, eess-IV  
Keywords: Style Transfer  
[Paper Link](http://arxiv.org/abs/2401.15636v1)  

---


**ABSTRACT**  
The rapid development of generative diffusion models has significantly advanced the field of style transfer. However, most current style transfer methods based on diffusion models typically involve a slow iterative optimization process, e.g., model fine-tuning and textual inversion of style concept. In this paper, we introduce FreeStyle, an innovative style transfer method built upon a pre-trained large diffusion model, requiring no further optimization. Besides, our method enables style transfer only through a text description of the desired style, eliminating the necessity of style images. Specifically, we propose a dual-stream encoder and single-stream decoder architecture, replacing the conventional U-Net in diffusion models. In the dual-stream encoder, two distinct branches take the content image and style text prompt as inputs, achieving content and style decoupling. In the decoder, we further modulate features from the dual streams based on a given content image and the corresponding style text prompt for precise style transfer. Our experimental results demonstrate high-quality synthesis and fidelity of our method across various content images and style text prompts. The code and more results are available at our project website:https://freestylefreelunch.github.io/.

{{</citation>}}


### (30/50) SCTransNet: Spatial-channel Cross Transformer Network for Infrared Small Target Detection (Shuai Yuan et al., 2024)

{{<citation>}}

Shuai Yuan, Hanlin Qin, Xiang Yan, Naveed AKhtar, Ajmal Mian. (2024)  
**SCTransNet: Spatial-channel Cross Transformer Network for Infrared Small Target Detection**  

---
Primary Category: cs.CV  
Categories: cs-CV, cs.CV  
Keywords: Transformer  
[Paper Link](http://arxiv.org/abs/2401.15583v2)  

---


**ABSTRACT**  
Infrared small target detection (IRSTD) has recently benefitted greatly from U-shaped neural models. However, largely overlooking effective global information modeling, existing techniques struggle when the target has high similarities with the background. We present a Spatial-channel Cross Transformer Network (SCTransNet) that leverages spatial-channel cross transformer blocks (SCTBs) on top of long-range skip connections to address the aforementioned challenge. In the proposed SCTBs, the outputs of all encoders are interacted with cross transformer to generate mixed features, which are redistributed to all decoders to effectively reinforce semantic differences between the target and clutter at full scales. Specifically, SCTB contains the following two key elements: (a) spatial-embedded single-head channel-cross attention (SSCA) for exchanging local spatial features and full-level global channel information to eliminate ambiguity among the encoders and facilitate high-level semantic associations of the images, and (b) a complementary feed-forward network (CFN) for enhancing the feature discriminability via a multi-scale strategy and cross-spatial-channel information interaction to promote beneficial information transfer. Our SCTransNet effectively encodes the semantic differences between targets and backgrounds to boost its internal representation for detecting small infrared targets accurately. Extensive experiments on three public datasets, NUDT-SIRST, NUAA-SIRST, and IRSTD-1k, demonstrate that the proposed SCTransNet outperforms existing IRSTD methods. Our code will be made public at https://github.com/xdFai.

{{</citation>}}


### (31/50) Intriguing Equivalence Structures of the Embedding Space of Vision Transformers (Shaeke Salman et al., 2024)

{{<citation>}}

Shaeke Salman, Md Montasir Bin Shams, Xiuwen Liu. (2024)  
**Intriguing Equivalence Structures of the Embedding Space of Vision Transformers**  

---
Primary Category: cs.CV  
Categories: cs-AI, cs-CV, cs-LG, cs.CV  
Keywords: Embedding, Transformer, Transformers  
[Paper Link](http://arxiv.org/abs/2401.15568v1)  

---


**ABSTRACT**  
Pre-trained large foundation models play a central role in the recent surge of artificial intelligence, resulting in fine-tuned models with remarkable abilities when measured on benchmark datasets, standard exams, and applications. Due to their inherent complexity, these models are not well understood. While small adversarial inputs to such models are well known, the structures of the representation space are not well characterized despite their fundamental importance. In this paper, using the vision transformers as an example due to the continuous nature of their input space, we show via analyses and systematic experiments that the representation space consists of large piecewise linear subspaces where there exist very different inputs sharing the same representations, and at the same time, local normal spaces where there are visually indistinguishable inputs having very different representations. The empirical results are further verified using the local directional estimations of the Lipschitz constants of the underlying models. Consequently, the resulting representations change the results of downstream models, and such models are subject to overgeneralization and with limited semantically meaningful generalization capability.

{{</citation>}}


### (32/50) BrepGen: A B-rep Generative Diffusion Model with Structured Latent Geometry (Xiang Xu et al., 2024)

{{<citation>}}

Xiang Xu, Joseph G. Lambourne, Pradeep Kumar Jayaraman, Zhengqing Wang, Karl D. D. Willis, Yasutaka Furukawa. (2024)  
**BrepGen: A B-rep Generative Diffusion Model with Structured Latent Geometry**  

---
Primary Category: cs.CV  
Categories: cs-CV, cs-LG, cs.CV  
Keywords: Transformer  
[Paper Link](http://arxiv.org/abs/2401.15563v1)  

---


**ABSTRACT**  
This paper presents BrepGen, a diffusion-based generative approach that directly outputs a Boundary representation (B-rep) Computer-Aided Design (CAD) model. BrepGen represents a B-rep model as a novel structured latent geometry in a hierarchical tree. With the root node representing a whole CAD solid, each element of a B-rep model (i.e., a face, an edge, or a vertex) progressively turns into a child-node from top to bottom. B-rep geometry information goes into the nodes as the global bounding box of each primitive along with a latent code describing the local geometric shape. The B-rep topology information is implicitly represented by node duplication. When two faces share an edge, the edge curve will appear twice in the tree, and a T-junction vertex with three incident edges appears six times in the tree with identical node features. Starting from the root and progressing to the leaf, BrepGen employs Transformer-based diffusion models to sequentially denoise node features while duplicated nodes are detected and merged, recovering the B-Rep topology information. Extensive experiments show that BrepGen sets a new milestone in CAD B-rep generation, surpassing existing methods on various benchmarks. Results on our newly collected furniture dataset further showcase its exceptional capability in generating complicated geometry. While previous methods were limited to generating simple prismatic shapes, BrepGen incorporates free-form and doubly-curved surfaces for the first time. Additional applications of BrepGen include CAD autocomplete and design interpolation. The code, pretrained models, and dataset will be released.

{{</citation>}}


## eess.SP (1)



### (33/50) Real-time EEG-based Emotion Recognition Model using Principal Component Analysis and Tree-based Models for Neurohumanities (Miguel A. Blanco-Rios et al., 2024)

{{<citation>}}

Miguel A. Blanco-Rios, Milton O. Candela-Leal, Cecilia Orozco-Romo, Paulina Remis-Serna, Carol S. Velez-Saboya, Jorge De-J. Lozoya-Santos, Manuel Cebral-Loureda, Mauricio A. Ramirez-Moreno. (2024)  
**Real-time EEG-based Emotion Recognition Model using Principal Component Analysis and Tree-based Models for Neurohumanities**  

---
Primary Category: eess.SP  
Categories: cs-HC, cs-LG, eess-SP, eess.SP, q-bio-NC  
Keywords: Emotion Recognition  
[Paper Link](http://arxiv.org/abs/2401.15743v1)  

---


**ABSTRACT**  
Within the field of Humanities, there is a recognized need for educational innovation, as there are currently no reported tools available that enable individuals to interact with their environment to create an enhanced learning experience in the humanities (e.g., immersive spaces). This project proposes a solution to address this gap by integrating technology and promoting the development of teaching methodologies in the humanities, specifically by incorporating emotional monitoring during the learning process of humanistic context inside an immersive space. In order to achieve this goal, a real-time emotion detection EEG-based system was developed to interpret and classify specific emotions. These emotions aligned with the early proposal by Descartes (Passions), including admiration, love, hate, desire, joy, and sadness. This system aims to integrate emotional data into the Neurohumanities Lab interactive platform, creating a comprehensive and immersive learning environment. This work developed a ML, real-time emotion detection model that provided Valence, Arousal, and Dominance (VAD) estimations every 5 seconds. Using PCA, PSD, RF, and Extra-Trees, the best 8 channels and their respective best band powers were extracted; furthermore, multiple models were evaluated using shift-based data division and cross-validations. After assessing their performance, Extra-Trees achieved a general accuracy of 96%, higher than the reported in the literature (88% accuracy). The proposed model provided real-time predictions of VAD variables and was adapted to classify Descartes' six main passions. However, with the VAD values obtained, more than 15 emotions can be classified (reported in the VAD emotion mapping) and extend the range of this application.

{{</citation>}}


## cs.AR (1)



### (34/50) LLM4SecHW: Leveraging Domain Specific Large Language Model for Hardware Debugging (Weimin Fu et al., 2024)

{{<citation>}}

Weimin Fu, Kaichen Yang, Raj Gautam Dutta, Xiaolong Guo, Gang Qu. (2024)  
**LLM4SecHW: Leveraging Domain Specific Large Language Model for Hardware Debugging**  

---
Primary Category: cs.AR  
Categories: cs-AI, cs-AR, cs.AR  
Keywords: Language Model  
[Paper Link](http://arxiv.org/abs/2401.16448v1)  

---


**ABSTRACT**  
This paper presents LLM4SecHW, a novel framework for hardware debugging that leverages domain specific Large Language Model (LLM). Despite the success of LLMs in automating various software development tasks, their application in the hardware security domain has been limited due to the constraints of commercial LLMs and the scarcity of domain specific data. To address these challenges, we propose a unique approach to compile a dataset of open source hardware design defects and their remediation steps, utilizing version control data. This dataset provides a substantial foundation for training machine learning models for hardware. LLM4SecHW employs fine tuning of medium sized LLMs based on this dataset, enabling the identification and rectification of bugs in hardware designs. This pioneering approach offers a reference workflow for the application of fine tuning domain specific LLMs in other research areas. We evaluate the performance of our proposed system on various open source hardware designs, demonstrating its efficacy in accurately identifying and correcting defects. Our work brings a new perspective on automating the quality control process in hardware design.

{{</citation>}}


## cs.IR (3)



### (35/50) The Impact of Snippet Reliability on Misinformation in Online Health Search (Anat Hashavit et al., 2024)

{{<citation>}}

Anat Hashavit, Tamar Stern, Hongning Wang, Sarit Kraus. (2024)  
**The Impact of Snippet Reliability on Misinformation in Online Health Search**  

---
Primary Category: cs.IR  
Categories: cs-IR, cs.IR  
Keywords: Google  
[Paper Link](http://arxiv.org/abs/2401.15720v1)  

---


**ABSTRACT**  
Search result snippets are crucial in modern search engines, providing users with a quick overview of a website's content. Snippets help users determine the relevance of a document to their information needs, and in certain scenarios even enable them to satisfy those needs without visiting web documents. Hence, it is crucial for snippets to reliably represent the content of their corresponding documents. While this may be a straightforward requirement for some queries, it can become challenging in the complex domain of healthcare, and can lead to misinformation. This paper aims to examine snippets' reliability in representing their corresponding documents, specifically in the health domain. To achieve this, we conduct a series of user studies using Google's search results, where participants are asked to infer viewpoints of search results pertaining to queries about the effectiveness of a medical intervention for a medical condition, based solely on their titles and snippets. Our findings reveal that a considerable portion of Google's snippets (28%) failed to present any viewpoint on the intervention's effectiveness, and that 35% were interpreted by participants as having a different viewpoint compared to their corresponding documents. To address this issue, we propose a snippet extraction solution tailored directly to users' information needs, i.e., extracting snippets that summarize documents' viewpoints regarding the intervention and condition that appear in the query. User study demonstrates that our information need-focused solution outperforms the mainstream query-based approach. With only 19.67% of snippets generated by our solution reported as not presenting a viewpoint and a mere 20.33% misinterpreted by participants. These results strongly suggest that an information need-focused approach can significantly improve the reliability of extracted snippets in online health search.

{{</citation>}}


### (36/50) PRE: A Peer Review Based Large Language Model Evaluator (Zhumin Chu et al., 2024)

{{<citation>}}

Zhumin Chu, Qingyao Ai, Yiteng Tu, Haitao Li, Yiqun Liu. (2024)  
**PRE: A Peer Review Based Large Language Model Evaluator**  

---
Primary Category: cs.IR  
Categories: cs-CL, cs-IR, cs.IR  
Keywords: GPT, GPT-4, Language Model  
[Paper Link](http://arxiv.org/abs/2401.15641v1)  

---


**ABSTRACT**  
The impressive performance of large language models (LLMs) has attracted considerable attention from the academic and industrial communities. Besides how to construct and train LLMs, how to effectively evaluate and compare the capacity of LLMs has also been well recognized as an important yet difficult problem. Existing paradigms rely on either human annotators or model-based evaluators to evaluate the performance of LLMs on different tasks. However, these paradigms often suffer from high cost, low generalizability, and inherited biases in practice, which make them incapable of supporting the sustainable development of LLMs in long term. In order to address these issues, inspired by the peer review systems widely used in academic publication process, we propose a novel framework that can automatically evaluate LLMs through a peer-review process. Specifically, for the evaluation of a specific task, we first construct a small qualification exam to select "reviewers" from a couple of powerful LLMs. Then, to actually evaluate the "submissions" written by different candidate LLMs, i.e., the evaluatees, we use the reviewer LLMs to rate or compare the submissions. The final ranking of evaluatee LLMs is generated based on the results provided by all reviewers. We conducted extensive experiments on text summarization tasks with eleven LLMs including GPT-4. The results demonstrate the existence of biasness when evaluating using a single LLM. Also, our PRE model outperforms all the baselines, illustrating the effectiveness of the peer review mechanism.

{{</citation>}}


### (37/50) RecDCL: Dual Contrastive Learning for Recommendation (Dan Zhang et al., 2024)

{{<citation>}}

Dan Zhang, Yangliao Geng, Wenwen Gong, Zhongang Qi, Zhiyu Chen, Xing Tang, Ying Shan, Yuxiao Dong, Jie Tang. (2024)  
**RecDCL: Dual Contrastive Learning for Recommendation**  

---
Primary Category: cs.IR  
Categories: cs-CL, cs-IR, cs.IR  
Keywords: Contrastive Learning, GNN  
[Paper Link](http://arxiv.org/abs/2401.15635v1)  

---


**ABSTRACT**  
Self-supervised recommendation (SSR) has achieved great success in mining the potential interacted behaviors for collaborative filtering in recent years. As a major branch, Contrastive Learning (CL) based SSR conquers data sparsity in Web platforms by contrasting the embedding between raw data and augmented data. However, existing CL-based SSR methods mostly focus on contrasting in a batch-wise way, failing to exploit potential regularity in the feature-wise dimension, leading to redundant solutions during the representation learning process of users (items) from Websites. Furthermore, the joint benefits of utilizing both Batch-wise CL (BCL) and Feature-wise CL (FCL) for recommendations remain underexplored. To address these issues, we investigate the relationship of objectives between BCL and FCL. Our study suggests a cooperative benefit of employing both methods, as evidenced from theoretical and experimental perspectives. Based on these insights, we propose a dual CL method for recommendation, referred to as RecDCL. RecDCL first eliminates redundant solutions on user-item positive pairs in a feature-wise manner. It then optimizes the uniform distributions within users and items using a polynomial kernel from an FCL perspective. Finally, it generates contrastive embedding on output vectors in a batch-wise objective. We conduct experiments on four widely-used benchmarks and an industrial dataset. The results consistently demonstrate that the proposed RecDCL outperforms the state-of-the-art GNNs-based and SSL-based models (with up to a 5.65\% improvement in terms of Recall@20), thereby confirming the effectiveness of the joint-wise objective. All source codes used in this paper are publicly available at \url{https://github.com/THUDM/RecDCL}}.

{{</citation>}}


## cs.CE (3)



### (38/50) Exploring the Impact of Blockchain, AI, and ML on Financial Accounting Efficiency and Transformation (Vijaya Kanaparthi, 2024)

{{<citation>}}

Vijaya Kanaparthi. (2024)  
**Exploring the Impact of Blockchain, AI, and ML on Financial Accounting Efficiency and Transformation**  

---
Primary Category: cs.CE  
Categories: cs-CE, cs.CE  
Keywords: AI, Financial  
[Paper Link](http://arxiv.org/abs/2401.15715v1)  

---


**ABSTRACT**  
Continuous innovations profoundly impact the financial and commercial domains, reshaping conventional business practices. Among the disruptive forces, Artificial Intelligence (AI), Machine Learning (ML), and blockchain technology stand out prominently. This study aims to evaluate the integration of blockchain, AI, and ML within financial accounting practices. It suggests a potential revolutionary impact on financial accounting through the adoption of blockchain technology and ML, promising reduced accounting expenses, heightened precision, real-time financial reporting capabilities, and expeditious auditing processes. AI's role in automating repetitive financial accounting tasks assists organizations in circumventing the need for additional staff, thereby minimizing associated costs. Consequently, to bolster efficiency, businesses are increasingly embracing blockchain technology and AI applications in their financial accounting operations.

{{</citation>}}


### (39/50) Transformational application of Artificial Intelligence and Machine learning in Financial Technologies and Financial services: A bibliometric review (Vijaya Kanaparthi, 2024)

{{<citation>}}

Vijaya Kanaparthi. (2024)  
**Transformational application of Artificial Intelligence and Machine learning in Financial Technologies and Financial services: A bibliometric review**  

---
Primary Category: cs.CE  
Categories: cs-CE, cs.CE  
Keywords: AI, Financial  
[Paper Link](http://arxiv.org/abs/2401.15710v1)  

---


**ABSTRACT**  
In this study, I employ a multifaceted comprehensive scientometric approach to explore the intellectual underpinnings of AI and ML in financial research by examining the publication patterns of articles, journals, authors, institutions, and nations by leveraging quantitative techniques, that transcend conventional systematic literature reviews, enabling the effective analysis of vast scientometric and bibliographic data. By applying these approaches, I identify influential works, seminal contributions, thought leaders, topical clusters, research streams, and new research frontiers, ultimately fostering a deeper understanding of the knowledge structure in AI and ML finance research by considering publication records from 2010 to 2022 from several search engines and database sources. The present study finds a marked increase in publications from 2017 to 2022, which highlights a growing interest and expanding research activity in the field, indicating its potential significance and relevance in the contemporary academic landscape.

{{</citation>}}


### (40/50) AI-based Personalization and Trust in Digital Finance (Vijaya Kanaparthi, 2024)

{{<citation>}}

Vijaya Kanaparthi. (2024)  
**AI-based Personalization and Trust in Digital Finance**  

---
Primary Category: cs.CE  
Categories: cs-CE, cs.CE  
Keywords: AI  
[Paper Link](http://arxiv.org/abs/2401.15700v1)  

---


**ABSTRACT**  
Personalized services bridge the gap between a financial institution and its customers and are built on trust. The more we trust the product, the keener we are to disclose our personal information in order to receive a highly personalized service that maximizes consumer value. Artificial Intelligence (AI) can help financial institutions tailor relevant products and services to their customers as well as improve their credit risk management, compliance, and fraud detection capabilities by incorporating chatbots and face recognition systems. The present study has analyzed sixteen research papers using the PRISMA model to perform a Systematic Literature Review (SLR). It has identified five research gaps and corresponding questions to analyze the present scenario. One of the gaps is credit risk detection for improved personalization and trust. Finally, an AI-based credit risk detection model has been built using four supervised machine learning classifiers viz., Support Vector Machine, Random Forest, Decision Tree, and Logistic Regression. Performance comparison shows an optimal performance of the model giving accuracy of ~89%, precision of ~88%, recall of ~89%, specificity of ~89%, F1_score of ~88%, and AUC of 0.77 for the Random Forest classifier. This model is foreseen to be most suitable for envisaging customer characteristics for which personalized credit risk mitigation strategies are particularly effective as compared to other existing works presented in this study.

{{</citation>}}


## cs.HC (4)



### (41/50) From Word Embedding to Reading Embedding Using Large Language Model, EEG and Eye-tracking (Yuhong Zhang et al., 2024)

{{<citation>}}

Yuhong Zhang, Shilai Yang, Gert Cauwenberghs, Tzyy-Ping Jung. (2024)  
**From Word Embedding to Reading Embedding Using Large Language Model, EEG and Eye-tracking**  

---
Primary Category: cs.HC  
Categories: cs-HC, cs.HC  
Keywords: BERT, Embedding, Language Model, Transformer, Transformers, Word Embedding  
[Paper Link](http://arxiv.org/abs/2401.15681v1)  

---


**ABSTRACT**  
Reading comprehension, a fundamental cognitive ability essential for knowledge acquisition, is a complex skill, with a notable number of learners lacking proficiency in this domain. This study introduces innovative tasks for Brain-Computer Interface (BCI), predicting the relevance of words or tokens read by individuals to the target inference words. We use state-of-the-art Large Language Models (LLMs) to guide a new reading embedding representation in training. This representation, integrating EEG and eye-tracking biomarkers through an attention-based transformer encoder, achieved a mean 5-fold cross-validation accuracy of 68.7% across nine subjects using a balanced sample, with the highest single-subject accuracy reaching 71.2%. This study pioneers the integration of LLMs, EEG, and eye-tracking for predicting human reading comprehension at the word level. We fine-tune the pre-trained Bidirectional Encoder Representations from Transformers (BERT) model for word embedding, devoid of information about the reading tasks. Despite this absence of task-specific details, the model effortlessly attains an accuracy of 92.7%, thereby validating our findings from LLMs. This work represents a preliminary step toward developing tools to assist reading.

{{</citation>}}


### (42/50) AI as a Medical Ally: Evaluating ChatGPT's Usage and Impact in Indian Healthcare (Aryaman Raina et al., 2024)

{{<citation>}}

Aryaman Raina, Prateek Mishra, Harshit goyal, Dhruv Kumar. (2024)  
**AI as a Medical Ally: Evaluating ChatGPT's Usage and Impact in Indian Healthcare**  

---
Primary Category: cs.HC  
Categories: cs-CY, cs-HC, cs.HC  
Keywords: AI, ChatGPT, GPT, Language Model  
[Paper Link](http://arxiv.org/abs/2401.15605v1)  

---


**ABSTRACT**  
This study investigates the integration and impact of Large Language Models (LLMs), like ChatGPT, in India's healthcare sector. Our research employs a dual approach, engaging both general users and medical professionals through surveys and interviews respectively. Our findings reveal that healthcare professionals value ChatGPT in medical education and preliminary clinical settings, but exercise caution due to concerns about reliability, privacy, and the need for cross-verification with medical references. General users show a preference for AI interactions in healthcare, but concerns regarding accuracy and trust persist. The study underscores the need for these technologies to complement, not replace, human medical expertise, highlighting the importance of developing LLMs in collaboration with healthcare providers. This paper enhances the understanding of LLMs in healthcare, detailing current usage, user trust, and improvement areas. Our insights inform future research and development, underscoring the need for ethically compliant, user-focused LLM advancements that address healthcare-specific challenges.

{{</citation>}}


### (43/50) Comuniqa : Exploring Large Language Models for improving speaking skills (Manas Mhasakar et al., 2024)

{{<citation>}}

Manas Mhasakar, Shikhar Sharma, Apurv Mehra, Utkarsh Venaik, Ujjwal Singhal, Dhruv Kumar, Kashish Mittal. (2024)  
**Comuniqa : Exploring Large Language Models for improving speaking skills**  

---
Primary Category: cs.HC  
Categories: cs-CY, cs-HC, cs.HC  
Keywords: Language Model  
[Paper Link](http://arxiv.org/abs/2401.15595v1)  

---


**ABSTRACT**  
This research paper explores the potential of Large Language Models (LLMs) to enhance speaking skills. We first present a novel LLM-based system, Comuniqa, for this task. We then take a humancentric approach to evaluate this system, comparing it with human experts. We also investigate the possibility of combining feedback from both LLM and human experts to enhance overall learning outcomes. We use purposive and random sampling for recruiting participants, categorizing them into three groups: those who use LLM-enabled apps for improving speaking skills, those guided by human experts for the same task and those who utilize both the LLM-enabled apps as well as the human experts. Using surveys, interviews, and actual study sessions, we provide a detailed perspective on the effectiveness of different learning modalities. Our preliminary findings suggest that while LLM-based systems have commendable accuracy, they lack human-level cognitive capabilities, both in terms of accuracy and empathy.

{{</citation>}}


### (44/50) Enhancing Human Experience in Human-Agent Collaboration: A Human-Centered Modeling Approach Based on Positive Human Gain (Yiming Gao et al., 2024)

{{<citation>}}

Yiming Gao, Feiyu Liu, Liang Wang, Zhenjie Lian, Dehua Zheng, Weixuan Wang, Wenjin Yang, Siqin Li, Xianliang Wang, Wenhui Chen, Jing Dai, Qiang Fu, Wei Yang, Lanxiao Huang, Wei Liu. (2024)  
**Enhancing Human Experience in Human-Agent Collaboration: A Human-Centered Modeling Approach Based on Positive Human Gain**  

---
Primary Category: cs.HC  
Categories: cs-AI, cs-HC, cs.HC  
Keywords: AI, Reinforcement Learning  
[Paper Link](http://arxiv.org/abs/2401.16444v1)  

---


**ABSTRACT**  
Existing game AI research mainly focuses on enhancing agents' abilities to win games, but this does not inherently make humans have a better experience when collaborating with these agents. For example, agents may dominate the collaboration and exhibit unintended or detrimental behaviors, leading to poor experiences for their human partners. In other words, most game AI agents are modeled in a "self-centered" manner. In this paper, we propose a "human-centered" modeling scheme for collaborative agents that aims to enhance the experience of humans. Specifically, we model the experience of humans as the goals they expect to achieve during the task. We expect that agents should learn to enhance the extent to which humans achieve these goals while maintaining agents' original abilities (e.g., winning games). To achieve this, we propose the Reinforcement Learning from Human Gain (RLHG) approach. The RLHG approach introduces a "baseline", which corresponds to the extent to which humans primitively achieve their goals, and encourages agents to learn behaviors that can effectively enhance humans in achieving their goals better. We evaluate the RLHG agent in the popular Multi-player Online Battle Arena (MOBA) game, Honor of Kings, by conducting real-world human-agent tests. Both objective performance and subjective preference results show that the RLHG agent provides participants better gaming experience.

{{</citation>}}


## stat.CO (1)



### (45/50) Ensemble-Based Annealed Importance Sampling (Haoxuan Chen et al., 2024)

{{<citation>}}

Haoxuan Chen, Lexing Ying. (2024)  
**Ensemble-Based Annealed Importance Sampling**  

---
Primary Category: stat.CO  
Categories: 65C05, 65C40, 65C60, 62P35, cs-LG, cs-NA, math-NA, physics-comp-ph, stat-CO, stat-ML, stat.CO  
Keywords: AI  
[Paper Link](http://arxiv.org/abs/2401.15645v1)  

---


**ABSTRACT**  
Sampling from a multimodal distribution is a fundamental and challenging problem in computational science and statistics. Among various approaches proposed for this task, one popular method is Annealed Importance Sampling (AIS). In this paper, we propose an ensemble-based version of AIS by combining it with population-based Monte Carlo methods to improve its efficiency. By keeping track of an ensemble instead of a single particle along some continuation path between the starting distribution and the target distribution, we take advantage of the interaction within the ensemble to encourage the exploration of undiscovered modes. Specifically, our main idea is to utilize either the snooker algorithm or the genetic algorithm used in Evolutionary Monte Carlo. We discuss how the proposed algorithm can be implemented and derive a partial differential equation governing the evolution of the ensemble under the continuous time and mean-field limit. We also test the efficiency of the proposed algorithm on various continuous and discrete distributions.

{{</citation>}}


## astro-ph.HE (1)



### (46/50) Deep Learning for Gamma-Ray Bursts: A data driven event framework for X/Gamma-Ray analysis in space telescopes (Riccardo Crupi, 2024)

{{<citation>}}

Riccardo Crupi. (2024)  
**Deep Learning for Gamma-Ray Bursts: A data driven event framework for X/Gamma-Ray analysis in space telescopes**  

---
Primary Category: astro-ph.HE  
Categories: astro-ph-HE, astro-ph.HE, cs-LG  
Keywords: AI  
[Paper Link](http://arxiv.org/abs/2401.15632v1)  

---


**ABSTRACT**  
This thesis comprises the first three chapters dedicated to providing an overview of Gamma Ray-Bursts (GRBs), their properties, the instrumentation used to detect them, and Artificial Intelligence (AI) applications in the context of GRBs, including a literature review and future prospects. Considering both the current and the next generation of high X-ray monitors, such as Fermi-GBM and HERMES Pathfinder (an in-orbit demonstration of six 3U nano-satellites), the research question revolves around the detection of long and faint high-energy transients, potentially GRBs, that might have been missed by previous detection algorithms. To address this, two chapters introduce a new data-driven framework, DeepGRB.   In Chapter 4, a Neural Network (NN) is described for background count rate estimation for X/gamma-ray detectors, providing a performance evaluation in different periods, including both solar maxima, solar minima periods, and one containing an ultra-long GRB. The application of eXplainable Artificial Intelligence (XAI) is performed for global and local feature importance analysis to better understand the behavior of the NN.   Chapter 5 employs FOCuS-Poisson for anomaly detection in count rate observations and estimation from the NN. DeepGRB demonstrates its capability to process Fermi-GBM data, confirming cataloged events and identifying new ones, providing further analysis with estimates for localization, duration, and classification. The chapter concludes with an automated classification method using Machine Learning techniques that incorporates XAI for eventual bias identification.

{{</citation>}}


## cs.CR (1)



### (47/50) Generative AI-enabled Blockchain Networks: Fundamentals, Applications, and Case Study (Cong T. Nguyen et al., 2024)

{{<citation>}}

Cong T. Nguyen, Yinqiu Liu, Hongyang Du, Dinh Thai Hoang, Dusit Niyato, Diep N. Nguyen, Shiwen Mao. (2024)  
**Generative AI-enabled Blockchain Networks: Fundamentals, Applications, and Case Study**  

---
Primary Category: cs.CR  
Categories: cs-AI, cs-CR, cs.CR  
Keywords: AI, Generative AI  
[Paper Link](http://arxiv.org/abs/2401.15625v1)  

---


**ABSTRACT**  
Generative Artificial Intelligence (GAI) has recently emerged as a promising solution to address critical challenges of blockchain technology, including scalability, security, privacy, and interoperability. In this paper, we first introduce GAI techniques, outline their applications, and discuss existing solutions for integrating GAI into blockchains. Then, we discuss emerging solutions that demonstrate the effectiveness of GAI in addressing various challenges of blockchain, such as detecting unknown blockchain attacks and smart contract vulnerabilities, designing key secret sharing schemes, and enhancing privacy. Moreover, we present a case study to demonstrate that GAI, specifically the generative diffusion model, can be employed to optimize blockchain network performance metrics. Experimental results clearly show that, compared to a baseline traditional AI approach, the proposed generative diffusion model approach can converge faster, achieve higher rewards, and significantly improve the throughput and latency of the blockchain network. Additionally, we highlight future research directions for GAI in blockchain applications, including personalized GAI-enabled blockchains, GAI-blockchain synergy, and privacy and security considerations within blockchain ecosystems.

{{</citation>}}


## cs.AI (1)



### (48/50) SNAP: Semantic Stories for Next Activity Prediction (Alon Oved et al., 2024)

{{<citation>}}

Alon Oved, Segev Shlomov, Sergey Zeltyn, Nir Mashkif, Avi Yaeli. (2024)  
**SNAP: Semantic Stories for Next Activity Prediction**  

---
Primary Category: cs.AI  
Categories: cs-AI, cs.AI  
Keywords: AI  
[Paper Link](http://arxiv.org/abs/2401.15621v1)  

---


**ABSTRACT**  
Predicting the next activity in an ongoing process is one of the most common classification tasks in the business process management (BPM) domain. It allows businesses to optimize resource allocation, enhance operational efficiency, and aids in risk mitigation and strategic decision-making. This provides a competitive edge in the rapidly evolving confluence of BPM and AI. Existing state-of-the-art AI models for business process prediction do not fully capitalize on available semantic information within process event logs. As current advanced AI-BPM systems provide semantically-richer textual data, the need for novel adequate models grows. To address this gap, we propose the novel SNAP method that leverages language foundation models by constructing semantic contextual stories from the process historical event logs and using them for the next activity prediction. We compared the SNAP algorithm with nine state-of-the-art models on six benchmark datasets and show that SNAP significantly outperforms them, especially for datasets with high levels of semantic content.

{{</citation>}}


## cs.SE (1)



### (49/50) OMPGPT: A Generative Pre-trained Transformer Model for OpenMP (Le Chen et al., 2024)

{{<citation>}}

Le Chen, Arijit Bhattacharjee, Nesreen Ahmed, Niranjan Hasabnis, Gal Oren, Vy Vo, Ali Jannesari. (2024)  
**OMPGPT: A Generative Pre-trained Transformer Model for OpenMP**  

---
Primary Category: cs.SE  
Categories: cs-DC, cs-LG, cs-SE, cs.SE  
Keywords: ChatGPT, GPT, NLP, Transformer  
[Paper Link](http://arxiv.org/abs/2401.16445v1)  

---


**ABSTRACT**  
Large language models (LLMs), as epitomized by models like ChatGPT, have revolutionized the field of natural language processing (NLP). Along with this trend, code-based large language models such as StarCoder, WizardCoder, and CodeLlama have emerged, trained extensively on vast repositories of code data. Yet, inherent in their design, these models primarily focus on generative tasks like code generation, code completion, and comment generation, and general support for multiple programming languages. While the generic abilities of code LLMs are useful for many programmers, the area of high-performance computing (HPC) has a narrower set of requirements that make a smaller and more domain-specific LM a smarter choice. This paper introduces OMPGPT, a novel model meticulously designed to harness the inherent strengths of language models for OpenMP pragma generation. Furthermore, we adopt and adapt prompt engineering techniques from the NLP domain to create chain-of-OMP, an innovative strategy designed to enhance OMPGPT's effectiveness. Our extensive evaluations demonstrate that OMPGPT outperforms existing large language models specialized in OpenMP tasks and maintains a notably smaller size, aligning it more closely with the typical hardware constraints of HPC environments. We consider our contribution as a pivotal bridge, connecting the advantage of language models with the specific demands of HPC tasks. The success of OMPGPT lays a solid foundation, suggesting its potential applicability and adaptability to a wider range of HPC tasks, thereby opening new avenues in the field of computational efficiency and effectiveness.

{{</citation>}}


## cs.DC (1)



### (50/50) Stitching Satellites to the Edge: Pervasive and Efficient Federated LEO Satellite Learning (Mohamed Elmahallawy et al., 2024)

{{<citation>}}

Mohamed Elmahallawy, Tie Luo. (2024)  
**Stitching Satellites to the Edge: Pervasive and Efficient Federated LEO Satellite Learning**  

---
Primary Category: cs.DC  
Categories: cs-DC, cs-LG, cs.DC  
Keywords: AI  
[Paper Link](http://arxiv.org/abs/2401.15541v1)  

---


**ABSTRACT**  
In the ambitious realm of space AI, the integration of federated learning (FL) with low Earth orbit (LEO) satellite constellations holds immense promise. However, many challenges persist in terms of feasibility, learning efficiency, and convergence. These hurdles stem from the bottleneck in communication, characterized by sporadic and irregular connectivity between LEO satellites and ground stations, coupled with the limited computation capability of satellite edge computing (SEC). This paper proposes a novel FL-SEC framework that empowers LEO satellites to execute large-scale machine learning (ML) tasks onboard efficiently. Its key components include i) personalized learning via divide-and-conquer, which identifies and eliminates redundant satellite images and converts complex multi-class classification problems to simple binary classification, enabling rapid and energy-efficient training of lightweight ML models suitable for IoT/edge devices on satellites; ii) orbital model retraining, which generates an aggregated "orbital model" per orbit and retrains it before sending to the ground station, significantly reducing the required communication rounds. We conducted experiments using Jetson Nano, an edge device closely mimicking the limited compute on LEO satellites, and a real satellite dataset. The results underscore the effectiveness of our approach, highlighting SEC's ability to run lightweight ML models on real and high-resolution satellite imagery. Our approach dramatically reduces FL convergence time by nearly 30 times, and satellite energy consumption down to as low as 1.38 watts, all while maintaining an exceptional accuracy of up to 96%.

{{</citation>}}
