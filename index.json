[{"categories":null,"contents":"Este archivo existe únicamente para responder a la URL /search con la plantilla de diseño search relacionada.\nNo se muestra ningún contenido aquí, todo el contenido se basa en la plantilla layouts/page/search.html\nEstablecer una prioridad muy baja en el mapa del sitio le dirá a los motores de búsqueda que éste no es un contenido importante.\nEsta implementación utiliza Fusejs, jquery y mark.js\nConfiguración inicial La búsqueda depende del tipo de contenido de salida adicional de JSON en config.toml\n``` [outputs] home = [\u0026ldquo;HTML\u0026rdquo;, \u0026ldquo;JSON\u0026rdquo;] ```\nBúsqueda de archivos adicionales Para buscar campos adicionales definidos en el front matter, debes añadirlo en 2 lugares.\nEditar layouts/_default/index.JSON Esto expone los valores en /index.json: por ejemplo, para agregar categories ``` \u0026hellip; \u0026ldquo;contents\u0026rdquo;:{{ .Content | plainify | jsonify }} {{ if .Params.tags }}, \u0026ldquo;tags\u0026rdquo;:{{ .Params.tags | jsonify }}{{end}}, \u0026ldquo;categories\u0026rdquo; : {{ .Params.categories | jsonify }}, \u0026hellip; ```\nEditar las opciones de fuse.js para buscar static/js/search.js ``` keys: [ \u0026ldquo;title\u0026rdquo;, \u0026ldquo;contents\u0026rdquo;, \u0026ldquo;tags\u0026rdquo;, \u0026ldquo;categories\u0026rdquo; ] ```\n","date":"June 8, 2010","hero":null,"permalink":"https://akitenkrad.github.io/blog-akitenkrad/search/","summary":"Este archivo existe únicamente para responder a la URL /search con la plantilla de diseño search relacionada.\nNo se muestra ningún contenido aquí, todo el contenido se basa en la plantilla layouts/page/search.html\nEstablecer una prioridad muy baja en el mapa del sitio le dirá a los motores de búsqueda que éste no es un contenido importante.\nEsta implementación utiliza Fusejs, jquery y mark.js\nConfiguración inicial La búsqueda depende del tipo de contenido de salida adicional de JSON en config.","tags":null,"title":"Resultados de Búsqueda"},{"categories":null,"contents":"Este archivo existe únicamente para responder a la URL /search con la plantilla de diseño search relacionada.\nNo se muestra ningún contenido aquí, todo el contenido se basa en la plantilla layouts/page/search.html\nEstablecer una prioridad muy baja en el mapa del sitio le dirá a los motores de búsqueda que éste no es un contenido importante.\nEsta implementación utiliza Fusejs, jquery y mark.js\nConfiguración inicial La búsqueda depende del tipo de contenido de salida adicional de JSON en config.toml\n``` [outputs] home = [\u0026ldquo;HTML\u0026rdquo;, \u0026ldquo;JSON\u0026rdquo;] ```\nBúsqueda de archivos adicionales Para buscar campos adicionales definidos en el front matter, debes añadirlo en 2 lugares.\nEditar layouts/_default/index.JSON Esto expone los valores en /index.json: por ejemplo, para agregar categories ``` \u0026hellip; \u0026ldquo;contents\u0026rdquo;:{{ .Content | plainify | jsonify }} {{ if .Params.tags }}, \u0026ldquo;tags\u0026rdquo;:{{ .Params.tags | jsonify }}{{end}}, \u0026ldquo;categories\u0026rdquo; : {{ .Params.categories | jsonify }}, \u0026hellip; ```\nEditar las opciones de fuse.js para buscar static/js/search.js ``` keys: [ \u0026ldquo;title\u0026rdquo;, \u0026ldquo;contents\u0026rdquo;, \u0026ldquo;tags\u0026rdquo;, \u0026ldquo;categories\u0026rdquo; ] ```\n","date":"June 8, 2010","hero":null,"permalink":"https://akitenkrad.github.io/blog-akitenkrad/search/","summary":"Este archivo existe únicamente para responder a la URL /search con la plantilla de diseño search relacionada.\nNo se muestra ningún contenido aquí, todo el contenido se basa en la plantilla layouts/page/search.html\nEstablecer una prioridad muy baja en el mapa del sitio le dirá a los motores de búsqueda que éste no es un contenido importante.\nEsta implementación utiliza Fusejs, jquery y mark.js\nConfiguración inicial La búsqueda depende del tipo de contenido de salida adicional de JSON en config.","tags":null,"title":"Resultados de Búsqueda"},{"categories":null,"contents":"This file exists solely to respond to /search URL with the related search layout template.\nNo content shown here is rendered, all content is based in the template layouts/page/search.html\nSetting a very low sitemap priority will tell search engines this is not important content.\nThis implementation uses Fusejs, jquery and mark.js\nInitial setup Search depends on additional output content type of JSON in config.toml ``` [outputs] home = [\u0026ldquo;HTML\u0026rdquo;, \u0026ldquo;JSON\u0026rdquo;] ```\nSearching additional fileds To search additional fields defined in front matter, you must add it in 2 places.\nEdit layouts/_default/index.JSON This exposes the values in /index.json i.e. add category ``` \u0026hellip; \u0026ldquo;contents\u0026rdquo;:{{ .Content | plainify | jsonify }} {{ if .Params.tags }}, \u0026ldquo;tags\u0026rdquo;:{{ .Params.tags | jsonify }}{{end}}, \u0026ldquo;categories\u0026rdquo; : {{ .Params.categories | jsonify }}, \u0026hellip; ```\nEdit fuse.js options to Search static/js/search.js ``` keys: [ \u0026ldquo;title\u0026rdquo;, \u0026ldquo;contents\u0026rdquo;, \u0026ldquo;tags\u0026rdquo;, \u0026ldquo;categories\u0026rdquo; ] ```\n","date":"June 8, 2010","hero":null,"permalink":"https://akitenkrad.github.io/blog-akitenkrad/search/","summary":"This file exists solely to respond to /search URL with the related search layout template.\nNo content shown here is rendered, all content is based in the template layouts/page/search.html\nSetting a very low sitemap priority will tell search engines this is not important content.\nThis implementation uses Fusejs, jquery and mark.js\nInitial setup Search depends on additional output content type of JSON in config.toml ``` [outputs] home = [\u0026ldquo;HTML\u0026rdquo;, \u0026ldquo;JSON\u0026rdquo;] ```","tags":null,"title":"Search Results"},{"categories":null,"contents":"This file exists solely to respond to /search URL with the related search layout template.\nNo content shown here is rendered, all content is based in the template layouts/page/search.html\nSetting a very low sitemap priority will tell search engines this is not important content.\nThis implementation uses Fusejs, jquery and mark.js\nInitial setup Search depends on additional output content type of JSON in config.toml ``` [outputs] home = [\u0026ldquo;HTML\u0026rdquo;, \u0026ldquo;JSON\u0026rdquo;] ```\nSearching additional fileds To search additional fields defined in front matter, you must add it in 2 places.\nEdit layouts/_default/index.JSON This exposes the values in /index.json i.e. add category ``` \u0026hellip; \u0026ldquo;contents\u0026rdquo;:{{ .Content | plainify | jsonify }} {{ if .Params.tags }}, \u0026ldquo;tags\u0026rdquo;:{{ .Params.tags | jsonify }}{{end}}, \u0026ldquo;categories\u0026rdquo; : {{ .Params.categories | jsonify }}, \u0026hellip; ```\nEdit fuse.js options to Search static/js/search.js ``` keys: [ \u0026ldquo;title\u0026rdquo;, \u0026ldquo;contents\u0026rdquo;, \u0026ldquo;tags\u0026rdquo;, \u0026ldquo;categories\u0026rdquo; ] ```\n","date":"June 8, 2010","hero":null,"permalink":"https://akitenkrad.github.io/blog-akitenkrad/search/","summary":"This file exists solely to respond to /search URL with the related search layout template.\nNo content shown here is rendered, all content is based in the template layouts/page/search.html\nSetting a very low sitemap priority will tell search engines this is not important content.\nThis implementation uses Fusejs, jquery and mark.js\nInitial setup Search depends on additional output content type of JSON in config.toml ``` [outputs] home = [\u0026ldquo;HTML\u0026rdquo;, \u0026ldquo;JSON\u0026rdquo;] ```","tags":null,"title":"Search Results"},{"categories":null,"contents":"This file exists solely to respond to /search URL with the related search layout template.\nNo content shown here is rendered, all content is based in the template layouts/page/search.html\nSetting a very low sitemap priority will tell search engines this is not important content.\nThis implementation uses Fusejs, jquery and mark.js\nInitial setup Search depends on additional output content type of JSON in config.toml ``` [outputs] home = [\u0026ldquo;HTML\u0026rdquo;, \u0026ldquo;JSON\u0026rdquo;] ```\nSearching additional fileds To search additional fields defined in front matter, you must add it in 2 places.\nEdit layouts/_default/index.JSON This exposes the values in /index.json i.e. add category ``` \u0026hellip; \u0026ldquo;contents\u0026rdquo;:{{ .Content | plainify | jsonify }} {{ if .Params.tags }}, \u0026ldquo;tags\u0026rdquo;:{{ .Params.tags | jsonify }}{{end}}, \u0026ldquo;categories\u0026rdquo; : {{ .Params.categories | jsonify }}, \u0026hellip; ```\nEdit fuse.js options to Search static/js/search.js ``` keys: [ \u0026ldquo;title\u0026rdquo;, \u0026ldquo;contents\u0026rdquo;, \u0026ldquo;tags\u0026rdquo;, \u0026ldquo;categories\u0026rdquo; ] ```\n","date":"June 8, 2010","hero":null,"permalink":"https://akitenkrad.github.io/blog-akitenkrad/search/","summary":"This file exists solely to respond to /search URL with the related search layout template.\nNo content shown here is rendered, all content is based in the template layouts/page/search.html\nSetting a very low sitemap priority will tell search engines this is not important content.\nThis implementation uses Fusejs, jquery and mark.js\nInitial setup Search depends on additional output content type of JSON in config.toml ``` [outputs] home = [\u0026ldquo;HTML\u0026rdquo;, \u0026ldquo;JSON\u0026rdquo;] ```","tags":null,"title":"Search Results"},{"categories":null,"contents":"This file exists solely to respond to /search URL with the related search layout template.\nNo content shown here is rendered, all content is based in the template layouts/page/search.html\nSetting a very low sitemap priority will tell search engines this is not important content.\nThis implementation uses Fusejs, jquery and mark.js\nInitial setup Search depends on additional output content type of JSON in config.toml ``` [outputs] home = [\u0026ldquo;HTML\u0026rdquo;, \u0026ldquo;JSON\u0026rdquo;] ```\nSearching additional fileds To search additional fields defined in front matter, you must add it in 2 places.\nEdit layouts/_default/index.JSON This exposes the values in /index.json i.e. add category ``` \u0026hellip; \u0026ldquo;contents\u0026rdquo;:{{ .Content | plainify | jsonify }} {{ if .Params.tags }}, \u0026ldquo;tags\u0026rdquo;:{{ .Params.tags | jsonify }}{{end}}, \u0026ldquo;categories\u0026rdquo; : {{ .Params.categories | jsonify }}, \u0026hellip; ```\nEdit fuse.js options to Search static/js/search.js ``` keys: [ \u0026ldquo;title\u0026rdquo;, \u0026ldquo;contents\u0026rdquo;, \u0026ldquo;tags\u0026rdquo;, \u0026ldquo;categories\u0026rdquo; ] ```\n","date":"June 8, 2010","hero":null,"permalink":"https://akitenkrad.github.io/blog-akitenkrad/search/","summary":"This file exists solely to respond to /search URL with the related search layout template.\nNo content shown here is rendered, all content is based in the template layouts/page/search.html\nSetting a very low sitemap priority will tell search engines this is not important content.\nThis implementation uses Fusejs, jquery and mark.js\nInitial setup Search depends on additional output content type of JSON in config.toml ``` [outputs] home = [\u0026ldquo;HTML\u0026rdquo;, \u0026ldquo;JSON\u0026rdquo;] ```","tags":null,"title":"Search Results"},{"categories":null,"contents":"This file exists solely to respond to /search URL with the related search layout template.\nNo content shown here is rendered, all content is based in the template layouts/page/search.html\nSetting a very low sitemap priority will tell search engines this is not important content.\nThis implementation uses Fusejs, jquery and mark.js\nInitial setup Search depends on additional output content type of JSON in config.toml ``` [outputs] home = [\u0026ldquo;HTML\u0026rdquo;, \u0026ldquo;JSON\u0026rdquo;] ```\nSearching additional fileds To search additional fields defined in front matter, you must add it in 2 places.\nEdit layouts/_default/index.JSON This exposes the values in /index.json i.e. add category ``` \u0026hellip; \u0026ldquo;contents\u0026rdquo;:{{ .Content | plainify | jsonify }} {{ if .Params.tags }}, \u0026ldquo;tags\u0026rdquo;:{{ .Params.tags | jsonify }}{{end}}, \u0026ldquo;categories\u0026rdquo; : {{ .Params.categories | jsonify }}, \u0026hellip; ```\nEdit fuse.js options to Search static/js/search.js ``` keys: [ \u0026ldquo;title\u0026rdquo;, \u0026ldquo;contents\u0026rdquo;, \u0026ldquo;tags\u0026rdquo;, \u0026ldquo;categories\u0026rdquo; ] ```\n","date":"June 8, 2010","hero":null,"permalink":"https://akitenkrad.github.io/blog-akitenkrad/search/","summary":"This file exists solely to respond to /search URL with the related search layout template.\nNo content shown here is rendered, all content is based in the template layouts/page/search.html\nSetting a very low sitemap priority will tell search engines this is not important content.\nThis implementation uses Fusejs, jquery and mark.js\nInitial setup Search depends on additional output content type of JSON in config.toml ``` [outputs] home = [\u0026ldquo;HTML\u0026rdquo;, \u0026ldquo;JSON\u0026rdquo;] ```","tags":null,"title":"Search Results"},{"categories":null,"contents":"This file exists solely to respond to /search URL with the related search layout template.\nNo content shown here is rendered, all content is based in the template layouts/page/search.html\nSetting a very low sitemap priority will tell search engines this is not important content.\nThis implementation uses Fusejs, jquery and mark.js\nInitial setup Search depends on additional output content type of JSON in config.toml ``` [outputs] home = [\u0026ldquo;HTML\u0026rdquo;, \u0026ldquo;JSON\u0026rdquo;] ```\nSearching additional fileds To search additional fields defined in front matter, you must add it in 2 places.\nEdit layouts/_default/index.JSON This exposes the values in /index.json i.e. add category ``` \u0026hellip; \u0026ldquo;contents\u0026rdquo;:{{ .Content | plainify | jsonify }} {{ if .Params.tags }}, \u0026ldquo;tags\u0026rdquo;:{{ .Params.tags | jsonify }}{{end}}, \u0026ldquo;categories\u0026rdquo; : {{ .Params.categories | jsonify }}, \u0026hellip; ```\nEdit fuse.js options to Search static/js/search.js ``` keys: [ \u0026ldquo;title\u0026rdquo;, \u0026ldquo;contents\u0026rdquo;, \u0026ldquo;tags\u0026rdquo;, \u0026ldquo;categories\u0026rdquo; ] ```\n","date":"June 8, 2010","hero":null,"permalink":"https://akitenkrad.github.io/blog-akitenkrad/search/","summary":"This file exists solely to respond to /search URL with the related search layout template.\nNo content shown here is rendered, all content is based in the template layouts/page/search.html\nSetting a very low sitemap priority will tell search engines this is not important content.\nThis implementation uses Fusejs, jquery and mark.js\nInitial setup Search depends on additional output content type of JSON in config.toml ``` [outputs] home = [\u0026ldquo;HTML\u0026rdquo;, \u0026ldquo;JSON\u0026rdquo;] ```","tags":null,"title":"Search Results"},{"categories":null,"contents":"This file exists solely to respond to /search URL with the related search layout template.\nNo content shown here is rendered, all content is based in the template layouts/page/search.html\nSetting a very low sitemap priority will tell search engines this is not important content.\nThis implementation uses Fusejs, jquery and mark.js\nInitial setup Search depends on additional output content type of JSON in config.toml ``` [outputs] home = [\u0026ldquo;HTML\u0026rdquo;, \u0026ldquo;JSON\u0026rdquo;] ```\nSearching additional fileds To search additional fields defined in front matter, you must add it in 2 places.\nEdit layouts/_default/index.JSON This exposes the values in /index.json i.e. add category ``` \u0026hellip; \u0026ldquo;contents\u0026rdquo;:{{ .Content | plainify | jsonify }} {{ if .Params.tags }}, \u0026ldquo;tags\u0026rdquo;:{{ .Params.tags | jsonify }}{{end}}, \u0026ldquo;categories\u0026rdquo; : {{ .Params.categories | jsonify }}, \u0026hellip; ```\nEdit fuse.js options to Search static/js/search.js ``` keys: [ \u0026ldquo;title\u0026rdquo;, \u0026ldquo;contents\u0026rdquo;, \u0026ldquo;tags\u0026rdquo;, \u0026ldquo;categories\u0026rdquo; ] ```\n","date":"June 8, 2010","hero":null,"permalink":"https://akitenkrad.github.io/blog-akitenkrad/search/","summary":"This file exists solely to respond to /search URL with the related search layout template.\nNo content shown here is rendered, all content is based in the template layouts/page/search.html\nSetting a very low sitemap priority will tell search engines this is not important content.\nThis implementation uses Fusejs, jquery and mark.js\nInitial setup Search depends on additional output content type of JSON in config.toml ``` [outputs] home = [\u0026ldquo;HTML\u0026rdquo;, \u0026ldquo;JSON\u0026rdquo;] ```","tags":null,"title":"Search Results"},{"categories":null,"contents":"This file exists solely to respond to /search URL with the related search layout template.\nNo content shown here is rendered, all content is based in the template layouts/page/search.html\nSetting a very low sitemap priority will tell search engines this is not important content.\nThis implementation uses Fusejs, jquery and mark.js\nInitial setup Search depends on additional output content type of JSON in config.toml ``` [outputs] home = [\u0026ldquo;HTML\u0026rdquo;, \u0026ldquo;JSON\u0026rdquo;] ```\nSearching additional fileds To search additional fields defined in front matter, you must add it in 2 places.\nEdit layouts/_default/index.JSON This exposes the values in /index.json i.e. add category ``` \u0026hellip; \u0026ldquo;contents\u0026rdquo;:{{ .Content | plainify | jsonify }} {{ if .Params.tags }}, \u0026ldquo;tags\u0026rdquo;:{{ .Params.tags | jsonify }}{{end}}, \u0026ldquo;categories\u0026rdquo; : {{ .Params.categories | jsonify }}, \u0026hellip; ```\nEdit fuse.js options to Search static/js/search.js ``` keys: [ \u0026ldquo;title\u0026rdquo;, \u0026ldquo;contents\u0026rdquo;, \u0026ldquo;tags\u0026rdquo;, \u0026ldquo;categories\u0026rdquo; ] ```\n","date":"June 8, 2010","hero":null,"permalink":"https://akitenkrad.github.io/blog-akitenkrad/search/","summary":"This file exists solely to respond to /search URL with the related search layout template.\nNo content shown here is rendered, all content is based in the template layouts/page/search.html\nSetting a very low sitemap priority will tell search engines this is not important content.\nThis implementation uses Fusejs, jquery and mark.js\nInitial setup Search depends on additional output content type of JSON in config.toml ``` [outputs] home = [\u0026ldquo;HTML\u0026rdquo;, \u0026ldquo;JSON\u0026rdquo;] ```","tags":null,"title":"Search Results"},{"categories":null,"contents":"This file exists solely to respond to /search URL with the related search layout template.\nNo content shown here is rendered, all content is based in the template layouts/page/search.html\nSetting a very low sitemap priority will tell search engines this is not important content.\nThis implementation uses Fusejs, jquery and mark.js\nInitial setup Search depends on additional output content type of JSON in config.toml ``` [outputs] home = [\u0026ldquo;HTML\u0026rdquo;, \u0026ldquo;JSON\u0026rdquo;] ```\nSearching additional fileds To search additional fields defined in front matter, you must add it in 2 places.\nEdit layouts/_default/index.JSON This exposes the values in /index.json i.e. add category ``` \u0026hellip; \u0026ldquo;contents\u0026rdquo;:{{ .Content | plainify | jsonify }} {{ if .Params.tags }}, \u0026ldquo;tags\u0026rdquo;:{{ .Params.tags | jsonify }}{{end}}, \u0026ldquo;categories\u0026rdquo; : {{ .Params.categories | jsonify }}, \u0026hellip; ```\nEdit fuse.js options to Search static/js/search.js ``` keys: [ \u0026ldquo;title\u0026rdquo;, \u0026ldquo;contents\u0026rdquo;, \u0026ldquo;tags\u0026rdquo;, \u0026ldquo;categories\u0026rdquo; ] ```\n","date":"June 8, 2010","hero":null,"permalink":"https://akitenkrad.github.io/blog-akitenkrad/search/","summary":"This file exists solely to respond to /search URL with the related search layout template.\nNo content shown here is rendered, all content is based in the template layouts/page/search.html\nSetting a very low sitemap priority will tell search engines this is not important content.\nThis implementation uses Fusejs, jquery and mark.js\nInitial setup Search depends on additional output content type of JSON in config.toml ``` [outputs] home = [\u0026ldquo;HTML\u0026rdquo;, \u0026ldquo;JSON\u0026rdquo;] ```","tags":null,"title":"Search Results"},{"categories":null,"contents":"This file exists solely to respond to /search URL with the related search layout template.\nNo content shown here is rendered, all content is based in the template layouts/page/search.html\nSetting a very low sitemap priority will tell search engines this is not important content.\nThis implementation uses Fusejs, jquery and mark.js\nInitial setup Search depends on additional output content type of JSON in config.toml ``` [outputs] home = [\u0026ldquo;HTML\u0026rdquo;, \u0026ldquo;JSON\u0026rdquo;] ```\nSearching additional fileds To search additional fields defined in front matter, you must add it in 2 places.\nEdit layouts/_default/index.JSON This exposes the values in /index.json i.e. add category ``` \u0026hellip; \u0026ldquo;contents\u0026rdquo;:{{ .Content | plainify | jsonify }} {{ if .Params.tags }}, \u0026ldquo;tags\u0026rdquo;:{{ .Params.tags | jsonify }}{{end}}, \u0026ldquo;categories\u0026rdquo; : {{ .Params.categories | jsonify }}, \u0026hellip; ```\nEdit fuse.js options to Search static/js/search.js ``` keys: [ \u0026ldquo;title\u0026rdquo;, \u0026ldquo;contents\u0026rdquo;, \u0026ldquo;tags\u0026rdquo;, \u0026ldquo;categories\u0026rdquo; ] ```\n","date":"June 8, 2010","hero":null,"permalink":"https://akitenkrad.github.io/blog-akitenkrad/search/","summary":"This file exists solely to respond to /search URL with the related search layout template.\nNo content shown here is rendered, all content is based in the template layouts/page/search.html\nSetting a very low sitemap priority will tell search engines this is not important content.\nThis implementation uses Fusejs, jquery and mark.js\nInitial setup Search depends on additional output content type of JSON in config.toml ``` [outputs] home = [\u0026ldquo;HTML\u0026rdquo;, \u0026ldquo;JSON\u0026rdquo;] ```","tags":null,"title":"Search Results"},{"categories":null,"contents":"This file exists solely to respond to /search URL with the related search layout template.\nNo content shown here is rendered, all content is based in the template layouts/page/search.html\nSetting a very low sitemap priority will tell search engines this is not important content.\nThis implementation uses Fusejs, jquery and mark.js\nInitial setup Search depends on additional output content type of JSON in config.toml ``` [outputs] home = [\u0026ldquo;HTML\u0026rdquo;, \u0026ldquo;JSON\u0026rdquo;] ```\nSearching additional fileds To search additional fields defined in front matter, you must add it in 2 places.\nEdit layouts/_default/index.JSON This exposes the values in /index.json i.e. add category ``` \u0026hellip; \u0026ldquo;contents\u0026rdquo;:{{ .Content | plainify | jsonify }} {{ if .Params.tags }}, \u0026ldquo;tags\u0026rdquo;:{{ .Params.tags | jsonify }}{{end}}, \u0026ldquo;categories\u0026rdquo; : {{ .Params.categories | jsonify }}, \u0026hellip; ```\nEdit fuse.js options to Search static/js/search.js ``` keys: [ \u0026ldquo;title\u0026rdquo;, \u0026ldquo;contents\u0026rdquo;, \u0026ldquo;tags\u0026rdquo;, \u0026ldquo;categories\u0026rdquo; ] ```\n","date":"June 8, 2010","hero":null,"permalink":"https://akitenkrad.github.io/blog-akitenkrad/search/","summary":"This file exists solely to respond to /search URL with the related search layout template.\nNo content shown here is rendered, all content is based in the template layouts/page/search.html\nSetting a very low sitemap priority will tell search engines this is not important content.\nThis implementation uses Fusejs, jquery and mark.js\nInitial setup Search depends on additional output content type of JSON in config.toml ``` [outputs] home = [\u0026ldquo;HTML\u0026rdquo;, \u0026ldquo;JSON\u0026rdquo;] ```","tags":null,"title":"Search Results"},{"categories":null,"contents":"This file exists solely to respond to /search URL with the related search layout template.\nNo content shown here is rendered, all content is based in the template layouts/page/search.html\nSetting a very low sitemap priority will tell search engines this is not important content.\nThis implementation uses Fusejs, jquery and mark.js\nInitial setup Search depends on additional output content type of JSON in config.toml ``` [outputs] home = [\u0026ldquo;HTML\u0026rdquo;, \u0026ldquo;JSON\u0026rdquo;] ```\nSearching additional fileds To search additional fields defined in front matter, you must add it in 2 places.\nEdit layouts/_default/index.JSON This exposes the values in /index.json i.e. add category ``` \u0026hellip; \u0026ldquo;contents\u0026rdquo;:{{ .Content | plainify | jsonify }} {{ if .Params.tags }}, \u0026ldquo;tags\u0026rdquo;:{{ .Params.tags | jsonify }}{{end}}, \u0026ldquo;categories\u0026rdquo; : {{ .Params.categories | jsonify }}, \u0026hellip; ```\nEdit fuse.js options to Search static/js/search.js ``` keys: [ \u0026ldquo;title\u0026rdquo;, \u0026ldquo;contents\u0026rdquo;, \u0026ldquo;tags\u0026rdquo;, \u0026ldquo;categories\u0026rdquo; ] ```\n","date":"June 8, 2010","hero":null,"permalink":"https://akitenkrad.github.io/blog-akitenkrad/search/","summary":"This file exists solely to respond to /search URL with the related search layout template.\nNo content shown here is rendered, all content is based in the template layouts/page/search.html\nSetting a very low sitemap priority will tell search engines this is not important content.\nThis implementation uses Fusejs, jquery and mark.js\nInitial setup Search depends on additional output content type of JSON in config.toml ``` [outputs] home = [\u0026ldquo;HTML\u0026rdquo;, \u0026ldquo;JSON\u0026rdquo;] ```","tags":null,"title":"Search Results"},{"categories":null,"contents":"This file exists solely to respond to /search URL with the related search layout template.\nNo content shown here is rendered, all content is based in the template layouts/page/search.html\nSetting a very low sitemap priority will tell search engines this is not important content.\nThis implementation uses Fusejs, jquery and mark.js\nInitial setup Search depends on additional output content type of JSON in config.toml ``` [outputs] home = [\u0026ldquo;HTML\u0026rdquo;, \u0026ldquo;JSON\u0026rdquo;] ```\nSearching additional fileds To search additional fields defined in front matter, you must add it in 2 places.\nEdit layouts/_default/index.JSON This exposes the values in /index.json i.e. add category ``` \u0026hellip; \u0026ldquo;contents\u0026rdquo;:{{ .Content | plainify | jsonify }} {{ if .Params.tags }}, \u0026ldquo;tags\u0026rdquo;:{{ .Params.tags | jsonify }}{{end}}, \u0026ldquo;categories\u0026rdquo; : {{ .Params.categories | jsonify }}, \u0026hellip; ```\nEdit fuse.js options to Search static/js/search.js ``` keys: [ \u0026ldquo;title\u0026rdquo;, \u0026ldquo;contents\u0026rdquo;, \u0026ldquo;tags\u0026rdquo;, \u0026ldquo;categories\u0026rdquo; ] ```\n","date":"June 8, 2010","hero":null,"permalink":"https://akitenkrad.github.io/blog-akitenkrad/search/","summary":"This file exists solely to respond to /search URL with the related search layout template.\nNo content shown here is rendered, all content is based in the template layouts/page/search.html\nSetting a very low sitemap priority will tell search engines this is not important content.\nThis implementation uses Fusejs, jquery and mark.js\nInitial setup Search depends on additional output content type of JSON in config.toml ``` [outputs] home = [\u0026ldquo;HTML\u0026rdquo;, \u0026ldquo;JSON\u0026rdquo;] ```","tags":null,"title":"Search Results"},{"categories":null,"contents":"This file exists solely to respond to /search URL with the related search layout template.\nNo content shown here is rendered, all content is based in the template layouts/page/search.html\nSetting a very low sitemap priority will tell search engines this is not important content.\nThis implementation uses Fusejs, jquery and mark.js\nInitial setup Search depends on additional output content type of JSON in config.toml ``` [outputs] home = [\u0026ldquo;HTML\u0026rdquo;, \u0026ldquo;JSON\u0026rdquo;] ```\nSearching additional fileds To search additional fields defined in front matter, you must add it in 2 places.\nEdit layouts/_default/index.JSON This exposes the values in /index.json i.e. add category ``` \u0026hellip; \u0026ldquo;contents\u0026rdquo;:{{ .Content | plainify | jsonify }} {{ if .Params.tags }}, \u0026ldquo;tags\u0026rdquo;:{{ .Params.tags | jsonify }}{{end}}, \u0026ldquo;categories\u0026rdquo; : {{ .Params.categories | jsonify }}, \u0026hellip; ```\nEdit fuse.js options to Search static/js/search.js ``` keys: [ \u0026ldquo;title\u0026rdquo;, \u0026ldquo;contents\u0026rdquo;, \u0026ldquo;tags\u0026rdquo;, \u0026ldquo;categories\u0026rdquo; ] ```\n","date":"June 8, 2010","hero":null,"permalink":"https://akitenkrad.github.io/blog-akitenkrad/search/","summary":"This file exists solely to respond to /search URL with the related search layout template.\nNo content shown here is rendered, all content is based in the template layouts/page/search.html\nSetting a very low sitemap priority will tell search engines this is not important content.\nThis implementation uses Fusejs, jquery and mark.js\nInitial setup Search depends on additional output content type of JSON in config.toml ``` [outputs] home = [\u0026ldquo;HTML\u0026rdquo;, \u0026ldquo;JSON\u0026rdquo;] ```","tags":null,"title":"Search Results"},{"categories":null,"contents":"This file exists solely to respond to /search URL with the related search layout template.\nNo content shown here is rendered, all content is based in the template layouts/page/search.html\nSetting a very low sitemap priority will tell search engines this is not important content.\nThis implementation uses Fusejs, jquery and mark.js\nInitial setup Search depends on additional output content type of JSON in config.toml ``` [outputs] home = [\u0026ldquo;HTML\u0026rdquo;, \u0026ldquo;JSON\u0026rdquo;] ```\nSearching additional fileds To search additional fields defined in front matter, you must add it in 2 places.\nEdit layouts/_default/index.JSON This exposes the values in /index.json i.e. add category ``` \u0026hellip; \u0026ldquo;contents\u0026rdquo;:{{ .Content | plainify | jsonify }} {{ if .Params.tags }}, \u0026ldquo;tags\u0026rdquo;:{{ .Params.tags | jsonify }}{{end}}, \u0026ldquo;categories\u0026rdquo; : {{ .Params.categories | jsonify }}, \u0026hellip; ```\nEdit fuse.js options to Search static/js/search.js ``` keys: [ \u0026ldquo;title\u0026rdquo;, \u0026ldquo;contents\u0026rdquo;, \u0026ldquo;tags\u0026rdquo;, \u0026ldquo;categories\u0026rdquo; ] ```\n","date":"June 8, 2010","hero":null,"permalink":"https://akitenkrad.github.io/blog-akitenkrad/search/","summary":"This file exists solely to respond to /search URL with the related search layout template.\nNo content shown here is rendered, all content is based in the template layouts/page/search.html\nSetting a very low sitemap priority will tell search engines this is not important content.\nThis implementation uses Fusejs, jquery and mark.js\nInitial setup Search depends on additional output content type of JSON in config.toml ``` [outputs] home = [\u0026ldquo;HTML\u0026rdquo;, \u0026ldquo;JSON\u0026rdquo;] ```","tags":null,"title":"Search Results"},{"categories":null,"contents":"This file exists solely to respond to /search URL with the related search layout template.\nNo content shown here is rendered, all content is based in the template layouts/page/search.html\nSetting a very low sitemap priority will tell search engines this is not important content.\nThis implementation uses Fusejs, jquery and mark.js\nInitial setup Search depends on additional output content type of JSON in config.toml ``` [outputs] home = [\u0026ldquo;HTML\u0026rdquo;, \u0026ldquo;JSON\u0026rdquo;] ```\nSearching additional fileds To search additional fields defined in front matter, you must add it in 2 places.\nEdit layouts/_default/index.JSON This exposes the values in /index.json i.e. add category ``` \u0026hellip; \u0026ldquo;contents\u0026rdquo;:{{ .Content | plainify | jsonify }} {{ if .Params.tags }}, \u0026ldquo;tags\u0026rdquo;:{{ .Params.tags | jsonify }}{{end}}, \u0026ldquo;categories\u0026rdquo; : {{ .Params.categories | jsonify }}, \u0026hellip; ```\nEdit fuse.js options to Search static/js/search.js ``` keys: [ \u0026ldquo;title\u0026rdquo;, \u0026ldquo;contents\u0026rdquo;, \u0026ldquo;tags\u0026rdquo;, \u0026ldquo;categories\u0026rdquo; ] ```\n","date":"June 8, 2010","hero":null,"permalink":"https://akitenkrad.github.io/blog-akitenkrad/search/","summary":"This file exists solely to respond to /search URL with the related search layout template.\nNo content shown here is rendered, all content is based in the template layouts/page/search.html\nSetting a very low sitemap priority will tell search engines this is not important content.\nThis implementation uses Fusejs, jquery and mark.js\nInitial setup Search depends on additional output content type of JSON in config.toml ``` [outputs] home = [\u0026ldquo;HTML\u0026rdquo;, \u0026ldquo;JSON\u0026rdquo;] ```","tags":null,"title":"Search Results"},{"categories":null,"contents":"This file exists solely to respond to /search URL with the related search layout template.\nNo content shown here is rendered, all content is based in the template layouts/page/search.html\nSetting a very low sitemap priority will tell search engines this is not important content.\nThis implementation uses Fusejs, jquery and mark.js\nInitial setup Search depends on additional output content type of JSON in config.toml ``` [outputs] home = [\u0026ldquo;HTML\u0026rdquo;, \u0026ldquo;JSON\u0026rdquo;] ```\nSearching additional fileds To search additional fields defined in front matter, you must add it in 2 places.\nEdit layouts/_default/index.JSON This exposes the values in /index.json i.e. add category ``` \u0026hellip; \u0026ldquo;contents\u0026rdquo;:{{ .Content | plainify | jsonify }} {{ if .Params.tags }}, \u0026ldquo;tags\u0026rdquo;:{{ .Params.tags | jsonify }}{{end}}, \u0026ldquo;categories\u0026rdquo; : {{ .Params.categories | jsonify }}, \u0026hellip; ```\nEdit fuse.js options to Search static/js/search.js ``` keys: [ \u0026ldquo;title\u0026rdquo;, \u0026ldquo;contents\u0026rdquo;, \u0026ldquo;tags\u0026rdquo;, \u0026ldquo;categories\u0026rdquo; ] ```\n","date":"June 8, 2010","hero":null,"permalink":"https://akitenkrad.github.io/blog-akitenkrad/search/","summary":"This file exists solely to respond to /search URL with the related search layout template.\nNo content shown here is rendered, all content is based in the template layouts/page/search.html\nSetting a very low sitemap priority will tell search engines this is not important content.\nThis implementation uses Fusejs, jquery and mark.js\nInitial setup Search depends on additional output content type of JSON in config.toml ``` [outputs] home = [\u0026ldquo;HTML\u0026rdquo;, \u0026ldquo;JSON\u0026rdquo;] ```","tags":null,"title":"Search Results"},{"categories":null,"contents":"This file exists solely to respond to /search URL with the related search layout template.\nNo content shown here is rendered, all content is based in the template layouts/page/search.html\nSetting a very low sitemap priority will tell search engines this is not important content.\nThis implementation uses Fusejs, jquery and mark.js\nInitial setup Search depends on additional output content type of JSON in config.toml ``` [outputs] home = [\u0026ldquo;HTML\u0026rdquo;, \u0026ldquo;JSON\u0026rdquo;] ```\nSearching additional fileds To search additional fields defined in front matter, you must add it in 2 places.\nEdit layouts/_default/index.JSON This exposes the values in /index.json i.e. add category ``` \u0026hellip; \u0026ldquo;contents\u0026rdquo;:{{ .Content | plainify | jsonify }} {{ if .Params.tags }}, \u0026ldquo;tags\u0026rdquo;:{{ .Params.tags | jsonify }}{{end}}, \u0026ldquo;categories\u0026rdquo; : {{ .Params.categories | jsonify }}, \u0026hellip; ```\nEdit fuse.js options to Search static/js/search.js ``` keys: [ \u0026ldquo;title\u0026rdquo;, \u0026ldquo;contents\u0026rdquo;, \u0026ldquo;tags\u0026rdquo;, \u0026ldquo;categories\u0026rdquo; ] ```\n","date":"June 8, 2010","hero":null,"permalink":"https://akitenkrad.github.io/blog-akitenkrad/search/","summary":"This file exists solely to respond to /search URL with the related search layout template.\nNo content shown here is rendered, all content is based in the template layouts/page/search.html\nSetting a very low sitemap priority will tell search engines this is not important content.\nThis implementation uses Fusejs, jquery and mark.js\nInitial setup Search depends on additional output content type of JSON in config.toml ``` [outputs] home = [\u0026ldquo;HTML\u0026rdquo;, \u0026ldquo;JSON\u0026rdquo;] ```","tags":null,"title":"Search Results"},{"categories":null,"contents":"This file exists solely to respond to /search URL with the related search layout template.\nNo content shown here is rendered, all content is based in the template layouts/page/search.html\nSetting a very low sitemap priority will tell search engines this is not important content.\nThis implementation uses Fusejs, jquery and mark.js\nInitial setup Search depends on additional output content type of JSON in config.toml ``` [outputs] home = [\u0026ldquo;HTML\u0026rdquo;, \u0026ldquo;JSON\u0026rdquo;] ```\nSearching additional fileds To search additional fields defined in front matter, you must add it in 2 places.\nEdit layouts/_default/index.JSON This exposes the values in /index.json i.e. add category ``` \u0026hellip; \u0026ldquo;contents\u0026rdquo;:{{ .Content | plainify | jsonify }} {{ if .Params.tags }}, \u0026ldquo;tags\u0026rdquo;:{{ .Params.tags | jsonify }}{{end}}, \u0026ldquo;categories\u0026rdquo; : {{ .Params.categories | jsonify }}, \u0026hellip; ```\nEdit fuse.js options to Search static/js/search.js ``` keys: [ \u0026ldquo;title\u0026rdquo;, \u0026ldquo;contents\u0026rdquo;, \u0026ldquo;tags\u0026rdquo;, \u0026ldquo;categories\u0026rdquo; ] ```\n","date":"June 8, 2010","hero":null,"permalink":"https://akitenkrad.github.io/blog-akitenkrad/search/","summary":"This file exists solely to respond to /search URL with the related search layout template.\nNo content shown here is rendered, all content is based in the template layouts/page/search.html\nSetting a very low sitemap priority will tell search engines this is not important content.\nThis implementation uses Fusejs, jquery and mark.js\nInitial setup Search depends on additional output content type of JSON in config.toml ``` [outputs] home = [\u0026ldquo;HTML\u0026rdquo;, \u0026ldquo;JSON\u0026rdquo;] ```","tags":null,"title":"Search Results"},{"categories":null,"contents":"This file exists solely to respond to /search URL with the related search layout template.\nNo content shown here is rendered, all content is based in the template layouts/page/search.html\nSetting a very low sitemap priority will tell search engines this is not important content.\nThis implementation uses Fusejs, jquery and mark.js\nInitial setup Search depends on additional output content type of JSON in config.toml ``` [outputs] home = [\u0026ldquo;HTML\u0026rdquo;, \u0026ldquo;JSON\u0026rdquo;] ```\nSearching additional fileds To search additional fields defined in front matter, you must add it in 2 places.\nEdit layouts/_default/index.JSON This exposes the values in /index.json i.e. add category ``` \u0026hellip; \u0026ldquo;contents\u0026rdquo;:{{ .Content | plainify | jsonify }} {{ if .Params.tags }}, \u0026ldquo;tags\u0026rdquo;:{{ .Params.tags | jsonify }}{{end}}, \u0026ldquo;categories\u0026rdquo; : {{ .Params.categories | jsonify }}, \u0026hellip; ```\nEdit fuse.js options to Search static/js/search.js ``` keys: [ \u0026ldquo;title\u0026rdquo;, \u0026ldquo;contents\u0026rdquo;, \u0026ldquo;tags\u0026rdquo;, \u0026ldquo;categories\u0026rdquo; ] ```\n","date":"June 8, 2010","hero":null,"permalink":"https://akitenkrad.github.io/blog-akitenkrad/search/","summary":"This file exists solely to respond to /search URL with the related search layout template.\nNo content shown here is rendered, all content is based in the template layouts/page/search.html\nSetting a very low sitemap priority will tell search engines this is not important content.\nThis implementation uses Fusejs, jquery and mark.js\nInitial setup Search depends on additional output content type of JSON in config.toml ``` [outputs] home = [\u0026ldquo;HTML\u0026rdquo;, \u0026ldquo;JSON\u0026rdquo;] ```","tags":null,"title":"Search Results"},{"categories":null,"contents":"This file exists solely to respond to /search URL with the related search layout template.\nNo content shown here is rendered, all content is based in the template layouts/page/search.html\nSetting a very low sitemap priority will tell search engines this is not important content.\nThis implementation uses Fusejs, jquery and mark.js\nInitial setup Search depends on additional output content type of JSON in config.toml ``` [outputs] home = [\u0026ldquo;HTML\u0026rdquo;, \u0026ldquo;JSON\u0026rdquo;] ```\nSearching additional fileds To search additional fields defined in front matter, you must add it in 2 places.\nEdit layouts/_default/index.JSON This exposes the values in /index.json i.e. add category ``` \u0026hellip; \u0026ldquo;contents\u0026rdquo;:{{ .Content | plainify | jsonify }} {{ if .Params.tags }}, \u0026ldquo;tags\u0026rdquo;:{{ .Params.tags | jsonify }}{{end}}, \u0026ldquo;categories\u0026rdquo; : {{ .Params.categories | jsonify }}, \u0026hellip; ```\nEdit fuse.js options to Search static/js/search.js ``` keys: [ \u0026ldquo;title\u0026rdquo;, \u0026ldquo;contents\u0026rdquo;, \u0026ldquo;tags\u0026rdquo;, \u0026ldquo;categories\u0026rdquo; ] ```\n","date":"June 8, 2010","hero":null,"permalink":"https://akitenkrad.github.io/blog-akitenkrad/search/","summary":"This file exists solely to respond to /search URL with the related search layout template.\nNo content shown here is rendered, all content is based in the template layouts/page/search.html\nSetting a very low sitemap priority will tell search engines this is not important content.\nThis implementation uses Fusejs, jquery and mark.js\nInitial setup Search depends on additional output content type of JSON in config.toml ``` [outputs] home = [\u0026ldquo;HTML\u0026rdquo;, \u0026ldquo;JSON\u0026rdquo;] ```","tags":null,"title":"Search Results"},{"categories":null,"contents":"This file exists solely to respond to /search URL with the related search layout template.\nNo content shown here is rendered, all content is based in the template layouts/page/search.html\nSetting a very low sitemap priority will tell search engines this is not important content.\nThis implementation uses Fusejs, jquery and mark.js\nInitial setup Search depends on additional output content type of JSON in config.toml ``` [outputs] home = [\u0026ldquo;HTML\u0026rdquo;, \u0026ldquo;JSON\u0026rdquo;] ```\nSearching additional fileds To search additional fields defined in front matter, you must add it in 2 places.\nEdit layouts/_default/index.JSON This exposes the values in /index.json i.e. add category ``` \u0026hellip; \u0026ldquo;contents\u0026rdquo;:{{ .Content | plainify | jsonify }} {{ if .Params.tags }}, \u0026ldquo;tags\u0026rdquo;:{{ .Params.tags | jsonify }}{{end}}, \u0026ldquo;categories\u0026rdquo; : {{ .Params.categories | jsonify }}, \u0026hellip; ```\nEdit fuse.js options to Search static/js/search.js ``` keys: [ \u0026ldquo;title\u0026rdquo;, \u0026ldquo;contents\u0026rdquo;, \u0026ldquo;tags\u0026rdquo;, \u0026ldquo;categories\u0026rdquo; ] ```\n","date":"June 8, 2010","hero":null,"permalink":"https://akitenkrad.github.io/blog-akitenkrad/search/","summary":"This file exists solely to respond to /search URL with the related search layout template.\nNo content shown here is rendered, all content is based in the template layouts/page/search.html\nSetting a very low sitemap priority will tell search engines this is not important content.\nThis implementation uses Fusejs, jquery and mark.js\nInitial setup Search depends on additional output content type of JSON in config.toml ``` [outputs] home = [\u0026ldquo;HTML\u0026rdquo;, \u0026ldquo;JSON\u0026rdquo;] ```","tags":null,"title":"অনুসন্ধানের ফলাফল"},{"categories":null,"contents":"This file exists solely to respond to /search URL with the related search layout template.\nNo content shown here is rendered, all content is based in the template layouts/page/search.html\nSetting a very low sitemap priority will tell search engines this is not important content.\nThis implementation uses Fusejs, jquery and mark.js\nInitial setup Search depends on additional output content type of JSON in config.toml ``` [outputs] home = [\u0026ldquo;HTML\u0026rdquo;, \u0026ldquo;JSON\u0026rdquo;] ```\nSearching additional fileds To search additional fields defined in front matter, you must add it in 2 places.\nEdit layouts/_default/index.JSON This exposes the values in /index.json i.e. add category ``` \u0026hellip; \u0026ldquo;contents\u0026rdquo;:{{ .Content | plainify | jsonify }} {{ if .Params.tags }}, \u0026ldquo;tags\u0026rdquo;:{{ .Params.tags | jsonify }}{{end}}, \u0026ldquo;categories\u0026rdquo; : {{ .Params.categories | jsonify }}, \u0026hellip; ```\nEdit fuse.js options to Search static/js/search.js ``` keys: [ \u0026ldquo;title\u0026rdquo;, \u0026ldquo;contents\u0026rdquo;, \u0026ldquo;tags\u0026rdquo;, \u0026ldquo;categories\u0026rdquo; ] ```\n","date":"June 8, 2010","hero":null,"permalink":"https://akitenkrad.github.io/blog-akitenkrad/search/","summary":"This file exists solely to respond to /search URL with the related search layout template.\nNo content shown here is rendered, all content is based in the template layouts/page/search.html\nSetting a very low sitemap priority will tell search engines this is not important content.\nThis implementation uses Fusejs, jquery and mark.js\nInitial setup Search depends on additional output content type of JSON in config.toml ``` [outputs] home = [\u0026ldquo;HTML\u0026rdquo;, \u0026ldquo;JSON\u0026rdquo;] ```","tags":null,"title":"অনুসন্ধানের ফলাফল"},{"categories":null,"contents":" Round-1: Overview Round-2: Model Implementation Details Round-3: Experiments Citation Yang, L., Xiao, Z., Jiang, W., Wei, Y., Hu, Y., \u0026amp; Wang, H. (2020).\nDynamic heterogeneous graph embedding using hierarchical attentions.\nLecture Notes in Computer Science (Including Subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics), 12036 LNCS.\nhttps://doi.org/10.1007/978-3-030-45442-5_53 Abstract Graph embedding has attracted many research interests. Existing works mainly focus on static homogeneous/heterogeneous networks or dynamic homogeneous networks. However, dynamic heterogeneous networks are more ubiquitous in reality, e.g. social network, e-commerce network, citation network, etc. There is still a lack of research on dynamic heterogeneous graph embedding. In this paper, we propose a novel dynamic heterogeneous graph embedding method using hierarchical attentions (DyHAN) that learns node embeddings leveraging both structural heterogeneity and temporal evolution. We evaluate our method on three real-world datasets. The results show that DyHAN outperforms various state-of-the-art baselines in terms of link prediction task.\nWhat\u0026rsquo;s New NodeとEdgeに関するDynamicなグラフのEmbedding手法を提案 Dataset CIKM 2019 EComm AI: User Behavior Diversities Prediction Higgs Twitter Dataset M. De Domenico, A. Lima, P. Mougel and M. Musolesi. The Anatomy of a Scientific Rumor. (Nature Open Access) Scientific Reports 3, 2980 (2013).\nThe Higgs dataset has been built after monitoring the spreading processes on Twitter before, during and after the announcement of the discovery of a new particle with the features of the elusive Higgs boson on 4th July 2012. The messages posted in Twitter about this discovery between 1st and 7th July 2012 are considered.\nDataset #nodes #edges #node-types #edge-types #time-steps EComm 37724 91033 2 4 11 Twitter 100000 63410 1 3 7 Alibaba.com 16620 93956 2 3 11 Model Description Architecture of DyHAN Dynamic Heterogeneous Graphsの定義 $$ \\begin{align*} \\text{Dynamic Heterogeneous Graphs}:\u0026amp; \\\\ \u0026amp; \\text{Graphs } = \\lbrace G^1, G^2, \\ldots G^T \\rbrace \\\\ \u0026amp; G^t = (\\mathcal{V}^t, \\mathcal{E}^t, \\mathcal{W}^t) \\\\ \u0026amp; \\text{where } \\mathcal{V}^t \\text{ is the node set with node type } o \\in \\mathcal{O} \\\\ \u0026amp; \\text{where } \\mathcal{E}^t \\text{ is the node set with node type } r \\in \\mathcal{R} \\\\ \u0026amp; |\\mathcal{O}| + |\\mathcal{R}| \u0026gt; 2 \\end{align*} $$\nDynamic Heterogeneous Graph Embedding は $$ f: \\mathcal{V} \\rightarrow \\mathbb{R}^d $$ を学習する．\nNode-Level Attention 時刻 $t$ におけるエッジタイプ $r$ のノードのペア $(i, j)$ の Importance Score を以下のように定義する．\n$$ \\begin{align*} \\alpha _{ij}^{rt} \u0026amp;= \\frac{\\exp{\\left(\\sigma\\left(a_r^{\\mathsf{T}}\\lbrack W_{nl}^rx_i || W_{nl}^rx_j\\rbrack\\right)\\right)}}{\\sum_{k \\in N_i^{rt}}\\exp{\\left(\\sigma\\left(a_r^{\\mathsf{T}}\\lbrack W_{nl}^rx_i || W_{nl}^rx_k\\rbrack\\right)\\right)}} \\in \\mathbb{R} \\\\ \\text{where }\u0026amp; \\\\ || \\mapsto \u0026amp;\\text{ concatenation} \\\\ x_i \u0026amp;\\in \\mathbb{R}^d \\\\ N_i^{rt} \u0026amp;\\mapsto \\text{sampled naighbor nodes for node } i \\text{ for edge type } r \\text{ and time stemp }r \\\\ W_{nl}^r \u0026amp;\\in \\mathbb{R}^{d \\times d} \\hspace{10pt} \\text{(parameter)} \\\\ a_r \u0026amp;\\in \\mathbb{R}^{2d} \\hspace{10pt} \\text{(parameter / node-level attention vector)} \\end{align*} $$\nImportance Scoreにより，時刻 $t$ におけるエッジタイプ $r$ のノード $i$ のEmbeddingは以下のように計算される．\n$$ h_i^{rt} = \\sigma\\left(\\sum_{j \\in N_i^{rt}}\\alpha_{ij}^{rt} \\cdot W_{nl}^rx_j\\right) \\in \\mathbb{R}^d $$\nEdge-Level Attention Hegerogeneous Graph において，同じタイプのエッジを共有するノードのEmbeddingの集合は，他のエッジタイプの集合と比較して区別できるような特徴を持っていると考えられる．\nそこで，このようなエッジの特徴を集約することを考える．\n時刻 $t$ におけるノード $i$ に関して，エッジタイプ $r$ の Importance Score を以下のように one-layer MLP で定式化する．\n$$ \\begin{align*} \\beta _i^{rt} \u0026amp;= \\frac{\\exp \\left(q^{\\mathsf{T}} \\cdot \\sigma \\left(W_{el}h_i^{rt} + b_{el}\\right)\\right)}{\\sum_{l=1}^R \\exp \\left(q^{\\mathsf{T}} \\cdot \\sigma \\left(W_{el}h_i^{lt} + b_{el}\\right)\\right)} \\in \\mathbb{R} \\\\ \\text{where }\u0026amp; \\\\ q \u0026amp;\\in \\mathbb{R}^d \\hspace{10pt} \\text{(parameter/edge-level attention vector)} \\\\ W_{el} \u0026amp;\\in \\mathbb{R}^{d \\times d} \\hspace{10pt} \\text{(parameter)} \\\\ b_{el} \u0026amp;\\in \\mathbb{R}^d \\hspace{10pt} \\text{(bias)} \\end{align*} $$\nImportance Scoreにより，時刻 $t$ におけるノード $i$ に関するエッジのEmbeddingは以下のように計算される．\n$$ h_i^t = \\sum_{r=1}^R \\beta _i^{rt} \\cdot h_i^{rt} \\in \\mathbb{R}^d $$\nTempral-Level Attention ノードのEmbeddingを計算後，時系列でそれらのEmbeddingを時刻 $T$ に集約する．\n手法は Scaled Dot-Product Attention に基づいている． Scaled Dot-Product Attention (Attention is All you Need (Ashish Vaswani et al., 2017)) Ashish Vaswani, Noam M. Shazeer, Niki Parmar, Jakob Uszkoreit, Llion Jones, Aidan N. Gomez, Lukasz Kaiser, Illia Polosukhin. (2017)\nAttention is All you Need\nNIPS\nPaper Link\nInfluential Citation Count (8450), SS-ID (204e3073870fae3d05bcbc2f6a8e263d9b72e776)\nABSTRACT\nThe dominant sequence transduction models are based on complex recurrent or convolutional neural networks in an encoder-decoder configuration. The best performing models also connect the encoder and decoder through an attention mechanism. We propose a new simple network architecture, the Transformer, based solely on attention mechanisms, dispensing with recurrence and convolutions entirely. Experiments on two machine translation tasks show these models to be superior in quality while being more parallelizable and requiring significantly less time to train. Our model achieves 28.4 BLEU on the WMT 2014 English-to-German translation task, improving over the existing best results, including ensembles by over 2 BLEU. On the WMT 2014 English-to-French translation task, our model establishes a new single-model state-of-the-art BLEU score of 41.8 after training for 3.5 days on eight GPUs, a small fraction of the training costs of the best models from the literature. We show that the Transformer generalizes well to other tasks by applying it successfully to English constituency parsing both with large and limited training data.\n$$ \\begin{align*} H_i \u0026amp;= \\lbrace h_i^1, h_i^2, \\ldots , h_i^{T-1} \\rbrace \\in \\mathbb{R}^{T \\times d} \\\\ Q \u0026amp;= H_i W_q \\\\ K \u0026amp;= H_i W_k \\\\ V \u0026amp;= H_i W_v \\\\ Z_i \u0026amp;= \\text{softmax}\\left( \\frac{QK^{\\mathsf{T}}}{\\sqrt{d\u0026rsquo;}} + M \\right) \\cdot V \\in \\mathbb{R}^{T \\times d\u0026rsquo;} \\\\ \\text{where}\u0026amp; \\\\ \u0026amp;W_q, W_k, W_v \\in \\mathbb{R}^{d \\times d\u0026rsquo;} \\hspace{10pt} \\text{(parameters)} \\\\ \u0026amp;M \\in \\mathbb{R}^{T \\times T} \\text{(a mask matrix)} \\\\ \u0026amp;M_{ij} = 0 \\hspace{10pt} \\text{if} \\hspace{5pt} i \\leq j \\hspace{10pt} \\text{else} \\hspace{3pt} -\\infty \\end{align*} $$\n$Z = \\lbrace z_i^1, z_i^2, \\ldots , z_i^T \\rbrace$ を得るので，$z_i^T$ が最終的なノードのEmbeddingとなる．\n（構造上，Multi-Head Attention に拡張することができる）\nOptimization グラフの構造及び時系列性を考慮して，最終時刻 $T$ において，近くにあるノードが似たEmbeddingを持つようにMetric Learningを実施する．\n$$ \\begin{align*} L(z_u^T) \u0026amp;= -\\log \\left( \\sigma \\left( \\left\\langle z_u^T, z_v^T \\right\\rangle \\right) \\right) - Q \\cdot \\mathbb{E}_{v_n \\sim P_n(v)}\\log \\left( \\sigma \\left( \\left\\langle -z_u^T, z_{v_n}^T \\right\\rangle \\right) \\right) \\\\ \\text{where}\u0026amp; \\\\ \u0026amp; \\langle , \\rangle \\mapsto \\text{inner product} \\\\ \u0026amp; v \\mapsto \\text{node that co-occurs near } u \\text{ on fixed-length random walk in the last time step} \\\\ \u0026amp; P_n \\mapsto \\text{negative sampling distribution (node\u0026rsquo;s degree in the last time step)} \\\\ \u0026amp; Q \\mapsto \\text{the number of negative samples} \\end{align*} $$\nTraining Settings $\\lbrace G^1, G^2, \\ldots , G^t\\rbrace$ を入力として，$G^{t+1}$ の Link Prediction を実施する 評価方法は既存研究に則る Dynamic Graph Representation Learning via Self-Attention Networks (Aravind Sankar et al., 2018) Aravind Sankar, Yanhong Wu, Liang Gou, Wei Zhang, Hao Yang. (2018)\nDynamic Graph Representation Learning via Self-Attention Networks\nArXiv\nPaper Link\nInfluential Citation Count (7), SS-ID (50a1a28d216ebf719ca1103593d5afe1e29e3ee1)\nABSTRACT\nLearning latent representations of nodes in graphs is an important and ubiquitous task with widespread applications such as link prediction, node classification, and graph visualization. Previous methods on graph representation learning mainly focus on static graphs, however, many real-world graphs are dynamic and evolve over time. In this paper, we present Dynamic Self-Attention Network (DySAT), a novel neural architecture that operates on dynamic graphs and learns node representations that capture both structural properties and temporal evolutionary patterns. Specifically, DySAT computes node representations by jointly employing self-attention layers along two dimensions: structural neighborhood and temporal dynamics. We conduct link prediction experiments on two classes of graphs: communication networks and bipartite rating networks. Our experimental results show that DySAT has a significant performance gain over several different state-of-the-art graph embedding baselines. Dynamic Network Embedding : An Extended Approach for Skip-gram based Network Embedding (Lun Du et al., 2018) Lun Du, Yun Wang, Guojie Song, Zhicong Lu, Junshan Wang. (2018)\nDynamic Network Embedding : An Extended Approach for Skip-gram based Network Embedding\nIJCAI\nPaper Link\nInfluential Citation Count (10), SS-ID (707defa78c0e5529c17fda92ce7b33f0b6674612)\nABSTRACT\nNetwork embedding, as an approach to learn low-dimensional representations of vertices, has been proved extremely useful in many applications. Lots of state-of-the-art network embedding methods based on Skip-gram framework are efficient and effective. However, these methods mainly focus on the static network embedding and cannot naturally generalize to the dynamic environment. In this paper, we propose a stable dynamic embedding framework with high efficiency. It is an extension for the Skip-gram based network embedding methods, which can keep the optimality of the objective in the Skip-gram based methods in theory. Our model can not only generalize to the new vertex representation, but also update the most affected original vertex representations during the evolvement of the network. Multi-class classification on three real-world networks demonstrates that, our model can update the vertex representations efficiently and achieve the performance of retraining simultaneously. Besides, the visualization experimental result illustrates that, our model is capable of avoiding the embedding space drifting. DyHANの出力に Logistic Regression Classifier を接続して Link Prediction 向けの予測モデルを構築 $G^{t+1}$ 時点のスナップショットから20%のエッジをハイパーパラメータチューニング向けのValidation Setとして切り出した 残りのエッジを $25:75$ に分割し，それぞれ学習データ・テストデータとして実験を実施 評価指標は ROC Curve 及び AUC Results Experimental results on three real-world datasets References Heterogeneous Graph Attention Network (Xiao Wang et al., 2019) Xiao Wang, Houye Ji, C. Shi, Bai Wang, Peng Cui, P. Yu, Yanfang Ye. (2019)\nHeterogeneous Graph Attention Network\nWWW\nPaper Link\nInfluential Citation Count (177), SS-ID (00b7efbf14a54cced4b9f19e663b70ffbd01324b)\nABSTRACT\nGraph neural network, as a powerful graph representation technique based on deep learning, has shown superior performance and attracted considerable research interest. However, it has not been fully considered in graph neural network for heterogeneous graph which contains different types of nodes and links. The heterogeneity and rich semantic information bring great challenges for designing a graph neural network for heterogeneous graph. Recently, one of the most exciting advancements in deep learning is the attention mechanism, whose great potential has been well demonstrated in various areas. In this paper, we first propose a novel heterogeneous graph neural network based on the hierarchical attention, including node-level and semantic-level attentions. Specifically, the node-level attention aims to learn the importance between a node and its meta-path based neighbors, while the semantic-level attention is able to learn the importance of different meta-paths. With the learned importance from both node-level and semantic-level attention, the importance of node and meta-path can be fully considered. Then the proposed model can generate node embedding by aggregating features from meta-path based neighbors in a hierarchical manner. Extensive experimental results on three real-world heterogeneous graphs not only show the superior performance of our proposed model over the state-of-the-arts, but also demonstrate its potentially good interpretability for graph analysis.\nRelationship Prediction in Dynamic Heterogeneous Information Networks (A. M. Fard et al., 2019) A. M. Fard, E. Bagheri, Ke Wang. (2019)\nRelationship Prediction in Dynamic Heterogeneous Information Networks\nECIR\nPaper Link\nInfluential Citation Count (0), SS-ID (06eb6cc2f68bba86e3ef5c1ece21a34687d86f29)\nABSTRACT\nLINE: Large-scale Information Network Embedding (Jian Tang et al., 2015) Jian Tang, Meng Qu, Mingzhe Wang, Ming Zhang, Jun Yan, Q. Mei. (2015)\nLINE: Large-scale Information Network Embedding\nWWW\nPaper Link\nInfluential Citation Count (861), SS-ID (0834e74304b547c9354b6d7da6fa78ef47a48fa8)\nABSTRACT\nThis paper studies the problem of embedding very large information networks into low-dimensional vector spaces, which is useful in many tasks such as visualization, node classification, and link prediction. Most existing graph embedding methods do not scale for real world information networks which usually contain millions of nodes. In this paper, we propose a novel network embedding method called the ``LINE,\u0026rsquo;\u0026rsquo; which is suitable for arbitrary types of information networks: undirected, directed, and/or weighted. The method optimizes a carefully designed objective function that preserves both the local and global network structures. An edge-sampling algorithm is proposed that addresses the limitation of the classical stochastic gradient descent and improves both the effectiveness and the efficiency of the inference. Empirical experiments prove the effectiveness of the LINE on a variety of real-world information networks, including language networks, social networks, and citation networks. The algorithm is very efficient, which is able to learn the embedding of a network with millions of vertices and billions of edges in a few hours on a typical single machine. The source code of the LINE is available online\\footnote{\\url{https://github.com/tangjianpku/LINE}}.\nDynGEM: Deep Embedding Method for Dynamic Graphs (Palash Goyal et al., 2018) Palash Goyal, Nitin Kamra, Xinran He, Yan Liu. (2018)\nDynGEM: Deep Embedding Method for Dynamic Graphs\nArXiv\nPaper Link\nInfluential Citation Count (35), SS-ID (1d49c0dd13911f44418d46ec5fac128d6c4bbf59)\nABSTRACT\nEmbedding large graphs in low dimensional spaces has recently attracted significant interest due to its wide applications such as graph visualization, link prediction and node classification. Existing methods focus on computing the embedding for static graphs. However, many graphs in practical applications are dynamic and evolve constantly over time. Naively applying existing embedding algorithms to each snapshot of dynamic graphs independently usually leads to unsatisfactory performance in terms of stability, flexibility and efficiency. In this work, we present an efficient algorithm DynGEM based on recent advances in deep autoencoders for graph embeddings, to address this problem. The major advantages of DynGEM include: (1) the embedding is stable over time, (2) it can handle growing dynamic graphs, and (3) it has better running time than using static embedding methods on each snapshot of a dynamic graph. We test DynGEM on a variety of tasks including graph visualization, graph reconstruction, link prediction and anomaly detection (on both synthetic and real datasets). Experimental results demonstrate the superior stability and scalability of our approach.\nAttention is All you Need (Ashish Vaswani et al., 2017) Ashish Vaswani, Noam M. Shazeer, Niki Parmar, Jakob Uszkoreit, Llion Jones, Aidan N. Gomez, Lukasz Kaiser, Illia Polosukhin. (2017)\nAttention is All you Need\nNIPS\nPaper Link\nInfluential Citation Count (8450), SS-ID (204e3073870fae3d05bcbc2f6a8e263d9b72e776)\nABSTRACT\nThe dominant sequence transduction models are based on complex recurrent or convolutional neural networks in an encoder-decoder configuration. The best performing models also connect the encoder and decoder through an attention mechanism. We propose a new simple network architecture, the Transformer, based solely on attention mechanisms, dispensing with recurrence and convolutions entirely. Experiments on two machine translation tasks show these models to be superior in quality while being more parallelizable and requiring significantly less time to train. Our model achieves 28.4 BLEU on the WMT 2014 English-to-German translation task, improving over the existing best results, including ensembles by over 2 BLEU. On the WMT 2014 English-to-French translation task, our model establishes a new single-model state-of-the-art BLEU score of 41.8 after training for 3.5 days on eight GPUs, a small fraction of the training costs of the best models from the literature. We show that the Transformer generalizes well to other tasks by applying it successfully to English constituency parsing both with large and limited training data.\nGraph Attention Networks (Petar Velickovic et al., 2017) Petar Velickovic, Guillem Cucurull, Arantxa Casanova, Adriana Romero, P. Lio’, Yoshua Bengio. (2017)\nGraph Attention Networks\nICLR\nPaper Link\nInfluential Citation Count (1525), SS-ID (33998aff64ce51df8dee45989cdca4b6b1329ec4)\nABSTRACT\nWe present graph attention networks (GATs), novel neural network architectures that operate on graph-structured data, leveraging masked self-attentional layers to address the shortcomings of prior methods based on graph convolutions or their approximations. By stacking layers in which nodes are able to attend over their neighborhoods\u0026rsquo; features, we enable (implicitly) specifying different weights to different nodes in a neighborhood, without requiring any kind of costly matrix operation (such as inversion) or depending on knowing the graph structure upfront. In this way, we address several key challenges of spectral-based graph neural networks simultaneously, and make our model readily applicable to inductive as well as transductive problems. Our GAT models have achieved or matched state-of-the-art results across four established transductive and inductive graph benchmarks: the Cora, Citeseer and Pubmed citation network datasets, as well as a protein-protein interaction dataset (wherein test graphs remain unseen during training).\nnode2vec: Scalable Feature Learning for Networks (Aditya Grover et al., 2016) Aditya Grover, J. Leskovec. (2016)\nnode2vec: Scalable Feature Learning for Networks\nKDD\nPaper Link\nInfluential Citation Count (1155), SS-ID (36ee2c8bd605afd48035d15fdc6b8c8842363376)\nABSTRACT\nPrediction tasks over nodes and edges in networks require careful effort in engineering features used by learning algorithms. Recent research in the broader field of representation learning has led to significant progress in automating prediction by learning the features themselves. However, present feature learning approaches are not expressive enough to capture the diversity of connectivity patterns observed in networks. Here we propose node2vec, an algorithmic framework for learning continuous feature representations for nodes in networks. In node2vec, we learn a mapping of nodes to a low-dimensional space of features that maximizes the likelihood of preserving network neighborhoods of nodes. We define a flexible notion of a node\u0026rsquo;s network neighborhood and design a biased random walk procedure, which efficiently explores diverse neighborhoods. Our algorithm generalizes prior work which is based on rigid notions of network neighborhoods, and we argue that the added flexibility in exploring neighborhoods is the key to learning richer representations. We demonstrate the efficacy of node2vec over existing state-of-the-art techniques on multi-label classification and link prediction in several real-world networks from diverse domains. Taken together, our work represents a new way for efficiently learning state-of-the-art task-independent representations in complex networks.\nSemi-Supervised Classification with Graph Convolutional Networks (Thomas Kipf et al., 2016) Thomas Kipf, M. Welling. (2016)\nSemi-Supervised Classification with Graph Convolutional Networks\nICLR\nPaper Link\nInfluential Citation Count (3468), SS-ID (36eff562f65125511b5dfab68ce7f7a943c27478)\nABSTRACT\nWe present a scalable approach for semi-supervised learning on graph-structured data that is based on an efficient variant of convolutional neural networks which operate directly on graphs. We motivate the choice of our convolutional architecture via a localized first-order approximation of spectral graph convolutions. Our model scales linearly in the number of graph edges and learns hidden layer representations that encode both local graph structure and features of nodes. In a number of experiments on citation networks and on a knowledge graph dataset we demonstrate that our approach outperforms related methods by a significant margin.\nHeterogeneous Information Network Embedding for Recommendation (C. Shi et al., 2017) C. Shi, Binbin Hu, Wayne Xin Zhao, Philip S. Yu. (2017)\nHeterogeneous Information Network Embedding for Recommendation\nIEEE Transactions on Knowledge and Data Engineering\nPaper Link\nInfluential Citation Count (45), SS-ID (378f0a62471ef232c7730d8a67717afa5104ab21)\nABSTRACT\nDue to the flexibility in modelling data heterogeneity, heterogeneous information network (HIN) has been adopted to characterize complex and heterogeneous auxiliary data in recommender systems, called HIN based recommendation. It is challenging to develop effective methods for HIN based recommendation in both extraction and exploitation of the information from HINs. Most of HIN based recommendation methods rely on path based similarity, which cannot fully mine latent structure features of users and items. In this paper, we propose a novel heterogeneous network embedding based approach for HIN based recommendation, called HERec. To embed HINs, we design a meta-path based random walk strategy to generate meaningful node sequences for network embedding. The learned node embeddings are first transformed by a set of fusion functions, and subsequently integrated into an extended matrix factorization (MF) model. The extended MF model together with fusion functions are jointly optimized for the rating prediction task. Extensive experiments on three real-world datasets demonstrate the effectiveness of the HERec model. Moreover, we show the capability of the HERec model for the cold-start problem, and reveal that the transformed embedding information from HINs can improve the recommendation performance.\nRepresentation Learning for Attributed Multiplex Heterogeneous Network (Yukuo Cen et al., 2019) Yukuo Cen, Xu Zou, Jianwei Zhang, Hongxia Yang, Jingren Zhou, Jie Tang. (2019)\nRepresentation Learning for Attributed Multiplex Heterogeneous Network\nKDD\nPaper Link\nInfluential Citation Count (27), SS-ID (3c64b7a74c749d43b1a4b96dd1a00620ba613ee0)\nABSTRACT\nNetwork embedding (or graph embedding) has been widely used in many real-world applications. However, existing methods mainly focus on networks with single-typed nodes/edges and cannot scale well to handle large networks. Many real-world networks consist of billions of nodes and edges of multiple types, and each node is associated with different attributes. In this paper, we formalize the problem of embedding learning for the Attributed Multiplex Heterogeneous Network and propose a unified framework to address this problem. The framework supports both transductive and inductive learning. We also give the theoretical analysis of the proposed framework, showing its connection with previous works and proving its better expressiveness. We conduct systematical evaluations for the proposed framework on four different genres of challenging datasets: Amazon, YouTube, Twitter, and Alibaba. Experimental results demonstrate that with the learned embeddings from the proposed framework, we can achieve statistically significant improvements (e.g., 5.99-28.23% lift by F1 scores; p\u0026laquo;0.01, t-test) over previous state-of-the-art methods for link prediction. The framework has also been successfully deployed on the recommendation system of a worldwide leading e-commerce company, Alibaba Group. Results of the offline A/B tests on product recommendation further confirm the effectiveness and efficiency of the framework in practice.\nDynamic Graph Representation Learning via Self-Attention Networks (Aravind Sankar et al., 2018) Aravind Sankar, Yanhong Wu, Liang Gou, Wei Zhang, Hao Yang. (2018)\nDynamic Graph Representation Learning via Self-Attention Networks\nArXiv\nPaper Link\nInfluential Citation Count (7), SS-ID (50a1a28d216ebf719ca1103593d5afe1e29e3ee1)\nABSTRACT\nLearning latent representations of nodes in graphs is an important and ubiquitous task with widespread applications such as link prediction, node classification, and graph visualization. Previous methods on graph representation learning mainly focus on static graphs, however, many real-world graphs are dynamic and evolve over time. In this paper, we present Dynamic Self-Attention Network (DySAT), a novel neural architecture that operates on dynamic graphs and learns node representations that capture both structural properties and temporal evolutionary patterns. Specifically, DySAT computes node representations by jointly employing self-attention layers along two dimensions: structural neighborhood and temporal dynamics. We conduct link prediction experiments on two classes of graphs: communication networks and bipartite rating networks. Our experimental results show that DySAT has a significant performance gain over several different state-of-the-art graph embedding baselines.\nInductive Representation Learning on Large Graphs (William L. Hamilton et al., 2017) William L. Hamilton, Z. Ying, J. Leskovec. (2017)\nInductive Representation Learning on Large Graphs\nNIPS\nPaper Link\nInfluential Citation Count (1380), SS-ID (6b7d6e6416343b2a122f8416e69059ce919026ef)\nABSTRACT\nLow-dimensional embeddings of nodes in large graphs have proved extremely useful in a variety of prediction tasks, from content recommendation to identifying protein functions. However, most existing approaches require that all nodes in the graph are present during training of the embeddings; these previous approaches are inherently transductive and do not naturally generalize to unseen nodes. Here we present GraphSAGE, a general, inductive framework that leverages node feature information (e.g., text attributes) to efficiently generate node embeddings for previously unseen data. Instead of training individual embeddings for each node, we learn a function that generates embeddings by sampling and aggregating features from a node\u0026rsquo;s local neighborhood. Our algorithm outperforms strong baselines on three inductive node-classification benchmarks: we classify the category of unseen nodes in evolving information graphs based on citation and Reddit post data, and we show that our algorithm generalizes to completely unseen graphs using a multi-graph dataset of protein-protein interactions.\nGraph Convolutional Neural Networks for Web-Scale Recommender Systems (Rex Ying et al., 2018) Rex Ying, Ruining He, Kaifeng Chen, Pong Eksombatchai, William L. Hamilton, J. Leskovec. (2018)\nGraph Convolutional Neural Networks for Web-Scale Recommender Systems\nKDD\nPaper Link\nInfluential Citation Count (145), SS-ID (6c96c2d4a3fbd572fef2d59cb856521ee1746789)\nABSTRACT\nRecent advancements in deep neural networks for graph-structured data have led to state-of-the-art performance on recommender system benchmarks. However, making these methods practical and scalable to web-scale recommendation tasks with billions of items and hundreds of millions of users remains an unsolved challenge. Here we describe a large-scale deep recommendation engine that we developed and deployed at Pinterest. We develop a data-efficient Graph Convolutional Network (GCN) algorithm, which combines efficient random walks and graph convolutions to generate embeddings of nodes (i.e., items) that incorporate both graph structure as well as node feature information. Compared to prior GCN approaches, we develop a novel method based on highly efficient random walks to structure the convolutions and design a novel training strategy that relies on harder-and-harder training examples to improve robustness and convergence of the model. We also develop an efficient MapReduce model inference algorithm to generate embeddings using a trained model. Overall, we can train on and embed graphs that are four orders of magnitude larger than typical GCN implementations. We show how GCN embeddings can be used to make high-quality recommendations in various settings at Pinterest, which has a massive underlying graph with 3 billion nodes representing pins and boards, and 17 billion edges. According to offline metrics, user studies, as well as A/B tests, our approach generates higher-quality recommendations than comparable deep learning based systems. To our knowledge, this is by far the largest application of deep graph embeddings to date and paves the way for a new generation of web-scale recommender systems based on graph convolutional architectures.\nDynamic Network Embedding : An Extended Approach for Skip-gram based Network Embedding (Lun Du et al., 2018) Lun Du, Yun Wang, Guojie Song, Zhicong Lu, Junshan Wang. (2018)\nDynamic Network Embedding : An Extended Approach for Skip-gram based Network Embedding\nIJCAI\nPaper Link\nInfluential Citation Count (10), SS-ID (707defa78c0e5529c17fda92ce7b33f0b6674612)\nABSTRACT\nNetwork embedding, as an approach to learn low-dimensional representations of vertices, has been proved extremely useful in many applications. Lots of state-of-the-art network embedding methods based on Skip-gram framework are efficient and effective. However, these methods mainly focus on the static network embedding and cannot naturally generalize to the dynamic environment. In this paper, we propose a stable dynamic embedding framework with high efficiency. It is an extension for the Skip-gram based network embedding methods, which can keep the optimality of the objective in the Skip-gram based methods in theory. Our model can not only generalize to the new vertex representation, but also update the most affected original vertex representations during the evolvement of the network. Multi-class classification on three real-world networks demonstrates that, our model can update the vertex representations efficiently and achieve the performance of retraining simultaneously. Besides, the visualization experimental result illustrates that, our model is capable of avoiding the embedding space drifting.\nDynamic Network Embedding by Modeling Triadic Closure Process (Le-kui Zhou et al., 2018) Le-kui Zhou, Yang Yang, Xiang Ren, Fei Wu, Yueting Zhuang. (2018)\nDynamic Network Embedding by Modeling Triadic Closure Process\nAAAI\nPaper Link\nInfluential Citation Count (43), SS-ID (7bfb46c47c25e46a5f7b168133f4e926ab44725b)\nABSTRACT\nNetwork embedding, which aims to learn the low-dimensional representations of vertices, is an important task and has attracted considerable research efforts recently. In real world, networks, like social network and biological networks, are dynamic and evolving over time. However, almost all the existing network embedding methods focus on static networks while ignore network dynamics. In this paper, we present a novel representation learning approach, DynamicTriad, to preserve both structural information and evolution patterns of a given network. The general idea of our approach is to impose triad, which is a group of three vertices and is one of the basic units of networks. In particular, we model how a closed triad, which consists of three vertices connected with each other, develops from an open triad that has two of three vertices not connected with each other. This triadic closure process is a fundamental mechanism in the formation and evolution of networks, thereby makes our model being able to capture the network dynamics and to learn representation vectors for each vertex at different time steps. Experimental results on three real-world networks demonstrate that, compared with several state-of-the-art techniques, DynamicTriad achieves substantial gains in several application scenarios. For example, our approach can effectively be applied and help to identify telephone frauds in a mobile network, and to predict whether a user will repay her loans or not in a loan network.\nA Comprehensive Survey on Graph Neural Networks (Zonghan Wu et al., 2019) Zonghan Wu, Shirui Pan, Fengwen Chen, Guodong Long, Chengqi Zhang, Philip S. Yu. (2019)\nA Comprehensive Survey on Graph Neural Networks\nIEEE Transactions on Neural Networks and Learning Systems\nPaper Link\nInfluential Citation Count (217), SS-ID (81a4fd3004df0eb05d6c1cef96ad33d5407820df)\nABSTRACT\nDeep learning has revolutionized many machine learning tasks in recent years, ranging from image classification and video processing to speech recognition and natural language understanding. The data in these tasks are typically represented in the Euclidean space. However, there is an increasing number of applications, where data are generated from non-Euclidean domains and are represented as graphs with complex relationships and interdependency between objects. The complexity of graph data has imposed significant challenges on the existing machine learning algorithms. Recently, many studies on extending deep learning approaches for graph data have emerged. In this article, we provide a comprehensive overview of graph neural networks (GNNs) in data mining and machine learning fields. We propose a new taxonomy to divide the state-of-the-art GNNs into four categories, namely, recurrent GNNs, convolutional GNNs, graph autoencoders, and spatial–temporal GNNs. We further discuss the applications of GNNs across various domains and summarize the open-source codes, benchmark data sets, and model evaluation of GNNs. Finally, we propose potential research directions in this rapidly growing field.\nmetapath2vec: Scalable Representation Learning for Heterogeneous Networks (Yuxiao Dong et al., 2017) Yuxiao Dong, N. Chawla, A. Swami. (2017)\nmetapath2vec: Scalable Representation Learning for Heterogeneous Networks\nKDD\nPaper Link\nInfluential Citation Count (168), SS-ID (c0af91371f426ff92117d2ccdadb2032bec23d2c)\nABSTRACT\nWe study the problem of representation learning in heterogeneous networks. Its unique challenges come from the existence of multiple types of nodes and links, which limit the feasibility of the conventional network embedding techniques. We develop two scalable representation learning models, namely metapath2vec and metapath2vec++. The metapath2vec model formalizes meta-path-based random walks to construct the heterogeneous neighborhood of a node and then leverages a heterogeneous skip-gram model to perform node embeddings. The metapath2vec++ model further enables the simultaneous modeling of structural and semantic correlations in heterogeneous networks. Extensive experiments show that metapath2vec and metapath2vec++ are able to not only outperform state-of-the-art embedding models in various heterogeneous network mining tasks, such as node classification, clustering, and similarity search, but also discern the structural and semantic correlations between diverse network objects.\nLearning Dynamic Graph Representations (Rakshit S. Trivedi et al., 2018) Rakshit S. Trivedi, Mehrdad Farajtabar, P. Biswal, H. Zha. (2018)\nLearning Dynamic Graph Representations\nPaper Link\nInfluential Citation Count (0), SS-ID (c0f169a55728b0b2c6be0d6217726682d1775020)\nABSTRACT\nWe address two fundamental questions that arise in learning over dynamic graphs: 1 (i) How to elegantly model dynamical processes over graphs? (ii) How to lever2 age such a model to effectively encode evolving graph information into low3 dimensional representations? We present DyRep a novel modeling framework 4 for dynamic graphs that posits representation learning as a latent mediation process 5 bridging two observed processes – dynamic of the network (topological evolution) 6 and dynamic on the network (activities of the nodes). To this end, we propose an 7 inductive framework comprising of two-time scale deep temporal point process 8 model parameterized by a temporal-attentive representation network and trained 9 end-to-end using an efficient unsupervised procedure. We demonstrate that DyRep 10 significantly outperforms state-of-art baselines for dynamic link prediction and 11 event time prediction and provide extensive qualitative analysis of our framework.1 12\nDeepWalk: online learning of social representations (Bryan Perozzi et al., 2014) Bryan Perozzi, Rami Al-Rfou, S. Skiena. (2014)\nDeepWalk: online learning of social representations\nKDD\nPaper Link\nInfluential Citation Count (1389), SS-ID (fff114cbba4f3ba900f33da574283e3de7f26c83)\nABSTRACT\nWe present DeepWalk, a novel approach for learning latent representations of vertices in a network. These latent representations encode social relations in a continuous vector space, which is easily exploited by statistical models. DeepWalk generalizes recent advancements in language modeling and unsupervised feature learning (or deep learning) from sequences of words to graphs. DeepWalk uses local information obtained from truncated random walks to learn latent representations by treating walks as the equivalent of sentences. We demonstrate DeepWalk\u0026rsquo;s latent representations on several multi-label network classification tasks for social networks such as BlogCatalog, Flickr, and YouTube. Our results show that DeepWalk outperforms challenging baselines which are allowed a global view of the network, especially in the presence of missing information. DeepWalk\u0026rsquo;s representations can provide F1 scores up to 10% higher than competing methods when labeled data is sparse. In some experiments, DeepWalk\u0026rsquo;s representations are able to outperform all baseline methods while using 60% less training data. DeepWalk is also scalable. It is an online learning algorithm which builds useful incremental results, and is trivially parallelizable. These qualities make it suitable for a broad class of real world applications such as network classification, and anomaly detection.\n","date":"July 27, 2022","hero":"/blog-akitenkrad/posts/papers/202207/20220727145036/hero.jpg","permalink":"https://akitenkrad.github.io/blog-akitenkrad/posts/papers/202207/20220727145036/","summary":"Round-1: Overview Round-2: Model Implementation Details Round-3: Experiments Citation Yang, L., Xiao, Z., Jiang, W., Wei, Y., Hu, Y., \u0026amp; Wang, H. (2020).\nDynamic heterogeneous graph embedding using hierarchical attentions.\nLecture Notes in Computer Science (Including Subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics), 12036 LNCS.\nhttps://doi.org/10.1007/978-3-030-45442-5_53 Abstract Graph embedding has attracted many research interests. Existing works mainly focus on static homogeneous/heterogeneous networks or dynamic homogeneous networks.","tags":["At:Round-2","Published:2020","DS:EComm","DS:Higgs Twitter Dataset","Link Prediction"],"title":"Dynamic Heterogeneous Graph Embedding Using Hierarchical Attentions"},{"categories":null,"contents":" Round-1: Overview Round-2: Model Implementation Details Round-3: Experiments Citation Xue, G., Zhong, M., Li, J., Chen, J., Zhai, C., \u0026amp; Kong, R. (2022)\nDynamic network embedding survey\nNeurocomputing, 472, 212–223. https://doi.org/10.1016/J.NEUCOM.2021.03.138 Abstract Since many real world networks are evolving over time, such as social networks and user-item networks, there are increasing research efforts on dynamic network embedding in recent years. They learn node representations from a sequence of evolving graphs but not only the latest network, for preserving both structural and temporal information from the dynamic networks. Due to the lack of comprehensive investigation of them, we give a survey of dynamic network embedding in this paper. Our survey inspects the data model, representation learning technique, evaluation and application of current related works and derives common patterns from them. Specifically, we present two basic data models, namely, discrete model and continuous model for dynamic networks. Correspondingly, we summarize two major categories of dynamic network embedding techniques, namely, structural-first and temporal-first that are adopted by most related works. Then we build a taxonomy that refines the category hierarchy by typical learning models. The popular experimental data sets and applications are also summarized. Lastly, we have a discussion of several distinct research topics in dynamic network embedding.\nWhat\u0026rsquo;s New Graph Neural NetworkにおけるEmbedding手法のうち，時間と共にNodeとEdgeが変化するDynamic GraphのEmbeddingをサーベイした論文 以下の観点からモデルが整理されている Node/Edgeを追加・削除できるかどうか Temporal-First Methodology vs Structural First Methodology Discrete Model Type vs Continuous Model Type History of Dynamic Graph Embedding Method Methodology Data Mode Node/Edge Addition Node/Edge Deletion Learning Techniques DANE S-first discrete both both Matrix Factorization DHPE S-first discrete both both Matrix Factorization Know-Evolve T-first continuous both - Deep Learning STGCN S-first discrete - - Deep Learning DNE S-first discrete both both Skip-gram DynGEM S-first discrete both both Deep Learning DepthLGP Others discrete both - Others DGNN T-first discrete both - Deep Learning dynnode2vec S-first discrete both both Skip-gram Continuous-Time Dynamic Networks S-first continuous edge - Skip-gram DySAT S-first discrete edge edge Deep Learning DyRep T-first continuous both - Deep Learning Netwalk S-first continuous edge edge Deep Learning DynamicTriad Others discrete both - Others HTNE S-first continous edge - Skip-gram JODIE T-first continuous edge Deep Learning EvolveGCN S-first discrete both - Deep Learning BurstGraph S-first discrete both - Deep Learning AddGraph S-first discrete edge - Deep Learning dyngraph2vec S-first discrete edge edge Deep Learning TGAT Others discrete both - Deep Learning DyHAN S-first discrete both both Deep Learning DyHATR T-first discrete both both Deep Learning THIGE T-first continuous edge edge Deep Learning MMDNE Others continuous both - Deep Learning References ADSAGE: Anomaly Detection in Sequences of Attributed Graph Edges applied to insider threat detection at fine-grained level (Mathieu Garchery et al., 2020) Mathieu Garchery, M. Granitzer. (2020)\nADSAGE: Anomaly Detection in Sequences of Attributed Graph Edges applied to insider threat detection at fine-grained level\nArXiv\nPaper Link\nInfluential Citation Count (1), SS-ID (003550bd8776ccffad0f7f07b7c36c83d077390e)\nABSTRACT\nPrevious works on the CERT insider threat detection case have neglected graph and text features despite their relevance to describe user behavior. Additionally, existing systems heavily rely on feature engineering and audit data aggregation to detect malicious activities. This is time consuming, requires expert knowledge and prevents tracing back alerts to precise user actions. To address these issues we introduce ADSAGE to detect anomalies in audit log events modeled as graph edges. Our general method is the first to perform anomaly detection at edge level while supporting both edge sequences and attributes, which can be numeric, categorical or even text. We describe how ADSAGE can be used for fine-grained, event level insider threat detection in different audit logs from the CERT use case. Remarking that there is no standard benchmark for the CERT problem, we use a previously proposed evaluation setting based on realistic recall-based metrics. We evaluate ADSAGE on authentication, email traffic and web browsing logs from the CERT insider threat datasets, as well as on real-world authentication events. ADSAGE is effective to detect anomalies in authentications, modeled as user to computer interactions, and in email communications. Simple baselines give surprisingly strong results as well. We also report performance split by malicious scenarios present in the CERT datasets: interestingly, several detectors are complementary and could be combined to improve detection. Overall, our results show that graph features are informative to characterize malicious insider activities, and that detection at fine-grained level is possible.\nHeterogeneous Graph Attention Network (Xiao Wang et al., 2019) Xiao Wang, Houye Ji, C. Shi, Bai Wang, Peng Cui, P. Yu, Yanfang Ye. (2019)\nHeterogeneous Graph Attention Network\nWWW\nPaper Link\nInfluential Citation Count (175), SS-ID (00b7efbf14a54cced4b9f19e663b70ffbd01324b)\nABSTRACT\nGraph neural network, as a powerful graph representation technique based on deep learning, has shown superior performance and attracted considerable research interest. However, it has not been fully considered in graph neural network for heterogeneous graph which contains different types of nodes and links. The heterogeneity and rich semantic information bring great challenges for designing a graph neural network for heterogeneous graph. Recently, one of the most exciting advancements in deep learning is the attention mechanism, whose great potential has been well demonstrated in various areas. In this paper, we first propose a novel heterogeneous graph neural network based on the hierarchical attention, including node-level and semantic-level attentions. Specifically, the node-level attention aims to learn the importance between a node and its meta-path based neighbors, while the semantic-level attention is able to learn the importance of different meta-paths. With the learned importance from both node-level and semantic-level attention, the importance of node and meta-path can be fully considered. Then the proposed model can generate node embedding by aggregating features from meta-path based neighbors in a hierarchical manner. Extensive experimental results on three real-world heterogeneous graphs not only show the superior performance of our proposed model over the state-of-the-arts, but also demonstrate its potentially good interpretability for graph analysis.\nMetapath-guided Heterogeneous Graph Neural Network for Intent Recommendation (Shaohua Fan et al., 2019) Shaohua Fan, Junxiong Zhu, Xiaotian Han, C. Shi, Linmei Hu, Biyu Ma, Yongliang Li. (2019)\nMetapath-guided Heterogeneous Graph Neural Network for Intent Recommendation\nKDD\nPaper Link\nInfluential Citation Count (14), SS-ID (025ea689e6ab3b544101df17233e87536a1e578a)\nABSTRACT\nWith the prevalence of mobile e-commerce nowadays, a new type of recommendation services, called intent recommendation, is widely used in many mobile e-commerce Apps, such as Taobao and Amazon. Different from traditional query recommendation and item recommendation, intent recommendation is to automatically recommend user intent according to user historical behaviors without any input when users open the App. Intent recommendation becomes very popular in the past two years, because of revealing user latent intents and avoiding tedious input in mobile phones. Existing methods used in industry usually need laboring feature engineering. Moreover, they only utilize attribute and statistic information of users and queries, and fail to take full advantage of rich interaction information in intent recommendation, which may result in limited performances. In this paper, we propose to model the complex objects and rich interactions in intent recommendation as a Heterogeneous Information Network. Furthermore, we present a novel M etapath-guided E mbedding method for I ntent Rec ommendation~(called MEIRec). In order to fully utilize rich structural information, we design a metapath-guided heterogeneous Graph Neural Network to learn the embeddings of objects in intent recommendation. In addition, in order to alleviate huge learning parameters in embeddings, we propose a uniform term embedding mechanism, in which embeddings of objects are made up with the same term embedding space. Offline experiments on real large-scale data show the superior performance of the proposed MEIRec, compared to representative methods.Moreover, the results of online experiments on Taobao e-commerce platform show that MEIRec not only gains a performance improvement of 1.54% on CTR metric, but also attracts up to 2.66% of new users to search queries.\nLearning representations by back-propagating errors (D. Rumelhart et al., 1986) D. Rumelhart, Geoffrey E. Hinton, Ronald J. Williams. (1986)\nLearning representations by back-propagating errors\nNature\nPaper Link\nInfluential Citation Count (701), SS-ID (052b1d8ce63b07fec3de9dbb583772d860b7c769)\nABSTRACT\nY. (성기익 et al., 2003) 성기익, 이영탁, 박계현, 전태국, 박표원, 한일용, 장윤희. (2003)\nY.\nIndustrial and Labor Relations Terms\nPaper Link\nInfluential Citation Count (3743), SS-ID (07b056a23b225fa4fc54cda80a8e6c2c74760541)\nABSTRACT\nLINE: Large-scale Information Network Embedding (Jian Tang et al., 2015) Jian Tang, Meng Qu, Mingzhe Wang, Ming Zhang, Jun Yan, Q. Mei. (2015)\nLINE: Large-scale Information Network Embedding\nWWW\nPaper Link\nInfluential Citation Count (862), SS-ID (0834e74304b547c9354b6d7da6fa78ef47a48fa8)\nABSTRACT\nThis paper studies the problem of embedding very large information networks into low-dimensional vector spaces, which is useful in many tasks such as visualization, node classification, and link prediction. Most existing graph embedding methods do not scale for real world information networks which usually contain millions of nodes. In this paper, we propose a novel network embedding method called the ``LINE,\u0026rsquo;\u0026rsquo; which is suitable for arbitrary types of information networks: undirected, directed, and/or weighted. The method optimizes a carefully designed objective function that preserves both the local and global network structures. An edge-sampling algorithm is proposed that addresses the limitation of the classical stochastic gradient descent and improves both the effectiveness and the efficiency of the inference. Empirical experiments prove the effectiveness of the LINE on a variety of real-world information networks, including language networks, social networks, and citation networks. The algorithm is very efficient, which is able to learn the embedding of a network with millions of vertices and billions of edges in a few hours on a typical single machine. The source code of the LINE is available online\\footnote{\\url{https://github.com/tangjianpku/LINE}}.\nA simple graph embedding for anomaly detection in a stream of heterogeneous labeled graphs (Abd Errahmane Kiouche et al., 2020) Abd Errahmane Kiouche, Sofiane Lagraa, Karima Amrouche, H. Seba. (2020)\nA simple graph embedding for anomaly detection in a stream of heterogeneous labeled graphs\nPattern Recognit.\nPaper Link\nInfluential Citation Count (0), SS-ID (0c43a39465085704058cbf57aa1300d956b68e63)\nABSTRACT\nContinuous-Time Dynamic Network Embeddings (G. Nguyen et al., 2018) G. Nguyen, J. B. Lee, Ryan A. Rossi, Nesreen Ahmed, Eunyee Koh, Sungchul Kim. (2018)\nContinuous-Time Dynamic Network Embeddings\nWWW\nPaper Link\nInfluential Citation Count (52), SS-ID (0ebc58242d10e14633bdad72b74b31c3d4ed9bdd)\nABSTRACT\nNetworks evolve continuously over time with the addition, deletion, and changing of links and nodes. Although many networks contain this type of temporal information, the majority of research in network representation learning has focused on static snapshots of the graph and has largely ignored the temporal dynamics of the network. In this work, we describe a general framework for incorporating temporal information into network embedding methods. The framework gives rise to methods for learning time-respecting embeddings from continuous-time dynamic networks. Overall, the experiments demonstrate the effectiveness of the proposed framework and dynamic network embedding approach as it achieves an average gain of 11.9% across all methods and graphs. The results indicate that modeling temporal dependencies in graphs is important for learning appropriate and meaningful network representations.\nSpatiotemporal Multi-Graph Convolution Network for Ride-Hailing Demand Forecasting (Xu Geng et al., 2019) Xu Geng, Yaguang Li, Leye Wang, Lingyu Zhang, Qiang Yang, Jieping Ye, Yan Liu. (2019)\nSpatiotemporal Multi-Graph Convolution Network for Ride-Hailing Demand Forecasting\nAAAI\nPaper Link\nInfluential Citation Count (37), SS-ID (0f8332fb651bf639ab110c65067ef2225f49eea5)\nABSTRACT\nRegion-level demand forecasting is an essential task in ridehailing services. Accurate ride-hailing demand forecasting can guide vehicle dispatching, improve vehicle utilization, reduce the wait-time, and mitigate traffic congestion. This task is challenging due to the complicated spatiotemporal dependencies among regions. Existing approaches mainly focus on modeling the Euclidean correlations among spatially adjacent regions while we observe that non-Euclidean pair-wise correlations among possibly distant regions are also critical for accurate forecasting. In this paper, we propose the spatiotemporal multi-graph convolution network (ST-MGCN), a novel deep learning model for ride-hailing demand forecasting. We first encode the non-Euclidean pair-wise correlations among regions into multiple graphs and then explicitly model these correlations using multi-graph convolution. To utilize the global contextual information in modeling the temporal correlation, we further propose contextual gated recurrent neural network which augments recurrent neural network with a contextual-aware gating mechanism to re-weights different historical observations. We evaluate the proposed model on two real-world large scale ride-hailing demand datasets and observe consistent improvement of more than 10% over stateof-the-art baselines.\nIntroducing the Enron Corpus (Bryan Klimt et al., 2004) Bryan Klimt, Yiming Yang. (2004)\nIntroducing the Enron Corpus\nCEAS\nPaper Link\nInfluential Citation Count (33), SS-ID (135d89a35623359aa3af7ce6f95b0078c6acc43a)\nABSTRACT\nA large set of email messages, the Enron corpus, was made public during the legal investigation concerning the Enron corporation. This dataset, along with a thorough explanation of its origin, is available at http://www-2.cs.cmu.edu/~enron/. This paper provides a brief introduction and analysis of the dataset. The raw Enron corpus contains 619,446 messages belonging to 158 users. We cleaned the corpus before this analysis by removing certain folders from each user, such as “discussion_threads”. These folders were present for most users, and did not appear to be used directly by the users, but rather were computer generated. Many, such as “all_documents”, also contained large numbers of duplicate emails, which were already present in the users’ other folders. Our goal in this paper is to analyze the suitability of this corpus for exploring how to classify messages as organized by a human, so these folders would have likely been misleading.\nA Survey on Dynamic Network Embedding (Yu Xie et al., 2020) Yu Xie, Chunyi Li, Bin Yu, Chen Zhang, Z. Tang. (2020)\nA Survey on Dynamic Network Embedding\nArXiv\nPaper Link\nInfluential Citation Count (0), SS-ID (164b315599ace13989426b85a0ce9428abedf00d)\nABSTRACT\nReal-world networks are composed of diverse interacting and evolving entities, while most of existing researches simply characterize them as particular static networks, without consideration of the evolution trend in dynamic networks. Recently, significant progresses in tracking the properties of dynamic networks have been made, which exploit changes of entities and links in the network to devise network embedding techniques. Compared to widely proposed static network embedding methods, dynamic network embedding endeavors to encode nodes as low-dimensional dense representations that effectively preserve the network structures and the temporal dynamics, which is beneficial to multifarious downstream machine learning tasks. In this paper, we conduct a systematical survey on dynamic network embedding. In specific, basic concepts of dynamic network embedding are described, notably, we propose a novel taxonomy of existing dynamic network embedding techniques for the first time, including matrix factorization based, Skip-Gram based, autoencoder based, neural networks based and other embedding methods. Additionally, we carefully summarize the commonly used datasets and a wide variety of subsequent tasks that dynamic network embedding can benefit. Afterwards and primarily, we suggest several challenges that the existing algorithms faced and outline possible directions to facilitate the future research, such as dynamic embedding models, large-scale dynamic networks, heterogeneous dynamic networks, dynamic attributed networks, task-oriented dynamic network embedding and more embedding spaces.\nInductive Representation Learning on Temporal Graphs (Da Xu et al., 2020) Da Xu, Chuanwei Ruan, Evren Körpeoglu, Sushant Kumar, Kannan Achan. (2020)\nInductive Representation Learning on Temporal Graphs\nICLR\nPaper Link\nInfluential Citation Count (41), SS-ID (1f58e8d4c827037d4c2a1afc695a88704e088beb)\nABSTRACT\nInductive representation learning on temporal graphs is an important step toward salable machine learning on real-world dynamic networks. The evolving nature of temporal dynamic graphs requires handling new nodes as well as capturing temporal patterns. The node embeddings, which are now functions of time, should represent both the static node features and the evolving topological structures. Moreover, node and topological features can be temporal as well, whose patterns the node embeddings should also capture. We propose the temporal graph attention (TGAT) layer to efficiently aggregate temporal-topological neighborhood features as well as to learn the time-feature interactions. For TGAT, we use the self-attention mechanism as building block and develop a novel functional time encoding technique based on the classical Bochner\u0026rsquo;s theorem from harmonic analysis. By stacking TGAT layers, the network recognizes the node embeddings as functions of time and is able to inductively infer embeddings for both new and observed nodes as the graph evolves. The proposed approach handles both node classification and link prediction task, and can be naturally extended to include the temporal edge features. We evaluate our method with transductive and inductive tasks under temporal settings with two benchmark and one industrial dataset. Our TGAT model compares favorably to state-of-the-art baselines as well as the previous temporal graph embedding approaches.\nNetwork Embedding and Change Modeling in Dynamic Heterogeneous Networks (Ranran Bian et al., 2019) Ranran Bian, Yun Sing Koh, G. Dobbie, A. Divoli. (2019)\nNetwork Embedding and Change Modeling in Dynamic Heterogeneous Networks\nSIGIR\nPaper Link\nInfluential Citation Count (2), SS-ID (21827f8fa462febc6f970a8b1f57a212e7e5feb6)\nABSTRACT\nNetwork embedding learns the vector representations of nodes. Most real world networks are heterogeneous and evolve over time. There are, however, no network embedding approaches designed for dynamic heterogeneous networks so far. Addressing this research gap is beneficial for analyzing and mining real world networks. We develop a novel representation learning method, change2vec, which considers a dynamic heterogeneous network as snapshots of networks with different time stamps. Instead of processing the whole network at each time stamp, change2vec models changes between two consecutive static networks by capturing newly-added and deleted nodes with their neighbour nodes as well as newly-formed or deleted edges that caused core structural changes known as triad closure or open processes. Change2vec leverages metapath based node embedding and change modeling to preserve both heterogeneous and dynamic features of a network. Experimental results show that change2vec outperforms two state-of-the-art methods in terms of clustering performance and efficiency.\nUnsupervised Inductive Graph-Level Representation Learning via Graph-Graph Proximity (Yunsheng Bai et al., 2019) Yunsheng Bai, Haoyang Ding, Yang Qiao, Agustin Marinovic, Ken Gu, Tingting Chen, Yizhou Sun, Wei Wang. (2019)\nUnsupervised Inductive Graph-Level Representation Learning via Graph-Graph Proximity\nIJCAI\nPaper Link\nInfluential Citation Count (3), SS-ID (307c5103c9ecbfc7f11f120d8ab9f33b24c6c650)\nABSTRACT\nWe introduce a novel approach to graph-level representation learning, which is to embed an entire graph into a vector space where the embeddings of two graphs preserve their graph-graph proximity. Our approach, UGraphEmb, is a general framework that provides a novel means to performing graph-level embedding in a completely unsupervised and inductive manner. The learned neural network can be considered as a function that receives any graph as input, either seen or unseen in the training set, and transforms it into an embedding. A novel graph-level embedding generation mechanism called Multi-Scale Node Attention (MSNA), is proposed. Experiments on five real graph datasets show that UGraphEmb achieves competitive accuracy in the tasks of graph classification, similarity ranking, and graph visualization.\nRelation constrained attributed network embedding (Yiqi Chen et al., 2020) Yiqi Chen, T. Qian. (2020)\nRelation constrained attributed network embedding\nInf. Sci.\nPaper Link\nInfluential Citation Count (0), SS-ID (32ff51dcb20d43241a006771d19c8c188aeb6081)\nABSTRACT\nnode2vec: Scalable Feature Learning for Networks (Aditya Grover et al., 2016) Aditya Grover, J. Leskovec. (2016)\nnode2vec: Scalable Feature Learning for Networks\nKDD\nPaper Link\nInfluential Citation Count (1156), SS-ID (36ee2c8bd605afd48035d15fdc6b8c8842363376)\nABSTRACT\nPrediction tasks over nodes and edges in networks require careful effort in engineering features used by learning algorithms. Recent research in the broader field of representation learning has led to significant progress in automating prediction by learning the features themselves. However, present feature learning approaches are not expressive enough to capture the diversity of connectivity patterns observed in networks. Here we propose node2vec, an algorithmic framework for learning continuous feature representations for nodes in networks. In node2vec, we learn a mapping of nodes to a low-dimensional space of features that maximizes the likelihood of preserving network neighborhoods of nodes. We define a flexible notion of a node\u0026rsquo;s network neighborhood and design a biased random walk procedure, which efficiently explores diverse neighborhoods. Our algorithm generalizes prior work which is based on rigid notions of network neighborhoods, and we argue that the added flexibility in exploring neighborhoods is the key to learning richer representations. We demonstrate the efficacy of node2vec over existing state-of-the-art techniques on multi-label classification and link prediction in several real-world networks from diverse domains. Taken together, our work represents a new way for efficiently learning state-of-the-art task-independent representations in complex networks.\n#p (G. Alagic et al., 2019) G. Alagic, Catharine Lo, Phanuel Chuka Hakwendenda. (2019)\n#p\nQuantum Inf. Comput.\nPaper Link\nInfluential Citation Count (5591), SS-ID (3bc63a1a3c0a5bb66af7bb61c34e379658820f90)\nABSTRACT\nEmbedding Temporal Network via Neighborhood Formation (Y. Zuo et al., 2018) Y. Zuo, Guannan Liu, Hao Lin, Jia Guo, Xiaoqian Hu, J. Wu. (2018)\nEmbedding Temporal Network via Neighborhood Formation\nKDD\nPaper Link\nInfluential Citation Count (24), SS-ID (3fbe522c63b973a83f88c6aac68bc1385e90ed5b)\nABSTRACT\nGiven the rich real-life applications of network mining as well as the surge of representation learning in recent years, network embedding has become the focal point of increasing research interests in both academic and industrial domains. Nevertheless, the complete temporal formation process of networks characterized by sequential interactive events between nodes has yet seldom been modeled in the existing studies, which calls for further research on the so-called temporal network embedding problem. In light of this, in this paper, we introduce the concept of neighborhood formation sequence to describe the evolution of a node, where temporal excitation effects exist between neighbors in the sequence, and thus we propose a Hawkes process based Temporal Network Embedding (HTNE) method. HTNE well integrates the Hawkes process into network embedding so as to capture the influence of historical neighbors on the current neighbors. In particular, the interactions of low-dimensional vectors are fed into the Hawkes process as base rate and temporal influence, respectively. In addition, attention mechanism is also integrated into HTNE to better determine the influence of historical neighbors on current neighbors of a node. Experiments on three large-scale real-life networks demonstrate that the embeddings learned from the proposed HTNE model achieve better performance than state-of-the-art methods in various tasks including node classification, link prediction, and embedding visualization. In particular, temporal recommendation based on arrival rate inferred from node embeddings shows excellent predictive power of the proposed model.\nTemporal Heterogeneous Interaction Graph Embedding for Next-Item Recommendation (Yugang Ji et al., 2020) Yugang Ji, Mingyang Yin, Yuan Fang, Hongxia Yang, Xiangwei Wang, Tianrui Jia, C. Shi. (2020)\nTemporal Heterogeneous Interaction Graph Embedding for Next-Item Recommendation\nECML/PKDD\nPaper Link\nInfluential Citation Count (0), SS-ID (4231353710ba2ebf263f255060480540c0695b18)\nABSTRACT\nLong Short-Term Memory (S. Hochreiter et al., 1997) S. Hochreiter, J. Schmidhuber. (1997)\nLong Short-Term Memory\nNeural Computation\nPaper Link\nInfluential Citation Count (8967), SS-ID (44d2abe2175df8153f465f6c39b68b76a0d40ab9)\nABSTRACT\nLearning to store information over extended time intervals by recurrent backpropagation takes a very long time, mostly because of insufficient, decaying error backflow. We briefly review Hochreiter\u0026rsquo;s (1991) analysis of this problem, then address it by introducing a novel, efficient, gradient based method called long short-term memory (LSTM). Truncating the gradient where this does not do harm, LSTM can learn to bridge minimal time lags in excess of 1000 discrete-time steps by enforcing constant error flow through constant error carousels within special units. Multiplicative gate units learn to open and close access to the constant error flow. LSTM is local in space and time; its computational complexity per time step and weight is O. 1. Our experiments with artificial data involve local, distributed, real-valued, and noisy pattern representations. In comparisons with real-time recurrent learning, back propagation through time, recurrent cascade correlation, Elman nets, and neural sequence chunking, LSTM leads to many more successful runs, and learns much faster. LSTM also solves complex, artificial long-time-lag tasks that have never been solved by previous recurrent network algorithms.\ndynnode2vec: Scalable Dynamic Network Embedding (Sedigheh Mahdavi et al., 2018) Sedigheh Mahdavi, Shima Khoshraftar, Aijun An. (2018)\ndynnode2vec: Scalable Dynamic Network Embedding\n2018 IEEE International Conference on Big Data (Big Data)\nPaper Link\nInfluential Citation Count (2), SS-ID (454a69d2b93049c794247e1e4dc2e4b590172dae)\nABSTRACT\nNetwork representation learning in low dimensional vector space has attracted considerable attention in both academic and industrial domains. Most real-world networks are dynamic with addition/deletion of nodes and edges. The existing graph embedding methods are designed for static networks and they cannot capture evolving patterns in a large dynamic network. In this paper, we propose a dynamic embedding method, dynnode2vec, based on the well-known graph embedding method node2vec. Node2vec is a random walk based embedding method for static networks. Applying static network embedding in dynamic settings has two crucial problems: 1) Generating random walks for every time step is time consuming 2) Embedding vector spaces in each timestamp are different. In order to tackle these challenges, dynnode2vec uses evolving random walks and initializes the current graph embedding with previous embedding vectors. We demonstrate the advantages of the proposed dynamic network embedding by conducting empirical evaluations on several large dynamic network datasets.\nDynamic Graph Representation Learning via Self-Attention Networks (Aravind Sankar et al., 2018) Aravind Sankar, Yanhong Wu, Liang Gou, Wei Zhang, Hao Yang. (2018)\nDynamic Graph Representation Learning via Self-Attention Networks\nArXiv\nPaper Link\nInfluential Citation Count (7), SS-ID (50a1a28d216ebf719ca1103593d5afe1e29e3ee1)\nABSTRACT\nLearning latent representations of nodes in graphs is an important and ubiquitous task with widespread applications such as link prediction, node classification, and graph visualization. Previous methods on graph representation learning mainly focus on static graphs, however, many real-world graphs are dynamic and evolve over time. In this paper, we present Dynamic Self-Attention Network (DySAT), a novel neural architecture that operates on dynamic graphs and learns node representations that capture both structural properties and temporal evolutionary patterns. Specifically, DySAT computes node representations by jointly employing self-attention layers along two dimensions: structural neighborhood and temporal dynamics. We conduct link prediction experiments on two classes of graphs: communication networks and bipartite rating networks. Our experimental results show that DySAT has a significant performance gain over several different state-of-the-art graph embedding baselines.\nDeep Inductive Network Representation Learning (Ryan A. Rossi et al., 2018) Ryan A. Rossi, R. Zhou, Nesreen Ahmed. (2018)\nDeep Inductive Network Representation Learning\nWWW\nPaper Link\nInfluential Citation Count (3), SS-ID (5ec39dcadbfa096592ac811679c3e1eb8ddff7db)\nABSTRACT\nThis paper presents a general inductive graph representation learning framework called DeepGL for learning deep node and edge features that generalize across-networks. In particular, DeepGL begins by deriving a set of base features from the graph (e.g., graphlet features) and automatically learns a multi-layered hierarchical graph representation where each successive layer leverages the output from the previous layer to learn features of a higher-order. Contrary to previous work, DeepGL learns relational functions (each representing a feature) that naturally generalize across-networks and are therefore useful for graph-based transfer learning tasks. Moreover, DeepGL naturally supports attributed graphs, learns interpretable inductive graph representations, and is space-efficient (by learning sparse feature vectors). In addition, DeepGL is expressive, flexible with many interchangeable components, efficient with a time complexity of O(|E|), and scalable for large networks via an efficient parallel implementation. Compared with recent methods, DeepGL is (1) effective for across-network transfer learning tasks and large (attributed) graphs, (2) space-efficient requiring up to 6x less memory, (3) fast with up to 182x speedup in runtime performance, and (4) accurate with an average improvement in AUC of 20% or more on many learning tasks and across a wide variety of networks.\nNetWalk: A Flexible Deep Embedding Approach for Anomaly Detection in Dynamic Networks (Wenchao Yu et al., 2018) Wenchao Yu, Wei Cheng, C. Aggarwal, Kai Zhang, Haifeng Chen, Wei Wang. (2018)\nNetWalk: A Flexible Deep Embedding Approach for Anomaly Detection in Dynamic Networks\nKDD\nPaper Link\nInfluential Citation Count (13), SS-ID (68f6fe021bd8efd8baf648138a8fe2182858e7cb)\nABSTRACT\nMassive and dynamic networks arise in many practical applications such as social media, security and public health. Given an evolutionary network, it is crucial to detect structural anomalies, such as vertices and edges whose \u0026ldquo;behaviors\u0026rsquo;\u0026rsquo; deviate from underlying majority of the network, in a real-time fashion. Recently, network embedding has proven a powerful tool in learning the low-dimensional representations of vertices in networks that can capture and preserve the network structure. However, most existing network embedding approaches are designed for static networks, and thus may not be perfectly suited for a dynamic environment in which the network representation has to be constantly updated. In this paper, we propose a novel approach, NetWalk, for anomaly detection in dynamic networks by learning network representations which can be updated dynamically as the network evolves. We first encode the vertices of the dynamic network to vector representations by clique embedding, which jointly minimizes the pairwise distance of vertex representations of each walk derived from the dynamic networks, and the deep autoencoder reconstruction error serving as a global regularization. The vector representations can be computed with constant space requirements using reservoir sampling. On the basis of the learned low-dimensional vertex representations, a clustering-based technique is employed to incrementally and dynamically detect network anomalies. Compared with existing approaches, NetWalk has several advantages: 1) the network embedding can be updated dynamically, 2) streaming network nodes and edges can be encoded efficiently with constant memory space usage, 3). flexible to be applied on different types of networks, and 4) network anomalies can be detected in real-time. Extensive experiments on four real datasets demonstrate the effectiveness of NetWalk.\nInductive Representation Learning on Large Graphs (William L. Hamilton et al., 2017) William L. Hamilton, Z. Ying, J. Leskovec. (2017)\nInductive Representation Learning on Large Graphs\nNIPS\nPaper Link\nInfluential Citation Count (1379), SS-ID (6b7d6e6416343b2a122f8416e69059ce919026ef)\nABSTRACT\nLow-dimensional embeddings of nodes in large graphs have proved extremely useful in a variety of prediction tasks, from content recommendation to identifying protein functions. However, most existing approaches require that all nodes in the graph are present during training of the embeddings; these previous approaches are inherently transductive and do not naturally generalize to unseen nodes. Here we present GraphSAGE, a general, inductive framework that leverages node feature information (e.g., text attributes) to efficiently generate node embeddings for previously unseen data. Instead of training individual embeddings for each node, we learn a function that generates embeddings by sampling and aggregating features from a node\u0026rsquo;s local neighborhood. Our algorithm outperforms strong baselines on three inductive node-classification benchmarks: we classify the category of unseen nodes in evolving information graphs based on citation and Reddit post data, and we show that our algorithm generalizes to completely unseen graphs using a multi-graph dataset of protein-protein interactions.\nMatrix Perturbation Theory (V. N. Bogaevski et al., 1991) V. N. Bogaevski, A. Povzner. (1991)\nMatrix Perturbation Theory\nPaper Link\nInfluential Citation Count (87), SS-ID (6c09c25131ac2e7f01fd14ce2a576c209f8ad23e)\nABSTRACT\nDynamic Network Embedding : An Extended Approach for Skip-gram based Network Embedding (Lun Du et al., 2018) Lun Du, Yun Wang, Guojie Song, Zhicong Lu, Junshan Wang. (2018)\nDynamic Network Embedding : An Extended Approach for Skip-gram based Network Embedding\nIJCAI\nPaper Link\nInfluential Citation Count (10), SS-ID (707defa78c0e5529c17fda92ce7b33f0b6674612)\nABSTRACT\nNetwork embedding, as an approach to learn low-dimensional representations of vertices, has been proved extremely useful in many applications. Lots of state-of-the-art network embedding methods based on Skip-gram framework are efficient and effective. However, these methods mainly focus on the static network embedding and cannot naturally generalize to the dynamic environment. In this paper, we propose a stable dynamic embedding framework with high efficiency. It is an extension for the Skip-gram based network embedding methods, which can keep the optimality of the objective in the Skip-gram based methods in theory. Our model can not only generalize to the new vertex representation, but also update the most affected original vertex representations during the evolvement of the network. Multi-class classification on three real-world networks demonstrates that, our model can update the vertex representations efficiently and achieve the performance of retraining simultaneously. Besides, the visualization experimental result illustrates that, our model is capable of avoiding the embedding space drifting.\nTemporal Network Embedding with Micro- and Macro-dynamics (Yuanfu Lu et al., 2019) Yuanfu Lu, Xiao Wang, C. Shi, Philip S. Yu, Yanfang Ye. (2019)\nTemporal Network Embedding with Micro- and Macro-dynamics\nCIKM\nPaper Link\nInfluential Citation Count (6), SS-ID (7111d50bebf139e5c2c226ff2b424dc4f9a3deb6)\nABSTRACT\nNetwork embedding aims to embed nodes into a low-dimensional space, while capturing the network structures and properties. Although quite a few promising network embedding methods have been proposed, most of them focus on static networks. In fact, temporal networks, which usually evolve over time in terms of microscopic and macroscopic dynamics, are ubiquitous. The micro-dynamics describe the formation process of network structures in a detailed manner, while the macro-dynamics refer to the evolution pattern of the network scale. Both micro- and macro-dynamics are the key factors to network evolution; however, how to elegantly capture both of them for temporal network embedding, especially macro-dynamics, has not yet been well studied. In this paper, we propose a novel temporal network embedding method with micro- and macro-dynamics, named $\\rmM^2DNE $. Specifically, for micro-dynamics, we regard the establishments of edges as the occurrences of chronological events and propose a temporal attention point process to capture the formation process of network structures in a fine-grained manner. For macro-dynamics, we define a general dynamics equation parameterized with network embeddings to capture the inherent evolution pattern and impose constraints in a higher structural level on network embeddings. Mutual evolutions of micro- and macro-dynamics in a temporal network alternately affect the process of learning node embeddings. Extensive experiments on three real-world temporal networks demonstrate that $\\rmM^2DNE $ significantly outperforms the state-of-the-arts not only in traditional tasks, e.g., network reconstruction, but also in temporal tendency-related tasks, e.g., scale prediction.\nAttributed Network Embedding for Learning in a Dynamic Environment (Jundong Li et al., 2017) Jundong Li, Harsh Dani, Xia Hu, Jiliang Tang, Yi Chang, Huan Liu. (2017)\nAttributed Network Embedding for Learning in a Dynamic Environment\nCIKM\nPaper Link\nInfluential Citation Count (20), SS-ID (736e8deabcae7e2f9eb6c41a1bfae1b5270a8dbd)\nABSTRACT\nNetwork embedding leverages the node proximity manifested to learn a low-dimensional node vector representation for each node in the network. The learned embeddings could advance various learning tasks such as node classification, network clustering, and link prediction. Most, if not all, of the existing works, are overwhelmingly performed in the context of plain and static networks. Nonetheless, in reality, network structure often evolves over time with addition/deletion of links and nodes. Also, a vast majority of real-world networks are associated with a rich set of node attributes, and their attribute values are also naturally changing, with the emerging of new content patterns and the fading of old content patterns. These changing characteristics motivate us to seek an effective embedding representation to capture network and attribute evolving patterns, which is of fundamental importance for learning in a dynamic environment. To our best knowledge, we are the first to tackle this problem with the following two challenges: (1) the inherently correlated network and node attributes could be noisy and incomplete, it necessitates a robust consensus representation to capture their individual properties and correlations; (2) the embedding learning needs to be performed in an online fashion to adapt to the changes accordingly. In this paper, we tackle this problem by proposing a novel dynamic attributed network embedding framework - DANE. In particular, DANE first provides an offline method for a consensus embedding and then leverages matrix perturbation theory to maintain the freshness of the end embedding results in an online manner. We perform extensive experiments on both synthetic and real attributed networks to corroborate the effectiveness and efficiency of the proposed framework.\nGraph Regularized Nonnegative Matrix Factorization for Data Representation (Zhenqiu Shu et al., 2017) Zhenqiu Shu, Xiaojun Wu, H. Fan, Pu Huang, Dong Wu, Cong Hu, Feiyue Ye. (2017)\nGraph Regularized Nonnegative Matrix Factorization for Data Representation\nIEEE Transactions on Pattern Analysis and Machine Intelligence\nPaper Link\nInfluential Citation Count (280), SS-ID (774dd71f42cca20aa0eaf93fc337ab48fb123fd1)\nABSTRACT\nGraphs over time: densification laws, shrinking diameters and possible explanations (J. Leskovec et al., 2005) J. Leskovec, J. Kleinberg, C. Faloutsos. (2005)\nGraphs over time: densification laws, shrinking diameters and possible explanations\nKDD \u0026lsquo;05\nPaper Link\nInfluential Citation Count (183), SS-ID (788b6f36a2b7cab86a5a29000e8b7cde25b85e73)\nABSTRACT\nHow do real graphs evolve over time? What are \u0026ldquo;normal\u0026rdquo; growth patterns in social, technological, and information networks? Many studies have discovered patterns in static graphs, identifying properties in a single snapshot of a large network, or in a very small number of snapshots; these include heavy tails for in- and out-degree distributions, communities, small-world phenomena, and others. However, given the lack of information about network evolution over long periods, it has been hard to convert these findings into statements about trends over time.Here we study a wide range of real graphs, and we observe some surprising phenomena. First, most of these graphs densify over time, with the number of edges growing super-linearly in the number of nodes. Second, the average distance between nodes often shrinks over time, in contrast to the conventional wisdom that such distance parameters should increase slowly as a function of the number of nodes (like O(log n) or O(log(log n)).Existing graph generation models do not exhibit these types of behavior, even at a qualitative level. We provide a new graph generator, based on a \u0026ldquo;forest fire\u0026rdquo; spreading process, that has a simple, intuitive justification, requires very few parameters (like the \u0026ldquo;flammability\u0026rdquo; of nodes), and produces graphs exhibiting the full range of properties observed both in prior work and in the present study.\nDynamic Network Embedding by Modeling Triadic Closure Process (Le-kui Zhou et al., 2018) Le-kui Zhou, Yang Yang, Xiang Ren, Fei Wu, Yueting Zhuang. (2018)\nDynamic Network Embedding by Modeling Triadic Closure Process\nAAAI\nPaper Link\nInfluential Citation Count (43), SS-ID (7bfb46c47c25e46a5f7b168133f4e926ab44725b)\nABSTRACT\nNetwork embedding, which aims to learn the low-dimensional representations of vertices, is an important task and has attracted considerable research efforts recently. In real world, networks, like social network and biological networks, are dynamic and evolving over time. However, almost all the existing network embedding methods focus on static networks while ignore network dynamics. In this paper, we present a novel representation learning approach, DynamicTriad, to preserve both structural information and evolution patterns of a given network. The general idea of our approach is to impose triad, which is a group of three vertices and is one of the basic units of networks. In particular, we model how a closed triad, which consists of three vertices connected with each other, develops from an open triad that has two of three vertices not connected with each other. This triadic closure process is a fundamental mechanism in the formation and evolution of networks, thereby makes our model being able to capture the network dynamics and to learn representation vectors for each vertex at different time steps. Experimental results on three real-world networks demonstrate that, compared with several state-of-the-art techniques, DynamicTriad achieves substantial gains in several application scenarios. For example, our approach can effectively be applied and help to identify telephone frauds in a mobile network, and to predict whether a user will repay her loans or not in a loan network.\nLearning Convolutional Neural Networks for Graphs (Mathias Niepert et al., 2016) Mathias Niepert, Mohamed Ahmed, Konstantin Kutzkov. (2016)\nLearning Convolutional Neural Networks for Graphs\nICML\nPaper Link\nInfluential Citation Count (142), SS-ID (7c6de5a9e02a779e24504619050c6118f4eac181)\nABSTRACT\nNumerous important problems can be framed as learning from graph data. We propose a framework for learning convolutional neural networks for arbitrary graphs. These graphs may be undirected, directed, and with both discrete and continuous node and edge attributes. Analogous to image-based convolutional networks that operate on locally connected regions of the input, we present a general approach to extracting locally connected regions from graphs. Using established benchmark data sets, we demonstrate that the learned feature representations are competitive with state of the art graph kernels and that their computation is highly efficient.\nDefining and evaluating network communities based on ground-truth (Jaewon Yang et al., 2012) Jaewon Yang, J. Leskovec. (2012)\nDefining and evaluating network communities based on ground-truth\n2012 IEEE 12th International Conference on Data Mining\nPaper Link\nInfluential Citation Count (136), SS-ID (7fb27e0123ca907b55b8ef57afa1612731eba034)\nABSTRACT\nDynamic Heterogeneous Information Network Embedding With Meta-Path Based Proximity (Xiao Wang et al., 2022) Xiao Wang, Yuanfu Lu, C. Shi, Ruijia Wang, Peng Cui, Shuai Mou. (2022)\nDynamic Heterogeneous Information Network Embedding With Meta-Path Based Proximity\nIEEE Transactions on Knowledge and Data Engineering\nPaper Link\nInfluential Citation Count (1), SS-ID (83b1453cc9b618e05b0365c94cfb6c72969d2471)\nABSTRACT\nHeterogeneous information network (HIN) embedding aims at learning the low-dimensional representation of nodes while preserving structure and semantics in a HIN. Existing methods mainly focus on static networks, while a real HIN usually evolves over time with the addition (deletion) of multiple types of nodes and edges. Because even a tiny change can influence the whole structure and semantics, the conventional HIN embedding methods need to be retrained to get the updated embeddings, which is time-consuming and unrealistic. In this paper, we investigate the problem of dynamic HIN embedding and propose a novel Dynamic HIN Embedding model (DyHNE) with meta-path based proximity. Specifically, we introduce the meta-path based first- and second-order proximities to preserve structure and semantics in HINs. As the HIN evolves over time, we naturally capture changes with the perturbation of meta-path augmented adjacency matrices. Thereafter, we learn the node embeddings by solving generalized eigenvalue problem effectively and employ eigenvalue perturbation to derive the updated embeddings efficiently without retraining. Experiments show that DyHNE outperforms the state-of-the-arts in terms of effectiveness and efficiency.\nEffective Deep Attributed Network Representation Learning With Topology Adapted Smoothing (Jia Chen et al., 2021) Jia Chen, Ming Zhong, Jianxin Li, Dianhui Wang, T. Qian, Hang Tu. (2021)\nEffective Deep Attributed Network Representation Learning With Topology Adapted Smoothing\nIEEE Transactions on Cybernetics\nPaper Link\nInfluential Citation Count (0), SS-ID (884badccf2b56bd3727c1fafe21431ccbb82984f)\nABSTRACT\nAttributed networks are ubiquitous in the real world, such as social networks. Therefore, many researchers take the node attributes into consideration in the network representation learning to improve the downstream task performance. In this article, we mainly focus on an untouched “oversmoothing” problem in the research of the attributed network representation learning. Although the Laplacian smoothing has been applied by the state-of-the-art works to learn a more robust node representation, these works cannot adapt to the topological characteristics of different networks, thereby causing the new oversmoothing problem and reducing the performance on some networks. In contrast, we adopt a smoothing parameter that is evaluated from the topological characteristics of a specified network, such as small worldness or node convergency and, thus, can smooth the nodes’ attribute and structure information adaptively and derive both robust and distinguishable node features for different networks. Moreover, we develop an integrated autoencoder to learn the node representation by reconstructing the combination of the smoothed structure and attribute information. By observation of extensive experiments, our approach can preserve the intrinsical information of networks more effectively than the state-of-the-art works on a number of benchmark datasets with very different topological characteristics.\nRepresentation Learning for Dynamic Graphs: A Survey (Seyed Mehran Kazemi et al., 2019) Seyed Mehran Kazemi, Rishab Goel, Kshitij Jain, I. Kobyzev, Akshay Sethi, Peter Forsyth, P. Poupart, K. Borgwardt. (2019)\nRepresentation Learning for Dynamic Graphs: A Survey\nJ. Mach. Learn. Res.\nPaper Link\nInfluential Citation Count (11), SS-ID (8a8e4fa580a81ba2fcb86965f323709cafcab275)\nABSTRACT\nGraphs arise naturally in many real-world applications including social networks, recommender systems, ontologies, biology, and computational finance. Traditionally, machine learning models for graphs have been mostly designed for static graphs. However, many applications involve evolving graphs. This introduces important challenges for learning and inference since nodes, attributes, and edges change over time. In this survey, we review the recent advances in representation learning for dynamic graphs, including dynamic knowledge graphs. We describe existing models from an encoder-decoder perspective, categorize these encoders and decoders based on the techniques they employ, and analyze the approaches in each category. We also review several prominent applications and widely used datasets and highlight directions for future research.\nSession-Based Social Recommendation via Dynamic Graph Attention Networks (Weiping Song et al., 2019) Weiping Song, Zhiping Xiao, Yifan Wang, Laurent Charlin, Ming Zhang, Jian Tang. (2019)\nSession-Based Social Recommendation via Dynamic Graph Attention Networks\nWSDM\nPaper Link\nInfluential Citation Count (13), SS-ID (901a6ad54f3bfc0ca6671f4e492703c671475288)\nABSTRACT\nOnline communities such as Facebook and Twitter are enormously popular and have become an essential part of the daily life of many of their users. Through these platforms, users can discover and create information that others will then consume. In that context, recommending relevant information to users becomes critical for viability. However, recommendation in online communities is a challenging problem: 1) users\u0026rsquo; interests are dynamic, and 2) users are influenced by their friends. Moreover, the influencers may be context-dependent. That is, different friends may be relied upon for different topics. Modeling both signals is therefore essential for recommendations. We propose a recommender system for online communities based on a dynamic-graph-attention neural network. We model dynamic user behaviors with a recurrent neural network, and context-dependent social influence with a graph-attention neural network, which dynamically infers the influencers based on users\u0026rsquo; current interests. The whole model can be efficiently fit on large-scale data. Experimental results on several real-world data sets demonstrate the effectiveness of our proposed approach over several competitive baselines including state-of-the-art models.\nThe structure of scientific collaboration networks. (M. Newman, 2000) M. Newman. (2000)\nThe structure of scientific collaboration networks.\nProceedings of the National Academy of Sciences of the United States of America\nPaper Link\nInfluential Citation Count (299), SS-ID (944eb4fc8737f5dbe72f4a73f9db58418eec2758)\nABSTRACT\nThe structure of scientific collaboration networks is investigated. Two scientists are considered connected if they have authored a paper together and explicit networks of such connections are constructed by using data drawn from a number of databases, including MEDLINE (biomedical research), the Los Alamos e-Print Archive (physics), and NCSTRL (computer science). I show that these collaboration networks form \u0026ldquo;small worlds,\u0026rdquo; in which randomly chosen pairs of scientists are typically separated by only a short path of intermediate acquaintances. I further give results for mean and distribution of numbers of collaborators of authors, demonstrate the presence of clustering in the networks, and highlight a number of apparent differences in the patterns of collaboration between the fields studied.\nDepthLGP: Learning Embeddings of Out-of-Sample Nodes in Dynamic Networks (Jianxin Ma et al., 2018) Jianxin Ma, Peng Cui, Wenwu Zhu. (2018)\nDepthLGP: Learning Embeddings of Out-of-Sample Nodes in Dynamic Networks\nAAAI\nPaper Link\nInfluential Citation Count (2), SS-ID (9499b38866b1eb87ae43fa5be02f9d08cd3c20a8)\nABSTRACT\nNetwork embedding algorithms to date are primarily designed for static networks, where all nodes are known before learning. How to infer embeddings for out-of-sample nodes, i.e. nodes that arrive after learning, remains an open problem. The problem poses great challenges to existing methods, since the inferred embeddings should preserve intricate network properties such as high-order proximity, share similar characteristics (i.e. be of a homogeneous space) with in-sample node embeddings, and be of low computational cost. To overcome these challenges, we propose a Deeply Transformed High-order Laplacian Gaussian Process (DepthLGP) method to infer embeddings for out-of-sample nodes. DepthLGP combines the strength of nonparametric probabilistic modeling and deep learning. In particular, we design a high-order Laplacian Gaussian process (hLGP) to encode network properties, which permits fast and scalable inference. In order to further ensure homogeneity, we then employ a deep neural network to learn a nonlinear transformation from latent states of the hLGP to node embeddings. DepthLGP is general, in that it is applicable to embeddings learned by any network embedding algorithms. We theoretically prove the expressive power of DepthLGP, and conduct extensive experiments on real-world networks. Empirical results demonstrate that our approach can achieve significant performance gain over existing approaches.\nPatterns and dynamics of users\u0026#39; behavior and interaction: Network analysis of an online community (P. Panzarasa et al., 2009) P. Panzarasa, Tore Opsahl, Kathleen M. Carley. (2009)\nPatterns and dynamics of users\u0026rsquo; behavior and interaction: Network analysis of an online community\nJ. Assoc. Inf. Sci. Technol.\nPaper Link\nInfluential Citation Count (35), SS-ID (9642d274c43f1e764a3eacd021205a4813ee33dd)\nABSTRACT\nThis research draws on longitudinal network data from an online community to examine patterns of users\u0026rsquo; behavior and social interaction, and infer the processes underpinning dynamics of system use. The online community represents a prototypical example of a complex evolving social network in which connections between users are established over time by online messages. We study the evolution of a variety of properties since the inception of the system, including how users create, reciprocate, and deepen relationships with one another, variations in users\u0026rsquo; gregariousness and popularity, reachability and typical distances among users, and the degree of local redundancy in the system. Results indicate that the system is a “small world” characterized by the emergence, in its early stages, of a hub-dominated structure with heterogeneity in users\u0026rsquo; behavior. We investigate whether hubs are responsible for holding the system together and facilitating information flow, examine first-mover advantages underpinning users\u0026rsquo; ability to rise to system prominence, and uncover gender differences in users\u0026rsquo; gregariousness, popularity, and local redundancy. We discuss the implications of the results for research on system use and evolving social networks, and for a host of applications, including information diffusion, communities of practice, and the security and robustness of information systems. © 2009 Wiley Periodicals, Inc.\nCommunity Interaction and Conflict on the Web (Srijan Kumar et al., 2018) Srijan Kumar, William L. Hamilton, J. Leskovec, Dan Jurafsky. (2018)\nCommunity Interaction and Conflict on the Web\nWWW\nPaper Link\nInfluential Citation Count (17), SS-ID (9935c8f8a37360196d92221ec092ae1880d272b8)\nABSTRACT\nUsers organize themselves into communities on web platforms. These communities can interact with one another, often leading to conflicts and toxic interactions. However, little is known about the mechanisms of interactions between communities and how they impact users. Here we study intercommunity interactions across 36,000 communities on Reddit, examining cases where users of one community are mobilized by negative sentiment to comment in another community. We show that such conflicts tend to be initiated by a handful of communities\u0026mdash;less than 1% of communities start 74% of conflicts. While conflicts tend to be initiated by highly active community members, they are carried out by significantly less active members. We find that conflicts are marked by formation of echo chambers, where users primarily talk to other users from their own community. In the long-term, conflicts have adverse effects and reduce the overall activity of users in the targeted communities. Our analysis of user interactions also suggests strategies for mitigating the negative impact of conflicts\u0026mdash;such as increasing direct engagement between attackers and defenders. Further, we accurately predict whether a conflict will occur by creating a novel LSTM model that combines graph embeddings, user, community, and text features. This model can be used to create an early-warning system for community moderators to prevent conflicts. Altogether, this work presents a data-driven view of community interactions and conflict, and paves the way towards healthier online communities.\nDiffusion Convolutional Recurrent Neural Network: Data-Driven Traffic Forecasting (Yaguang Li et al., 2017) Yaguang Li, Rose Yu, C. Shahabi, Yan Liu. (2017)\nDiffusion Convolutional Recurrent Neural Network: Data-Driven Traffic Forecasting\nICLR\nPaper Link\nInfluential Citation Count (248), SS-ID (9ba0186ed40656329c421f55ada7313293e13f17)\nABSTRACT\nSpatiotemporal forecasting has various applications in neuroscience, climate and transportation domain. Traffic forecasting is one canonical example of such learning task. The task is challenging due to (1) complex spatial dependency on road networks, (2) non-linear temporal dynamics with changing road conditions and (3) inherent difficulty of long-term forecasting. To address these challenges, we propose to model the traffic flow as a diffusion process on a directed graph and introduce Diffusion Convolutional Recurrent Neural Network (DCRNN), a deep learning framework for traffic forecasting that incorporates both spatial and temporal dependency in the traffic flow. Specifically, DCRNN captures the spatial dependency using bidirectional random walks on the graph, and the temporal dependency using the encoder-decoder architecture with scheduled sampling. We evaluate the framework on two real-world large scale road network traffic datasets and observe consistent improvement of 12% - 15% over state-of-the-art baselines.\nHigh-Order Proximity Preserved Embedding for Dynamic Networks (Dingyuan Zhu et al., 2018) Dingyuan Zhu, Peng Cui, Ziwei Zhang, J. Pei, Wenwu Zhu. (2018)\nHigh-Order Proximity Preserved Embedding for Dynamic Networks\nIEEE Transactions on Knowledge and Data Engineering\nPaper Link\nInfluential Citation Count (2), SS-ID (a830dc13918f078f8e85d15995f678db5f4f7483)\nABSTRACT\nNetwork embedding, aiming to embed a network into a low dimensional vector space while preserving the inherent structural properties of the network, has attracted considerable attention. However, most existing embedding methods focus on the static network while neglecting the evolving characteristic of real-world networks. Meanwhile, most of previous methods cannot well preserve the high-order proximity, which is a critical structural property of networks. These problems motivate us to seek an effective and efficient way to preserve the high-order proximity in embedding vectors when the networks evolve over time. In this paper, we propose a novel method of Dynamic High-order Proximity preserved Embedding (DHPE). Specifically, we adopt the generalized SVD (GSVD) to preserve the high-order proximity. Then, by transforming the GSVD problem to a generalized eigenvalue problem, we propose a generalized eigen perturbation to incrementally update the results of GSVD to incorporate the changes of dynamic networks. Further, we propose an accelerated solution to the DHPE model so that it achieves a linear time complexity with respect to the number of nodes and number of changed edges in the network. Our empirical experiments on one synthetic network and several real-world networks demonstrate the effectiveness and efficiency of the proposed method.\nAddGraph: Anomaly Detection in Dynamic Graph Using Attention-based Temporal GCN (Li Zheng et al., 2019) Li Zheng, Zhenpeng Li, Jian Li, Zhao Li, Jun Gao. (2019)\nAddGraph: Anomaly Detection in Dynamic Graph Using Attention-based Temporal GCN\nIJCAI\nPaper Link\nInfluential Citation Count (5), SS-ID (a86efed0b0ae3a08460d1dd4b8a02f09659daccb)\nABSTRACT\nAnomaly detection in dynamic graphs becomes very critical in many different application scenarios, e.g., recommender systems, while it also raises huge challenges due to the high flexible nature of anomaly and lack of sufficient labelled data. It is better to learn the anomaly patterns by considering all possible features including the structural, content and temporal features, rather than utilizing heuristic rules over the partial features. In this paper, we propose AddGraph, a general end-to-end anomalous edge detection framework using an extended temporal GCN (Graph Convolutional Network) with an attention model, which can capture both long-term patterns and the short-term patterns in dynamic graphs. In order to cope with insufficient explicit labelled data, we employ the negative sampling and margin loss in training of AddGraph in a semi-supervised fashion. We conduct extensive experiments on real-world datasets, and illustrate that AddGraph can outperform the state-of-the-art competitors in anomaly detection significantly.\nLarge Scale Evolving Graphs with Burst Detection (Yifeng Zhao et al., 2019) Yifeng Zhao, Xiangwei Wang, Hongxia Yang, Le Song, Jie Tang. (2019)\nLarge Scale Evolving Graphs with Burst Detection\nIJCAI\nPaper Link\nInfluential Citation Count (1), SS-ID (a974e4a7e590d1e6abe0eaf5933e483802fd5666)\nABSTRACT\nAnalyzing large-scale evolving graphs are crucial for understanding the dynamic and evolutionary nature of social networks. Most existing works focus on discovering repeated and consistent temporal patterns, however, such patterns cannot fully explain the complexity observed in dynamic networks. For example, in recommendation scenarios, users sometimes purchase products on a whim during a window shopping.Thus, in this paper, we design and implement a novel framework called BurstGraph which can capture both recurrent and consistent patterns, and especially unexpected bursty network changes. The performance of the proposed algorithm is demonstrated on both a simulated dataset and a world-leading E-Commerce company dataset, showing that they are able to discriminate recurrent events from extremely bursty events in terms of action propensity.\nA Hierarchical Contextual Attention-based GRU Network for Sequential Recommendation (Qiang Cui et al., 2017) Qiang Cui, Shu Wu, Yan Huang, Liang Wang. (2017)\nA Hierarchical Contextual Attention-based GRU Network for Sequential Recommendation\nNeurocomputing\nPaper Link\nInfluential Citation Count (3), SS-ID (acc7631e25483f0b42630a784b65cef240c8a80b)\nABSTRACT\nEmpirical Evaluation of Gated Recurrent Neural Networks on Sequence Modeling (Junyoung Chung et al., 2014) Junyoung Chung, Çaglar Gülçehre, Kyunghyun Cho, Yoshua Bengio. (2014)\nEmpirical Evaluation of Gated Recurrent Neural Networks on Sequence Modeling\nArXiv\nPaper Link\nInfluential Citation Count (1287), SS-ID (adfcf065e15fd3bc9badf6145034c84dfb08f204)\nABSTRACT\nIn this paper we compare different types of recurrent units in recurrent neural networks (RNNs). Especially, we focus on more sophisticated units that implement a gating mechanism, such as a long short-term memory (LSTM) unit and a recently proposed gated recurrent unit (GRU). We evaluate these recurrent units on the tasks of polyphonic music modeling and speech signal modeling. Our experiments revealed that these advanced recurrent units are indeed better than more traditional recurrent units such as tanh units. Also, we found GRU to be comparable to LSTM.\nNonlinear dimensionality reduction by locally linear embedding. (S. Roweis et al., 2000) S. Roweis, L. Saul. (2000)\nNonlinear dimensionality reduction by locally linear embedding.\nScience\nPaper Link\nInfluential Citation Count (1574), SS-ID (afcd6da7637ddeef6715109aca248da7a24b1c65)\nABSTRACT\nMany areas of science depend on exploratory data analysis and visualization. The need to analyze large amounts of multivariate data raises the fundamental problem of dimensionality reduction: how to discover compact representations of high-dimensional data. Here, we introduce locally linear embedding (LLE), an unsupervised learning algorithm that computes low-dimensional, neighborhood-preserving embeddings of high-dimensional inputs. Unlike clustering methods for local dimensionality reduction, LLE maps its inputs into a single global coordinate system of lower dimensionality, and its optimizations do not involve local minima. By exploiting the local symmetries of linear reconstructions, LLE is able to learn the global structure of nonlinear manifolds, such as those generated by images of faces or documents of text.\nST-TrafficNet: A Spatial-Temporal Deep Learning Network for Traffic Forecasting (Huakang Lu et al., 2020) Huakang Lu, Dongmin Huang, Youyi Song, Dazhi Jiang, Teng Zhou, Jing Qin. (2020)\nST-TrafficNet: A Spatial-Temporal Deep Learning Network for Traffic Forecasting\nPaper Link\nInfluential Citation Count (0), SS-ID (b1418d8a941195c91ea1752e1a901abf9ee82bc1)\nABSTRACT\nThis paper presents a spatial-temporal deep learning network, termed ST-TrafficNet, for traffic flow forecasting. Recent deep learning methods highly relate accurate predetermined graph structure for the complex spatial dependencies of traffic flow, and ineffectively harvest high dimensional temporal features of the traffic flow. In this paper, a novel multi-diffusion convolution block constructed by an attentive diffusion convolution and bidirectional diffusion convolution is proposed, which is capable to extract precise potential spatial dependencies. Moreover, a stacked Long Short-Term Memory (LSTM) block is adopted to capture high-dimensional temporal features. By integrating the two blocks, the ST-TrafficNet can learn the spatial-temporal dependencies of intricate traffic data accurately. The performance of the ST-TrafficNet has been evaluated on two real-world benchmark datasets by comparing it with three commonly-used methods and seven state-of-the-art ones. The Mean Absolute Error (MAE), Root Mean Square Error (RMSE), and Mean Absolute Percentage Error (MAPE) of the proposed method outperform not only the commonly-used methods, but also the state-of-the-art ones in 15 min, 30 min, and 60 min time-steps.\nTrust Management for the Semantic Web (Matthew Richardson et al., 2003) Matthew Richardson, R. Agrawal, Pedro M. Domingos. (2003)\nTrust Management for the Semantic Web\nSEMWEB\nPaper Link\nInfluential Citation Count (58), SS-ID (b242449cfb6f681ad3c6cfd66afece3ba03bf35d)\nABSTRACT\nGraRep: Learning Graph Representations with Global Structural Information (Shaosheng Cao et al., 2015) Shaosheng Cao, Wei Lu, Qiongkai Xu. (2015)\nGraRep: Learning Graph Representations with Global Structural Information\nCIKM\nPaper Link\nInfluential Citation Count (142), SS-ID (c2fd72cb2a77941e655b5d949d0d59b01e173c3b)\nABSTRACT\nIn this paper, we present {GraRep}, a novel model for learning vertex representations of weighted graphs. This model learns low dimensional vectors to represent vertices appearing in a graph and, unlike existing work, integrates global structural information of the graph into the learning process. We also formally analyze the connections between our work and several previous research efforts, including the DeepWalk model of Perozzi et al. as well as the skip-gram model with negative sampling of Mikolov et al. We conduct experiments on a language network, a social network as well as a citation network and show that our learned global representations can be effectively used as features in tasks such as clustering, classification and visualization. Empirical results demonstrate that our representation significantly outperforms other state-of-the-art methods in such tasks.\nStructural Deep Network Embedding (Daixin Wang et al., 2016) Daixin Wang, Peng Cui, Wenwu Zhu. (2016)\nStructural Deep Network Embedding\nKDD\nPaper Link\nInfluential Citation Count (238), SS-ID (d0b7c8828f0fca4dd901674e8fb5bd464a187664)\nABSTRACT\nNetwork embedding is an important method to learn low-dimensional representations of vertexes in networks, aiming to capture and preserve the network structure. Almost all the existing network embedding methods adopt shallow models. However, since the underlying network structure is complex, shallow models cannot capture the highly non-linear network structure, resulting in sub-optimal network representations. Therefore, how to find a method that is able to effectively capture the highly non-linear network structure and preserve the global and local structure is an open yet important problem. To solve this problem, in this paper we propose a Structural Deep Network Embedding method, namely SDNE. More specifically, we first propose a semi-supervised deep model, which has multiple layers of non-linear functions, thereby being able to capture the highly non-linear network structure. Then we propose to exploit the first-order and second-order proximity jointly to preserve the network structure. The second-order proximity is used by the unsupervised component to capture the global network structure. While the first-order proximity is used as the supervised information in the supervised component to preserve the local network structure. By jointly optimizing them in the semi-supervised deep model, our method can preserve both the local and global network structure and is robust to sparse networks. Empirically, we conduct the experiments on five real-world networks, including a language network, a citation network and three social networks. The results show that compared to the baselines, our method can reconstruct the original network significantly better and achieves substantial gains in three applications, i.e. multi-label classification, link prediction and visualization.\nPredicting Dynamic Embedding Trajectory in Temporal Interaction Networks (Srijan Kumar et al., 2019) Srijan Kumar, Xikun Zhang, J. Leskovec. (2019)\nPredicting Dynamic Embedding Trajectory in Temporal Interaction Networks\nKDD\nPaper Link\nInfluential Citation Count (46), SS-ID (d584d87b5a4c51c4ec231c692421dd17dd1e64be)\nABSTRACT\nModeling sequential interactions between users and items/products is crucial in domains such as e-commerce, social networking, and education. Representation learning presents an attractive opportunity to model the dynamic evolution of users and items, where each user/item can be embedded in a Euclidean space and its evolution can be modeled by an embedding trajectory in this space. However, existing dynamic embedding methods generate embeddings only when users take actions and do not explicitly model the future trajectory of the user/item in the embedding space. Here we propose JODIE, a coupled recurrent neural network model that learns the embedding trajectories of users and items. JODIE employs two recurrent neural networks to update the embedding of a user and an item at every interaction. Crucially, JODIE also models the future embedding trajectory of a user/item. To this end, it introduces a novel projection operator that learns to estimate the embedding of the user at any time in the future. These estimated embeddings are then used to predict future user-item interactions. To make the method scalable, we develop a t-Batch algorithm that creates time-consistent batches and leads to 9x faster training. We conduct six experiments to validate JODIE on two prediction tasks\u0026mdash;future interaction prediction and state change prediction\u0026mdash;using four real-world datasets. We show that JODIE outperforms six state-of-the-art algorithms in these tasks by at least 20% in predicting future interactions and 12% in state change prediction.\nCollective dynamics of ‘small-world’ networks (D. Watts et al., 1998) D. Watts, S. Strogatz. (1998)\nCollective dynamics of ‘small-world’ networks\nNature\nPaper Link\nInfluential Citation Count (2151), SS-ID (d61031326150ba23f90e6587c13d99188209250e)\nABSTRACT\nMotifs in Temporal Networks (Ashwin Paranjape et al., 2016) Ashwin Paranjape, Austin R. Benson, J. Leskovec. (2016)\nMotifs in Temporal Networks\nWSDM\nPaper Link\nInfluential Citation Count (56), SS-ID (d6b5baeaee6b5266bc2a3918f400fe831837376d)\nABSTRACT\nNetworks are a fundamental tool for modeling complex systems in a variety of domains including social and communication networks as well as biology and neuroscience. The counts of small subgraph patterns in networks, called network motifs, are crucial to understanding the structure and function of these systems. However, the role of network motifs for temporal networks, which contain many timestamped links between nodes, is not well understood. Here we develop a notion of a temporal network motif as an elementary unit of temporal networks and provide a general methodology for counting such motifs. We define temporal network motifs as induced subgraphs on sequences of edges, design several fast algorithms for counting temporal network motifs, and prove their runtime complexity. We also show that our fast algorithms achieve 1.3x to 56.5x speedups compared to a baseline method. We use our algorithms to count temporal network motifs in a variety of real-world datasets. Results show that networks from different domains have significantly different motif frequencies, whereas networks from the same domain tend to have similar motif frequencies. We also find that measuring motif counts at various time scales reveals different behavior.\nTrust Management for Semantic Web (Maryam Tahajod et al., 2009) Maryam Tahajod, A. Iranmehr, Nasim Khozooyi. (2009)\nTrust Management for Semantic Web\n2009 Second International Conference on Computer and Electrical Engineering\nPaper Link\nInfluential Citation Count (38), SS-ID (de837e0e18b4c695d0810f77074b9258b1b3264b)\nABSTRACT\nThe contemporary Web is heading towards its next stage of evolution. From a clump of unorganized information spaces, the Web is becoming more focused on the meaning of information that is a Semantic Web. Trust is an integral component in semantic web, allowing people to act under uncertainty and with the risk of negative consequences. In this paper we discussed trust management and its connection to the semantic web. We first discussed aspects of semantic web and trust management including defining trust and describing trust negotiations and then relationship of them. After that we explored how mechanisms of XML access control are used to protect the confidentiality, integrity and availability of ontologies in trust management.\nModeling Dynamic Heterogeneous Network for Link Prediction using Hierarchical Attention with Temporal RNN (Hansheng Xue et al., 2020) Hansheng Xue, Luwei Yang, Wen Jiang, Yi Wei, Y. Hu, Yu Lin. (2020)\nModeling Dynamic Heterogeneous Network for Link Prediction using Hierarchical Attention with Temporal RNN\nECML/PKDD\nPaper Link\nInfluential Citation Count (3), SS-ID (e2060d420ee4abbf993763a207754f702086af4e)\nABSTRACT\nHeterogeneous Graph Neural Network (Chuxu Zhang et al., 2019) Chuxu Zhang, Dongjin Song, Chao Huang, A. Swami, N. Chawla. (2019)\nHeterogeneous Graph Neural Network\nKDD\nPaper Link\nInfluential Citation Count (54), SS-ID (e3d662bbd0e5539fe22a85f3518f960595b9914e)\nABSTRACT\nRepresentation learning in heterogeneous graphs aims to pursue a meaningful vector representation for each node so as to facilitate downstream applications such as link prediction, personalized recommendation, node classification, etc. This task, however, is challenging not only because of the demand to incorporate heterogeneous structural (graph) information consisting of multiple types of nodes and edges, but also due to the need for considering heterogeneous attributes or contents (e.g., text or image) associated with each node. Despite a substantial amount of effort has been made to homogeneous (or heterogeneous) graph embedding, attributed graph embedding as well as graph neural networks, few of them can jointly consider heterogeneous structural (graph) information as well as heterogeneous contents information of each node effectively. In this paper, we propose HetGNN, a heterogeneous graph neural network model, to resolve this issue. Specifically, we first introduce a random walk with restart strategy to sample a fixed size of strongly correlated heterogeneous neighbors for each node and group them based upon node types. Next, we design a neural network architecture with two modules to aggregate feature information of those sampled neighboring nodes. The first module encodes \u0026ldquo;deep\u0026rdquo; feature interactions of heterogeneous contents and generates content embedding for each node. The second module aggregates content (attribute) embeddings of different neighboring groups (types) and further combines them by considering the impacts of different groups to obtain the ultimate node embedding. Finally, we leverage a graph context loss and a mini-batch gradient descent procedure to train the model in an end-to-end manner. Extensive experiments on several datasets demonstrate that HetGNN can outperform state-of-the-art baselines in various graph mining tasks, i.e., link prediction, recommendation, node classification \u0026amp; clustering and inductive node classification \u0026amp; clustering.\nH-VGRAE: A Hierarchical Stochastic Spatial-Temporal Embedding Method for Robust Anomaly Detection in Dynamic Networks (Chenming Yang et al., 2020) Chenming Yang, Liang Zhou, Hui Wen, Zhiheng Zhou, Yue Wu. (2020)\nH-VGRAE: A Hierarchical Stochastic Spatial-Temporal Embedding Method for Robust Anomaly Detection in Dynamic Networks\nArXiv\nPaper Link\nInfluential Citation Count (0), SS-ID (f19ecd4f61cd3497e9d0436512a81b8d75ffc551)\nABSTRACT\nDetecting anomalous edges and nodes in dynamic networks is critical in various areas, such as social media, computer networks, and so on. Recent approaches leverage network embedding technique to learn how to generate node representations for normal training samples and detect anomalies deviated from normal patterns. However, most existing network embedding approaches learn deterministic node representations, which are sensitive to fluctuations of the topology and attributes due to the high flexibility and stochasticity of dynamic networks. In this paper, a stochastic neural network, named by Hierarchical Variational Graph Recurrent Autoencoder (H-VGRAE), is proposed to detect anomalies in dynamic networks by the learned robust node representations in the form of random variables. H-VGRAE is a semi-supervised model to capture normal patterns in training set by maximizing the likelihood of the adjacency matrix and node attributes via variational inference. Comparing with existing methods, H-VGRAE has three main advantages: 1) H-VGRAE learns robust node representations through stochasticity modeling and the extraction of multi-scale spatial-temporal features; 2) H-VGRAE can be extended to deep structure with the increase of the dynamic network scale; 3) the anomalous edge and node can be located and interpreted from the probabilistic perspective. Extensive experiments on four real-world datasets demonstrate the outperformance of H-VGRAE on anomaly detection in dynamic networks compared with state-of-the-art competitors.\nSpatial-Temporal Synchronous Graph Convolutional Networks: A New Framework for Spatial-Temporal Network Data Forecasting (Chao Song et al., 2020) Chao Song, Youfang Lin, S. Guo, Huaiyu Wan. (2020)\nSpatial-Temporal Synchronous Graph Convolutional Networks: A New Framework for Spatial-Temporal Network Data Forecasting\nAAAI\nPaper Link\nInfluential Citation Count (32), SS-ID (f420663fe8c69ed5ea5236201a1f4c734cd145a7)\nABSTRACT\nSpatial-temporal network data forecasting is of great importance in a huge amount of applications for traffic management and urban planning. However, the underlying complex spatial-temporal correlations and heterogeneities make this problem challenging. Existing methods usually use separate components to capture spatial and temporal correlations and ignore the heterogeneities in spatial-temporal data. In this paper, we propose a novel model, named Spatial-Temporal Synchronous Graph Convolutional Networks (STSGCN), for spatial-temporal network data forecasting. The model is able to effectively capture the complex localized spatial-temporal correlations through an elaborately designed spatial-temporal synchronous modeling mechanism. Meanwhile, multiple modules for different time periods are designed in the model to effectively capture the heterogeneities in localized spatial-temporal graphs. Extensive experiments are conducted on four real-world datasets, which demonstrates that our method achieves the state-of-the-art performance and consistently outperforms other baselines.\nAuto-association by multilayer perceptrons and singular value decomposition (H. Bourlard et al., 1988) H. Bourlard, Y. Kamp. (1988)\nAuto-association by multilayer perceptrons and singular value decomposition\nBiological Cybernetics\nPaper Link\nInfluential Citation Count (46), SS-ID (f5821548720901c89b3b7481f7500d7cd64e99bd)\nABSTRACT\n‘S’ (P. Alam, 2021) P. Alam. (2021)\n‘S’\nComposites Engineering: An A–Z Guide\nPaper Link\nInfluential Citation Count (4531), SS-ID (f69f237073ef04043fdbd5bb6844b5b2da8e0930)\nABSTRACT\ndyngraph2vec: Capturing Network Dynamics using Dynamic Graph Representation Learning (Palash Goyal et al., 2018) Palash Goyal, Sujit Rokka Chhetri, A. Canedo. (2018)\ndyngraph2vec: Capturing Network Dynamics using Dynamic Graph Representation Learning\nKnowl. Based Syst.\nPaper Link\nInfluential Citation Count (26), SS-ID (f6e59062382fdec9b95c3abef1c27efc3b2ec1c7)\nABSTRACT\nDynamic Heterogeneous Graph Embedding Using Hierarchical Attentions (Luwei Yang et al., 2020) Luwei Yang, Zhibo Xiao, Wen Jiang, Yi Wei, Y. Hu, Hao Wang. (2020)\nDynamic Heterogeneous Graph Embedding Using Hierarchical Attentions\nECIR\nPaper Link\nInfluential Citation Count (2), SS-ID (ffe5b25c6cf8de37823907c3aed7738ea393902e)\nABSTRACT\nDeepWalk: online learning of social representations (Bryan Perozzi et al., 2014) Bryan Perozzi, Rami Al-Rfou, S. Skiena. (2014)\nDeepWalk: online learning of social representations\nKDD\nPaper Link\nInfluential Citation Count (1389), SS-ID (fff114cbba4f3ba900f33da574283e3de7f26c83)\nABSTRACT\nWe present DeepWalk, a novel approach for learning latent representations of vertices in a network. These latent representations encode social relations in a continuous vector space, which is easily exploited by statistical models. DeepWalk generalizes recent advancements in language modeling and unsupervised feature learning (or deep learning) from sequences of words to graphs. DeepWalk uses local information obtained from truncated random walks to learn latent representations by treating walks as the equivalent of sentences. We demonstrate DeepWalk\u0026rsquo;s latent representations on several multi-label network classification tasks for social networks such as BlogCatalog, Flickr, and YouTube. Our results show that DeepWalk outperforms challenging baselines which are allowed a global view of the network, especially in the presence of missing information. DeepWalk\u0026rsquo;s representations can provide F1 scores up to 10% higher than competing methods when labeled data is sparse. In some experiments, DeepWalk\u0026rsquo;s representations are able to outperform all baseline methods while using 60% less training data. DeepWalk is also scalable. It is an online learning algorithm which builds useful incremental results, and is trivially parallelizable. These qualities make it suitable for a broad class of real world applications such as network classification, and anomaly detection.\n","date":"July 26, 2022","hero":"/blog-akitenkrad/posts/papers/202207/20220726163444/hero.png","permalink":"https://akitenkrad.github.io/blog-akitenkrad/posts/papers/202207/20220726163444/","summary":"Round-1: Overview Round-2: Model Implementation Details Round-3: Experiments Citation Xue, G., Zhong, M., Li, J., Chen, J., Zhai, C., \u0026amp; Kong, R. (2022)\nDynamic network embedding survey\nNeurocomputing, 472, 212–223. https://doi.org/10.1016/J.NEUCOM.2021.03.138 Abstract Since many real world networks are evolving over time, such as social networks and user-item networks, there are increasing research efforts on dynamic network embedding in recent years. They learn node representations from a sequence of evolving graphs but not only the latest network, for preserving both structural and temporal information from the dynamic networks.","tags":["At:Round-1","Published:2022"],"title":"Dynamic Network Embedding Survey"},{"categories":null,"contents":" 等号 コマンド 出力 コマンド 出力 コマンド 出力 コマンド 出力 = $=$ \\neq $\\neq$ \\sim $\\sim$ \\simeq $\\simeq$ \\approx $\\approx$ \\fallingdotseq $\\fallingdotseq$ \\risingdotseq $\\risingdotseq$ \\equiv $\\equiv$ 不等号 コマンド 出力 コマンド 出力 コマンド 出力 コマンド 出力 \u0026gt; $\u0026gt;$ \u0026lt; $\u0026lt;$ \\geq $\\geq$ \\geqq $\\geqq$ \\leq $\\leq$ \\leqq $\\leqq$ \\gg $\\gg$ \\ll $\\ll$ 演算子 コマンド 出力 コマンド 出力 コマンド 出力 コマンド 出力 + $+$ - $-$ \\times $\\times$ \\div $\\div$ \\pm $\\pm$ \\mp $\\mp$ \\oplus $\\oplus$ \\ominus $\\ominus$ \\oslash $\\oslash$ \\circ $\\circ$ \\cdot $\\cdot$ \\bullet $\\bullet$ \\ltimes $\\ltimes$ \\rtimes $\\rtimes$ 集合 コマンド 出力 コマンド 出力 コマンド 出力 コマンド 出力 \\in $\\in$ \\ni $\\ni$ \\notin $\\notin$ \\subset $\\subset$ \\supset $\\supset$ \\subseteq $\\subseteq$ \\supseteq $\\supseteq$ \\nsubseteq $\\nsubseteq$ \\cap $\\cap$ \\cup $\\cup$ \\emptyset $\\emptyset$ \\infty $\\infty$ 括弧 コマンド 出力 コマンド 出力 コマンド 出力 コマンド 出力 () $()$ {}, \\lbrace \\rbrace $\\lbrace \\rbrace$ [], \\lbrack \\rbrack $\\lbrack \\rbrack$ \\lanble \\ranble $\\langle \\rangle$ ||, \\lvert \\rvert $\\lvert \\rvert$ \\|\\|, \\lVert \\rVert $\\lVert \\rVert$ \\lfloor \\rfloor $\\lfloor \\rfloor$ \\lceil \\rceil $\\lceil \\rceil $ \\ulcorner \\urcorner $\\ulcorner \\urcorner$ \\llcorner \\lrcorner $\\llcorner \\lrcorner$ 修飾 コマンド 出力 コマンド 出力 コマンド 出力 コマンド 出力 A^T $A^T$ A^\\mathrm{T} $A^\\mathrm{T}$ A^\\mathsf{T} $A^\\mathsf{T}$ A^\\intercal $A^\\intercal$ A^\\top $A^\\top$ x^{\\prime} $x^{\\prime}$ x^{\\backprime} $x^{\\backprime}$ \\hat{x} $\\hat{x}$ \\check{x} $\\check{x}$ \\grave{x} $\\grave{x}$ \\acute{x} $\\acute{x}$ \\breve{x} $\\breve{x}$ \\bar{x} $\\bar{x}$ \\tilde{x} $\\tilde{x}$ \\dot{x} $\\dot{x}$ \\ddot{x} $\\ddot{x}$ \\dddot{x} $\\dddot{x}$ \\vec{x} $\\vec{x}$ \\overrightarrow{x} $\\overrightarrow{x}$ \\widehat{x} $\\widehat{x}$ \\boldsymbol{x} $\\boldsymbol{x}$ \\overline{数式} $\\overline{数式}$ \\underline{数式} $\\underline{数式}$ \\overbrace{数式} $\\overbrace{数式}$ \\overbrace{数式}^{説明} $\\overbrace{数式}^{説明}$ \\underbrace{数式} $\\underbrace{数式}$ \\underbrace{数式}_{説明} $\\underbrace{数式}_{説明}$ 矢印 コマンド 出力 コマンド 出力 コマンド 出力 コマンド 出力 \\leftarrow, \\gets $\\gets$ \\rightarrow, \\to $\\to$ \\longleftarrow $\\longleftarrow$ \\longrightarrow $\\longrightarrow$ \\Leftarrow $\\Leftarrow$ \\Rightarrow $\\Rightarrow$ \\Longleftarrow $\\Longleftarrow$ \\Longrightarrow $\\Longrightarrow$ \\leftrightarrow $\\leftrightarrow$ \\longleftrightarrow $\\longleftrightarrow$ \\Leftrightarrow $\\Leftrightarrow$ \\Longleftrightarrow, \\iff $ \\Longleftrightarrow$ \\nearrow $\\nearrow$ \\swarrow $\\swarrow$ \\searrow $\\searrow$ \\nwarrow $\\nwarrow$ \\uparrow $\\uparrow$ \\downarrow $\\downarrow$ \\Uparrow $\\Uparrow$ \\Downarrow $\\Downarrow$ \\updownarrow $\\updownarrow$ \\Updownarrow $\\Updownarrow$ \\mapsto $\\mapsto$ \\longmapsto $\\longmapsto$ \\hookleftarrow $\\hookleftarrow$ \\hookrightarrow $\\hookrightarrow$ \\twoheadleftarrow $\\twoheadleftarrow$ \\twoheadrightarrow $\\twoheadrightarrow$ \\circlearrowleft $\\circlearrowleft$ \\circlearrowright $\\circlearrowright$ \\curvearrowleft $\\curvearrowleft$ \\curvearrowright $\\curvearrowright$ \\leftharpoonup $\\leftharpoonup$ \\rightharpoonup $\\rightharpoonup$ \\leftharpoondown $\\leftharpoondown$ \\rightharpoondown $\\rightharpoondown$ \\leftrightharpoons $\\leftrightharpoons$ \\rightleftharpoons $\\rightleftharpoons$ \\upharpoonleft $\\upharpoonleft$ \\upharpoonright $\\upharpoonright$ \\downharpoonleft $\\downharpoonleft$ \\downharpoonright $\\downharpoonright$ \\leftarrowtail $\\leftarrowtail$ \\rightarrowtail $\\rightarrowtail$ \\Lsh $\\Lsh$ \\Rsh $\\Rsh$ \\leftrightsquigarrow $\\leftrightsquigarrow$ \\rightsquigarrow $\\rightsquigarrow$ \\looparrowleft $\\looparrowleft$ \\looparrowright $\\looparrowright$ \\Lleftarrow $\\Lleftarrow$ \\Rrightarrow $\\Rrightarrow$ \\nleftarrow $\\nleftarrow$ \\nrightarrow $\\nrightarrow$ \\nLeftarrow $\\nLeftarrow$ \\nRightarrow $\\nRightarrow$ \\nleftrightarrow $\\nleftrightarrow$ \\nLeftrightarrow $\\nLeftrightarrow$ \\xleftarrow{a} $\\xleftarrow{a}$ \\xrightarrow{a} $\\xrightarrow{a}$ \\xleftarrow[b]{} $\\xleftarrow[b]{}$ \\xrightarrow[b]{} $\\xrightarrow[b]{}$ \\xleftarrow[b]{a} $\\xleftarrow[b]{a}$ \\xrightarrow[b]{a} $\\xrightarrow[b]{a}$ \\overset{\\mathrm{def}}{\\iff} $\\overset{\\mathrm{def}}{\\iff}$ ","date":"June 3, 2022","hero":"/blog-akitenkrad/posts/latex/hero.jpg","permalink":"https://akitenkrad.github.io/blog-akitenkrad/posts/latex/","summary":" 等号 コマンド 出力 コマンド 出力 コマンド 出力 コマンド 出力 = $=$ \\neq $\\neq$ \\sim $\\sim$ \\simeq $\\simeq$ \\approx $\\approx$ \\fallingdotseq $\\fallingdotseq$ \\risingdotseq $\\risingdotseq$ \\equiv $\\equiv$ 不等号 コマンド 出力 コマンド 出力 コマンド 出力 コマンド 出力 \u0026gt; $\u0026gt;$ \u0026lt; $\u0026lt;$ \\geq $\\geq$ \\geqq $\\geqq$ \\leq $\\leq$ \\leqq $\\leqq$ \\gg $\\gg$ \\ll $\\ll$ 演算子 コマンド 出力 コマンド 出力 コマンド 出力 コマンド 出力 + $+$ - $-$ \\times $\\times$ \\div $\\div$ \\pm $\\pm$ \\mp $\\mp$ \\oplus $\\oplus$ \\ominus $\\ominus$ \\oslash $\\oslash$ \\circ $\\circ$ \\cdot $\\cdot$ \\bullet $\\bullet$ \\ltimes $\\ltimes$ \\rtimes $\\rtimes$ 集合 コマンド 出力 コマンド 出力 コマンド 出力 コマンド 出力 \\in $\\in$ \\ni $\\ni$ \\notin $\\notin$ \\subset $\\subset$ \\supset $\\supset$ \\subseteq $\\subseteq$ \\supseteq $\\supseteq$ \\nsubseteq $\\nsubseteq$ \\cap $\\cap$ \\cup $\\cup$ \\emptyset $\\emptyset$ \\infty $\\infty$ 括弧 コマンド 出力 コマンド 出力 コマンド 出力 コマンド 出力 () $()$ {}, \\lbrace \\rbrace $\\lbrace \\rbrace$ [], \\lbrack \\rbrack $\\lbrack \\rbrack$ \\lanble \\ranble $\\langle \\rangle$ ||, \\lvert \\rvert $\\lvert \\rvert$ \\|\\|, \\lVert \\rVert $\\lVert \\rVert$ \\lfloor \\rfloor $\\lfloor \\rfloor$ \\lceil \\rceil $\\lceil \\rceil $ \\ulcorner \\urcorner $\\ulcorner \\urcorner$ \\llcorner \\lrcorner $\\llcorner \\lrcorner$ 修飾 コマンド 出力 コマンド 出力 コマンド 出力 コマンド 出力 A^T $A^T$ A^\\mathrm{T} $A^\\mathrm{T}$ A^\\mathsf{T} $A^\\mathsf{T}$ A^\\intercal $A^\\intercal$ A^\\top $A^\\top$ x^{\\prime} $x^{\\prime}$ x^{\\backprime} $x^{\\backprime}$ \\hat{x} $\\hat{x}$ \\check{x} $\\check{x}$ \\grave{x} $\\grave{x}$ \\acute{x} $\\acute{x}$ \\breve{x} $\\breve{x}$ \\bar{x} $\\bar{x}$ \\tilde{x} $\\tilde{x}$ \\dot{x} $\\dot{x}$ \\ddot{x} $\\ddot{x}$ \\dddot{x} $\\dddot{x}$ \\vec{x} $\\vec{x}$ \\overrightarrow{x} $\\overrightarrow{x}$ \\widehat{x} $\\widehat{x}$ \\boldsymbol{x} $\\boldsymbol{x}$ \\overline{数式} $\\overline{数式}$ \\underline{数式} $\\underline{数式}$ \\overbrace{数式} $\\overbrace{数式}$ \\overbrace{数式}^{説明} $\\overbrace{数式}^{説明}$ \\underbrace{数式} $\\underbrace{数式}$ \\underbrace{数式}_{説明} $\\underbrace{数式}_{説明}$ 矢印 コマンド 出力 コマンド 出力 コマンド 出力 コマンド 出力 \\leftarrow, \\gets $\\gets$ \\rightarrow, \\to $\\to$ \\longleftarrow $\\longleftarrow$ \\longrightarrow $\\longrightarrow$ \\Leftarrow $\\Leftarrow$ \\Rightarrow $\\Rightarrow$ \\Longleftarrow $\\Longleftarrow$ \\Longrightarrow $\\Longrightarrow$ \\leftrightarrow $\\leftrightarrow$ \\longleftrightarrow $\\longleftrightarrow$ \\Leftrightarrow $\\Leftrightarrow$ \\Longleftrightarrow, \\iff $ \\Longleftrightarrow$ \\nearrow $\\nearrow$ \\swarrow $\\swarrow$ \\searrow $\\searrow$ \\nwarrow $\\nwarrow$ \\uparrow $\\uparrow$ \\downarrow $\\downarrow$ \\Uparrow $\\Uparrow$ \\Downarrow $\\Downarrow$ \\updownarrow $\\updownarrow$ \\Updownarrow $\\Updownarrow$ \\mapsto $\\mapsto$ \\longmapsto $\\longmapsto$ \\hookleftarrow $\\hookleftarrow$ \\hookrightarrow $\\hookrightarrow$ \\twoheadleftarrow $\\twoheadleftarrow$ \\twoheadrightarrow $\\twoheadrightarrow$ \\circlearrowleft $\\circlearrowleft$ \\circlearrowright $\\circlearrowright$ \\curvearrowleft $\\curvearrowleft$ \\curvearrowright $\\curvearrowright$ \\leftharpoonup $\\leftharpoonup$ \\rightharpoonup $\\rightharpoonup$ \\leftharpoondown $\\leftharpoondown$ \\rightharpoondown $\\rightharpoondown$ \\leftrightharpoons $\\leftrightharpoons$ \\rightleftharpoons $\\rightleftharpoons$ \\upharpoonleft $\\upharpoonleft$ \\upharpoonright $\\upharpoonright$ \\downharpoonleft $\\downharpoonleft$ \\downharpoonright $\\downharpoonright$ \\leftarrowtail $\\leftarrowtail$ \\rightarrowtail $\\rightarrowtail$ \\Lsh $\\Lsh$ \\Rsh $\\Rsh$ \\leftrightsquigarrow $\\leftrightsquigarrow$ \\rightsquigarrow $\\rightsquigarrow$ \\looparrowleft $\\looparrowleft$ \\looparrowright $\\looparrowright$ \\Lleftarrow $\\Lleftarrow$ \\Rrightarrow $\\Rrightarrow$ \\nleftarrow $\\nleftarrow$ \\nrightarrow $\\nrightarrow$ \\nLeftarrow $\\nLeftarrow$ \\nRightarrow $\\nRightarrow$ \\nleftrightarrow $\\nleftrightarrow$ \\nLeftrightarrow $\\nLeftrightarrow$ \\xleftarrow{a} $\\xleftarrow{a}$ \\xrightarrow{a} $\\xrightarrow{a}$ \\xleftarrow[b]{} $\\xleftarrow[b]{}$ \\xrightarrow[b]{} $\\xrightarrow[b]{}$ \\xleftarrow[b]{a} $\\xleftarrow[b]{a}$ \\xrightarrow[b]{a} $\\xrightarrow[b]{a}$ \\overset{\\mathrm{def}}{\\iff} $\\overset{\\mathrm{def}}{\\iff}$ ","tags":["Latex"],"title":"Latex Mathematics Syntax Guide"},{"categories":null,"contents":" Round-1: Overview Round-2: Model Implementation Details Round-3: Experiments Citation Sennrich, R., Haddow, B., \u0026amp; Birch, A. (2015).\nNeural Machine Translation of Rare Words with Subword Units.\nhttps://doi.org/10.48550/arxiv.1508.07909 Abstract Neural machine translation (NMT) models typically operate with a fixed vocabulary, but translation is an open-vocabulary problem. Previous work addresses the translation of out-of-vocabulary words by backing off to a dictionary. In this paper, we introduce a simpler and more effective approach, making the NMT model capable of open-vocabulary translation by encoding rare and unknown words as sequences of subword units. This is based on the intuition that various word classes are translatable via smaller units than words, for instance names (via character copying or transliteration), compounds (via compositional translation), and cognates and loanwords (via phonological and morphological transformations). We discuss the suitability of different word segmentation techniques, including simple character n-gram models and a segmentation based on the byte pair encoding compression algorithm, and empirically show that subword models improve over a back-off dictionary baseline for the WMT 15 translation tasks English-German and English-Russian by 1.1 and 1.3 BLEU, respectively.\nWhat\u0026rsquo;s New Machine Translationは本来Open-Vocabularyなタスクだが，従来の研究の多くは事前に辞書を構築された辞書を使ってモデルを構築している．したがって，辞書に存在しない単語を翻訳することができない．そこで，単語をさらに粒度の小さなサブワードに分割することで出現頻度の低い単語や新出単語に対応する手法を提案した． n-gramモデル byte pair encoding 提案手法にて，WMT15タスクにおけるEnglish→German，English→Russianの翻訳でBLEUを改善することに成功した． Dataset EMNLP 2015 TENTH WORKSHOP ON STATISTICAL MACHINE TRANSLATION https://www.statmt.org/wmt15/index.html\n17-18 September 2015\nLisbon, Portugal Dataset Details\nModel Description Training Settings Results English → German English → Russian Translation using subword examples References Learning Phrase Representations using RNN Encoder–Decoder for Statistical Machine Translation (Kyunghyun Cho et al., 2014) Kyunghyun Cho, Bart van Merrienboer, Çaglar Gülçehre, Dzmitry Bahdanau, Fethi Bougares, Holger Schwenk, Yoshua Bengio. (2014)\nLearning Phrase Representations using RNN Encoder–Decoder for Statistical Machine Translation\nEMNLP\nPaper Link\nInfluential Citation Count (2602), SS-ID (0b544dfe355a5070b60986319a3f51fb45d1348e)\nABSTRACT\nIn this paper, we propose a novel neural network model called RNN Encoder‐ Decoder that consists of two recurrent neural networks (RNN). One RNN encodes a sequence of symbols into a fixedlength vector representation, and the other decodes the representation into another sequence of symbols. The encoder and decoder of the proposed model are jointly trained to maximize the conditional probability of a target sequence given a source sequence. The performance of a statistical machine translation system is empirically found to improve by using the conditional probabilities of phrase pairs computed by the RNN Encoder‐Decoder as an additional feature in the existing log-linear model. Qualitatively, we show that the proposed model learns a semantically and syntactically meaningful representation of linguistic phrases.\nUnsupervised Discovery of Morphemes (Mathias Creutz et al., 2002) Mathias Creutz, K. Lagus. (2002)\nUnsupervised Discovery of Morphemes\nSIGMORPHON\nPaper Link\nInfluential Citation Count (52), SS-ID (0c5043108eda7d2fa467fe91e3c47d4ba08e0b48)\nABSTRACT\nWe present two methods for unsupervised segmentation of words into morpheme-like units. The model utilized is especially suited for languages with a rich morphology, such as Finnish. The first method is based on the Minimum Description Length (MDL) principle and works online. In the second method, Maximum Likelihood (ML) optimization is used. The quality of the segmentations is measured using an evaluation method that compares the segmentations produced to an existing morphological analysis. Experiments on both Finnish and English corpora show that the presented methods perform well compared to a current state-of-the-art system.\nOn Using Very Large Target Vocabulary for Neural Machine Translation (Sébastien Jean et al., 2014) Sébastien Jean, Kyunghyun Cho, R. Memisevic, Yoshua Bengio. (2014)\nOn Using Very Large Target Vocabulary for Neural Machine Translation\nACL\nPaper Link\nInfluential Citation Count (75), SS-ID (1938624bb9b0f999536dcc8d8f519810bb4e1b3b)\nABSTRACT\nNeural machine translation, a recently proposed approach to machine translation based purely on neural networks, has shown promising results compared to the existing approaches such as phrase-based statistical machine translation. Despite its recent success, neural machine translation has its limitation in handling a larger vocabulary, as training complexity as well as decoding complexity increase proportionally to the number of target words. In this paper, we propose a method based on importance sampling that allows us to use a very large target vocabulary without increasing training complexity. We show that decoding can be efficiently done even with the model having a very large target vocabulary by selecting only a small subset of the whole target vocabulary. The models trained by the proposed approach are empirically found to outperform the baseline models with a small vocabulary as well as the LSTM-based neural machine translation models. Furthermore, when we use the ensemble of a few models with very large target vocabularies, we achieve the state-of-the-art translation performance (measured by BLEU) on the English!German translation and almost as high performance as state-of-the-art English!French translation system.\nAddressing the Rare Word Problem in Neural Machine Translation (Thang Luong et al., 2014) Thang Luong, Ilya Sutskever, Quoc V. Le, Oriol Vinyals, Wojciech Zaremba. (2014)\nAddressing the Rare Word Problem in Neural Machine Translation\nACL\nPaper Link\nInfluential Citation Count (85), SS-ID (1956c239b3552e030db1b78951f64781101125ed)\nABSTRACT\nNeural Machine Translation (NMT) is a new approach to machine translation that has shown promising results that are comparable to traditional approaches. A significant weakness in conventional NMT systems is their inability to correctly translate very rare words: end-to-end NMTs tend to have relatively small vocabularies with a single unk symbol that represents every possible out-of-vocabulary (OOV) word. In this paper, we propose and implement an effective technique to address this problem. We train an NMT system on data that is augmented by the output of a word alignment algorithm, allowing the NMT system to emit, for each OOV word in the target sentence, the position of its corresponding word in the source sentence. This information is later utilized in a post-processing step that translates every OOV word using a dictionary. Our experiments on the WMT’14 English to French translation task show that this method provides a substantial improvement of up to 2.8 BLEU points over an equivalent NMT system that does not use this technique. With 37.5 BLEU points, our NMT system is the first to surpass the best result achieved on a WMT’14 contest task.\nA new algorithm for data compression (Philip Gage, 1994) Philip Gage. (1994)\nA new algorithm for data compression\nPaper Link\nInfluential Citation Count (85), SS-ID (1aa9c0045f1fe8c79cce03c7c14ef4b4643a21f8)\nABSTRACT\nData compression is becoming increasingly important as a way to stretch disk space and speed up data transfers. This article describes a simple general-purpose data compression algorithm, called Byte Pair Encoding (BPE), which provides almost as much compression as the popular Lempel, Ziv, and Welch (LZW) method [3, 2]. (I mention the LZW method in particular because it delivers good overall performance and is widely used.) BPE’s compression speed is somewhat slower than LZW’s, but BPE’s expansion is faster. The main advantage of BPE is the small, fast expansion routine, ideal for applications with limited memory. The accompanying C code provides an efficient implementation of the algorithm.\nSUBWORD LANGUAGE MODELING WITH NEURAL NETWORKS (Tomas Mikolov et al., 2011) Tomas Mikolov, Ilya Sutskever, Anoop Deoras, H. Le, Stefan Kombrink, J. Cernocký. (2011)\nSUBWORD LANGUAGE MODELING WITH NEURAL NETWORKS\nPaper Link\nInfluential Citation Count (17), SS-ID (1fd7fc06653723b05abe5f3d1de393ddcf6bdddb)\nABSTRACT\nWe explore the performance of several types of language mode ls on the word-level and the character-level language modelin g tasks. This includes two recently proposed recurrent neural netwo rk architectures, a feedforward neural network model, a maximum ent ropy model and the usual smoothed n-gram models. We then propose a simple technique for learning sub-word level units from th e data, and show that it combines advantages of both character and wo rdlevel models. Finally, we show that neural network based lan gu ge models can be order of magnitude smaller than compressed n-g ram models, at the same level of performance when applied to a Bro dcast news RT04 speech recognition task. By using sub-word un its, the size can be reduced even more.\nMontreal Neural Machine Translation Systems for WMT’15 (Sébastien Jean et al., 2015) Sébastien Jean, Orhan Firat, Kyunghyun Cho, R. Memisevic, Yoshua Bengio. (2015)\nMontreal Neural Machine Translation Systems for WMT’15\nWMT@EMNLP\nPaper Link\nInfluential Citation Count (13), SS-ID (25eb839f39507fe6983ad3e692b2f8d93a5cb0cc)\nABSTRACT\nNeural machine translation (NMT) systems have recently achieved results comparable to the state of the art on a few translation tasks, including English→French and English→German. The main purpose of the Montreal Institute for Learning Algorithms (MILA) submission to WMT’15 is to evaluate this new approach on a greater variety of language pairs. Furthermore, the human evaluation campaign may help us and the research community to better understand the behaviour of our systems. We use the RNNsearch architecture, which adds an attention mechanism to the encoderdecoder. We also leverage some of the recent developments in NMT, including the use of large vocabularies, unknown word replacement and, to a limited degree, the inclusion of monolingual language models.\nchrF: character n-gram F-score for automatic MT evaluation (Maja Popovic, 2015) Maja Popovic. (2015)\nchrF: character n-gram F-score for automatic MT evaluation\nWMT@EMNLP\nPaper Link\nInfluential Citation Count (63), SS-ID (285c165c81fc9275955147a892b9a039ec8b1052)\nABSTRACT\nWe propose the use of character n-gram F-score for automatic evaluation of machine translation output. Character ngrams have already been used as a part of more complex metrics, but their individual potential has not been investigated yet. We report system-level correlations with human rankings for 6-gram F1-score (CHRF) on the WMT12, WMT13 and WMT14 data as well as segment-level correlation for 6gram F1 (CHRF) and F3-scores (CHRF3) on WMT14 data for all available target languages. The results are very promising, especially for the CHRF3 score – for translation from English, this variant showed the highest segment-level correlations outperforming even the best metrics on the WMT14 shared evaluation task.\nUnsupervised Multilingual Learning for Morphological Segmentation (Benjamin Snyder et al., 2008) Benjamin Snyder, R. Barzilay. (2008)\nUnsupervised Multilingual Learning for Morphological Segmentation\nACL\nPaper Link\nInfluential Citation Count (8), SS-ID (36ffcc1cc218ca36de384a107fb48e5abe2e6359)\nABSTRACT\nFor centuries, the deep connection between languages has brought about major discoveries about human communication. In this paper we investigate how this powerful source of information can be exploited for unsupervised language learning. In particular, we study the task of morphological segmentation of multiple languages. We present a nonparametric Bayesian model that jointly induces morpheme segmentations of each language under consideration and at the same time identifies cross-lingual morpheme patterns, or abstract morphemes. We apply our model to three Semitic languages: Arabic, Hebrew, Aramaic, as well as to English. Our results demonstrate that learning morphological models in tandem reduces error by up to 24% relative to monolingual models. Furthermore, we provide evidence that our joint model achieves better performance when applied to languages from the same family.\nImproving SMT quality with morpho-syntactic analysis (S. Nießen et al., 2000) S. Nießen, H. Ney. (2000)\nImproving SMT quality with morpho-syntactic analysis\nCOLING\nPaper Link\nInfluential Citation Count (3), SS-ID (3dffe5ebf00f10dd137beff00d94952f1af658c3)\nABSTRACT\nIn the framework of statistical machine translation (SMT), correspondences between the words in the source and the target language are learned from bilingual corpora on the basis of so-called alignment models. Many of the statistical systems use little or no linguistic knowledge to structure the underlying models. In this paper we argue that training data is typically not large enough to sufficiently represent the range of different phenomena in natural languages and that SMT can take advantage of the explicit introduction of some knowledge about the languages under consideration. The improvement of the translation results is demonstrated on two different German-English corpora.\nCompositional Morphology for Word Representations and Language Modelling (Jan A. Botha et al., 2014) Jan A. Botha, P. Blunsom. (2014)\nCompositional Morphology for Word Representations and Language Modelling\nICML\nPaper Link\nInfluential Citation Count (22), SS-ID (46f418bf6fab132f193661226c5c27d67f870ea5)\nABSTRACT\nThis paper presents a scalable method for integrating compositional morphological representations into a vector-based probabilistic language model. Our approach is evaluated in the context of log-bilinear language models, rendered suitably efficient for implementation inside a machine translation decoder by factoring the vocabulary. We perform both intrinsic and extrinsic evaluations, presenting results on a range of languages which demonstrate that our model learns morphological representations that both perform well on word similarity tasks and lead to substantial reductions in perplexity. When used for translation into morphologically rich languages with large vocabularies, our models obtain improvements of up to 1.2 BLEU points relative to a baseline system using back-off n-gram models.\nMoses: Open Source Toolkit for Statistical Machine Translation (Philipp Koehn et al., 2007) Philipp Koehn, Hieu T. Hoang, Alexandra Birch, Chris Callison-Burch, Marcello Federico, N. Bertoldi, Brooke Cowan, Wade Shen, C. Moran, R. Zens, Chris Dyer, Ondrej Bojar, Alexandra Constantin, Evan Herbst. (2007)\nMoses: Open Source Toolkit for Statistical Machine Translation\nACL\nPaper Link\nInfluential Citation Count (807), SS-ID (4ee2eab4c298c1824a9fb8799ad8eed21be38d21)\nABSTRACT\nWe describe an open-source toolkit for statistical machine translation whose novel contributions are (a) support for linguistically motivated factors, (b) confusion network decoding, and (c) efficient data formats for translation models and language models. In addition to the SMT decoder, the toolkit also includes a wide variety of tools for training, tuning and applying the system to many translation tasks.\nBetter Word Representations with Recursive Neural Networks for Morphology (Thang Luong et al., 2013) Thang Luong, R. Socher, Christopher D. Manning. (2013)\nBetter Word Representations with Recursive Neural Networks for Morphology\nCoNLL\nPaper Link\nInfluential Citation Count (70), SS-ID (53ab89807caead278d3deb7b6a4180b277d3cb77)\nABSTRACT\nVector-space word representations have been very successful in recent years at improving performance across a variety of NLP tasks. However, common to most existing work, words are regarded as independent entities without any explicit relationship among morphologically related words being modeled. As a result, rare and complex words are often poorly estimated, and all unknown words are represented in a rather crude way using only one or a few vectors. This paper addresses this shortcoming by proposing a novel model that is capable of building representations for morphologically complex words from their morphemes. We combine recursive neural networks (RNNs), where each morpheme is a basic unit, with neural language models (NLMs) to consider contextual information in learning morphologicallyaware word representations. Our learned models outperform existing word representations by a good margin on word similarity tasks across many datasets, including a new dataset we introduce focused on rare words to complement existing ones in an interesting way.\nAssociation for Computational Linguistics (D. Litman et al., 2001) D. Litman, J. Hirschberg, M. Swerts, Scott Miller, L. Ramshaw, R. Weischedel, Eugene Charniak, Lillian Lee. (2001)\nAssociation for Computational Linguistics\nPaper Link\nInfluential Citation Count (67), SS-ID (566eb7be43b8a2b2daff82b03711098a84859b2a)\nABSTRACT\nUnsupervised Morphology Rivals Supervised Morphology for Arabic MT (D. Stallard et al., 2012) D. Stallard, Jacob Devlin, Michael Kayser, Yoong Keok Lee, R. Barzilay. (2012)\nUnsupervised Morphology Rivals Supervised Morphology for Arabic MT\nACL\nPaper Link\nInfluential Citation Count (1), SS-ID (5ab5cc1c135a1af68fdea604474b70f4121db623)\nABSTRACT\nIf unsupervised morphological analyzers could approach the effectiveness of supervised ones, they would be a very attractive choice for improving MT performance on low-resource inflected languages. In this paper, we compare performance gains for state-of-the-art supervised vs. unsupervised morphological analyzers, using a state-of-the-art Arabic-to-English MT system. We apply maximum marginal decoding to the unsupervised analyzer, and show that this yields the best published segmentation accuracy for Arabic, while also making segmentation output more stable. Our approach gives an 18% relative BLEU gain for Levantine dialectal Arabic. Furthermore, it gives higher gains for Modern Standard Arabic (MSA), as measured on NIST MT-08, than does MADA (Habash and Rambow, 2005), a leading supervised MSA segmenter.\nResults of the WMT13 Metrics Shared Task (Ondrej Bojar et al., 2016) Ondrej Bojar, Yvette Graham, Amir Kamran, Miloš Stanojević. (2016)\nResults of the WMT13 Metrics Shared Task\nWMT@EMNLP\nPaper Link\nInfluential Citation Count (10), SS-ID (626331a8284feaa059555d4ea808b78ace5de4a5)\nABSTRACT\nThis paper presents the results of the WMT16 Metrics Shared Task. We asked participants of this task to score the outputs of the MT systems involved in the WMT16 Shared Translation Task. We collected scores of 16 metrics from 9 research groups. In addition to that, we computed scores of 9 standard metrics (BLEU, SentBLEU, NIST, WER, PER, TER and CDER) as baselines. The collected scores were evaluated in terms of system-level correlation (how well each metric’s scores correlate with WMT16 official manual ranking of systems) and in terms of segment level correlation (how often a metric agrees with humans in comparing two translations of a particular sentence). This year there are several additions to the setup: large number of language pairs (18 in total), datasets from different domains (news, IT and medical), and different kinds of judgments: relative ranking (RR), direct assessment (DA) and HUME manual semantic judgments. Finally, generation of large number of hybrid systems was trialed for provision of more conclusive system-level metric rankings.\nWord hy-phen-a-tion by com-put-er (hyphenation, computer) (Franklin Mark Liang, 1983) Franklin Mark Liang. (1983)\nWord hy-phen-a-tion by com-put-er (hyphenation, computer)\nPaper Link\nInfluential Citation Count (14), SS-ID (6c0f01c67f43e35859025d3424e0268b4d1ee2f1)\nABSTRACT\nThis thesis describes research leading to an improved word hyphenation algorithm for the T(,E)X82 typesetting system. Hyphenation is viewed primarily as a data compression problem, where we are given a dictionary of words with allowable division points, and try to devise methods that take advantage of the large amount of redundancy present. The new hyphenation algorithm is based on the idea of hyphenating and inhibiting patterns. These are simply strings of letters that, when they match in a word, give us information about hyphenation at some point in the pattern. For example, \u0026lsquo;-tion\u0026rsquo; and \u0026lsquo;c-c\u0026rsquo; are good hyphenating patterns. An important feature of this method is that a suitable set of patterns can be extracted automatically from the dictionary. In order to represent the set of patterns in a compact form that is also reasonably efficient for searching, the author has developed a new data structure called a packed trie. This data structure allows the very fast search times characteristic of indexed tries, but in many cases it entirely eliminates the wasted space for null links usually present in such tries. We demonstrate the versatility and practical advantages of this data structure by using a variant of it as the critical component of the program that generates the patterns from the dictionary. The resulting hyphenation algorithm uses about 4500 patterns that compile into a packed trie occupying 25K bytes of storage. These patterns find 89% of the hyphens in a pocket dictionary word list, with essentially no error. By comparison, the uncompressed dictionary occupies over 500K bytes.\nFinding Function in Form: Compositional Character Models for Open Vocabulary Word Representation (Wang Ling et al., 2015) Wang Ling, Chris Dyer, A. Black, I. Trancoso, Ramón Fernández Astudillo, Silvio Amir, Luís Marujo, T. Luís. (2015)\nFinding Function in Form: Compositional Character Models for Open Vocabulary Word Representation\nEMNLP\nPaper Link\nInfluential Citation Count (78), SS-ID (6dab1c6491929d396e9e5463bc2e87af88602aa2)\nABSTRACT\nWe introduce a model for constructing vector representations of words by composing characters using bidirectional LSTMs. Relative to traditional word representation models that have independent vectors for each word type, our model requires only a single vector per character type and a fixed set of parameters for the compositional model. Despite the compactness of this model and, more importantly, the arbitrary nature of the form‐function relationship in language, our “composed” word representations yield state-of-the-art results in language modeling and part-of-speech tagging. Benefits over traditional baselines are particularly pronounced in morphologically rich languages (e.g., Turkish).\nCharacter-Based PSMT for Closely Related Languages (J. Tiedemann, 2009) J. Tiedemann. (2009)\nCharacter-Based PSMT for Closely Related Languages\nEAMT\nPaper Link\nInfluential Citation Count (4), SS-ID (71088c81d1fb157844c61ac24fb1dd2a70d0e59f)\nABSTRACT\nTranslating unknown words between related languages using a character-based statistical machine translation model can be beneficial. In this paper, we describe a simple method to combine character-based models with standard word-based models to increase the coverage of a phrase-based SMT system. Using this approach, we can show a modest improvement when translating between Norwegian and Swedish. The potentials of applying character-based models to closely related languages is also illustrated by applying the character model on its own. The performance of such an approach is similar to the word-level baseline and closer to the reference in terms of string similarity.\nA Joint Dependency Model of Morphological and Syntactic Structure for Statistical Machine Translation (Rico Sennrich et al., 2015) Rico Sennrich, B. Haddow. (2015)\nA Joint Dependency Model of Morphological and Syntactic Structure for Statistical Machine Translation\nEMNLP\nPaper Link\nInfluential Citation Count (0), SS-ID (726244c312dc1145e9e9ee32ce641ab8dd9c6e74)\nABSTRACT\nWhen translating between two languages that differ in their degree of morphological synthesis, syntactic structures in one language may be realized as morphological structures in the other, and SMT models need a mechanism to learn such translations. Prior work has used morpheme splitting with flat representations that do not encode the hierarchical structure between morphemes, but this structure is relevant for learning morphosyntactic constraints and selectional preferences. We propose to model syntactic and morphological structure jointly in a dependency translation model, allowing the system to generalize to the level of morphemes. We present a dependency representation of German compounds and particle verbs that results in improvements in translation quality of 1.4‐1.8 BLEU in the WMT English‐German translation task.\nA Simple, Fast, and Effective Reparameterization of IBM Model 2 (Chris Dyer et al., 2013) Chris Dyer, Victor Chahuneau, Noah A. Smith. (2013)\nA Simple, Fast, and Effective Reparameterization of IBM Model 2\nNAACL\nPaper Link\nInfluential Citation Count (106), SS-ID (7b5e31257f01aba987f16e175a3e49e00a5bd3bb)\nABSTRACT\nWe present a simple log-linear reparameterization of IBM Model 2 that overcomes problems arising from Model 1’s strong assumptions and Model 2’s overparameterization. Efficient inference, likelihood evaluation, and parameter estimation algorithms are provided. Training the model is consistently ten times faster than Model 4. On three large-scale translation tasks, systems built using our alignment model outperform IBM Model 4. An open-source implementation of the alignment model described in this paper is available from http://github.com/clab/fast align .\nOn the difficulty of training recurrent neural networks (Razvan Pascanu et al., 2012) Razvan Pascanu, Tomas Mikolov, Yoshua Bengio. (2012)\nOn the difficulty of training recurrent neural networks\nICML\nPaper Link\nInfluential Citation Count (285), SS-ID (84069287da0a6b488b8c933f3cb5be759cb6237e)\nABSTRACT\nThere are two widely known issues with properly training recurrent neural networks, the vanishing and the exploding gradient problems detailed in Bengio et al. (1994). In this paper we attempt to improve the understanding of the underlying issues by exploring these problems from an analytical, a geometric and a dynamical systems perspective. Our analysis is used to justify a simple yet effective solution. We propose a gradient norm clipping strategy to deal with exploding gradients and a soft constraint for the vanishing gradients problem. We validate empirically our hypothesis and proposed solutions in the experimental section.\nADADELTA: An Adaptive Learning Rate Method (Matthew D. Zeiler, 2012) Matthew D. Zeiler. (2012)\nADADELTA: An Adaptive Learning Rate Method\nArXiv\nPaper Link\nInfluential Citation Count (784), SS-ID (8729441d734782c3ed532a7d2d9611b438c0a09a)\nABSTRACT\nWe present a novel per-dimension learning rate method for gradient descent called ADADELTA. The method dynamically adapts over time using only first order information and has minimal computational overhead beyond vanilla stochastic gradient descent. The method requires no manual tuning of a learning rate and appears robust to noisy gradient information, different model architecture choices, various data modalities and selection of hyperparameters. We show promising results compared to other methods on the MNIST digit classification task using a single machine and on a large scale voice dataset in a distributed cluster environment.\nMachine Translation without Words through Substring Alignment (Graham Neubig et al., 2012) Graham Neubig, Taro Watanabe, Shinsuke Mori, Tatsuya Kawahara. (2012)\nMachine Translation without Words through Substring Alignment\nACL\nPaper Link\nInfluential Citation Count (1), SS-ID (88b66f705a329da8292e7b8aa4bfe26de4759cfa)\nABSTRACT\nIn this paper, we demonstrate that accurate machine translation is possible without the concept of \u0026ldquo;words,\u0026rdquo; treating MT as a problem of transformation between character strings. We achieve this result by applying phrasal inversion transduction grammar alignment techniques to character strings to train a character-based translation model, and using this in the phrase-based MT framework. We also propose a look-ahead parsing algorithm and substring-informed prior probabilities to achieve more effective and efficient alignment. In an evaluation, we demonstrate that character-based translation can achieve results that compare to word-based systems while effectively translating unknown and uncommon words over several language pairs.\nCharacter-Aware Neural Language Models (Yoon Kim et al., 2015) Yoon Kim, Yacine Jernite, D. Sontag, Alexander M. Rush. (2015)\nCharacter-Aware Neural Language Models\nAAAI\nPaper Link\nInfluential Citation Count (166), SS-ID (891ce1687e2befddd19f54e4eef1d3f39c8dbaf7)\nABSTRACT\nWe describe a simple neural language model that relies only on character-level inputs. Predictions are still made at the word-level. Our model employs a convolutional neural network (CNN) and a highway network over characters, whose output is given to a long short-term memory (LSTM) recurrent neural network language model (RNN-LM). On the English Penn Treebank the model is on par with the existing state-of-the-art despite having 60% fewer parameters. On languages with rich morphology (Arabic, Czech, French, German, Spanish, Russian), the model outperforms word-level/morpheme-level LSTM baselines, again with fewer parameters. The results suggest that on many languages, character inputs are sufficient for language modeling. Analysis of word representations obtained from the character composition part of the model reveals that the model is able to encode, from characters only, both semantic and orthographic information.\nVariable length word encodings for neural translation models (Jiameng Gao, 2016) Jiameng Gao. (2016)\nVariable length word encodings for neural translation models\nPaper Link\nInfluential Citation Count (0), SS-ID (8c3cf30db12d17638b01e0e464e09d6b58a88187)\nABSTRACT\nAs described by Zipf’s law, vast proportions of words in most natural languages occur very infrequently, meaning that in a statistical learning framework these words would be poorly modelled for any given corpus of practical, finite size. This is known as the rare word problem. This is often worsened by the implementation of neural networks, since neural networks make use of softmax functions in the output layer. Evaluating these functions for each word in the vocabulary becomes computationally expensive in both training and runtime, as the normalisation constant is a summation of exponentials in the order O(|V|), where V is the output vocabulary. A simple method to counteract this is to label rare and infrequent words in the training corpus as an unknown word token, thereby limiting the size of the vocabulary. Nevertheless, doing so only worsens the fact that, for a given translation corpus, the vocabulary may not include all words in the natural languages involved. This is an issue in agglutinative languages, where unseen, legitimate words can be formed from known constituent words, making them di cult to model. This is known as the unknown word problem. We attempt to implement LSTM recurrent neural network language models based on Zaremba et al. (2014) for rescoring in the Syntactical-Guided Neural Machine Translation system by Stahlberg et al. (2016). Further, we compare methods to compress the vocabulary of a language through certain coding schemes, in order to reduce the impact of the computationally expensive softmax layer, and investigate there are better ways to represent natural language in neural network structures other than using tokens on the word level. Previous work have focused on word encodings for end-to-end translation systems, while we primarily focus on the more general application of language modelling. We implement byte-pair encoding, Hu↵man coding and character decomposition, and compare their performance in a SMT setting to a truncated vocabulary that is standard for neural network language models. We find that BPE is better than character-level decomposition as it is more e cient, especially for the most frequent words, and it gives higher BLEU scores than Hu↵man coding and is able to decompose new words in the language. We also show that by using byte-pair encoding we can improve the BLEU score performance for SMT systems over that of a truncated vocabulary, investigating whether this is due to the e cient decomposition or the enlarged vocabulary.\nEffective Approaches to Attention-based Neural Machine Translation (Thang Luong et al., 2015) Thang Luong, Hieu Pham, Christopher D. Manning. (2015)\nEffective Approaches to Attention-based Neural Machine Translation\nEMNLP\nPaper Link\nInfluential Citation Count (605), SS-ID (93499a7c7f699b6630a86fad964536f9423bb6d0)\nABSTRACT\nAn attentional mechanism has lately been used to improve neural machine translation (NMT) by selectively focusing on parts of the source sentence during translation. However, there has been little work exploring useful architectures for attention-based NMT. This paper examines two simple and effective classes of attentional mechanism: a global approach which always attends to all source words and a local one that only looks at a subset of source words at a time. We demonstrate the effectiveness of both approaches on the WMT translation tasks between English and German in both directions. With local attention, we achieve a significant gain of 5.0 BLEU points over non-attentional systems that already incorporate known techniques such as dropout. Our ensemble model using different attention architectures yields a new state-of-the-art result in the WMT’15 English to German translation task with 25.9 BLEU points, an improvement of 1.0 BLEU points over the existing best system backed by NMT and an n-gram reranker. 1\nVariable-Length Word Encodings for Neural Translation Models (Rohan Chitnis et al., 2015) Rohan Chitnis, John DeNero. (2015)\nVariable-Length Word Encodings for Neural Translation Models\nEMNLP\nPaper Link\nInfluential Citation Count (6), SS-ID (93a9694b6a4149e815c30a360347593b75860761)\nABSTRACT\nRecent work in neural machine translation has shown promising performance, but the most eective architectures do not scale naturally to large vocabulary sizes. We propose and compare three variable-length encoding schemes that represent a large vocabulary corpus using a much smaller vocabulary with no loss in information. Common words are unaected by our encoding, but rare words are encoded using a sequence of two pseudo-words. Our method is simple and eective: it requires no complete dictionaries, learning procedures, increased training time, changes to the model, or new parameters. Compared to a baseline that replaces all rare words with an unknown word symbol, our best variable-length encoding strategy improves WMT English-French translation performance by up to 1.7 BLEU.\nRecurrent Continuous Translation Models (Nal Kalchbrenner et al., 2013) Nal Kalchbrenner, P. Blunsom. (2013)\nRecurrent Continuous Translation Models\nEMNLP\nPaper Link\nInfluential Citation Count (87), SS-ID (944a1cfd79dbfb6fef460360a0765ba790f4027a)\nABSTRACT\nWe introduce a class of probabilistic continuous translation models called Recurrent Continuous Translation Models that are purely based on continuous representations for words, phrases and sentences and do not rely on alignments or phrasal translation units. The models have a generation and a conditioning aspect. The generation of the translation is modelled with a target Recurrent Language Model, whereas the conditioning on the source sentence is modelled with a Convolutional Sentence Model. Through various experiments, we show first that our models obtain a perplexity with respect to gold translations that is \u0026gt; 43% lower than that of stateof-the-art alignment-based translation models. Secondly, we show that they are remarkably sensitive to the word order, syntax, and meaning of the source sentence despite lacking alignments. Finally we show that they match a state-of-the-art system when rescoring n-best lists of translations.\nCharacter-Based Pivot Translation for Under-Resourced Languages and Domains (J. Tiedemann, 2012) J. Tiedemann. (2012)\nCharacter-Based Pivot Translation for Under-Resourced Languages and Domains\nEACL\nPaper Link\nInfluential Citation Count (6), SS-ID (b0b3c2e5e924621b234a24037fa4f4410b478b49)\nABSTRACT\nIn this paper we investigate the use of character-level translation models to support the translation from and to under-resourced languages and textual domains via closely related pivot languages. Our experiments show that these low-level models can be successful even with tiny amounts of training data. We test the approach on movie subtitles for three language pairs and legal texts for another language pair in a domain adaptation task. Our pivot translations outperform the baselines by a large margin.\nEmpirical Methods for Compound Splitting (Philipp Koehn et al., 2003) Philipp Koehn, Kevin Knight. (2003)\nEmpirical Methods for Compound Splitting\nEACL\nPaper Link\nInfluential Citation Count (41), SS-ID (cdaae7a8f0db8b280266606004f1c6f164a13f6d)\nABSTRACT\nCompounded words are a challenge for NLP applications such as machine translation (MT). We introduce methods to learn splitting rules from monolingual and parallel corpora. We evaluate them against a gold standard and measure their impact on performance of statistical MT systems. Results show accuracy of 99.1% and performance gains for MT of 0.039 BLEU on a German-English noun phrase translation task.\nSequence to Sequence Learning with Neural Networks (Ilya Sutskever et al., 2014) Ilya Sutskever, Oriol Vinyals, Quoc V. Le. (2014)\nSequence to Sequence Learning with Neural Networks\nNIPS\nPaper Link\nInfluential Citation Count (1289), SS-ID (cea967b59209c6be22829699f05b8b1ac4dc092d)\nABSTRACT\nDeep Neural Networks (DNNs) are powerful models that have achieved excellent performance on difficult learning tasks. Although DNNs work well whenever large labeled training sets are available, they cannot be used to map sequences to sequences. In this paper, we present a general end-to-end approach to sequence learning that makes minimal assumptions on the sequence structure. Our method uses a multilayered Long Short-Term Memory (LSTM) to map the input sequence to a vector of a fixed dimensionality, and then another deep LSTM to decode the target sequence from the vector. Our main result is that on an English to French translation task from the WMT-14 dataset, the translations produced by the LSTM achieve a BLEU score of 34.8 on the entire test set, where the LSTM\u0026rsquo;s BLEU score was penalized on out-of-vocabulary words. Additionally, the LSTM did not have difficulty on long sentences. For comparison, a phrase-based SMT system achieves a BLEU score of 33.3 on the same dataset. When we used the LSTM to rerank the 1000 hypotheses produced by the aforementioned SMT system, its BLEU score increases to 36.5, which is close to the previous state of the art. The LSTM also learned sensible phrase and sentence representations that are sensitive to word order and are relatively invariant to the active and the passive voice. Finally, we found that reversing the order of the words in all source sentences (but not target sentences) improved the LSTM\u0026rsquo;s performance markedly, because doing so introduced many short term dependencies between the source and the target sentence which made the optimization problem easier.\nThe Edinburgh/JHU Phrase-based Machine Translation Systems for WMT 2015 (B. Haddow et al., 2015) B. Haddow, Matthias Huck, Alexandra Birch, Nikolay Bogoychev, Philipp Koehn. (2015)\nThe Edinburgh/JHU Phrase-based Machine Translation Systems for WMT 2015\nWMT@EMNLP\nPaper Link\nInfluential Citation Count (0), SS-ID (d8c5e6adf7023def3be0bee91799e18607cf588f)\nABSTRACT\nThis paper describes the submission of the University of Edinburgh and the Johns Hopkins University for the shared translation task of the EMNLP 2015 Tenth Workshop on Statistical Machine Translation (WMT 2015). We set up phrase-based statistical machine translation systems for all ten language pairs of this year’s evaluation campaign, which are English paired with Czech, Finnish, French, German, and Russian in both translation directions. Novel research directions we investigated include: neural network language models and bilingual neural network language models, a comprehensive use of word classes, and sparse lexicalized reordering features.\nA New Algorithm For Data Compression (R. Uma, 2013) R. Uma. (2013)\nA New Algorithm For Data Compression\nPaper Link\nInfluential Citation Count (1), SS-ID (db734a0e1dc65fe3fe2eef474aefba6d083f54dd)\nABSTRACT\nMorphology-aware statistical machine translation based on morphs induced in an unsupervised manner (Sami Virpioja et al., 2007) Sami Virpioja, Jaakko J. Väyrynen, Mathias Creutz, Markus Sadeniemi. (2007)\nMorphology-aware statistical machine translation based on morphs induced in an unsupervised manner\nMTSUMMIT\nPaper Link\nInfluential Citation Count (6), SS-ID (dca029eafe302034f0e7784b9266403938c55263)\nABSTRACT\nIn this paper, we apply a method of unsupervised morphology learning to a state-of-the-art phrase-based statistical ma chine translation (SMT) system. In SMT, words are traditionally used as the smallest units of translation. Such a system generalizes poorl y to word forms that do not occur in the training data. In particular, this is problematic for languages that are highly compounding, highly inflecting, or both. An alternative way is to use sub-word units, such as morphemes. We use the Morfessor algorithm to find statistical mo rphemelike units (called morphs) that can be used to reduce the size of the lexicon and improve the ability to generalize. Transl ation and language models are trained directly on morphs instead of words. The approach is tested on three Nordic languages (Danish, Finnish, and Swedish) that are included in the Europarl corpus consisting of the Proceedings of the European Parliament. However, in our experiments we did not obtain higher BLEU scores for the morph model than for the standard word-based approach. Nonetheless, the proposed morph-based solution has clear benefits, as morpho logically well motivated structures (phrases) are learned , and the proportion of words left untranslated is clearly reduced.\nCan We Translate Letters? (David Vilar et al., 2007) David Vilar, Jan-Thorsten Peter, H. Ney. (2007)\nCan We Translate Letters?\nWMT@ACL\nPaper Link\nInfluential Citation Count (8), SS-ID (e9ad27106dd487893bcc1cc12bbf645168c60f87)\nABSTRACT\nCurrent statistical machine translation systems handle the translation process as the transformation of a string of symbols into another string of symbols. Normally the symbols dealt with are the words in different languages, sometimes with some additional information included, like morphological data. In this work we try to push the approach to the limit, working not on the level of words, but treating both the source and target sentences as a string of letters. We try to find out if a nearly unmodified state-of-the-art translation system is able to cope with the problem and whether it is capable to further generalize translation rules, for example at the level of word suffixes and translation of unseen words. Experiments are carried out for the translation of Catalan to Spanish.\nModelling out-of-vocabulary words for robust speech recognition (Issam Bazzi et al., 2002) Issam Bazzi, James R. Glass. (2002)\nModelling out-of-vocabulary words for robust speech recognition\nPaper Link\nInfluential Citation Count (9), SS-ID (ec5f929b57cf12b4d624ab125f337c14ad642ab1)\nABSTRACT\nThis thesis concerns the problem of unknown or out-of-vocabulary (OOV) words in continuous speech recognition. We propose a novel approach for handling OOV words within a single-stage recognition framework. To achieve this goal, an explicit and detailed model of OOV words is constructed and then used to augment the closed-vocabulary search space of a standard speech recognizer. This OOV model achieves open-vocabulary recognition through the use of more flexible subword units that can be concatenated during recognition to form new phone sequences corresponding to potential new words. Examples of such subword units are phones, syllables, or some automatically-learned multi-phone sequences. Subword units have the attractive property of being a closed set, and thus are able to cover any new words, and can conceivably cover most utterances with partially spoken words as well. The main challenge with such an approach is ensuring that the OOV model does not absorb portions of the speech signal corresponding to in-vocabulary (IV) words. In dealing with this challenge, we explore several research issues related to designing the subword lexicon, language model, and topology of the OOV model. We present a dictionary-based approach for estimating subword language models. Such language models are utilized within the subword search space to help recognize the underlying phonetic transcription of OOV words. We also propose a data-driven iterative bottom-up procedure for automatically creating a multi-phone subword inventory. Starting with individual phones, this procedure uses the maximum mutual information principle to successively merge phones to obtain longer subword units. The thesis also extends this OOV approach to modelling multiple classes of OOV words. In addition, the thesis examines an approach for combining OOV modelling with recognition confidence scoring. (Copies available exclusively from MIT Libraries, Rm. 14-0551, Cambridge, MA 02139-4307. Ph. 617-253-5668; Fax 617-253-1690.)\nIntegrating an Unsupervised Transliteration Model into Statistical Machine Translation (Nadir Durrani et al., 2014) Nadir Durrani, Hassan Sajjad, Hieu Hoang, Philipp Koehn. (2014)\nIntegrating an Unsupervised Transliteration Model into Statistical Machine Translation\nEACL\nPaper Link\nInfluential Citation Count (3), SS-ID (fa144b01862baa5de61d22fd3f922a3ddd54ac4d)\nABSTRACT\nWe investigate three methods for integrating an unsupervised transliteration model into an end-to-end SMT system. We induce a transliteration model from parallel data and use it to translate OOV words. Our approach is fully unsupervised and language independent. In the methods to integrate transliterations, we observed improvements from 0.23-0.75 ( 0.41) BLEU points across 7 language pairs. We also show that our mined transliteration corpora provide better rule coverage and translation quality compared to the gold standard transliteration corpora.\nNeural Machine Translation by Jointly Learning to Align and Translate (Dzmitry Bahdanau et al., 2014) Dzmitry Bahdanau, Kyunghyun Cho, Yoshua Bengio. (2014)\nNeural Machine Translation by Jointly Learning to Align and Translate\nICLR\nPaper Link\nInfluential Citation Count (2464), SS-ID (fa72afa9b2cbc8f0d7b05d52548906610ffbb9c5)\nABSTRACT\nNeural machine translation is a recently proposed approach to machine translation. Unlike the traditional statistical machine translation, the neural machine translation aims at building a single neural network that can be jointly tuned to maximize the translation performance. The models proposed recently for neural machine translation often belong to a family of encoder-decoders and consists of an encoder that encodes a source sentence into a fixed-length vector from which a decoder generates a translation. In this paper, we conjecture that the use of a fixed-length vector is a bottleneck in improving the performance of this basic encoder-decoder architecture, and propose to extend this by allowing a model to automatically (soft-)search for parts of a source sentence that are relevant to predicting a target word, without having to form these parts as a hard segment explicitly. With this new approach, we achieve a translation performance comparable to the existing state-of-the-art phrase-based system on the task of English-to-French translation. Furthermore, qualitative analysis reveals that the (soft-)alignments found by the model agree well with our intuition.\nCharacter-based Neural Machine Translation (Wang Ling et al., 2015) Wang Ling, I. Trancoso, Chris Dyer, A. Black. (2015)\nCharacter-based Neural Machine Translation\nArXiv\nPaper Link\nInfluential Citation Count (11), SS-ID (ff1577528a34a11c2a81d2451d346c412c674c02)\nABSTRACT\nWe introduce a neural machine translation model that views the input and output sentences as sequences of characters rather than words. Since word-level information provides a crucial source of bias, our input model composes representations of character sequences into representations of words (as determined by whitespace boundaries), and then these are translated using a joint attention/translation model. In the target language, the translation is modeled as a sequence of word vectors, but each word is generated one character at a time, conditional on the previous character generations in each word. As the representation and generation of words is performed at the character level, our model is capable of interpreting and generating unseen word forms. A secondary benefit of this approach is that it alleviates much of the challenges associated with preprocessing/tokenization of the source and target languages. We show that our model can achieve translation results that are on par with conventional word-based models.\n","date":"May 30, 2022","hero":"/blog-akitenkrad/posts/papers/202205/20220530102936/hero.jpg","permalink":"https://akitenkrad.github.io/blog-akitenkrad/posts/papers/202205/20220530102936/","summary":"Round-1: Overview Round-2: Model Implementation Details Round-3: Experiments Citation Sennrich, R., Haddow, B., \u0026amp; Birch, A. (2015).\nNeural Machine Translation of Rare Words with Subword Units.\nhttps://doi.org/10.48550/arxiv.1508.07909 Abstract Neural machine translation (NMT) models typically operate with a fixed vocabulary, but translation is an open-vocabulary problem. Previous work addresses the translation of out-of-vocabulary words by backing off to a dictionary. In this paper, we introduce a simpler and more effective approach, making the NMT model capable of open-vocabulary translation by encoding rare and unknown words as sequences of subword units.","tags":["At:Round-1","Published:2015","Machine Translation","Byte Pair Encoding","Embedding","DS:WMT2015"],"title":"Neural Machine Translation of Rare Words with Subword Units"},{"categories":null,"contents":" Round-1: Overview Round-2: Model Implementation Details Round-3: Experiments Citation Vaswani, A., Shazeer, N., Parmar, N., Uszkoreit, J., Jones, L., Gomez, A. N., Kaiser, Ł., \u0026amp; Polosukhin, I. (2017).\nAttention is all you need.\nAdvances in Neural Information Processing Systems, 2017-Decem, 5999–6009.\nhttp://arxiv.org/abs/1706.03762 Abstract The dominant sequence transduction models are based on complex recurrent or convolutional neural networks in an encoder-decoder configuration. The best performing models also connect the encoder and decoder through an attention mechanism. We propose a new simple network architecture, the Transformer, based solely on attention mechanisms, dispensing with recurrence and convolutions entirely. Experiments on two machine translation tasks show these models to be superior in quality while being more parallelizable and requiring significantly less time to train. Our model achieves 28.4 BLEU on the WMT 2014 English-to-German translation task, improving over the existing best results, including ensembles by over 2 BLEU. On the WMT 2014 English-to-French translation task, our model establishes a new single-model state-of-the-art BLEU score of 41.8 after training for 3.5 days on eight GPUs, a small fraction of the training costs of the best models from the literature. We show that the Transformer generalizes well to other tasks by applying it successfully to English constituency parsing both with large and limited training data.\nWhat\u0026rsquo;s New Dataset WMT 2014 English-German Dataset ACL 2014 NINTH WORKSHOP ON STATISTICAL MACHINE TRANSLATION\n26-27 June 2014\nBaltimore, USA\nhttps://www.statmt.org/wmt14/index.html Model Description Encoder and Decoder Stacks Input $n$ 個のトークンの列 $(x_1, \\ldots, x_n)$ をEmbeddingしたベクトル $\\textbf{z} = (z_1, \\ldots, z_n)$ Output $m$ 個のトークンの列(確率) $(y_1, \\ldots, y_m)$ Encoder $N=6$ Residual + Layer Normalization → $\\text{LayerNorm}(x+\\text{SubLayer}(x))$ Decoder $N=6$ Attention $$ \\begin{align*} \\text{Attention}(Q,K,V) = \\text{softmax}\\left(\\frac{QK^{\\top}}{\\sqrt{d_k}}\\right)V \\end{align*} $$\nResults Machine Translation on WMT 2014 Model Variations References A Deep Reinforced Model for Abstractive Summarization (Romain Paulus et al., 2017) Romain Paulus, Caiming Xiong, R. Socher. (2017)\nA Deep Reinforced Model for Abstractive Summarization\nICLR\nPaper Link\nInfluential Citation Count (163), SS-ID (032274e57f7d8b456bd255fe76b909b2c1d7458e)\nABSTRACT\nAttentional, RNN-based encoder-decoder models for abstractive summarization have achieved good performance on short input and output sequences. For longer documents and summaries however these models often include repetitive and incoherent phrases. We introduce a neural network model with a novel intra-attention that attends over the input and continuously generated output separately, and a new training method that combines standard supervised word prediction and reinforcement learning (RL). Models trained only with supervised learning often exhibit \u0026ldquo;exposure bias\u0026rdquo; - they assume ground truth is provided at each step during training. However, when standard word prediction is combined with the global sequence prediction training of RL the resulting summaries become more readable. We evaluate this model on the CNN/Daily Mail and New York Times datasets. Our model obtains a 41.16 ROUGE-1 score on the CNN/Daily Mail dataset, an improvement over previous state-of-the-art models. Human evaluation also shows that our model produces higher quality summaries.\nBuilding a Large Annotated Corpus of English: The Penn Treebank (M. Marcus et al., 1993) M. Marcus, Beatrice Santorini, Mary Ann Marcinkiewicz. (1993)\nBuilding a Large Annotated Corpus of English: The Penn Treebank\nCL\nPaper Link\nInfluential Citation Count (1350), SS-ID (0b44fcbeea9415d400c5f5789d6b892b6f98daff)\nABSTRACT\nAbstract : As a result of this grant, the researchers have now published oil CDROM a corpus of over 4 million words of running text annotated with part-of- speech (POS) tags, with over 3 million words of that material assigned skeletal grammatical structure. This material now includes a fully hand-parsed version of the classic Brown corpus. About one half of the papers at the ACL Workshop on Using Large Text Corpora this past summer were based on the materials generated by this grant.\nLearning Phrase Representations using RNN Encoder–Decoder for Statistical Machine Translation (Kyunghyun Cho et al., 2014) Kyunghyun Cho, Bart van Merrienboer, Çaglar Gülçehre, Dzmitry Bahdanau, Fethi Bougares, Holger Schwenk, Yoshua Bengio. (2014)\nLearning Phrase Representations using RNN Encoder–Decoder for Statistical Machine Translation\nEMNLP\nPaper Link\nInfluential Citation Count (2601), SS-ID (0b544dfe355a5070b60986319a3f51fb45d1348e)\nABSTRACT\nIn this paper, we propose a novel neural network model called RNN Encoder‐ Decoder that consists of two recurrent neural networks (RNN). One RNN encodes a sequence of symbols into a fixedlength vector representation, and the other decodes the representation into another sequence of symbols. The encoder and decoder of the proposed model are jointly trained to maximize the conditional probability of a target sequence given a source sequence. The performance of a statistical machine translation system is empirically found to improve by using the conditional probabilities of phrase pairs computed by the RNN Encoder‐Decoder as an additional feature in the existing log-linear model. Qualitatively, we show that the proposed model learns a semantically and syntactically meaningful representation of linguistic phrases.\nStructured Attention Networks (Yoon Kim et al., 2017) Yoon Kim, Carl Denton, Luong Hoang, Alexander M. Rush. (2017)\nStructured Attention Networks\nICLR\nPaper Link\nInfluential Citation Count (26), SS-ID (13d9323a8716131911bfda048a40e2cde1a76a46)\nABSTRACT\nAttention networks have proven to be an effective approach for embedding categorical inference within a deep neural network. However, for many tasks we may want to model richer structural dependencies without abandoning end-to-end training. In this work, we experiment with incorporating richer structural distributions, encoded using graphical models, within deep networks. We show that these structured attention networks are simple extensions of the basic attention procedure, and that they allow for extending attention beyond the standard soft-selection approach, such as attending to partial segmentations or to subtrees. We experiment with two different classes of structured attention networks: a linear-chain conditional random field and a graph-based parsing model, and describe how these models can be practically implemented as neural network layers. Experiments show that this approach is effective for incorporating structural biases, and structured attention networks outperform baseline attention models on a variety of synthetic and real tasks: tree transduction, neural machine translation, question answering, and natural language inference. We further find that models trained in this way learn interesting unsupervised hidden representations that generalize simple attention.\nLong Short-Term Memory-Networks for Machine Reading (Jianpeng Cheng et al., 2016) Jianpeng Cheng, Li Dong, Mirella Lapata. (2016)\nLong Short-Term Memory-Networks for Machine Reading\nEMNLP\nPaper Link\nInfluential Citation Count (59), SS-ID (13fe71da009484f240c46f14d9330e932f8de210)\nABSTRACT\nIn this paper we address the question of how to render sequence-level networks better at handling structured input. We propose a machine reading simulator which processes text incrementally from left to right and performs shallow reasoning with memory and attention. The reader extends the Long Short-Term Memory architecture with a memory network in place of a single memory cell. This enables adaptive memory usage during recurrence with neural attention, offering a way to weakly induce relations among tokens. The system is initially designed to process a single sequence but we also demonstrate how to integrate it with an encoder-decoder architecture. Experiments on language modeling, sentiment analysis, and natural language inference show that our model matches or outperforms the state of the art.\nFast and Accurate Shift-Reduce Constituent Parsing (Muhua Zhu et al., 2013) Muhua Zhu, Yue Zhang, Wenliang Chen, Min Zhang, Jingbo Zhu. (2013)\nFast and Accurate Shift-Reduce Constituent Parsing\nACL\nPaper Link\nInfluential Citation Count (25), SS-ID (174bbdb96252454cbb40a9c4e53335996235a008)\nABSTRACT\nShift-reduce dependency parsers give comparable accuracies to their chartbased counterparts, yet the best shiftreduce constituent parsers still lag behind the state-of-the-art. One important reason is the existence of unary nodes in phrase structure trees, which leads to different numbers of shift-reduce actions between different outputs for the same input. This turns out to have a large empirical impact on the framework of global training and beam search. We propose a simple yet effective extension to the shift-reduce process, which eliminates size differences between action sequences in beam-search. Our parser gives comparable accuracies to the state-of-the-art chart parsers. With linear run-time complexity, our parser is over an order of magnitude faster than the fastest chart parser.\nNeural Machine Translation of Rare Words with Subword Units (Rico Sennrich et al., 2015) Rico Sennrich, B. Haddow, Alexandra Birch. (2015)\nNeural Machine Translation of Rare Words with Subword Units\nACL\nPaper Link\nInfluential Citation Count (836), SS-ID (1af68821518f03568f913ab03fc02080247a27ff)\nABSTRACT\nNeural machine translation (NMT) models typically operate with a fixed vocabulary, but translation is an open-vocabulary problem. Previous work addresses the translation of out-of-vocabulary words by backing off to a dictionary. In this paper, we introduce a simpler and more effective approach, making the NMT model capable of open-vocabulary translation by encoding rare and unknown words as sequences of subword units. This is based on the intuition that various word classes are translatable via smaller units than words, for instance names (via character copying or transliteration), compounds (via compositional translation), and cognates and loanwords (via phonological and morphological transformations). We discuss the suitability of different word segmentation techniques, including simple character n-gram models and a segmentation based on the byte pair encoding compression algorithm, and empirically show that subword models improve over a back-off dictionary baseline for the WMT 15 translation tasks English-German and English-Russian by 1.1 and 1.3 BLEU, respectively.\nA Structured Self-attentive Sentence Embedding (Zhouhan Lin et al., 2017) Zhouhan Lin, Minwei Feng, C. D. Santos, Mo Yu, Bing Xiang, Bowen Zhou, Yoshua Bengio. (2017)\nA Structured Self-attentive Sentence Embedding\nICLR\nPaper Link\nInfluential Citation Count (148), SS-ID (204a4a70428f3938d2c538a4d74c7ae0416306d8)\nABSTRACT\nThis paper proposes a new model for extracting an interpretable sentence embedding by introducing self-attention. Instead of using a vector, we use a 2-D matrix to represent the embedding, with each row of the matrix attending on a different part of the sentence. We also propose a self-attention mechanism and a special regularization term for the model. As a side effect, the embedding comes with an easy way of visualizing what specific parts of the sentence are encoded into the embedding. We evaluate our model on 3 different tasks: author profiling, sentiment classification, and textual entailment. Results show that our model yields a significant performance gain compared to other sentence embedding methods in all of the 3 tasks.\nRethinking the Inception Architecture for Computer Vision (Christian Szegedy et al., 2015) Christian Szegedy, Vincent Vanhoucke, S. Ioffe, Jonathon Shlens, Z. Wojna. (2015)\nRethinking the Inception Architecture for Computer Vision\n2016 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)\nPaper Link\nInfluential Citation Count (2198), SS-ID (23ffaa0fe06eae05817f527a47ac3291077f9e58)\nABSTRACT\nConvolutional networks are at the core of most state of-the-art computer vision solutions for a wide variety of tasks. Since 2014 very deep convolutional networks started to become mainstream, yielding substantial gains in various benchmarks. Although increased model size and computational cost tend to translate to immediate quality gains for most tasks (as long as enough labeled data is provided for training), computational efficiency and low parameter count are still enabling factors for various use cases such as mobile vision and big-data scenarios. Here we are exploring ways to scale up networks in ways that aim at utilizing the added computation as efficiently as possible by suitably factorized convolutions and aggressive regularization. We benchmark our methods on the ILSVRC 2012 classification challenge validation set demonstrate substantial gains over the state of the art: 21:2% top-1 and 5:6% top-5 error for single frame evaluation using a network with a computational cost of 5 billion multiply-adds per inference and with using less than 25 million parameters. With an ensemble of 4 models and multi-crop evaluation, we report 3:5% top-5 error and 17:3% top-1 error on the validation set and 3:6% top-5 error on the official test set.\nDeep Residual Learning for Image Recognition (Kaiming He et al., 2015) Kaiming He, X. Zhang, Shaoqing Ren, Jian Sun. (2015)\nDeep Residual Learning for Image Recognition\n2016 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)\nPaper Link\nInfluential Citation Count (19695), SS-ID (2c03df8b48bf3fa39054345bafabfeff15bfd11d)\nABSTRACT\nDeeper neural networks are more difficult to train. We present a residual learning framework to ease the training of networks that are substantially deeper than those used previously. We explicitly reformulate the layers as learning residual functions with reference to the layer inputs, instead of learning unreferenced functions. We provide comprehensive empirical evidence showing that these residual networks are easier to optimize, and can gain accuracy from considerably increased depth. On the ImageNet dataset we evaluate residual nets with a depth of up to 152 layers - 8× deeper than VGG nets [40] but still having lower complexity. An ensemble of these residual nets achieves 3.57% error on the ImageNet test set. This result won the 1st place on the ILSVRC 2015 classification task. We also present analysis on CIFAR-10 with 100 and 1000 layers. The depth of representations is of central importance for many visual recognition tasks. Solely due to our extremely deep representations, we obtain a 28% relative improvement on the COCO object detection dataset. Deep residual nets are foundations of our submissions to ILSVRC \u0026amp; COCO 2015 competitions1, where we also won the 1st places on the tasks of ImageNet detection, ImageNet localization, COCO detection, and COCO segmentation.\nExploring the Limits of Language Modeling (R. Józefowicz et al., 2016) R. Józefowicz, Oriol Vinyals, M. Schuster, Noam M. Shazeer, Yonghui Wu. (2016)\nExploring the Limits of Language Modeling\nArXiv\nPaper Link\nInfluential Citation Count (117), SS-ID (2f2d8f8072e5cc9b296fad551f65f183bdbff7aa)\nABSTRACT\nIn this work we explore recent advances in Recurrent Neural Networks for large scale Language Modeling, a task central to language understanding. We extend current models to deal with two key challenges present in this task: corpora and vocabulary sizes, and complex, long term structure of language. We perform an exhaustive study on techniques such as character Convolutional Neural Networks or Long-Short Term Memory, on the One Billion Word Benchmark. Our best single model significantly improves state-of-the-art perplexity from 51.3 down to 30.0 (whilst reducing the number of parameters by a factor of 20), while an ensemble of models sets a new record by improving perplexity from 41.0 down to 23.7. We also release these models for the NLP and ML community to study and improve upon.\nDropout: a simple way to prevent neural networks from overfitting (Nitish Srivastava et al., 2014) Nitish Srivastava, Geoffrey E. Hinton, A. Krizhevsky, Ilya Sutskever, R. Salakhutdinov. (2014)\nDropout: a simple way to prevent neural networks from overfitting\nJ. Mach. Learn. Res.\nPaper Link\nInfluential Citation Count (2236), SS-ID (34f25a8704614163c4095b3ee2fc969b60de4698)\nABSTRACT\nDeep neural nets with a large number of parameters are very powerful machine learning systems. However, overfitting is a serious problem in such networks. Large networks are also slow to use, making it difficult to deal with overfitting by combining the predictions of many different large neural nets at test time. Dropout is a technique for addressing this problem. The key idea is to randomly drop units (along with their connections) from the neural network during training. This prevents units from co-adapting too much. During training, dropout samples from an exponential number of different \u0026ldquo;thinned\u0026rdquo; networks. At test time, it is easy to approximate the effect of averaging the predictions of all these thinned networks by simply using a single unthinned network that has smaller weights. This significantly reduces overfitting and gives major improvements over other regularization methods. We show that dropout improves the performance of neural networks on supervised learning tasks in vision, speech recognition, document classification and computational biology, obtaining state-of-the-art results on many benchmark data sets.\nConvolutional Sequence to Sequence Learning (Jonas Gehring et al., 2017) Jonas Gehring, Michael Auli, David Grangier, Denis Yarats, Yann Dauphin. (2017)\nConvolutional Sequence to Sequence Learning\nICML\nPaper Link\nInfluential Citation Count (296), SS-ID (43428880d75b3a14257c3ee9bda054e61eb869c0)\nABSTRACT\nThe prevalent approach to sequence to sequence learning maps an input sequence to a variable length output sequence via recurrent neural networks. We introduce an architecture based entirely on convolutional neural networks. Compared to recurrent models, computations over all elements can be fully parallelized during training and optimization is easier since the number of non-linearities is fixed and independent of the input length. Our use of gated linear units eases gradient propagation and we equip each decoder layer with a separate attention module. We outperform the accuracy of the deep LSTM setup of Wu et al. (2016) on both WMT'14 English-German and WMT'14 English-French translation at an order of magnitude faster speed, both on GPU and CPU.\nLong Short-Term Memory (S. Hochreiter et al., 1997) S. Hochreiter, J. Schmidhuber. (1997)\nLong Short-Term Memory\nNeural Computation\nPaper Link\nInfluential Citation Count (8600), SS-ID (44d2abe2175df8153f465f6c39b68b76a0d40ab9)\nABSTRACT\nLearning to store information over extended time intervals by recurrent backpropagation takes a very long time, mostly because of insufficient, decaying error backflow. We briefly review Hochreiter\u0026rsquo;s (1991) analysis of this problem, then address it by introducing a novel, efficient, gradient based method called long short-term memory (LSTM). Truncating the gradient where this does not do harm, LSTM can learn to bridge minimal time lags in excess of 1000 discrete-time steps by enforcing constant error flow through constant error carousels within special units. Multiplicative gate units learn to open and close access to the constant error flow. LSTM is local in space and time; its computational complexity per time step and weight is O. 1. Our experiments with artificial data involve local, distributed, real-valued, and noisy pattern representations. In comparisons with real-time recurrent learning, back propagation through time, recurrent cascade correlation, Elman nets, and neural sequence chunking, LSTM leads to many more successful runs, and learns much faster. LSTM also solves complex, artificial long-time-lag tasks that have never been solved by previous recurrent network algorithms.\nMassive Exploration of Neural Machine Translation Architectures (D. Britz et al., 2017) D. Britz, Anna Goldie, Minh-Thang Luong, Quoc V. Le. (2017)\nMassive Exploration of Neural Machine Translation Architectures\nEMNLP 2017\nPaper Link\nInfluential Citation Count (31), SS-ID (4550a4c714920ef57d19878e31c9ebae37b049b2)\nABSTRACT\nNeural Machine Translation (NMT) has shown remarkable progress over the past few years, with production systems now being deployed to end-users. As the field is moving rapidly, it has become unclear which elements of NMT architectures have a significant impact on translation quality. In this work, we present a large-scale analysis of the sensitivity of NMT architectures to common hyperparameters. We report empirical results and variance numbers for several hundred experimental runs, corresponding to over 250,000 GPU hours on a WMT English to German translation task. Our experiments provide practical insights into the relative importance of factors such as embedding size, network depth, RNN cell type, residual connections, attention mechanism, and decoding heuristics. As part of this contribution, we also release an open-source NMT framework in TensorFlow to make it easy for others to reproduce our results and perform their own experiments.\nGrammar as a Foreign Language (Oriol Vinyals et al., 2014) Oriol Vinyals, Lukasz Kaiser, Terry Koo, Slav Petrov, Ilya Sutskever, Geoffrey E. Hinton. (2014)\nGrammar as a Foreign Language\nNIPS\nPaper Link\nInfluential Citation Count (95), SS-ID (47570e7f63e296f224a0e7f9a0d08b0de3cbaf40)\nABSTRACT\nSyntactic constituency parsing is a fundamental problem in natural language processing and has been the subject of intensive research and engineering for decades. As a result, the most accurate parsers are domain specific, complex, and inefficient. In this paper we show that the domain agnostic attention-enhanced sequence-to-sequence model achieves state-of-the-art results on the most widely used syntactic constituency parsing dataset, when trained on a large synthetic corpus that was annotated using existing parsers. It also matches the performance of standard parsers when trained only on a small human-annotated dataset, which shows that this model is highly data-efficient, in contrast to sequence-to-sequence models without the attention mechanism. Our parser is also fast, processing over a hundred sentences per second with an unoptimized CPU implementation.\nEnd-To-End Memory Networks (Sainbayar Sukhbaatar et al., 2015) Sainbayar Sukhbaatar, Arthur D. Szlam, J. Weston, R. Fergus. (2015)\nEnd-To-End Memory Networks\nNIPS\nPaper Link\nInfluential Citation Count (232), SS-ID (4f10b9f47c5bb6b54dd4f5ca8d9fa2c0bbd7ec5e)\nABSTRACT\nWe introduce a neural network with a recurrent attention model over a possibly large external memory. The architecture is a form of Memory Network [23] but unlike the model in that work, it is trained end-to-end, and hence requires significantly less supervision during training, making it more generally applicable in realistic settings. It can also be seen as an extension of RNNsearch [2] to the case where multiple computational steps (hops) are performed per output symbol. The flexibility of the model allows us to apply it to tasks as diverse as (synthetic) question answering [22] and to language modeling. For the former our approach is competitive with Memory Networks, but with less supervision. For the latter, on the Penn TreeBank and Text8 datasets our approach demonstrates comparable performance to RNNs and LSTMs. In both cases we show that the key concept of multiple computational hops yields improved results.\nOutrageously Large Neural Networks: The Sparsely-Gated Mixture-of-Experts Layer (Noam M. Shazeer et al., 2017) Noam M. Shazeer, Azalia Mirhoseini, Krzysztof Maziarz, Andy Davis, Quoc V. Le, Geoffrey E. Hinton, J. Dean. (2017)\nOutrageously Large Neural Networks: The Sparsely-Gated Mixture-of-Experts Layer\nICLR\nPaper Link\nInfluential Citation Count (72), SS-ID (510e26733aaff585d65701b9f1be7ca9d5afc586)\nABSTRACT\nThe capacity of a neural network to absorb information is limited by its number of parameters. Conditional computation, where parts of the network are active on a per-example basis, has been proposed in theory as a way of dramatically increasing model capacity without a proportional increase in computation. In practice, however, there are significant algorithmic and performance challenges. In this work, we address these challenges and finally realize the promise of conditional computation, achieving greater than 1000x improvements in model capacity with only minor losses in computational efficiency on modern GPU clusters. We introduce a Sparsely-Gated Mixture-of-Experts layer (MoE), consisting of up to thousands of feed-forward sub-networks. A trainable gating network determines a sparse combination of these experts to use for each example. We apply the MoE to the tasks of language modeling and machine translation, where model capacity is critical for absorbing the vast quantities of knowledge available in the training corpora. We present model architectures in which a MoE with up to 137 billion parameters is applied convolutionally between stacked LSTM layers. On large language modeling and machine translation benchmarks, these models achieve significantly better results than state-of-the-art at lower computational cost.\nXception: Deep Learning with Depthwise Separable Convolutions (François Chollet, 2016) François Chollet. (2016)\nXception: Deep Learning with Depthwise Separable Convolutions\n2017 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)\nPaper Link\nInfluential Citation Count (1017), SS-ID (5b6ec746d309b165f9f9def873a2375b6fb40f3d)\nABSTRACT\nWe present an interpretation of Inception modules in convolutional neural networks as being an intermediate step in-between regular convolution and the depthwise separable convolution operation (a depthwise convolution followed by a pointwise convolution). In this light, a depthwise separable convolution can be understood as an Inception module with a maximally large number of towers. This observation leads us to propose a novel deep convolutional neural network architecture inspired by Inception, where Inception modules have been replaced with depthwise separable convolutions. We show that this architecture, dubbed Xception, slightly outperforms Inception V3 on the ImageNet dataset (which Inception V3 was designed for), and significantly outperforms Inception V3 on a larger image classification dataset comprising 350 million images and 17,000 classes. Since the Xception architecture has the same number of parameters as Inception V3, the performance gains are not due to increased capacity but rather to a more efficient use of model parameters.\nSelf-Training PCFG Grammars with Latent Annotations Across Languages (Zhongqiang Huang et al., 2009) Zhongqiang Huang, M. Harper. (2009)\nSelf-Training PCFG Grammars with Latent Annotations Across Languages\nEMNLP\nPaper Link\nInfluential Citation Count (7), SS-ID (5bfd8d40bc071fffaf93685a46974b122ee4239d)\nABSTRACT\nWe investigate the effectiveness of self-training PCFG grammars with latent annotations (PCFG-LA) for parsing languages with different amounts of labeled training data. Compared to Charniak\u0026rsquo;s lexicalized parser, the PCFG-LA parser was more effectively adapted to a language for which parsing has been less well developed (i.e., Chinese) and benefited more from self-training. We show for the first time that self-training is able to significantly improve the performance of the PCFG-LA parser, a single generative parser, on both small and large amounts of labeled training data. Our approach achieves state-of-the-art parsing accuracies for a single parser on both English (91.5%) and Chinese (85.2%).\nNeural GPUs Learn Algorithms (Lukasz Kaiser et al., 2015) Lukasz Kaiser, Ilya Sutskever. (2015)\nNeural GPUs Learn Algorithms\nICLR\nPaper Link\nInfluential Citation Count (29), SS-ID (5e4eb58d5b47ac1c73f4cf189497170e75ae6237)\nABSTRACT\nLearning an algorithm from examples is a fundamental problem that has been widely studied. Recently it has been addressed using neural networks, in particular by Neural Turing Machines (NTMs). These are fully differentiable computers that use backpropagation to learn their own programming. Despite their appeal NTMs have a weakness that is caused by their sequential nature: they are not parallel and are are hard to train due to their large depth when unfolded. We present a neural network architecture to address this problem: the Neural GPU. It is based on a type of convolutional gated recurrent unit and, like the NTM, is computationally universal. Unlike the NTM, the Neural GPU is highly parallel which makes it easier to train and efficient to run. An essential property of algorithms is their ability to handle inputs of arbitrary size. We show that the Neural GPU can be trained on short instances of an algorithmic task and successfully generalize to long instances. We verified it on a number of tasks including long addition and long multiplication of numbers represented in binary. We train the Neural GPU on numbers with upto 20 bits and observe no errors whatsoever while testing it, even on much longer numbers. To achieve these results we introduce a technique for training deep recurrent networks: parameter sharing relaxation. We also found a small amount of dropout and gradient noise to have a large positive effect on learning and generalization.\nUsing the Output Embedding to Improve Language Models (Ofir Press et al., 2016) Ofir Press, Lior Wolf. (2016)\nUsing the Output Embedding to Improve Language Models\nEACL\nPaper Link\nInfluential Citation Count (31), SS-ID (63e39cdf1ad884da6bc69096bb3413b5b1100559)\nABSTRACT\nWe study the topmost weight matrix of neural network language models. We show that this matrix constitutes a valid word embedding. When training language models, we recommend tying the input embedding and this output embedding. We analyze the resulting update rules and show that the tied embedding evolves in a more similar way to the output embedding than to the input embedding in the untied model. We also offer a new method of regularizing the output embedding. Our methods lead to a significant reduction in perplexity, as we are able to show on a variety of neural network language models. Finally, we show that weight tying can reduce the size of neural translation models to less than half of their original size without harming their performance.\nRecurrent Neural Network Grammars (Chris Dyer et al., 2016) Chris Dyer, A. Kuncoro, Miguel Ballesteros, Noah A. Smith. (2016)\nRecurrent Neural Network Grammars\nNAACL\nPaper Link\nInfluential Citation Count (85), SS-ID (7345843e87c81e24e42264859b214d26042f8d51)\nABSTRACT\nWe introduce recurrent neural network grammars, probabilistic models of sentences with explicit phrase structure. We explain efficient inference procedures that allow application to both parsing and language modeling. Experiments show that they provide better parsing in English than any single previously published supervised generative model and better language modeling than state-of-the-art sequential RNNs in English and Chinese.\nCan Active Memory Replace Attention? (Lukasz Kaiser et al., 2016) Lukasz Kaiser, Samy Bengio. (2016)\nCan Active Memory Replace Attention?\nNIPS\nPaper Link\nInfluential Citation Count (5), SS-ID (735d547fc75e0772d2a78c46a1cc5fad7da1474c)\nABSTRACT\nSeveral mechanisms to focus attention of a neural network on selected parts of its input or memory have been used successfully in deep learning models in recent years. Attention has improved image classification, image captioning, speech recognition, generative models, and learning algorithmic tasks, but it had probably the largest impact on neural machine translation. Recently, similar improvements have been obtained using alternative mechanisms that do not focus on a single part of a memory but operate on all of it in parallel, in a uniform way. Such mechanism, which we call active memory, improved over attention in algorithmic tasks, image processing, and in generative modelling. So far, however, active memory has not improved over attention for most natural language processing tasks, in particular for machine translation. We analyze this shortcoming in this paper and propose an extended model of active memory that matches existing attention models on neural machine translation and generalizes better to longer sentences. We investigate this model and explain why previous active memory models did not succeed. Finally, we discuss when active memory brings most benefits and where attention can be a better choice.\nEffective Self-Training for Parsing (David McClosky et al., 2006) David McClosky, Eugene Charniak, Mark Johnson. (2006)\nEffective Self-Training for Parsing\nNAACL\nPaper Link\nInfluential Citation Count (63), SS-ID (78a9513e70f596077179101f6cb6eadc51602039)\nABSTRACT\nWe present a simple, but surprisingly effective, method of self-training a two-phase parser-reranker system using readily available unlabeled data. We show that this type of bootstrapping is possible for parsing when the bootstrapped parses are processed by a discriminative reranker. Our improved model achieves an f-score of 92.1%, an absolute 1.1% improvement (12% error reduction) over the previous best result for Wall Street Journal parsing. Finally, we provide some analysis to better understand the phenomenon.\nFactorization tricks for LSTM networks (O. Kuchaiev et al., 2017) O. Kuchaiev, Boris Ginsburg. (2017)\nFactorization tricks for LSTM networks\nICLR\nPaper Link\nInfluential Citation Count (11), SS-ID (79baf48bd560060549998d7b61751286de062e2a)\nABSTRACT\nWe present two simple ways of reducing the number of parameters and accelerating the training of large Long Short-Term Memory (LSTM) networks: the first one is \u0026ldquo;matrix factorization by design\u0026rdquo; of LSTM matrix into the product of two smaller matrices, and the second one is partitioning of LSTM matrix, its inputs and states into the independent groups. Both approaches allow us to train large LSTM networks significantly faster to the near state-of the art perplexity while using significantly less RNN parameters.\nGenerating Sequences With Recurrent Neural Networks (A. Graves, 2013) A. Graves. (2013)\nGenerating Sequences With Recurrent Neural Networks\nArXiv\nPaper Link\nInfluential Citation Count (307), SS-ID (89b1f4740ae37fd04f6ac007577bdd34621f0861)\nABSTRACT\nThis paper shows how Long Short-term Memory recurrent neural networks can be used to generate complex sequences with long-range structure, simply by predicting one data point at a time. The approach is demonstrated for text (where the data are discrete) and online handwriting (where the data are real-valued). It is then extended to handwriting synthesis by allowing the network to condition its predictions on a text sequence. The resulting system is able to generate highly realistic cursive handwriting in a wide variety of styles.\nNeural Machine Translation in Linear Time (Nal Kalchbrenner et al., 2016) Nal Kalchbrenner, Lasse Espeholt, K. Simonyan, Aäron van den Oord, A. Graves, K. Kavukcuoglu. (2016)\nNeural Machine Translation in Linear Time\nArXiv\nPaper Link\nInfluential Citation Count (40), SS-ID (98445f4172659ec5e891e031d8202c102135c644)\nABSTRACT\nWe present a novel neural network for processing sequences. The ByteNet is a one-dimensional convolutional neural network that is composed of two parts, one to encode the source sequence and the other to decode the target sequence. The two network parts are connected by stacking the decoder on top of the encoder and preserving the temporal resolution of the sequences. To address the differing lengths of the source and the target, we introduce an efficient mechanism by which the decoder is dynamically unfolded over the representation of the encoder. The ByteNet uses dilation in the convolutional layers to increase its receptive field. The resulting network has two core properties: it runs in time that is linear in the length of the sequences and it sidesteps the need for excessive memorization. The ByteNet decoder attains state-of-the-art performance on character-level language modelling and outperforms the previous best results obtained with recurrent networks. The ByteNet also achieves state-of-the-art performance on character-to-character machine translation on the English-to-German WMT translation task, surpassing comparable neural translation models that are based on recurrent networks with attentional pooling and run in quadratic time. We find that the latent alignment structure contained in the representations reflects the expected alignment between the tokens.\nAdam: A Method for Stochastic Optimization (Diederik P. Kingma et al., 2014) Diederik P. Kingma, Jimmy Ba. (2014)\nAdam: A Method for Stochastic Optimization\nICLR\nPaper Link\nInfluential Citation Count (14846), SS-ID (a6cb366736791bcccc5c8639de5a8f9636bf87e8)\nABSTRACT\nWe introduce Adam, an algorithm for first-order gradient-based optimization of stochastic objective functions, based on adaptive estimates of lower-order moments. The method is straightforward to implement, is computationally efficient, has little memory requirements, is invariant to diagonal rescaling of the gradients, and is well suited for problems that are large in terms of data and/or parameters. The method is also appropriate for non-stationary objectives and problems with very noisy and/or sparse gradients. The hyper-parameters have intuitive interpretations and typically require little tuning. Some connections to related algorithms, on which Adam was inspired, are discussed. We also analyze the theoretical convergence properties of the algorithm and provide a regret bound on the convergence rate that is comparable to the best known results under the online convex optimization framework. Empirical results demonstrate that Adam works well in practice and compares favorably to other stochastic optimization methods. Finally, we discuss AdaMax, a variant of Adam based on the infinity norm.\nEmpirical Evaluation of Gated Recurrent Neural Networks on Sequence Modeling (Junyoung Chung et al., 2014) Junyoung Chung, Çaglar Gülçehre, Kyunghyun Cho, Yoshua Bengio. (2014)\nEmpirical Evaluation of Gated Recurrent Neural Networks on Sequence Modeling\nArXiv\nPaper Link\nInfluential Citation Count (1228), SS-ID (adfcf065e15fd3bc9badf6145034c84dfb08f204)\nABSTRACT\nIn this paper we compare different types of recurrent units in recurrent neural networks (RNNs). Especially, we focus on more sophisticated units that implement a gating mechanism, such as a long short-term memory (LSTM) unit and a recently proposed gated recurrent unit (GRU). We evaluate these recurrent units on the tasks of polyphonic music modeling and speech signal modeling. Our experiments revealed that these advanced recurrent units are indeed better than more traditional recurrent units such as tanh units. Also, we found GRU to be comparable to LSTM.\nGradient Flow in Recurrent Nets: the Difficulty of Learning Long-Term Dependencies (S. Hochreiter et al., 2001) S. Hochreiter, Yoshua Bengio. (2001)\nGradient Flow in Recurrent Nets: the Difficulty of Learning Long-Term Dependencies\nPaper Link\nInfluential Citation Count (57), SS-ID (aed054834e2c696807cc8b227ac7a4197196e211)\nABSTRACT\nD3EGF(FIH)J KMLONPEGQSRPETN UCV.WYX(Z R.[ V R6\\M[ X N@]^O`JaNcb V RcQ W d EGKeL(^(QgfhKeLOE?i)^(QSj ETNPfPQkRl[ V R)m\u0026quot;[ X ^(KeLOEG^ npo qarpo m\u0026quot;[ X ^(KeLOEG^tsAu EGNPb V ^ v wyx zlwO{(|(}\u0026lt;~OC}((xp{ay.~A}~ Cl3#|\u0026lt;Azw#|l6 (|  JpfhL XV EG^O QgJ  ETFOR] ^O\\JNPb V RcQ X E)ETR 6EGKeLOETNcKMLOE F ETN V RcQgJp^(^OE ZgZ E i ^(Qkj EGNPfhQSRO E OE2m1Jp^ RcNY E VZ sO! ¡ q.n sCD X KGKa8¢EG^ RPNhE¤£ ¥¦Q ZgZ Es m§J^ RPNO E VZ s( ̈ X  EG©#EKas# V ^ V  V s(H a «a¬3­ ®#|.Y ̄y} xa°OC}l{x  yxlY~3{|  ±2Pz   V J Z J U N V fhKTJp^(Q  ETFOR J\\ D vYf3RPEGb ́f V ^(§JpbF X RPETN@D KTQEG^(KTE i ^(QSjpEGNPfhQSR4vμJ\\ U¶Z JaNPEG^(K·E jYQ V (Q ̧D V ^ R V m V N3R V aOs#1 o ¡Ga r U QNhE^OoTE1⁄4»,] R VZ vC1⁄2 3⁄4  x ± x  #¿ }À 3t}lC}2P}\u0026lt;~ ¬t[ X NPE^§D KeL(b ́Qg(L X ©yETN ]  DY]_Á JNPfhJÃÂ Z j EToQ V a rpopo2Ä X  V ^(J(sCD Å)QSRPoTEGN ZgV ^( Æ #|{3 ̄|.(C}.C¿Y}p Pzw\nDeep Recurrent Models with Fast-Forward Connections for Neural Machine Translation (Jie Zhou et al., 2016) Jie Zhou, Ying Cao, Xuguang Wang, Peng Li, W. Xu. (2016)\nDeep Recurrent Models with Fast-Forward Connections for Neural Machine Translation\nTACL\nPaper Link\nInfluential Citation Count (18), SS-ID (b60abe57bc195616063be10638c6437358c81d1e)\nABSTRACT\nNeural machine translation (NMT) aims at solving machine translation (MT) problems using neural networks and has exhibited promising results in recent years. However, most of the existing NMT models are shallow and there is still a performance gap between a single NMT model and the best conventional MT system. In this work, we introduce a new type of linear connections, named fast-forward connections, based on deep Long Short-Term Memory (LSTM) networks, and an interleaved bi-directional architecture for stacking the LSTM layers. Fast-forward connections play an essential role in propagating the gradients and building a deep topology of depth 16. On the WMT’14 English-to-French task, we achieve BLEU=37.7 with a single attention model, which outperforms the corresponding single shallow model by 6.2 BLEU points. This is the first time that a single NMT model achieves state-of-the-art performance and outperforms the best conventional model by 0.7 BLEU points. We can still achieve BLEU=36.3 even without using an attention mechanism. After special handling of unknown words and model ensembling, we obtain the best score reported to date on this task with BLEU=40.4. Our models are also validated on the more difficult WMT’14 English-to-German task.\nSequence to Sequence Learning with Neural Networks (Ilya Sutskever et al., 2014) Ilya Sutskever, Oriol Vinyals, Quoc V. Le. (2014)\nSequence to Sequence Learning with Neural Networks\nNIPS\nPaper Link\nInfluential Citation Count (1288), SS-ID (cea967b59209c6be22829699f05b8b1ac4dc092d)\nABSTRACT\nDeep Neural Networks (DNNs) are powerful models that have achieved excellent performance on difficult learning tasks. Although DNNs work well whenever large labeled training sets are available, they cannot be used to map sequences to sequences. In this paper, we present a general end-to-end approach to sequence learning that makes minimal assumptions on the sequence structure. Our method uses a multilayered Long Short-Term Memory (LSTM) to map the input sequence to a vector of a fixed dimensionality, and then another deep LSTM to decode the target sequence from the vector. Our main result is that on an English to French translation task from the WMT-14 dataset, the translations produced by the LSTM achieve a BLEU score of 34.8 on the entire test set, where the LSTM\u0026rsquo;s BLEU score was penalized on out-of-vocabulary words. Additionally, the LSTM did not have difficulty on long sentences. For comparison, a phrase-based SMT system achieves a BLEU score of 33.3 on the same dataset. When we used the LSTM to rerank the 1000 hypotheses produced by the aforementioned SMT system, its BLEU score increases to 36.5, which is close to the previous state of the art. The LSTM also learned sensible phrase and sentence representations that are sensitive to word order and are relatively invariant to the active and the passive voice. Finally, we found that reversing the order of the words in all source sentences (but not target sentences) improved the LSTM\u0026rsquo;s performance markedly, because doing so introduced many short term dependencies between the source and the target sentence which made the optimization problem easier.\nMulti-task Sequence to Sequence Learning (Minh-Thang Luong et al., 2015) Minh-Thang Luong, Quoc V. Le, Ilya Sutskever, Oriol Vinyals, Lukasz Kaiser. (2015)\nMulti-task Sequence to Sequence Learning\nICLR\nPaper Link\nInfluential Citation Count (67), SS-ID (d76c07211479e233f7c6a6f32d5346c983c5598f)\nABSTRACT\nSequence to sequence learning has recently emerged as a new paradigm in supervised learning. To date, most of its applications focused on only one task and not much work explored this framework for multiple tasks. This paper examines three multi-task learning (MTL) settings for sequence to sequence models: (a) the oneto-many setting - where the encoder is shared between several tasks such as machine translation and syntactic parsing, (b) the many-to-one setting - useful when only the decoder can be shared, as in the case of translation and image caption generation, and (c) the many-to-many setting - where multiple encoders and decoders are shared, which is the case with unsupervised objectives and translation. Our results show that training on a small amount of parsing and image caption data can improve the translation quality between English and German by up to 1.5 BLEU points over strong single-task baselines on the WMT benchmarks. Furthermore, we have established a new state-of-the-art result in constituent parsing with 93.0 F1. Lastly, we reveal interesting properties of the two unsupervised learning objectives, autoencoder and skip-thought, in the MTL context: autoencoder helps less in terms of perplexities but more on BLEU scores compared to skip-thought.\nGoogle\u0026#39;s Neural Machine Translation System: Bridging the Gap between Human and Machine Translation (Yonghui Wu et al., 2016) Yonghui Wu, M. Schuster, Z. Chen, Quoc V. Le, Mohammad Norouzi, Wolfgang Macherey, M. Krikun, Yuan Cao, Qin Gao, Klaus Macherey, J. Klingner, Apurva Shah, Melvin Johnson, Xiaobing Liu, Lukasz Kaiser, Stephan Gouws, Y. Kato, Taku Kudo, H. Kazawa, K. Stevens, George Kurian, Nishant Patil, Wei Wang, C. Young, Jason R. Smith, Jason Riesa, Alex Rudnick, Oriol Vinyals, G. Corrado, Macduff Hughes, J. Dean. (2016)\nGoogle\u0026rsquo;s Neural Machine Translation System: Bridging the Gap between Human and Machine Translation\nArXiv\nPaper Link\nInfluential Citation Count (348), SS-ID (dbde7dfa6cae81df8ac19ef500c42db96c3d1edd)\nABSTRACT\nNeural Machine Translation (NMT) is an end-to-end learning approach for automated translation, with the potential to overcome many of the weaknesses of conventional phrase-based translation systems. Unfortunately, NMT systems are known to be computationally expensive both in training and in translation inference. Also, most NMT systems have difficulty with rare words. These issues have hindered NMT\u0026rsquo;s use in practical deployments and services, where both accuracy and speed are essential. In this work, we present GNMT, Google\u0026rsquo;s Neural Machine Translation system, which attempts to address many of these issues. Our model consists of a deep LSTM network with 8 encoder and 8 decoder layers using attention and residual connections. To improve parallelism and therefore decrease training time, our attention mechanism connects the bottom layer of the decoder to the top layer of the encoder. To accelerate the final translation speed, we employ low-precision arithmetic during inference computations. To improve handling of rare words, we divide words into a limited set of common sub-word units (\u0026ldquo;wordpieces\u0026rdquo;) for both input and output. This method provides a good balance between the flexibility of \u0026ldquo;character\u0026rdquo;-delimited models and the efficiency of \u0026ldquo;word\u0026rdquo;-delimited models, naturally handles translation of rare words, and ultimately improves the overall accuracy of the system. Our beam search technique employs a length-normalization procedure and uses a coverage penalty, which encourages generation of an output sentence that is most likely to cover all the words in the source sentence. On the WMT'14 English-to-French and English-to-German benchmarks, GNMT achieves competitive results to state-of-the-art. Using a human side-by-side evaluation on a set of isolated simple sentences, it reduces translation errors by an average of 60% compared to Google\u0026rsquo;s phrase-based production system.\nLearning Accurate, Compact, and Interpretable Tree Annotation (Slav Petrov et al., 2006) Slav Petrov, Leon Barrett, R. Thibaux, D. Klein. (2006)\nLearning Accurate, Compact, and Interpretable Tree Annotation\nACL\nPaper Link\nInfluential Citation Count (154), SS-ID (f52de7242e574b70410ca6fb70b79c811919fc00)\nABSTRACT\nWe present an automatic approach to tree annotation in which basic nonterminal symbols are alternately split and merged to maximize the likelihood of a training treebank. Starting with a simple X-bar grammar, we learn a new grammar whose nonterminals are subsymbols of the original nonterminals. In contrast with previous work, we are able to split various terminals to different degrees, as appropriate to the actual complexity in the data. Our grammars automatically learn the kinds of linguistic distinctions exhibited in previous work on manual tree annotation. On the other hand, our grammars are much more compact and substantially more accurate than previous work on automatic annotation. Despite its simplicity, our best grammar achieves an F1 of 90.2% on the Penn Treebank, higher than fully lexicalized systems.\nNeural Machine Translation by Jointly Learning to Align and Translate (Dzmitry Bahdanau et al., 2014) Dzmitry Bahdanau, Kyunghyun Cho, Yoshua Bengio. (2014)\nNeural Machine Translation by Jointly Learning to Align and Translate\nICLR\nPaper Link\nInfluential Citation Count (2463), SS-ID (fa72afa9b2cbc8f0d7b05d52548906610ffbb9c5)\nABSTRACT\nNeural machine translation is a recently proposed approach to machine translation. Unlike the traditional statistical machine translation, the neural machine translation aims at building a single neural network that can be jointly tuned to maximize the translation performance. The models proposed recently for neural machine translation often belong to a family of encoder-decoders and consists of an encoder that encodes a source sentence into a fixed-length vector from which a decoder generates a translation. In this paper, we conjecture that the use of a fixed-length vector is a bottleneck in improving the performance of this basic encoder-decoder architecture, and propose to extend this by allowing a model to automatically (soft-)search for parts of a source sentence that are relevant to predicting a target word, without having to form these parts as a hard segment explicitly. With this new approach, we achieve a translation performance comparable to the existing state-of-the-art phrase-based system on the task of English-to-French translation. Furthermore, qualitative analysis reveals that the (soft-)alignments found by the model agree well with our intuition.\n","date":"May 29, 2022","hero":"/blog-akitenkrad/posts/papers/202205/20220529131339/hero.jpg","permalink":"https://akitenkrad.github.io/blog-akitenkrad/posts/papers/202205/20220529131339/","summary":"Round-1: Overview Round-2: Model Implementation Details Round-3: Experiments Citation Vaswani, A., Shazeer, N., Parmar, N., Uszkoreit, J., Jones, L., Gomez, A. N., Kaiser, Ł., \u0026amp; Polosukhin, I. (2017).\nAttention is all you need.\nAdvances in Neural Information Processing Systems, 2017-Decem, 5999–6009.\nhttp://arxiv.org/abs/1706.03762 Abstract The dominant sequence transduction models are based on complex recurrent or convolutional neural networks in an encoder-decoder configuration. The best performing models also connect the encoder and decoder through an attention mechanism.","tags":["At:Round-1","Published:2017","Attention","Transformer"],"title":"Attention Is All You Need"},{"categories":null,"contents":" Round-1: Overview Round-2: Model Implementation Details Round-3: Experiments Citation Abstract What\u0026rsquo;s New Dataset Model Description Training Settings Results References Semi-Supervised Text Classification Using EM (O. Chapelle et al., 2006) O. Chapelle, Bernhard SchÃ¶lkopf, A. Zien. (2006)\nSemi-Supervised Text Classification Using EM\nPaper Link\nInfluential Citation Count (2), SS-ID (03bafef700d35112a9926dd1b2be91a4aa6984a4)\nABSTRACT\nThis chapter contains sections titled: Introduction, A Generative Model for Text, Experimental Results with Basic EM, Using a More Expressive Generative Model, Overcoming the Challenges of Local Maxima, Conclusions and Summary\nSQuAD: 100,000\u0026#43; Questions for Machine Comprehension of Text (Pranav Rajpurkar et al., 2016) Pranav Rajpurkar, Jian Zhang, Konstantin Lopyrev, Percy Liang. (2016)\nSQuAD: 100,000+ Questions for Machine Comprehension of Text\nEMNLP\nPaper Link\nInfluential Citation Count (1099), SS-ID (05dd7254b632376973f3a1b4d39485da17814df5)\nABSTRACT\nWe present the Stanford Question Answering Dataset (SQuAD), a new reading comprehension dataset consisting of 100,000+ questions posed by crowdworkers on a set of Wikipedia articles, where the answer to each question is a segment of text from the corresponding reading passage. We analyze the dataset to understand the types of reasoning required to answer the questions, leaning heavily on dependency and constituency trees. We build a strong logistic regression model, which achieves an F1 score of 51.0%, a significant improvement over a simple baseline (20%). However, human performance (86.8%) is much higher, indicating that the dataset presents a good challenge problem for future research. The dataset is freely available at this https URL\nSemi-supervised sequence tagging with bidirectional language models (Matthew E. Peters et al., 2017) Matthew E. Peters, Waleed Ammar, Chandra Bhagavatula, Russell Power. (2017)\nSemi-supervised sequence tagging with bidirectional language models\nACL\nPaper Link\nInfluential Citation Count (49), SS-ID (0bb4cadc80c0afaf29c57518dc9c06f8fcfa5f38)\nABSTRACT\nPre-trained word embeddings learned from unlabeled text have become a standard component of neural network architectures for NLP tasks. However, in most cases, the recurrent network that operates on word-level representations to produce context sensitive representations is trained on relatively little labeled data. In this paper, we demonstrate a general semi-supervised approach for adding pre- trained context embeddings from bidirectional language models to NLP systems and apply it to sequence labeling tasks. We evaluate our model on two standard datasets for named entity recognition (NER) and chunking, and in both cases achieve state of the art results, surpassing previous systems that use other forms of transfer or joint learning with additional labeled data and task specific gazetteers.\nDiscriminative Improvements to Distributional Sentence Similarity (Yangfeng Ji et al., 2013) Yangfeng Ji, Jacob Eisenstein. (2013)\nDiscriminative Improvements to Distributional Sentence Similarity\nEMNLP\nPaper Link\nInfluential Citation Count (17), SS-ID (0e5fa90e28fab414c8ef3ac6ca937c6195c2860e)\nABSTRACT\nMatrix and tensor factorization have been applied to a number of semantic relatedness tasks, including paraphrase identification. The key idea is that similarity in the latent space implies semantic relatedness. We describe three ways in which labeled data can improve the accuracy of these approaches on paraphrase classification. First, we design a new discriminative term-weighting metric called TF-KLD, which outperforms TF-IDF. Next, we show that using the latent representation from matrix factorization as features in a classification algorithm substantially improves accuracy. Finally, we combine latent features with fine-grained n-gram overlap features, yielding performance that is 3% more accurate than the prior state-of-the-art.\nAligning Books and Movies: Towards Story-Like Visual Explanations by Watching Movies and Reading Books (Yukun Zhu et al., 2015) Yukun Zhu, Ryan Kiros, R. Zemel, R. Salakhutdinov, R. Urtasun, A. Torralba, S. Fidler. (2015)\nAligning Books and Movies: Towards Story-Like Visual Explanations by Watching Movies and Reading Books\n2015 IEEE International Conference on Computer Vision (ICCV)\nPaper Link\nInfluential Citation Count (172), SS-ID (0e6824e137847be0599bb0032e37042ed2ef5045)\nABSTRACT\nBooks are a rich source of both fine-grained information, how a character, an object or a scene looks like, as well as high-level semantics, what someone is thinking, feeling and how these states evolve through a story. This paper aims to align books to their movie releases in order to provide rich descriptive explanations for visual content that go semantically far beyond the captions available in the current datasets. To align movies and books we propose a neural sentence embedding that is trained in an unsupervised way from a large corpus of books, as well as a video-text neural embedding for computing similarities between movie clips and sentences in the book. We propose a context-aware CNN to combine information from multiple sources. We demonstrate good quantitative performance for movie/book alignment and show several qualitative examples that showcase the diversity of tasks our model can be used for.\nLearning Entity Representation for Entity Disambiguation (Z. He et al., 2013) Z. He, Shujie Liu, Mu Li, Ming Zhou, Longkai Zhang, Houfeng Wang. (2013)\nLearning Entity Representation for Entity Disambiguation\nACL\nPaper Link\nInfluential Citation Count (16), SS-ID (10ce58375314f90f83ca3bb88840cbc67bf8050f)\nABSTRACT\nNeural Machine Translation of Rare Words with Subword Units (Rico Sennrich et al., 2015) Rico Sennrich, B. Haddow, Alexandra Birch. (2015)\nNeural Machine Translation of Rare Words with Subword Units\nACL\nPaper Link\nInfluential Citation Count (840), SS-ID (1af68821518f03568f913ab03fc02080247a27ff)\nABSTRACT\nNeural machine translation (NMT) models typically operate with a fixed vocabulary, but translation is an open-vocabulary problem. Previous work addresses the translation of out-of-vocabulary words by backing off to a dictionary. In this paper, we introduce a simpler and more effective approach, making the NMT model capable of open-vocabulary translation by encoding rare and unknown words as sequences of subword units. This is based on the intuition that various word classes are translatable via smaller units than words, for instance names (via character copying or transliteration), compounds (via compositional translation), and cognates and loanwords (via phonological and morphological transformations). We discuss the suitability of different word segmentation techniques, including simple character n-gram models and a segmentation based on the byte pair encoding compression algorithm, and empirically show that subword models improve over a back-off dictionary baseline for the WMT 15 translation tasks English-German and English-Russian by 1.1 and 1.3 BLEU, respectively.\nUniversal Language Model Fine-tuning for Text Classification (Jeremy Howard et al., 2018) Jeremy Howard, Sebastian Ruder. (2018)\nUniversal Language Model Fine-tuning for Text Classification\nACL\nPaper Link\nInfluential Citation Count (224), SS-ID (1e077413b25c4d34945cc2707e17e46ed4fe784a)\nABSTRACT\nInductive transfer learning has greatly impacted computer vision, but existing approaches in NLP still require task-specific modifications and training from scratch. We propose Universal Language Model Fine-tuning (ULMFiT), an effective transfer learning method that can be applied to any task in NLP, and introduce techniques that are key for fine-tuning a language model. Our method significantly outperforms the state-of-the-art on six text classification tasks, reducing the error by 18-24% on the majority of datasets. Furthermore, with only 100 labeled examples, it matches the performance of training from scratch on 100 times more data. We open-source our pretrained models and code.\nConvolutional Neural Networks for Sentence Classification (Yoon Kim, 2014) Yoon Kim. (2014)\nConvolutional Neural Networks for Sentence Classification\nEMNLP\nPaper Link\nInfluential Citation Count (1603), SS-ID (1f6ba0782862ec12a5ec6d7fb608523d55b0c6ba)\nABSTRACT\nWe report on a series of experiments with convolutional neural networks (CNN) trained on top of pre-trained word vectors for sentence-level classification tasks. We show that a simple CNN with little hyperparameter tuning and static vectors achieves excellent results on multiple benchmarks. Learning task-specific vectors through fine-tuning offers further gains in performance. We additionally propose a simple modification to the architecture to allow for the use of both task-specific and static vectors. The CNN models discussed herein improve upon the state of the art on 4 out of 7 tasks, which include sentiment analysis and question classification.\nAttention is All you Need (Ashish Vaswani et al., 2017) Ashish Vaswani, Noam M. Shazeer, Niki Parmar, Jakob Uszkoreit, Llion Jones, Aidan N. Gomez, Lukasz Kaiser, Illia Polosukhin. (2017)\nAttention is All you Need\nNIPS\nPaper Link\nInfluential Citation Count (7881), SS-ID (204e3073870fae3d05bcbc2f6a8e263d9b72e776)\nABSTRACT\nThe dominant sequence transduction models are based on complex recurrent or convolutional neural networks in an encoder-decoder configuration. The best performing models also connect the encoder and decoder through an attention mechanism. We propose a new simple network architecture, the Transformer, based solely on attention mechanisms, dispensing with recurrence and convolutions entirely. Experiments on two machine translation tasks show these models to be superior in quality while being more parallelizable and requiring significantly less time to train. Our model achieves 28.4 BLEU on the WMT 2014 English-to-German translation task, improving over the existing best results, including ensembles by over 2 BLEU. On the WMT 2014 English-to-French translation task, our model establishes a new single-model state-of-the-art BLEU score of 41.8 after training for 3.5 days on eight GPUs, a small fraction of the training costs of the best models from the literature. We show that the Transformer generalizes well to other tasks by applying it successfully to English constituency parsing both with large and limited training data.\nReasoning about Entailment with Neural Attention (Tim Rocktäschel et al., 2015) Tim Rocktäschel, Edward Grefenstette, K. Hermann, Tomás Kociský, P. Blunsom. (2015)\nReasoning about Entailment with Neural Attention\nICLR\nPaper Link\nInfluential Citation Count (86), SS-ID (2846e83d405cbe3bf2f0f3b5f635dd8b3c680c45)\nABSTRACT\nWhile most approaches to automatically recognizing entailment relations have used classifiers employing hand engineered features derived from complex natural language processing pipelines, in practice their performance has been only slightly better than bag-of-word pair classifiers using only lexical similarity. The only attempt so far to build an end-to-end differentiable neural network for entailment failed to outperform such a simple similarity classifier. In this paper, we propose a neural model that reads two sentences to determine entailment using long short-term memory units. We extend this model with a word-by-word neural attention mechanism that encourages reasoning over entailments of pairs of words and phrases. Furthermore, we present a qualitative analysis of attention weights produced by this model, demonstrating such reasoning capabilities. On a large entailment dataset this model outperforms the previous best neural model and a classifier with engineered features by a substantial margin. It is the first generic end-to-end differentiable system that achieves state-of-the-art accuracy on a textual entailment dataset.\nStory Comprehension for Predicting What Happens Next (Snigdha Chaturvedi et al., 2017) Snigdha Chaturvedi, Haoruo Peng, D. Roth. (2017)\nStory Comprehension for Predicting What Happens Next\nEMNLP\nPaper Link\nInfluential Citation Count (9), SS-ID (2cdc28b4f34410ff70099ae845daaaa25813f0e9)\nABSTRACT\nAutomatic story comprehension is a fundamental challenge in Natural Language Understanding, and can enable computers to learn about social norms, human behavior and commonsense. In this paper, we present a story comprehension model that explores three distinct semantic aspects: (i) the sequence of events described in the story, (ii) its emotional trajectory, and (iii) its plot consistency. We judge the model’s understanding of real-world stories by inquiring if, like humans, it can develop an expectation of what will happen next in a given story. Specifically, we use it to predict the correct ending of a given short story from possible alternatives. The model uses a hidden variable to weigh the semantic aspects in the context of the story. Our experiments demonstrate the potential of our approach to characterize these semantic aspects, and the strength of the hidden variable based approach. The model outperforms the state-of-the-art approaches and achieves best results on a publicly available dataset.\nSemi-Supervised Learning for Natural Language (P. Liang, 2005) P. Liang. (2005)\nSemi-Supervised Learning for Natural Language\nPaper Link\nInfluential Citation Count (33), SS-ID (31b4c03d721dc10b87c178277c1d369f91db8f0e)\nABSTRACT\nStatistical supervised learning techniques have been successful for many natural language processing tasks, but they require labeled datasets, which can be expensive to obtain. On the other hand, unlabeled data (raw text) is often available \u0026ldquo;for free\u0026rdquo; in large quantities. Unlabeled data has shown promise in improving the performance of a number of tasks, e.g. word sense disambiguation, information extraction, and natural language parsing. In this thesis, we focus on two segmentation tasks, named-entity recognition and Chinese word segmentation. The goal of named-entity recognition is to detect and classify names of people, organizations, and locations in a sentence. The goal of Chinese word segmentation is to find the word boundaries in a sentence that has been written as a string of characters without spaces. Our approach is as follows: In a preprocessing step, we use raw text to cluster words and calculate mutual information statistics. The output of this step is then used as features in a supervised model, specifically a global linear model trained using the Perceptron algorithm. We also compare Markov and semi-Markov models on the two segmentation tasks. Our results show that features derived from unlabeled data substantially improves performance, both in terms of reducing the amount of labeled data needed to achieve a certain performance level and in terms of reducing the error using a fixed amount of labeled data. We find that sometimes semi-Markov models can also improve performance over Markov models. Thesis Supervisor: Michael Collins Title: Assistant Professor, CSAIL\nA Stochastic Approximation Method (H. Robbins, 1951) H. Robbins. (1951)\nA Stochastic Approximation Method\nPaper Link\nInfluential Citation Count (739), SS-ID (34ddd8865569c2c32dec9bf7ffc817ff42faaa01)\nABSTRACT\nLet M(x) denote the expected value at level x of the response to a certain experiment. M(x) is assumed to be a monotone function of x but is unknown tot he experiment, and it is desire to find the solution x=0 of the equation M(x) = a, where x is a given constant. we give a method for making successive experiments at levels x1, x2,\u0026hellip; in such a way that x, will tend to 0 in probability.\nA Simple but Tough-to-Beat Baseline for Sentence Embeddings (Sanjeev Arora et al., 2017) Sanjeev Arora, Yingyu Liang, Tengyu Ma. (2017)\nA Simple but Tough-to-Beat Baseline for Sentence Embeddings\nICLR\nPaper Link\nInfluential Citation Count (156), SS-ID (3f1802d3f4f5f6d66875dac09112f978f12e1e1e)\nABSTRACT\nDeep Contextualized Word Representations (Matthew E. Peters et al., 2018) Matthew E. Peters, Mark Neumann, Mohit Iyyer, Matt Gardner, Christopher Clark, Kenton Lee, Luke Zettlemoyer. (2018)\nDeep Contextualized Word Representations\nNAACL\nPaper Link\nInfluential Citation Count (1362), SS-ID (3febb2bed8865945e7fddc99efd791887bb7e14f)\nABSTRACT\nWe introduce a new type of deep contextualized word representation that models both (1) complex characteristics of word use (e.g., syntax and semantics), and (2) how these uses vary across linguistic contexts (i.e., to model polysemy). Our word vectors are learned functions of the internal states of a deep bidirectional language model (biLM), which is pre-trained on a large text corpus. We show that these representations can be easily added to existing models and significantly improve the state of the art across six challenging NLP problems, including question answering, textual entailment and sentiment analysis. We also present an analysis showing that exposing the deep internals of the pre-trained network is crucial, allowing downstream models to mix different types of semi-supervision signals.\nBridging Nonlinearities and Stochastic Regularizers with Gaussian Error Linear Units (Dan Hendrycks et al., 2016) Dan Hendrycks, Kevin Gimpel. (2016)\nBridging Nonlinearities and Stochastic Regularizers with Gaussian Error Linear Units\nArXiv\nPaper Link\nInfluential Citation Count (45), SS-ID (4361e64f2d12d63476fdc88faf72a0f70d9a2ffb)\nABSTRACT\nWe propose the Gaussian Error Linear Unit (GELU), a high-performing neural network activation function. The GELU nonlinearity is the expected transformation of a stochastic regularizer which randomly applies the identity or zero map, combining the intuitions of dropout and zoneout while respecting neuron values. This connection suggests a new probabilistic understanding of nonlinearities. We perform an empirical evaluation of the GELU nonlinearity against the ReLU and ELU activations and find performance improvements across all tasks.\nGreedy Layer-Wise Training of Deep Networks (B. Schölkopf et al., 2007) B. Schölkopf, J. Platt, T. Hofmann. (2007)\nGreedy Layer-Wise Training of Deep Networks\nPaper Link\nInfluential Citation Count (134), SS-ID (43c8a545f7166659e9e21c88fe234e0323855216)\nABSTRACT\nComplexity theory of circuits strongly suggests that deep architectures can be much more ef cient (sometimes exponentially) than shallow architectures, in terms of computational elements required to represent some functions. Deep multi-layer neural networks have many levels of non-linearities allowing them to compactly represent highly non-linear and highly-varying functions. However, until recently it was not clear how to train such deep networks, since gradient-based optimization starting from random initialization appears to often get stuck in poor solutions. Hinton et al. recently introduced a greedy layer-wise unsupervised learning algorithm for Deep Belief Networks (DBN), a generative model with many layers of hidden causal variables. In the context of the above optimization problem, we study this algorithm empirically and explore variants to better understand its success and extend it to cases where the inputs are continuous or where the structure of the input distribution is not revealing enough about the variable to be predicted in a supervised task. Our experiments also confirm the hypothesis that the greedy layer-wise unsupervised training strategy mostly helps the optimization, by initializing weights in a region near a good local minimum, giving rise to internal distributed representations that are high-level abstractions of the input, bringing better generalization.\nFixing Weight Decay Regularization in Adam (I. Loshchilov et al., 2017) I. Loshchilov, F. Hutter. (2017)\nFixing Weight Decay Regularization in Adam\nArXiv\nPaper Link\nInfluential Citation Count (97), SS-ID (45dfef0cc1ed96558c1c650432ce39d6a1050b6a)\nABSTRACT\nWe note that common implementations of adaptive gradient algorithms, such as Adam, limit the potential benefit of weight decay regularization, because the weights do not decay multiplicatively (as would be expected for standard weight decay) but by an additive constant factor. We propose a simple way to resolve this issue by decoupling weight decay and the optimization steps taken w.r.t. the loss function. We provide empirical evidence that our proposed modification (i) decouples the optimal choice of weight decay factor from the setting of the learning rate for both standard SGD and Adam, and (ii) substantially improves Adam\u0026rsquo;s generalization performance, allowing it to compete with SGD with momentum on image classification datasets (on which it was previously typically outperformed by the latter). We also demonstrate that longer optimization runs require smaller weight decay values for optimal results and introduce a normalized variant of weight decay to reduce this dependence. Finally, we propose a version of Adam with warm restarts (AdamWR) that has strong anytime performance while achieving state-of-the-art results on CIFAR-10 and ImageNet32x32. Our source code will become available after the review process.\nAutomatically Constructing a Corpus of Sentential Paraphrases (W. Dolan et al., 2005) W. Dolan, Chris Brockett. (2005)\nAutomatically Constructing a Corpus of Sentential Paraphrases\nIJCNLP\nPaper Link\nInfluential Citation Count (143), SS-ID (475354f10798f110d34792b6d88f31d6d5cb099e)\nABSTRACT\nAn obstacle to research in automatic paraphrase identification and generation is the lack of large-scale, publiclyavailable labeled corpora of sentential paraphrases. This paper describes the creation of the recently-released Microsoft Research Paraphrase Corpus, which contains 5801 sentence pairs, each hand-labeled with a binary judgment as to whether the pair constitutes a paraphrase. The corpus was created using heuristic extraction techniques in conjunction with an SVM-based classifier to select likely sentence-level paraphrases from a large corpus of topicclustered news data. These pairs were then submitted to human judges, who confirmed that 67% were in fact semantically equivalent. In addition to describing the corpus itself, we explore a number of issues that arose in defining guidelines for the human raters.\nSemi-supervised Sequence Learning (Andrew M. Dai et al., 2015) Andrew M. Dai, Quoc V. Le. (2015)\nSemi-supervised Sequence Learning\nNIPS\nPaper Link\nInfluential Citation Count (54), SS-ID (4aa9f5150b46320f534de4747a2dd0cd7f3fe292)\nABSTRACT\nWe present two approaches to use unlabeled data to improve Sequence Learning with recurrent networks. The first approach is to predict what comes next in a sequence, which is a language model in NLP. The second approach is to use a sequence autoencoder, which reads the input sequence into a vector and predicts the input sequence again. These two algorithms can be used as a \u0026ldquo;pretraining\u0026rdquo; algorithm for a later supervised sequence learning algorithm. In other words, the parameters obtained from the pretraining step can then be used as a starting point for other supervised training models. In our experiments, we find that long short term memory recurrent networks after pretrained with the two approaches become more stable to train and generalize better. With pretraining, we were able to achieve strong performance in many classification tasks, such as text classification with IMDB, DBpedia or image recognition in CIFAR-10.\nTowards Human-level Machine Reading Comprehension: Reasoning and Inference with Multiple Strategies (Yichong Xu et al., 2017) Yichong Xu, Jingjing Liu, Jianfeng Gao, Yelong Shen, Xiaodong Liu. (2017)\nTowards Human-level Machine Reading Comprehension: Reasoning and Inference with Multiple Strategies\nArXiv\nPaper Link\nInfluential Citation Count (2), SS-ID (4e013e6c800666c5bc611ca820ae437a7139cbb6)\nABSTRACT\nThis paper presents a new MRC model that is capable of three key comprehension skills: 1) handling rich variations in question types; 2) understanding potential answer choices; and 3) drawing inference through multiple sentences. The model is based on the proposed MUlti-Strategy Inference for Comprehension (MUSIC) architecture, which is able to dynamically apply different attention strategies to different types of questions on the fly. By incorporating a multi-step inference engine analogous to ReasoNet (Shen et al., 2017), MUSIC can also effectively perform multi-sentence inference in generating answers. Evaluation on the RACE dataset shows that the proposed method significantly outperforms previous state-of-the-art models by 7.5% in relative accuracy.\nA unified architecture for natural language processing: deep neural networks with multitask learning (Ronan Collobert et al., 2008) Ronan Collobert, J. Weston. (2008)\nA unified architecture for natural language processing: deep neural networks with multitask learning\nICML \u0026lsquo;08\nPaper Link\nInfluential Citation Count (259), SS-ID (57458bc1cffe5caa45a885af986d70f723f406b4)\nABSTRACT\nWe describe a single convolutional neural network architecture that, given a sentence, outputs a host of language processing predictions: part-of-speech tags, chunks, named entity tags, semantic roles, semantically similar words and the likelihood that the sentence makes sense (grammatically and semantically) using a language model. The entire network is trained jointly on all these tasks using weight-sharing, an instance of multitask learning. All the tasks use labeled data except the language model which is learnt from unlabeled text and represents a novel form of semi-supervised learning for the shared tasks. We show how both multitask learning and semi-supervised learning improve the generalization of the shared tasks, resulting in state-of-the-art-performance.\nUNSUPERVISED MACHINE TRANSLATION USING MONOLINGUAL CORPORA ONLY (Piotr, 2017) Piotr. (2017)\nUNSUPERVISED MACHINE TRANSLATION USING MONOLINGUAL CORPORA ONLY\nPaper Link\nInfluential Citation Count (9), SS-ID (57ea3bc5ad8d67909b086a92a801a5e5f2d17035)\nABSTRACT\nMachine translation has recently achieved impressive performance thanks to recent advances in deep learning and the availability of large-scale parallel corpora. There have been numerous attempts to extend these successes to low-resource language pairs, yet requiring tens of thousands of parallel sentences. In this work, we take this research direction to the extreme and investigate whether it is possible to learn to translate even without any parallel data. We propose a model that takes sentences from monolingual corpora in two different languages and maps them into the same latent space. By learning to reconstruct in both languages from this shared feature space, the model effectively learns to translate without using any labeled data. We demonstrate our model on two widely used datasets and two language pairs, reporting BLEU scores of 32.8 and 15.1 on the Multi30k and WMT English-French datasets, without using even a single parallel sentence at training time.\nA Broad-Coverage Challenge Corpus for Sentence Understanding through Inference (Adina Williams et al., 2017) Adina Williams, Nikita Nangia, Samuel R. Bowman. (2017)\nA Broad-Coverage Challenge Corpus for Sentence Understanding through Inference\nNAACL\nPaper Link\nInfluential Citation Count (463), SS-ID (5ded2b8c64491b4a67f6d39ce473d4b9347a672e)\nABSTRACT\nThis paper introduces the Multi-Genre Natural Language Inference (MultiNLI) corpus, a dataset designed for use in the development and evaluation of machine learning models for sentence understanding. At 433k examples, this resource is one of the largest corpora available for natural language inference (a.k.a. recognizing textual entailment), improving upon available resources in both its coverage and difficulty. MultiNLI accomplishes this by offering data from ten distinct genres of written and spoken English, making it possible to evaluate systems on nearly the full complexity of the language, while supplying an explicit setting for evaluating cross-genre domain adaptation. In addition, an evaluation using existing machine learning models designed for the Stanford NLI corpus shows that it represents a substantially more difficult task than does that corpus, despite the two showing similar levels of inter-annotator agreement.\nStochastic Answer Networks for Natural Language Inference (Xiaodong Liu et al., 2018) Xiaodong Liu, Kevin Duh, Jianfeng Gao. (2018)\nStochastic Answer Networks for Natural Language Inference\nArXiv\nPaper Link\nInfluential Citation Count (3), SS-ID (6084b58d8b4b0caf3a2a7f3a1bee1cc527927e39)\nABSTRACT\nWe propose a stochastic answer network (SAN) to explore multi-step inference strategies in Natural Language Inference. Rather than directly predicting the results given the inputs, the model maintains a state and iteratively refines its predictions. Our experiments show that SAN achieves the state-of-the-art results on three benchmarks: Stanford Natural Language Inference (SNLI) dataset, MultiGenre Natural Language Inference (MultiNLI) dataset and Quora Question Pairs dataset.\nSplit-Brain Autoencoders: Unsupervised Learning by Cross-Channel Prediction (Richard Zhang et al., 2016) Richard Zhang, Phillip Isola, Alexei A. Efros. (2016)\nSplit-Brain Autoencoders: Unsupervised Learning by Cross-Channel Prediction\n2017 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)\nPaper Link\nInfluential Citation Count (37), SS-ID (62f3d3015cee122bd147d7d878c85f70cc15680d)\nABSTRACT\nWe propose split-brain autoencoders, a straightforward modification of the traditional autoencoder architecture, for unsupervised representation learning. The method adds a split to the network, resulting in two disjoint sub-networks. Each sub-network is trained to perform a difficult task – predicting one subset of the data channels from another. Together, the sub-networks extract features from the entire input signal. By forcing the network to solve cross-channel prediction tasks, we induce a representation within the network which transfers well to other, unseen tasks. This method achieves state-of-the-art performance on several large-scale transfer learning benchmarks.\nRACE: Large-scale ReAding Comprehension Dataset From Examinations (Guokun Lai et al., 2017) Guokun Lai, Qizhe Xie, Hanxiao Liu, Yiming Yang, E. Hovy. (2017)\nRACE: Large-scale ReAding Comprehension Dataset From Examinations\nEMNLP\nPaper Link\nInfluential Citation Count (183), SS-ID (636a79420d838eabe4af7fb25d6437de45ab64e8)\nABSTRACT\nWe present RACE, a new dataset for benchmark evaluation of methods in the reading comprehension task. Collected from the English exams for middle and high school Chinese students in the age range between 12 to 18, RACE consists of near 28,000 passages and near 100,000 questions generated by human experts (English instructors), and covers a variety of topics which are carefully designed for evaluating the students’ ability in understanding and reasoning. In particular, the proportion of questions that requires reasoning is much larger in RACE than that in other benchmark datasets for reading comprehension, and there is a significant gap between the performance of the state-of-the-art models (43%) and the ceiling human performance (95%). We hope this new dataset can serve as a valuable resource for research and evaluation in machine comprehension. The dataset is freely available at http://www.cs.cmu.edu/~glai1/data/race/ and the code is available at https://github.com/qizhex/RACE_AR_baselines.\nRecursive Deep Models for Semantic Compositionality Over a Sentiment Treebank (R. Socher et al., 2013) R. Socher, Alex Perelygin, Jean Wu, Jason Chuang, Christopher D. Manning, A. Ng, Christopher Potts. (2013)\nRecursive Deep Models for Semantic Compositionality Over a Sentiment Treebank\nEMNLP\nPaper Link\nInfluential Citation Count (885), SS-ID (687bac2d3320083eb4530bf18bb8f8f721477600)\nABSTRACT\nSemantic word spaces have been very useful but cannot express the meaning of longer phrases in a principled way. Further progress towards understanding compositionality in tasks such as sentiment detection requires richer supervised training and evaluation resources and more powerful models of composition. To remedy this, we introduce a Sentiment Treebank. It includes fine grained sentiment labels for 215,154 phrases in the parse trees of 11,855 sentences and presents new challenges for sentiment compositionality. To address them, we introduce the Recursive Neural Tensor Network. When trained on the new treebank, this model outperforms all previous methods on several metrics. It pushes the state of the art in single sentence positive/negative classification from 80% up to 85.4%. The accuracy of predicting fine-grained sentiment labels for all phrases reaches 80.7%, an improvement of 9.7% over bag of features baselines. Lastly, it is the only model that can accurately capture the effects of negation and its scope at various tree levels for both positive and negative phrases.\nSkip-Thought Vectors (Ryan Kiros et al., 2015) Ryan Kiros, Yukun Zhu, R. Salakhutdinov, R. Zemel, R. Urtasun, A. Torralba, S. Fidler. (2015)\nSkip-Thought Vectors\nNIPS\nPaper Link\nInfluential Citation Count (259), SS-ID (6e795c6e9916174ae12349f5dc3f516570c17ce8)\nABSTRACT\nWe describe an approach for unsupervised learning of a generic, distributed sentence encoder. Using the continuity of text from books, we train an encoder-decoder model that tries to reconstruct the surrounding sentences of an encoded passage. Sentences that share semantic and syntactic properties are thus mapped to similar vector representations. We next introduce a simple vocabulary expansion method to encode words that were not seen as part of training, allowing us to expand our vocabulary to a million words. After training our model, we extract and evaluate our vectors with linear models on 8 tasks: semantic relatedness, paraphrase detection, image-sentence ranking, question-type classification and 4 benchmark sentiment and subjectivity datasets. The end result is an off-the-shelf encoder that can produce highly generic sentence representations that are robust and perform well in practice.\nA Simple and Effective Approach to the Story Cloze Test (Siddarth Srinivasan et al., 2018) Siddarth Srinivasan, Richa Arora, Mark O. Riedl. (2018)\nA Simple and Effective Approach to the Story Cloze Test\nNAACL\nPaper Link\nInfluential Citation Count (2), SS-ID (72c2cc507bc7203bcb4eaf6a3df6e9e8f8514e31)\nABSTRACT\nIn the Story Cloze Test, a system is presented with a 4-sentence prompt to a story, and must determine which one of two potential endings is the ‘right’ ending to the story. Previous work has shown that ignoring the training set and training a model on the validation set can achieve high accuracy on this task due to stylistic differences between the story endings in the training set and validation and test sets. Following this approach, we present a simpler fully-neural approach to the Story Cloze Test using skip-thought embeddings of the stories in a feed-forward network that achieves close to state-of-the-art performance on this task without any feature engineering. We also find that considering just the last sentence of the prompt instead of the whole prompt yields higher accuracy with our approach.\nGenerating Wikipedia by Summarizing Long Sequences (Peter J. Liu et al., 2018) Peter J. Liu, Mohammad Saleh, Etienne Pot, Ben Goodrich, Ryan Sepassi, Lukasz Kaiser, Noam M. Shazeer. (2018)\nGenerating Wikipedia by Summarizing Long Sequences\nICLR\nPaper Link\nInfluential Citation Count (77), SS-ID (7570afa31c68e24fce1342b7d67c591787219bc1)\nABSTRACT\nWe show that generating English Wikipedia articles can be approached as a multi- document summarization of source documents. We use extractive summarization to coarsely identify salient information and a neural abstractive model to generate the article. For the abstractive model, we introduce a decoder-only architecture that can scalably attend to very long sequences, much longer than typical encoder- decoder architectures used in sequence transduction. We show that this model can generate fluent, coherent multi-sentence paragraphs and even whole Wikipedia articles. When given reference documents, we show it can extract relevant factual information as reflected in perplexity, ROUGE scores and human evaluations.\nWhen and Why Are Pre-Trained Word Embeddings Useful for Neural Machine Translation? (Ye Qi et al., 2018) Ye Qi, Devendra Singh Sachan, Matthieu Felix, S. Padmanabhan, Graham Neubig. (2018)\nWhen and Why Are Pre-Trained Word Embeddings Useful for Neural Machine Translation?\nNAACL\nPaper Link\nInfluential Citation Count (27), SS-ID (7b29f45df975ed1e4c3864b6ab4483f11086aa76)\nABSTRACT\nThe performance of Neural Machine Translation (NMT) systems often suffers in low-resource scenarios where sufficiently large-scale parallel corpora cannot be obtained. Pre-trained word embeddings have proven to be invaluable for improving performance in natural language analysis tasks, which often suffer from paucity of data. However, their utility for NMT has not been extensively explored. In this work, we perform five sets of experiments that analyze when we can expect pre-trained word embeddings to help in NMT tasks. We show that such embeddings can be surprisingly effective in some cases – providing gains of up to 20 BLEU points in the most favorable setting.\nSemi-Supervised Sequential Labeling and Segmentation Using Giga-Word Scale Unlabeled Data (Jun Suzuki et al., 2008) Jun Suzuki, Hideki Isozaki. (2008)\nSemi-Supervised Sequential Labeling and Segmentation Using Giga-Word Scale Unlabeled Data\nACL\nPaper Link\nInfluential Citation Count (11), SS-ID (7ece4e8d31f872d928369ac2cf58a616a7182112)\nABSTRACT\nThis paper provides evidence that the use of more unlabeled data in semi-supervised learning can improve the performance of Natural Language Processing (NLP) tasks, such as part-of-speech tagging, syntactic chunking, and named entity recognition. We first propose a simple yet powerful semi-supervised discriminative model appropriate for handling large scale unlabeled data. Then, we describe experiments performed on widely used test collections, namely, PTB III data, CoNLL’00 and ’03 shared task data for the above three NLP tasks, respectively. We incorporate up to 1G-words (one billion tokens) of unlabeled data, which is the largest amount of unlabeled data ever used for these tasks, to investigate the performance improvement. In addition, our results are superior to the best reported results for all of the above test collections.\nExtracting and composing robust features with denoising autoencoders (Pascal Vincent et al., 2008) Pascal Vincent, H. Larochelle, Yoshua Bengio, Pierre-Antoine Manzagol. (2008)\nExtracting and composing robust features with denoising autoencoders\nICML \u0026lsquo;08\nPaper Link\nInfluential Citation Count (454), SS-ID (843959ffdccf31c6694d135fad07425924f785b1)\nABSTRACT\nPrevious work has shown that the difficulties in learning deep generative or discriminative models can be overcome by an initial unsupervised learning step that maps inputs to useful intermediate representations. We introduce and motivate a new training principle for unsupervised learning of a representation based on the idea of making the learned representations robust to partial corruption of the input pattern. This approach can be used to train autoencoders, and these denoising autoencoders can be stacked to initialize deep architectures. The algorithm can be motivated from a manifold learning and information theoretic perspective or from a generative model perspective. Comparative experiments clearly show the surprising advantage of corrupting the input of autoencoders on a pattern classification benchmark suite.\nUnsupervised Pretraining for Sequence to Sequence Learning (Prajit Ramachandran et al., 2016) Prajit Ramachandran, Peter J. Liu, Quoc V. Le. (2016)\nUnsupervised Pretraining for Sequence to Sequence Learning\nEMNLP\nPaper Link\nInfluential Citation Count (13), SS-ID (85f94d8098322f8130512b4c6c4627548ce4a6cc)\nABSTRACT\nThis work presents a general unsupervised learning method to improve the accuracy of sequence to sequence (seq2seq) models. In our method, the weights of the encoder and decoder of a seq2seq model are initialized with the pretrained weights of two language models and then fine-tuned with labeled data. We apply this method to challenging benchmarks in machine translation and abstractive summarization and find that it significantly improves the subsequent supervised models. Our main result is that pretraining improves the generalization of seq2seq models. We achieve state-of-the-art results on the WMT English→German task, surpassing a range of methods using both phrase-based machine translation and neural machine translation. Our method achieves a significant improvement of 1.3 BLEU from th previous best models on both WMT’14 and WMT’15 English→German. We also conduct human evaluations on abstractive summarization and find that our method outperforms a purely supervised learning baseline in a statistically significant manner.\nDistributed Representations of Words and Phrases and their Compositionality (Tomas Mikolov et al., 2013) Tomas Mikolov, Ilya Sutskever, Kai Chen, G. Corrado, J. Dean. (2013)\nDistributed Representations of Words and Phrases and their Compositionality\nNIPS\nPaper Link\nInfluential Citation Count (3626), SS-ID (87f40e6f3022adbc1f1905e3e506abad05a9964f)\nABSTRACT\nThe recently introduced continuous Skip-gram model is an efficient method for learning high-quality distributed vector representations that capture a large number of precise syntactic and semantic word relationships. In this paper we present several extensions that improve both the quality of the vectors and the training speed. By subsampling of the frequent words we obtain significant speedup and also learn more regular word representations. We also describe a simple alternative to the hierarchical softmax called negative sampling. An inherent limitation of word representations is their indifference to word order and their inability to represent idiomatic phrases. For example, the meanings of \u0026ldquo;Canada\u0026rdquo; and \u0026ldquo;Air\u0026rdquo; cannot be easily combined to obtain \u0026ldquo;Air Canada\u0026rdquo;. Motivated by this example, we present a simple method for finding phrases in text, and show that learning good vector representations for millions of phrases is possible.\nA Fast Learning Algorithm for Deep Belief Nets (Geoffrey E. Hinton et al., 2006) Geoffrey E. Hinton, Simon Osindero, Y. Teh. (2006)\nA Fast Learning Algorithm for Deep Belief Nets\nNeural Computation\nPaper Link\nInfluential Citation Count (1144), SS-ID (8978cf7574ceb35f4c3096be768c7547b28a35d0)\nABSTRACT\nWe show how to use complementary priors to eliminate the explaining-away effects that make inference difficult in densely connected belief nets that have many hidden layers. Using complementary priors, we derive a fast, greedy algorithm that can learn deep, directed belief networks one layer at a time, provided the top two layers form an undirected associative memory. The fast, greedy algorithm is used to initialize a slower learning procedure that fine-tunes the weights using a contrastive version of the wake-sleep algorithm. After fine-tuning, a network with three hidden layers forms a very good generative model of the joint distribution of handwritten digit images and their labels. This generative model gives better digit classification than the best discriminative learning algorithms. The low-dimensional manifolds on which the digits lie are modeled by long ravines in the free-energy landscape of the top-level associative memory, and it is easy to explore these ravines by using the directed connections to display what the associative memory has in mind.\nSemi-Supervised Text Classification Using EM (K. Nigam et al., 2006) K. Nigam, A. McCallum, Tom Michael Mitchell. (2006)\nSemi-Supervised Text Classification Using EM\nSemi-Supervised Learning\nPaper Link\nInfluential Citation Count (11), SS-ID (8eefd28eb47e72794bb0355d8abcbebaac9d8ab1)\nABSTRACT\nFor several decades, statisticians have advocated using a combination of labeled and unlabeled data to train classifiers by estimating parameters of a generative model through iterative Expectation-Maximization (EM) techniques. This chapter explores the effectiveness of this approach when applied to the domain of text classification. Text documents are represented here with a bag-of-words model, which leads to a generative classification model based on a mixture of multinomials. This model is an extremely simplistic representation of the complexities of written text. This chapter explains and illustrates three key points about semi-supervised learning for text classification with generative models. First, despite the simplistic representation, some text domains have a high positive correlation between generative model probability and classification accuracy. In these domains, a straightforward application of EM with the naive Bayes text model works well. Second, some text domains do not have this correlation. Here we can adopt a more expressive and appropriate generative model that does have a positive correlation. In these domains, semi-supervised learning again improves classification accuracy. Finally, EM suffers from the problem of local maxima, especially in high dimension domains such as text classification. We demonstrate that deterministic annealing, a variant of EM, can help overcome the problem of local maxima and increase classification accuracy further when the generative model is appropriate.\nQuora Question Pairs (Zihang Chen et al., 2017) Zihang Chen, Hongbo Zhang, Xiaoji Zhang, Leqi Zhao. (2017)\nQuora Question Pairs\nPaper Link\nInfluential Citation Count (9), SS-ID (8ff46c88964a36985f2b45933a3d47b81bd87bd0)\nABSTRACT\nQuora Question Pairs is an active Kaggle Competition, which challenges participants to tackle the natural language processing (NLP) problem of identifying duplicate questions [1]. The issue of duplicate questions stems from the enormous number of visitors on the Quora website (a platform for asking questions and connecting with people that contribute answers), making it hard to avoid having similar worded questions from different users. Effectively detecting duplicate questions not only saves time for seekers to find the best answer to their questions, but also reduces the effort of writers in terms of answering multiple versions of the same question[1].\nConstituency Parsing with a Self-Attentive Encoder (Nikita Kitaev et al., 2018) Nikita Kitaev, D. Klein. (2018)\nConstituency Parsing with a Self-Attentive Encoder\nACL\nPaper Link\nInfluential Citation Count (40), SS-ID (928f9dccb806a3278d20d82cc53781c5f44e2bb1)\nABSTRACT\nWe demonstrate that replacing an LSTM encoder with a self-attentive architecture can lead to improvements to a state-of-the-art discriminative constituency parser. The use of attention makes explicit the manner in which information is propagated between different locations in the sentence, which we use to both analyze our model and propose potential improvements. For example, we find that separating positional and content information in the encoder can lead to improved parsing accuracy. Additionally, we evaluate different approaches for lexical representation. Our parser achieves new state-of-the-art results for single models trained on the Penn Treebank: 93.55 F1 without the use of any external data, and 95.13 F1 when using pre-trained word representations. Our parser also outperforms the previous best-published accuracy figures on 8 of the 9 languages in the SPMRL dataset.\nEfficient Learning of Sparse Representations with an Energy-Based Model (Marc\u0026#39;Aurelio Ranzato et al., 2006) Marc\u0026rsquo;Aurelio Ranzato, Christopher S. Poultney, S. Chopra, Yann LeCun. (2006)\nEfficient Learning of Sparse Representations with an Energy-Based Model\nNIPS\nPaper Link\nInfluential Citation Count (55), SS-ID (932c2a02d462abd75af018125413b1ceaa1ee3f4)\nABSTRACT\nWe describe a novel unsupervised method for learning sparse, overcomplete features. The model uses a linear encoder, and a linear decoder preceded by a sparsifying non-linearity that turns a code vector into a quasi-binary sparse code vector. Given an input, the optimal code minimizes the distance between the output of the decoder and the input patch while being as similar as possible to the encoder output. Learning proceeds in a two-phase EM-like fashion: (1) compute the minimum-energy code vector, (2) adjust the parameters of the encoder and decoder so as to decrease the energy. The model produces \u0026ldquo;stroke detectors\u0026rdquo; when trained on handwritten numerals, and Gabor-like filters when trained on natural image patches. Inference and learning are very fast, requiring no preprocessing, and no expensive sampling. Using the proposed unsupervised method to initialize the first layer of a convolutional network, we achieved an error rate slightly lower than the best reported result on the MNIST dataset. Finally, an extension of the method is described to learn topographical filter maps.\nGLUE: A Multi-Task Benchmark and Analysis Platform for Natural Language Understanding (Alex Wang et al., 2018) Alex Wang, Amanpreet Singh, Julian Michael, Felix Hill, Omer Levy, Samuel R. Bowman. (2018)\nGLUE: A Multi-Task Benchmark and Analysis Platform for Natural Language Understanding\nBlackboxNLP@EMNLP\nPaper Link\nInfluential Citation Count (672), SS-ID (93b8da28d006415866bf48f9a6e06b5242129195)\nABSTRACT\nHuman ability to understand language is general, flexible, and robust. In contrast, most NLU models above the word level are designed for a specific task and struggle with out-of-domain data. If we aspire to develop models with understanding beyond the detection of superficial correspondences between inputs and outputs, then it is critical to develop a unified model that can execute a range of linguistic tasks across different domains. To facilitate research in this direction, we present the General Language Understanding Evaluation (GLUE, gluebenchmark.com): a benchmark of nine diverse NLU tasks, an auxiliary dataset for probing models for understanding of specific linguistic phenomena, and an online platform for evaluating and comparing models. For some benchmark tasks, training data is plentiful, but for others it is limited or does not match the genre of the test set. GLUE thus favors models that can represent linguistic knowledge in a way that facilitates sample-efficient learning and effective knowledge-transfer across tasks. While none of the datasets in GLUE were created from scratch for the benchmark, four of them feature privately-held test data, which is used to ensure that the benchmark is used fairly. We evaluate baselines that use ELMo (Peters et al., 2018), a powerful transfer learning technique, as well as state-of-the-art sentence representation models. The best models still achieve fairly low absolute scores. Analysis with our diagnostic dataset yields similarly weak performance over all phenomena tested, with some exceptions.\nLSDSem 2017 Shared Task: The Story Cloze Test (N. Mostafazadeh et al., 2017) N. Mostafazadeh, Michael Roth, Annie Louis, Nathanael Chambers, James F. Allen. (2017)\nLSDSem 2017 Shared Task: The Story Cloze Test\nLSDSem@EACL\nPaper Link\nInfluential Citation Count (14), SS-ID (97394554eb5a74c3160c6bd743fcd3e4bd6cbe28)\nABSTRACT\nThe LSDSem’17 shared task is the Story Cloze Test, a new evaluation for story understanding and script learning. This test provides a system with a four-sentence story and two possible endings, and the system must choose the correct ending to the story. Successful narrative understanding (getting closer to human performance of 100%) requires systems to link various levels of semantics to commonsense knowledge. A total of eight systems participated in the shared task, with a variety of approaches including.\nWhy Does Unsupervised Pre-training Help Deep Learning? (P. Glöckner, 2013) P. Glöckner. (2013)\nWhy Does Unsupervised Pre-training Help Deep Learning?\nPaper Link\nInfluential Citation Count (53), SS-ID (97474c55c834584b71f006557aed70e09eb6eb47)\nABSTRACT\nLayer Normalization (Jimmy Ba et al., 2016) Jimmy Ba, J. Kiros, Geoffrey E. Hinton. (2016)\nLayer Normalization\nArXiv\nPaper Link\nInfluential Citation Count (168), SS-ID (97fb4e3d45bb098e27e0071448b6152217bd35a5)\nABSTRACT\nTraining state-of-the-art, deep neural networks is computationally expensive. One way to reduce the training time is to normalize the activities of the neurons. A recently introduced technique called batch normalization uses the distribution of the summed input to a neuron over a mini-batch of training cases to compute a mean and variance which are then used to normalize the summed input to that neuron on each training case. This significantly reduces the training time in feedforward neural networks. However, the effect of batch normalization is dependent on the mini-batch size and it is not obvious how to apply it to recurrent neural networks. In this paper, we transpose batch normalization into layer normalization by computing the mean and variance used for normalization from all of the summed inputs to the neurons in a layer on a single training case. Like batch normalization, we also give each neuron its own adaptive bias and gain which are applied after the normalization but before the non-linearity. Unlike batch normalization, layer normalization performs exactly the same computation at training and test times. It is also straightforward to apply to recurrent neural networks by computing the normalization statistics separately at each time step. Layer normalization is very effective at stabilizing the hidden state dynamics in recurrent networks. Empirically, we show that layer normalization can substantially reduce the training time compared with previously published techniques.\nSemi-Supervised Learning Literature Survey (Xiaojin Zhu, 2005) Xiaojin Zhu. (2005)\nSemi-Supervised Learning Literature Survey\nPaper Link\nInfluential Citation Count (244), SS-ID (a007f46b3303bdb50e705b441c367e595666538c)\nABSTRACT\nGPU Kernels for Block-Sparse Weights (Scott Gray et al., 2017) Scott Gray, Alec Radford, Diederik P. Kingma. (2017)\nGPU Kernels for Block-Sparse Weights\nPaper Link\nInfluential Citation Count (12), SS-ID (a07609c2ed39d049d3e59b61408fb600c6ab0950)\nABSTRACT\nWe’re releasing highly optimized GPU kernels for an underexplored class of neural network architectures: networks with block-sparse weights. The kernels allow for efficient evaluation and differentiation of linear layers, including convolutional layers, with flexibly configurable block-sparsity patterns in the weight matrix. We find that depending on the sparsity, these kernels can run orders of magnitude faster than the best available alternatives such as cuBLAS. Using the kernels we improve upon the state-of-the-art in text sentiment analysis and generative modeling of text and images. By releasing our kernels in the open we aim to spur further advancement in model and algorithm design.\nA Fast and Accurate Dependency Parser using Neural Networks (Danqi Chen et al., 2014) Danqi Chen, Christopher D. Manning. (2014)\nA Fast and Accurate Dependency Parser using Neural Networks\nEMNLP\nPaper Link\nInfluential Citation Count (143), SS-ID (a14045a751f5d8ed387c8630a86a3a2861b90643)\nABSTRACT\nAlmost all current dependency parsers classify based on millions of sparse indicator features. Not only do these features generalize poorly, but the cost of feature computation restricts parsing speed significantly. In this work, we propose a novel way of learning a neural network classifier for use in a greedy, transition-based dependency parser. Because this classifier learns and uses just a small number of dense features, it can work very fast, while achieving an about 2% improvement in unlabeled and labeled attachment scores on both English and Chinese datasets. Concretely, our parser is able to parse more than 1000 sentences per second at 92.2% unlabeled attachment score on the English Penn Treebank.\nSemEval-2017 Task 1: Semantic Textual Similarity Multilingual and Crosslingual Focused Evaluation (Daniel Matthew Cer et al., 2017) Daniel Matthew Cer, Mona T. Diab, Eneko Agirre, I. Lopez-Gazpio, Lucia Specia. (2017)\nSemEval-2017 Task 1: Semantic Textual Similarity Multilingual and Crosslingual Focused Evaluation\nSemEval@ACL\nPaper Link\nInfluential Citation Count (165), SS-ID (a23fa96e7217ba0e9405d9e1fe3cdedd57b6e096)\nABSTRACT\nSemantic Textual Similarity (STS) measures the meaning similarity of sentences. Applications include machine translation (MT), summarization, generation, question answering (QA), short answer grading, semantic search, dialog and conversational systems. The STS shared task is a venue for assessing the current state-of-the-art. The 2017 task focuses on multilingual and cross-lingual pairs with one sub-track exploring MT quality estimation (MTQE) data. The task obtained strong participation from 31 teams, with 17 participating in all language tracks. We summarize performance and review a selection of well performing methods. Analysis highlights common errors, providing insight into the limitations of existing models. To support ongoing work on semantic representations, the STS Benchmark is introduced as a new shared training and evaluation set carefully selected from the corpus of English STS shared task data (2012-2017).\nAdam: A Method for Stochastic Optimization (Diederik P. Kingma et al., 2014) Diederik P. Kingma, Jimmy Ba. (2014)\nAdam: A Method for Stochastic Optimization\nICLR\nPaper Link\nInfluential Citation Count (14937), SS-ID (a6cb366736791bcccc5c8639de5a8f9636bf87e8)\nABSTRACT\nWe introduce Adam, an algorithm for first-order gradient-based optimization of stochastic objective functions, based on adaptive estimates of lower-order moments. The method is straightforward to implement, is computationally efficient, has little memory requirements, is invariant to diagonal rescaling of the gradients, and is well suited for problems that are large in terms of data and/or parameters. The method is also appropriate for non-stationary objectives and problems with very noisy and/or sparse gradients. The hyper-parameters have intuitive interpretations and typically require little tuning. Some connections to related algorithms, on which Adam was inspired, are discussed. We also analyze the theoretical convergence properties of the algorithm and provide a regret bound on the convergence rate that is comparable to the best known results under the online convex optimization framework. Empirical results demonstrate that Adam works well in practice and compares favorably to other stochastic optimization methods. Finally, we discuss AdaMax, a variant of Adam based on the infinity norm.\nDiscourse-Based Objectives for Fast Unsupervised Sentence Representation Learning (Yacine Jernite et al., 2017) Yacine Jernite, Samuel R. Bowman, D. Sontag. (2017)\nDiscourse-Based Objectives for Fast Unsupervised Sentence Representation Learning\nArXiv\nPaper Link\nInfluential Citation Count (9), SS-ID (a97dc52807d80454e78d255f9fbd7b0fab56bd03)\nABSTRACT\nThis work presents a novel objective function for the unsupervised training of neural network sentence encoders. It exploits signals from paragraph-level discourse coherence to train these models to understand text. Our objective is purely discriminative, allowing us to train models many times faster than was possible under prior methods, and it yields models which perform well in extrinsic evaluations.\nSemi-supervised Multitask Learning for Sequence Labeling (Marek Rei, 2017) Marek Rei. (2017)\nSemi-supervised Multitask Learning for Sequence Labeling\nACL\nPaper Link\nInfluential Citation Count (17), SS-ID (ac17cfa150d802750b46220084d850cfdb64d1c1)\nABSTRACT\nWe propose a sequence labeling framework with a secondary training objective, learning to predict surrounding words for every word in the dataset. This language modeling objective incentivises the system to learn general-purpose patterns of semantic and syntactic composition, which are also useful for improving accuracy on different sequence labeling tasks. The architecture was evaluated on a range of datasets, covering the tasks of error detection in learner texts, named entity recognition, chunking and POS-tagging. The novel language modeling objective provided consistent performance improvements on every benchmark, without requiring any additional annotated or unannotated data.\nLearning General Purpose Distributed Sentence Representations via Large Scale Multi-task Learning (Sandeep Subramanian et al., 2018) Sandeep Subramanian, Adam Trischler, Yoshua Bengio, C. Pal. (2018)\nLearning General Purpose Distributed Sentence Representations via Large Scale Multi-task Learning\nICLR\nPaper Link\nInfluential Citation Count (38), SS-ID (afc2850945a871e72c245818f9bc141bd659b453)\nABSTRACT\nA lot of the recent success in natural language processing (NLP) has been driven by distributed vector representations of words trained on large amounts of text in an unsupervised manner. These representations are typically used as general purpose features for words across a range of NLP problems. However, extending this success to learning representations of sequences of words, such as sentences, remains an open problem. Recent work has explored unsupervised as well as supervised learning techniques with different training objectives to learn general purpose fixed-length sentence representations. In this work, we present a simple, effective multi-task learning framework for sentence representations that combines the inductive biases of diverse training objectives in a single model. We train this model on several data sources with multiple training objectives on over 100 million sentences. Extensive experiments demonstrate that sharing a single recurrent sentence encoder across weakly related tasks leads to consistent improvements over previous methods. We present substantial improvements in the context of transfer learning and low-resource settings using our learned general-purpose representations.\nResolving Complex Cases of Definite Pronouns: The Winograd Schema Challenge (Altaf Rahman et al., 2012) Altaf Rahman, Vincent Ng. (2012)\nResolving Complex Cases of Definite Pronouns: The Winograd Schema Challenge\nEMNLP\nPaper Link\nInfluential Citation Count (37), SS-ID (b0c5f72790cca220541ea4809d1e43b4bdad1124)\nABSTRACT\nWe examine the task of resolving complex cases of definite pronouns, specifically those for which traditional linguistic constraints on coreference (e.g., Binding Constraints, gender and number agreement) as well as commonly-used resolution heuristics (e.g., string-matching facilities, syntactic salience) are not useful. Being able to solve this task has broader implications in artificial intelligence: a restricted version of it, sometimes referred to as the Winograd Schema Challenge, has been suggested as a conceptually and practically appealing alternative to the Turing Test. We employ a knowledge-rich approach to this task, which yields a pronoun resolver that outperforms state-of-the-art resolvers by nearly 18 points in accuracy on our dataset.\nNatural Language Processing (Almost) from Scratch (Ronan Collobert et al., 2011) Ronan Collobert, J. Weston, L. Bottou, Michael Karlen, K. Kavukcuoglu, P. Kuksa. (2011)\nNatural Language Processing (Almost) from Scratch\nJ. Mach. Learn. Res.\nPaper Link\nInfluential Citation Count (680), SS-ID (bc1022b031dc6c7019696492e8116598097a8c12)\nABSTRACT\nWe propose a unified neural network architecture and learning algorithm that can be applied to various natural language processing tasks including part-of-speech tagging, chunking, named entity recognition, and semantic role labeling. This versatility is achieved by trying to avoid task-specific engineering and therefore disregarding a lot of prior knowledge. Instead of exploiting man-made input features carefully optimized for each task, our system learns internal representations on the basis of vast amounts of mostly unlabeled training data. This work is then used as a basis for building a freely available tagging system with good performance and minimal computational requirements.\nAn efficient framework for learning sentence representations (L. Logeswaran et al., 2018) L. Logeswaran, Honglak Lee. (2018)\nAn efficient framework for learning sentence representations\nICLR\nPaper Link\nInfluential Citation Count (29), SS-ID (bc1d609520290e0460c49b685675eb5a57fa5935)\nABSTRACT\nIn this work we propose a simple and efficient framework for learning sentence representations from unlabelled data. Drawing inspiration from the distributional hypothesis and recent work on learning sentence representations, we reformulate the problem of predicting the context in which a sentence appears as a classification problem. Given a sentence and its context, a classifier distinguishes context sentences from other contrastive sentences based on their vector representations. This allows us to efficiently learn different types of encoding functions, and we show that the model learns high-quality sentence representations. We demonstrate that our sentence representations outperform state-of-the-art unsupervised and supervised representation learning methods on several downstream NLP tasks that involve understanding sentence semantics while achieving an order of magnitude speedup in training time.\nLearned in Translation: Contextualized Word Vectors (Bryan McCann et al., 2017) Bryan McCann, James Bradbury, Caiming Xiong, R. Socher. (2017)\nLearned in Translation: Contextualized Word Vectors\nNIPS\nPaper Link\nInfluential Citation Count (65), SS-ID (bc8fa64625d9189f5801837e7b133e7fe3c581f7)\nABSTRACT\nComputer vision has benefited from initializing multiple deep layers with weights pretrained on large supervised training sets like ImageNet. Natural language processing (NLP) typically sees initialization of only the lowest layer of deep models with pretrained word vectors. In this paper, we use a deep LSTM encoder from an attentional sequence-to-sequence model trained for machine translation (MT) to contextualize word vectors. We show that adding these context vectors (CoVe) improves performance over using only unsupervised word and character vectors on a wide variety of common NLP tasks: sentiment analysis (SST, IMDb), question classification (TREC), entailment (SNLI), and question answering (SQuAD). For fine-grained sentiment analysis and entailment, CoVe improves performance of our baseline models to the state of the art.\nECNU at SemEval-2017 Task 1: Leverage Kernel-based Traditional NLP features and Neural Networks to Build a Universal Model for Multilingual and Cross-lingual Semantic Textual Similarity (Junfeng Tian et al., 2017) Junfeng Tian, Zhi-Min Zhou, Man Lan, Yuanbin Wu. (2017)\nECNU at SemEval-2017 Task 1: Leverage Kernel-based Traditional NLP features and Neural Networks to Build a Universal Model for Multilingual and Cross-lingual Semantic Textual Similarity\nSemEval@ACL\nPaper Link\nInfluential Citation Count (9), SS-ID (caa8a41d58e386c56f56d46bbe79df9cb1087338)\nABSTRACT\nTo address semantic similarity on multilingual and cross-lingual sentences, we firstly translate other foreign languages into English, and then feed our monolingual English system with various interactive features. Our system is further supported by combining with deep learning semantic similarity and our best run achieves the mean Pearson correlation 73.16% in primary track.\nSciTaiL: A Textual Entailment Dataset from Science Question Answering (Tushar Khot et al., 2018) Tushar Khot, Ashish Sabharwal, Peter Clark. (2018)\nSciTaiL: A Textual Entailment Dataset from Science Question Answering\nAAAI\nPaper Link\nInfluential Citation Count (75), SS-ID (cf8c493079702ec420ab4fc9c0fabb56b2a16c84)\nABSTRACT\nWe present a new dataset and model for textual entailment, derived from treating multiple-choice question-answering as an entailment problem. SCITAIL is the first entailment set that is created solely from natural sentences that already exist independently “in the wild” rather than sentences authored specifically for the entailment task. Different from existing entailment datasets, we create hypotheses from science questions and the corresponding answer candidates, and premises from relevant web sentences retrieved from a large corpus. These sentences are often linguistically challenging. This, combined with the high lexical similarity of premise and hypothesis for both entailed and non-entailed pairs, makes this new entailment task particularly difficult. The resulting challenge is evidenced by state-of-the-art textual entailment systems achieving mediocre performance on SCITAIL, especially in comparison to a simple majority class baseline. As a step forward, we demonstrate that one can improve accuracy on SCITAIL by 5% using a new neural model that exploits linguistic structure.\nTeaching Machines to Read and Comprehend (K. Hermann et al., 2015) K. Hermann, Tomás Kociský, Edward Grefenstette, Lasse Espeholt, Will Kay, Mustafa Suleyman, P. Blunsom. (2015)\nTeaching Machines to Read and Comprehend\nNIPS\nPaper Link\nInfluential Citation Count (399), SS-ID (d1505c6123c102e53eb19dff312cb25cea840b72)\nABSTRACT\nTeaching machines to read natural language documents remains an elusive challenge. Machine reading systems can be tested on their ability to answer questions posed on the contents of documents that they have seen, but until now large scale training and test datasets have been missing for this type of evaluation. In this work we define a new methodology that resolves this bottleneck and provides large scale supervised reading comprehension data. This allows us to develop a class of attention based deep neural networks that learn to read real documents and answer complex questions with minimal prior knowledge of language structure.\nSemi-Supervised Conditional Random Fields for Improved Sequence Segmentation and Labeling (Feng Jiao et al., 2006) Feng Jiao, Shaojun Wang, Chi-Hoon Lee, R. Greiner, Dale Schuurmans. (2006)\nSemi-Supervised Conditional Random Fields for Improved Sequence Segmentation and Labeling\nACL\nPaper Link\nInfluential Citation Count (21), SS-ID (d5f5110d65eda0d2df7329582a232a86bf9a3a65)\nABSTRACT\nWe present a new semi-supervised training procedure for conditional random fields (CRFs) that can be used to train sequence segmentors and labelers from a combination of labeled and unlabeled training data. Our approach is based on extending the minimum entropy regularization framework to the structured prediction case, yielding a training objective that combines unlabeled conditional entropy with labeled conditional likelihood. Although the training objective is no longer concave, it can still be used to improve an initial model (e.g. obtained from supervised training) by iterative ascent. We apply our new training algorithm to the problem of identifying gene and protein mentions in biological texts, and show that incorporating unlabeled data improves the performance of the supervised CRF in this case.\nMulti-range Reasoning for Machine Comprehension (Yi Tay et al., 2018) Yi Tay, Anh Tuan Luu, S. C. Hui. (2018)\nMulti-range Reasoning for Machine Comprehension\nArXiv\nPaper Link\nInfluential Citation Count (4), SS-ID (d66ad3628c11c45bde5d4b65b9c1109a95d364d4)\nABSTRACT\nWe propose MRU (Multi-Range Reasoning Units), a new fast compositional encoder for machine comprehension (MC). Our proposed MRU encoders are characterized by multi-ranged gating, executing a series of parameterized contract-and-expand layers for learning gating vectors that benefit from long and short-term dependencies. The aims of our approach are as follows: (1) learning representations that are concurrently aware of long and short-term context, (2) modeling relationships between intra-document blocks and (3) fast and efficient sequence encoding. We show that our proposed encoder demonstrates promising results both as a standalone encoder and as well as a complementary building block. We conduct extensive experiments on three challenging MC datasets, namely RACE, SearchQA and NarrativeQA, achieving highly competitive performance on all. On the RACE benchmark, our model outperforms DFN (Dynamic Fusion Networks) by 1.5%-6% without using any recurrent or convolution layers. Similarly, we achieve competitive performance relative to AMANDA on the SearchQA benchmark and BiDAF on the NarrativeQA benchmark without using any LSTM/GRU layers. Finally, incorporating MRU encoders with standard BiLSTM architectures further improves performance, achieving state-of-the-art results.\nThe Sixth PASCAL Recognizing Textual Entailment Challenge (L. Bentivogli et al., 2009) L. Bentivogli, Peter Clark, Ido Dagan, Danilo Giampiccolo. (2009)\nThe Sixth PASCAL Recognizing Textual Entailment Challenge\nTAC\nPaper Link\nInfluential Citation Count (83), SS-ID (db8885a0037fe47d973ade79d696586453710233)\nABSTRACT\nThis paper presents the Sixth Recognizing Textual Entailment (RTE-6) challenge. This year a major innovation was introduced, as the traditional Main Task was replaced by a new task, similar to the RTE-5 Search Pilot, in which Textual Entailment is performed on a real corpus in the Update Summarization scenario. A subtask was also proposed, aimed at detecting novel information. To continue the effort of testing RTE in NLP applications, a KBP Validation Pilot Task was set up, in which RTE systems had to validate the output of systems participating in the KBP Slot Filling Task. Eighteen teams participated in the Main Task (48 submitted runs) and 9 in the Novelty Detection Subtask (22 submitted runs). As for the Pilot, 10 runs were submitted by 3 participants. Finally, the exploratory effort started in RTE-5 to perform resource evaluation through ablation tests was not only reiterated in RTE-6, but also extended to tools.\nUnsupervised Machine Translation Using Monolingual Corpora Only (Guillaume Lample et al., 2017) Guillaume Lample, Ludovic Denoyer, Marc\u0026rsquo;Aurelio Ranzato. (2017)\nUnsupervised Machine Translation Using Monolingual Corpora Only\nICLR\nPaper Link\nInfluential Citation Count (141), SS-ID (e3d772986d176057aca2f5e3eb783da53b559134)\nABSTRACT\nMachine translation has recently achieved impressive performance thanks to recent advances in deep learning and the availability of large-scale parallel corpora. There have been numerous attempts to extend these successes to low-resource language pairs, yet requiring tens of thousands of parallel sentences. In this work, we take this research direction to the extreme and investigate whether it is possible to learn to translate even without any parallel data. We propose a model that takes sentences from monolingual corpora in two different languages and maps them into the same latent space. By learning to reconstruct in both languages from this shared feature space, the model effectively learns to translate without using any labeled data. We demonstrate our model on two widely used datasets and two language pairs, reporting BLEU scores of 32.8 and 15.1 on the Multi30k and WMT English-French datasets, without using even a single parallel sentence at training time.\nRoles of Pre-Training and Fine-Tuning in Context-Dependent DBN-HMMs for Real-World Speech Recognition (Dong Yu et al., 2010) Dong Yu, L. Deng, George E. Dahl. (2010)\nRoles of Pre-Training and Fine-Tuning in Context-Dependent DBN-HMMs for Real-World Speech Recognition\nPaper Link\nInfluential Citation Count (3), SS-ID (ecd4bc32bb2717c96f76dd100fcd1255a07bd656)\nABSTRACT\nRecently, deep learning techniques have been successfully applied to automatic speech recognition tasks -first to phonetic recognition with context-independent deep belief network (DBN) hidden Markov models (HMMs) and later to large vocabulary continuous speech recognition using context-dependent (CD) DBN-HMMs. In this paper, we report our most recent experiments designed to understand the roles of the two main phases of the DBN learning -pre-training and fine tuning -in the recognition performance of a CD-DBN-HMM based large-vocabulary speech recognizer. As expected, we show that pre-training can initialize weights to a point in the space where fine-tuning can be effective and thus is crucial in training deep structured models. However, a moderate increase of the amount of unlabeled pre-training data has an insignificant effect on the final recognition results as long as the original training size is sufficiently large to initialize the DBN weights. On the other hand, with additional labeled training data, the fine-tuning phase of DBN training can significantly improve the recognition accuracy.\nSupervised Learning of Universal Sentence Representations from Natural Language Inference Data (A. Conneau et al., 2017) A. Conneau, Douwe Kiela, Holger Schwenk, Loïc Barrault, Antoine Bordes. (2017)\nSupervised Learning of Universal Sentence Representations from Natural Language Inference Data\nEMNLP\nPaper Link\nInfluential Citation Count (319), SS-ID (ee7b883e35d754ae4f71c21bb71f9f03e4ffbb2c)\nABSTRACT\nMany modern NLP systems rely on word embeddings, previously trained in an unsupervised manner on large corpora, as base features. Efforts to obtain embeddings for larger chunks of text, such as sentences, have however not been so successful. Several attempts at learning unsupervised representations of sentences have not reached satisfactory enough performance to be widely adopted. In this paper, we show how universal sentence representations trained using the supervised data of the Stanford Natural Language Inference datasets can consistently outperform unsupervised methods like SkipThought vectors on a wide range of transfer tasks. Much like how computer vision uses ImageNet to obtain features, which can then be transferred to other tasks, our work tends to indicate the suitability of natural language inference for transfer learning to other NLP tasks. Our encoder is publicly available.\nA large annotated corpus for learning natural language inference (Samuel R. Bowman et al., 2015) Samuel R. Bowman, Gabor Angeli, Christopher Potts, Christopher D. Manning. (2015)\nA large annotated corpus for learning natural language inference\nEMNLP\nPaper Link\nInfluential Citation Count (665), SS-ID (f04df4e20a18358ea2f689b4c129781628ef7fc1)\nABSTRACT\nUnderstanding entailment and contradiction is fundamental to understanding natural language, and inference about entailment and contradiction is a valuable testing ground for the development of semantic representations. However, machine learning research in this area has been dramatically limited by the lack of large-scale resources. To address this, we introduce the Stanford Natural Language Inference corpus, a new, freely available collection of labeled sentence pairs, written by humans doing a novel grounded task based on image captioning. At 570K pairs, it is two orders of magnitude larger than all other resources of its type. This increase in scale allows lexicalized classifiers to outperform some sophisticated existing entailment models, and it allows a neural network-based model to perform competitively on natural language inference benchmarks for the first time.\nA Compare-Propagate Architecture with Alignment Factorization for Natural Language Inference (Yi Tay et al., 2017) Yi Tay, Anh Tuan Luu, S. C. Hui. (2017)\nA Compare-Propagate Architecture with Alignment Factorization for Natural Language Inference\nArXiv\nPaper Link\nInfluential Citation Count (5), SS-ID (f14dc3dba4a58fd380cce41e44552fd5f7812a4c)\nABSTRACT\nThis paper presents a new deep learning architecture for Natural Language Inference (NLI). Firstly, we introduce a new compare-propagate architecture where alignments pairs are compared and then propagated to upper layers for enhanced representation learning. Secondly, we adopt novel factorization layers for efficient compression of alignment vectors into scalar valued features, which are then be used to augment the base word representations. The design of our approach is aimed to be conceptually simple, compact and yet powerful. We conduct experiments on three popular benchmarks, SNLI, MultiNLI and SciTail, achieving state-of-the-art performance on all. A lightweight parameterization of our model enjoys a $\\approx 300%$ reduction in parameter size compared to the ESIM and DIIN, while maintaining competitive performance. Visual analysis shows that our propagated features are highly interpretable, opening new avenues to explainability in neural NLI models.\nGloVe: Global Vectors for Word Representation (Jeffrey Pennington et al., 2014) Jeffrey Pennington, R. Socher, Christopher D. Manning. (2014)\nGloVe: Global Vectors for Word Representation\nEMNLP\nPaper Link\nInfluential Citation Count (3515), SS-ID (f37e1b62a767a307c046404ca96bc140b3e68cb5)\nABSTRACT\nRecent methods for learning vector space representations of words have succeeded in capturing fine-grained semantic and syntactic regularities using vector arithmetic, but the origin of these regularities has remained opaque. We analyze and make explicit the model properties needed for such regularities to emerge in word vectors. The result is a new global logbilinear regression model that combines the advantages of the two major model families in the literature: global matrix factorization and local context window methods. Our model efficiently leverages statistical information by training only on the nonzero elements in a word-word cooccurrence matrix, rather than on the entire sparse matrix or on individual context windows in a large corpus. The model produces a vector space with meaningful substructure, as evidenced by its performance of 75% on a recent word analogy task. It also outperforms related models on similarity tasks and named entity recognition.\nDistributed Representations of Sentences and Documents (Quoc V. Le et al., 2014) Quoc V. Le, Tomas Mikolov. (2014)\nDistributed Representations of Sentences and Documents\nICML\nPaper Link\nInfluential Citation Count (964), SS-ID (f527bcfb09f32e6a4a8afc0b37504941c1ba2cee)\nABSTRACT\nMany machine learning algorithms require the input to be represented as a fixed-length feature vector. When it comes to texts, one of the most common fixed-length features is bag-of-words. Despite their popularity, bag-of-words features have two major weaknesses: they lose the ordering of the words and they also ignore semantics of the words. For example, \u0026ldquo;powerful,\u0026rdquo; \u0026ldquo;strong\u0026rdquo; and \u0026ldquo;Paris\u0026rdquo; are equally distant. In this paper, we propose Paragraph Vector, an unsupervised algorithm that learns fixed-length feature representations from variable-length pieces of texts, such as sentences, paragraphs, and documents. Our algorithm represents each document by a dense vector which is trained to predict words in the document. Its construction gives our algorithm the potential to overcome the weaknesses of bag-of-words models. Empirical results show that Paragraph Vectors outperforms bag-of-words models as well as other techniques for text representations. Finally, we achieve new state-of-the-art results on several text classification and sentiment analysis tasks.\n","date":"May 25, 2022","hero":"/blog-akitenkrad/posts/papers/202205/20220525115521/hero.png","permalink":"https://akitenkrad.github.io/blog-akitenkrad/posts/papers/202205/20220525115521/","summary":"Round-1: Overview Round-2: Model Implementation Details Round-3: Experiments Citation Abstract What\u0026rsquo;s New Dataset Model Description Training Settings Results References Semi-Supervised Text Classification Using EM (O. Chapelle et al., 2006) O. Chapelle, Bernhard SchÃ¶lkopf, A. Zien. (2006)\nSemi-Supervised Text Classification Using EM\nPaper Link\nInfluential Citation Count (2), SS-ID (03bafef700d35112a9926dd1b2be91a4aa6984a4)\nABSTRACT\nThis chapter contains sections titled: Introduction, A Generative Model for Text, Experimental Results with Basic EM, Using a More Expressive Generative Model, Overcoming the Challenges of Local Maxima, Conclusions and Summary","tags":["At:Round-1","Published:2006"],"title":"Improving Language Understanding by Generative Pre-Training"},{"categories":null,"contents":" Round-1: Overview Round-2: Model Implementation Details Round-3: Experiments Citation Liu, Y., Ott, M., Goyal, N., Du, J., Joshi, M., Chen, D., Levy, O., Lewis, M., Zettlemoyer, L., \u0026amp; Stoyanov, V. (2019).\nRoBERTa: A Robustly Optimized BERT Pretraining Approach.\nhttps://doi.org/10.48550/arxiv.1907.11692 Abstract Language model pretraining has led to significant performance gains but careful comparison between different approaches is challenging. Training is computationally expensive, often done on private datasets of different sizes, and, as we will show, hyperparameter choices have significant impact on the final results. We present a replication study of BERT pretraining (Devlin et al., 2019) that carefully measures the impact of many key hyperparameters and training data size. We find that BERT was significantly undertrained, and can match or exceed the performance of every model published after it. Our best model achieves state-of-the-art results on GLUE, RACE and SQuAD. These results highlight the importance of previously overlooked design choices, and raise questions about the source of recently reported improvements. We release our models and code.\nWhat\u0026rsquo;s New BERTの学習設定を精査し，最も精度が向上する設定方針を提案 Dynamic Masking 事前学習のMasked Language Modelingにおいて，同じマスクを使い回すのではなく，エポックごとに動的に単語をマスキングすると精度が向上する Input Full-Sentence \u0026amp; Exclude NSP オリジナルのBERTでは入力文章がセグメント単位でコンテキストが短いため，セグメント単位ではなくドキュメント内の文章全体をインプットとした方が精度が向上する 事前学習のNext Sentence Prediction (NSP)は除外した方が精度が向上する Training with large batches 学習時のステップ数とバッチサイズを変更した場合のモデルの精度の変動を検証し，バッチサイズを大きくした方が精度が向上する Byte-Pair Encoding トークンのエンコーディング方式に Byte-Pair Encoding (BPE) を採用（言語モデルにはBPEが適していると考えられるが，精度は向上していない） モデルの学習にあたって，新しいデータセットである CC-News を導入 Dataset For Training BookCorpus (Zhu et al., 2015) Yukun Zhu, Ryan Kiros, R. Zemel, R. Salakhutdinov, R. Urtasun, A. Torralba, S. Fidler. (2015)\nAligning Books and Movies: Towards Story-Like Visual Explanations by Watching Movies and Reading Books\n2015 IEEE International Conference on Computer Vision (ICCV)\nPaper Link\nInfluential Citation Count (172), SS-ID (0e6824e137847be0599bb0032e37042ed2ef5045)\nABSTRACT\nBooks are a rich source of both fine-grained information, how a character, an object or a scene looks like, as well as high-level semantics, what someone is thinking, feeling and how these states evolve through a story. This paper aims to align books to their movie releases in order to provide rich descriptive explanations for visual content that go semantically far beyond the captions available in the current datasets. To align movies and books we propose a neural sentence embedding that is trained in an unsupervised way from a large corpus of books, as well as a video-text neural embedding for computing similarities between movie clips and sentences in the book. We propose a context-aware CNN to combine information from multiple sources. We demonstrate good quantitative performance for movie/book alignment and show several qualitative examples that showcase the diversity of tasks our model can be used for.\nCC-News (original dataset collected from CommonCrawl News Dataset (Nagel, 2016)) Sebastian Nagel. (2016)\nCc-news\nhttp://web.archive.org/save/http://commoncrawl.org/2016/10/news-dataset-available OpenWebText (Gokaslan and Cohen, 2019) Aaron Gokaslan and Vanya Cohen. (2019)\nOpenweb-text corpus\nhttp://web.archive.org/save/http://Skylion007.github.io/OpenWebTextCorpus Stories (Trinh and Le, 2018) Trieu H. Trinh, Quoc V. Le. (2018)\nA Simple Method for Commonsense Reasoning\nArXiv\nPaper Link\nInfluential Citation Count (16), SS-ID (d7b6753a2d4a2b286c396854063bde3a91b75535)\nABSTRACT\nCommonsense reasoning is a long-standing challenge for deep learning. For example, it is difficult to use neural networks to tackle the Winograd Schema dataset (Levesque et al., 2011). In this paper, we present a simple method for commonsense reasoning with neural networks, using unsupervised learning. Key to our method is the use of language models, trained on a massive amount of unlabled data, to score multiple choice questions posed by commonsense reasoning tests. On both Pronoun Disambiguation and Winograd Schema challenges, our models outperform previous state-of-the-art methods by a large margin, without using expensive annotated knowledge bases or hand-engineered features. We train an array of large RNN language models that operate at word or character level on LM-1-Billion, CommonCrawl, SQuAD, Gutenberg Books, and a customized corpus for this task and show that diversity of training data plays an important role in test performance. Further analysis also shows that our system successfully discovers important features of the context that decide the correct answer, indicating a good grasp of commonsense knowledge.\nFor Evaluation GLUE (Wang et al., 2018) Alex Wang, Amanpreet Singh, Julian Michael, Felix Hill, Omer Levy, Samuel R. Bowman. (2018)\nGLUE: A Multi-Task Benchmark and Analysis Platform for Natural Language Understanding\nBlackboxNLP@EMNLP\nPaper Link\nInfluential Citation Count (659), SS-ID (93b8da28d006415866bf48f9a6e06b5242129195)\nABSTRACT\nHuman ability to understand language is general, flexible, and robust. In contrast, most NLU models above the word level are designed for a specific task and struggle with out-of-domain data. If we aspire to develop models with understanding beyond the detection of superficial correspondences between inputs and outputs, then it is critical to develop a unified model that can execute a range of linguistic tasks across different domains. To facilitate research in this direction, we present the General Language Understanding Evaluation (GLUE, gluebenchmark.com): a benchmark of nine diverse NLU tasks, an auxiliary dataset for probing models for understanding of specific linguistic phenomena, and an online platform for evaluating and comparing models. For some benchmark tasks, training data is plentiful, but for others it is limited or does not match the genre of the test set. GLUE thus favors models that can represent linguistic knowledge in a way that facilitates sample-efficient learning and effective knowledge-transfer across tasks. While none of the datasets in GLUE were created from scratch for the benchmark, four of them feature privately-held test data, which is used to ensure that the benchmark is used fairly. We evaluate baselines that use ELMo (Peters et al., 2018), a powerful transfer learning technique, as well as state-of-the-art sentence representation models. The best models still achieve fairly low absolute scores. Analysis with our diagnostic dataset yields similarly weak performance over all phenomena tested, with some exceptions.\nSQuAD v1.1 (Rajpurkar et al., 2016) Pranav Rajpurkar, Jian Zhang, Konstantin Lopyrev, Percy Liang. (2016)\nSQuAD: 100,000+ Questions for Machine Comprehension of Text\nEMNLP\nPaper Link\nInfluential Citation Count (1089), SS-ID (05dd7254b632376973f3a1b4d39485da17814df5)\nABSTRACT\nWe present the Stanford Question Answering Dataset (SQuAD), a new reading comprehension dataset consisting of 100,000+ questions posed by crowdworkers on a set of Wikipedia articles, where the answer to each question is a segment of text from the corresponding reading passage. We analyze the dataset to understand the types of reasoning required to answer the questions, leaning heavily on dependency and constituency trees. We build a strong logistic regression model, which achieves an F1 score of 51.0%, a significant improvement over a simple baseline (20%). However, human performance (86.8%) is much higher, indicating that the dataset presents a good challenge problem for future research. The dataset is freely available at this https URL\nSQuAD v2.0 (Rajpurkar et al., 2018) Pranav Rajpurkar, Robin Jia, Percy Liang. (2018)\nKnow What You Don’t Know: Unanswerable Questions for SQuAD\nACL\nPaper Link\nInfluential Citation Count (348), SS-ID (4d1c856275744c0284312a3a50efb6ca9dc4cd4c)\nABSTRACT\nExtractive reading comprehension systems can often locate the correct answer to a question in a context document, but they also tend to make unreliable guesses on questions for which the correct answer is not stated in the context. Existing datasets either focus exclusively on answerable questions, or use automatically generated unanswerable questions that are easy to identify. To address these weaknesses, we present SQuADRUn, a new dataset that combines the existing Stanford Question Answering Dataset (SQuAD) with over 50,000 unanswerable questions written adversarially by crowdworkers to look similar to answerable ones. To do well on SQuADRUn, systems must not only answer questions when possible, but also determine when no answer is supported by the paragraph and abstain from answering. SQuADRUn is a challenging natural language understanding task for existing models: a strong neural system that gets 86% F1 on SQuAD achieves only 66% F1 on SQuADRUn. We release SQuADRUn to the community as the successor to SQuAD.\nRACE (Lai et al., 2017) Guokun Lai, Qizhe Xie, Hanxiao Liu, Yiming Yang, E. Hovy. (2017)\nRACE: Large-scale ReAding Comprehension Dataset From Examinations\nEMNLP\nPaper Link\nInfluential Citation Count (183), SS-ID (636a79420d838eabe4af7fb25d6437de45ab64e8)\nABSTRACT\nWe present RACE, a new dataset for benchmark evaluation of methods in the reading comprehension task. Collected from the English exams for middle and high school Chinese students in the age range between 12 to 18, RACE consists of near 28,000 passages and near 100,000 questions generated by human experts (English instructors), and covers a variety of topics which are carefully designed for evaluating the students’ ability in understanding and reasoning. In particular, the proportion of questions that requires reasoning is much larger in RACE than that in other benchmark datasets for reading comprehension, and there is a significant gap between the performance of the state-of-the-art models (43%) and the ceiling human performance (95%). We hope this new dataset can serve as a valuable resource for research and evaluation in machine comprehension. The dataset is freely available at http://www.cs.cmu.edu/~glai1/data/race/ and the code is available at https://github.com/qizhex/RACE_AR_baselines.\nModel Description Training Settings Results Static vs. Dynamic Masking Static MaskingとDynamic Maskingの比較結果． Dynamic Maskingの方が精度が若干良い． Model Input Format and NSP モデルの入力フォーマットをSegment，Sentence-Pair，Full-Sentences，Doc-Sentencesで比較． 入力とする文章は一つのドキュメントから文全体を取り出してモデルに投入した方が精度が向上する． セグメント単位で投入するよりも広い範囲のコンテキストを扱うことができるためではないかと考えられる． NSPについては様々な議論があり，オリジナルのBERTではNSPを導入した方が精度が良くなるとされている一方で，NSPタスクを疑問視する研究もある．この論文では事前学習のNSPタスクは除外した方が，エンドタスクの精度が向上したとのこと． Training with Large Batches 同じサイズのデータを投入する場合に，バッチサイズを大きくしてステップ数を減らした方がエンドタスクの精度が向上する Evaluation of RoBERTa References ERNIE: Enhanced Representation through Knowledge Integration (Yu Sun et al., 2019) Yu Sun, Shuohuan Wang, Yukun Li, Shikun Feng, Xuyi Chen, Han Zhang, Xin Tian, Danxiang Zhu, Hao Tian, Hua Wu. (2019)\nERNIE: Enhanced Representation through Knowledge Integration\nArXiv\nPaper Link\nInfluential Citation Count (65), SS-ID (031e4e43aaffd7a479738dcea69a2d5be7957aa3)\nABSTRACT\nWe present a novel language representation model enhanced by knowledge called ERNIE (Enhanced Representation through kNowledge IntEgration). Inspired by the masking strategy of BERT, ERNIE is designed to learn language representation enhanced by knowledge masking strategies, which includes entity-level masking and phrase-level masking. Entity-level strategy masks entities which are usually composed of multiple words.Phrase-level strategy masks the whole phrase which is composed of several words standing together as a conceptual unit.Experimental results show that ERNIE outperforms other baseline methods, achieving new state-of-the-art results on five Chinese natural language processing tasks including natural language inference, semantic similarity, named entity recognition, sentiment analysis and question answering. We also demonstrate that ERNIE has more powerful knowledge inference capacity on a cloze test.\nSQuAD: 100,000\u0026#43; Questions for Machine Comprehension of Text (Pranav Rajpurkar et al., 2016) Pranav Rajpurkar, Jian Zhang, Konstantin Lopyrev, Percy Liang. (2016)\nSQuAD: 100,000+ Questions for Machine Comprehension of Text\nEMNLP\nPaper Link\nInfluential Citation Count (1089), SS-ID (05dd7254b632376973f3a1b4d39485da17814df5)\nABSTRACT\nWe present the Stanford Question Answering Dataset (SQuAD), a new reading comprehension dataset consisting of 100,000+ questions posed by crowdworkers on a set of Wikipedia articles, where the answer to each question is a segment of text from the corresponding reading passage. We analyze the dataset to understand the types of reasoning required to answer the questions, leaning heavily on dependency and constituency trees. We build a strong logistic regression model, which achieves an F1 score of 51.0%, a significant improvement over a simple baseline (20%). However, human performance (86.8%) is much higher, indicating that the dataset presents a good challenge problem for future research. The dataset is freely available at this https URL\nAligning Books and Movies: Towards Story-Like Visual Explanations by Watching Movies and Reading Books (Yukun Zhu et al., 2015) Yukun Zhu, Ryan Kiros, R. Zemel, R. Salakhutdinov, R. Urtasun, A. Torralba, S. Fidler. (2015)\nAligning Books and Movies: Towards Story-Like Visual Explanations by Watching Movies and Reading Books\n2015 IEEE International Conference on Computer Vision (ICCV)\nPaper Link\nInfluential Citation Count (172), SS-ID (0e6824e137847be0599bb0032e37042ed2ef5045)\nABSTRACT\nBooks are a rich source of both fine-grained information, how a character, an object or a scene looks like, as well as high-level semantics, what someone is thinking, feeling and how these states evolve through a story. This paper aims to align books to their movie releases in order to provide rich descriptive explanations for visual content that go semantically far beyond the captions available in the current datasets. To align movies and books we propose a neural sentence embedding that is trained in an unsupervised way from a large corpus of books, as well as a video-text neural embedding for computing similarities between movie clips and sentences in the book. We propose a context-aware CNN to combine information from multiple sources. We demonstrate good quantitative performance for movie/book alignment and show several qualitative examples that showcase the diversity of tasks our model can be used for.\nThe Seventh PASCAL Recognizing Textual Entailment Challenge (L. Bentivogli et al., 2011) L. Bentivogli, Peter Clark, Ido Dagan, Danilo Giampiccolo. (2011)\nThe Seventh PASCAL Recognizing Textual Entailment Challenge\nTAC\nPaper Link\nInfluential Citation Count (16), SS-ID (0f8468de03ee9f12d693237bec87916311bf1c24)\nABSTRACT\nThis paper presents the Seventh Recognizing Textual Entailment (RTE-7) challenge. This year’s challenge replicated the exercise proposed in RTE-6, consisting of a Main Task, in which Textual Entailment is performed on a real corpus in the Update Summarization scenario; a Main subtask aimed at detecting novel information; and a KBP Validation Task, in which RTE systems had to validate the output of systems participating in the KBP Slot Filling Task. Thirteen teams participated in the Main Task (submitting 33 runs) and 5 in the Novelty Detection Subtask (submitting 13 runs). The KBP Validation Task was undertaken by 2 participants which submitted 5 runs. The ablation test experiment, introduced in RTE-5 to evaluate the impact of knowledge resources used by the systems participating in the Main Task and extended also to tools in RTE-6, was also repeated in RTE-7.\nThe Winograd Schema Challenge (H. Levesque et al., 2011) H. Levesque, E. Davis, L. Morgenstern. (2011)\nThe Winograd Schema Challenge\nKR\nPaper Link\nInfluential Citation Count (150), SS-ID (128cb6b891aee1b5df099acb48e2efecfcff689f)\nABSTRACT\nIn this paper, we present an alternative to the Turing Test that has some conceptual and practical advantages. Like the original, it involves responding to typed English sentences, and English-speaking adults will have no difficulty with it. Unlike the original, the subject is not required to engage in a conversation and fool an interrogator into believing she is dealing with a person. Moreover, the test is arranged in such a way that having full access to a large corpus of English text might not help much. Finally, the interrogator or a third party will be able to decide unambiguously after a few minutes whether or not a subject has passed the test.\nKERMIT: Generative Insertion-Based Modeling for Sequences (William Chan et al., 2019) William Chan, Nikita Kitaev, Kelvin Guu, Mitchell Stern, Jakob Uszkoreit. (2019)\nKERMIT: Generative Insertion-Based Modeling for Sequences\nArXiv\nPaper Link\nInfluential Citation Count (4), SS-ID (130277ff64c7171c90d98d7e73f4bda8a0b0c1f9)\nABSTRACT\nWe present KERMIT, a simple insertion-based approach to generative modeling for sequences and sequence pairs. KERMIT models the joint distribution and its decompositions (i.e., marginals and conditionals) using a single neural network and, unlike much prior work, does not rely on a prespecified factorization of the data distribution. During training, one can feed KERMIT paired data $(x, y)$ to learn the joint distribution $p(x, y)$, and optionally mix in unpaired data $x$ or $y$ to refine the marginals $p(x)$ or $p(y)$. During inference, we have access to the conditionals $p(x \\mid y)$ and $p(y \\mid x)$ in both directions. We can also sample from the joint distribution or the marginals. The model supports both serial fully autoregressive decoding and parallel partially autoregressive decoding, with the latter exhibiting an empirically logarithmic runtime. We demonstrate through experiments in machine translation, representation learning, and zero-shot cloze question answering that our unified approach is capable of matching or exceeding the performance of dedicated state-of-the-art systems across a wide range of tasks without the need for problem-specific architectural adaptation.\nThe Second PASCAL Recognising Textual Entailment Challenge (Roy Bar-Haim et al., 2006) Roy Bar-Haim, Ido Dagan, Bill Dolan, L. Ferro, Danilo Giampiccolo, B. Magnini. (2006)\nThe Second PASCAL Recognising Textual Entailment Challenge\nPaper Link\nInfluential Citation Count (51), SS-ID (136326377c122560768db674e35f5bcd6de3bc40)\nABSTRACT\nThis paper describes the Second PASCAL Recognising Textual Entailment Challenge (RTE-2). 1 We describe the RTE2 dataset and overview the submissions for the challenge. One of the main goals for this year’s dataset was to provide more “realistic” text-hypothesis examples, based mostly on outputs of actual systems. The 23 submissions for the challenge present diverse approaches and research directions, and the best results achieved this year are considerably higher than last year’s state of the art.\nMASS: Masked Sequence to Sequence Pre-training for Language Generation (Kaitao Song et al., 2019) Kaitao Song, Xu Tan, Tao Qin, Jianfeng Lu, Tie-Yan Liu. (2019)\nMASS: Masked Sequence to Sequence Pre-training for Language Generation\nICML\nPaper Link\nInfluential Citation Count (108), SS-ID (145b8b5d99a2beba6029418ca043585b90138d12)\nABSTRACT\nPre-training and fine-tuning, e.g., BERT, have achieved great success in language understanding by transferring knowledge from rich-resource pre-training task to the low/zero-resource downstream tasks. Inspired by the success of BERT, we propose MAsked Sequence to Sequence pre-training (MASS) for the encoder-decoder based language generation tasks. MASS adopts the encoder-decoder framework to reconstruct a sentence fragment given the remaining part of the sentence: its encoder takes a sentence with randomly masked fragment (several consecutive tokens) as input, and its decoder tries to predict this masked fragment. In this way, MASS can jointly train the encoder and decoder to develop the capability of representation extraction and language modeling. By further fine-tuning on a variety of zero/low-resource language generation tasks, including neural machine translation, text summarization and conversational response generation (3 tasks and totally 8 datasets), MASS achieves significant improvements over the baselines without pre-training or with other pre-training methods. Specially, we achieve the state-of-the-art accuracy (37.5 in terms of BLEU score) on the unsupervised English-French translation, even beating the early attention-based supervised model.\nGaussian Error Linear Units (GELUs) (Dan Hendrycks et al., 2016) Dan Hendrycks, Kevin Gimpel. (2016)\nGaussian Error Linear Units (GELUs)\nPaper Link\nInfluential Citation Count (117), SS-ID (15f4c35889ccc1ae258b680c2ca2fcbfe1e260f7)\nABSTRACT\nWe propose the Gaussian Error Linear Unit (GELU), a high-performing neural network activation function. The GELU activation function is $x\\Phi(x)$, where $\\Phi(x)$ the standard Gaussian cumulative distribution function. The GELU nonlinearity weights inputs by their value, rather than gates inputs by their sign as in ReLUs ($x\\mathbf{1}_{x\u0026gt;0}$). We perform an empirical evaluation of the GELU nonlinearity against the ReLU and ELU activations and find performance improvements across all considered computer vision, natural language processing, and speech tasks.\nNeural Machine Translation of Rare Words with Subword Units (Rico Sennrich et al., 2015) Rico Sennrich, B. Haddow, Alexandra Birch. (2015)\nNeural Machine Translation of Rare Words with Subword Units\nACL\nPaper Link\nInfluential Citation Count (834), SS-ID (1af68821518f03568f913ab03fc02080247a27ff)\nABSTRACT\nNeural machine translation (NMT) models typically operate with a fixed vocabulary, but translation is an open-vocabulary problem. Previous work addresses the translation of out-of-vocabulary words by backing off to a dictionary. In this paper, we introduce a simpler and more effective approach, making the NMT model capable of open-vocabulary translation by encoding rare and unknown words as sequences of subword units. This is based on the intuition that various word classes are translatable via smaller units than words, for instance names (via character copying or transliteration), compounds (via compositional translation), and cognates and loanwords (via phonological and morphological transformations). We discuss the suitability of different word segmentation techniques, including simple character n-gram models and a segmentation based on the byte pair encoding compression algorithm, and empirically show that subword models improve over a back-off dictionary baseline for the WMT 15 translation tasks English-German and English-Russian by 1.1 and 1.3 BLEU, respectively.\nUnified Language Model Pre-training for Natural Language Understanding and Generation (Li Dong et al., 2019) Li Dong, Nan Yang, Wenhui Wang, Furu Wei, Xiaodong Liu, Yu Wang, Jianfeng Gao, M. Zhou, H. Hon. (2019)\nUnified Language Model Pre-training for Natural Language Understanding and Generation\nNeurIPS\nPaper Link\nInfluential Citation Count (107), SS-ID (1c71771c701aadfd72c5866170a9f5d71464bb88)\nABSTRACT\nThis paper presents a new Unified pre-trained Language Model (UniLM) that can be fine-tuned for both natural language understanding and generation tasks. The model is pre-trained using three types of language modeling tasks: unidirectional, bidirectional, and sequence-to-sequence prediction. The unified modeling is achieved by employing a shared Transformer network and utilizing specific self-attention masks to control what context the prediction conditions on. UniLM compares favorably with BERT on the GLUE benchmark, and the SQuAD 2.0 and CoQA question answering tasks. Moreover, UniLM achieves new state-of-the-art results on five natural language generation datasets, including improving the CNN/DailyMail abstractive summarization ROUGE-L to 40.51 (2.04 absolute improvement), the Gigaword abstractive summarization ROUGE-L to 35.75 (0.86 absolute improvement), the CoQA generative question answering F1 score to 82.5 (37.1 absolute improvement), the SQuAD question generation BLEU-4 to 22.12 (3.75 absolute improvement), and the DSTC7 document-grounded dialog response generation NIST-4 to 2.67 (human performance is 2.65). The code and pre-trained models are available at this https URL.\nUniversal Language Model Fine-tuning for Text Classification (Jeremy Howard et al., 2018) Jeremy Howard, Sebastian Ruder. (2018)\nUniversal Language Model Fine-tuning for Text Classification\nACL\nPaper Link\nInfluential Citation Count (224), SS-ID (1e077413b25c4d34945cc2707e17e46ed4fe784a)\nABSTRACT\nInductive transfer learning has greatly impacted computer vision, but existing approaches in NLP still require task-specific modifications and training from scratch. We propose Universal Language Model Fine-tuning (ULMFiT), an effective transfer learning method that can be applied to any task in NLP, and introduce techniques that are key for fine-tuning a language model. Our method significantly outperforms the state-of-the-art on six text classification tasks, reducing the error by 18-24% on the majority of datasets. Furthermore, with only 100 labeled examples, it matches the performance of training from scratch on 100 times more data. We open-source our pretrained models and code.\nAttention is All you Need (Ashish Vaswani et al., 2017) Ashish Vaswani, Noam M. Shazeer, Niki Parmar, Jakob Uszkoreit, Llion Jones, Aidan N. Gomez, Lukasz Kaiser, Illia Polosukhin. (2017)\nAttention is All you Need\nNIPS\nPaper Link\nInfluential Citation Count (7808), SS-ID (204e3073870fae3d05bcbc2f6a8e263d9b72e776)\nABSTRACT\nThe dominant sequence transduction models are based on complex recurrent or convolutional neural networks in an encoder-decoder configuration. The best performing models also connect the encoder and decoder through an attention mechanism. We propose a new simple network architecture, the Transformer, based solely on attention mechanisms, dispensing with recurrence and convolutions entirely. Experiments on two machine translation tasks show these models to be superior in quality while being more parallelizable and requiring significantly less time to train. Our model achieves 28.4 BLEU on the WMT 2014 English-to-German translation task, improving over the existing best results, including ensembles by over 2 BLEU. On the WMT 2014 English-to-French translation task, our model establishes a new single-model state-of-the-art BLEU score of 41.8 after training for 3.5 days on eight GPUs, a small fraction of the training costs of the best models from the literature. We show that the Transformer generalizes well to other tasks by applying it successfully to English constituency parsing both with large and limited training data.\nMixed Precision Training (P. Micikevicius et al., 2017) P. Micikevicius, Sharan Narang, Jonah Alben, G. Diamos, Erich Elsen, David García, Boris Ginsburg, Michael Houston, O. Kuchaiev, Ganesh Venkatesh, Hao Wu. (2017)\nMixed Precision Training\nICLR\nPaper Link\nInfluential Citation Count (68), SS-ID (2e10560579f2bdeae0143141f26bd9f0a195b4b7)\nABSTRACT\nDeep neural networks have enabled progress in a wide variety of applications. Growing the size of the neural network typically results in improved accuracy. As model sizes grow, the memory and compute requirements for training these models also increases. We introduce a technique to train deep neural networks using half precision floating point numbers. In our technique, weights, activations and gradients are stored in IEEE half-precision format. Half-precision floating numbers have limited numerical range compared to single-precision numbers. We propose two techniques to handle this loss of information. Firstly, we recommend maintaining a single-precision copy of the weights that accumulates the gradients after each optimizer step. This single-precision copy is rounded to half-precision format during training. Secondly, we propose scaling the loss appropriately to handle the loss of information with half-precision gradients. We demonstrate that this approach works for a wide variety of models including convolution neural networks, recurrent neural networks and generative adversarial networks. This technique works for large scale models with more than 100 million parameters trained on large datasets. Using this approach, we can reduce the memory consumption of deep learning models by nearly 2x. In future processors, we can also expect a significant computation speedup using half-precision hardware units.\nReducing BERT Pre-Training Time from 3 Days to 76 Minutes (Yang You et al., 2019) Yang You, Jing Li, Jonathan Hseu, Xiaodan Song, J. Demmel, Cho-Jui Hsieh. (2019)\nReducing BERT Pre-Training Time from 3 Days to 76 Minutes\nArXiv\nPaper Link\nInfluential Citation Count (13), SS-ID (3c6dca9041f54583aeab60587c9e6e9272104dc1)\nABSTRACT\nLarge-batch training is key to speeding up deep neural network training in large distributed systems. However, large-batch training is difficult because it produces a generalization gap. Straightforward optimization often leads to accuracy loss on the test set. BERT \\cite{devlin2018bert} is a state-of-the-art deep learning model that builds on top of deep bidirectional transformers for language understanding. Previous large-batch training techniques do not perform well for BERT when we scale the batch size (e.g. beyond 8192). BERT pre-training also takes a long time to finish (around three days on 16 TPUv3 chips). To solve this problem, we propose the LAMB optimizer, which helps us to scale the batch size to 65536 without losing accuracy. LAMB is a general optimizer that works for both small and large batch sizes and does not need hyper-parameter tuning besides the learning rate. The baseline BERT-Large model needs 1 million iterations to finish pre-training, while LAMB with batch size 65536/32768 only needs 8599 iterations. We push the batch size to the memory limit of a TPUv3 pod and can finish BERT training in 76 minutes.\nDeep Contextualized Word Representations (Matthew E. Peters et al., 2018) Matthew E. Peters, Mark Neumann, Mohit Iyyer, Matt Gardner, Christopher Clark, Kenton Lee, Luke Zettlemoyer. (2018)\nDeep Contextualized Word Representations\nNAACL\nPaper Link\nInfluential Citation Count (1358), SS-ID (3febb2bed8865945e7fddc99efd791887bb7e14f)\nABSTRACT\nWe introduce a new type of deep contextualized word representation that models both (1) complex characteristics of word use (e.g., syntax and semantics), and (2) how these uses vary across linguistic contexts (i.e., to model polysemy). Our word vectors are learned functions of the internal states of a deep bidirectional language model (biLM), which is pre-trained on a large text corpus. We show that these representations can be easily added to existing models and significantly improve the state of the art across six challenging NLP problems, including question answering, textual entailment and sentiment analysis. We also present an analysis showing that exposing the deep internals of the pre-trained network is crucial, allowing downstream models to mix different types of semi-supervision signals.\nBridging Nonlinearities and Stochastic Regularizers with Gaussian Error Linear Units (Dan Hendrycks et al., 2016) Dan Hendrycks, Kevin Gimpel. (2016)\nBridging Nonlinearities and Stochastic Regularizers with Gaussian Error Linear Units\nArXiv\nPaper Link\nInfluential Citation Count (45), SS-ID (4361e64f2d12d63476fdc88faf72a0f70d9a2ffb)\nABSTRACT\nWe propose the Gaussian Error Linear Unit (GELU), a high-performing neural network activation function. The GELU nonlinearity is the expected transformation of a stochastic regularizer which randomly applies the identity or zero map, combining the intuitions of dropout and zoneout while respecting neuron values. This connection suggests a new probabilistic understanding of nonlinearities. We perform an empirical evaluation of the GELU nonlinearity against the ReLU and ELU activations and find performance improvements across all tasks.\nAutomatically Constructing a Corpus of Sentential Paraphrases (W. Dolan et al., 2005) W. Dolan, Chris Brockett. (2005)\nAutomatically Constructing a Corpus of Sentential Paraphrases\nIJCNLP\nPaper Link\nInfluential Citation Count (141), SS-ID (475354f10798f110d34792b6d88f31d6d5cb099e)\nABSTRACT\nAn obstacle to research in automatic paraphrase identification and generation is the lack of large-scale, publiclyavailable labeled corpora of sentential paraphrases. This paper describes the creation of the recently-released Microsoft Research Paraphrase Corpus, which contains 5801 sentence pairs, each hand-labeled with a binary judgment as to whether the pair constitutes a paraphrase. The corpus was created using heuristic extraction techniques in conjunction with an SVM-based classifier to select likely sentence-level paraphrases from a large corpus of topicclustered news data. These pairs were then submitted to human judges, who confirmed that 67% were in fact semantically equivalent. In addition to describing the corpus itself, we explore a number of issues that arose in defining guidelines for the human raters.\nSemi-supervised Sequence Learning (Andrew M. Dai et al., 2015) Andrew M. Dai, Quoc V. Le. (2015)\nSemi-supervised Sequence Learning\nNIPS\nPaper Link\nInfluential Citation Count (53), SS-ID (4aa9f5150b46320f534de4747a2dd0cd7f3fe292)\nABSTRACT\nWe present two approaches to use unlabeled data to improve Sequence Learning with recurrent networks. The first approach is to predict what comes next in a sequence, which is a language model in NLP. The second approach is to use a sequence autoencoder, which reads the input sequence into a vector and predicts the input sequence again. These two algorithms can be used as a \u0026ldquo;pretraining\u0026rdquo; algorithm for a later supervised sequence learning algorithm. In other words, the parameters obtained from the pretraining step can then be used as a starting point for other supervised training models. In our experiments, we find that long short term memory recurrent networks after pretrained with the two approaches become more stable to train and generalize better. With pretraining, we were able to achieve strong performance in many classification tasks, such as text classification with IMDB, DBpedia or image recognition in CIFAR-10.\nKnow What You Don’t Know: Unanswerable Questions for SQuAD (Pranav Rajpurkar et al., 2018) Pranav Rajpurkar, Robin Jia, Percy Liang. (2018)\nKnow What You Don’t Know: Unanswerable Questions for SQuAD\nACL\nPaper Link\nInfluential Citation Count (348), SS-ID (4d1c856275744c0284312a3a50efb6ca9dc4cd4c)\nABSTRACT\nExtractive reading comprehension systems can often locate the correct answer to a question in a context document, but they also tend to make unreliable guesses on questions for which the correct answer is not stated in the context. Existing datasets either focus exclusively on answerable questions, or use automatically generated unanswerable questions that are easy to identify. To address these weaknesses, we present SQuADRUn, a new dataset that combines the existing Stanford Question Answering Dataset (SQuAD) with over 50,000 unanswerable questions written adversarially by crowdworkers to look similar to answerable ones. To do well on SQuADRUn, systems must not only answer questions when possible, but also determine when no answer is supported by the paragraph and abstain from answering. SQuADRUn is a challenging natural language understanding task for existing models: a strong neural system that gets 86% F1 on SQuAD achieves only 66% F1 on SQuADRUn. We release SQuADRUn to the community as the successor to SQuAD.\nA Broad-Coverage Challenge Corpus for Sentence Understanding through Inference (Adina Williams et al., 2017) Adina Williams, Nikita Nangia, Samuel R. Bowman. (2017)\nA Broad-Coverage Challenge Corpus for Sentence Understanding through Inference\nNAACL\nPaper Link\nInfluential Citation Count (458), SS-ID (5ded2b8c64491b4a67f6d39ce473d4b9347a672e)\nABSTRACT\nThis paper introduces the Multi-Genre Natural Language Inference (MultiNLI) corpus, a dataset designed for use in the development and evaluation of machine learning models for sentence understanding. At 433k examples, this resource is one of the largest corpora available for natural language inference (a.k.a. recognizing textual entailment), improving upon available resources in both its coverage and difficulty. MultiNLI accomplishes this by offering data from ten distinct genres of written and spoken English, making it possible to evaluate systems on nearly the full complexity of the language, while supplying an explicit setting for evaluating cross-genre domain adaptation. In addition, an evaluation using existing machine learning models designed for the Stanford NLI corpus shows that it represents a substantially more difficult task than does that corpus, despite the two showing similar levels of inter-annotator agreement.\nRACE: Large-scale ReAding Comprehension Dataset From Examinations (Guokun Lai et al., 2017) Guokun Lai, Qizhe Xie, Hanxiao Liu, Yiming Yang, E. Hovy. (2017)\nRACE: Large-scale ReAding Comprehension Dataset From Examinations\nEMNLP\nPaper Link\nInfluential Citation Count (183), SS-ID (636a79420d838eabe4af7fb25d6437de45ab64e8)\nABSTRACT\nWe present RACE, a new dataset for benchmark evaluation of methods in the reading comprehension task. Collected from the English exams for middle and high school Chinese students in the age range between 12 to 18, RACE consists of near 28,000 passages and near 100,000 questions generated by human experts (English instructors), and covers a variety of topics which are carefully designed for evaluating the students’ ability in understanding and reasoning. In particular, the proportion of questions that requires reasoning is much larger in RACE than that in other benchmark datasets for reading comprehension, and there is a significant gap between the performance of the state-of-the-art models (43%) and the ceiling human performance (95%). We hope this new dataset can serve as a valuable resource for research and evaluation in machine comprehension. The dataset is freely available at http://www.cs.cmu.edu/~glai1/data/race/ and the code is available at https://github.com/qizhex/RACE_AR_baselines.\nMulti-Task Deep Neural Networks for Natural Language Understanding (Xiaodong Liu et al., 2019) Xiaodong Liu, Pengcheng He, Weizhu Chen, Jianfeng Gao. (2019)\nMulti-Task Deep Neural Networks for Natural Language Understanding\nACL\nPaper Link\nInfluential Citation Count (172), SS-ID (658721bc13b0fa97366d38c05a96bf0a9f4bb0ac)\nABSTRACT\nIn this paper, we present a Multi-Task Deep Neural Network (MT-DNN) for learning representations across multiple natural language understanding (NLU) tasks. MT-DNN not only leverages large amounts of cross-task data, but also benefits from a regularization effect that leads to more general representations to help adapt to new tasks and domains. MT-DNN extends the model proposed in Liu et al. (2015) by incorporating a pre-trained bidirectional transformer language model, known as BERT (Devlin et al., 2018). MT-DNN obtains new state-of-the-art results on ten NLU tasks, including SNLI, SciTail, and eight out of nine GLUE tasks, pushing the GLUE benchmark to 82.7% (2.2% absolute improvement) as of February 25, 2019 on the latest GLUE test set. We also demonstrate using the SNLI and SciTail datasets that the representations learned by MT-DNN allow domain adaptation with substantially fewer in-domain labels than the pre-trained BERT representations. Our code and pre-trained models will be made publicly available.\nRecursive Deep Models for Semantic Compositionality Over a Sentiment Treebank (R. Socher et al., 2013) R. Socher, Alex Perelygin, Jean Wu, Jason Chuang, Christopher D. Manning, A. Ng, Christopher Potts. (2013)\nRecursive Deep Models for Semantic Compositionality Over a Sentiment Treebank\nEMNLP\nPaper Link\nInfluential Citation Count (876), SS-ID (687bac2d3320083eb4530bf18bb8f8f721477600)\nABSTRACT\nSemantic word spaces have been very useful but cannot express the meaning of longer phrases in a principled way. Further progress towards understanding compositionality in tasks such as sentiment detection requires richer supervised training and evaluation resources and more powerful models of composition. To remedy this, we introduce a Sentiment Treebank. It includes fine grained sentiment labels for 215,154 phrases in the parse trees of 11,855 sentences and presents new challenges for sentiment compositionality. To address them, we introduce the Recursive Neural Tensor Network. When trained on the new treebank, this model outperforms all previous methods on several metrics. It pushes the state of the art in single sentence positive/negative classification from 80% up to 85.4%. The accuracy of predicting fine-grained sentiment labels for all phrases reaches 80.7%, an improvement of 9.7% over bag of features baselines. Lastly, it is the only model that can accurately capture the effects of negation and its scope at various tree levels for both positive and negative phrases.\nImproving Multi-Task Deep Neural Networks via Knowledge Distillation for Natural Language Understanding (Xiaodong Liu et al., 2019) Xiaodong Liu, Pengcheng He, Weizhu Chen, Jianfeng Gao. (2019)\nImproving Multi-Task Deep Neural Networks via Knowledge Distillation for Natural Language Understanding\nArXiv\nPaper Link\nInfluential Citation Count (21), SS-ID (7ebed46b7f3ec913e508e6468304fcaea832eda1)\nABSTRACT\nThis paper explores the use of knowledge distillation to improve a Multi-Task Deep Neural Network (MT-DNN) (Liu et al., 2019) for learning text representations across multiple natural language understanding tasks. Although ensemble learning can improve model performance, serving an ensemble of large DNNs such as MT-DNN can be prohibitively expensive. Here we apply the knowledge distillation method (Hinton et al., 2015) in the multi-task learning setting. For each task, we train an ensemble of different MT-DNNs (teacher) that outperforms any single model, and then train a single MT-DNN (student) via multi-task learning to \\emph{distill} knowledge from these ensemble teachers. We show that the distilled MT-DNN significantly outperforms the original MT-DNN on 7 out of 9 GLUE tasks, pushing the GLUE benchmark (single model) to 83.7% (1.5% absolute improvement\\footnote{ Based on the GLUE leaderboard at this https URL as of April 1, 2019.}). The code and pre-trained models will be made publicly available at this https URL.\nSpanBERT: Improving Pre-training by Representing and Predicting Spans (Mandar Joshi et al., 2019) Mandar Joshi, Danqi Chen, Yinhan Liu, Daniel S. Weld, Luke Zettlemoyer, Omer Levy. (2019)\nSpanBERT: Improving Pre-training by Representing and Predicting Spans\nTACL\nPaper Link\nInfluential Citation Count (185), SS-ID (81f5810fbbab9b7203b9556f4ce3c741875407bc)\nABSTRACT\nWe present SpanBERT, a pre-training method that is designed to better represent and predict spans of text. Our approach extends BERT by (1) masking contiguous random spans, rather than random tokens, and (2) training the span boundary representations to predict the entire content of the masked span, without relying on the individual token representations within it. SpanBERT consistently outperforms BERT and our better-tuned baselines, with substantial gains on span selection tasks such as question answering and coreference resolution. In particular, with the same training data and model size as BERTlarge, our single model obtains 94.6% and 88.7% F1 on SQuAD 1.1 and 2.0 respectively. We also achieve a new state of the art on the OntoNotes coreference resolution task (79.6% F1), strong performance on the TACRED relation extraction benchmark, and even gains on GLUE.1\nnews-please - A Generic News Crawler and Extractor (Felix Hamborg et al., 2017) Felix Hamborg, Norman Meuschke, Corinna Breitinger, Bela Gipp. (2017)\nnews-please - A Generic News Crawler and Extractor\nISI\nPaper Link\nInfluential Citation Count (1), SS-ID (86f86f7017ca11d4d849006b2938e6f02bfe16d9)\nABSTRACT\nThe amount of news published and read online has increased tremendously in recent years, making news data an interesting resource for many research disciplines, such as the social sciences and linguistics. However, large scale collection of news data is cumbersome due to a lack of generic tools for crawling and extracting such data. We present news-please, a generic, multi-language, open-source crawler and extractor for news that works out-of-the-box for a large variety of news websites. Our system allows crawling arbitrary news websites and extracting the major elements of news articles on those websites, i.e., title, lead paragraph, main content, publication date, author, and main image. Compared to existing tools, news-please features full website extraction requiring only the root URL.\nGLUE: A Multi-Task Benchmark and Analysis Platform for Natural Language Understanding (Alex Wang et al., 2018) Alex Wang, Amanpreet Singh, Julian Michael, Felix Hill, Omer Levy, Samuel R. Bowman. (2018)\nGLUE: A Multi-Task Benchmark and Analysis Platform for Natural Language Understanding\nBlackboxNLP@EMNLP\nPaper Link\nInfluential Citation Count (659), SS-ID (93b8da28d006415866bf48f9a6e06b5242129195)\nABSTRACT\nHuman ability to understand language is general, flexible, and robust. In contrast, most NLU models above the word level are designed for a specific task and struggle with out-of-domain data. If we aspire to develop models with understanding beyond the detection of superficial correspondences between inputs and outputs, then it is critical to develop a unified model that can execute a range of linguistic tasks across different domains. To facilitate research in this direction, we present the General Language Understanding Evaluation (GLUE, gluebenchmark.com): a benchmark of nine diverse NLU tasks, an auxiliary dataset for probing models for understanding of specific linguistic phenomena, and an online platform for evaluating and comparing models. For some benchmark tasks, training data is plentiful, but for others it is limited or does not match the genre of the test set. GLUE thus favors models that can represent linguistic knowledge in a way that facilitates sample-efficient learning and effective knowledge-transfer across tasks. While none of the datasets in GLUE were created from scratch for the benchmark, four of them feature privately-held test data, which is used to ensure that the benchmark is used fairly. We evaluate baselines that use ELMo (Peters et al., 2018), a powerful transfer learning technique, as well as state-of-the-art sentence representation models. The best models still achieve fairly low absolute scores. Analysis with our diagnostic dataset yields similarly weak performance over all phenomena tested, with some exceptions.\nLanguage Models are Unsupervised Multitask Learners (Alec Radford et al., 2019) Alec Radford, Jeff Wu, Rewon Child, D. Luan, Dario Amodei, Ilya Sutskever. (2019)\nLanguage Models are Unsupervised Multitask Learners\nPaper Link\nInfluential Citation Count (1384), SS-ID (9405cc0d6169988371b2755e573cc28650d14dfe)\nABSTRACT\nNatural language processing tasks, such as question answering, machine translation, reading comprehension, and summarization, are typically approached with supervised learning on taskspecific datasets. We demonstrate that language models begin to learn these tasks without any explicit supervision when trained on a new dataset of millions of webpages called WebText. When conditioned on a document plus questions, the answers generated by the language model reach 55 F1 on the CoQA dataset matching or exceeding the performance of 3 out of 4 baseline systems without using the 127,000+ training examples. The capacity of the language model is essential to the success of zero-shot task transfer and increasing it improves performance in a log-linear fashion across tasks. Our largest model, GPT-2, is a 1.5B parameter Transformer that achieves state of the art results on 7 out of 8 tested language modeling datasets in a zero-shot setting but still underfits WebText. Samples from the model reflect these improvements and contain coherent paragraphs of text. These findings suggest a promising path towards building language processing systems which learn to perform tasks from their naturally occurring demonstrations.\nCloze-driven Pretraining of Self-attention Networks (Alexei Baevski et al., 2019) Alexei Baevski, Sergey Edunov, Yinhan Liu, Luke Zettlemoyer, Michael Auli. (2019)\nCloze-driven Pretraining of Self-attention Networks\nEMNLP\nPaper Link\nInfluential Citation Count (14), SS-ID (9f1c5777a193b2c3bb2b25e248a156348e5ba56d)\nABSTRACT\nWe present a new approach for pretraining a bi-directional transformer model that provides significant performance gains across a variety of language understanding problems. Our model solves a cloze-style word reconstruction task, where each word is ablated and must be predicted given the rest of the text. Experiments demonstrate large performance gains on GLUE and new state of the art results on NER as well as constituency parsing benchmarks, consistent with BERT. We also present a detailed analysis of a number of factors that contribute to effective pretraining, including data domain and size, model capacity, and variations on the cloze objective.\nAdam: A Method for Stochastic Optimization (Diederik P. Kingma et al., 2014) Diederik P. Kingma, Jimmy Ba. (2014)\nAdam: A Method for Stochastic Optimization\nICLR\nPaper Link\nInfluential Citation Count (14812), SS-ID (a6cb366736791bcccc5c8639de5a8f9636bf87e8)\nABSTRACT\nWe introduce Adam, an algorithm for first-order gradient-based optimization of stochastic objective functions, based on adaptive estimates of lower-order moments. The method is straightforward to implement, is computationally efficient, has little memory requirements, is invariant to diagonal rescaling of the gradients, and is well suited for problems that are large in terms of data and/or parameters. The method is also appropriate for non-stationary objectives and problems with very noisy and/or sparse gradients. The hyper-parameters have intuitive interpretations and typically require little tuning. Some connections to related algorithms, on which Adam was inspired, are discussed. We also analyze the theoretical convergence properties of the algorithm and provide a regret bound on the convergence rate that is comparable to the best known results under the online convex optimization framework. Empirical results demonstrate that Adam works well in practice and compares favorably to other stochastic optimization methods. Finally, we discuss AdaMax, a variant of Adam based on the infinity norm.\nDefending Against Neural Fake News (Rowan Zellers et al., 2019) Rowan Zellers, Ari Holtzman, Hannah Rashkin, Yonatan Bisk, Ali Farhadi, Franziska Roesner, Yejin Choi. (2019)\nDefending Against Neural Fake News\nNeurIPS\nPaper Link\nInfluential Citation Count (59), SS-ID (ad7129af0644dbcafa9aa2f111cb76526ea444a1)\nABSTRACT\nRecent progress in natural language generation has raised dual-use concerns. While applications like summarization and translation are positive, the underlying technology also might enable adversaries to generate neural fake news: targeted propaganda that closely mimics the style of real news. Modern computer security relies on careful threat modeling: identifying potential threats and vulnerabilities from an adversary\u0026rsquo;s point of view, and exploring potential mitigations to these threats. Likewise, developing robust defenses against neural fake news requires us first to carefully investigate and characterize the risks of these models. We thus present a model for controllable text generation called Grover. Given a headline like `Link Found Between Vaccines and Autism,\u0026rsquo; Grover can generate the rest of the article; humans find these generations to be more trustworthy than human-written disinformation. Developing robust verification techniques against generators like Grover is critical. We find that best current discriminators can classify neural fake news from real, human-written, news with 73% accuracy, assuming access to a moderate level of training data. Counterintuitively, the best defense against Grover turns out to be Grover itself, with 92% accuracy, demonstrating the importance of public release of strong generators. We investigate these results further, showing that exposure bias \u0026ndash; and sampling strategies that alleviate its effects \u0026ndash; both leave artifacts that similar discriminators can pick up on. We conclude by discussing ethical issues regarding the technology, and plan to release Grover publicly, helping pave the way for better detection of neural fake news.\nFine-tuned Language Models for Text Classification (Jeremy Howard et al., 2018) Jeremy Howard, Sebastian Ruder. (2018)\nFine-tuned Language Models for Text Classification\nArXiv\nPaper Link\nInfluential Citation Count (20), SS-ID (ad76c236fe641aa52d1d6c28bf362ae9ffac91e7)\nABSTRACT\nTransfer learning has revolutionized computer vision, but existing approaches in NLP still require task-specific modifications and training from scratch. We propose Fine-tuned Language Models (FitLaM), an effective transfer learning method that can be applied to any task in NLP, and introduce techniques that are key for fine-tuning a state-of-the-art language model. Our method significantly outperforms the state-of-the-art on five text classification tasks, reducing the error by 18-24% on the majority of datasets. We open-source our pretrained models and code to enable adoption by the community.\nThe Third PASCAL Recognizing Textual Entailment Challenge (Danilo Giampiccolo et al., 2007) Danilo Giampiccolo, B. Magnini, Ido Dagan, W. Dolan. (2007)\nThe Third PASCAL Recognizing Textual Entailment Challenge\nACL-PASCAL@ACL\nPaper Link\nInfluential Citation Count (64), SS-ID (b2815bc4c9e4260227cd7ca0c9d68d41c4c2f58b)\nABSTRACT\nAutomatic differentiation in PyTorch (Adam Paszke et al., 2017) Adam Paszke, S. Gross, Soumith Chintala, Gregory Chanan, E. Yang, Zach DeVito, Zeming Lin, Alban Desmaison, L. Antiga, Adam Lerer. (2017)\nAutomatic differentiation in PyTorch\nPaper Link\nInfluential Citation Count (1170), SS-ID (b36a5bb1707bb9c70025294b3a310138aae8327a)\nABSTRACT\nIn this article, we describe an automatic differentiation module of PyTorch — a library designed to enable rapid research on machine learning models. It builds upon a few projects, most notably Lua Torch, Chainer, and HIPS Autograd [4], and provides a high performance environment with easy access to automatic differentiation of models executed on different devices (CPU and GPU). To make prototyping easier, PyTorch does not follow the symbolic approach used in many other deep learning frameworks, but focuses on differentiation of purely imperative programs, with a focus on extensibility and low overhead. Note that this preprint is a draft of certain sections from an upcoming paper covering all PyTorch features.\nLearned in Translation: Contextualized Word Vectors (Bryan McCann et al., 2017) Bryan McCann, James Bradbury, Caiming Xiong, R. Socher. (2017)\nLearned in Translation: Contextualized Word Vectors\nNIPS\nPaper Link\nInfluential Citation Count (65), SS-ID (bc8fa64625d9189f5801837e7b133e7fe3c581f7)\nABSTRACT\nComputer vision has benefited from initializing multiple deep layers with weights pretrained on large supervised training sets like ImageNet. Natural language processing (NLP) typically sees initialization of only the lowest layer of deep models with pretrained word vectors. In this paper, we use a deep LSTM encoder from an attentional sequence-to-sequence model trained for machine translation (MT) to contextualize word vectors. We show that adding these context vectors (CoVe) improves performance over using only unsupervised word and character vectors on a wide variety of common NLP tasks: sentiment analysis (SST, IMDb), question classification (TREC), entailment (SNLI), and question answering (SQuAD). For fine-grained sentiment analysis and entailment, CoVe improves performance of our baseline models to the state of the art.\nScaling Neural Machine Translation (Myle Ott et al., 2018) Myle Ott, Sergey Edunov, David Grangier, Michael Auli. (2018)\nScaling Neural Machine Translation\nWMT\nPaper Link\nInfluential Citation Count (69), SS-ID (bf8fe437f779f2098f9af82b534aa51dc9edb06f)\nABSTRACT\nSequence to sequence learning models still require several days to reach state of the art performance on large benchmark datasets using a single machine. This paper shows that reduced precision and large batch training can speedup training by nearly 5x on a single 8-GPU machine with careful tuning and implementation. On WMT’14 English-German translation, we match the accuracy of Vaswani et al. (2017) in under 5 hours when training on 8 GPUs and we obtain a new state of the art of 29.3 BLEU after training for 85 minutes on 128 GPUs. We further improve these results to 29.8 BLEU by training on the much larger Paracrawl dataset. On the WMT’14 English-French task, we obtain a state-of-the-art BLEU of 43.2 in 8.5 hours on 128 GPUs.\nA Surprisingly Robust Trick for the Winograd Schema Challenge (Vid Kocijan et al., 2019) Vid Kocijan, Ana-Maria Cretu, Oana-Maria Camburu, Yordan Yordanov, Thomas Lukasiewicz. (2019)\nA Surprisingly Robust Trick for the Winograd Schema Challenge\nACL\nPaper Link\nInfluential Citation Count (19), SS-ID (c57298fe3faf87f9f24414821b0df7ebb7634320)\nABSTRACT\nThe Winograd Schema Challenge (WSC) dataset WSC273 and its inference counterpart WNLI are popular benchmarks for natural language understanding and commonsense reasoning. In this paper, we show that the performance of three language models on WSC273 strongly improves when fine-tuned on a similar pronoun disambiguation problem dataset (denoted WSCR). We additionally generate a large unsupervised WSC-like dataset. By fine-tuning the BERT language model both on the introduced and on the WSCR dataset, we achieve overall accuracies of 72.2% and 71.9% on WSC273 and WNLI, improving the previous state-of-the-art solutions by 8.5% and 6.8%, respectively. Furthermore, our fine-tuned models are also consistently more robust on the “complex” subsets of WSC273, introduced by Trichelair et al. (2018).\nNeural Network Acceptability Judgments (Alex Warstadt et al., 2018) Alex Warstadt, Amanpreet Singh, Samuel R. Bowman. (2018)\nNeural Network Acceptability Judgments\nTransactions of the Association for Computational Linguistics\nPaper Link\nInfluential Citation Count (93), SS-ID (cb0f3ee1e98faf92429d601cdcd76c69c1e484eb)\nABSTRACT\nAbstract This paper investigates the ability of artificial neural networks to judge the grammatical acceptability of a sentence, with the goal of testing their linguistic competence. We introduce the Corpus of Linguistic Acceptability (CoLA), a set of 10,657 English sentences labeled as grammatical or ungrammatical from published linguistics literature. As baselines, we train several recurrent neural network models on acceptability classification, and find that our models outperform unsupervised models by Lau et al. (2016) on CoLA. Error-analysis on specific grammatical phenomena reveals that both Lau et al.’s models and ours learn systematic generalizations like subject-verb-object order. However, all models we test perform far below human level on a wide range of grammatical constructions.\nA Simple Method for Commonsense Reasoning (Trieu H. Trinh et al., 2018) Trieu H. Trinh, Quoc V. Le. (2018)\nA Simple Method for Commonsense Reasoning\nArXiv\nPaper Link\nInfluential Citation Count (16), SS-ID (d7b6753a2d4a2b286c396854063bde3a91b75535)\nABSTRACT\nCommonsense reasoning is a long-standing challenge for deep learning. For example, it is difficult to use neural networks to tackle the Winograd Schema dataset (Levesque et al., 2011). In this paper, we present a simple method for commonsense reasoning with neural networks, using unsupervised learning. Key to our method is the use of language models, trained on a massive amount of unlabled data, to score multiple choice questions posed by commonsense reasoning tests. On both Pronoun Disambiguation and Winograd Schema challenges, our models outperform previous state-of-the-art methods by a large margin, without using expensive annotated knowledge bases or hand-engineered features. We train an array of large RNN language models that operate at word or character level on LM-1-Billion, CommonCrawl, SQuAD, Gutenberg Books, and a customized corpus for this task and show that diversity of training data plays an important role in test performance. Further analysis also shows that our system successfully discovers important features of the context that decide the correct answer, indicating a good grasp of commonsense knowledge.\nSuperGLUE: A Stickier Benchmark for General-Purpose Language Understanding Systems (Alex Wang et al., 2019) Alex Wang, Yada Pruksachatkun, Nikita Nangia, Amanpreet Singh, Julian Michael, Felix Hill, Omer Levy, Samuel R. Bowman. (2019)\nSuperGLUE: A Stickier Benchmark for General-Purpose Language Understanding Systems\nNeurIPS\nPaper Link\nInfluential Citation Count (146), SS-ID (d9f6ada77448664b71128bb19df15765336974a6)\nABSTRACT\nIn the last year, new models and methods for pretraining and transfer learning have driven striking performance improvements across a range of language understanding tasks. The GLUE benchmark, introduced a little over one year ago, offers a single-number metric that summarizes progress on a diverse set of such tasks, but performance on the benchmark has recently surpassed the level of non-expert humans, suggesting limited headroom for further research. In this paper we present SuperGLUE, a new benchmark styled after GLUE with a new set of more difficult language understanding tasks, a software toolkit, and a public leaderboard. SuperGLUE is available at this http URL.\nThe Sixth PASCAL Recognizing Textual Entailment Challenge (L. Bentivogli et al., 2009) L. Bentivogli, Peter Clark, Ido Dagan, Danilo Giampiccolo. (2009)\nThe Sixth PASCAL Recognizing Textual Entailment Challenge\nTAC\nPaper Link\nInfluential Citation Count (82), SS-ID (db8885a0037fe47d973ade79d696586453710233)\nABSTRACT\nThis paper presents the Sixth Recognizing Textual Entailment (RTE-6) challenge. This year a major innovation was introduced, as the traditional Main Task was replaced by a new task, similar to the RTE-5 Search Pilot, in which Textual Entailment is performed on a real corpus in the Update Summarization scenario. A subtask was also proposed, aimed at detecting novel information. To continue the effort of testing RTE in NLP applications, a KBP Validation Pilot Task was set up, in which RTE systems had to validate the output of systems participating in the KBP Slot Filling Task. Eighteen teams participated in the Main Task (48 submitted runs) and 9 in the Novelty Detection Subtask (22 submitted runs). As for the Pilot, 10 runs were submitted by 3 participants. Finally, the exploratory effort started in RTE-5 to perform resource evaluation through ablation tests was not only reiterated in RTE-6, but also extended to tools.\nThe PASCAL Recognising Textual Entailment Challenge (Ido Dagan et al., 2007) Ido Dagan, Oren Glickman, B. Magnini. (2007)\nThe PASCAL Recognising Textual Entailment Challenge\nMLCW\nPaper Link\nInfluential Citation Count (235), SS-ID (de794d50713ea5f91a7c9da3d72041e2f5ef8452)\nABSTRACT\nBERT: Pre-training of Deep Bidirectional Transformers for Language Understanding (Jacob Devlin et al., 2019) Jacob Devlin, Ming-Wei Chang, Kenton Lee, Kristina Toutanova. (2019)\nBERT: Pre-training of Deep Bidirectional Transformers for Language Understanding\nNAACL\nPaper Link\nInfluential Citation Count (10347), SS-ID (df2b0e26d0599ce3e70df8a9da02e51594e0e992)\nABSTRACT\nWe introduce a new language representation model called BERT, which stands for Bidirectional Encoder Representations from Transformers. Unlike recent language representation models (Peters et al., 2018a; Radford et al., 2018), BERT is designed to pre-train deep bidirectional representations from unlabeled text by jointly conditioning on both left and right context in all layers. As a result, the pre-trained BERT model can be fine-tuned with just one additional output layer to create state-of-the-art models for a wide range of tasks, such as question answering and language inference, without substantial task-specific architecture modifications. BERT is conceptually simple and empirically powerful. It obtains new state-of-the-art results on eleven natural language processing tasks, including pushing the GLUE score to 80.5 (7.7 point absolute improvement), MultiNLI accuracy to 86.7% (4.6% absolute improvement), SQuAD v1.1 question answering Test F1 to 93.2 (1.5 point absolute improvement) and SQuAD v2.0 Test F1 to 83.1 (5.1 point absolute improvement).\nXLNet: Generalized Autoregressive Pretraining for Language Understanding (Zhilin Yang et al., 2019) Zhilin Yang, Zihang Dai, Yiming Yang, J. Carbonell, R. Salakhutdinov, Quoc V. Le. (2019)\nXLNet: Generalized Autoregressive Pretraining for Language Understanding\nNeurIPS\nPaper Link\nInfluential Citation Count (651), SS-ID (e0c6abdbdecf04ffac65c440da77fb9d66bb474c)\nABSTRACT\nWith the capability of modeling bidirectional contexts, denoising autoencoding based pretraining like BERT achieves better performance than pretraining approaches based on autoregressive language modeling. However, relying on corrupting the input with masks, BERT neglects dependency between the masked positions and suffers from a pretrain-finetune discrepancy. In light of these pros and cons, we propose XLNet, a generalized autoregressive pretraining method that (1) enables learning bidirectional contexts by maximizing the expected likelihood over all permutations of the factorization order and (2) overcomes the limitations of BERT thanks to its autoregressive formulation. Furthermore, XLNet integrates ideas from Transformer-XL, the state-of-the-art autoregressive model, into pretraining. Empirically, under comparable experiment settings, XLNet outperforms BERT on 20 tasks, often by a large margin, including question answering, natural language inference, sentiment analysis, and document ranking.\nCross-lingual Language Model Pretraining (Guillaume Lample et al., 2019) Guillaume Lample, A. Conneau. (2019)\nCross-lingual Language Model Pretraining\nNeurIPS\nPaper Link\nInfluential Citation Count (356), SS-ID (ec4eba83f6b3266d9ae7cabb2b2cb1518f727edc)\nABSTRACT\nRecent studies have demonstrated the efficiency of generative pretraining for English natural language understanding. In this work, we extend this approach to multiple languages and show the effectiveness of cross-lingual pretraining. We propose two methods to learn cross-lingual language models (XLMs): one unsupervised that only relies on monolingual data, and one supervised that leverages parallel data with a new cross-lingual language model objective. We obtain state-of-the-art results on cross-lingual classification, unsupervised and supervised machine translation. On XNLI, our approach pushes the state of the art by an absolute gain of 4.9% accuracy. On unsupervised machine translation, we obtain 34.3 BLEU on WMT’16 German-English, improving the previous state of the art by more than 9 BLEU. On supervised machine translation, we obtain a new state of the art of 38.5 BLEU on WMT’16 Romanian-English, outperforming the previous best approach by more than 4 BLEU. Our code and pretrained models will be made publicly available.\nA large annotated corpus for learning natural language inference (Samuel R. Bowman et al., 2015) Samuel R. Bowman, Gabor Angeli, Christopher Potts, Christopher D. Manning. (2015)\nA large annotated corpus for learning natural language inference\nEMNLP\nPaper Link\nInfluential Citation Count (664), SS-ID (f04df4e20a18358ea2f689b4c129781628ef7fc1)\nABSTRACT\nUnderstanding entailment and contradiction is fundamental to understanding natural language, and inference about entailment and contradiction is a valuable testing ground for the development of semantic representations. However, machine learning research in this area has been dramatically limited by the lack of large-scale resources. To address this, we introduce the Stanford Natural Language Inference corpus, a new, freely available collection of labeled sentence pairs, written by humans doing a novel grounded task based on image captioning. At 570K pairs, it is two orders of magnitude larger than all other resources of its type. This increase in scale allows lexicalized classifiers to outperform some sophisticated existing entailment models, and it allows a neural network-based model to perform competitively on natural language inference benchmarks for the first time.\nfairseq: A Fast, Extensible Toolkit for Sequence Modeling (Myle Ott et al., 2019) Myle Ott, Sergey Edunov, Alexei Baevski, Angela Fan, S. Gross, Nathan Ng, David Grangier, Michael Auli. (2019)\nfairseq: A Fast, Extensible Toolkit for Sequence Modeling\nNAACL\nPaper Link\nInfluential Citation Count (160), SS-ID (faadd7d081c8d67e8c2567e8a5579e46cd6b2280)\nABSTRACT\nfairseq is an open-source sequence modeling toolkit that allows researchers and developers to train custom models for translation, summarization, language modeling, and other text generation tasks. The toolkit is based on PyTorch and supports distributed training across multiple GPUs and machines. We also support fast mixed-precision training and inference on modern GPUs. A demo video can be found at https://www.youtube.com/watch?v=OtgDdWtHvto\n","date":"May 23, 2022","hero":"/blog-akitenkrad/posts/papers/202205/20220523223206/hero.jpg","permalink":"https://akitenkrad.github.io/blog-akitenkrad/posts/papers/202205/20220523223206/","summary":"Round-1: Overview Round-2: Model Implementation Details Round-3: Experiments Citation Liu, Y., Ott, M., Goyal, N., Du, J., Joshi, M., Chen, D., Levy, O., Lewis, M., Zettlemoyer, L., \u0026amp; Stoyanov, V. (2019).\nRoBERTa: A Robustly Optimized BERT Pretraining Approach.\nhttps://doi.org/10.48550/arxiv.1907.11692 Abstract Language model pretraining has led to significant performance gains but careful comparison between different approaches is challenging. Training is computationally expensive, often done on private datasets of different sizes, and, as we will show, hyperparameter choices have significant impact on the final results.","tags":["At:Round-1","Published:2019","BERT"],"title":"RoBERTa: A Robustly Optimized BERT Pretraining Approach"},{"categories":null,"contents":" Round-1: Overview Round-2: Model Implementation Details Round-3: Experiments Citation Kipf, T. N., \u0026amp; Welling, M. (2016).\nSemi-Supervised Classification with Graph Convolutional Networks.\nProceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition. (2019)\nhttps://doi.org/10.48550/arxiv.1609.02907 Abstract We present a scalable approach for semi-supervised learning on graph-structured data that is based on an efficient variant of convolutional neural networks which operate directly on graphs. We motivate the choice of our convolutional architecture via a localized first-order approximation of spectral graph convolutions. Our model scales linearly in the number of graph edges and learns hidden layer representations that encode both local graph structure and features of nodes. In a number of experiments on citation networks and on a knowledge graph dataset we demonstrate that our approach outperforms related methods by a significant margin.\nWhat\u0026rsquo;s New グラフをニューラルネットワークで直接扱えるようなシンプルなプロパゲーションルール（GCN）を提案した． GCNをノードのSemi-Supervised Classificationタスクで使用した場合に，速度・スケーラビリティの観点で有用であることを示した． Dataset Citeseer (Sen et al., 2008) P. Sen, Galileo Namata, M. Bilgic, L. Getoor, B. Gallagher, Tina Eliassi-Rad. (2008)\nCollective Classification in Network Data\nAI Mag.\nPaper Link\nInfluential Citation Count (437), SS-ID (c5f2f13778af201f486b0b3c4c8f6fcf36d4ca36)\nABSTRACT\nMany real-world applications produce networked data such as the world-wide web (hypertext documents connected via hyperlinks), social networks (for example, people connected by friendship links), communication networks (computers connected via communication links) and biological networks (for example, protein interaction networks). A recent focus in machine learning research has been to extend traditional machine learning classification techniques to classify nodes in such networks. In this article, we provide a brief introduction to this area of research and how it has progressed during the past decade. We introduce four of the most widely used inference algorithms for classifying networked data and empirically compare them on both synthetic and real-world data.\nCora (Sen et al., 2008) P. Sen, Galileo Namata, M. Bilgic, L. Getoor, B. Gallagher, Tina Eliassi-Rad. (2008)\nCollective Classification in Network Data\nAI Mag.\nPaper Link\nInfluential Citation Count (437), SS-ID (c5f2f13778af201f486b0b3c4c8f6fcf36d4ca36)\nABSTRACT\nMany real-world applications produce networked data such as the world-wide web (hypertext documents connected via hyperlinks), social networks (for example, people connected by friendship links), communication networks (computers connected via communication links) and biological networks (for example, protein interaction networks). A recent focus in machine learning research has been to extend traditional machine learning classification techniques to classify nodes in such networks. In this article, we provide a brief introduction to this area of research and how it has progressed during the past decade. We introduce four of the most widely used inference algorithms for classifying networked data and empirically compare them on both synthetic and real-world data.\nPubmed (Sen et al., 2008) P. Sen, Galileo Namata, M. Bilgic, L. Getoor, B. Gallagher, Tina Eliassi-Rad. (2008)\nCollective Classification in Network Data\nAI Mag.\nPaper Link\nInfluential Citation Count (437), SS-ID (c5f2f13778af201f486b0b3c4c8f6fcf36d4ca36)\nABSTRACT\nMany real-world applications produce networked data such as the world-wide web (hypertext documents connected via hyperlinks), social networks (for example, people connected by friendship links), communication networks (computers connected via communication links) and biological networks (for example, protein interaction networks). A recent focus in machine learning research has been to extend traditional machine learning classification techniques to classify nodes in such networks. In this article, we provide a brief introduction to this area of research and how it has progressed during the past decade. We introduce four of the most widely used inference algorithms for classifying networked data and empirically compare them on both synthetic and real-world data.\nNELL (Carlson et al., 2010) Andrew Carlson, J. Betteridge, B. Kisiel, Burr Settles, Estevam R. Hruschka, Tom Michael Mitchell. (2010)\nToward an Architecture for Never-Ending Language Learning\nAAAI\nPaper Link\nInfluential Citation Count (235), SS-ID (f7312b8568d63bbbb239583ed282f46cdc40978d)\nABSTRACT\nWe consider here the problem of building a never-ending language learner; that is, an intelligent computer agent that runs forever and that each day must (1) extract, or read, information from the web to populate a growing structured knowledge base, and (2) learn to perform this task better than on the previous day. In particular, we propose an approach and a set of design principles for such an agent, describe a partial implementation of such a system that has already learned to extract a knowledge base containing over 242,000 beliefs with an estimated precision of 74% after running for 67 days, and discuss lessons learned from this preliminary attempt to build a never-ending learning agent.\nDataset Summary Yang et al. (2016) Zhilin Yang, William W. Cohen, R. Salakhutdinov. (2016)\nRevisiting Semi-Supervised Learning with Graph Embeddings\nICML\nPaper Link\nInfluential Citation Count (178), SS-ID (3d846cb01f6a975554035d2210b578ca61344b22)\nABSTRACT\nWe present a semi-supervised learning framework based on graph embeddings. Given a graph between instances, we train an embedding for each instance to jointly predict the class label and the neighborhood context in the graph. We develop both transductive and inductive variants of our method. In the transductive variant of our method, the class labels are determined by both the learned embeddings and input feature vectors, while in the inductive variant, the embeddings are defined as a parametric function of the feature vectors, so predictions can be made on instances not seen during training. On a large and diverse set of benchmark tasks, including text classification, distantly supervised entity extraction, and entity classification, we show improved performance over many of the existing models.\nModel Description multi-layer Graph Convolutional Network (GCN) グラフベースのニューラルネットワークモデル $f(X, A)$ に対して,\n（$X \\in \\mathbb{R}^{N \\times N}$ はノードの特徴行列，$A \\in \\mathbb{R}^{N \\times N}$ はグラフ $\\mathcal{G}=(\\mathcal{V},\\mathcal{E}), v_i \\in \\mathcal{V}, (v_i, v_j) \\in \\mathcal{E}$ の隣接行列，$D_{ii}=\\sum_j A_{ij}$ は次数行列）\n$$ \\begin{align*} H^{(l+1)} \u0026amp;= \\sigma \\left(\\tilde{D}^{-\\frac{1}{2}}\\tilde{A}\\tilde{D}^{-\\frac{1}{2}}H^{(l)}W^{(l)}\\right) \\\\ \\text{where} \u0026amp; \\\\ \u0026amp;\\begin{split} \u0026amp;\\tilde{A} \u0026amp;= A + I_N \\\\ \u0026amp;\\tilde{D}{ii} \u0026amp;= \\sum_j\\tilde{A}{ij} \\\\ \u0026amp;W^{(l)} \u0026amp;: \\text{ layer-specific trainable parameter} \\\\ \u0026amp;\\sigma (\\cdot) \u0026amp;: \\text{ activation function such as } \\text{ReLU}(\\cdot) = \\max(0, \\cdot) \\\\ \u0026amp;H^{(0)} \u0026amp;= X \\end{split} \\\\ \\text{shapes} \u0026amp; \\\\ \u0026amp;\\begin{split}\n\u0026amp;H^{(l)} \u0026amp;\\in \\mathbb{R}^{N \\times D} \\\\ \u0026amp;A, D \u0026amp;\\in \\mathbb{R}^{N \\times N} \\\\ \u0026amp;W^{(l)} \u0026amp;\\in \\mathbb{R}^{D \\times D}\n\\end{split} \\end{align*} $$\nSpectral Graph Convolutions → GCN 以下，グラフの畳み込み演算からGraph Convolutional Network (GCN)\n$$ H^{(l+1)} = \\sigma \\left(\\tilde{D}^{-\\frac{1}{2}}\\tilde{A}\\tilde{D}^{-\\frac{1}{2}}H^{(l)}W^{(l)}\\right) $$\nを導出する．\n各ノードに対応する特徴ベクトル $x \\in \\mathbb{R}^N$ とフィルター $g_{\\theta} = \\text{diag}(\\theta), \\theta \\in \\mathbb{R}^N$ のグラフ畳み込み演算を以下のように定義する．\n$$ \\begin{align*} g_{\\theta} \\star x \u0026amp;= Ug_{\\theta}U^{\\top}x \\\\ \\text{where}\u0026amp; \\\\ \u0026amp;\\begin{split} \u0026amp;U \u0026amp;: \\text{the matrix of eigenvectors of the normalized graph Laplacian (正規化グラフラプラシアン)} \\\\ \u0026amp;L \u0026amp;= I_N - D^{-\\frac{1}{2}}AD^{-\\frac{1}{2}} \\\\ \u0026amp;\u0026amp;= U\\Lambda U^{\\top} \\\\ \u0026amp;\\Lambda \u0026amp;: \\text{対角成分に }L\\text{ の固有値を持つ対角行列} \\\\ (\u0026amp;U^{\\top}x \u0026amp;: x\\text{ のグラフフーリエ変換}) \\end{split} \\end{align*} $$\n$U$ の計算コストは $\\mathcal{O}(N^2)$ であり重いため，Hammond et al. (2009)で提案されている手法を用いてチェビシェフの多項式 $T_k(x)$ により$K$次まで $g_{\\theta}(\\Lambda)$ を近似する．\nHammond et al. (2009) D. K. Hammond, P. Vandergheynst, R. Gribonval. (2009)\nWavelets on Graphs via Spectral Graph Theory\nArXiv\nPaper Link\nInfluential Citation Count (165), SS-ID (8e8152d46c8ff1070805096c214df7f389c57b80) $$ \\begin{align*} g_{{\\theta}\u0026rsquo;}(\\Lambda) \u0026amp;\\approx \\sum_{k=0}^{K}{\\theta}\u0026rsquo;_k T_k(\\tilde{\\Lambda}) \\\\ \\text{where} \u0026amp; \\\\ \u0026amp;\\begin{split} \u0026amp;\\tilde{\\Lambda} \u0026amp;= \\frac{2}{\\lambda {max}}\\Lambda - I_N \\\\ \u0026amp;\\lambda {max} \u0026amp;: \\text{the largest eigenvalue of }L \\\\ \u0026amp;{\\theta}\u0026rsquo; \u0026amp;\\in \\mathbb{R}^K \\\\ \u0026amp;T_k(x) \u0026amp;= 2xT{k-1}(x) - T{k-2}(x) \\\\ \u0026amp;T_0(x) \u0026amp;= 1 \\\\ \u0026amp;T_1(x) \u0026amp;= x \\end{split} \\end{align*} $$\nしたがって，グラフ畳み込み演算はチェビシェフの多項式を用いて以下のように近似することができる．\n$$ \\begin{align*} g_{{\\theta}\u0026rsquo;} \\star x \u0026amp;\\approx \\sum_{k=0}^{K}{\\theta}\u0026rsquo;_k T_k(\\tilde{L}) \\\\ \\text{where} \u0026amp; \\\\ \u0026amp;\\begin{split} \u0026amp;\\tilde{L} = \\frac{2}{\\lambda _{max}}L - I_N \\\\ \u0026amp;\\because (U\\Lambda U^{\\top})^k = U\\Lambda^kU^{\\top} \\end{split} \\end{align*} $$\nこの近似の計算コストは $\\mathcal{O}(|\\mathcal{E}|)$ となり，エッジの数に比例するようになる．\nここで， $K=1$，$\\lambda _{max}=2$ の場合を考える．グラフ畳み込み演算単体としては線形になるが，このレイヤを複数重ねることよってニューラルネットワークから十分な表現力を得ることができると考え，値をこのように固定している．\nこのとき，\n$$ \\begin{align*} g_{{\\theta}\u0026rsquo;} \\star x \u0026amp;\\approx {\\theta}\u0026rsquo;_0x + {\\theta}\u0026rsquo;_1(L-I_N)x \\\\ \u0026amp;= {\\theta}\u0026rsquo;_0x - {\\theta}\u0026rsquo;_1D^{-\\frac{1}{2}}AD^{-\\frac{1}{2}}x \\end{align*} $$\nとなり，上式は ${\\theta}\u0026rsquo;_0$ と ${\\theta}\u0026rsquo;_1$ の2つだけのパラメータに依存するようになる．\nこのフィルタパラメータはグラフ全体で共有する．\nさらに，ニューラルネットー枠としては最適化するパラメータの数を減らしたほうが有利になるため，\n$$ \\theta = {\\theta}\u0026rsquo;_0 = -{\\theta}\u0026rsquo;_1 $$\nとして，\n$$ g_{{\\theta}\u0026rsquo;} \\star x \\approx \\theta(I_N + D^{-\\frac{1}{2}}AD^{-\\frac{1}{2}})x $$\nを得る．\nここで，\n$$ \\begin{align*} I_N + D^{-\\frac{1}{2}}AD^{-\\frac{1}{2}} \u0026amp;= \\tilde{D}^{-\\frac{1}{2}}\\tilde{A}\\tilde{D}^{-\\frac{1}{2}} \\\\ \\text{where} \u0026amp; \\\\ \u0026amp;\\begin{split} \u0026amp;\\tilde{A} \u0026amp;= A + I_N \\\\ \u0026amp;\\tilde{D}{ii} \u0026amp;= \\sum_j\\tilde{A}{ij} \\end{split} \\end{align*} $$\nとして行列表現を用いれば，\n$$ \\begin{align*} Z \u0026amp;= \\tilde{D}^{-\\frac{1}{2}}\\tilde{A}\\tilde{D}^{-\\frac{1}{2}}X\\Theta \\\\ \\text{where} \u0026amp; \\\\ \u0026amp;\\begin{split} \u0026amp;X \u0026amp;\\in \\mathbb{R}^{N \\times C} \\\\ \u0026amp;\\Theta \u0026amp;\\in \\mathbb{R}^{C \\times F} \\\\ \u0026amp;N \u0026amp;: \\text{the number of nodes} \\\\ \u0026amp;C \u0026amp;: \\text{the number of input channels i.e. C-dimensional feature fector for each node} \\\\ \u0026amp;F \u0026amp;: \\text{the number of filter channels} \\end{split} \\end{align*} $$\nを得る． これを複数レイヤ重ねることによって，GCNは\n$$ H^{(l+1)} = \\sigma \\left(\\tilde{D}^{-\\frac{1}{2}}\\tilde{A}\\tilde{D}^{-\\frac{1}{2}}H^{(l)}W^{(l)}\\right) $$\nとなる．\nResults Node Classification Evaluation of Propagation Model Training Time per Epoch References LINE: Large-scale Information Network Embedding (Jian Tang et al., 2015) Jian Tang, Meng Qu, Mingzhe Wang, Ming Zhang, Jun Yan, Q. Mei. (2015)\nLINE: Large-scale Information Network Embedding\nWWW\nPaper Link\nInfluential Citation Count (835), SS-ID (0834e74304b547c9354b6d7da6fa78ef47a48fa8)\nABSTRACT\nThis paper studies the problem of embedding very large information networks into low-dimensional vector spaces, which is useful in many tasks such as visualization, node classification, and link prediction. Most existing graph embedding methods do not scale for real world information networks which usually contain millions of nodes. In this paper, we propose a novel network embedding method called the ``LINE,\u0026rsquo;\u0026rsquo; which is suitable for arbitrary types of information networks: undirected, directed, and/or weighted. The method optimizes a carefully designed objective function that preserves both the local and global network structures. An edge-sampling algorithm is proposed that addresses the limitation of the classical stochastic gradient descent and improves both the effectiveness and the efficiency of the inference. Empirical experiments prove the effectiveness of the LINE on a variety of real-world information networks, including language networks, social networks, and citation networks. The algorithm is very efficient, which is able to learn the embedding of a network with millions of vertices and billions of edges in a few hours on a typical single machine. The source code of the LINE is available online\\footnote{\\url{https://github.com/tangjianpku/LINE}}.\nAn Information Flow Model for Conflict and Fission in Small Groups (W. Zachary, 1977) W. Zachary. (1977)\nAn Information Flow Model for Conflict and Fission in Small Groups\nJournal of Anthropological Research\nPaper Link\nInfluential Citation Count (325), SS-ID (0de728ad1b67221d7a7302f809f987bb926f4504)\nABSTRACT\nData from a voluntary association are used to construct a new formal model for a traditional anthropological problem, fission in small groups. The process leading to fission is viewed as an unequal flow of sentiments and information across the ties in a social network. This flow is unequal because it is uniquely constrained by the contextual range and sensitivity of each relationship in the network. The subsequent differential sharing of sentiments leads to the formation of subgroups with more internal stability than the group as a whole, and results in fission. The Ford-Fulkerson labeling algorithm allows an accurate prediction of membership in the subgroups and of the locus of the fission to be made from measurements of the potential for information flow across each edge in the network. Methods for measurement of potential information flow are discussed, and it is shown that all appropriate techniques will generate the same predictions.\nSemi-Supervised Learning Using Gaussian Fields and Harmonic Functions (Xiaojin Zhu et al., 2003) Xiaojin Zhu, Zoubin Ghahramani, J. Lafferty. (2003)\nSemi-Supervised Learning Using Gaussian Fields and Harmonic Functions\nICML\nPaper Link\nInfluential Citation Count (520), SS-ID (125842668eab7decac136db8a59d392dc5e4e395)\nABSTRACT\nAn approach to semi-supervised learning is proposed that is based on a Gaussian random field model. Labeled and unlabeled data are represented as vertices in a weighted graph, with edge weights encoding the similarity between instances. The learning problem is then formulated in terms of a Gaussian random field on this graph, where the mean of the field is characterized in terms of harmonic functions, and is efficiently obtained using matrix methods or belief propagation. The resulting learning algorithms have intimate connections with random walks, electric networks, and spectral graph theory. We discuss methods to incorporate class priors and the predictions of classifiers obtained by supervised learning. We also propose a method of parameter learning by entropy minimization, and show the algorithm\u0026rsquo;s ability to perform feature selection. Promising experimental results are presented for synthetic data, digit classification, and text classification tasks.\nDiffusion-Convolutional Neural Networks (James Atwood et al., 2015) James Atwood, D. Towsley. (2015)\nDiffusion-Convolutional Neural Networks\nNIPS\nPaper Link\nInfluential Citation Count (69), SS-ID (18b47b83a373f33d6b902a3615f42c10f7600d72)\nABSTRACT\nWe present diffusion-convolutional neural networks (DCNNs), a new model for graph-structured data. Through the introduction of a diffusion-convolution operation, we show how diffusion-based representations can be learned from graph-structured data and used as an effective basis for node classification. DCNNs have several attractive qualities, including a latent representation for graphical data that is invariant under isomorphism, as well as polynomial-time prediction and learning that can be represented as tensor operations and efficiently implemented on the GPU. Through several experiments with real structured datasets, we demonstrate that DCNNs are able to outperform probabilistic relational models and kernel-on-graph methods at relational node classification tasks.\nManifold Regularization: A Geometric Framework for Learning from Labeled and Unlabeled Examples (Mikhail Belkin et al., 2006) Mikhail Belkin, P. Niyogi, V. Sindhwani. (2006)\nManifold Regularization: A Geometric Framework for Learning from Labeled and Unlabeled Examples\nJ. Mach. Learn. Res.\nPaper Link\nInfluential Citation Count (480), SS-ID (19bb0dce99466077e9bc5a2ad4941607fc28b40c)\nABSTRACT\nWe propose a family of learning algorithms based on a new form of regularization that allows us to exploit the geometry of the marginal distribution. We focus on a semi-supervised framework that incorporates labeled and unlabeled data in a general-purpose learner. Some transductive graph learning algorithms and standard methods including support vector machines and regularized least squares can be obtained as special cases. We use properties of reproducing kernel Hilbert spaces to prove new Representer theorems that provide theoretical basis for the algorithms. As a result (in contrast to purely graph-based approaches) we obtain a natural out-of-sample extension to novel examples and so are able to handle both transductive and truly semi-supervised settings. We present experimental evidence suggesting that our semi-supervised algorithms are able to use unlabeled data effectively. Finally we have a brief discussion of unsupervised and fully supervised learning within our general framework.\nVisualizing Data using t-SNE (L. V. D. Maaten et al., 2008) L. V. D. Maaten, Geoffrey E. Hinton. (2008)\nVisualizing Data using t-SNE\nPaper Link\nInfluential Citation Count (828), SS-ID (1c46943103bd7b7a2c7be86859995a4144d1938b)\nABSTRACT\nWe present a new technique called “t-SNE” that visualizes high-dimensional data by giving each datapoint a location in a two or three-dimensional map. The technique is a variation of Stochastic Neighbor Embedding (Hinton and Roweis, 2002) that is much easier to optimize, and produces significantly better visualizations by reducing the tendency to crowd points together in the center of the map. t-SNE is better than existing techniques at creating a single map that reveals structure at many different scales. This is particularly important for high-dimensional data that lie on several different, but related, low-dimensional manifolds, such as images of objects from multiple classes seen from multiple viewpoints. For visualizing the structure of very large datasets, we show how t-SNE can use random walks on neighborhood graphs to allow the implicit structure of all of the data to influence the way in which a subset of the data is displayed. We illustrate the performance of t-SNE on a wide variety of datasets and compare it with many other non-parametric visualization techniques, including Sammon mapping, Isomap, and Locally Linear Embedding. The visualizations produced by t-SNE are significantly better than those produced by the other techniques on almost all of the datasets.\nDeep Residual Learning for Image Recognition (Kaiming He et al., 2015) Kaiming He, X. Zhang, Shaoqing Ren, Jian Sun. (2015)\nDeep Residual Learning for Image Recognition\n2016 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)\nPaper Link\nInfluential Citation Count (19570), SS-ID (2c03df8b48bf3fa39054345bafabfeff15bfd11d)\nABSTRACT\nDeeper neural networks are more difficult to train. We present a residual learning framework to ease the training of networks that are substantially deeper than those used previously. We explicitly reformulate the layers as learning residual functions with reference to the layer inputs, instead of learning unreferenced functions. We provide comprehensive empirical evidence showing that these residual networks are easier to optimize, and can gain accuracy from considerably increased depth. On the ImageNet dataset we evaluate residual nets with a depth of up to 152 layers - 8× deeper than VGG nets [40] but still having lower complexity. An ensemble of these residual nets achieves 3.57% error on the ImageNet test set. This result won the 1st place on the ILSVRC 2015 classification task. We also present analysis on CIFAR-10 with 100 and 1000 layers. The depth of representations is of central importance for many visual recognition tasks. Solely due to our extremely deep representations, we obtain a 28% relative improvement on the COCO object detection dataset. Deep residual nets are foundations of our submissions to ILSVRC \u0026amp; COCO 2015 competitions1, where we also won the 1st places on the tasks of ImageNet detection, ImageNet localization, COCO detection, and COCO segmentation.\nDropout: a simple way to prevent neural networks from overfitting (Nitish Srivastava et al., 2014) Nitish Srivastava, Geoffrey E. Hinton, A. Krizhevsky, Ilya Sutskever, R. Salakhutdinov. (2014)\nDropout: a simple way to prevent neural networks from overfitting\nJ. Mach. Learn. Res.\nPaper Link\nInfluential Citation Count (2230), SS-ID (34f25a8704614163c4095b3ee2fc969b60de4698)\nABSTRACT\nDeep neural nets with a large number of parameters are very powerful machine learning systems. However, overfitting is a serious problem in such networks. Large networks are also slow to use, making it difficult to deal with overfitting by combining the predictions of many different large neural nets at test time. Dropout is a technique for addressing this problem. The key idea is to randomly drop units (along with their connections) from the neural network during training. This prevents units from co-adapting too much. During training, dropout samples from an exponential number of different \u0026ldquo;thinned\u0026rdquo; networks. At test time, it is easy to approximate the effect of averaging the predictions of all these thinned networks by simply using a single unthinned network that has smaller weights. This significantly reduces overfitting and gives major improvements over other regularization methods. We show that dropout improves the performance of neural networks on supervised learning tasks in vision, speech recognition, document classification and computational biology, obtaining state-of-the-art results on many benchmark data sets.\nnode2vec: Scalable Feature Learning for Networks (Aditya Grover et al., 2016) Aditya Grover, J. Leskovec. (2016)\nnode2vec: Scalable Feature Learning for Networks\nKDD\nPaper Link\nInfluential Citation Count (1117), SS-ID (36ee2c8bd605afd48035d15fdc6b8c8842363376)\nABSTRACT\nPrediction tasks over nodes and edges in networks require careful effort in engineering features used by learning algorithms. Recent research in the broader field of representation learning has led to significant progress in automating prediction by learning the features themselves. However, present feature learning approaches are not expressive enough to capture the diversity of connectivity patterns observed in networks. Here we propose node2vec, an algorithmic framework for learning continuous feature representations for nodes in networks. In node2vec, we learn a mapping of nodes to a low-dimensional space of features that maximizes the likelihood of preserving network neighborhoods of nodes. We define a flexible notion of a node\u0026rsquo;s network neighborhood and design a biased random walk procedure, which efficiently explores diverse neighborhoods. Our algorithm generalizes prior work which is based on rigid notions of network neighborhoods, and we argue that the added flexibility in exploring neighborhoods is the key to learning richer representations. We demonstrate the efficacy of node2vec over existing state-of-the-art techniques on multi-label classification and link prediction in several real-world networks from diverse domains. Taken together, our work represents a new way for efficiently learning state-of-the-art task-independent representations in complex networks.\nRevisiting Semi-Supervised Learning with Graph Embeddings (Zhilin Yang et al., 2016) Zhilin Yang, William W. Cohen, R. Salakhutdinov. (2016)\nRevisiting Semi-Supervised Learning with Graph Embeddings\nICML\nPaper Link\nInfluential Citation Count (178), SS-ID (3d846cb01f6a975554035d2210b578ca61344b22)\nABSTRACT\nWe present a semi-supervised learning framework based on graph embeddings. Given a graph between instances, we train an embedding for each instance to jointly predict the class label and the neighborhood context in the graph. We develop both transductive and inductive variants of our method. In the transductive variant of our method, the class labels are determined by both the learned embeddings and input feature vectors, while in the inductive variant, the embeddings are defined as a parametric function of the feature vectors, so predictions can be made on instances not seen during training. On a large and diverse set of benchmark tasks, including text classification, distantly supervised entity extraction, and entity classification, we show improved performance over many of the existing models.\nThe Graph Neural Network Model (F. Scarselli et al., 2009) F. Scarselli, M. Gori, A. Tsoi, M. Hagenbuchner, G. Monfardini. (2009)\nThe Graph Neural Network Model\nIEEE Transactions on Neural Networks\nPaper Link\nInfluential Citation Count (270), SS-ID (3efd851140aa28e95221b55fcc5659eea97b172d)\nABSTRACT\nMany underlying relationships among data in several areas of science and engineering, e.g., computer vision, molecular chemistry, molecular biology, pattern recognition, and data mining, can be represented in terms of graphs. In this paper, we propose a new neural network model, called graph neural network (GNN) model, that extends existing neural network methods for processing the data represented in graph domains. This GNN model, which can directly process most of the practically useful types of graphs, e.g., acyclic, cyclic, directed, and undirected, implements a function tau(G,n) isin IRm that maps a graph G and one of its nodes n into an m-dimensional Euclidean space. A supervised learning algorithm is derived to estimate the parameters of the proposed GNN model. The computational cost of the proposed algorithm is also considered. Some experimental results are shown to validate the proposed learning algorithm, and to demonstrate its generalization capabilities.\nLearning with Local and Global Consistency (Dengyong Zhou et al., 2003) Dengyong Zhou, O. Bousquet, T. N. Lal, J. Weston, B. Schölkopf. (2003)\nLearning with Local and Global Consistency\nNIPS\nPaper Link\nInfluential Citation Count (601), SS-ID (46770a8e7e2af28f5253e5961f709be74e34c1f6)\nABSTRACT\nWe consider the general problem of learning from labeled and unlabeled data, which is often called semi-supervised learning or transductive inference. A principled approach to semi-supervised learning is to design a classifying function which is sufficiently smooth with respect to the intrinsic structure collectively revealed by known labeled and unlabeled points. We present a simple algorithm to obtain such a smooth solution. Our method yields encouraging experimental results on a number of classification problems and demonstrates effective use of unlabeled data.\nGated Graph Sequence Neural Networks (Yujia Li et al., 2015) Yujia Li, Daniel Tarlow, Marc Brockschmidt, R. Zemel. (2015)\nGated Graph Sequence Neural Networks\nICLR\nPaper Link\nInfluential Citation Count (283), SS-ID (492f57ee9ceb61fb5a47ad7aebfec1121887a175)\nABSTRACT\nAbstract: Graph-structured data appears frequently in domains including chemistry, natural language semantics, social networks, and knowledge bases. In this work, we study feature learning techniques for graph-structured inputs. Our starting point is previous work on Graph Neural Networks (Scarselli et al., 2009), which we modify to use gated recurrent units and modern optimization techniques and then extend to output sequences. The result is a flexible and broadly useful class of neural network models that has favorable inductive biases relative to purely sequence-based models (e.g., LSTMs) when the problem is graph-structured. We demonstrate the capabilities on some simple AI (bAbI) and graph algorithm learning tasks. We then show it achieves state-of-the-art performance on a problem from program verification, in which subgraphs need to be matched to abstract data structures.\nSemi-Supervised Learning with Spectral Graph Wavelets (D. Shuman et al., 2011) D. Shuman, M. Faraji, P. Vandergheynst. (2011)\nSemi-Supervised Learning with Spectral Graph Wavelets\nPaper Link\nInfluential Citation Count (2), SS-ID (4a5a12f0ffaad71edd2d77a0fdd134f65d0e90f4)\nABSTRACT\nWe consider the transductive learning problem when the labels belong to a continuous space. Through the use of spectral graph wavelets, we explore the benefits of multiresolution analysis on a graph constructed from the labeled and unlabeled data. The spectral graph wavelets behave like discrete multiscale differential operators on graphs, and thus can sparsely approximate piecewise smooth signals. Therefore, rather than enforce a prior belief that the labels are globally smooth with respect to the intrinsic structure of the graph, we enforce sparse priors on the spectral graph wavelet coefficients. One issue that arises when the proportion of data with labels is low is that the fine scale wavelets that are useful in sparsely representing discontinuities are largely masked, making it difficult to recover the high frequency components of the label sequence. We discuss this challenge, and propose one method to use the structured sparsity of the wavelet coefficients to aid label reconstruction.\nConvolutional Networks on Graphs for Learning Molecular Fingerprints (D. Duvenaud et al., 2015) D. Duvenaud, D. Maclaurin, J. Aguilera-Iparraguirre, R. Gómez-Bombarelli, Timothy D. Hirzel, Alán Aspuru-Guzik, Ryan P. Adams. (2015)\nConvolutional Networks on Graphs for Learning Molecular Fingerprints\nNIPS\nPaper Link\nInfluential Citation Count (148), SS-ID (5d1bfeed240709725c78bc72ea40e55410b373dc)\nABSTRACT\nWe introduce a convolutional neural network that operates directly on graphs. These networks allow end-to-end learning of prediction pipelines whose inputs are graphs of arbitrary size and shape. The architecture we present generalizes standard molecular feature extraction methods based on circular fingerprints. We show that these data-driven features are more interpretable, and have better predictive performance on a variety of tasks.\nSpectral Networks and Locally Connected Networks on Graphs (Joan Bruna et al., 2013) Joan Bruna, Wojciech Zaremba, Arthur D. Szlam, Yann LeCun. (2013)\nSpectral Networks and Locally Connected Networks on Graphs\nICLR\nPaper Link\nInfluential Citation Count (264), SS-ID (5e925a9f1e20df61d1e860a7aa71894b35a1c186)\nABSTRACT\nConvolutional Neural Networks are extremely efficient architectures in image and audio recognition tasks, thanks to their ability to exploit the local translational invariance of signal classes over their domain. In this paper we consider possible generalizations of CNNs to signals defined on more general domains without the action of a translation group. In particular, we propose two constructions, one based upon a hierarchical clustering of the domain, and another based on the spectrum of the graph Laplacian. We show through experiments that for low-dimensional graphs it is possible to learn convolutional layers with a number of parameters independent of the input size, resulting in efficient deep architectures.\nTransductive Inference for Text Classification using Support Vector Machines (T. Joachims, 1999) T. Joachims. (1999)\nTransductive Inference for Text Classification using Support Vector Machines\nICML\nPaper Link\nInfluential Citation Count (421), SS-ID (74b1a9e50f18af8a7b9f8dd38f40e0466ad7a8e8)\nABSTRACT\nThis paper introduces Transductive Support Vector Machines (TSVMs) for text classi cation. While regular Support Vector Machines (SVMs) try to induce a general decision function for a learning task, Transductive Support Vector Machines take into account a particular test set and try to minimize misclassi cations of just those particular examples. The paper presents an analysis of why TSVMs are well suited for text classi cation. These theoretical ndings are supported by experiments on three test collections. The experiments show substantial improvements over inductive methods, especially for small training sets, cutting the number of labeled training examples down to a twentieth on some tasks. This work also proposes an algorithm for training TSVMs e ciently, handling 10,000 examples and more.\nLearning Convolutional Neural Networks for Graphs (Mathias Niepert et al., 2016) Mathias Niepert, Mohamed Ahmed, Konstantin Kutzkov. (2016)\nLearning Convolutional Neural Networks for Graphs\nICML\nPaper Link\nInfluential Citation Count (136), SS-ID (7c6de5a9e02a779e24504619050c6118f4eac181)\nABSTRACT\nNumerous important problems can be framed as learning from graph data. We propose a framework for learning convolutional neural networks for arbitrary graphs. These graphs may be undirected, directed, and with both discrete and continuous node and edge attributes. Analogous to image-based convolutional networks that operate on locally connected regions of the input, we present a general approach to extracting locally connected regions from graphs. Using established benchmark data sets, we demonstrate that the learned feature representations are competitive with state of the art graph kernels and that their computation is highly efficient.\nDeep learning via semi-supervised embedding (J. Weston et al., 2008) J. Weston, F. Ratle, Ronan Collobert. (2008)\nDeep learning via semi-supervised embedding\nICML \u0026lsquo;08\nPaper Link\nInfluential Citation Count (51), SS-ID (7ee368e60d0b826e78f965aad8d6c7d406127104)\nABSTRACT\nWe show how nonlinear embedding algorithms popular for use with shallow semi-supervised learning techniques such as kernel methods can be applied to deep multilayer architectures, either as a regularizer at the output layer, or on each layer of the architecture. This provides a simple alternative to existing approaches to deep learning whilst yielding competitive error rates compared to those methods, and existing shallow semi-supervised techniques.\nDistributed Representations of Words and Phrases and their Compositionality (Tomas Mikolov et al., 2013) Tomas Mikolov, Ilya Sutskever, Kai Chen, G. Corrado, J. Dean. (2013)\nDistributed Representations of Words and Phrases and their Compositionality\nNIPS\nPaper Link\nInfluential Citation Count (3603), SS-ID (87f40e6f3022adbc1f1905e3e506abad05a9964f)\nABSTRACT\nThe recently introduced continuous Skip-gram model is an efficient method for learning high-quality distributed vector representations that capture a large number of precise syntactic and semantic word relationships. In this paper we present several extensions that improve both the quality of the vectors and the training speed. By subsampling of the frequent words we obtain significant speedup and also learn more regular word representations. We also describe a simple alternative to the hierarchical softmax called negative sampling. An inherent limitation of word representations is their indifference to word order and their inability to represent idiomatic phrases. For example, the meanings of \u0026ldquo;Canada\u0026rdquo; and \u0026ldquo;Air\u0026rdquo; cannot be easily combined to obtain \u0026ldquo;Air Canada\u0026rdquo;. Motivated by this example, we present a simple method for finding phrases in text, and show that learning good vector representations for millions of phrases is possible.\nWavelets on Graphs via Spectral Graph Theory (D. K. Hammond et al., 2009) D. K. Hammond, P. Vandergheynst, R. Gribonval. (2009)\nWavelets on Graphs via Spectral Graph Theory\nArXiv\nPaper Link\nInfluential Citation Count (165), SS-ID (8e8152d46c8ff1070805096c214df7f389c57b80)\nABSTRACT\nLink-Based Classification (, 2014) . (2014)\nLink-Based Classification\nEncyclopedia of Social Network Analysis and Mining\nPaper Link\nInfluential Citation Count (48), SS-ID (91bf323aec3270df0ec8082389119d536c395655)\nABSTRACT\nUnder Review as a Conference Paper at Iclr 2017 Delving into Transferable Adversarial Ex- Amples and Black-box Attacks (Xinyun Chen, 2016) Xinyun Chen. (2016)\nUnder Review as a Conference Paper at Iclr 2017 Delving into Transferable Adversarial Ex- Amples and Black-box Attacks\nPaper Link\nInfluential Citation Count (4), SS-ID (94e3e7bc3d23276f0ee2d1cb8f9d14aa19668d5f)\nABSTRACT\nAn intriguing property of deep neural networks is the existence of adversarial examples, which can transfer among different architectures. These transferable adversarial examples may severely hinder deep neural network-based applications. Previous works mostly study the transferability using small scale datasets. In this work, we are the first to conduct an extensive study of the transferability over large models and a large scale dataset, and we are also the first to study the transferability of targeted adversarial examples with their target labels. We study both non-targeted and targeted adversarial examples, and show that while transferable non-targeted adversarial examples are easy to find, targeted adversarial examples generated using existing approaches almost never transfer with their target labels. Therefore, we propose novel ensemble-based approaches to generating transferable adversarial examples. Using such approaches, we observe a large proportion of targeted adversarial examples that are able to transfer with their target labels for the first time. We also present some geometric studies to help understanding the transferable adversarial examples. Finally, we show that the adversarial examples generated using ensemble-based approaches can successfully attack Clarifai.com, which is a black-box image classification system.\nThe Weisfeiler-Lehman Method and Graph Isomorphism Testing (B. Douglas, 2011) B. Douglas. (2011)\nThe Weisfeiler-Lehman Method and Graph Isomorphism Testing\nPaper Link\nInfluential Citation Count (2), SS-ID (9b44a53069dcf4dc10c34e456bf3a5ff160d3ede)\nABSTRACT\nProperties of the $k$-equivalent' graph families constructed in Cai, F\\\u0026quot;{u}rer and Immerman, and Evdokimov and Ponomarenko are analysed relative the the recursive $k$-dim WL method. An extension to the recursive $k$-dim WL method is presented that is shown to efficiently characterise all such types of counterexample\u0026rsquo; graphs, under certain assumptions. These assumptions are shown to hold in all known cases.\nA new model for learning in graph domains (M. Gori et al., 2005) M. Gori, G. Monfardini, F. Scarselli. (2005)\nA new model for learning in graph domains\nProceedings. 2005 IEEE International Joint Conference on Neural Networks, 2005.\nPaper Link\nInfluential Citation Count (63), SS-ID (9ca9f28676ad788d04ba24a51141a9a0a0df4d67)\nABSTRACT\nIn several applications the information is naturally represented by graphs. Traditional approaches cope with graphical data structures using a preprocessing phase which transforms the graphs into a set of flat vectors. However, in this way, important topological information may be lost and the achieved results may heavily depend on the preprocessing stage. This paper presents a new neural model, called graph neural network (GNN), capable of directly processing graphs. GNNs extends recursive neural networks and can be applied on most of the practically useful kinds of graphs, including directed, undirected, labelled and cyclic graphs. A learning algorithm for GNNs is proposed and some experiments are discussed which assess the properties of the model.\nAdam: A Method for Stochastic Optimization (Diederik P. Kingma et al., 2014) Diederik P. Kingma, Jimmy Ba. (2014)\nAdam: A Method for Stochastic Optimization\nICLR\nPaper Link\nInfluential Citation Count (14748), SS-ID (a6cb366736791bcccc5c8639de5a8f9636bf87e8)\nABSTRACT\nWe introduce Adam, an algorithm for first-order gradient-based optimization of stochastic objective functions, based on adaptive estimates of lower-order moments. The method is straightforward to implement, is computationally efficient, has little memory requirements, is invariant to diagonal rescaling of the gradients, and is well suited for problems that are large in terms of data and/or parameters. The method is also appropriate for non-stationary objectives and problems with very noisy and/or sparse gradients. The hyper-parameters have intuitive interpretations and typically require little tuning. Some connections to related algorithms, on which Adam was inspired, are discussed. We also analyze the theoretical convergence properties of the algorithm and provide a regret bound on the convergence rate that is comparable to the best known results under the online convex optimization framework. Empirical results demonstrate that Adam works well in practice and compares favorably to other stochastic optimization methods. Finally, we discuss AdaMax, a variant of Adam based on the infinity norm.\nUnderstanding the difficulty of training deep feedforward neural networks (Xavier Glorot et al., 2010) Xavier Glorot, Yoshua Bengio. (2010)\nUnderstanding the difficulty of training deep feedforward neural networks\nAISTATS\nPaper Link\nInfluential Citation Count (647), SS-ID (b71ac1e9fb49420d13e084ac67254a0bbd40f83f)\nABSTRACT\nWhereas before 2006 it appears that deep multilayer neural networks were not successfully trained, since then several algorithms have been shown to successfully train them, with experimental results showing the superiority of deeper vs less deep architectures. All these experimental results were obtained with new initialization or training mechanisms. Our objective here is to understand better why standard gradient descent from random initialization is doing so poorly with deep neural networks, to better understand these recent relative successes and help design better algorithms in the future. We first observe the influence of the non-linear activations functions. We find that the logistic sigmoid activation is unsuited for deep networks with random initialization because of its mean value, which can drive especially the top hidden layer into saturation. Surprisingly, we find that saturated units can move out of saturation by themselves, albeit slowly, and explaining the plateaus sometimes seen when training neural networks. We find that a new non-linearity that saturates less can often be beneficial. Finally, we study how activations and gradients vary across layers and during training, with the idea that training may be more difficult when the singular values of the Jacobian associated with each layer are far from 1. Based on these considerations, we propose a new initialization scheme that brings substantially faster convergence. 1 Deep Neural Networks Deep learning methods aim at learning feature hierarchies with features from higher levels of the hierarchy formed by the composition of lower level features. They include Appearing in Proceedings of the 13 International Conference on Artificial Intelligence and Statistics (AISTATS) 2010, Chia Laguna Resort, Sardinia, Italy. Volume 9 of JMLR: WC Weston et al., 2008). Much attention has recently been devoted to them (see (Bengio, 2009) for a review), because of their theoretical appeal, inspiration from biology and human cognition, and because of empirical success in vision (Ranzato et al., 2007; Larochelle et al., 2007; Vincent et al., 2008) and natural language processing (NLP) (Collobert \u0026amp; Weston, 2008; Mnih \u0026amp; Hinton, 2009). Theoretical results reviewed and discussed by Bengio (2009), suggest that in order to learn the kind of complicated functions that can represent high-level abstractions (e.g. in vision, language, and other AI-level tasks), one may need deep architectures. Most of the recent experimental results with deep architecture are obtained with models that can be turned into deep supervised neural networks, but with initialization or training schemes different from the classical feedforward neural networks (Rumelhart et al., 1986). Why are these new algorithms working so much better than the standard random initialization and gradient-based optimization of a supervised training criterion? Part of the answer may be found in recent analyses of the effect of unsupervised pretraining (Erhan et al., 2009), showing that it acts as a regularizer that initializes the parameters in a “better” basin of attraction of the optimization procedure, corresponding to an apparent local minimum associated with better generalization. But earlier work (Bengio et al., 2007) had shown that even a purely supervised but greedy layer-wise procedure would give better results. So here instead of focusing on what unsupervised pre-training or semi-supervised criteria bring to deep architectures, we focus on analyzing what may be going wrong with good old (but deep) multilayer neural networks. Our analysis is driven by investigative experiments to monitor activations (watching for saturation of hidden units) and gradients, across layers and across training iterations. We also evaluate the effects on these of choices of activation function (with the idea that it might affect saturation) and initialization procedure (since unsupervised pretraining is a particular form of initialization and it has a drastic impact).\nPublished as a conference paper at ICLR 2018 S IMULATING A CTION D YNAMICS WITH N EURAL P ROCESS N ETWORKS (A. Bosselut et al., 2018) A. Bosselut, Omer Levy, Ari Holtzman, C. Ennis, D. Fox, Yejin Choi. (2018)\nPublished as a conference paper at ICLR 2018 S IMULATING A CTION D YNAMICS WITH N EURAL P ROCESS N ETWORKS\nPaper Link\nInfluential Citation Count (0), SS-ID (bcd857d75841aa3e92cd4284a8818aba9f6c0c3f)\nABSTRACT\nUnderstanding procedural language requires anticipating the causal effects of actions, even when they are not explicitly stated. In this work, we introduce Neural Process Networks to understand procedural text through (neural) simulation of action dynamics. Our model complements existing memory architectures with dynamic entity tracking by explicitly modeling actions as state transformers. The model updates the states of the entities by executing learned action operators. Empirical results demonstrate that our proposed model can reason about the unstated causal effects of actions, allowing it to provide more accurate contextual information for understanding and generating procedural text, all while offering more interpretable internal representations than existing alternatives.\nConvolutional Neural Networks on Graphs with Fast Localized Spectral Filtering (M. Defferrard et al., 2016) M. Defferrard, X. Bresson, P. Vandergheynst. (2016)\nConvolutional Neural Networks on Graphs with Fast Localized Spectral Filtering\nNIPS\nPaper Link\nInfluential Citation Count (548), SS-ID (c41eb895616e453dcba1a70c9b942c5063cc656c)\nABSTRACT\nIn this work, we are interested in generalizing convolutional neural networks (CNNs) from low-dimensional regular grids, where image, video and speech are represented, to high-dimensional irregular domains, such as social networks, brain connectomes or words\u0026rsquo; embedding, represented by graphs. We present a formulation of CNNs in the context of spectral graph theory, which provides the necessary mathematical background and efficient numerical schemes to design fast localized convolutional filters on graphs. Importantly, the proposed technique offers the same linear computational complexity and constant learning complexity as classical CNNs, while being universal to any graph structure. Experiments on MNIST and 20NEWS demonstrate the ability of this novel deep learning system to learn local, stationary, and compositional features on graphs.\nCollective Classification in Network Data (P. Sen et al., 2008) P. Sen, Galileo Namata, M. Bilgic, L. Getoor, B. Gallagher, Tina Eliassi-Rad. (2008)\nCollective Classification in Network Data\nAI Mag.\nPaper Link\nInfluential Citation Count (437), SS-ID (c5f2f13778af201f486b0b3c4c8f6fcf36d4ca36)\nABSTRACT\nMany real-world applications produce networked data such as the world-wide web (hypertext documents connected via hyperlinks), social networks (for example, people connected by friendship links), communication networks (computers connected via communication links) and biological networks (for example, protein interaction networks). A recent focus in machine learning research has been to extend traditional machine learning classification techniques to classify nodes in such networks. In this article, we provide a brief introduction to this area of research and how it has progressed during the past decade. We introduce four of the most widely used inference algorithms for classifying networked data and empirically compare them on both synthetic and real-world data.\nToward an Architecture for Never-Ending Language Learning (Andrew Carlson et al., 2010) Andrew Carlson, J. Betteridge, B. Kisiel, Burr Settles, Estevam R. Hruschka, Tom Michael Mitchell. (2010)\nToward an Architecture for Never-Ending Language Learning\nAAAI\nPaper Link\nInfluential Citation Count (235), SS-ID (f7312b8568d63bbbb239583ed282f46cdc40978d)\nABSTRACT\nWe consider here the problem of building a never-ending language learner; that is, an intelligent computer agent that runs forever and that each day must (1) extract, or read, information from the web to populate a growing structured knowledge base, and (2) learn to perform this task better than on the previous day. In particular, we propose an approach and a set of design principles for such an agent, describe a partial implementation of such a system that has already learned to extract a knowledge base containing over 242,000 beliefs with an estimated precision of 74% after running for 67 days, and discuss lessons learned from this preliminary attempt to build a never-ending learning agent.\nOn Modularity Clustering (U. Brandes et al., 2008) U. Brandes, D. Delling, M. Gaertler, Robert Görke, M. Hoefer, Z. Nikoloski, D. Wagner. (2008)\nOn Modularity Clustering\nIEEE Transactions on Knowledge and Data Engineering\nPaper Link\nInfluential Citation Count (71), SS-ID (f99939c9c396de3ba12b3326c50dca00dab4060d)\nABSTRACT\nModularity is a recently introduced quality measure for graph clusterings. It has immediately received considerable attention in several disciplines, particularly in the complex systems literature, although its properties are not well understood. We study the problem of finding clusterings with maximum modularity, thus providing theoretical foundations for past and present work based on this measure. More precisely, we prove the conjectured hardness of maximizing modularity both in the general case and with the restriction to cuts and give an Integer Linear Programming formulation. This is complemented by first insights into the behavior and performance of the commonly applied greedy agglomerative approach.\nDeepWalk: online learning of social representations (Bryan Perozzi et al., 2014) Bryan Perozzi, Rami Al-Rfou, S. Skiena. (2014)\nDeepWalk: online learning of social representations\nKDD\nPaper Link\nInfluential Citation Count (1340), SS-ID (fff114cbba4f3ba900f33da574283e3de7f26c83)\nABSTRACT\nWe present DeepWalk, a novel approach for learning latent representations of vertices in a network. These latent representations encode social relations in a continuous vector space, which is easily exploited by statistical models. DeepWalk generalizes recent advancements in language modeling and unsupervised feature learning (or deep learning) from sequences of words to graphs. DeepWalk uses local information obtained from truncated random walks to learn latent representations by treating walks as the equivalent of sentences. We demonstrate DeepWalk\u0026rsquo;s latent representations on several multi-label network classification tasks for social networks such as BlogCatalog, Flickr, and YouTube. Our results show that DeepWalk outperforms challenging baselines which are allowed a global view of the network, especially in the presence of missing information. DeepWalk\u0026rsquo;s representations can provide F1 scores up to 10% higher than competing methods when labeled data is sparse. In some experiments, DeepWalk\u0026rsquo;s representations are able to outperform all baseline methods while using 60% less training data. DeepWalk is also scalable. It is an online learning algorithm which builds useful incremental results, and is trivially parallelizable. These qualities make it suitable for a broad class of real world applications such as network classification, and anomaly detection.\n","date":"May 20, 2022","hero":"/blog-akitenkrad/posts/papers/202205/20220520124748/hero.jpg","permalink":"https://akitenkrad.github.io/blog-akitenkrad/posts/papers/202205/20220520124748/","summary":"Round-1: Overview Round-2: Model Implementation Details Round-3: Experiments Citation Kipf, T. N., \u0026amp; Welling, M. (2016).\nSemi-Supervised Classification with Graph Convolutional Networks.\nProceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition. (2019)\nhttps://doi.org/10.48550/arxiv.1609.02907 Abstract We present a scalable approach for semi-supervised learning on graph-structured data that is based on an efficient variant of convolutional neural networks which operate directly on graphs. We motivate the choice of our convolutional architecture via a localized first-order approximation of spectral graph convolutions.","tags":["At:Round-2","Published:2016","Graph Convolutional Network","Semi-Supervised","Graph","DS:Citeseer","DS:Cora","DS:Pubmet","DS:NELL"],"title":"Semi-Supervised Classification with Graph Convolutional Networks"},{"categories":null,"contents":" Round-1: Overview Round-2: Model Implementation Details Round-3: Experiments Citation Jeong, C., Jang, S., Shin, H., Park, E., \u0026amp; Choi, S. (2019).\nA Context-Aware Citation Recommendation Model with BERT and Graph Convolutional Networks.\nhttps://doi.org/10.48550/arxiv.1903.06464 Abstract With the tremendous growth in the number of scientific papers being published, searching for references while writing a scientific paper is a time-consuming process. A technique that could add a reference citation at the appropriate place in a sentence will be beneficial. In this perspective, context-aware citation recommendation has been researched upon for around two decades. Many researchers have utilized the text data called the context sentence, which surrounds the citation tag, and the metadata of the target paper to find the appropriate cited research. However, the lack of well-organized benchmarking datasets and no model that can attain high performance has made the research difficult. In this paper, we propose a deep learning based model and well-organized dataset for context-aware paper citation recommendation. Our model comprises a document encoder and a context encoder, which uses Graph Convolutional Networks (GCN) layer and Bidirectional Encoder Representations from Transformers (BERT), which is a pre-trained model of textual data. By modifying the related PeerRead dataset, we propose a new dataset called FullTextPeerRead containing context sentences to cited references and paper metadata. To the best of our knowledge, This dataset is the first well-organized dataset for context-aware paper recommendation. The results indicate that the proposed model with the proposed datasets can attain state-of-the-art performance and achieve a more than 28% improvement in mean average precision (MAP) and recall@k.\nWhat\u0026rsquo;s New Citation Recommendationにおいて新しいベンチマークデータセット FullTextPeerRead を構築 BERTとGCNを組み合わせたCitation Recommendationモデルを構築しSOTAを達成 Dataset Dataset (https://github.com/TeamLab/bert-gcn-for-paper-citation)\nAAN (Radev et al., 2013) 及びPeerRead (Kang et al., 2018) をベースにして新しいデータセットを構築 既存のデータセットは引用に関わる部分に関してコンテキスト情報が含まれていないため，arXiv Vanityを使用してコンテキスト情報を抽出しデータセットに追加した arXiv VanityではLatexで書かれたPDFをHTMLに変換できるので，Latexで書かれていない論文は対象外となっている arXiv Vanityから機械的に収集したデータはノイズが多いため，手動でデータをクリーニング Radev et al. (2013) Dragomir R. Radev, Pradeep Muthukrishnan, Vahed Qazvinian, Amjad Abu-Jbara. (2013)\nThe ACL anthology network corpus\nLang. Resour. Evaluation\nPaper Link\nInfluential Citation Count (50), SS-ID (e01eae8dea6fbaa1ae7fc83535053932268df430) Kang et al. (2018) Dongyeop Kang, Waleed Ammar, Bhavana Dalvi, Madeleine van Zuylen, Sebastian Kohlmeier, E. Hovy, Roy Schwartz. (2018)\nA Dataset of Peer Reviews (PeerRead): Collection, Insights and NLP Applications\nNAACL\nPaper Link\nInfluential Citation Count (19), SS-ID (53489041a08ef1a6cd19b4c95ce092a148283b6b)\nABSTRACT\nPeer reviewing is a central component in the scientific publishing process. We present the first public dataset of scientific peer reviews available for research purposes (PeerRead v1),1 providing an opportunity to study this important artifact. The dataset consists of 14.7K paper drafts and the corresponding accept/reject decisions in top-tier venues including ACL, NIPS and ICLR. The dataset also includes 10.7K textual peer reviews written by experts for a subset of the papers. We describe the data collection process and report interesting observed phenomena in the peer reviews. We also propose two novel NLP tasks based on this dataset and provide simple baseline models. In the first task, we show that simple models can predict whether a paper is accepted with up to 21% error reduction compared to the majority baseline. In the second task, we predict the numerical scores of review aspects and show that simple models can outperform the mean baseline for aspects with high variance such as ‘originality’ and ‘impact’.\nDataset Statistics Model Description Training Settings Results Main Results ベースラインモデルのCACR (Yang et al., 2018) に比べて高い精度を達成 Yang et al. (2018) Libin Yang, Yu Zheng, Xiaoyan Cai, Hang Dai, Dejun Mu, Lantian Guo, Tao Dai. (2018)\nA LSTM Based Model for Personalized Context-Aware Citation Recommendation\nIEEE Access\nPaper Link\nInfluential Citation Count (3), SS-ID (52020530c72e189ca0d295e611063a0aaa9109c2)\nABSTRACT\nThe rapid growth of scientific papers makes it difficult to find relevant and appropriate citations. Context-aware citation recommendation aims to overcome this problem by providing a list of scientific papers given a short passage of text. In this paper, we propose a long–short-term memory (LSTM)-based model for context-aware citation recommendation, which first learns the distributed representations of the citation contexts and the scientific papers separately based on LSTM, and then measures the relevance based on the learned distributed representation of citation contexts and the scientific papers. Finally, the scientific papers with high relevance scores are selected as the recommendation list. In particular, we try to incorporate author information, venue information, and content information in scientific paper distributed vector representation. Furthermore, we integrate author information of the given context in citation context distributed vector representation. Thus, the proposed model makes personalized context-aware citation recommendation possible, which is a new issue that few papers addressed in the past. When conducting experiments on the ACL Anthology Network and DBLP data sets, the results demonstrate the proposed LSTM-based model for context-aware citation recommendation is able to achieve considerable improvement over previous context-aware citation recommendation approaches. The personalized recommendation approach is also competitive with the non-personalized recommendation approach.\nAblation Study 全ての場合において，GCNを追加した方が精度が向上した GCNは入力単語・文章の数が少ない方がモデルに対するインパクトは大きくなる コンテキストの長さが一定数以上を超えるとモデルの精度の上昇幅は緩やかになっていく 引用頻度が高くなるほどモデルの精度は向上する References Context-Based Collaborative Filtering for Citation Recommendation (Haifeng Liu et al., 2015) Haifeng Liu, Xiangjie Kong, Xiaomei Bai, Wei Wang, T. M. Bekele, Feng Xia. (2015)\nContext-Based Collaborative Filtering for Citation Recommendation\nIEEE Access\nPaper Link\nInfluential Citation Count (6), SS-ID (0fb67f88fed7dc3592653a892eee2b8697806451)\nABSTRACT\nCitation recommendation is an interesting and significant research area as it solves the information overload in academia by automatically suggesting relevant references for a research paper. Recently, with the rapid proliferation of information technology, research papers are rapidly published in various conferences and journals. This makes citation recommendation a highly important and challenging discipline. In this paper, we propose a novel citation recommendation method that uses only easily obtained citation relations as source data. The rationale underlying this method is that, if two citing papers are significantly co-occurring with the same citing paper(s), they should be similar to some extent. Based on the above rationale, an association mining technique is employed to obtain the paper representation of each citing paper from the citation context. Then, these paper representations are pairwise compared to compute similarities between the citing papers for collaborative filtering. We evaluate our proposed method through two relevant real-world data sets. Our experimental results demonstrate that the proposed method significantly outperforms the baseline method in terms of precision, recall, and F1, as well as mean average precision and mean reciprocal rank, which are metrics related to the rank information in the recommendation list.\nDiscourse Segmentation of Multi-Party Conversation (Michel Galley et al., 2003) Michel Galley, K. McKeown, E. Fosler-Lussier, Hongyan Jing. (2003)\nDiscourse Segmentation of Multi-Party Conversation\nACL\nPaper Link\nInfluential Citation Count (73), SS-ID (118a331364f30592d12eafe9af8a8c84b59b961c)\nABSTRACT\nWe present a domain-independent topic segmentation algorithm for multi-party speech. Our feature-based algorithm combines knowledge about content using a text-based algorithm as a feature and about form using linguistic and acoustic cues about topic shifts extracted from speech. This segmentation algorithm uses automatically induced decision rules to combine the different features. The embedded text-based algorithm builds on lexical cohesion and has performance comparable to state-of-the-art algorithms based on lexical information. A significant error reduction is obtained by combining the two knowledge sources.\nStochastic Inversion Transduction Grammars and Bilingual Parsing of Parallel Corpora (Dekai Wu, 1997) Dekai Wu. (1997)\nStochastic Inversion Transduction Grammars and Bilingual Parsing of Parallel Corpora\nComput. Linguistics\nPaper Link\nInfluential Citation Count (114), SS-ID (13b6eeb28328252a35cdcbe3ab8d09d2a9caf99d)\nABSTRACT\nWe introduce (1) a novel stochastic inversion transduction grammar formalism for bilingual language modeling of sentence-pairs, and (2) the concept of bilingual parsing with a variety of parallel corpus analysis applications. Aside from the bilingual orientation, three major features distinguish the formalism from the finite-state transducers more traditionally found in computational linguistics: it skips directly to a context-free rather than finite-state base, it permits a minimal extra degree of ordering flexibility, and its probabilistic formulation admits an efficient maximum-likelihood bilingual parsing algorithm. A convenient normal form is shown to exist. Analysis of the formalism\u0026rsquo;s expressiveness suggests that it is particularly well suited to modeling ordering shifts between languages, balancing needed flexibility against complexity constraints. We discuss a number of examples of how stochastic inversion transduction grammars bring bilingual constraints to bear upon problematic corpus analysis tasks such as segmentation, bracketing, phrasal alignment, and parsing.\nQuoteRec: Toward Quote Recommendation for Writing (Jiwei Tan et al., 2018) Jiwei Tan, Xiaojun Wan, Hui Liu, Jianguo Xiao. (2018)\nQuoteRec: Toward Quote Recommendation for Writing\nACM Trans. Inf. Syst.\nPaper Link\nInfluential Citation Count (2), SS-ID (15b09272a3b7476ca4b1fbfdac5675797b3c3ff7)\nABSTRACT\nQuote is a language phenomenon of transcribing the statement of someone else, such as a proverb and a famous saying. An appropriate usage of quote usually equips the expression with more elegance and credibility. However, there are times when we are eager to stress our idea by citing a quote, while nothing relevant comes to mind. Therefore, it is exciting to have a recommender system which provides quote recommendations while we are writing. This article extends previous study of quote recommendation, the task that recommends the appropriate quote according to the context (i.e., the content occurring before and after the quote). In this article, a quote recommender system called QuoteRec is presented to tackle the task. We investigate two models to learn the vector representations of quotes and contexts, and then rank the candidate quotes based on the representations. The first model learns the quote representation according to the contexts of a quote. The second model is an extension of the neural network model in previous study, which learns the representation of a quote by concerning both its content and contexts. Experimental results demonstrate the effectiveness of the two models in learning the semantic representations of quotes, and the neural network model achieves state-of-the-art results on the quote recommendation task.\nMeasuring contextual citation impact of scientific journals (H. Moed, 2009) H. Moed. (2009)\nMeasuring contextual citation impact of scientific journals\nJ. Informetrics\nPaper Link\nInfluential Citation Count (50), SS-ID (172aed103a885735bce827fee4a24bed30eefd9e)\nABSTRACT\nCitation recommendation without author supervision (Qi He et al., 2011) Qi He, Daniel Kifer, J. Pei, P. Mitra, C. Lee Giles. (2011)\nCitation recommendation without author supervision\nWSDM \u0026lsquo;11\nPaper Link\nInfluential Citation Count (10), SS-ID (1954a67069a6744cc6c85f258c430431118a9916)\nABSTRACT\nAutomatic recommendation of citations for a manuscript is highly valuable for scholarly activities since it can substantially improve the efficiency and quality of literature search. The prior techniques placed a considerable burden on users, who were required to provide a representative bibliography or to mark passages where citations are needed. In this paper we present a system that considerably reduces this burden: a user simply inputs a query manuscript (without a bibliography) and our system automatically finds locations where citations are needed. We show that naïve approaches do not work well due to massive noise in the document corpus. We produce a successful approach by carefully examining the relevance between segments in a query manuscript and the representative segments extracted from a document corpus. An extensive empirical evaluation using the CiteSeerX data set shows that our approach is effective.\nMinimum Error Rate Training in Statistical Machine Translation (F. Och, 2003) F. Och. (2003)\nMinimum Error Rate Training in Statistical Machine Translation\nACL\nPaper Link\nInfluential Citation Count (487), SS-ID (1f12451245667a85d0ee225a80880fc93c71cc8b)\nABSTRACT\nOften, the training procedure for statistical machine translation models is based on maximum likelihood or related criteria. A general problem of this approach is that there is only a loose relation to the final translation quality on unseen text. In this paper, we analyze various training criteria which directly optimize translation quality. These training criteria make use of recently proposed automatic evaluation metrics. We describe a new algorithm for efficient training an unsmoothed error count. We show that significantly better results can often be obtained if the final evaluation criterion is taken directly into account as part of the training procedure.\nProceedings of the 19th international conference on World wide web (M. Rappa et al., 2010) M. Rappa, Paul Jones, J. Freire, Soumen Chakrabarti. (2010)\nProceedings of the 19th international conference on World wide web\nWWW 2010\nPaper Link\nInfluential Citation Count (16), SS-ID (2829bdbb2950b4eac1c43aa0f627a7bb14c9a775)\nABSTRACT\nWelcome to the World Wide Web Conference held during April 26-30, 2010, at the Raleigh Convention Center in Raleigh, North Carolina, USA. The WWW Conference is the largest and premier annual forum where researchers and developers from around the world assemble to share, discuss and debate the latest developments on Web technologies and standards and the Web\u0026rsquo;s impact on society and culture. We are pleased to present the proceedings of the conference as its published record. Based on input from several office holders in recent WWW conferences, we implemented a number of modifications in the review process this time. In earlier years, WWW used a partitioned track system, and each paper was sent to exactly one track. This year, we implemented a system of overlapping (broad) areas and (fine) topics. Each broad area was represented by at least two, but often more, area chairs (ACs), who helped recruit the rest of the program committee (PC) members, but PC members were not partitioned by area. Each paper could potentially be assigned to any PC member. We downloaded a number of recent papers by each PC member to create a profile, and used its similarity with each submitted paper as one signal into the paper assignment process, while paying close attention to bids for papers by PC members. The assignments were then fine-tuned by the ACs. Each paper was first reviewed by three PC members. Then the ACs initiated discussions, solicited additional reviews if needed, and wrote at least one meta-review per paper summarizing and justifying the final decision. For most papers, the ACs had a confident decision before the PC meeting held 14-15th January. At this meeting, particularly complicated decisions were made and reviewed. Overall, we believe the two-tier review process ensures in-depth, reliable and fair evaluations. Other new features include a new demo track, where anyone, not just industrial exhibitors, can show a working system, and a new category of Application and Experience (A+E) papers that were reviewed for merit in design, implementation, benchmarking or extensive experience, as distinct from a core technical idea as in regular research submissions. Some A+E papers were nominated for demos. Other tracks for posters, tutorials, workshops, and developers were run as usual, separate from the research track. 754 research papers were submitted. Of these, 91 were accepted as regular research papers and 14 were accepted as A+E papers. A total of 24 tutorials were proposed and 11 accepted. A total of 19 workshops were proposed and 11 were accepted. A total of 90 posters and 27 demos will be exhibited.\nSemi-Supervised Classification with Graph Convolutional Networks (Thomas Kipf et al., 2016) Thomas Kipf, M. Welling. (2016)\nSemi-Supervised Classification with Graph Convolutional Networks\nICLR\nPaper Link\nInfluential Citation Count (3166), SS-ID (36eff562f65125511b5dfab68ce7f7a943c27478)\nABSTRACT\nWe present a scalable approach for semi-supervised learning on graph-structured data that is based on an efficient variant of convolutional neural networks which operate directly on graphs. We motivate the choice of our convolutional architecture via a localized first-order approximation of spectral graph convolutions. Our model scales linearly in the number of graph edges and learns hidden layer representations that encode both local graph structure and features of nodes. In a number of experiments on citation networks and on a knowledge graph dataset we demonstrate that our approach outperforms related methods by a significant margin.\nContext-aware citation recommendation (Qi He et al., 2010) Qi He, J. Pei, Daniel Kifer, P. Mitra, C. Lee Giles. (2010)\nContext-aware citation recommendation\nWWW \u0026lsquo;10\nPaper Link\nInfluential Citation Count (32), SS-ID (3c0312918ac9fea614abaa0732d83f3e76c16f7d)\nABSTRACT\nWhen you write papers, how many times do you want to make some citations at a place but you are not sure which papers to cite? Do you wish to have a recommendation system which can recommend a small number of good candidates for every place that you want to make some citations? In this paper, we present our initiative of building a context-aware citation recommendation system. High quality citation recommendation is challenging: not only should the citations recommended be relevant to the paper under composition, but also should match the local contexts of the places citations are made. Moreover, it is far from trivial to model how the topic of the whole paper and the contexts of the citation places should affect the selection and ranking of citations. To tackle the problem, we develop a context-aware approach. The core idea is to design a novel non-parametric probabilistic model which can measure the context-based relevance between a citation context and a document. Our approach can recommend citations for a context effectively. Moreover, it can recommend a set of citations for a paper with high quality. We implement a prototype system in CiteSeerX. An extensive empirical evaluation in the CiteSeerX digital library against many baselines demonstrates the effectiveness and the scalability of our approach.\nStochastic Backpropagation and Approximate Inference in Deep Generative Models (Danilo Jimenez Rezende et al., 2014) Danilo Jimenez Rezende, S. Mohamed, Daan Wierstra. (2014)\nStochastic Backpropagation and Approximate Inference in Deep Generative Models\nICML\nPaper Link\nInfluential Citation Count (640), SS-ID (484ad17c926292fbe0d5211540832a8c8a8e958b)\nABSTRACT\nWe marry ideas from deep neural networks and approximate Bayesian inference to derive a generalised class of deep, directed generative models, endowed with a new algorithm for scalable inference and learning. Our algorithm introduces a recognition model to represent approximate posterior distributions, and that acts as a stochastic encoder of the data. We develop stochastic back-propagation \u0026ndash; rules for back-propagation through stochastic variables \u0026ndash; and use this to develop an algorithm that allows for joint optimisation of the parameters of both the generative and recognition model. We demonstrate on several real-world data sets that the model generates realistic samples, provides accurate imputations of missing data and is a useful tool for high-dimensional data visualisation.\nA LSTM Based Model for Personalized Context-Aware Citation Recommendation (Libin Yang et al., 2018) Libin Yang, Yu Zheng, Xiaoyan Cai, Hang Dai, Dejun Mu, Lantian Guo, Tao Dai. (2018)\nA LSTM Based Model for Personalized Context-Aware Citation Recommendation\nIEEE Access\nPaper Link\nInfluential Citation Count (3), SS-ID (52020530c72e189ca0d295e611063a0aaa9109c2)\nABSTRACT\nThe rapid growth of scientific papers makes it difficult to find relevant and appropriate citations. Context-aware citation recommendation aims to overcome this problem by providing a list of scientific papers given a short passage of text. In this paper, we propose a long–short-term memory (LSTM)-based model for context-aware citation recommendation, which first learns the distributed representations of the citation contexts and the scientific papers separately based on LSTM, and then measures the relevance based on the learned distributed representation of citation contexts and the scientific papers. Finally, the scientific papers with high relevance scores are selected as the recommendation list. In particular, we try to incorporate author information, venue information, and content information in scientific paper distributed vector representation. Furthermore, we integrate author information of the given context in citation context distributed vector representation. Thus, the proposed model makes personalized context-aware citation recommendation possible, which is a new issue that few papers addressed in the past. When conducting experiments on the ACL Anthology Network and DBLP data sets, the results demonstrate the proposed LSTM-based model for context-aware citation recommendation is able to achieve considerable improvement over previous context-aware citation recommendation approaches. The personalized recommendation approach is also competitive with the non-personalized recommendation approach.\nA scientometric review of emerging trends and new developments in recommendation systems (Meen Chul Kim et al., 2015) Meen Chul Kim, Chaomei Chen. (2015)\nA scientometric review of emerging trends and new developments in recommendation systems\nScientometrics\nPaper Link\nInfluential Citation Count (6), SS-ID (52c22ac616688491ce58c0f9f25c2cef81aacba1)\nABSTRACT\nA Dataset of Peer Reviews (PeerRead): Collection, Insights and NLP Applications (Dongyeop Kang et al., 2018) Dongyeop Kang, Waleed Ammar, Bhavana Dalvi, Madeleine van Zuylen, Sebastian Kohlmeier, E. Hovy, Roy Schwartz. (2018)\nA Dataset of Peer Reviews (PeerRead): Collection, Insights and NLP Applications\nNAACL\nPaper Link\nInfluential Citation Count (19), SS-ID (53489041a08ef1a6cd19b4c95ce092a148283b6b)\nABSTRACT\nPeer reviewing is a central component in the scientific publishing process. We present the first public dataset of scientific peer reviews available for research purposes (PeerRead v1),1 providing an opportunity to study this important artifact. The dataset consists of 14.7K paper drafts and the corresponding accept/reject decisions in top-tier venues including ACL, NIPS and ICLR. The dataset also includes 10.7K textual peer reviews written by experts for a subset of the papers. We describe the data collection process and report interesting observed phenomena in the peer reviews. We also propose two novel NLP tasks based on this dataset and provide simple baseline models. In the first task, we show that simple models can predict whether a paper is accepted with up to 21% error reduction compared to the majority baseline. In the second task, we predict the numerical scores of review aspects and show that simple models can outperform the mean baseline for aspects with high variance such as ‘originality’ and ‘impact’.\nVariational Graph Auto-Encoders (Thomas Kipf et al., 2016) Thomas Kipf, M. Welling. (2016)\nVariational Graph Auto-Encoders\nArXiv\nPaper Link\nInfluential Citation Count (353), SS-ID (54906484f42e871f7c47bbfe784a358b1448231f)\nABSTRACT\nWe introduce the variational graph auto-encoder (VGAE), a framework for unsupervised learning on graph-structured data based on the variational auto-encoder (VAE). This model makes use of latent variables and is capable of learning interpretable latent representations for undirected graphs. We demonstrate this model using a graph convolutional network (GCN) encoder and a simple inner product decoder. Our model achieves competitive results on a link prediction task in citation networks. In contrast to most existing models for unsupervised learning on graph-structured data and link prediction, our model can naturally incorporate node features, which significantly improves predictive performance on a number of benchmark datasets.\nA bibliometric and network analysis of the field of computational linguistics (Dragomir R. Radev et al., 2015) Dragomir R. Radev, M. Joseph, B. Gibson, Pradeep Muthukrishnan. (2015)\nA bibliometric and network analysis of the field of computational linguistics\nJ. Assoc. Inf. Sci. Technol.\nPaper Link\nInfluential Citation Count (1), SS-ID (7300b624588c62fb5af4fbd948969c8803b28d46)\nABSTRACT\nThe ACL Anthology is a large collection of research papers in computational linguistics. Citation data were obtained using text extraction from a collection of PDF files with significant manual postprocessing performed to clean up the results. Manual annotation of the references was then performed to complete the citation network. We analyzed the networks of paper citations, author citations, and author collaborations in an attempt to identify the most central papers and authors. The analysis includes general network statistics, PageRank, metrics across publication years and venues, the impact factor and h‐index, as well as other measures.\nLearning Convolutional Neural Networks for Graphs (Mathias Niepert et al., 2016) Mathias Niepert, Mohamed Ahmed, Konstantin Kutzkov. (2016)\nLearning Convolutional Neural Networks for Graphs\nICML\nPaper Link\nInfluential Citation Count (136), SS-ID (7c6de5a9e02a779e24504619050c6118f4eac181)\nABSTRACT\nNumerous important problems can be framed as learning from graph data. We propose a framework for learning convolutional neural networks for arbitrary graphs. These graphs may be undirected, directed, and with both discrete and continuous node and edge attributes. Analogous to image-based convolutional networks that operate on locally connected regions of the input, we present a general approach to extracting locally connected regions from graphs. Using established benchmark data sets, we demonstrate that the learned feature representations are competitive with state of the art graph kernels and that their computation is highly efficient.\nPredicting the citations of scholarly paper (Xiaomei Bai et al., 2019) Xiaomei Bai, Fuli Zhang, Ivan Lee. (2019)\nPredicting the citations of scholarly paper\nJ. Informetrics\nPaper Link\nInfluential Citation Count (0), SS-ID (7f57a5bdbf6c711c711e1901864eaa4237b01f9f)\nABSTRACT\nInferring Dynamic User Interests in Streams of Short Texts for User Clustering (Shangsong Liang et al., 2017) Shangsong Liang, Z. Ren, Yukun Zhao, Jun Ma, Emine Yilmaz, M. de Rijke. (2017)\nInferring Dynamic User Interests in Streams of Short Texts for User Clustering\nACM Trans. Inf. Syst.\nPaper Link\nInfluential Citation Count (0), SS-ID (803a6b4333302fae7d05f2e2e196954540db2b01)\nABSTRACT\nUser clustering has been studied from different angles. In order to identify shared interests, behavior-based methods consider similar browsing or search patterns of users, whereas content-based methods use information from the contents of the documents visited by the users. So far, content-based user clustering has mostly focused on static sets of relatively long documents. Given the dynamic nature of social media, there is a need to dynamically cluster users in the context of streams of short texts. User clustering in this setting is more challenging than in the case of long documents, as it is difficult to capture the users’ dynamic topic distributions in sparse data settings. To address this problem, we propose a dynamic user clustering topic model (UCT). UCT adaptively tracks changes of each user’s time-varying topic distributions based both on the short texts the user posts during a given time period and on previously estimated distributions. To infer changes, we propose a Gibbs sampling algorithm where a set of word pairs from each user is constructed for sampling. UCT can be used in two ways: (1) as a short-term dependency model that infers a user’s current topic distribution based on the user’s topic distributions during the previous time period only, and (2) as a long-term dependency model that infers a user’s current topic distributions based on the user’s topic distributions during multiple time periods in the past. The clustering results are explainable and human-understandable, in contrast to many other clustering algorithms. For evaluation purposes, we work with a dataset consisting of users and tweets from each user. Experimental results demonstrate the effectiveness of our proposed short-term and long-term dependency user clustering models compared to state-of-the-art baselines.\nCross-language context-aware citation recommendation in scientific articles (Xuewei Tang et al., 2014) Xuewei Tang, Xiaojun Wan, Xun Zhang. (2014)\nCross-language context-aware citation recommendation in scientific articles\nSIGIR\nPaper Link\nInfluential Citation Count (2), SS-ID (851332942f7cfbd74e3f2799309c1383fa547fb6)\nABSTRACT\nAdequacy of citations is very important for a scientific paper. However, it is not an easy job to find appropriate citations for a given context, especially for citations in different languages. In this paper, we define a novel task of cross-language context-aware citation recommendation, which aims at recommending English citations for a given context of the place where a citation is made in a Chinese paper. This task is very challenging because the contexts and citations are written in different languages and there exists a language gap when matching them. To tackle this problem, we propose the bilingual context-citation embedding algorithm (i.e. BLSRec-I), which can learn a low-dimensional joint embedding space for both contexts and citations. Moreover, two advanced algorithms named BLSRec-II and BLSRec-III are proposed by enhancing BLSRec-I with translation results and abstract information, respectively. We evaluate the proposed methods based on a real dataset that contains Chinese contexts and English citations. The results demonstrate that our proposed algorithms can outperform a few baselines and the BLSRec-II and BLSRec-III methods can outperform the BLSRec-I method.\nNeural Citation Network for Context-Aware Citation Recommendation (Travis Ebesu et al., 2017) Travis Ebesu, Yi Fang. (2017)\nNeural Citation Network for Context-Aware Citation Recommendation\nSIGIR\nPaper Link\nInfluential Citation Count (15), SS-ID (a191c41607ce88e731fe8fc08faf6677c1f47903)\nABSTRACT\nThe accelerating rate of scientific publications makes it difficult to find relevant citations or related work. Context-aware citation recommendation aims to solve this problem by providing a curated list of high-quality candidates given a short passage of text. Existing literature adopts bag-of-word representations leading to the loss of valuable semantics and lacks the ability to integrate metadata or generalize to unseen manuscripts in the training set. We propose a flexible encoder-decoder architecture called Neural Citation Network (NCN), embodying a robust representation of the citation context with a max time delay neural network, further augmented with an attention mechanism and author networks. The recurrent neural network decoder consults this representation when determining the optimal paper to recommend based solely on its title. Quantitative results on the large-scale CiteSeer dataset reveal NCN cultivates a significant improvement over competitive baselines. Qualitative evidence highlights the effectiveness of the proposed end-to-end neural network revealing a promising research direction for citation recommendation.\nA Maximum Entropy Model for Part-Of-Speech Tagging (A. Ratnaparkhi, 1996) A. Ratnaparkhi. (1996)\nA Maximum Entropy Model for Part-Of-Speech Tagging\nEMNLP\nPaper Link\nInfluential Citation Count (110), SS-ID (a574e320d899e7e82e341eb64baef7dfe8a24642)\nABSTRACT\nThis paper presents a statistical model which trains from a corpus annotated with Part Of Speech tags and assigns them to previously unseen text with state of the art accuracy The model can be classi ed as a Maximum Entropy model and simultaneously uses many contextual features to predict the POS tag Furthermore this paper demonstrates the use of specialized fea tures to model di cult tagging decisions discusses the corpus consistency problems discovered during the implementation of these features and proposes a training strategy that mitigates these problems\nAdam: A Method for Stochastic Optimization (Diederik P. Kingma et al., 2014) Diederik P. Kingma, Jimmy Ba. (2014)\nAdam: A Method for Stochastic Optimization\nICLR\nPaper Link\nInfluential Citation Count (14742), SS-ID (a6cb366736791bcccc5c8639de5a8f9636bf87e8)\nABSTRACT\nWe introduce Adam, an algorithm for first-order gradient-based optimization of stochastic objective functions, based on adaptive estimates of lower-order moments. The method is straightforward to implement, is computationally efficient, has little memory requirements, is invariant to diagonal rescaling of the gradients, and is well suited for problems that are large in terms of data and/or parameters. The method is also appropriate for non-stationary objectives and problems with very noisy and/or sparse gradients. The hyper-parameters have intuitive interpretations and typically require little tuning. Some connections to related algorithms, on which Adam was inspired, are discussed. We also analyze the theoretical convergence properties of the algorithm and provide a regret bound on the convergence rate that is comparable to the best known results under the online convex optimization framework. Empirical results demonstrate that Adam works well in practice and compares favorably to other stochastic optimization methods. Finally, we discuss AdaMax, a variant of Adam based on the infinity norm.\nLanguage Resources and Evaluation (N. Calzolari, 1966) N. Calzolari. (1966)\nLanguage Resources and Evaluation\nPaper Link\nInfluential Citation Count (4), SS-ID (b7c42dcbefb9ff13d17d2b3bf3fb38ae3bfcebd5)\nABSTRACT\nStatistical Significance Tests for Machine Translation Evaluation (Philipp Koehn, 2004) Philipp Koehn. (2004)\nStatistical Significance Tests for Machine Translation Evaluation\nEMNLP\nPaper Link\nInfluential Citation Count (124), SS-ID (cb826a3899752b796f14df1c50378c64954a6b0a)\nABSTRACT\nIf two translation systems differ differ in performance on a test set, can we trust that this indicates a difference in true system quality? To answer this question, we describe bootstrap resampling methods to compute statistical significance of test results, and validate them on the concrete example of the BLEU score. Even for small test sizes of only 300 sentences, our methods may give us assurances that test result differences are real.\nText Tiling: Segmenting Text into Multi-paragraph Subtopic Passages (Marti A. Hearst, 1997) Marti A. Hearst. (1997)\nText Tiling: Segmenting Text into Multi-paragraph Subtopic Passages\nCL\nPaper Link\nInfluential Citation Count (197), SS-ID (cb91a9ef1723440bd35a3e5965a2e180ad1ab36f)\nABSTRACT\nTextTiling is a technique for subdividing texts into multi-paragraph units that represent passages, or subtopics. The discourse cues for identifying major subtopic shifts are patterns of lexical co-occurrence and distribution. The algorithm is fully implemented and is shown to produce segmentation that corresponds well to human judgments of the subtopic boundaries of 12 texts. Multi-paragraph subtopic segmentation should be useful for many text analysis tasks, including information retrieval and summarization.\nBERT: Pre-training of Deep Bidirectional Transformers for Language Understanding (Jacob Devlin et al., 2019) Jacob Devlin, Ming-Wei Chang, Kenton Lee, Kristina Toutanova. (2019)\nBERT: Pre-training of Deep Bidirectional Transformers for Language Understanding\nNAACL\nPaper Link\nInfluential Citation Count (10235), SS-ID (df2b0e26d0599ce3e70df8a9da02e51594e0e992)\nABSTRACT\nWe introduce a new language representation model called BERT, which stands for Bidirectional Encoder Representations from Transformers. Unlike recent language representation models (Peters et al., 2018a; Radford et al., 2018), BERT is designed to pre-train deep bidirectional representations from unlabeled text by jointly conditioning on both left and right context in all layers. As a result, the pre-trained BERT model can be fine-tuned with just one additional output layer to create state-of-the-art models for a wide range of tasks, such as question answering and language inference, without substantial task-specific architecture modifications. BERT is conceptually simple and empirically powerful. It obtains new state-of-the-art results on eleven natural language processing tasks, including pushing the GLUE score to 80.5 (7.7 point absolute improvement), MultiNLI accuracy to 86.7% (4.6% absolute improvement), SQuAD v1.1 question answering Test F1 to 93.2 (1.5 point absolute improvement) and SQuAD v2.0 Test F1 to 83.1 (5.1 point absolute improvement).\nThe ACL anthology network corpus (Dragomir R. Radev et al., 2013) Dragomir R. Radev, Pradeep Muthukrishnan, Vahed Qazvinian, Amjad Abu-Jbara. (2013)\nThe ACL anthology network corpus\nLang. Resour. Evaluation\nPaper Link\nInfluential Citation Count (50), SS-ID (e01eae8dea6fbaa1ae7fc83535053932268df430)\nABSTRACT\nA Neural Probabilistic Model for Context Based Citation Recommendation (W. Huang et al., 2015) W. Huang, Zhaohui Wu, Chen Liang, P. Mitra, C. Lee Giles. (2015)\nA Neural Probabilistic Model for Context Based Citation Recommendation\nAAAI\nPaper Link\nInfluential Citation Count (14), SS-ID (e5aa3cf6d6521ca67a49cb7c7e13cbd914f83bf8)\nABSTRACT\nAutomatic citation recommendation can be very useful for authoring a paper and is an AI-complete problem due to the challenge of bridging the semantic gap between citation context and the cited paper. It is not always easy for knowledgeable researchers to give an accurate citation context for a cited paper or to find the right paper to cite given context. To help with this problem, we propose a novel neural probabilistic model that jointly learns the semantic representations of citation contexts and cited papers. The probability of citing a paper given a citation context is estimated by training a multi-layer neural network. We implement and evaluate our model on the entire CiteSeer dataset, which at the time of this work consists of 10,760,318 citation contexts from 1,017,457 papers. We show that the proposed model significantly outperforms other state-of-the-art models in recall, MAP, MRR, and nDCG.\nAnalyzing the performance of top-k retrieval algorithms (M. Fontoura et al., -1) M. Fontoura, Daat Document-at-a-time, Taat Term-at-a-time. (-1)\nAnalyzing the performance of top-k retrieval algorithms\nPaper Link\nInfluential Citation Count (0), SS-ID (ebb5f4273e461e21db6afcdbca698295cb0d21e1)\nABSTRACT\nProceedings of the 2018 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies, Volume 3 (Industry Papers) (M. Walker et al., 2018) M. Walker, Heng Ji, Amanda Stent. (2018)\nProceedings of the 2018 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies, Volume 3 (Industry Papers)\nNAACL 2018\nPaper Link\nInfluential Citation Count (5), SS-ID (ed2b7bfbbf5e48d750d7c3e0046e55341cecd335)\nABSTRACT\nMulti-Paragraph Segmentation of Expository Texts (Marti A. Hearst, 1994) Marti A. Hearst. (1994)\nMulti-Paragraph Segmentation of Expository Texts\nPaper Link\nInfluential Citation Count (9), SS-ID (f1626b2b04237165f14701be43ca38e91cb04464)\nABSTRACT\nWe present a method for partitioning expository texts into coherent multi-paragraph units which re ect the subtopic structure of the texts. Using Chafe\u0026rsquo;s Flow Model of discourse, we observe that subtopics are often expressed by the interaction of multiple simultaneous themes. We describe two fully-implemented algorithms that use only term repetition information to determine the extents of the subtopics. We show that the segments correspond well to human judgements of the major subtopic boundaries of thirteen lengthy texts, and suggest the use of such segments in information retrieval applications.\nDistributed Representations of Sentences and Documents (Quoc V. Le et al., 2014) Quoc V. Le, Tomas Mikolov. (2014)\nDistributed Representations of Sentences and Documents\nICML\nPaper Link\nInfluential Citation Count (953), SS-ID (f527bcfb09f32e6a4a8afc0b37504941c1ba2cee)\nABSTRACT\nMany machine learning algorithms require the input to be represented as a fixed-length feature vector. When it comes to texts, one of the most common fixed-length features is bag-of-words. Despite their popularity, bag-of-words features have two major weaknesses: they lose the ordering of the words and they also ignore semantics of the words. For example, \u0026ldquo;powerful,\u0026rdquo; \u0026ldquo;strong\u0026rdquo; and \u0026ldquo;Paris\u0026rdquo; are equally distant. In this paper, we propose Paragraph Vector, an unsupervised algorithm that learns fixed-length feature representations from variable-length pieces of texts, such as sentences, paragraphs, and documents. Our algorithm represents each document by a dense vector which is trained to predict words in the document. Its construction gives our algorithm the potential to overcome the weaknesses of bag-of-words models. Empirical results show that Paragraph Vectors outperforms bag-of-words models as well as other techniques for text representations. Finally, we achieve new state-of-the-art results on several text classification and sentiment analysis tasks.\n","date":"May 18, 2022","hero":"/blog-akitenkrad/posts/papers/202205/20220518224923/hero.png","permalink":"https://akitenkrad.github.io/blog-akitenkrad/posts/papers/202205/20220518224923/","summary":"Round-1: Overview Round-2: Model Implementation Details Round-3: Experiments Citation Jeong, C., Jang, S., Shin, H., Park, E., \u0026amp; Choi, S. (2019).\nA Context-Aware Citation Recommendation Model with BERT and Graph Convolutional Networks.\nhttps://doi.org/10.48550/arxiv.1903.06464 Abstract With the tremendous growth in the number of scientific papers being published, searching for references while writing a scientific paper is a time-consuming process. A technique that could add a reference citation at the appropriate place in a sentence will be beneficial.","tags":["At:Round-1","Published:2019","Citation Recommendation","DS:FullTextPeerRead","BERT","Graph Convolutional Network"],"title":"A Context-Aware Citation Recommendation Model with BERT and Graph Convolutional Networks"},{"categories":null,"contents":" Round-1: Overview Round-2: Model Implementation Details Round-3: Experiments Citation Cheng, H., Shen, Y., Liu, X., He, P., Chen, W., \u0026amp; Gao, J. (2021).\nUnitedQA: A Hybrid Approach for Open Domain Question Answering.\nhttps://doi.org/10.48550/arxiv.2101.00178 Abstract To date, most of recent work under the retrieval-reader framework for open-domain QA focuses on either extractive or generative reader exclusively. In this paper, we study a hybrid approach for leveraging the strengths of both models. We apply novel techniques to enhance both extractive and generative readers built upon recent pretrained neural language models, and find that proper training methods can provide large improvement over previous state-of-the-art models. We demonstrate that a simple hybrid approach by combining answers from both readers can efficiently take advantages of extractive and generative answer inference strategies and outperforms single models as well as homogeneous ensembles. Our approach outperforms previous state-of-the-art models by 3.3 and 2.7 points in exact match on NaturalQuestions and TriviaQA respectively.\nWhat\u0026rsquo;s New Question Answeringのタスクにおいて，ExtractiveなモデルとGenerativeなモデルをアンサンブルしたUnitedQAを提案． Extractiveモデルを改善 UnitedQA-E Multi-objective for Weakly-supervised QA\nCheng et al. (2020)で提案されたmulti-objective formulationを導入 Posterior Differential Regularization\nCheng et al. (2020)で提案されたPosterior Differential Regularization (PDR)を導入 Generativeモデルを改善 UnitedQA-G Decoder Attention Bias\nデコーダとして使用しているT5のAttentionにバイアスを乗せることでロバスト性を高める Adversarial Training\n学習方法を改良 Cheng et al. (2020) - Multi-objective Hao Cheng, Ming-Wei Chang, Kenton Lee, Kristina Toutanova. (2020)\nProbabilistic Assumptions Matter: Improved Models for Distantly-Supervised Document-Level Question Answering\nACL\nPaper Link\nInfluential Citation Count (3), SS-ID (74abf8638a3dde78f20047dc72413780f2c28fb7)\nABSTRACT\nWe address the problem of extractive question answering using document-level distant super-vision, pairing questions and relevant documents with answer strings. We compare previously used probability space and distant supervision assumptions (assumptions on the correspondence between the weak answer string labels and possible answer mention spans). We show that these assumptions interact, and that different configurations provide complementary benefits. We demonstrate that a multi-objective model can efficiently combine the advantages of multiple assumptions and outperform the best individual formulation. Our approach outperforms previous state-of-the-art models by 4.3 points in F1 on TriviaQA-Wiki and 1.7 points in Rouge-L on NarrativeQA summaries.\nCheng et al. (2020) - PDR Hao Cheng, Xiaodong Liu, Lis Pereira, Yaoliang Yu, Jianfeng Gao. (2020)\nPosterior Differential Regularization with f-divergence for Improving Model Robustness\nNAACL\nPaper Link\nInfluential Citation Count (0), SS-ID (1a2bed6bed5f28095ebe5793f0c31d38690d6cd4)\nABSTRACT\nWe address the problem of enhancing model robustness through regularization. Specifically, we focus on methods that regularize the model posterior difference between clean and noisy inputs. Theoretically, we provide a connection of two recent methods, Jacobian Regularization and Virtual Adversarial Training, under this framework. Additionally, we generalize the posterior differential regularization to the family of f-divergences and characterize the overall framework in terms of the Jacobian matrix. Empirically, we compare those regularizations and standard BERT training on a diverse set of tasks to provide a comprehensive profile of their effect on model generalization. For both fully supervised and semi-supervised settings, we show that regularizing the posterior difference with f-divergence can result in well-improved model robustness. In particular, with a proper f-divergence, a BERT-base model can achieve comparable generalization as its BERT-large counterpart for in-domain, adversarial and domain shift scenarios, indicating the great potential of the proposed framework for enhancing NLP model robustness.\nDataset Natural Questions T. Kwiatkowski, Jennimaria Palomaki, Olivia Redfield, Michael Collins, Ankur P. Parikh, Chris Alberti, D. Epstein, Illia Polosukhin, Jacob Devlin, Kenton Lee, Kristina Toutanova, Llion Jones, Matthew Kelcey, Ming-Wei Chang, Andrew M. Dai, Jakob Uszkoreit, Quoc V. Le, Slav Petrov. (2019)\nNatural Questions: A Benchmark for Question Answering Research\nTACL\nPaper Link\nInfluential Citation Count (124), SS-ID (17dbd7b72029181327732e4d11b52a08ed4630d0)\nABSTRACT\nWe present the Natural Questions corpus, a question answering data set. Questions consist of real anonymized, aggregated queries issued to the Google search engine. An annotator is presented with a question along with a Wikipedia page from the top 5 search results, and annotates a long answer (typically a paragraph) and a short answer (one or more entities) if present on the page, or marks null if no long/short answer is present. The public release consists of 307,373 training examples with single annotations; 7,830 examples with 5-way annotations for development data; and a further 7,842 examples with 5-way annotated sequestered as test data. We present experiments validating quality of the data. We also describe analysis of 25-way annotations on 302 examples, giving insights into human variability on the annotation task. We introduce robust metrics for the purposes of evaluating question answering systems; demonstrate high human upper bounds on these metrics; and establish baseline results using competitive methods drawn from related literature.\nTriviaQA Mandar Joshi, Eunsol Choi, Daniel S. Weld, Luke Zettlemoyer. (2017)\nTriviaQA: A Large Scale Distantly Supervised Challenge Dataset for Reading Comprehension\nACL\nPaper Link\nInfluential Citation Count (193), SS-ID (f010affab57b5fcf1cd6be23df79d8ec98c7289c)\nABSTRACT\nWe present TriviaQA, a challenging reading comprehension dataset containing over 650K question-answer-evidence triples. TriviaQA includes 95K question-answer pairs authored by trivia enthusiasts and independently gathered evidence documents, six per question on average, that provide high quality distant supervision for answering the questions. We show that, in comparison to other recently introduced large-scale datasets, TriviaQA (1) has relatively complex, compositional questions, (2) has considerable syntactic and lexical variability between questions and corresponding answer-evidence sentences, and (3) requires more cross sentence reasoning to find answers. We also present two baseline algorithms: a feature-based classifier and a state-of-the-art neural network, that performs well on SQuAD reading comprehension. Neither approach comes close to human performance (23% and 40% vs. 80%), suggesting that TriviaQA is a challenging testbed that is worth significant future study. Data and code available at \u0026ndash; this http URL\nModel Description Training Settings Results Main Results ベースラインのモデル（REALM，RAG，DPR，T5-FID）と比較して精度を大きく向上させることに成功． Ablation Study BERTベースとELECTRAベースのモデルで提案手法を深掘り． Multi-obj，PDRともモデルの性能向上に寄与していることがわかる． References SQuAD: 100,000\u0026#43; Questions for Machine Comprehension of Text (Pranav Rajpurkar et al., 2016) Pranav Rajpurkar, Jian Zhang, Konstantin Lopyrev, Percy Liang. (2016)\nSQuAD: 100,000+ Questions for Machine Comprehension of Text\nEMNLP\nPaper Link\nInfluential Citation Count (1068), SS-ID (05dd7254b632376973f3a1b4d39485da17814df5)\nABSTRACT\nWe present the Stanford Question Answering Dataset (SQuAD), a new reading comprehension dataset consisting of 100,000+ questions posed by crowdworkers on a set of Wikipedia articles, where the answer to each question is a segment of text from the corresponding reading passage. We analyze the dataset to understand the types of reasoning required to answer the questions, leaning heavily on dependency and constituency trees. We build a strong logistic regression model, which achieves an F1 score of 51.0%, a significant improvement over a simple baseline (20%). However, human performance (86.8%) is much higher, indicating that the dataset presents a good challenge problem for future research. The dataset is freely available at this https URL\nDistilling the Knowledge in a Neural Network (Geoffrey E. Hinton et al., 2015) Geoffrey E. Hinton, Oriol Vinyals, J. Dean. (2015)\nDistilling the Knowledge in a Neural Network\nArXiv\nPaper Link\nInfluential Citation Count (1219), SS-ID (0c908739fbff75f03469d13d4a1a07de3414ee19)\nABSTRACT\nA very simple way to improve the performance of almost any machine learning algorithm is to train many different models on the same data and then to average their predictions. Unfortunately, making predictions using a whole ensemble of models is cumbersome and may be too computationally expensive to allow deployment to a large number of users, especially if the individual models are large neural nets. Caruana and his collaborators have shown that it is possible to compress the knowledge in an ensemble into a single model which is much easier to deploy and we develop this approach further using a different compression technique. We achieve some surprising results on MNIST and we show that we can significantly improve the acoustic model of a heavily used commercial system by distilling the knowledge in an ensemble of models into a single model. We also introduce a new type of ensemble composed of one or more full models and many specialist models which learn to distinguish fine-grained classes that the full models confuse. Unlike a mixture of experts, these specialist models can be trained rapidly and in parallel.\nMulti-passage BERT: A Globally Normalized BERT Model for Open-domain Question Answering (Zhiguo Wang et al., 2019) Zhiguo Wang, Patrick Ng, Xiaofei Ma, Ramesh Nallapati, Bing Xiang. (2019)\nMulti-passage BERT: A Globally Normalized BERT Model for Open-domain Question Answering\nEMNLP\nPaper Link\nInfluential Citation Count (16), SS-ID (0cf535110808d33fdf4db3ffa1621dea16e29c0d)\nABSTRACT\nBERT model has been successfully applied to open-domain QA tasks. However, previous work trains BERT by viewing passages corresponding to the same question as independent training instances, which may cause incomparable scores for answers from different passages. To tackle this issue, we propose a multi-passage BERT model to globally normalize answer scores across all passages of the same question, and this change enables our QA model find better answers by utilizing more passages. In addition, we find that splitting articles into passages with the length of 100 words by sliding window improves performance by 4%. By leveraging a passage ranker to select high-quality passages, multi-passage BERT gains additional 2%. Experiments on four standard benchmarks showed that our multi-passage BERT outperforms all state-of-the-art models on all benchmarks. In particular, on the OpenSQuAD dataset, our model gains 21.4% EM and 21.5% F1 over all non-BERT models, and 5.8% EM and 6.5% F1 over BERT-based models.\nReading Wikipedia to Answer Open-Domain Questions (Danqi Chen et al., 2017) Danqi Chen, Adam Fisch, J. Weston, Antoine Bordes. (2017)\nReading Wikipedia to Answer Open-Domain Questions\nACL\nPaper Link\nInfluential Citation Count (281), SS-ID (104715e1097b7ebee436058bfd9f45540f269845)\nABSTRACT\nThis paper proposes to tackle open- domain question answering using Wikipedia as the unique knowledge source: the answer to any factoid question is a text span in a Wikipedia article. This task of machine reading at scale combines the challenges of document retrieval (finding the relevant articles) with that of machine comprehension of text (identifying the answer spans from those articles). Our approach combines a search component based on bigram hashing and TF-IDF matching with a multi-layer recurrent neural network model trained to detect answers in Wikipedia paragraphs. Our experiments on multiple existing QA datasets indicate that (1) both modules are highly competitive with respect to existing counterparts and (2) multitask learning using distant supervision on their combination is an effective complete system on this challenging task.\nNatural Questions: A Benchmark for Question Answering Research (T. Kwiatkowski et al., 2019) T. Kwiatkowski, Jennimaria Palomaki, Olivia Redfield, Michael Collins, Ankur P. Parikh, Chris Alberti, D. Epstein, Illia Polosukhin, Jacob Devlin, Kenton Lee, Kristina Toutanova, Llion Jones, Matthew Kelcey, Ming-Wei Chang, Andrew M. Dai, Jakob Uszkoreit, Quoc V. Le, Slav Petrov. (2019)\nNatural Questions: A Benchmark for Question Answering Research\nTACL\nPaper Link\nInfluential Citation Count (124), SS-ID (17dbd7b72029181327732e4d11b52a08ed4630d0)\nABSTRACT\nWe present the Natural Questions corpus, a question answering data set. Questions consist of real anonymized, aggregated queries issued to the Google search engine. An annotator is presented with a question along with a Wikipedia page from the top 5 search results, and annotates a long answer (typically a paragraph) and a short answer (one or more entities) if present on the page, or marks null if no long/short answer is present. The public release consists of 307,373 training examples with single annotations; 7,830 examples with 5-way annotations for development data; and a further 7,842 examples with 5-way annotated sequestered as test data. We present experiments validating quality of the data. We also describe analysis of 25-way annotations on 302 examples, giving insights into human variability on the annotation task. We introduce robust metrics for the purposes of evaluating question answering systems; demonstrate high human upper bounds on these metrics; and establish baseline results using competitive methods drawn from related literature.\nPosterior Differential Regularization with f-divergence for Improving Model Robustness (Hao Cheng et al., 2020) Hao Cheng, Xiaodong Liu, Lis Pereira, Yaoliang Yu, Jianfeng Gao. (2020)\nPosterior Differential Regularization with f-divergence for Improving Model Robustness\nNAACL\nPaper Link\nInfluential Citation Count (0), SS-ID (1a2bed6bed5f28095ebe5793f0c31d38690d6cd4)\nABSTRACT\nWe address the problem of enhancing model robustness through regularization. Specifically, we focus on methods that regularize the model posterior difference between clean and noisy inputs. Theoretically, we provide a connection of two recent methods, Jacobian Regularization and Virtual Adversarial Training, under this framework. Additionally, we generalize the posterior differential regularization to the family of f-divergences and characterize the overall framework in terms of the Jacobian matrix. Empirically, we compare those regularizations and standard BERT training on a diverse set of tasks to provide a comprehensive profile of their effect on model generalization. For both fully supervised and semi-supervised settings, we show that regularizing the posterior difference with f-divergence can result in well-improved model robustness. In particular, with a proper f-divergence, a BERT-base model can achieve comparable generalization as its BERT-large counterpart for in-domain, adversarial and domain shift scenarios, indicating the great potential of the proposed framework for enhancing NLP model robustness.\nA Discrete Hard EM Approach for Weakly Supervised Question Answering (Sewon Min et al., 2019) Sewon Min, Danqi Chen, Hannaneh Hajishirzi, Luke Zettlemoyer. (2019)\nA Discrete Hard EM Approach for Weakly Supervised Question Answering\nEMNLP\nPaper Link\nInfluential Citation Count (19), SS-ID (30eff53e981695c7296d258b8dc44b4c7b482a0c)\nABSTRACT\nMany question answering (QA) tasks only provide weak supervision for how the answer should be computed. For example, TriviaQA answers are entities that can be mentioned multiple times in supporting documents, while DROP answers can be computed by deriving many different equations from numbers in the reference text. In this paper, we show it is possible to convert such tasks into discrete latent variable learning problems with a precomputed, task-specific set of possible solutions (e.g. different mentions or equations) that contains one correct option. We then develop a hard EM learning scheme that computes gradients relative to the most likely solution at each update. Despite its simplicity, we show that this approach significantly outperforms previous methods on six QA tasks, including absolute gains of 2–10%, and achieves the state-of-the-art on five of them. Using hard updates instead of maximizing marginal likelihood is key to these results as it encourages the model to find the one correct answer, which we show through detailed qualitative analysis.\nRocketQA: An Optimized Training Approach to Dense Passage Retrieval for Open-Domain Question Answering (Yingqi Qu et al., 2020) Yingqi Qu, Yuchen Ding, Jing Liu, Kai Liu, Ruiyang Ren, Xin Zhao, Daxiang Dong, Hua Wu, Haifeng Wang. (2020)\nRocketQA: An Optimized Training Approach to Dense Passage Retrieval for Open-Domain Question Answering\nNAACL\nPaper Link\nInfluential Citation Count (36), SS-ID (3416e5e5694855f7175125b5fe2e0b659c3cdbfa)\nABSTRACT\nIn open-domain question answering, dense passage retrieval has become a new paradigm to retrieve relevant passages for finding answers. Typically, the dual-encoder architecture is adopted to learn dense representations of questions and passages for semantic matching. However, it is difficult to effectively train a dual-encoder due to the challenges including the discrepancy between training and inference, the existence of unlabeled positives and limited training data. To address these challenges, we propose an optimized training approach, called RocketQA, to improving dense passage retrieval. We make three major technical contributions in RocketQA, namely cross-batch negatives, denoised hard negatives and data augmentation. The experiment results show that RocketQA significantly outperforms previous state-of-the-art models on both MSMARCO and Natural Questions. We also conduct extensive experiments to examine the effectiveness of the three strategies in RocketQA. Besides, we demonstrate that the performance of end-to-end QA can be improved based on our RocketQA retriever.\nSimple and Effective Multi-Paragraph Reading Comprehension (Christopher Clark et al., 2017) Christopher Clark, Matt Gardner. (2017)\nSimple and Effective Multi-Paragraph Reading Comprehension\nACL\nPaper Link\nInfluential Citation Count (48), SS-ID (3c78c6df5eb1695b6a399e346dde880af27d1016)\nABSTRACT\nWe consider the problem of adapting neural paragraph-level question answering models to the case where entire documents are given as input. Our proposed solution trains models to produce well calibrated confidence scores for their results on individual paragraphs. We sample multiple paragraphs from the documents during training, and use a shared-normalization training objective that encourages the model to produce globally correct output. We combine this method with a state-of-the-art pipeline for training models on document QA data. Experiments demonstrate strong performance on several document QA datasets. Overall, we are able to achieve a score of 71.3 F1 on the web portion of TriviaQA, a large improvement from the 56.7 F1 of the previous best system.\nExploring the Limits of Transfer Learning with a Unified Text-to-Text Transformer (Colin Raffel et al., 2019) Colin Raffel, Noam M. Shazeer, Adam Roberts, Katherine Lee, Sharan Narang, Michael Matena, Yanqi Zhou, Wei Li, Peter J. Liu. (2019)\nExploring the Limits of Transfer Learning with a Unified Text-to-Text Transformer\nJ. Mach. Learn. Res.\nPaper Link\nInfluential Citation Count (634), SS-ID (3cfb319689f06bf04c2e28399361f414ca32c4b3)\nABSTRACT\nTransfer learning, where a model is first pre-trained on a data-rich task before being fine-tuned on a downstream task, has emerged as a powerful technique in natural language processing (NLP). The effectiveness of transfer learning has given rise to a diversity of approaches, methodology, and practice. In this paper, we explore the landscape of transfer learning techniques for NLP by introducing a unified framework that converts every language problem into a text-to-text format. Our systematic study compares pre-training objectives, architectures, unlabeled datasets, transfer approaches, and other factors on dozens of language understanding tasks. By combining the insights from our exploration with scale and our new \u0026ldquo;Colossal Clean Crawled Corpus\u0026rdquo;, we achieve state-of-the-art results on many benchmarks covering summarization, question answering, text classification, and more. To facilitate future work on transfer learning for NLP, we release our dataset, pre-trained models, and code.\nInformation Theory and Statistics: A Tutorial (I. Csiszár et al., 2004) I. Csiszár, P. Shields. (2004)\nInformation Theory and Statistics: A Tutorial\nFound. Trends Commun. Inf. Theory\nPaper Link\nInfluential Citation Count (49), SS-ID (46cc7d0d9ab944d678deeaeb899e3c2ffd745d6c)\nABSTRACT\nThis tutorial is concerned with applications of information theory concepts in statistics, in the finite alphabet setting. The information measure known as information divergence or Kullback-Leibler distance or relative entropy plays a key role, often with a geometric flavor as an analogue of squared Euclidean distance, as in the concepts of I-projection, I-radius and I-centroid. The topics covered include large deviations, hypothesis testing, maximum likelihood estimation in exponential families, analysis of contingency tables, and iterative algorithms with an \u0026ldquo;information geometry\u0026rdquo; background. Also, an introduction is provided to the theory of universal coding, and to statistical inference via the minimum description length principle motivated by that theory.\nVirtual Adversarial Training: A Regularization Method for Supervised and Semi-Supervised Learning (Takeru Miyato et al., 2017) Takeru Miyato, S. Maeda, Masanori Koyama, S. Ishii. (2017)\nVirtual Adversarial Training: A Regularization Method for Supervised and Semi-Supervised Learning\nIEEE Transactions on Pattern Analysis and Machine Intelligence\nPaper Link\nInfluential Citation Count (282), SS-ID (4b1c6f6521da545892f3f5dc39461584d4a27ec0)\nABSTRACT\nWe propose a new regularization method based on virtual adversarial loss: a new measure of local smoothness of the conditional label distribution given input. Virtual adversarial loss is defined as the robustness of the conditional label distribution around each input data point against local perturbation. Unlike adversarial training, our method defines the adversarial direction without label information and is hence applicable to semi-supervised learning. Because the directions in which we smooth the model are only “virtually” adversarial, we call our method virtual adversarial training (VAT). The computational cost of VAT is relatively low. For neural networks, the approximated gradient of virtual adversarial loss can be computed with no more than two pairs of forward- and back-propagations. In our experiments, we applied VAT to supervised and semi-supervised learning tasks on multiple benchmark datasets. With a simple enhancement of the algorithm based on the entropy minimization principle, our VAT achieves state-of-the-art performance for semi-supervised learning tasks on SVHN and CIFAR-10.\nKnow What You Don’t Know: Unanswerable Questions for SQuAD (Pranav Rajpurkar et al., 2018) Pranav Rajpurkar, Robin Jia, Percy Liang. (2018)\nKnow What You Don’t Know: Unanswerable Questions for SQuAD\nACL\nPaper Link\nInfluential Citation Count (340), SS-ID (4d1c856275744c0284312a3a50efb6ca9dc4cd4c)\nABSTRACT\nExtractive reading comprehension systems can often locate the correct answer to a question in a context document, but they also tend to make unreliable guesses on questions for which the correct answer is not stated in the context. Existing datasets either focus exclusively on answerable questions, or use automatically generated unanswerable questions that are easy to identify. To address these weaknesses, we present SQuADRUn, a new dataset that combines the existing Stanford Question Answering Dataset (SQuAD) with over 50,000 unanswerable questions written adversarially by crowdworkers to look similar to answerable ones. To do well on SQuADRUn, systems must not only answer questions when possible, but also determine when no answer is supported by the paragraph and abstain from answering. SQuADRUn is a challenging natural language understanding task for existing models: a strong neural system that gets 86% F1 on SQuAD achieves only 66% F1 on SQuADRUn. We release SQuADRUn to the community as the successor to SQuAD.\nRetrieval-Augmented Generation for Knowledge-Intensive NLP Tasks (Patrick Lewis et al., 2020) Patrick Lewis, Ethan Perez, Aleksandara Piktus, Fabio Petroni, Vladimir Karpukhin, Naman Goyal, Heinrich Kuttler, M. Lewis, Wen-tau Yih, Tim Rocktäschel, Sebastian Riedel, Douwe Kiela. (2020)\nRetrieval-Augmented Generation for Knowledge-Intensive NLP Tasks\nNeurIPS\nPaper Link\nInfluential Citation Count (54), SS-ID (58ed1fbaabe027345f7bb3a6312d41c5aac63e22)\nABSTRACT\nLarge pre-trained language models have been shown to store factual knowledge in their parameters, and achieve state-of-the-art results when fine-tuned on downstream NLP tasks. However, their ability to access and precisely manipulate knowledge is still limited, and hence on knowledge-intensive tasks, their performance lags behind task-specific architectures. Additionally, providing provenance for their decisions and updating their world knowledge remain open research problems. Pre-trained models with a differentiable access mechanism to explicit non-parametric memory can overcome this issue, but have so far been only investigated for extractive downstream tasks. We explore a general-purpose fine-tuning recipe for retrieval-augmented generation (RAG) \u0026ndash; models which combine pre-trained parametric and non-parametric memory for language generation. We introduce RAG models where the parametric memory is a pre-trained seq2seq model and the non-parametric memory is a dense vector index of Wikipedia, accessed with a pre-trained neural retriever. We compare two RAG formulations, one which conditions on the same retrieved passages across the whole generated sequence, the other can use different passages per token. We fine-tune and evaluate our models on a wide range of knowledge-intensive NLP tasks and set the state-of-the-art on three open domain QA tasks, outperforming parametric seq2seq models and task-specific retrieve-and-extract architectures. For language generation tasks, we find that RAG models generate more specific, diverse and factual language than a state-of-the-art parametric-only seq2seq baseline.\nDeep Compression: Compressing Deep Neural Network with Pruning, Trained Quantization and Huffman Coding (Song Han et al., 2015) Song Han, Huizi Mao, W. Dally. (2015)\nDeep Compression: Compressing Deep Neural Network with Pruning, Trained Quantization and Huffman Coding\nICLR\nPaper Link\nInfluential Citation Count (611), SS-ID (642d0f49b7826adcf986616f4af77e736229990f)\nABSTRACT\nNeural networks are both computationally intensive and memory intensive, making them difficult to deploy on embedded systems with limited hardware resources. To address this limitation, we introduce \u0026ldquo;deep compression\u0026rdquo;, a three stage pipeline: pruning, trained quantization and Huffman coding, that work together to reduce the storage requirement of neural networks by 35x to 49x without affecting their accuracy. Our method first prunes the network by learning only the important connections. Next, we quantize the weights to enforce weight sharing, finally, we apply Huffman coding. After the first two steps we retrain the network to fine tune the remaining connections and the quantized centroids. Pruning, reduces the number of connections by 9x to 13x; Quantization then reduces the number of bits that represent each connection from 32 to 5. On the ImageNet dataset, our method reduced the storage required by AlexNet by 35x, from 240MB to 6.9MB, without loss of accuracy. Our method reduced the size of VGG-16 by 49x from 552MB to 11.3MB, again with no loss of accuracy. This allows fitting the model into on-chip SRAM cache rather than off-chip DRAM memory. Our compression method also facilitates the use of complex neural networks in mobile applications where application size and download bandwidth are constrained. Benchmarked on CPU, GPU and mobile GPU, compressed network has 3x to 4x layerwise speedup and 3x to 7x better energy efficiency.\nThe TREC-8 Question Answering Track Report (E. Voorhees, 1999) E. Voorhees. (1999)\nThe TREC-8 Question Answering Track Report\nTREC\nPaper Link\nInfluential Citation Count (157), SS-ID (646d4888871aca2a25111eb2520e4c47e253b014)\nABSTRACT\nThe TREC-8 Question Answering track was the first large-scale evaluation of domain-independent question answering systems. This paper summarizes the results of the track by giving a brief overview of the different approaches taken to solve the problem. The most accurate systems found a correct response for more than 2/3 of the questions. Relatively simple bag-of-words approaches were adequate for finding answers when responses could be as long as a paragraph (250 bytes), but more sophisticated processing was necessary for more direct responses (50 bytes).\nThe TREC-8 Question Answering track was an initial e\u000bort to bring the bene\u000cts of large-scale evaluation to bear on a question answering (QA) task. The goal in the QA task is to retrieve small snippets of text that contain the actual answer to a question rather than the document lists traditionally returned by text retrieval systems. The assumption is that users would usually prefer to be given the answer rather than and the answer themselves in a document.\nThis paper summarizes the retrieval results of the track; a companion paper (\\The TREC-8 Question Answering Track Evaluation\u0026quot;) gives details about how the evaluation was implemented. By necessity, a track report can give only an overview of the different approaches used in the track. Readers are urged to consult the participants\u0026rsquo; papers elsewhere in the Proceedings for details regarding a particular approach.\nProbabilistic Assumptions Matter: Improved Models for Distantly-Supervised Document-Level Question Answering (Hao Cheng et al., 2020) Hao Cheng, Ming-Wei Chang, Kenton Lee, Kristina Toutanova. (2020)\nProbabilistic Assumptions Matter: Improved Models for Distantly-Supervised Document-Level Question Answering\nACL\nPaper Link\nInfluential Citation Count (3), SS-ID (74abf8638a3dde78f20047dc72413780f2c28fb7)\nABSTRACT\nWe address the problem of extractive question answering using document-level distant super-vision, pairing questions and relevant documents with answer strings. We compare previously used probability space and distant supervision assumptions (assumptions on the correspondence between the weak answer string labels and possible answer mention spans). We show that these assumptions interact, and that different configurations provide complementary benefits. We demonstrate that a multi-objective model can efficiently combine the advantages of multiple assumptions and outperform the best individual formulation. Our approach outperforms previous state-of-the-art models by 4.3 points in F1 on TriviaQA-Wiki and 1.7 points in Rouge-L on NarrativeQA summaries.\nELECTRA: Pre-training Text Encoders as Discriminators Rather Than Generators (Kevin Clark et al., 2020) Kevin Clark, Minh-Thang Luong, Quoc V. Le, Christopher D. Manning. (2020)\nELECTRA: Pre-training Text Encoders as Discriminators Rather Than Generators\nICLR\nPaper Link\nInfluential Citation Count (288), SS-ID (756810258e3419af76aff38c895c20343b0602d0)\nABSTRACT\nWhile masked language modeling (MLM) pre-training methods such as BERT produce excellent results on downstream NLP tasks, they require large amounts of compute to be effective. These approaches corrupt the input by replacing some tokens with [MASK] and then train a model to reconstruct the original tokens. As an alternative, we propose a more sample-efficient pre-training task called replaced token detection. Instead of masking the input, our approach corrupts it by replacing some input tokens with plausible alternatives sampled from a small generator network. Then, instead of training a model that predicts the original identities of the corrupted tokens, we train a discriminative model that predicts whether each token in the corrupted input was replaced by a generator sample or not. Thorough experiments demonstrate this new pre-training task is more efficient than MLM because the model learns from all input tokens rather than just the small subset that was masked out. As a result, the contextual representations learned by our approach substantially outperform the ones learned by methods such as BERT and XLNet given the same model size, data, and compute. The gains are particularly strong for small models; for example, we train a model on one GPU for 4 days that outperforms GPT (trained using 30x more compute) on the GLUE natural language understanding benchmark. Our approach also works well at scale, where we match the performance of RoBERTa, the current state-of-the-art pre-trained transformer, while using less than 1/4 of the compute.\nDense Passage Retrieval for Open-Domain Question Answering (Vladimir Karpukhin et al., 2020) Vladimir Karpukhin, Barlas Oğuz, Sewon Min, Patrick Lewis, Ledell Yu Wu, Sergey Edunov, Danqi Chen, Wen-tau Yih. (2020)\nDense Passage Retrieval for Open-Domain Question Answering\nEMNLP\nPaper Link\nInfluential Citation Count (226), SS-ID (79cd9f77e5258f62c0e15d11534aea6393ef73fe)\nABSTRACT\nOpen-domain question answering relies on efficient passage retrieval to select candidate contexts, where traditional sparse vector space models, such as TF-IDF or BM25, are the de facto method. In this work, we show that retrieval can be practically implemented using dense representations alone, where embeddings are learned from a small number of questions and passages by a simple dual-encoder framework. When evaluated on a wide range of open-domain QA datasets, our dense retriever outperforms a strong Lucene-BM25 system largely by 9%-19% absolute in terms of top-20 passage retrieval accuracy, and helps our end-to-end QA system establish new state-of-the-art on multiple open-domain QA benchmarks.\nREALM: Retrieval-Augmented Language Model Pre-Training (Kelvin Guu et al., 2020) Kelvin Guu, Kenton Lee, Z. Tung, Panupong Pasupat, Ming-Wei Chang. (2020)\nREALM: Retrieval-Augmented Language Model Pre-Training\nArXiv\nPaper Link\nInfluential Citation Count (63), SS-ID (832fff14d2ed50eb7969c4c4b976c35776548f56)\nABSTRACT\nLanguage model pre-training has been shown to capture a surprising amount of world knowledge, crucial for NLP tasks such as question answering. However, this knowledge is stored implicitly in the parameters of a neural network, requiring ever-larger networks to cover more facts. To capture knowledge in a more modular and interpretable way, we augment language model pre-training with a latent knowledge retriever, which allows the model to retrieve and attend over documents from a large corpus such as Wikipedia, used during pre-training, fine-tuning and inference. For the first time, we show how to pre-train such a knowledge retriever in an unsupervised manner, using masked language modeling as the learning signal and backpropagating through a retrieval step that considers millions of documents. We demonstrate the effectiveness of Retrieval-Augmented Language Model pre-training (REALM) by fine-tuning on the challenging task of Open-domain Question Answering (Open-QA). We compare against state-of-the-art models for both explicit and implicit knowledge storage on three popular Open-QA benchmarks, and find that we outperform all previous methods by a significant margin (4-16% absolute accuracy), while also providing qualitative benefits such as interpretability and modularity.\nLatent Retrieval for Weakly Supervised Open Domain Question Answering (Kenton Lee et al., 2019) Kenton Lee, Ming-Wei Chang, Kristina Toutanova. (2019)\nLatent Retrieval for Weakly Supervised Open Domain Question Answering\nACL\nPaper Link\nInfluential Citation Count (99), SS-ID (a81874b4a651a740fffbfc47ef96515e8c7f782f)\nABSTRACT\nRecent work on open domain question answering (QA) assumes strong supervision of the supporting evidence and/or assumes a blackbox information retrieval (IR) system to retrieve evidence candidates. We argue that both are suboptimal, since gold evidence is not always available, and QA is fundamentally different from IR. We show for the first time that it is possible to jointly learn the retriever and reader from question-answer string pairs and without any IR system. In this setting, evidence retrieval from all of Wikipedia is treated as a latent variable. Since this is impractical to learn from scratch, we pre-train the retriever with an Inverse Cloze Task. We evaluate on open versions of five QA datasets. On datasets where the questioner already knows the answer, a traditional IR system such as BM25 is sufficient. On datasets where a user is genuinely seeking an answer, we show that learned retrieval is crucial, outperforming BM25 by up to 19 points in exact match.\nNeural Approaches to Conversational AI (Jianfeng Gao et al., 2018) Jianfeng Gao, Michel Galley, Lihong Li. (2018)\nNeural Approaches to Conversational AI\nFound. Trends Inf. Retr.\nPaper Link\nInfluential Citation Count (30), SS-ID (a94c0fc00c7a823cebd2d17094a2d7ab3652a5b6)\nABSTRACT\nThe present paper surveys neural approaches to conversational AI that have been developed in the last few years. We group conversational systems into three categories: (1) question answering agents, (2) task-oriented dialogue agents, and (3) chatbots. For each category, we present a review of state-of-the-art neural approaches, draw the connection between them and traditional approaches, and discuss the progress that has been made and challenges still being faced, using specific systems and models as case studies.\nTargeted Adversarial Training for Natural Language Understanding (Lis Pereira et al., 2021) Lis Pereira, Xiaodong Liu, Hao Cheng, Hoifung Poon, Jianfeng Gao, I. Kobayashi. (2021)\nTargeted Adversarial Training for Natural Language Understanding\nNAACL\nPaper Link\nInfluential Citation Count (1), SS-ID (a9e8c7544b41ff133b04a321179c22f7da3c3cdc)\nABSTRACT\nWe present a simple yet effective Targeted Adversarial Training (TAT) algorithm to improve adversarial training for natural language understanding. The key idea is to introspect current mistakes and prioritize adversarial training steps to where the model errs the most. Experiments show that TAT can significantly improve accuracy over standard adversarial training on GLUE and attain new state-of-the-art zero-shot results on XNLI. Our code will be released upon acceptance of the paper.\nSMART: Robust and Efficient Fine-Tuning for Pre-trained Natural Language Models through Principled Regularized Optimization (Haoming Jiang et al., 2019) Haoming Jiang, Pengcheng He, Weizhu Chen, Xiaodong Liu, Jianfeng Gao, T. Zhao. (2019)\nSMART: Robust and Efficient Fine-Tuning for Pre-trained Natural Language Models through Principled Regularized Optimization\nACL\nPaper Link\nInfluential Citation Count (23), SS-ID (ab70853cd5912c470f6ff95e95481980f0a2a41b)\nABSTRACT\nTransfer learning has fundamentally changed the landscape of natural language processing (NLP). Many state-of-the-art models are first pre-trained on a large text corpus and then fine-tuned on downstream tasks. However, due to limited data resources from downstream tasks and the extremely high complexity of pre-trained models, aggressive fine-tuning often causes the fine-tuned model to overfit the training data of downstream tasks and fail to generalize to unseen data. To address such an issue in a principled manner, we propose a new learning framework for robust and efficient fine-tuning for pre-trained models to attain better generalization performance. The proposed framework contains two important ingredients: 1. Smoothness-inducing regularization, which effectively manages the complexity of the model; 2. Bregman proximal point optimization, which is an instance of trust-region methods and can prevent aggressive updating. Our experiments show that the proposed framework achieves new state-of-the-art performance on a number of NLP tasks including GLUE, SNLI, SciTail and ANLI. Moreover, it also outperforms the state-of-the-art T5 model, which is the largest pre-trained model containing 11 billion parameters, on GLUE.\nOpen-domain question answering (M. Greenwood, 2005) M. Greenwood. (2005)\nOpen-domain question answering\nPaper Link\nInfluential Citation Count (2), SS-ID (b5403ef8446c2106d35155e7f05a45977d0c7f85)\nABSTRACT\nA sparse representation is known to be an effective means to encode precise lexical cues in information retrieval tasks by associating each dimension with a unique ngram-based feature. However, it has often relied on term frequency (such as tf-idf and BM25) or hand-engineered features that are coarse-grained (document-level) and often task-specific, hence not easily generalizable and not appropriate for finegrained (word or phrase-level) retrieval. In this work, we propose an effective method for learning a highly contextualized, word-level sparse representation by utilizing rectified self-attention weights on the neighboring n-grams. We kernelize the inner product space during training for memory efficiency without the explicit mapping of the large sparse vectors. We particularly focus on the application of our model to phrase retrieval problem, which has recently shown to be a promising direction for open-domain question answering (QA) and requires lexically sensitive phrase encoding. We demonstrate the effectiveness of the learned sparse representations by not only drastically improving the phrase retrieval accuracy (by more than 4%), but also outperforming all other (pipeline-based) open-domain QA methods with up to x97 faster inference in SQUADOPEN and CURATEDTREC.1\nDenoising Distantly Supervised Open-Domain Question Answering (Yankai Lin et al., 2018) Yankai Lin, Haozhe Ji, Zhiyuan Liu, Maosong Sun. (2018)\nDenoising Distantly Supervised Open-Domain Question Answering\nACL\nPaper Link\nInfluential Citation Count (21), SS-ID (ba1382a0574baa0345fd727f259bc86797fe1381)\nABSTRACT\nDistantly supervised open-domain question answering (DS-QA) aims to find answers in collections of unlabeled text. Existing DS-QA models usually retrieve related paragraphs from a large-scale corpus and apply reading comprehension technique to extract answers from the most relevant paragraph. They ignore the rich information contained in other paragraphs. Moreover, distant supervision data inevitably accompanies with the wrong labeling problem, and these noisy data will substantially degrade the performance of DS-QA. To address these issues, we propose a novel DS-QA model which employs a paragraph selector to filter out those noisy paragraphs and a paragraph reader to extract the correct answer from those denoised paragraphs. Experimental results on real-world datasets show that our model can capture useful information from noisy data and achieve significant improvements on DS-QA as compared to all baselines.\nLeveraging Passage Retrieval with Generative Models for Open Domain Question Answering (Gautier Izacard et al., 2020) Gautier Izacard, Edouard Grave. (2020)\nLeveraging Passage Retrieval with Generative Models for Open Domain Question Answering\nEACL\nPaper Link\nInfluential Citation Count (44), SS-ID (bde0c85ed3d61de2a8874ddad70497b3d68bc8ad)\nABSTRACT\nGenerative models for open domain question answering have proven to be competitive, without resorting to external knowledge. While promising, this approach requires to use models with billions of parameters, which are expensive to train and query. In this paper, we investigate how much these models can benefit from retrieving text passages, potentially containing evidence. We obtain state-of-the-art results on the Natural Questions and TriviaQA open benchmarks. Interestingly, we observe that the performance of this method significantly improves when increasing the number of retrieved passages. This is evidence that sequence-to-sequence models offers a flexible framework to efficiently aggregate and combine evidence from multiple passages.\nPre-training via Paraphrasing (M. Lewis et al., 2020) M. Lewis, Marjan Ghazvininejad, Gargi Ghosh, Armen Aghajanyan, Sida Wang, Luke Zettlemoyer. (2020)\nPre-training via Paraphrasing\nNeurIPS\nPaper Link\nInfluential Citation Count (26), SS-ID (c00ba15810496669d47d2ed5b627e6c7d2b1f6aa)\nABSTRACT\nWe introduce MARGE, a pre-trained sequence-to-sequence model learned with an unsupervised multi-lingual multi-document paraphrasing objective. MARGE provides an alternative to the dominant masked language modeling paradigm, where we self-supervise the reconstruction of target text by retrieving a set of related texts (in many languages) and conditioning on them to maximize the likelihood of generating the original. We show it is possible to jointly learn to do retrieval and reconstruction, given only a random initialization. The objective noisily captures aspects of paraphrase, translation, multi-document summarization, and information retrieval, allowing for strong zero-shot performance on several tasks. For example, with no additional task-specific training we achieve BLEU scores of up to 35.8 for document translation. We further show that fine-tuning gives strong performance on a range of discriminative and generative tasks in many languages, making MARGE the most generally applicable pre-training method to date.\nQuestion and Answer Test-Train Overlap in Open-Domain Question Answering Datasets (Patrick Lewis et al., 2020) Patrick Lewis, Pontus Stenetorp, Sebastian Riedel. (2020)\nQuestion and Answer Test-Train Overlap in Open-Domain Question Answering Datasets\nEACL\nPaper Link\nInfluential Citation Count (15), SS-ID (cb58542c94ce83b09f5d3809e69518ba52709c92)\nABSTRACT\nIdeally Open-Domain Question Answering models should exhibit a number of competencies, ranging from simply memorizing questions seen at training time, to answering novel question formulations with answers seen during training, to generalizing to completely novel questions with novel answers. However, single aggregated test set scores do not show the full picture of what capabilities models truly have. In this work, we perform a detailed study of the test sets of three popular open-domain benchmark datasets with respect to these competencies. We find that 30% of test-set questions have a near-duplicate paraphrase in their corresponding train sets. In addition, we find that 60-70% of answers in the test sets are also present in the train sets. Using these findings, we evaluate a variety of popular open-domain models to obtain greater insight into what extent they can generalize, and what drives their overall performance. We find that all models perform substantially worse on questions that cannot be memorized from train sets, with a mean absolute performance difference of 61% between repeated and non-repeated data. Finally we show that simple nearest-neighbor models outperform a BART closed-book QA model, further highlighting the role that train set memorization plays in these benchmarks\nQuantized Neural Networks: Training Neural Networks with Low Precision Weights and Activations (Itay Hubara et al., 2016) Itay Hubara, Matthieu Courbariaux, Daniel Soudry, Ran El-Yaniv, Yoshua Bengio. (2016)\nQuantized Neural Networks: Training Neural Networks with Low Precision Weights and Activations\nJ. Mach. Learn. Res.\nPaper Link\nInfluential Citation Count (106), SS-ID (d2e4147eecae6f914e9e1e9aece8fdd2eaed809f)\nABSTRACT\nWe introduce a method to train Quantized Neural Networks (QNNs) \u0026ndash; neural networks with extremely low precision (e.g., 1-bit) weights and activations, at run-time. At traintime the quantized weights and activations are used for computing the parameter gradients. During the forward pass, QNNs drastically reduce memory size and accesses, and replace most arithmetic operations with bit-wise operations. As a result, power consumption is expected to be drastically reduced. We trained QNNs over the MNIST, CIFAR-10, SVHN and ImageNet datasets. The resulting QNNs achieve prediction accuracy comparable to their 32-bit counterparts. For example, our quantized version of AlexNet with 1-bit weights and 2-bit activations achieves 51% top-1 accuracy. Moreover, we quantize the parameter gradients to 6-bits as well which enables gradients computation using only bit-wise operation. Quantized recurrent neural networks were tested over the Penn Treebank dataset, and achieved comparable accuracy as their 32-bit counterparts using only 4-bits. Last but not least, we programmed a binary matrix multiplication GPU kernel with which it is possible to run our MNIST QNN 7 times faster than with an unoptimized GPU kernel, without suffering any loss in classification accuracy. The QNN code is available online.\nBERT: Pre-training of Deep Bidirectional Transformers for Language Understanding (Jacob Devlin et al., 2019) Jacob Devlin, Ming-Wei Chang, Kenton Lee, Kristina Toutanova. (2019)\nBERT: Pre-training of Deep Bidirectional Transformers for Language Understanding\nNAACL\nPaper Link\nInfluential Citation Count (9978), SS-ID (df2b0e26d0599ce3e70df8a9da02e51594e0e992)\nABSTRACT\nWe introduce a new language representation model called BERT, which stands for Bidirectional Encoder Representations from Transformers. Unlike recent language representation models (Peters et al., 2018a; Radford et al., 2018), BERT is designed to pre-train deep bidirectional representations from unlabeled text by jointly conditioning on both left and right context in all layers. As a result, the pre-trained BERT model can be fine-tuned with just one additional output layer to create state-of-the-art models for a wide range of tasks, such as question answering and language inference, without substantial task-specific architecture modifications. BERT is conceptually simple and empirically powerful. It obtains new state-of-the-art results on eleven natural language processing tasks, including pushing the GLUE score to 80.5 (7.7 point absolute improvement), MultiNLI accuracy to 86.7% (4.6% absolute improvement), SQuAD v1.1 question answering Test F1 to 93.2 (1.5 point absolute improvement) and SQuAD v2.0 Test F1 to 83.1 (5.1 point absolute improvement).\nRetrieval Augmented Language Model Pre-Training (Kelvin Guu et al., 2020) Kelvin Guu, Kenton Lee, Z. Tung, Panupong Pasupat, Ming-Wei Chang. (2020)\nRetrieval Augmented Language Model Pre-Training\nICML\nPaper Link\nInfluential Citation Count (20), SS-ID (ea1f95989f808f409a3cd29b128000c04036c224)\nABSTRACT\nTriviaQA: A Large Scale Distantly Supervised Challenge Dataset for Reading Comprehension (Mandar Joshi et al., 2017) Mandar Joshi, Eunsol Choi, Daniel S. Weld, Luke Zettlemoyer. (2017)\nTriviaQA: A Large Scale Distantly Supervised Challenge Dataset for Reading Comprehension\nACL\nPaper Link\nInfluential Citation Count (193), SS-ID (f010affab57b5fcf1cd6be23df79d8ec98c7289c)\nABSTRACT\nWe present TriviaQA, a challenging reading comprehension dataset containing over 650K question-answer-evidence triples. TriviaQA includes 95K question-answer pairs authored by trivia enthusiasts and independently gathered evidence documents, six per question on average, that provide high quality distant supervision for answering the questions. We show that, in comparison to other recently introduced large-scale datasets, TriviaQA (1) has relatively complex, compositional questions, (2) has considerable syntactic and lexical variability between questions and corresponding answer-evidence sentences, and (3) requires more cross sentence reasoning to find answers. We also present two baseline algorithms: a feature-based classifier and a state-of-the-art neural network, that performs well on SQuAD reading comprehension. Neither approach comes close to human performance (23% and 40% vs. 80%), suggesting that TriviaQA is a challenging testbed that is worth significant future study. Data and code available at \u0026ndash; this http URL\nRobust Large Margin Deep Neural Networks (Jure Sokolic et al., 2017) Jure Sokolic, R. Giryes, G. Sapiro, M. Rodrigues. (2017)\nRobust Large Margin Deep Neural Networks\nIEEE Transactions on Signal Processing\nPaper Link\nInfluential Citation Count (29), SS-ID (f657e68dde470641ba1a6cd7ab755e6359a32840)\nABSTRACT\nThe generalization error of deep neural networks via their classification margin is studied in this paper. Our approach is based on the Jacobian matrix of a deep neural network and can be applied to networks with arbitrary nonlinearities and pooling layers, and to networks with different architectures such as feed forward networks and residual networks. Our analysis leads to the conclusion that a bounded spectral norm of the network\u0026rsquo;s Jacobian matrix in the neighbourhood of the training samples is crucial for a deep neural network of arbitrary depth and width to generalize well. This is a significant improvement over the current bounds in the literature, which imply that the generalization error grows with either the width or the depth of the network. Moreover, it shows that the recently proposed batch normalization and weight normalization reparametrizations enjoy good generalization properties, and leads to a novel network regularizer based on the network\u0026rsquo;s Jacobian matrix. The analysis is supported with experimental results on the MNIST, CIFAR-10, LaRED, and ImageNet datasets.\n","date":"May 14, 2022","hero":"/blog-akitenkrad/posts/papers/202205/20220514151839/hero.jpg","permalink":"https://akitenkrad.github.io/blog-akitenkrad/posts/papers/202205/20220514151839/","summary":"Round-1: Overview Round-2: Model Implementation Details Round-3: Experiments Citation Cheng, H., Shen, Y., Liu, X., He, P., Chen, W., \u0026amp; Gao, J. (2021).\nUnitedQA: A Hybrid Approach for Open Domain Question Answering.\nhttps://doi.org/10.48550/arxiv.2101.00178 Abstract To date, most of recent work under the retrieval-reader framework for open-domain QA focuses on either extractive or generative reader exclusively. In this paper, we study a hybrid approach for leveraging the strengths of both models.","tags":["At:Round-1","Published:2021","Question Answering","Extractive-MRC","Generative-MRC","DS:Natural Questions","DS:TriviaQA"],"title":"UnitedQA: A Hybrid Approach for Open Domain Question Answering"},{"categories":null,"contents":" Round-1: Overview Round-2: Model Implementation Details Round-3: Experiments Citation Nishida, K., Saito, I., Nishida, K., Shinoda, K., Otsuka, A., Asano, H., \u0026amp; Tomita, J. (2020).\nMulti-style Generative Reading Comprehension.\nACL 2019 - 57th Annual Meeting of the Association for Computational Linguistics, Proceedings of the Conference, 2273–2284.\nhttps://doi.org/10.18653/v1/p19-1220 Abstract This study tackles generative reading comprehension (RC), which consists of answering questions based on textual evidence and natural language generation (NLG). We proposea multi-style abstractive summarization model for question answering, called Masque. The proposed model has two key characteristics. First, unlike most studies on RC that have focused on extracting an answer span from the provided passages, our model instead focuses on generating a summary from the question and multiple passages. This serves to cover various answer styles required for real-world applications. Second, whereas previous studies built a specific model for each answer style because of the difficulty of acquiring one general model, our approach learns multi-style answers within a model to improve the NLG capability for all styles involved. This also enables our model to give an answer in the target style. Experiments show that our model achieves state-of-the-art performance on the Q\u0026amp;A task and the Q\u0026amp;A + NLG task of MSMARCO 2.1 and the summary task of NarrativeQA. We observe that the transfer of the style-independent NLG capability to the targetstyle is the key to its success.\nWhat\u0026rsquo;s New 複数のPassageを入力にして Abstractive Summarization によりQAシステムで回答を生成する． 既存手法の多くは入力のPassageの文字列の一部を抽出して回答を作成するが，一部のデータセットでは抽出型の方法では回答を作成できないものがある． この点を解決するために，Transformerをベースとした Abstractive Summarization の手法により回答を生成する生成型のモデル Masque を提案した． Masqueから生成される回答は，Vocabularyに含まれる語彙とPassageに散らばっている単語を集約することで文章として生成される． 質問の形式に応じて適切な回答を出力できるように質問形式を含めてモデルを学習する QAの質問には，数値を答えるだけのものから文章を要約するものまで，様々なバリエーションがある．それぞれの質問の形式に応じて適切な回答方法があり，それらは一つの回答方法でカバーされるものではないため，Masqueでは質問形式に応じて適切な回答を生成できるよう，質問形式も学習するような仕組みになっている． Dataset MSMARCO (Bajaj et al., 2018) Daniel Fernando Campos, Tri Nguyen, M. Rosenberg, Xia Song, Jianfeng Gao, Saurabh Tiwary, Rangan Majumder, L. Deng, Bhaskar Mitra. (2016)\nMS MARCO: A Human Generated MAchine Reading COmprehension Dataset\nCoCo@NIPS\nPaper Link\nInfluential Citation Count (190), SS-ID (a69cf45d44a9d806d2487a1ffb9eca71ee73c2ee)\nABSTRACT\nThis paper presents our recent work on the design and development of a new, large scale dataset, which we name MS MARCO, for MAchine Reading COmprehension. This new dataset is aimed to overcome a number of well-known weaknesses of previous publicly available datasets for the same task of reading comprehension and question answering. In MS MARCO, all questions are sampled from real anonymized user queries. The context passages, from which answers in the dataset are derived, are extracted from real web documents using the most advanced version of the Bing search engine. The answers to the queries are human generated. Finally, a subset of these queries has multiple answers. We aim to release one million queries and the corresponding answers in the dataset, which, to the best of our knowledge, is the most comprehensive real-world dataset of its kind in both quantity and quality. We are currently releasing 100,000 queries with their corresponding answers to inspire work in reading comprehension and question answering along with gathering feedback from the research community.\nNarrativeQA (Kocisky et al., 2018) Tomás Kociský, Jonathan Schwarz, P. Blunsom, Chris Dyer, K. Hermann, Gábor Melis, Edward Grefenstette. (2017)\nThe NarrativeQA Reading Comprehension Challenge\nTACL\nPaper Link\nInfluential Citation Count (83), SS-ID (d91043f0d48b9b2c8ff7ee321abb8fd7efafff7a)\nABSTRACT\nReading comprehension (RC)—in contrast to information retrieval—requires integrating information and reasoning about events, entities, and their relations across a full document. Question answering is conventionally used to assess RC ability, in both artificial agents and children learning to read. However, existing RC datasets and tasks are dominated by questions that can be solved by selecting answers using superficial information (e.g., local context similarity or global term frequency); they thus fail to test for the essential integrative aspect of RC. To encourage progress on deeper comprehension of language, we present a new dataset and set of tasks in which the reader must answer questions about stories by reading entire books or movie scripts. These tasks are designed so that successfully answering their questions requires understanding the underlying narrative rather than relying on shallow pattern matching or salience. We show that although humans solve the tasks easily, standard RC models struggle on the tasks presented here. We provide an analysis of the dataset and the challenges it presents.\nDataset Summary\nModel Description Problem Formulation $$ \\begin{align*} \\text{Question} \u0026amp;: x^q = \\lbrace x_1^q, \\ldots , x_J^q \\rbrace \u0026amp; x_j^q \u0026amp;\\in \\mathbb{R}^V \\\\ \\text{Passages} \u0026amp;: x^{p_k} = \\lbrace x_1^{p_k}, \\ldots , x_L^{p_k} \\rbrace \u0026amp; x_l^{p_k} \u0026amp;\\in \\mathbb{R}^V \\\\ \\text{Answer Style Label} \u0026amp;: s \u0026amp; s \u0026amp;\\in \\mathbb{N}^+_{\\geqq 0} \\\\ \\text{RC model output} \u0026amp;: y = \\lbrace y_1, \\ldots , y_T \\rbrace \u0026amp; y_t \u0026amp;\\in \\mathbb{R}^V \\\\ \\text{where} \\\\ \u0026amp; J: \\text{length(number of words) of question} \\\\ \u0026amp; K: \\text{number of passages} \\\\ \u0026amp; L: \\text{length(number of words) of each passage} \\\\ \u0026amp; T: \\text{length of model output} \\end{align*} $$\nMachine Reading Comprehension Model $$ f := (x^q, \\lbrace x^{p_k} \\rbrace , s) \\rightarrow P(y | x^q, \\lbrace x^{p_k} \\rbrace , s) $$\nModel Traning Formulation $$ \\begin{align*} (x^q, \\lbrace x^{p_k} \\rbrace , s, y, a, \\lbrace r^{p_k} \\rbrace) \u0026amp; \\rightarrow \\text{loss}(P(y | x^q, \\lbrace x^{p_k} \\rbrace , s)) \\\\ \\text{where} \\\\ a = 1 \\hspace{5pt} \u0026amp; \\text{if the question is answerable otherwise} \\hspace{5pt} 0 \\\\ r^{p_k} = 1 \\hspace{5pt} \u0026amp; \\text{if the }k\\text{-th passage is required otherwise} \\hspace{5pt} 0 \\end{align*} $$\nModel Architecture Model Architecture Question-Passages Reader Word Embedding Layer $$ \\begin{align*} W^q \u0026amp;= \\lbrace w_1^q, \\ldots , w_J^q \\rbrace \u0026amp;=\u0026amp; \\hspace{5pt} \\text{2L-Highway}(\\text{GloVe+ELMo}(x^q)) \u0026amp; w_j^q \\in \\mathbb{R}^{d_{\\text{word}} \\times V} \\\\ W^{p_k} \u0026amp;= \\lbrace w_1^{p_k}, \\ldots , w_L^{p_k} \\rbrace \u0026amp;=\u0026amp; \\hspace{5pt} \\text{2L-Highway}(\\text{GloVe+ELMo}(x^{p_k})) \u0026amp; w_j^{p_k} \\in \\mathbb{R}^{d_{\\text{word}} \\times V} \\\\ \\end{align*} $$ ※ the ELMo is bidirectional\nGloVe (Jeffrey Pennington et al., 2014) Jeffrey Pennington, R. Socher, Christopher D. Manning. (2014)\nGloVe: Global Vectors for Word Representation\nEMNLP\nPaper Link\nInfluential Citation Count (3462), SS-ID (f37e1b62a767a307c046404ca96bc140b3e68cb5)\nABSTRACT\nRecent methods for learning vector space representations of words have succeeded in capturing fine-grained semantic and syntactic regularities using vector arithmetic, but the origin of these regularities has remained opaque. We analyze and make explicit the model properties needed for such regularities to emerge in word vectors. The result is a new global logbilinear regression model that combines the advantages of the two major model families in the literature: global matrix factorization and local context window methods. Our model efficiently leverages statistical information by training only on the nonzero elements in a word-word cooccurrence matrix, rather than on the entire sparse matrix or on individual context windows in a large corpus. The model produces a vector space with meaningful substructure, as evidenced by its performance of 75% on a recent word analogy task. It also outperforms related models on similarity tasks and named entity recognition. ELMo (Matthew E. Peters et al., 2018) Matthew E. Peters, Mark Neumann, Mohit Iyyer, Matt Gardner, Christopher Clark, Kenton Lee, Luke Zettlemoyer. (2018)\nDeep Contextualized Word Representations\nNAACL\nPaper Link\nInfluential Citation Count (1347), SS-ID (3febb2bed8865945e7fddc99efd791887bb7e14f)\nABSTRACT\nWe introduce a new type of deep contextualized word representation that models both (1) complex characteristics of word use (e.g., syntax and semantics), and (2) how these uses vary across linguistic contexts (i.e., to model polysemy). Our word vectors are learned functions of the internal states of a deep bidirectional language model (biLM), which is pre-trained on a large text corpus. We show that these representations can be easily added to existing models and significantly improve the state of the art across six challenging NLP problems, including question answering, textual entailment and sentiment analysis. We also present an analysis showing that exposing the deep internals of the pre-trained network is crucial, allowing downstream models to mix different types of semi-supervision signals. Highway Networks (R. Srivastava et al., 2015) R. Srivastava, Klaus Greff, J. Schmidhuber. (2015)\nHighway Networks\nArXiv\nPaper Link\nInfluential Citation Count (81), SS-ID (e0945081b5b87187a53d4329cf77cd8bff635795)\nABSTRACT\nThere is plenty of theoretical and empirical evidence that depth of neural networks is a crucial ingredient for their success. However, network training becomes more difficult with increasing depth and training of very deep networks remains an open problem. In this extended abstract, we introduce a new architecture designed to ease gradient-based training of very deep networks. We refer to networks with this architecture as highway networks, since they allow unimpeded information flow across several layers on information highways. The architecture is characterized by the use of gating units which learn to regulate the flow of information through a network. Highway networks with hundreds of layers can be trained directly using stochastic gradient descent and with a variety of activation functions, opening up the possibility of studying extremely deep and efficient architectures. Bidirectional Attention Flow for Machine Comprehension (Minjoon Seo et al., 2016) Minjoon Seo, Aniruddha Kembhavi, Ali Farhadi, Hannaneh Hajishirzi. (2016)\nBidirectional Attention Flow for Machine Comprehension\nICLR\nPaper Link\nInfluential Citation Count (439), SS-ID (3a7b63b50c64f4ec3358477790e84cbd6be2a0b4)\nABSTRACT\nMachine comprehension (MC), answering a query about a given context paragraph, requires modeling complex interactions between the context and the query. Recently, attention mechanisms have been successfully extended to MC. Typically these methods use attention to focus on a small portion of the context and summarize it with a fixed-size vector, couple attentions temporally, and/or often form a uni-directional attention. In this paper we introduce the Bi-Directional Attention Flow (BIDAF) network, a multi-stage hierarchical process that represents the context at different levels of granularity and uses bi-directional attention flow mechanism to obtain a query-aware context representation without early summarization. Our experimental evaluations show that our model achieves the state-of-the-art results in Stanford Question Answering Dataset (SQuAD) and CNN/DailyMail cloze test. Shared Encoder Layer $$ \\begin{align*} E^q \u0026amp;= \\lbrace e_1^q, \\ldots e_J^q \\rbrace \u0026amp;=\u0026amp; \\text{Shared-Transformer-Encoder-Blok}(W^q) \u0026amp; e_j^q \u0026amp;\\in \\mathbb{R}^d \\\\ E^{p_k} \u0026amp;= \\lbrace e_1^{p_k}, \\ldots e_L^{p_k} \\rbrace \u0026amp;=\u0026amp; \\text{Shared-Transformer-Encoder-Blok}(W^{p_k}) \u0026amp; e_l^{p_k} \u0026amp;\\in \\mathbb{R}^d \\end{align*} $$\nDual Attention Layer Similarity Matrix $$ \\begin{align*} U^{p_k} \u0026amp;\\in \\mathbb{R}^{L \\times J} \\\\ \\text{where} \\\\ \u0026amp; U_{lj}^{p_k} = {w^a}^{\\mathsf{T}} \\left[ E_l^{p_k} ; E_j^q ; E_l^{p_k} \\odot E_j^q \\right] \\\\ \u0026amp; w^a \\in \\mathbb{R}^{3d} \\hspace{10pt} \\text{(learnable parameters)} \\\\ \u0026amp; \\odot \\mapsto \\text{hadamard product} \\\\ \u0026amp; ; \\mapsto \\text{vector concatenation across the rows} \\end{align*} $$\nBidirectional Attention Flow for Machine Comprehension (Minjoon Seo et al., 2016) Minjoon Seo, Aniruddha Kembhavi, Ali Farhadi, Hannaneh Hajishirzi. (2016)\nBidirectional Attention Flow for Machine Comprehension\nICLR\nPaper Link\nInfluential Citation Count (439), SS-ID (3a7b63b50c64f4ec3358477790e84cbd6be2a0b4)\nABSTRACT\nMachine comprehension (MC), answering a query about a given context paragraph, requires modeling complex interactions between the context and the query. Recently, attention mechanisms have been successfully extended to MC. Typically these methods use attention to focus on a small portion of the context and summarize it with a fixed-size vector, couple attentions temporally, and/or often form a uni-directional attention. In this paper we introduce the Bi-Directional Attention Flow (BIDAF) network, a multi-stage hierarchical process that represents the context at different levels of granularity and uses bi-directional attention flow mechanism to obtain a query-aware context representation without early summarization. Our experimental evaluations show that our model achieves the state-of-the-art results in Stanford Question Answering Dataset (SQuAD) and CNN/DailyMail cloze test. Normalized Similarity Matrix $$ \\begin{align*} A^{p_k} \u0026amp;= \\text{softmax}_j\\left( {U^{p_k}}^\\mathsf{T} \\right) \u0026amp;\\in \\mathbb{R}^{J \\times L} \\\\ B^{p_k} \u0026amp;= \\text{softmax}_l\\left( {U^{p_k}} \\right) \u0026amp;\\in \\mathbb{R}^{L \\times J} \\\\ \\end{align*} $$\nDynamic Coattention Networks (DCN) $$ \\begin{align*} G^{q \\rightarrow p_k} \u0026amp;= \\left\\lbrack E^{p_k} ; \\bar{A}^{p_k} ; \\bar{\\bar{A}}^{p_k}; E^{p_k} \\odot \\bar{A}^{p_k}; E^{p_k} \\odot \\bar{\\bar{A}}^{p_k} \\right\\rbrack \u0026amp;\\in \\mathbb{R}^{5d \\times L} \\\\ G^{p \\rightarrow q} \u0026amp;= \\left\\lbrack E^q ; \\bar{B} ; \\bar{\\bar{B}}; E^q \\odot \\bar{B} ; E^q \\odot \\bar{\\bar{B}}\\right\\rbrack \u0026amp;\\in \\mathbb{R}^{5d \\times J} \\\\ \\text{where} \\\\ \u0026amp; \\bar{A}^{p_k} = E^q A^{p_k} \u0026amp;\\in \\mathbb{R}^{d \\times L} \\\\ \u0026amp; \\bar{B}^{p_k} = E^{p_k} B^{p_k} \u0026amp;\\in \\mathbb{R}^{d \\times J} \\\\ \u0026amp; \\bar{\\bar{A}}^{p_k} = \\bar{B}^{p_k} A^{p_k} \u0026amp;\\in \\mathbb{R}^{d \\times L} \\\\ \u0026amp; \\bar{\\bar{B}}^{p_k} = \\bar{A}^{p_k} B^{p_k} \u0026amp;\\in \\mathbb{R}^{d \\times J} \\\\ \u0026amp; \\bar{B} = \\max_k \\left(\\bar{B}^{p_k}\\right) \u0026amp;\\in \\mathbb{R}^{d \\times J} \\\\ \u0026amp; \\bar{\\bar{B}} = \\max_k \\left( \\bar{\\bar{B}}^{p_k} \\right) \u0026amp;\\in \\mathbb{R}^{d \\times J} \\end{align*} $$\nDCN (Caiming Xiong et al., 2016) Caiming Xiong, Victor Zhong, R. Socher. (2016)\nDynamic Coattention Networks For Question Answering\nICLR\nPaper Link\nInfluential Citation Count (111), SS-ID (e978d832a4d86571e1b52aa1685dc32ccb250f50)\nABSTRACT\nSeveral deep learning models have been proposed for question answering. However, due to their single-pass nature, they have no way to recover from local maxima corresponding to incorrect answers. To address this problem, we introduce the Dynamic Coattention Network (DCN) for question answering. The DCN first fuses co-dependent representations of the question and the document in order to focus on relevant parts of both. Then a dynamic pointing decoder iterates over potential answer spans. This iterative procedure enables the model to recover from initial local maxima corresponding to incorrect answers. On the Stanford question answering dataset, a single DCN model improves the previous state of the art from 71.0% F1 to 75.9%, while a DCN ensemble obtains 80.4% F1. Model Encoder Layer $$ \\begin{align*} M^q \u0026amp;= \\text{Transformer-Encoder-Block}(G^{p \\rightarrow q}) \u0026amp;\\in \\mathbb{R}^{d \\times J} \\\\ M^{p_k} \u0026amp;= \\text{Transformer-Encoder-Block}(G^{q \\rightarrow p_k}) \u0026amp;\\in \\mathbb{R}^{d \\times L} \\end{align*} $$\nPassage Ranker 各 $\\lbrace M^{p_k} \\rbrace$ の先頭の単語 $M_1^{p_k}$ を受け取ってQuestionに対する $k$番目のPassageの関連性スコアを算出する\n入力の文章の情報を $M_1^{p_k}$ に集約するように学習する\n$$ \\begin{align*} \\beta^{p_k} \u0026amp;= \\text{sigmoid}\\left( {w^r}^\\mathsf{T} M_1^{p_k} \\right) \\in \\mathbb{R} \\\\ \\text{where} \\\\ \u0026amp; M_1^{p_k} \\in \\mathbb{R}^d \\\\ \u0026amp; w^r \\in \\mathbb{R}^d \\end{align*} $$\nAnswer Possibility Classifier Word Embedding Layer 基本構成は Reader Module と同じだが，Answer出力時の先読みを防ぐため，ELMo は unidirectional 一つのモデルで複数のAnswer Styleを扱うために，Artificial Tokens を導入 Answerの先頭( $y_1$ )にAnswer Styleに対応するトークンを導入する テスト時には，先頭のトークンを指定することで解答のスタイルをコントロールすることができるようになる モデルのアーキテクチャには影響しない $$ \\begin{align*} y \u0026amp;= \\left\\lbrace y_{\\text{style}}, y_1, \\ldots, y_T \\right\\rbrace \\\\ W^{\\text{answer}} \u0026amp;= \\lbrace w_{\\text{style}}^{\\text{answer}}, w_1^{\\text{answer}}, \\ldots, w_T^{\\text{answer}} \\rbrace = \\text{2L-Highway}(\\text{GloVe+ELMo}(y)) \u0026amp; w_t^{\\text{answer}} \u0026amp;\\in \\mathbb{R}^{d_{\\text{word}} \\times V} \\end{align*} $$\n※ the ELMo is unidirectional\nArtificial Token $\\rightarrow$ (Melvin Johnson et al., 2016) Melvin Johnson, M. Schuster, Quoc V. Le, M. Krikun, Yonghui Wu, Z. Chen, Nikhil Thorat, F. Viégas, M. Wattenberg, G. Corrado, Macduff Hughes, J. Dean. (2016)\nGoogle’s Multilingual Neural Machine Translation System: Enabling Zero-Shot Translation\nTACL\nPaper Link\nInfluential Citation Count (162), SS-ID (a486e2839291111bb44fa1f07731ada123539f75)\nABSTRACT\nWe propose a simple solution to use a single Neural Machine Translation (NMT) model to translate between multiple languages. Our solution requires no changes to the model architecture from a standard NMT system but instead introduces an artificial token at the beginning of the input sentence to specify the required target language. Using a shared wordpiece vocabulary, our approach enables Multilingual NMT systems using a single model. On the WMT’14 benchmarks, a single multilingual model achieves comparable performance for English→French and surpasses state-of-theart results for English→German. Similarly, a single multilingual model surpasses state-of-the-art results for French→English and German→English on WMT’14 and WMT’15 benchmarks, respectively. On production corpora, multilingual models of up to twelve language pairs allow for better translation of many individual pairs. Our models can also learn to perform implicit bridging between language pairs never seen explicitly during training, showing that transfer learning and zero-shot translation is possible for neural translation. Finally, we show analyses that hints at a universal interlingua representation in our models and also show some interesting examples when mixing languages. Artificial Token $\\rightarrow$ (Shunsuke Takeno et al., 2017) Shunsuke Takeno, M. Nagata, Kazuhide Yamamoto. (2017)\nControlling Target Features in Neural Machine Translation via Prefix Constraints\nWAT@IJCNLP\nPaper Link\nInfluential Citation Count (0), SS-ID (c034abc8ee67af5ffe717f8c52971dccd308ea2a)\nABSTRACT\nWe propose prefix constraints, a novel method to enforce constraints on target sentences in neural machine translation. It places a sequence of special tokens at the beginning of target sentence (target prefix), while side constraints places a special token at the end of source sentence (source suffix). Prefix constraints can be predicted from source sentence jointly with target sentence, while side constraints (Sennrich et al., 2016) must be provided by the user or predicted by some other methods. In both methods, special tokens are designed to encode arbitrary features on target-side or metatextual information. We show that prefix constraints are more flexible than side constraints and can be used to control the behavior of neural machine translation, in terms of output length, bidirectional decoding, domain adaptation, and unaligned target word generation. Attention Decoder Layer $$ \\begin{align*} M^{\\text{answer}} \u0026amp;= \\text{Normed-ResNet}(\\text{Masked-Transformer-Encoder-Block}(W^{\\text{answer}})) \u0026amp;\\in \\mathbb{R}^{d \\times T\u0026rsquo;} \\\\ M^{\\text{answer}+q} \u0026amp;= \\text{Normed-ResNet}(\\text{Transformer-Encoder-Block}(M^{\\text{answer}}, M^q)) \u0026amp;\\in \\mathbb{R}^{d \\times T\u0026rsquo;} \\\\ M^{\\text{answer}+q+p_{all}} \u0026amp;= \\text{Normed-ResNet}(\\text{Transformer-Encoder-Block}(M^{\\text{answer}+q}, M^{p_{all}})) \u0026amp;\\in \\mathbb{R}^{d \\times T\u0026rsquo;} \\\\ S = \\lbrace s_1, \\ldots, s_{T\u0026rsquo;} \\rbrace \u0026amp;= \\text{Normed-ResNet}(\\text{Feed-Forward}(M^{\\text{answer}+q+p_{all}})) \u0026amp;\\in \\mathbb{R}^{d \\times T\u0026rsquo;} \\\\ \u0026amp; \\text{where} \\\\ \u0026amp; T\u0026rsquo; = T+1 \\hspace{10pt} \\text{(answer style + answer)} \\\\ \u0026amp; M^{p_{all}} = \\left[M^{p_1}, \\ldots, M^{p_K}\\right] \\in \\mathbb{R}^{d \\times KL} \\\\ \u0026amp; [, ] \\mapsto \\text{vector concatenation across the columns} \\end{align*} $$\nMulti-source Pointer-Generator Multi-source Pointer-Generator mechanism Extended vocabulary distribution Question及びPassagesのVocabularyとCommon Wordsを合わせたVocabularyをExtended Vocaburary( $V_{\\text{ext}}$ )とする $$ \\begin{align*} P^v(y_t) \u0026amp;= \\text{softmax}\\left( {W^2}^\\mathsf{T} \\left(W^1 s_t + b^1 \\right) \\right) \\\\ \u0026amp;\\text{where} \\\\ \u0026amp; W^2 \\in \\mathbb{R}^{d_{\\text{word}} \\times V_{\\text{ext}}} \\\\ \u0026amp; W^1 \\in \\mathbb{R}^{d_{\\text{word}} \\times d} \\\\ \u0026amp; b^1 \\in \\mathbb{R}^{d_{\\text{word}}} \\\\ \u0026amp; P^v(y_t) = 0 \\hspace{10pt} \\text{if }y_t\\text{ is an out-of-vocabulary word for } V \\end{align*} $$\nExtended vocabulary $\\rightarrow$ (Hakan Inan et al., 2016) Hakan Inan, Khashayar Khosravi, R. Socher. (2016)\nTying Word Vectors and Word Classifiers: A Loss Framework for Language Modeling\nICLR\nPaper Link\nInfluential Citation Count (34), SS-ID (424aef7340ee618132cc3314669400e23ad910ba)\nABSTRACT\nRecurrent neural networks have been very successful at predicting sequences of words in tasks such as language modeling. However, all such models are based on the conventional classification framework, where the model is trained against one-hot targets, and each word is represented both as an input and as an output in isolation. This causes inefficiencies in learning both in terms of utilizing all of the information and in terms of the number of parameters needed to train. We introduce a novel theoretical framework that facilitates better learning in language modeling, and show that our framework leads to tying together the input embedding and the output projection matrices, greatly reducing the number of trainable variables. Our framework leads to state of the art performance on the Penn Treebank with a variety of network models. Copy distribution Additional Attention Layer $$ \\begin{align*} e_l^{p_k} \u0026amp;= {w^p}^\\mathsf{T} \\tanh \\left(W^{pm} M_l^{p_k} + W^{ps} s_t + b^p \\right) \\\\ \\alpha_t^p \u0026amp;= \\text{softmax}\\left(\\left[ e^{p_1}; \\ldots; e^{p_K}\\right]\\right) \u0026amp;\\in \\mathbb{R}^{KL} \\\\ c_t^p \u0026amp;= \\sum_l \\alpha_{tl}^p M_l^{p_{all}} \u0026amp;\\in \\mathbb{R}^d \\\\ \u0026amp; \\text{where} \\\\ \u0026amp; w^p, b^p \\in \\mathbb{R}^d \\hspace{10pt} \\text{(learnable paramters)} \\\\ \u0026amp; W^{pm}, W^{ps} \\in \\mathbb{R}^{d \\times d} \\hspace{10pt} \\text{(learnable paramters)} \\end{align*} $$\nQuestion及びPassagesのそれぞれに対してCopy Distributions (over the extended vocabulary)を算出する\n$$ \\begin{align*} P^q(y_t) \u0026amp;= \\sum_{j:x_j^q=y_t} \\alpha_{tj}^q \\\\ P^p(y_t) \u0026amp;= \\sum_{l:x_l^{p_{k(l)}}=y_t} \\alpha_{tl}^p \\\\ \u0026amp; \\text{where} \\\\ \u0026amp; k(l) \\mapsto \\text{the passage index corresponding to the }l\\text{-th word in the concatenated passages} \\end{align*} $$\nTransformer-based pointer-generator $\\rightarrow$ (Sebastian Gehrmann et al., 2018) Sebastian Gehrmann, Yuntian Deng, Alexander M. Rush. (2018)\nBottom-Up Abstractive Summarization\nEMNLP\nPaper Link\nInfluential Citation Count (75), SS-ID (7af89df3691d8c33aaf1858f7cc51da1bc9549a9)\nABSTRACT\nNeural summarization produces outputs that are fluent and readable, but which can be poor at content selection, for instance often copying full sentences from the source document. This work explores the use of data-efficient content selectors to over-determine phrases in a source document that should be part of the summary. We use this selector as a bottom-up attention step to constrain the model to likely phrases. We show that this approach improves the ability to compress text, while still generating fluent summaries. This two-step process is both simpler and higher performing than other end-to-end content selection models, leading to significant improvements on ROUGE for both the CNN-DM and NYT corpus. Furthermore, the content selector can be trained with as little as 1,000 sentences making it easy to transfer a trained summarizer to a new domain. Final distribution $$ \\begin{align*} P(y_t) \u0026amp;= \\lambda^v P^v(y_t) + \\lambda^q P^q(y_t) + \\lambda^p P^p(y_t) \\\\ \\lambda^v, \\lambda^q, \\lambda^p \u0026amp;= \\text{softmax}\\left( W^m\\left[ s_t; c_t^q; c_t^p \\right] + b^m \\right) \\\\ \u0026amp; \\text{where} \\\\ \u0026amp; W^m \\in \\mathbb{R}^{3 \\times 3d} \\\\ \u0026amp; b^m \\in \\mathbb{R}^3 \\end{align*} $$\nCombined Attention 関連性のないPassageに含まれる単語が混入することを防ぐために，Combined Attention を導入する Additional Attention Layerを下記の式で修正する $$ \\alpha_{tl}^p = \\frac{\\alpha_{tl}^p \\beta^{p_k(l)}}{\\sum_{l\u0026rsquo;} \\alpha_{tl\u0026rsquo;}^p \\beta^{p_k(l\u0026rsquo;)}} $$\nLoss Function $$ \\begin{align*} L(\\theta) \u0026amp;= L_{\\text{dec}} + \\gamma_{\\text{rank}} L_{\\text{rank}} + \\gamma_{\\text{cls}} L_{\\text{cls}} \\\\ L_{\\text{dec}} \u0026amp;= -\\frac{1}{N_{\\text{able}}} \\sum_{(a,y) \\in \\mathcal{D}} \\frac{a}{T} \\sum_t \\log P(y_t) \\\\ L_{\\text{rank}} \u0026amp;= -\\frac{1}{NK}\\sum_k\\sum_{r^{p_k} \\in \\mathcal{D}} \\left( r^{p_k} \\log \\beta^{p_k} + (1 - r^{p_k}) \\log (1 - \\beta^{p_k}) \\right) \\\\ L_{\\text{cls}} \u0026amp;= -\\frac{1}{N}\\sum_{a \\in \\mathcal{D}} \\left( a\\log P(a) + (1 - a) \\log (1 - P(a)) \\right) \\\\ \u0026amp; \\text{where} \\\\ \u0026amp; \\gamma_{\\text{rank}}, \\gamma_{\\text{cls}} \\mapsto \\text{balancing hyper-parameters} \\\\ \u0026amp; N_{\\text{able}} \\mapsto \\text{answerable examples} \\\\ \u0026amp; \\mathcal{D} \\mapsto \\text{the training dataset} \\end{align*} $$\nTraining Settings Results MSMARCO v2 NarrativeQA References SQuAD: 100,000\u0026#43; Questions for Machine Comprehension of Text (Pranav Rajpurkar et al., 2016) Pranav Rajpurkar, Jian Zhang, Konstantin Lopyrev, Percy Liang. (2016)\nSQuAD: 100,000+ Questions for Machine Comprehension of Text\nEMNLP\nPaper Link\nInfluential Citation Count (1066), SS-ID (05dd7254b632376973f3a1b4d39485da17814df5)\nABSTRACT\nWe present the Stanford Question Answering Dataset (SQuAD), a new reading comprehension dataset consisting of 100,000+ questions posed by crowdworkers on a set of Wikipedia articles, where the answer to each question is a segment of text from the corresponding reading passage. We analyze the dataset to understand the types of reasoning required to answer the questions, leaning heavily on dependency and constituency trees. We build a strong logistic regression model, which achieves an F1 score of 51.0%, a significant improvement over a simple baseline (20%). However, human performance (86.8%) is much higher, indicating that the dataset presents a good challenge problem for future research. The dataset is freely available at this https URL\nStyle Transfer in Text: Exploration and Evaluation (Zhenxin Fu et al., 2017) Zhenxin Fu, Xiaoye Tan, Nanyun Peng, Dongyan Zhao, Rui Yan. (2017)\nStyle Transfer in Text: Exploration and Evaluation\nAAAI\nPaper Link\nInfluential Citation Count (86), SS-ID (065191b835fee705a6a5a2818aaa944437089ce8)\nABSTRACT\nStyle transfer is an important problem in natural language processing (NLP). However, the progress in language style transfer is lagged behind other domains, such as computer vision, mainly because of the lack of parallel data and principle evaluation metrics. In this paper, we propose to learn style transfer with non-parallel data. We explore two models to achieve this goal, and the key idea behind the proposed models is to learn separate content representations and style representations using adversarial networks. We also propose novel evaluation metrics which measure two aspects of style transfer: transfer strength and content preservation. We access our models and the evaluation metrics on two tasks: paper-news title transfer, and positive-negative review transfer. Results show that the proposed content preservation metric is highly correlate to human judgments, and the proposed models are able to generate sentences with higher style transfer strength and similar content preservation score comparing to auto-encoder.\nEfficient and Robust Question Answering from Minimal Context over Documents (Sewon Min et al., 2018) Sewon Min, Victor Zhong, R. Socher, Caiming Xiong. (2018)\nEfficient and Robust Question Answering from Minimal Context over Documents\nACL\nPaper Link\nInfluential Citation Count (11), SS-ID (090294db9fbcfc27e38b11050029bcb6fb794331)\nABSTRACT\nNeural models for question answering (QA) over documents have achieved significant performance improvements. Although effective, these models do not scale to large corpora due to their complex modeling of interactions between the document and the question. Moreover, recent work has shown that such models are sensitive to adversarial inputs. In this paper, we study the minimal context required to answer the question, and find that most questions in existing datasets can be answered with a small set of sentences. Inspired by this observation, we propose a simple sentence selector to select the minimal set of sentences to feed into the QA model. Our overall system achieves significant reductions in training (up to 15 times) and inference times (up to 13 times), with accuracy comparable to or better than the state-of-the-art on SQuAD, NewsQA, TriviaQA and SQuAD-Open. Furthermore, our experimental results and analyses show that our approach is more robust to adversarial inputs.\nMulti-Passage Machine Reading Comprehension with Cross-Passage Answer Verification (Yizhong Wang et al., 2018) Yizhong Wang, Kai Liu, Jing Liu, W. He, Yajuan Lyu, Hua Wu, Sujian Li, Haifeng Wang. (2018)\nMulti-Passage Machine Reading Comprehension with Cross-Passage Answer Verification\nACL\nPaper Link\nInfluential Citation Count (14), SS-ID (0985497d1de3ffd11713e75289cc2ad55836623d)\nABSTRACT\nMachine reading comprehension (MRC) on real web data usually requires the machine to answer a question by analyzing multiple passages retrieved by search engine. Compared with MRC on a single passage, multi-passage MRC is more challenging, since we are likely to get multiple confusing answer candidates from different passages. To address this problem, we propose an end-to-end neural model that enables those answer candidates from different passages to verify each other based on their content representations. Specifically, we jointly train three modules that can predict the final answer based on three factors: the answer boundary, the answer content and the cross-passage answer verification. The experimental results show that our method outperforms the baseline by a large margin and achieves the state-of-the-art performance on the English MS-MARCO dataset and the Chinese DuReader dataset, both of which are designed for MRC in real-world settings.\nReading Wikipedia to Answer Open-Domain Questions (Danqi Chen et al., 2017) Danqi Chen, Adam Fisch, J. Weston, Antoine Bordes. (2017)\nReading Wikipedia to Answer Open-Domain Questions\nACL\nPaper Link\nInfluential Citation Count (281), SS-ID (104715e1097b7ebee436058bfd9f45540f269845)\nABSTRACT\nThis paper proposes to tackle open- domain question answering using Wikipedia as the unique knowledge source: the answer to any factoid question is a text span in a Wikipedia article. This task of machine reading at scale combines the challenges of document retrieval (finding the relevant articles) with that of machine comprehension of text (identifying the answer spans from those articles). Our approach combines a search component based on bigram hashing and TF-IDF matching with a multi-layer recurrent neural network model trained to detect answers in Wikipedia paragraphs. Our experiments on multiple existing QA datasets indicate that (1) both modules are highly competitive with respect to existing counterparts and (2) multitask learning using distant supervision on their combination is an effective complete system on this challenging task.\nGaussian Error Linear Units (GELUs) (Dan Hendrycks et al., 2016) Dan Hendrycks, Kevin Gimpel. (2016)\nGaussian Error Linear Units (GELUs)\nPaper Link\nInfluential Citation Count (113), SS-ID (15f4c35889ccc1ae258b680c2ca2fcbfe1e260f7)\nABSTRACT\nWe propose the Gaussian Error Linear Unit (GELU), a high-performing neural network activation function. The GELU activation function is $x\\Phi(x)$, where $\\Phi(x)$ the standard Gaussian cumulative distribution function. The GELU nonlinearity weights inputs by their value, rather than gates inputs by their sign as in ReLUs ($x\\mathbf{1}_{x\u0026gt;0}$). We perform an empirical evaluation of the GELU nonlinearity against the ReLU and ELU activations and find performance improvements across all considered computer vision, natural language processing, and speech tasks.\nMultitask Learning (R. Caruana, 1997) R. Caruana. (1997)\nMultitask Learning\nMachine Learning\nPaper Link\nInfluential Citation Count (38), SS-ID (161ffb54a3fdf0715b198bb57bd22f910242eb49)\nABSTRACT\nMultitask Learning is an approach to inductive transfer that improves generalization by using the domain information contained in the training signals of related tasks as an inductive bias. It does this by learning tasks in parallel while using a shared representation; what is learned for each task can help other tasks be learned better. This paper reviews prior work on MTL, presents new evidence that MTL in backprop nets discovers task relatedness without the need of supervisory signals, and presents new results for MTL with k-nearest neighbor and kernel regression. In this paper we demonstrate multitask learning in three domains. We explain how multitask learning works, and show that there are many opportunities for multitask learning in real domains. We present an algorithm and results for multitask learning with case-based methods like k-nearest neighbor and kernel regression, and sketch an algorithm for multitask learning in decision trees. Because multitask learning works, can be applied to many different kinds of domains, and can be used with different learning algorithms, we conjecture there will be many opportunities for its use on real-world problems.\nLearning and Evaluating General Linguistic Intelligence (Dani Yogatama et al., 2019) Dani Yogatama, Cyprien de Masson d\u0026rsquo;Autume, Jerome T. Connor, Tomás Kociský, Mike Chrzanowski, Lingpeng Kong, Angeliki Lazaridou, Wang Ling, Lei Yu, Chris Dyer, P. Blunsom. (2019)\nLearning and Evaluating General Linguistic Intelligence\nArXiv\nPaper Link\nInfluential Citation Count (6), SS-ID (19281b9ecdb5c07a93423a506627ab9d9b0cf039)\nABSTRACT\nWe define general linguistic intelligence as the ability to reuse previously acquired knowledge about a language\u0026rsquo;s lexicon, syntax, semantics, and pragmatic conventions to adapt to new tasks quickly. Using this definition, we analyze state-of-the-art natural language understanding models and conduct an extensive empirical investigation to evaluate them against these criteria through a series of experiments that assess the task-independence of the knowledge being acquired by the learning process. In addition to task performance, we propose a new evaluation metric based on an online encoding of the test data that quantifies how quickly an existing agent (model) learns a new task. Our results show that while the field has made impressive progress in terms of model architectures that generalize to many tasks, these models still require a lot of in-domain training examples (e.g., for fine tuning, training task-specific modules), and are prone to catastrophic forgetting. Moreover, we find that far from solving general tasks (e.g., document question answering), our models are overfitting to the quirks of particular datasets (e.g., SQuAD). We discuss missing components and conjecture on how to make progress toward general linguistic intelligence.\nDelete, Retrieve, Generate: a Simple Approach to Sentiment and Style Transfer (Juncen Li et al., 2018) Juncen Li, Robin Jia, He He, Percy Liang. (2018)\nDelete, Retrieve, Generate: a Simple Approach to Sentiment and Style Transfer\nNAACL\nPaper Link\nInfluential Citation Count (115), SS-ID (1975ae6d8693eedfb07d5348798351fe51ab242b)\nABSTRACT\nWe consider the task of text attribute transfer: transforming a sentence to alter a specific attribute (e.g., sentiment) while preserving its attribute-independent content (e.g., “screen is just the right size” to “screen is too small”). Our training data includes only sentences labeled with their attribute (e.g., positive and negative), but not pairs of sentences that only differ in the attributes, so we must learn to disentangle attributes from attribute-independent content in an unsupervised way. Previous work using adversarial methods has struggled to produce high-quality outputs. In this paper, we propose simpler methods motivated by the observation that text attributes are often marked by distinctive phrases (e.g., “too small”). Our strongest method extracts content words by deleting phrases associated with the sentence’s original attribute value, retrieves new phrases associated with the target attribute, and uses a neural model to fluently combine these into a final output. Based on human evaluation, our best method generates grammatical and appropriate responses on 22% more inputs than the best previous system, averaged over three attribute transfer datasets: altering sentiment of reviews on Yelp, altering sentiment of reviews on Amazon, and altering image captions to be more romantic or humorous.\nAttention is All you Need (Ashish Vaswani et al., 2017) Ashish Vaswani, Noam M. Shazeer, Niki Parmar, Jakob Uszkoreit, Llion Jones, Aidan N. Gomez, Lukasz Kaiser, Illia Polosukhin. (2017)\nAttention is All you Need\nNIPS\nPaper Link\nInfluential Citation Count (7622), SS-ID (204e3073870fae3d05bcbc2f6a8e263d9b72e776)\nABSTRACT\nThe dominant sequence transduction models are based on complex recurrent or convolutional neural networks in an encoder-decoder configuration. The best performing models also connect the encoder and decoder through an attention mechanism. We propose a new simple network architecture, the Transformer, based solely on attention mechanisms, dispensing with recurrence and convolutions entirely. Experiments on two machine translation tasks show these models to be superior in quality while being more parallelizable and requiring significantly less time to train. Our model achieves 28.4 BLEU on the WMT 2014 English-to-German translation task, improving over the existing best results, including ensembles by over 2 BLEU. On the WMT 2014 English-to-French translation task, our model establishes a new single-model state-of-the-art BLEU score of 41.8 after training for 3.5 days on eight GPUs, a small fraction of the training costs of the best models from the literature. We show that the Transformer generalizes well to other tasks by applying it successfully to English constituency parsing both with large and limited training data.\nHotpotQA: A Dataset for Diverse, Explainable Multi-hop Question Answering (Zhilin Yang et al., 2018) Zhilin Yang, Peng Qi, Saizheng Zhang, Yoshua Bengio, William W. Cohen, R. Salakhutdinov, Christopher D. Manning. (2018)\nHotpotQA: A Dataset for Diverse, Explainable Multi-hop Question Answering\nEMNLP\nPaper Link\nInfluential Citation Count (195), SS-ID (22655979df781d222eaf812b0d325fa9adf11594)\nABSTRACT\nExisting question answering (QA) datasets fail to train QA systems to perform complex reasoning and provide explanations for answers. We introduce HotpotQA, a new dataset with 113k Wikipedia-based question-answer pairs with four key features: (1) the questions require finding and reasoning over multiple supporting documents to answer; (2) the questions are diverse and not constrained to any pre-existing knowledge bases or knowledge schemas; (3) we provide sentence-level supporting facts required for reasoning, allowing QA systems to reason with strong supervision and explain the predictions; (4) we offer a new type of factoid comparison questions to test QA systems’ ability to extract relevant facts and perform necessary comparison. We show that HotpotQA is challenging for the latest QA systems, and the supporting facts enable models to improve performance and make explainable predictions.\nRethinking the Inception Architecture for Computer Vision (Christian Szegedy et al., 2015) Christian Szegedy, Vincent Vanhoucke, S. Ioffe, Jonathon Shlens, Z. Wojna. (2015)\nRethinking the Inception Architecture for Computer Vision\n2016 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)\nPaper Link\nInfluential Citation Count (2183), SS-ID (23ffaa0fe06eae05817f527a47ac3291077f9e58)\nABSTRACT\nConvolutional networks are at the core of most state of-the-art computer vision solutions for a wide variety of tasks. Since 2014 very deep convolutional networks started to become mainstream, yielding substantial gains in various benchmarks. Although increased model size and computational cost tend to translate to immediate quality gains for most tasks (as long as enough labeled data is provided for training), computational efficiency and low parameter count are still enabling factors for various use cases such as mobile vision and big-data scenarios. Here we are exploring ways to scale up networks in ways that aim at utilizing the added computation as efficiently as possible by suitably factorized convolutions and aggressive regularization. We benchmark our methods on the ILSVRC 2012 classification challenge validation set demonstrate substantial gains over the state of the art: 21:2% top-1 and 5:6% top-5 error for single frame evaluation using a network with a computational cost of 5 billion multiply-adds per inference and with using less than 25 million parameters. With an ensemble of 4 models and multi-crop evaluation, we report 3:5% top-5 error and 17:3% top-1 error on the validation set and 3:6% top-5 error on the official test set.\nGuiding Generation for Abstractive Text Summarization Based on Key Information Guide Network (Chenliang Li et al., 2018) Chenliang Li, Weiran Xu, Si Li, Sheng Gao. (2018)\nGuiding Generation for Abstractive Text Summarization Based on Key Information Guide Network\nNAACL\nPaper Link\nInfluential Citation Count (9), SS-ID (2770a733eecdda23c1b3f9408c9202efec4f0da0)\nABSTRACT\nNeural network models, based on the attentional encoder-decoder model, have good capability in abstractive text summarization. However, these models are hard to be controlled in the process of generation, which leads to a lack of key information. We propose a guiding generation model that combines the extractive method and the abstractive method. Firstly, we obtain keywords from the text by a extractive model. Then, we introduce a Key Information Guide Network (KIGN), which encodes the keywords to the key information representation, to guide the process of generation. In addition, we use a prediction-guide mechanism, which can obtain the long-term value for future decoding, to further guide the summary generation. We evaluate our model on the CNN/Daily Mail dataset. The experimental results show that our model leads to significant improvements.\nU-Net: Machine Reading Comprehension with Unanswerable Questions (Fu Sun et al., 2018) Fu Sun, Linyang Li, Xipeng Qiu, Yang Liu. (2018)\nU-Net: Machine Reading Comprehension with Unanswerable Questions\nArXiv\nPaper Link\nInfluential Citation Count (6), SS-ID (27e98e09cf09bc13c913d01676e5f32624011050)\nABSTRACT\nMachine reading comprehension with unanswerable questions is a new challenging task for natural language processing. A key subtask is to reliably predict whether the question is unanswerable. In this paper, we propose a unified model, called U-Net, with three important components: answer pointer, no-answer pointer, and answer verifier. We introduce a universal node and thus process the question and its context passage as a single contiguous sequence of tokens. The universal node encodes the fused information from both the question and passage, and plays an important role to predict whether the question is answerable and also greatly improves the conciseness of the U-Net. Different from the state-of-art pipeline models, U-Net can be learned in an end-to-end fashion. The experimental results on the SQuAD 2.0 dataset show that U-Net can effectively predict the unanswerability of questions and achieves an F1 score of 71.7 on SQuAD 2.0.\nToward Controlled Generation of Text (Zhiting Hu et al., 2017) Zhiting Hu, Zichao Yang, Xiaodan Liang, R. Salakhutdinov, E. Xing. (2017)\nToward Controlled Generation of Text\nICML\nPaper Link\nInfluential Citation Count (96), SS-ID (2a215755d7548ffc82079ce734c4ac60b62f6f56)\nABSTRACT\nGeneric generation and manipulation of text is challenging and has limited success compared to recent deep generative modeling in visual domain. This paper aims at generating plausible natural language sentences, whose attributes are dynamically controlled by learning disentangled latent representations with designated semantics. We propose a new neural generative model which combines variational auto-encoders and holistic attribute discriminators for effective imposition of semantic structures. With differentiable approximation to discrete text samples, explicit constraints on independent attribute controls, and efficient collaborative learning of generator and discriminators, our model learns highly interpretable representations from even only word annotations, and produces realistic sentences with desired attributes. Quantitative evaluation validates the accuracy of sentence and attribute generation.\nDeep Residual Learning for Image Recognition (Kaiming He et al., 2015) Kaiming He, X. Zhang, Shaoqing Ren, Jian Sun. (2015)\nDeep Residual Learning for Image Recognition\n2016 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)\nPaper Link\nInfluential Citation Count (19458), SS-ID (2c03df8b48bf3fa39054345bafabfeff15bfd11d)\nABSTRACT\nDeeper neural networks are more difficult to train. We present a residual learning framework to ease the training of networks that are substantially deeper than those used previously. We explicitly reformulate the layers as learning residual functions with reference to the layer inputs, instead of learning unreferenced functions. We provide comprehensive empirical evidence showing that these residual networks are easier to optimize, and can gain accuracy from considerably increased depth. On the ImageNet dataset we evaluate residual nets with a depth of up to 152 layers - 8× deeper than VGG nets [40] but still having lower complexity. An ensemble of these residual nets achieves 3.57% error on the ImageNet test set. This result won the 1st place on the ILSVRC 2015 classification task. We also present analysis on CIFAR-10 with 100 and 1000 layers. The depth of representations is of central importance for many visual recognition tasks. Solely due to our extremely deep representations, we obtain a 28% relative improvement on the COCO object detection dataset. Deep residual nets are foundations of our submissions to ILSVRC \u0026amp; COCO 2015 competitions1, where we also won the 1st places on the tasks of ImageNet detection, ImageNet localization, COCO detection, and COCO segmentation.\nDropout: a simple way to prevent neural networks from overfitting (Nitish Srivastava et al., 2014) Nitish Srivastava, Geoffrey E. Hinton, A. Krizhevsky, Ilya Sutskever, R. Salakhutdinov. (2014)\nDropout: a simple way to prevent neural networks from overfitting\nJ. Mach. Learn. Res.\nPaper Link\nInfluential Citation Count (2210), SS-ID (34f25a8704614163c4095b3ee2fc969b60de4698)\nABSTRACT\nDeep neural nets with a large number of parameters are very powerful machine learning systems. However, overfitting is a serious problem in such networks. Large networks are also slow to use, making it difficult to deal with overfitting by combining the predictions of many different large neural nets at test time. Dropout is a technique for addressing this problem. The key idea is to randomly drop units (along with their connections) from the neural network during training. This prevents units from co-adapting too much. During training, dropout samples from an exponential number of different \u0026ldquo;thinned\u0026rdquo; networks. At test time, it is easy to approximate the effect of averaging the predictions of all these thinned networks by simply using a single unthinned network that has smaller weights. This significantly reduces overfitting and gives major improvements over other regularization methods. We show that dropout improves the performance of neural networks on supervised learning tasks in vision, speech recognition, document classification and computational biology, obtaining state-of-the-art results on many benchmark data sets.\nBidirectional Attention Flow for Machine Comprehension (Minjoon Seo et al., 2016) Minjoon Seo, Aniruddha Kembhavi, Ali Farhadi, Hannaneh Hajishirzi. (2016)\nBidirectional Attention Flow for Machine Comprehension\nICLR\nPaper Link\nInfluential Citation Count (439), SS-ID (3a7b63b50c64f4ec3358477790e84cbd6be2a0b4)\nABSTRACT\nMachine comprehension (MC), answering a query about a given context paragraph, requires modeling complex interactions between the context and the query. Recently, attention mechanisms have been successfully extended to MC. Typically these methods use attention to focus on a small portion of the context and summarize it with a fixed-size vector, couple attentions temporally, and/or often form a uni-directional attention. In this paper we introduce the Bi-Directional Attention Flow (BIDAF) network, a multi-stage hierarchical process that represents the context at different levels of granularity and uses bi-directional attention flow mechanism to obtain a query-aware context representation without early summarization. Our experimental evaluations show that our model achieves the state-of-the-art results in Stanford Question Answering Dataset (SQuAD) and CNN/DailyMail cloze test.\nSimple and Effective Multi-Paragraph Reading Comprehension (Christopher Clark et al., 2017) Christopher Clark, Matt Gardner. (2017)\nSimple and Effective Multi-Paragraph Reading Comprehension\nACL\nPaper Link\nInfluential Citation Count (48), SS-ID (3c78c6df5eb1695b6a399e346dde880af27d1016)\nABSTRACT\nWe consider the problem of adapting neural paragraph-level question answering models to the case where entire documents are given as input. Our proposed solution trains models to produce well calibrated confidence scores for their results on individual paragraphs. We sample multiple paragraphs from the documents during training, and use a shared-normalization training objective that encourages the model to produce globally correct output. We combine this method with a state-of-the-art pipeline for training models on document QA data. Experiments demonstrate strong performance on several document QA datasets. Overall, we are able to achieve a score of 71.3 F1 on the web portion of TriviaQA, a large improvement from the 56.7 F1 of the previous best system.\nControlling Output Length in Neural Encoder-Decoders (Yuta Kikuchi et al., 2016) Yuta Kikuchi, Graham Neubig, Ryohei Sasano, Hiroya Takamura, M. Okumura. (2016)\nControlling Output Length in Neural Encoder-Decoders\nEMNLP\nPaper Link\nInfluential Citation Count (19), SS-ID (3cfdec4f1664fcdc20fd5a6d3f86e7b40cf19f70)\nABSTRACT\nNeural encoder-decoder models have shown great success in many sequence generation tasks. However, previous work has not investigated situations in which we would like to control the length of encoder-decoder outputs. This capability is crucial for applications such as text summarization, in which we have to generate concise summaries with a desired length. In this paper, we propose methods for controlling the output sequence length for neural encoder-decoder models: two decoding-based methods and two learning-based methods. Results show that our learning-based methods have the capability to control length without degrading summary quality in a summarization task.\nDeep Contextualized Word Representations (Matthew E. Peters et al., 2018) Matthew E. Peters, Mark Neumann, Mohit Iyyer, Matt Gardner, Christopher Clark, Kenton Lee, Luke Zettlemoyer. (2018)\nDeep Contextualized Word Representations\nNAACL\nPaper Link\nInfluential Citation Count (1347), SS-ID (3febb2bed8865945e7fddc99efd791887bb7e14f)\nABSTRACT\nWe introduce a new type of deep contextualized word representation that models both (1) complex characteristics of word use (e.g., syntax and semantics), and (2) how these uses vary across linguistic contexts (i.e., to model polysemy). Our word vectors are learned functions of the internal states of a deep bidirectional language model (biLM), which is pre-trained on a large text corpus. We show that these representations can be easily added to existing models and significantly improve the state of the art across six challenging NLP problems, including question answering, textual entailment and sentiment analysis. We also present an analysis showing that exposing the deep internals of the pre-trained network is crucial, allowing downstream models to mix different types of semi-supervision signals.\nFast Abstractive Summarization with Reinforce-Selected Sentence Rewriting (Yen-Chun Chen et al., 2018) Yen-Chun Chen, Mohit Bansal. (2018)\nFast Abstractive Summarization with Reinforce-Selected Sentence Rewriting\nACL\nPaper Link\nInfluential Citation Count (51), SS-ID (41b3180745068934bd9f7f2fbc2efc00c64d534b)\nABSTRACT\nInspired by how humans summarize long documents, we propose an accurate and fast summarization model that first selects salient sentences and then rewrites them abstractively (i.e., compresses and paraphrases) to generate a concise overall summary. We use a novel sentence-level policy gradient method to bridge the non-differentiable computation between these two neural networks in a hierarchical way, while maintaining language fluency. Empirically, we achieve the new state-of-the-art on all metrics (including human evaluation) on the CNN/Daily Mail dataset, as well as significantly higher abstractiveness scores. Moreover, by first operating at the sentence-level and then the word-level, we enable parallel decoding of our neural generative model that results in substantially faster (10-20x) inference speed as well as 4x faster training convergence than previous long-paragraph encoder-decoder models. We also demonstrate the generalization of our model on the test-only DUC-2002 dataset, where we achieve higher scores than a state-of-the-art model.\nTying Word Vectors and Word Classifiers: A Loss Framework for Language Modeling (Hakan Inan et al., 2016) Hakan Inan, Khashayar Khosravi, R. Socher. (2016)\nTying Word Vectors and Word Classifiers: A Loss Framework for Language Modeling\nICLR\nPaper Link\nInfluential Citation Count (34), SS-ID (424aef7340ee618132cc3314669400e23ad910ba)\nABSTRACT\nRecurrent neural networks have been very successful at predicting sequences of words in tasks such as language modeling. However, all such models are based on the conventional classification framework, where the model is trained against one-hot targets, and each word is represented both as an input and as an output in isolation. This causes inefficiencies in learning both in terms of utilizing all of the information and in terms of the number of parameters needed to train. We introduce a novel theoretical framework that facilitates better learning in language modeling, and show that our framework leads to tying together the input embedding and the output projection matrices, greatly reducing the number of trainable variables. Our framework leads to state of the art performance on the Penn Treebank with a variety of network models.\nBridging Nonlinearities and Stochastic Regularizers with Gaussian Error Linear Units (Dan Hendrycks et al., 2016) Dan Hendrycks, Kevin Gimpel. (2016)\nBridging Nonlinearities and Stochastic Regularizers with Gaussian Error Linear Units\nArXiv\nPaper Link\nInfluential Citation Count (42), SS-ID (4361e64f2d12d63476fdc88faf72a0f70d9a2ffb)\nABSTRACT\nWe propose the Gaussian Error Linear Unit (GELU), a high-performing neural network activation function. The GELU nonlinearity is the expected transformation of a stochastic regularizer which randomly applies the identity or zero map, combining the intuitions of dropout and zoneout while respecting neuron values. This connection suggests a new probabilistic understanding of nonlinearities. We perform an empirical evaluation of the GELU nonlinearity against the ReLU and ELU activations and find performance improvements across all tasks.\nFixing Weight Decay Regularization in Adam (I. Loshchilov et al., 2017) I. Loshchilov, F. Hutter. (2017)\nFixing Weight Decay Regularization in Adam\nArXiv\nPaper Link\nInfluential Citation Count (93), SS-ID (45dfef0cc1ed96558c1c650432ce39d6a1050b6a)\nABSTRACT\nWe note that common implementations of adaptive gradient algorithms, such as Adam, limit the potential benefit of weight decay regularization, because the weights do not decay multiplicatively (as would be expected for standard weight decay) but by an additive constant factor. We propose a simple way to resolve this issue by decoupling weight decay and the optimization steps taken w.r.t. the loss function. We provide empirical evidence that our proposed modification (i) decouples the optimal choice of weight decay factor from the setting of the learning rate for both standard SGD and Adam, and (ii) substantially improves Adam\u0026rsquo;s generalization performance, allowing it to compete with SGD with momentum on image classification datasets (on which it was previously typically outperformed by the latter). We also demonstrate that longer optimization runs require smaller weight decay values for optimal results and introduce a normalized variant of weight decay to reduce this dependence. Finally, we propose a version of Adam with warm restarts (AdamWR) that has strong anytime performance while achieving state-of-the-art results on CIFAR-10 and ImageNet32x32. Our source code will become available after the review process.\nMulti-Reward Reinforced Summarization with Saliency and Entailment (Ramakanth Pasunuru et al., 2018) Ramakanth Pasunuru, Mohit Bansal. (2018)\nMulti-Reward Reinforced Summarization with Saliency and Entailment\nNAACL\nPaper Link\nInfluential Citation Count (9), SS-ID (46d8767a078778aaa00d436b671a78f90667ebff)\nABSTRACT\nAbstractive text summarization is the task of compressing and rewriting a long document into a short summary while maintaining saliency, directed logical entailment, and non-redundancy. In this work, we address these three important aspects of a good summary via a reinforcement learning approach with two novel reward functions: ROUGESal and Entail, on top of a coverage-based baseline. The ROUGESal reward modifies the ROUGE metric by up-weighting the salient phrases/words detected via a keyphrase classifier. The Entail reward gives high (length-normalized) scores to logically-entailed summaries using an entailment classifier. Further, we show superior performance improvement when these rewards are combined with traditional metric (ROUGE) based rewards, via our novel and effective multi-reward approach of optimizing multiple rewards simultaneously in alternate mini-batches. Our method achieves the new state-of-the-art results on CNN/Daily Mail dataset as well as strong improvements in a test-only transfer setup on DUC-2002.\nAttention-Guided Answer Distillation for Machine Reading Comprehension (Minghao Hu et al., 2018) Minghao Hu, Yuxing Peng, Furu Wei, Zhen Huang, Dongsheng Li, Nan Yang, M. Zhou. (2018)\nAttention-Guided Answer Distillation for Machine Reading Comprehension\nEMNLP\nPaper Link\nInfluential Citation Count (6), SS-ID (48fdf50da3d2bbd3b85ea9d17bbf3d173f6164ea)\nABSTRACT\nDespite that current reading comprehension systems have achieved significant advancements, their promising performances are often obtained at the cost of making an ensemble of numerous models. Besides, existing approaches are also vulnerable to adversarial attacks. This paper tackles these problems by leveraging knowledge distillation, which aims to transfer knowledge from an ensemble model to a single model. We first demonstrate that vanilla knowledge distillation applied to answer span prediction is effective for reading comprehension systems. We then propose two novel approaches that not only penalize the prediction on confusing answers but also guide the training with alignment information distilled from the ensemble. Experiments show that our best student model has only a slight drop of 0.4% F1 on the SQuAD test set compared to the ensemble teacher, while running 12x faster during inference. It even outperforms the teacher on adversarial SQuAD datasets and NarrativeQA benchmark.\nS-Net: From Answer Extraction to Answer Synthesis for Machine Reading Comprehension (Chuanqi Tan et al., 2018) Chuanqi Tan, Furu Wei, Nan Yang, Bowen Du, Weifeng Lv, M. Zhou. (2018)\nS-Net: From Answer Extraction to Answer Synthesis for Machine Reading Comprehension\nAAAI\nPaper Link\nInfluential Citation Count (3), SS-ID (49f4ab44c9672f88637b7feaa182cf0b8b07a4c8)\nABSTRACT\nIn this paper, we present a novel approach to machine reading comprehension for the MS-MARCO dataset. Unlike the SQuAD dataset that aims to answer a question with exact text spans in a passage, the MS-MARCO dataset defines the task as answering a question from multiple passages and the words in the answer are not necessary in the passages. We therefore develop an extraction-then-synthesis framework to synthesize answers from extraction results. Specifically, the answer extraction model is first employed to predict the most important sub-spans from the passage as evidence, and the answer synthesis model takes the evidence as additional features along with the question and passage to further elaborate the final answers. We build the answer extraction model with state-ofthe-art neural networks for single passage reading comprehension, and propose an additional task of passage ranking to help answer extraction in multiple passages. The answer synthesis model is based on the sequence-to-sequence neural networks with extracted evidences as features. Experiments show that our extraction-then-synthesis method outperforms state-of-the-art methods.\nRetrieve-and-Read: Multi-task Learning of Information Retrieval and Reading Comprehension (Kyosuke Nishida et al., 2018) Kyosuke Nishida, Itsumi Saito, A. Otsuka, H. Asano, J. Tomita. (2018)\nRetrieve-and-Read: Multi-task Learning of Information Retrieval and Reading Comprehension\nCIKM\nPaper Link\nInfluential Citation Count (3), SS-ID (4b69fbc425daf8f60f4dce42696b9b6d08d6c64f)\nABSTRACT\nThis study considers the task of machine reading at scale (MRS) wherein, given a question, a system first performs the information retrieval (IR) task of finding relevant passages in a knowledge source and then carries out the reading comprehension (RC) task of extracting an answer span from the passages. Previous MRS studies, in which the IR component was trained without considering answer spans, struggled to accurately find a small number of relevant passages from a large set of passages. In this paper, we propose a simple and effective approach that incorporates the IR and RC tasks by using supervised multi-task learning in order that the IR component can be trained by considering answer spans. Experimental results on the standard benchmark, answering SQuAD questions using the full Wikipedia as the knowledge source, showed that our model achieved state-of-the-art performance. Moreover, we thoroughly evaluated the individual contributions of our model components with our new Japanese dataset and SQuAD. The results showed significant improvements in the IR task and provided a new perspective on IR for RC: it is effective to teach which part of the passage answers the question rather than to give only a relevance score to the whole passage.\nKnow What You Don’t Know: Unanswerable Questions for SQuAD (Pranav Rajpurkar et al., 2018) Pranav Rajpurkar, Robin Jia, Percy Liang. (2018)\nKnow What You Don’t Know: Unanswerable Questions for SQuAD\nACL\nPaper Link\nInfluential Citation Count (340), SS-ID (4d1c856275744c0284312a3a50efb6ca9dc4cd4c)\nABSTRACT\nExtractive reading comprehension systems can often locate the correct answer to a question in a context document, but they also tend to make unreliable guesses on questions for which the correct answer is not stated in the context. Existing datasets either focus exclusively on answerable questions, or use automatically generated unanswerable questions that are easy to identify. To address these weaknesses, we present SQuADRUn, a new dataset that combines the existing Stanford Question Answering Dataset (SQuAD) with over 50,000 unanswerable questions written adversarially by crowdworkers to look similar to answerable ones. To do well on SQuADRUn, systems must not only answer questions when possible, but also determine when no answer is supported by the paragraph and abstain from answering. SQuADRUn is a challenging natural language understanding task for existing models: a strong neural system that gets 86% F1 on SQuAD achieves only 66% F1 on SQuADRUn. We release SQuADRUn to the community as the successor to SQuAD.\nS-Net: From Answer Extraction to Answer Generation for Machine Reading Comprehension (Chuanqi Tan et al., 2017) Chuanqi Tan, Furu Wei, Nan Yang, Weifeng Lv, M. Zhou. (2017)\nS-Net: From Answer Extraction to Answer Generation for Machine Reading Comprehension\nAAAI 2017\nPaper Link\nInfluential Citation Count (5), SS-ID (53875e16feb74e9425e2f9da743794c850087817)\nABSTRACT\nIn this paper, we present a novel approach to machine reading comprehension for the MS-MARCO dataset. Unlike the SQuAD dataset that aims to answer a question with exact text spans in a passage, the MS-MARCO dataset defines the task as answering a question from multiple passages and the words in the answer are not necessary in the passages. We therefore develop an extraction-then-synthesis framework to synthesize answers from extraction results. Specifically, the answer extraction model is first employed to predict the most important sub-spans from the passage as evidence, and the answer synthesis model takes the evidence as additional features along with the question and passage to further elaborate the final answers. We build the answer extraction model with state-of-the-art neural networks for single passage reading comprehension, and propose an additional task of passage ranking to help answer extraction in multiple passages. The answer synthesis model is based on the sequence-to-sequence neural networks with extracted evidences as features. Experiments show that our extraction-then-synthesis method outperforms state-of-the-art methods.\nGet To The Point: Summarization with Pointer-Generator Networks (A. See et al., 2017) A. See, Peter J. Liu, Christopher D. Manning. (2017)\nGet To The Point: Summarization with Pointer-Generator Networks\nACL\nPaper Link\nInfluential Citation Count (614), SS-ID (668db48c6a79826456341680ee1175dfc4cced71)\nABSTRACT\nNeural sequence-to-sequence models have provided a viable new approach for abstractive text summarization (meaning they are not restricted to simply selecting and rearranging passages from the original text). However, these models have two shortcomings: they are liable to reproduce factual details inaccurately, and they tend to repeat themselves. In this work we propose a novel architecture that augments the standard sequence-to-sequence attentional model in two orthogonal ways. First, we use a hybrid pointer-generator network that can copy words from the source text via pointing, which aids accurate reproduction of information, while retaining the ability to produce novel words through the generator. Second, we use coverage to keep track of what has been summarized, which discourages repetition. We apply our model to the CNN / Daily Mail summarization task, outperforming the current abstractive state-of-the-art by at least 2 ROUGE points.\nCommonsense for Generative Multi-Hop Question Answering Tasks (Lisa Bauer et al., 2018) Lisa Bauer, Yicheng Wang, Mohit Bansal. (2018)\nCommonsense for Generative Multi-Hop Question Answering Tasks\nEMNLP\nPaper Link\nInfluential Citation Count (12), SS-ID (711b1f7cc4e92d6f40c7813c6f0e1c2e179d48ad)\nABSTRACT\nReading comprehension QA tasks have seen a recent surge in popularity, yet most works have focused on fact-finding extractive QA. We instead focus on a more challenging multi-hop generative task (NarrativeQA), which requires the model to reason, gather, and synthesize disjoint pieces of information within the context to generate an answer. This type of multi-step reasoning also often requires understanding implicit relations, which humans resolve via external, background commonsense knowledge. We first present a strong generative baseline that uses a multi-attention mechanism to perform multiple hops of reasoning and a pointer-generator decoder to synthesize the answer. This model performs substantially better than previous generative models, and is competitive with current state-of-the-art span prediction models. We next introduce a novel system for selecting grounded multi-hop relational commonsense information from ConceptNet via a pointwise mutual information and term-frequency based scoring function. Finally, we effectively use this extracted commonsense information to fill in gaps of reasoning between context hops, using a selectively-gated attention mechanism. This boosts the model’s performance significantly (also verified via human evaluation), establishing a new state-of-the-art for the task. We also show that our background knowledge enhancements are generalizable and improve performance on QAngaroo-WikiHop, another multi-hop reasoning dataset.\nBottom-Up Abstractive Summarization (Sebastian Gehrmann et al., 2018) Sebastian Gehrmann, Yuntian Deng, Alexander M. Rush. (2018)\nBottom-Up Abstractive Summarization\nEMNLP\nPaper Link\nInfluential Citation Count (75), SS-ID (7af89df3691d8c33aaf1858f7cc51da1bc9549a9)\nABSTRACT\nNeural summarization produces outputs that are fluent and readable, but which can be poor at content selection, for instance often copying full sentences from the source document. This work explores the use of data-efficient content selectors to over-determine phrases in a source document that should be part of the summary. We use this selector as a bottom-up attention step to constrain the model to likely phrases. We show that this approach improves the ability to compress text, while still generating fluent summaries. This two-step process is both simpler and higher performing than other end-to-end content selection models, leading to significant improvements on ROUGE for both the CNN-DM and NYT corpus. Furthermore, the content selector can be trained with as little as 1,000 sentences making it easy to transfer a trained summarizer to a new domain.\nGenerating Sequences With Recurrent Neural Networks (A. Graves, 2013) A. Graves. (2013)\nGenerating Sequences With Recurrent Neural Networks\nArXiv\nPaper Link\nInfluential Citation Count (307), SS-ID (89b1f4740ae37fd04f6ac007577bdd34621f0861)\nABSTRACT\nThis paper shows how Long Short-term Memory recurrent neural networks can be used to generate complex sequences with long-range structure, simply by predicting one data point at a time. The approach is demonstrated for text (where the data are discrete) and online handwriting (where the data are real-valued). It is then extended to handwriting synthesis by allowing the network to condition its predictions on a text sequence. The resulting system is able to generate highly realistic cursive handwriting in a wide variety of styles.\nQANet: Combining Local Convolution with Global Self-Attention for Reading Comprehension (Adams Wei Yu et al., 2018) Adams Wei Yu, David Dohan, Minh-Thang Luong, Rui Zhao, Kai Chen, Mohammad Norouzi, Quoc V. Le. (2018)\nQANet: Combining Local Convolution with Global Self-Attention for Reading Comprehension\nICLR\nPaper Link\nInfluential Citation Count (155), SS-ID (8c1b00128e74f1cd92aede3959690615695d5101)\nABSTRACT\nCurrent end-to-end machine reading and question answering (Q\u0026amp;A) models are primarily based on recurrent neural networks (RNNs) with attention. Despite their success, these models are often slow for both training and inference due to the sequential nature of RNNs. We propose a new Q\u0026amp;A architecture called QANet, which does not require recurrent networks: Its encoder consists exclusively of convolution and self-attention, where convolution models local interactions and self-attention models global interactions. On the SQuAD dataset, our model is 3x to 13x faster in training and 4x to 9x faster in inference, while achieving equivalent accuracy to recurrent models. The speed-up gain allows us to train the model with much more data. We hence combine our model with data generated by backtranslation from a neural machine translation model. On the SQuAD dataset, our single model, trained with augmented data, achieves 84.6 F1 score on the test set, which is significantly better than the best published F1 score of 81.8.\nDiversity driven attention model for query-based abstractive summarization (Preksha Nema et al., 2017) Preksha Nema, Mitesh M. Khapra, Anirban Laha, Balaraman Ravindran. (2017)\nDiversity driven attention model for query-based abstractive summarization\nACL\nPaper Link\nInfluential Citation Count (24), SS-ID (91957e38773e52203708039103e1163cf8786637)\nABSTRACT\nAbstractive summarization aims to generate a shorter version of the document covering all the salient points in a compact and coherent fashion. On the other hand, query-based summarization highlights those points that are relevant in the context of a given query. The encode-attend-decode paradigm has achieved notable success in machine translation, extractive summarization, dialog systems, etc. But it suffers from the drawback of generation of repeated phrases. In this work we propose a model for the query-based summarization task based on the encode-attend-decode paradigm with two key additions (i) a query attention model (in addition to document attention model) which learns to focus on different portions of the query at different time steps (instead of using a static representation for the query) and (ii) a new diversity based attention model which aims to alleviate the problem of repeating phrases in the summary. In order to enable the testing of this model we introduce a new query-based summarization dataset building on debatepedia. Our experiments show that with these two additions the proposed model clearly outperforms vanilla encode-attend-decode models with a gain of 28% (absolute) in ROUGE-L scores.\nLanguage Models are Unsupervised Multitask Learners (Alec Radford et al., 2019) Alec Radford, Jeff Wu, Rewon Child, D. Luan, Dario Amodei, Ilya Sutskever. (2019)\nLanguage Models are Unsupervised Multitask Learners\nPaper Link\nInfluential Citation Count (1317), SS-ID (9405cc0d6169988371b2755e573cc28650d14dfe)\nABSTRACT\nNatural language processing tasks, such as question answering, machine translation, reading comprehension, and summarization, are typically approached with supervised learning on taskspecific datasets. We demonstrate that language models begin to learn these tasks without any explicit supervision when trained on a new dataset of millions of webpages called WebText. When conditioned on a document plus questions, the answers generated by the language model reach 55 F1 on the CoQA dataset matching or exceeding the performance of 3 out of 4 baseline systems without using the 127,000+ training examples. The capacity of the language model is essential to the success of zero-shot task transfer and increasing it improves performance in a log-linear fashion across tasks. Our largest model, GPT-2, is a 1.5B parameter Transformer that achieves state of the art results on 7 out of 8 tested language modeling datasets in a zero-shot setting but still underfits WebText. Samples from the model reflect these improvements and contain coherent paragraphs of text. These findings suggest a promising path towards building language processing systems which learn to perform tasks from their naturally occurring demonstrations.\nThe Natural Language Decathlon: Multitask Learning as Question Answering (Bryan McCann et al., 2018) Bryan McCann, N. Keskar, Caiming Xiong, R. Socher. (2018)\nThe Natural Language Decathlon: Multitask Learning as Question Answering\nArXiv\nPaper Link\nInfluential Citation Count (38), SS-ID (9784fbf77295860b2e412137b86356d70b25e3c0)\nABSTRACT\nPresented on August 28, 2018 at 12:15 p.m. in the Pettit Microelectronics Research Center, Room 102 A/B.\nLayer Normalization (Jimmy Ba et al., 2016) Jimmy Ba, J. Kiros, Geoffrey E. Hinton. (2016)\nLayer Normalization\nArXiv\nPaper Link\nInfluential Citation Count (164), SS-ID (97fb4e3d45bb098e27e0071448b6152217bd35a5)\nABSTRACT\nTraining state-of-the-art, deep neural networks is computationally expensive. One way to reduce the training time is to normalize the activities of the neurons. A recently introduced technique called batch normalization uses the distribution of the summed input to a neuron over a mini-batch of training cases to compute a mean and variance which are then used to normalize the summed input to that neuron on each training case. This significantly reduces the training time in feedforward neural networks. However, the effect of batch normalization is dependent on the mini-batch size and it is not obvious how to apply it to recurrent neural networks. In this paper, we transpose batch normalization into layer normalization by computing the mean and variance used for normalization from all of the summed inputs to the neurons in a layer on a single training case. Like batch normalization, we also give each neuron its own adaptive bias and gain which are applied after the normalization but before the non-linearity. Unlike batch normalization, layer normalization performs exactly the same computation at training and test times. It is also straightforward to apply to recurrent neural networks by computing the normalization statistics separately at each time step. Layer normalization is very effective at stabilizing the hidden state dynamics in recurrent networks. Empirically, we show that layer normalization can substantially reduce the training time compared with previously published techniques.\nCoQA: A Conversational Question Answering Challenge (Siva Reddy et al., 2018) Siva Reddy, Danqi Chen, Christopher D. Manning. (2018)\nCoQA: A Conversational Question Answering Challenge\nTACL\nPaper Link\nInfluential Citation Count (106), SS-ID (990a7b4eceedb6e053e6386269481bdfc42a1094)\nABSTRACT\nHumans gather information through conversations involving a series of interconnected questions and answers. For machines to assist in information gathering, it is therefore essential to enable them to answer conversational questions. We introduce CoQA, a novel dataset for building Conversational Question Answering systems. Our dataset contains 127k questions with answers, obtained from 8k conversations about text passages from seven diverse domains. The questions are conversational, and the answers are free-form text with their corresponding evidence highlighted in the passage. We analyze CoQA in depth and show that conversational questions have challenging phenomena not present in existing reading comprehension datasets (e.g., coreference and pragmatic reasoning). We evaluate strong dialogue and reading comprehension models on CoQA. The best system obtains an F1 score of 65.4%, which is 23.4 points behind human performance (88.8%), indicating that there is ample room for improvement. We present CoQA as a challenge to the community at https://stanfordnlp.github.io/coqa.\nDuReader: a Chinese Machine Reading Comprehension Dataset from Real-world Applications (Wei He et al., 2017) Wei He, Kai Liu, Jing Liu, Yajuan Lyu, Shiqi Zhao, Xinyan Xiao, Yuan Liu, Yizhong Wang, Hua Wu, Qiaoqiao She, Xuan Liu, Tian Wu, Haifeng Wang. (2017)\nDuReader: a Chinese Machine Reading Comprehension Dataset from Real-world Applications\nQA@ACL\nPaper Link\nInfluential Citation Count (32), SS-ID (995b7affd684b910d5a1c520c3af00fd20cc39b0)\nABSTRACT\nThis paper introduces DuReader, a new large-scale, open-domain Chinese ma- chine reading comprehension (MRC) dataset, designed to address real-world MRC. DuReader has three advantages over previous MRC datasets: (1) data sources: questions and documents are based on Baidu Search and Baidu Zhidao; answers are manually generated. (2) question types: it provides rich annotations for more question types, especially yes-no and opinion questions, that leaves more opportunity for the research community. (3) scale: it contains 200K questions, 420K answers and 1M documents; it is the largest Chinese MRC dataset so far. Experiments show that human performance is well above current state-of-the-art baseline systems, leaving plenty of room for the community to make improvements. To help the community make these improvements, both DuReader and baseline systems have been posted online. We also organize a shared competition to encourage the exploration of more models. Since the release of the task, there are significant improvements over the baselines.\nRead \u0026#43; Verify: Machine Reading Comprehension with Unanswerable Questions (Minghao Hu et al., 2018) Minghao Hu, Furu Wei, Yuxing Peng, Zhen Huang, Nan Yang, Ming Zhou. (2018)\nRead + Verify: Machine Reading Comprehension with Unanswerable Questions\nAAAI\nPaper Link\nInfluential Citation Count (18), SS-ID (9a5ba9aee44ab873f3d60b05e2773c693707da88)\nABSTRACT\nMachine reading comprehension with unanswerable questions aims to abstain from answering when no answer can be inferred. In addition to extract answers, previous works usually predict an additional “no-answer” probability to detect unanswerable cases. However, they fail to validate the answerability of the question by verifying the legitimacy of the predicted answer. To address this problem, we propose a novel read-then-verify system, which not only utilizes a neural reader to extract candidate answers and produce no-answer probabilities, but also leverages an answer verifier to decide whether the predicted answer is entailed by the input snippets. Moreover, we introduce two auxiliary losses to help the reader better handle answer extraction as well as no-answer detection, and investigate three different architectures for the answer verifier. Our experiments on the SQuAD 2.0 dataset show that our system obtains a score of 74.2 F1 on test set, achieving state-of-the-art results at the time of submission (Aug. 28th, 2018).\nControllable Abstractive Summarization (Angela Fan et al., 2017) Angela Fan, David Grangier, Michael Auli. (2017)\nControllable Abstractive Summarization\nNMT@ACL\nPaper Link\nInfluential Citation Count (19), SS-ID (9b4a861151fabae1dfd61c917d031c86d26be704)\nABSTRACT\nCurrent models for document summarization disregard user preferences such as the desired length, style, the entities that the user might be interested in, or how much of the document the user has already read. We present a neural summarization model with a simple but effective mechanism to enable users to specify these high level attributes in order to control the shape of the final summaries to better suit their needs. With user input, our system can produce high quality summaries that follow user preferences. Without user input, we set the control variables automatically – on the full text CNN-Dailymail dataset, we outperform state of the art abstractive systems (both in terms of F1-ROUGE1 40.38 vs. 39.53 F1-ROUGE and human evaluation.\nAverage Precision at n (Nick Craswell et al., 2009) Nick Craswell, S. Robertson. (2009)\nAverage Precision at n\nEncyclopedia of Database Systems\nPaper Link\nInfluential Citation Count (0), SS-ID (9b4d80975930a6c75d1fb762aa07333b3b755b86)\nABSTRACT\nGoogle’s Multilingual Neural Machine Translation System: Enabling Zero-Shot Translation (Melvin Johnson et al., 2016) Melvin Johnson, M. Schuster, Quoc V. Le, M. Krikun, Yonghui Wu, Z. Chen, Nikhil Thorat, F. Viégas, M. Wattenberg, G. Corrado, Macduff Hughes, J. Dean. (2016)\nGoogle’s Multilingual Neural Machine Translation System: Enabling Zero-Shot Translation\nTACL\nPaper Link\nInfluential Citation Count (162), SS-ID (a486e2839291111bb44fa1f07731ada123539f75)\nABSTRACT\nWe propose a simple solution to use a single Neural Machine Translation (NMT) model to translate between multiple languages. Our solution requires no changes to the model architecture from a standard NMT system but instead introduces an artificial token at the beginning of the input sentence to specify the required target language. Using a shared wordpiece vocabulary, our approach enables Multilingual NMT systems using a single model. On the WMT’14 benchmarks, a single multilingual model achieves comparable performance for English→French and surpasses state-of-theart results for English→German. Similarly, a single multilingual model surpasses state-of-the-art results for French→English and German→English on WMT’14 and WMT’15 benchmarks, respectively. On production corpora, multilingual models of up to twelve language pairs allow for better translation of many individual pairs. Our models can also learn to perform implicit bridging between language pairs never seen explicitly during training, showing that transfer learning and zero-shot translation is possible for neural translation. Finally, we show analyses that hints at a universal interlingua representation in our models and also show some interesting examples when mixing languages.\nMS MARCO: A Human Generated MAchine Reading COmprehension Dataset (Daniel Fernando Campos et al., 2016) Daniel Fernando Campos, Tri Nguyen, M. Rosenberg, Xia Song, Jianfeng Gao, Saurabh Tiwary, Rangan Majumder, L. Deng, Bhaskar Mitra. (2016)\nMS MARCO: A Human Generated MAchine Reading COmprehension Dataset\nCoCo@NIPS\nPaper Link\nInfluential Citation Count (190), SS-ID (a69cf45d44a9d806d2487a1ffb9eca71ee73c2ee)\nABSTRACT\nThis paper presents our recent work on the design and development of a new, large scale dataset, which we name MS MARCO, for MAchine Reading COmprehension. This new dataset is aimed to overcome a number of well-known weaknesses of previous publicly available datasets for the same task of reading comprehension and question answering. In MS MARCO, all questions are sampled from real anonymized user queries. The context passages, from which answers in the dataset are derived, are extracted from real web documents using the most advanced version of the Bing search engine. The answers to the queries are human generated. Finally, a subset of these queries has multiple answers. We aim to release one million queries and the corresponding answers in the dataset, which, to the best of our knowledge, is the most comprehensive real-world dataset of its kind in both quantity and quality. We are currently releasing 100,000 queries with their corresponding answers to inspire work in reading comprehension and question answering along with gathering feedback from the research community.\nAdam: A Method for Stochastic Optimization (Diederik P. Kingma et al., 2014) Diederik P. Kingma, Jimmy Ba. (2014)\nAdam: A Method for Stochastic Optimization\nICLR\nPaper Link\nInfluential Citation Count (14649), SS-ID (a6cb366736791bcccc5c8639de5a8f9636bf87e8)\nABSTRACT\nWe introduce Adam, an algorithm for first-order gradient-based optimization of stochastic objective functions, based on adaptive estimates of lower-order moments. The method is straightforward to implement, is computationally efficient, has little memory requirements, is invariant to diagonal rescaling of the gradients, and is well suited for problems that are large in terms of data and/or parameters. The method is also appropriate for non-stationary objectives and problems with very noisy and/or sparse gradients. The hyper-parameters have intuitive interpretations and typically require little tuning. Some connections to related algorithms, on which Adam was inspired, are discussed. We also analyze the theoretical convergence properties of the algorithm and provide a regret bound on the convergence rate that is comparable to the best known results under the online convex optimization framework. Empirical results demonstrate that Adam works well in practice and compares favorably to other stochastic optimization methods. Finally, we discuss AdaMax, a variant of Adam based on the infinity norm.\nDuoRC: Towards Complex Language Understanding with Paraphrased Reading Comprehension (Amrita Saha et al., 2018) Amrita Saha, Rahul Aralikatte, Mitesh M. Khapra, Karthik Sankaranarayanan. (2018)\nDuoRC: Towards Complex Language Understanding with Paraphrased Reading Comprehension\nACL\nPaper Link\nInfluential Citation Count (16), SS-ID (a7bbb084f5de4f318c811776afeba2b05439c234)\nABSTRACT\nWe propose DuoRC, a novel dataset for Reading Comprehension (RC) that motivates several new challenges for neural approaches in language understanding beyond those offered by existing RC datasets. DuoRC contains 186,089 unique question-answer pairs created from a collection of 7680 pairs of movie plots where each pair in the collection reflects two versions of the same movie - one from Wikipedia and the other from IMDb - written by two different authors. We asked crowdsourced workers to create questions from one version of the plot and a different set of workers to extract or synthesize answers from the other version. This unique characteristic of DuoRC where questions and answers are created from different versions of a document narrating the same underlying story, ensures by design, that there is very little lexical overlap between the questions created from one version and the segments containing the answer in the other version. Further, since the two versions have different levels of plot detail, narration style, vocabulary, etc., answering questions from the second version requires deeper language understanding and incorporating external background knowledge. Additionally, the narrative style of passages arising from movie plots (as opposed to typical descriptive passages in existing datasets) exhibits the need to perform complex reasoning over events across multiple sentences. Indeed, we observe that state-of-the-art neural RC models which have achieved near human performance on the SQuAD dataset, even when coupled with traditional NLP techniques to address the challenges presented in DuoRC exhibit very poor performance (F1 score of 37.42% on DuoRC v/s 86% on SQuAD dataset). This opens up several interesting research avenues wherein DuoRC could complement other RC datasets to explore novel neural approaches for studying language understanding.\nGated Self-Matching Networks for Reading Comprehension and Question Answering (Wenhui Wang et al., 2017) Wenhui Wang, Nan Yang, Furu Wei, Baobao Chang, M. Zhou. (2017)\nGated Self-Matching Networks for Reading Comprehension and Question Answering\nACL\nPaper Link\nInfluential Citation Count (97), SS-ID (b798cfd967e1a9ca5e7bc995d33a907bf65d1c7f)\nABSTRACT\nIn this paper, we present the gated self-matching networks for reading comprehension style question answering, which aims to answer questions from a given passage. We first match the question and passage with gated attention-based recurrent networks to obtain the question-aware passage representation. Then we propose a self-matching attention mechanism to refine the representation by matching the passage against itself, which effectively encodes information from the whole passage. We finally employ the pointer networks to locate the positions of answers from the passages. We conduct extensive experiments on the SQuAD dataset. The single model achieves 71.3% on the evaluation metrics of exact match on the hidden test set, while the ensemble model further boosts the results to 75.9%. At the time of submission of the paper, our model holds the first place on the SQuAD leaderboard for both single and ensemble model.\nDensely Connected Attention Propagation for Reading Comprehension (Yi Tay et al., 2018) Yi Tay, Anh Tuan Luu, S. C. Hui, J. Su. (2018)\nDensely Connected Attention Propagation for Reading Comprehension\nNeurIPS\nPaper Link\nInfluential Citation Count (4), SS-ID (baca3fb4f55bc8d3bf853eb6e970086017ecc79c)\nABSTRACT\nWe propose DecaProp (Densely Connected Attention Propagation), a new densely connected neural architecture for reading comprehension (RC). There are two distinct characteristics of our model. Firstly, our model densely connects all pairwise layers of the network, modeling relationships between passage and query across all hierarchical levels. Secondly, the dense connectors in our network are learned via attention instead of standard residual skip-connectors. To this end, we propose novel Bidirectional Attention Connectors (BAC) for efficiently forging connections throughout the network. We conduct extensive experiments on four challenging RC benchmarks. Our proposed approach achieves state-of-the-art results on all four, outperforming existing baselines by up to 2.6% to 14.2% in absolute F1 score.\nControlling Politeness in Neural Machine Translation via Side Constraints (Rico Sennrich et al., 2016) Rico Sennrich, B. Haddow, Alexandra Birch. (2016)\nControlling Politeness in Neural Machine Translation via Side Constraints\nNAACL\nPaper Link\nInfluential Citation Count (51), SS-ID (bf0f141bae83bd6d5ca0c37839d53f0d06059b34)\nABSTRACT\nMany languages use honoriﬁcs to express politeness, social distance, or the relative social status between the speaker and their ad-dressee(s). In machine translation from a language without honoriﬁcs such as English, it is difﬁcult to predict the appropriate honoriﬁc, but users may want to control the level of politeness in the output. In this paper, we perform a pilot study to control honoriﬁcs in neural machine translation (NMT) via side constraints , focusing on English → German. We show that by marking up the (English) source side of the training data with a feature that en-codes the use of honoriﬁcs on the (German) target side, we can control the honoriﬁcs produced at test time. Experiments show that the choice of honoriﬁcs has a big impact on translation quality as measured by B LEU , and oracle experiments show that substantial im-provements are possible by constraining the translation to the desired level of politeness.\nStyle Transfer Through Back-Translation (Shrimai Prabhumoye et al., 2018) Shrimai Prabhumoye, Yulia Tsvetkov, R. Salakhutdinov, A. Black. (2018)\nStyle Transfer Through Back-Translation\nACL\nPaper Link\nInfluential Citation Count (49), SS-ID (bface38422b7e53287134c4d01a39fa58edd4469)\nABSTRACT\nStyle transfer is the task of rephrasing the text to contain specific stylistic properties without changing the intent or affect within the context. This paper introduces a new method for automatic style transfer. We first learn a latent representation of the input sentence which is grounded in a language translation model in order to better preserve the meaning of the sentence while reducing stylistic properties. Then adversarial generation techniques are used to make the output match the desired style. We evaluate this technique on three different style transformations: sentiment, gender and political slant. Compared to two state-of-the-art style transfer modeling techniques we show improvements both in automatic evaluation of style transfer and in manual evaluation of meaning preservation and fluency.\nControlling Target Features in Neural Machine Translation via Prefix Constraints (Shunsuke Takeno et al., 2017) Shunsuke Takeno, M. Nagata, Kazuhide Yamamoto. (2017)\nControlling Target Features in Neural Machine Translation via Prefix Constraints\nWAT@IJCNLP\nPaper Link\nInfluential Citation Count (0), SS-ID (c034abc8ee67af5ffe717f8c52971dccd308ea2a)\nABSTRACT\nWe propose prefix constraints, a novel method to enforce constraints on target sentences in neural machine translation. It places a sequence of special tokens at the beginning of target sentence (target prefix), while side constraints places a special token at the end of source sentence (source suffix). Prefix constraints can be predicted from source sentence jointly with target sentence, while side constraints (Sennrich et al., 2016) must be provided by the user or predicted by some other methods. In both methods, special tokens are designed to encode arbitrary features on target-side or metatextual information. We show that prefix constraints are more flexible than side constraints and can be used to control the behavior of neural machine translation, in terms of output length, bidirectional decoding, domain adaptation, and unaligned target word generation.\nA Deep Cascade Model for Multi-Document Reading Comprehension (Ming Yan et al., 2018) Ming Yan, Jiangnan Xia, Chen Wu, Bin Bi, Zhongzhou Zhao, Ji Zhang, Luo Si, Rui Wang, Wei Wang, Haiqing Chen. (2018)\nA Deep Cascade Model for Multi-Document Reading Comprehension\nAAAI\nPaper Link\nInfluential Citation Count (3), SS-ID (c435d84e38575b0ba52420bbc62230db8cd5bc14)\nABSTRACT\nA fundamental trade-off between effectiveness and efficiency needs to be balanced when designing an online question answering system. Effectiveness comes from sophisticated functions such as extractive machine reading comprehension (MRC), while efficiency is obtained from improvements in preliminary retrieval components such as candidate document selection and paragraph ranking. Given the complexity of the real-world multi-document MRC scenario, it is difficult to jointly optimize both in an end-to-end system. To address this problem, we develop a novel deep cascade learning model, which progressively evolves from the documentlevel and paragraph-level ranking of candidate texts to more precise answer extraction with machine reading comprehension. Specifically, irrelevant documents and paragraphs are first filtered out with simple functions for efficiency consideration. Then we jointly train three modules on the remaining texts for better tracking the answer: the document extraction, the paragraph extraction and the answer extraction. Experiment results show that the proposed method outperforms the previous state-of-the-art methods on two large-scale multidocument benchmark datasets, i.e., TriviaQA and DuReader. In addition, our online system can stably serve typical scenarios with millions of daily requests in less than 50ms.\nImproving Language Understanding by Generative Pre-Training (Alec Radford et al., 2018) Alec Radford, Karthik Narasimhan. (2018)\nImproving Language Understanding by Generative Pre-Training\nPaper Link\nInfluential Citation Count (591), SS-ID (cd18800a0fe0b668a1cc19f2ec95b5003d0a5035)\nABSTRACT\nNatural language understanding comprises a wide range of diverse tasks such as textual entailment, question answering, semantic similarity assessment, and document classiﬁcation. Although large unlabeled text corpora are abundant, labeled data for learning these speciﬁc tasks is scarce, making it challenging for discriminatively trained models to perform adequately. We demonstrate that large gains on these tasks can be realized by generative pre-training of a language model on a diverse corpus of unlabeled text, followed by discriminative ﬁne-tuning on each speciﬁc task. In contrast to previous approaches, we make use of task-aware input transformations during ﬁne-tuning to achieve effective transfer while requiring minimal changes to the model architecture. We demonstrate the effectiveness of our approach on a wide range of benchmarks for natural language understanding. Our general task-agnostic model outperforms discriminatively trained models that use architectures speciﬁcally crafted for each task, signiﬁcantly improving upon the state of the art in 9 out of the 12 tasks studied. For instance, we achieve absolute improvements of 8.9% on commonsense reasoning (Stories Cloze Test), 5.7% on question answering (RACE), and 1.5% on textual entailment (MultiNLI).\nDecoupled Weight Decay Regularization (I. Loshchilov et al., 2017) I. Loshchilov, F. Hutter. (2017)\nDecoupled Weight Decay Regularization\nICLR\nPaper Link\nInfluential Citation Count (579), SS-ID (d07284a6811f1b2745d91bdb06b040b57f226882)\nABSTRACT\nL$_2$ regularization and weight decay regularization are equivalent for standard stochastic gradient descent (when rescaled by the learning rate), but as we demonstrate this is \\emph{not} the case for adaptive gradient algorithms, such as Adam. While common implementations of these algorithms employ L$_2$ regularization (often calling it \u0026ldquo;weight decay\u0026rdquo; in what may be misleading due to the inequivalence we expose), we propose a simple modification to recover the original formulation of weight decay regularization by \\emph{decoupling} the weight decay from the optimization steps taken w.r.t. the loss function. We provide empirical evidence that our proposed modification (i) decouples the optimal choice of weight decay factor from the setting of the learning rate for both standard SGD and Adam and (ii) substantially improves Adam\u0026rsquo;s generalization performance, allowing it to compete with SGD with momentum on image classification datasets (on which it was previously typically outperformed by the latter). Our proposed decoupled weight decay has already been adopted by many researchers, and the community has implemented it in TensorFlow and PyTorch; the complete source code for our experiments is available at this https URL\nA Unified Model for Extractive and Abstractive Summarization using Inconsistency Loss (W. Hsu et al., 2018) W. Hsu, Chieh-Kai Lin, Ming-Ying Lee, Kerui Min, Jing Tang, Min Sun. (2018)\nA Unified Model for Extractive and Abstractive Summarization using Inconsistency Loss\nACL\nPaper Link\nInfluential Citation Count (29), SS-ID (d381709212dccf397284eee54a1e3010a4ef777f)\nABSTRACT\nWe propose a unified model combining the strength of extractive and abstractive summarization. On the one hand, a simple extractive model can obtain sentence-level attention with high ROUGE scores but less readable. On the other hand, a more complicated abstractive model can obtain word-level dynamic attention to generate a more readable paragraph. In our model, sentence-level attention is used to modulate the word-level attention such that words in less attended sentences are less likely to be generated. Moreover, a novel inconsistency loss function is introduced to penalize the inconsistency between two levels of attentions. By end-to-end training our model with the inconsistency loss and original losses of extractive and abstractive models, we achieve state-of-the-art ROUGE scores while being the most informative and readable summarization on the CNN/Daily Mail dataset in a solid human evaluation.\nCut to the Chase: A Context Zoom-in Network for Reading Comprehension (S. Indurthi et al., 2018) S. Indurthi, Seunghak Yu, Seohyun Back, H. Cuayáhuitl. (2018)\nCut to the Chase: A Context Zoom-in Network for Reading Comprehension\nEMNLP\nPaper Link\nInfluential Citation Count (0), SS-ID (d7baaa250fbe7a9f5da4cafa8d0ba4e5f1b903a7)\nABSTRACT\nIn recent years many deep neural networks have been proposed to solve Reading Comprehension (RC) tasks. Most of these models suffer from reasoning over long documents and do not trivially generalize to cases where the answer is not present as a span in a given document. We present a novel neural-based architecture that is capable of extracting relevant regions based on a given question-document pair and generating a well-formed answer. To show the effectiveness of our architecture, we conducted several experiments on the recently proposed and challenging RC dataset ‘NarrativeQA’. The proposed architecture outperforms state-of-the-art results by 12.62% (ROUGE-L) relative improvement.\nBleu: a Method for Automatic Evaluation of Machine Translation (Kishore Papineni et al., 2002) Kishore Papineni, S. Roukos, T. Ward, Wei-Jing Zhu. (2002)\nBleu: a Method for Automatic Evaluation of Machine Translation\nACL\nPaper Link\nInfluential Citation Count (4215), SS-ID (d7da009f457917aa381619facfa5ffae9329a6e9)\nABSTRACT\nHuman evaluations of machine translation are extensive but expensive. Human evaluations can take months to finish and involve human labor that can not be reused. We propose a method of automatic machine translation evaluation that is quick, inexpensive, and language-independent, that correlates highly with human evaluation, and that has little marginal cost per run. We present this method as an automated understudy to skilled human judges which substitutes for them when there is need for quick or frequent evaluations.\nThe NarrativeQA Reading Comprehension Challenge (Tomás Kociský et al., 2017) Tomás Kociský, Jonathan Schwarz, P. Blunsom, Chris Dyer, K. Hermann, Gábor Melis, Edward Grefenstette. (2017)\nThe NarrativeQA Reading Comprehension Challenge\nTACL\nPaper Link\nInfluential Citation Count (83), SS-ID (d91043f0d48b9b2c8ff7ee321abb8fd7efafff7a)\nABSTRACT\nReading comprehension (RC)—in contrast to information retrieval—requires integrating information and reasoning about events, entities, and their relations across a full document. Question answering is conventionally used to assess RC ability, in both artificial agents and children learning to read. However, existing RC datasets and tasks are dominated by questions that can be solved by selecting answers using superficial information (e.g., local context similarity or global term frequency); they thus fail to test for the essential integrative aspect of RC. To encourage progress on deeper comprehension of language, we present a new dataset and set of tasks in which the reader must answer questions about stories by reading entire books or movie scripts. These tasks are designed so that successfully answering their questions requires understanding the underlying narrative rather than relying on shallow pattern matching or salience. We show that although humans solve the tasks easily, standard RC models struggle on the tasks presented here. We provide an analysis of the dataset and the challenges it presents.\nQuery-Based Abstractive Summarization Using Neural Networks (Johan Hasselqvist et al., 2017) Johan Hasselqvist, Niklas Helmertz, Mikael Kågebäck. (2017)\nQuery-Based Abstractive Summarization Using Neural Networks\nArXiv\nPaper Link\nInfluential Citation Count (6), SS-ID (ddb3b822f7b03abaa9da09288605ee0bdad9e61e)\nABSTRACT\nCreating short summaries of documents with respect to a query has applications in for example search engines, where it may help inform users of the most relevant results. Constructing such a summary automatically, with the potential expressiveness of a human-written summary, is a difficult problem yet to be fully solved. In this thesis, a neural network model for this task is presented. We adapt an existing dataset of news article summaries for the task and train a pointer-generator model using this dataset to summarize such articles. The generated summaries are then evaluated by measuring similarity to reference summaries. We observe that the generated summaries exhibit abstractive properties, but also that they have issues, such as rarely being truthful. However, we show that a neural network summarization model, similar to existing neural network models for abstractive summarization, can be constructed to make use of queries for more targeted summaries.\nBERT: Pre-training of Deep Bidirectional Transformers for Language Understanding (Jacob Devlin et al., 2019) Jacob Devlin, Ming-Wei Chang, Kenton Lee, Kristina Toutanova. (2019)\nBERT: Pre-training of Deep Bidirectional Transformers for Language Understanding\nNAACL\nPaper Link\nInfluential Citation Count (9961), SS-ID (df2b0e26d0599ce3e70df8a9da02e51594e0e992)\nABSTRACT\nWe introduce a new language representation model called BERT, which stands for Bidirectional Encoder Representations from Transformers. Unlike recent language representation models (Peters et al., 2018a; Radford et al., 2018), BERT is designed to pre-train deep bidirectional representations from unlabeled text by jointly conditioning on both left and right context in all layers. As a result, the pre-trained BERT model can be fine-tuned with just one additional output layer to create state-of-the-art models for a wide range of tasks, such as question answering and language inference, without substantial task-specific architecture modifications. BERT is conceptually simple and empirically powerful. It obtains new state-of-the-art results on eleven natural language processing tasks, including pushing the GLUE score to 80.5 (7.7 point absolute improvement), MultiNLI accuracy to 86.7% (4.6% absolute improvement), SQuAD v1.1 question answering Test F1 to 93.2 (1.5 point absolute improvement) and SQuAD v2.0 Test F1 to 83.1 (5.1 point absolute improvement).\nHighway Networks (R. Srivastava et al., 2015) R. Srivastava, Klaus Greff, J. Schmidhuber. (2015)\nHighway Networks\nArXiv\nPaper Link\nInfluential Citation Count (81), SS-ID (e0945081b5b87187a53d4329cf77cd8bff635795)\nABSTRACT\nThere is plenty of theoretical and empirical evidence that depth of neural networks is a crucial ingredient for their success. However, network training becomes more difficult with increasing depth and training of very deep networks remains an open problem. In this extended abstract, we introduce a new architecture designed to ease gradient-based training of very deep networks. We refer to networks with this architecture as highway networks, since they allow unimpeded information flow across several layers on information highways. The architecture is characterized by the use of gating units which learn to regulate the flow of information through a network. Highway networks with hundreds of layers can be trained directly using stochastic gradient descent and with a variety of activation functions, opening up the possibility of studying extremely deep and efficient architectures.\nDynamic Coattention Networks For Question Answering (Caiming Xiong et al., 2016) Caiming Xiong, Victor Zhong, R. Socher. (2016)\nDynamic Coattention Networks For Question Answering\nICLR\nPaper Link\nInfluential Citation Count (111), SS-ID (e978d832a4d86571e1b52aa1685dc32ccb250f50)\nABSTRACT\nSeveral deep learning models have been proposed for question answering. However, due to their single-pass nature, they have no way to recover from local maxima corresponding to incorrect answers. To address this problem, we introduce the Dynamic Coattention Network (DCN) for question answering. The DCN first fuses co-dependent representations of the question and the document in order to focus on relevant parts of both. Then a dynamic pointing decoder iterates over potential answer spans. This iterative procedure enables the model to recover from initial local maxima corresponding to incorrect answers. On the Stanford question answering dataset, a single DCN model improves the previous state of the art from 71.0% F1 to 75.9%, while a DCN ensemble obtains 80.4% F1.\nR3: Reinforced Reader-Ranker for Open-Domain Question Answering (Shuohang Wang et al., 2017) Shuohang Wang, Mo Yu, Xiaoxiao Guo, Zhiguo Wang, Tim Klinger, Wei Zhang, Shiyu Chang, G. Tesauro, Bowen Zhou, Jing Jiang. (2017)\nR3: Reinforced Reader-Ranker for Open-Domain Question Answering\nArXiv\nPaper Link\nInfluential Citation Count (18), SS-ID (eac12391f1f7761d5eba71d345cbccbe721971c2)\nABSTRACT\nIn recent years researchers have achieved considerable success applying neural network methods to question answering (QA). These approaches have achieved state of the art results in simplified closed-domain settings such as the SQuAD (Rajpurkar et al., 2016) dataset, which provides a pre-selected passage, from which the answer to a given question may be extracted. More recently, researchers have begun to tackle open-domain QA, in which the model is given a question and access to a large corpus (e.g., wikipedia) instead of a pre-selected passage (Chen et al., 2017a). This setting is more complex as it requires large-scale search for relevant passages by an information retrieval component, combined with a reading comprehension model that \u0026ldquo;reads\u0026rdquo; the passages to generate an answer to the question. Performance in this setting lags considerably behind closed-domain performance. In this paper, we present a novel open-domain QA system called Reinforced Ranker-Reader $(R^3)$, based on two algorithmic innovations. First, we propose a new pipeline for open-domain QA with a Ranker component, which learns to rank retrieved passages in terms of likelihood of generating the ground-truth answer to a given question. Second, we propose a novel method that jointly trains the Ranker along with an answer-generation Reader model, based on reinforcement learning. We report extensive experimental results showing that our method significantly improves on the state of the art for multiple open-domain QA datasets.\nTriviaQA: A Large Scale Distantly Supervised Challenge Dataset for Reading Comprehension (Mandar Joshi et al., 2017) Mandar Joshi, Eunsol Choi, Daniel S. Weld, Luke Zettlemoyer. (2017)\nTriviaQA: A Large Scale Distantly Supervised Challenge Dataset for Reading Comprehension\nACL\nPaper Link\nInfluential Citation Count (193), SS-ID (f010affab57b5fcf1cd6be23df79d8ec98c7289c)\nABSTRACT\nWe present TriviaQA, a challenging reading comprehension dataset containing over 650K question-answer-evidence triples. TriviaQA includes 95K question-answer pairs authored by trivia enthusiasts and independently gathered evidence documents, six per question on average, that provide high quality distant supervision for answering the questions. We show that, in comparison to other recently introduced large-scale datasets, TriviaQA (1) has relatively complex, compositional questions, (2) has considerable syntactic and lexical variability between questions and corresponding answer-evidence sentences, and (3) requires more cross sentence reasoning to find answers. We also present two baseline algorithms: a feature-based classifier and a state-of-the-art neural network, that performs well on SQuAD reading comprehension. Neither approach comes close to human performance (23% and 40% vs. 80%), suggesting that TriviaQA is a challenging testbed that is worth significant future study. Data and code available at \u0026ndash; this http URL\nGloVe: Global Vectors for Word Representation (Jeffrey Pennington et al., 2014) Jeffrey Pennington, R. Socher, Christopher D. Manning. (2014)\nGloVe: Global Vectors for Word Representation\nEMNLP\nPaper Link\nInfluential Citation Count (3462), SS-ID (f37e1b62a767a307c046404ca96bc140b3e68cb5)\nABSTRACT\nRecent methods for learning vector space representations of words have succeeded in capturing fine-grained semantic and syntactic regularities using vector arithmetic, but the origin of these regularities has remained opaque. We analyze and make explicit the model properties needed for such regularities to emerge in word vectors. The result is a new global logbilinear regression model that combines the advantages of the two major model families in the literature: global matrix factorization and local context window methods. Our model efficiently leverages statistical information by training only on the nonzero elements in a word-word cooccurrence matrix, rather than on the entire sparse matrix or on individual context windows in a large corpus. The model produces a vector space with meaningful substructure, as evidenced by its performance of 75% on a recent word analogy task. It also outperforms related models on similarity tasks and named entity recognition.\nNatural Language (Michael Böttner, 1997) Michael Böttner. (1997)\nNatural Language\nRelational Methods in Computer Science\nPaper Link\nInfluential Citation Count (0), SS-ID (f3fc961cc3bb5bf5e6f32119c4ff76d86f761eb4)\nABSTRACT\nZero-Shot Relation Extraction via Reading Comprehension (Omer Levy et al., 2017) Omer Levy, Minjoon Seo, Eunsol Choi, Luke Zettlemoyer. (2017)\nZero-Shot Relation Extraction via Reading Comprehension\nCoNLL\nPaper Link\nInfluential Citation Count (49), SS-ID (fa025e5d117929361bcf798437957762eb5bb6d4)\nABSTRACT\nWe show that relation extraction can be reduced to answering simple reading comprehension questions, by associating one or more natural-language questions with each relation slot. This reduction has several advantages: we can (1) learn relation-extraction models by extending recent neural reading-comprehension techniques, (2) build very large training sets for those models by combining relation-specific crowd-sourced questions with distant supervision, and even (3) do zero-shot learning by extracting new relation types that are only specified at test-time, for which we have no labeled training examples. Experiments on a Wikipedia slot-filling task demonstrate that the approach can generalize to new questions for known relation types with high accuracy, and that zero-shot generalization to unseen relation types is possible, at lower accuracy levels, setting the bar for future work on this task.\nMean Reciprocal Rank (Nick Craswell, 2009) Nick Craswell. (2009)\nMean Reciprocal Rank\nEncyclopedia of Database Systems\nPaper Link\nInfluential Citation Count (33), SS-ID (fbe79d6661c83b5b0b1dccb7d3e3565e8678df3e)\nABSTRACT\n","date":"May 11, 2022","hero":"/blog-akitenkrad/posts/papers/202205/20220511010217/hero.jpg","permalink":"https://akitenkrad.github.io/blog-akitenkrad/posts/papers/202205/20220511010217/","summary":"Round-1: Overview Round-2: Model Implementation Details Round-3: Experiments Citation Nishida, K., Saito, I., Nishida, K., Shinoda, K., Otsuka, A., Asano, H., \u0026amp; Tomita, J. (2020).\nMulti-style Generative Reading Comprehension.\nACL 2019 - 57th Annual Meeting of the Association for Computational Linguistics, Proceedings of the Conference, 2273–2284.\nhttps://doi.org/10.18653/v1/p19-1220 Abstract This study tackles generative reading comprehension (RC), which consists of answering questions based on textual evidence and natural language generation (NLG). We proposea multi-style abstractive summarization model for question answering, called Masque.","tags":["At:Round-2","Published:2020","Question Answering","Generative MRC","DS:MS-MARCO","DS:NarrativeQA"],"title":"Multi-Style Generative Reading Comprehension"},{"categories":null,"contents":" Round-1: Overview Round-2: Model Implementation Details Round-3: Experiments Citation Makarov, I., Kiselev, D., Nikitinsky, N., \u0026amp; Subelj, L. (2021).\nSurvey on graph embeddings and their applications to machine learning problems on graphs.\nPeerJ Computer Science, 7, 1–62.\nPaper Link Abstract Dealing with relational data always required significant computational resources,domain expertise and task-dependent feature engineering to incorporate structuralinformation into a predictive model. Nowadays, a family of automated graphfeature engineering techniques has been proposed in different streams of literature. So-called graph embeddings provide a powerful tool to construct vectorized featurespaces for graphs and their components, such as nodes, edges and subgraphsunder preserving inner graph properties. Using the constructed feature spaces, manymachine learning problems on graphs can be solved via standard frameworkssuitable for vectorized feature representation.\nOur survey aims to describe the coreconcepts of graph embeddings and provide several taxonomies for their description. First, we start with the methodological approach and extract three types of graphembedding models based on matrix factorization, random-walks and deep learningapproaches. Next, we describe how different types of networks impact the abilityof models to incorporate structural and attributed data into a unified embedding. Going further, we perform a thorough evaluation of graph embedding applications tomachine learning problems on graphs, among which are node classification, linkprediction, clustering, visualization, compression, and a family of the whole graphembedding algorithms suitable for graph classification, similarity and alignmentproblems. Finally, we overview the existing applications of graph embeddings tocomputer science domains, formulate open problems and provide experimentresults, explaining how different networks properties result in graph embeddingsquality in the four classic machine learning problems on graphs, such as nodeclassification, link prediction, clustering and graph visualization.\nAs a result, oursurvey covers a new rapidly growingfield of network feature engineering, presents anin-depth analysis of models based on network types, and overviews a wide range ofapplications to machine learning problems on graphs.\nWhat\u0026rsquo;s New グラフを対象とした分散表現（Representation）の理論に関するサーベイ．Graph Representationは複雑なグラフの構造を低次元のベクトル空間に写像する関数である．\n既存のグラフエンジニアリングの手法 vertex degrees clustering coefficients graph kernels neighborhood similarity Past Reviews Learning network representations (L. G. Moyano, 2017) L. G. Moyano. (2017)\nLearning network representations\nPaper Link\nInfluential Citation Count (0), SS-ID (51a748c8d7b780c2bb863a2259598a3a216330f1)\nABSTRACT\nAbstract In this review I present several representation learning methods, and discuss the latest advancements with emphasis in applications to network science. Representation learning is a set of techniques that has the goal of efficiently mapping data structures into convenient latent spaces. Either for dimensionality reduction or for gaining semantic content, this type of feature embeddings has demonstrated to be useful, for example, for node classification or link prediction tasks, among many other relevant applications to networks. I provide a description of the state-of-the-art of network representation learning as well as a detailed account of the connections with other fields of study such as continuous word embeddings and deep learning architectures. Finally, I provide a broad view of several applications of these techniques to networks in various domains. Representation Learning on Graphs: Methods and Applications (William L. Hamilton et al., 2017) William L. Hamilton, Rex Ying, J. Leskovec. (2017)\nRepresentation Learning on Graphs: Methods and Applications\nIEEE Data Eng. Bull.\nPaper Link\nInfluential Citation Count (140), SS-ID (ecf6c42d84351f34e1625a6a2e4cc6526da45c74)\nABSTRACT\nMachine learning on graphs is an important and ubiquitous task with applications ranging from drug design to friendship recommendation in social networks. The primary challenge in this domain is finding a way to represent, or encode, graph structure so that it can be easily exploited by machine learning models. Traditionally, machine learning approaches relied on user-defined heuristics to extract features encoding structural information about a graph (e.g., degree statistics or kernel functions). However, recent years have seen a surge in approaches that automatically learn to encode graph structure into low-dimensional embeddings, using techniques based on deep learning and nonlinear dimensionality reduction. Here we provide a conceptual review of key advancements in this area of representation learning on graphs, including matrix factorization-based methods, random-walk based algorithms, and graph neural networks. We review methods to embed individual nodes as well as approaches to embed entire (sub)graphs. In doing so, we develop a unified framework to describe these recent approaches, and we highlight a number of important applications and directions for future work. グラフモデルに関するシンプルな分類を提示． Lee et al. (2018) J. B. Lee, Ryan A. Rossi, Sungchul Kim, Nesreen Ahmed, Eunyee Koh. (2018)\nAttention Models in Graphs\nACM Trans. Knowl. Discov. Data\nPaper Link\nInfluential Citation Count (1), SS-ID (cc23c580b7d8063415fb6eb512053d1079b849de)\nABSTRACT\nGraph-structured data arise naturally in many different application domains. By representing data as graphs, we can capture entities (i.e., nodes) as well as their relationships (i.e., edges) with each other. Many useful insights can be derived from graph-structured data as demonstrated by an ever-growing body of work focused on graph mining. However, in the real-world, graphs can be both large—with many complex patterns—and noisy, which can pose a problem for effective graph mining. An effective way to deal with this issue is to incorporate “attention” into graph mining solutions. An attention mechanism allows a method to focus on task-relevant parts of the graph, helping it to make better decisions. In this work, we conduct a comprehensive and focused survey of the literature on the emerging field of graph attention models. We introduce three intuitive taxonomies to group existing work. These are based on problem setting (type of input and output), the type of attention mechanism used, and the task (e.g., graph classification, link prediction). We motivate our taxonomies through detailed examples and use each to survey competing approaches from a unique standpoint. Finally, we highlight several challenges in the area and discuss promising directions for future work.\nGraph Attentionモデルのサーベイを実施． グラフモデルにおけるAttentionの使い所について，インプット，アウトプット，グラフのタイプ，タスクのタイプなどの観点から分類を提案した． Wu et al. (2019) Zonghan Wu, Shirui Pan, Fengwen Chen, Guodong Long, Chengqi Zhang, Philip S. Yu. (2019)\nA Comprehensive Survey on Graph Neural Networks\nIEEE Transactions on Neural Networks and Learning Systems\nPaper Link\nInfluential Citation Count (197), SS-ID (81a4fd3004df0eb05d6c1cef96ad33d5407820df)\nABSTRACT\nDeep learning has revolutionized many machine learning tasks in recent years, ranging from image classification and video processing to speech recognition and natural language understanding. The data in these tasks are typically represented in the Euclidean space. However, there is an increasing number of applications, where data are generated from non-Euclidean domains and are represented as graphs with complex relationships and interdependency between objects. The complexity of graph data has imposed significant challenges on the existing machine learning algorithms. Recently, many studies on extending deep learning approaches for graph data have emerged. In this article, we provide a comprehensive overview of graph neural networks (GNNs) in data mining and machine learning fields. We propose a new taxonomy to divide the state-of-the-art GNNs into four categories, namely, recurrent GNNs, convolutional GNNs, graph autoencoders, and spatial–temporal GNNs. We further discuss the applications of GNNs across various domains and summarize the open-source codes, benchmark data sets, and model evaluation of GNNs. Finally, we propose potential research directions in this rapidly growing field.\nChen et al. (2018) Haochen Chen, Bryan Perozzi, Rami Al-Rfou, S. Skiena. (2018)\nA Tutorial on Network Embeddings\nArXiv\nPaper Link\nInfluential Citation Count (1), SS-ID (1706a4ef5556ecdd680416d46e033e0476290361)\nABSTRACT\nNetwork embedding methods aim at learning low-dimensional latent representation of nodes in a network. These representations can be used as features for a wide range of tasks on graphs such as classification, clustering, link prediction, and visualization. In this survey, we give an overview of network embeddings by summarizing and categorizing recent advancements in this research field. We first discuss the desirable properties of network embeddings and briefly introduce the history of network embedding algorithms. Then, we discuss network embedding methods under different scenarios, such as supervised versus unsupervised learning, learning embeddings for homogeneous networks versus for heterogeneous networks, etc. We further demonstrate the applications of network embeddings, and conclude the survey with future work in this area.\nZhang, Cui \u0026amp; Zhu (2018) Ziwei Zhang, Peng Cui, Wenwu Zhu. (2018)\nDeep Learning on Graphs: A Survey\nIEEE Transactions on Knowledge and Data Engineering\nPaper Link\nInfluential Citation Count (23), SS-ID (30b38ca8151bbd5a5ff45bce94297d1248ff58b5)\nABSTRACT\nDeep learning has been shown to be successful in a number of domains, ranging from acoustics, images, to natural language processing. However, applying deep learning to the ubiquitous graph data is non-trivial because of the unique characteristics of graphs. Recently, substantial research efforts have been devoted to applying deep learning methods to graphs, resulting in beneficial advances in graph analysis techniques. In this survey, we comprehensively review the different types of deep learning methods on graphs. We divide the existing methods into five categories based on their model architectures and training strategies: graph recurrent neural networks, graph convolutional networks, graph autoencoders, graph reinforcement learning, and graph adversarial methods. We then provide a comprehensive overview of these methods in a systematic manner mainly by following their development history. We also analyze the differences and compositions of different methods. Finally, we briefly outline the applications in which they have been used and discuss potential future research directions.\nGraph Neural Networkに関するサーベイを実施． Chen et al (2018)はEmbeddingモデルを選択するためのメタ戦略を提案しているが，Deep Leaningモデルに対してのみとなっている． Zhang, Cui \u0026amp; Zhu (2018)は，他のGNNに関するサーベイとよく似ているが，強化学習やSampling Strategy，Skip-Connection，Inductive-Learning，Adversarial-Learningなど新しく提案された手法を盛り込んでいる． Cui et al. (2018) Peng Cui, Xiao Wang, J. Pei, Wenwu Zhu. (2017)\nA Survey on Network Embedding\nIEEE Transactions on Knowledge and Data Engineering\nPaper Link\nInfluential Citation Count (28), SS-ID (ce840188f3395815201b7da49f9bb40d24fc046a)\nABSTRACT\nNetwork embedding assigns nodes in a network to low-dimensional representations and effectively preserves the network structure. Recently, a significant amount of progresses have been made toward this emerging network analysis paradigm. In this survey, we focus on categorizing and then reviewing the current development on network embedding methods, and point out its future research directions. We first summarize the motivation of network embedding. We discuss the classical graph embedding algorithms and their relationship with network embedding. Afterwards and primarily, we provide a comprehensive overview of a large number of network embedding methods in a systematic manner, covering the structure- and property-preserving network embedding methods, the network embedding methods with side information, and the advanced information preserving network embedding methods. Moreover, several evaluation approaches for network embedding and some useful online resources, including the network data sets and softwares, are reviewed, too. Finally, we discuss the framework of exploiting these network embedding methods to build an effective system and point out some potential future directions.\nモデルがどのような情報を保持しているのか，という観点から既存研究を比較検討． 本サーベイはモデルのタイプにはとらわれずに，学習手法，入力となるグラフの特徴量，タスク，グラフ以外の領域への応用など様々な観点から既存のサーベイを踏まえて更なる一般化を試みる．\nPreliminaries Definition of Graph $V$ をノードの集合，$E$をエッジの集合，$A$をグラフの隣接行列，$G(V,E)$をグラフとするとき，Graph Embeddingを構成するプロセスは以下のように定義される．\nDefinition 1 (Graph Embedding) Graph Embedding is a mapping from a collection of substractures (most commonly either all nodes, or all edges, or certain subgraphs) to $\\mathbb{R}^d$.\n$$ f:V \\rightarrow \\mathbb{R}^d, d \\ll |V| $$\nグラフ関連のタスクは多くの場合，教師なし学習である． ラベルが一部しかついていない半教師あり学習の場合も多い． ラベル付きのデータがあれば，一部のラベルを欠損させることでMasked Modelを構築することもできる． 元のデータから情報量をできるだけ落とさずに重要な情報を抽出しつつ，ベクトル空間にデータを圧縮するプロセスがEmbeddingである． 重要な情報としてよく挙げられるものとしては，node proximityやstructural similarityがある． Definition 2 (First and second order proximities) First-order priximity (1次近傍) ペアになっている頂点間の近傍を表す． 全ての頂点に関して，$v_i$と$v_j$の間の重み$a_{ij} \\in \\mathbb{R}$は，この2頂点間の近傍を特徴づけるものである．これらをまとめたものが隣接行列$A=(a_{ij})^n_{i,j=1}$となる． Second-order proximity (2次近傍) A neighborhood of vertex $v_i$ $N_{v_i} = {v_k|a_{ik} \u0026gt; 0, k \\neq i}$を満たす隣接頂点の集合を表す． $v_i$自体は含まれない． 2頂点$v_i$，$v_j$において，$N_{v_i}$と$N_{v_j}$の類似度をSecond-order proximityと呼ぶ． Methods for Constructing Graph Embedding Paper sources サーベイの論文取得元一覧\nCategory Name Link Description Curated List by Chen https://github.com/chihming/ awesome-network-embedding Curated List by Rozemberczki https://github.com/benedekrozemberczki/ awesome-graph-classification Curated List by Rebo https://github.com/MaxwellRebo/ awesome-2vec Curated List by Soru https://gist.github.com/mommi84/ awesome-kge Conferences Complex Networks https://complexnetworks.org/ International Conference on Complex Networks and their Applications Conferences The Web https://www2020.thewebconf.org/ The Web Conference is international conference on the World Wide Web. Conferences WSDM http://www.wsdm-conference.org/ Web-inspired research involving search and data mining Conferences IJCAI https://www.ijcai.org/ International Joint Conferences on Artificial Intelligence Conferences AAAI https://www.aaai.org/ Association for the Advancement of Artificial Intelligence Conferences ICML https://icml.cc/ International Conference on Machine Learning Conferences SIGKDD https://www.kdd.org/ Special Interest Group in Knowledge Discovery and Databases Domain Conferences ACL http://www.acl2019.org/ Association for Computational Linguistics Domain Conferences CVPR http://cvpr2019.thecvf.com/ Conference on Computer Vision and Pattern Recognition Publishers ACM DL https://dl.acm.org/ Full-text articles database by Association for Computing Machinery Publishers IEEE Xplore https://ieeexplore.ieee.org/Xplore/home.jsp Research published by Institute of Electrical and Electronics Engineers Publishers Link Springer https://link.springer.com/ Online collection of scientific journals, books and reference works Indexing Services Scopus https://www.scopus.com/ Abstract and citation database Indexing Services Web of Science https://www.webofknowledge.com/ Citation Indexer Indexing Services Scholar Google https://scholar.google.com/ Web search engine for indexing full-text papers or its metadata 論文収集時に使用したキーワード graph/network embeddings graph/network representation graph neural networks graph convolutional networks graph convolution graph attention graph/network classification/link prediction/clustering deep learning for graphs geometric deep learning GCN GNN GAT Dimensionality reduction (matrix factorization) methods Factorizationモデルはグラフの構造を低次元の分散表現に写像する手法として様々な機械学習の分野でよく使われている．graph similarity matrix を用いている研究が多い．\nDefinition 3 (Matrix Factorization) Matrix Factorization is a decomposition of a matrix to the product of matrices. In this sense, the first matrix in series is named self node representation and the last matrix refers to node context.\n行列分解系の手法 MDS (Multi-Dimensional Scaling; 多次元尺度構成法) LSI (Latent Semantic Indexing) LDA (Latent Dirichlet Allocation)の拡張 グラフからProximity Matrixを構成する方法 ISOMAP LLE (Locally Linear Embedding) LPP (Locality Preserving Projections) Definition 4 (Graph Laplacian) If matrix $D$ is the diagonal degree matrix, that is\n$$ D=\\text{diag}(\\sum_jA_{ij}) $$\n, then Laplacian matrix can be defined as\n$$ L = D - A $$\nLE (Laplacian Eigenmaps) Kernel Eigenmaps Cauchy Graph Embedding SPE (Structure Preserving Embedding) GF (Graph Factorization) GraRep HOPE M-NMF (Modularized Nonnegative Matrix Factorization) ATP (Asymmetric Transitivity Preservation) SDNE (Structural Deep Network Embedding) FactorizationベースのEmbeddingは深く研究されている領域だが，グラフの規模が大きくなった場合に計算コストが非常に高くなるため，多くの研究では規模の大きなグラフに対しては小さな近傍に対してしか適用されていない．\nSequence-based approaches Definition 5 (Random walk on graph) Random walk on graph is a sequence of nodes obtained from the random process of node sampling. Usually, probability of choice of node $j$ after node $i$ is proportional to $A_{i,j}$.\nMatrix Factoizationの短所を改善する手法として，Random Walkをベースとしたノードの2次近傍の特徴を保持する手法が開発された．\nNewman (2003) M. Newman. (2003)\nA measure of betweenness centrality based on random walks\nSoc. Networks\nPaper Link\nInfluential Citation Count (123), SS-ID (0a575498f9e6bc0cc43b977c6e952101f89be90c) Pirotte et al. (2007) François Fouss, A. Pirotte, J. Renders, Marco Saerens. (2007)\nRandom-Walk Computation of Similarities between Nodes of a Graph with Application to Collaborative Recommendation\nIEEE Transactions on Knowledge and Data Engineering\nPaper Link\nInfluential Citation Count (84), SS-ID (474db64356d6c9c82fe2a8604cd6c13bc17bae78)\nABSTRACT\nThis work presents a new perspective on characterizing the similarity between elements of a database or, more generally, nodes of a weighted and undirected graph. It is based on a Markov-chain model of random walk through the database. More precisely, we compute quantities (the average commute time, the pseudoinverse of the Laplacian matrix of the graph, etc.) that provide similarities between any pair of nodes, having the nice property of increasing when the number of paths connecting those elements increases and when the \u0026ldquo;length\u0026rdquo; of paths decreases. It turns out that the square root of the average commute time is a Euclidean distance and that the pseudoinverse of the Laplacian matrix is a kernel matrix (its elements are inner products closely related to commute times). A principal component analysis (PCA) of the graph is introduced for computing the subspace projection of the node vectors in a manner that preserves as much variance as possible in terms of the Euclidean commute-time distance. This graph PCA provides a nice interpretation to the \u0026ldquo;Fiedler vector,\u0026rdquo; widely used for graph partitioning. The model is evaluated on a collaborative-recommendation task where suggestions are made about which movies people should watch based upon what they watched in the past. Experimental results on the MovieLens database show that the Laplacian-based similarities perform well in comparison with other methods. The model, which nicely fits into the so-called \u0026ldquo;statistical relational learning\u0026rdquo; framework, could also be used to compute document or word similarities, and, more generally, it could be applied to machine-learning and pattern-recognition tasks involving a relational database\n特に，NLPにおけるSkip-gramのアイディアをもとにして，Embeddingからノードの2次近傍のうちどの隣接ノードを考慮するかという点に関する確率を最大化するという考えが中心になっている．\nMikolov et al. (2013) Tomas Mikolov, Ilya Sutskever, Kai Chen, G. Corrado, J. Dean. (2013)\nDistributed Representations of Words and Phrases and their Compositionality\nNIPS\nPaper Link\nInfluential Citation Count (3587), SS-ID (87f40e6f3022adbc1f1905e3e506abad05a9964f)\nABSTRACT\nThe recently introduced continuous Skip-gram model is an efficient method for learning high-quality distributed vector representations that capture a large number of precise syntactic and semantic word relationships. In this paper we present several extensions that improve both the quality of the vectors and the training speed. By subsampling of the frequent words we obtain significant speedup and also learn more regular word representations. We also describe a simple alternative to the hierarchical softmax called negative sampling. An inherent limitation of word representations is their indifference to word order and their inability to represent idiomatic phrases. For example, the meanings of \u0026ldquo;Canada\u0026rdquo; and \u0026ldquo;Air\u0026rdquo; cannot be easily combined to obtain \u0026ldquo;Air Canada\u0026rdquo;. Motivated by this example, we present a simple method for finding phrases in text, and show that learning good vector representations for millions of phrases is possible.\nPennington, Socher \u0026amp; Manning (2014) Jeffrey Pennington, R. Socher, Christopher D. Manning. (2014)\nGloVe: Global Vectors for Word Representation\nEMNLP\nPaper Link\nInfluential Citation Count (3451), SS-ID (f37e1b62a767a307c046404ca96bc140b3e68cb5)\nABSTRACT\nRecent methods for learning vector space representations of words have succeeded in capturing fine-grained semantic and syntactic regularities using vector arithmetic, but the origin of these regularities has remained opaque. We analyze and make explicit the model properties needed for such regularities to emerge in word vectors. The result is a new global logbilinear regression model that combines the advantages of the two major model families in the literature: global matrix factorization and local context window methods. Our model efficiently leverages statistical information by training only on the nonzero elements in a word-word cooccurrence matrix, rather than on the entire sparse matrix or on individual context windows in a large corpus. The model produces a vector space with meaningful substructure, as evidenced by its performance of 75% on a recent word analogy task. It also outperforms related models on similarity tasks and named entity recognition.\nDefinition 6 (Skip-gram) Skip-gram is method to learn sequence element $i$ representation via maximization of probability of elements in context of $i$ based on representation of $i$.\nNode2Vec DeepWalk\nRandom WalkとSkip-gramを組み合わせてEmbeddingを学習する手法 LINE Diff2Vec Walklets\nGraRep (Cao, Lu \u0026amp; Xu, 2015)を一般化した手法で，DeepWalkの低次近傍におけるバイアスを低減したものでもある HARP Struct2Vec Biased-Graph2Vec GraphWave Graph Attention Metapath2Vec GenVector GEMSEC DDRW (Discriminative Deep Random Walk) Exponential Family Graph Embedding Sequence-basedモデルはノードの列をサンプリングしてNLPでいうところのコンテキストを考慮しながらEmbeddingを学習するので，精度の高いEmbeddingを学習することができる．\n一方でノードやエッジの\u0026quot;additional features\u0026quot;を考慮することはできない．\nDeep learning: graph convolutions Deep Autoencoderを使用して非線形なグラフの特徴を捉えつつ低次元なEmbeddingを構成\nただし，どちらの手法もグラフ全体をインプットにするため，大規模なグラフには向かない SDNE (Structural Deep Network Embedding) DNGR (Deep Neural networks for learning Graph Representations) GCN (Graph Convolutional Network) GraphSAINT\n学習時のグラフでーたのスケーラビリティ問題に対する解決策を提案． VGAE (Variational Graph AutoEncoder)\nEncoder/DecoderにGCNを採用し，GAEに確率変数を導入して拡張した手法． GraphSAGE\n各ノードのk-hopの範囲で特徴量を集約する手法．大規模なグラフにも適用できる． PinSAGE\nGraphSAGEを拡張してImportance Scoreを導入した．GraphSAGEに比べてより大規模なグラフを精度良く扱えるようになっている． GAT (Graph Attention) Geniepath\nAggregation Layerを改善して，Node2Vecを一般化したモデルを提案． MPNN (Message Passing Neural Network) Graph Generative Adversarial Networks ARVGA (Adversarially Regularized Variational Graph Autoencoder) DGGAN Anonymized GCN RASE Graph Embedding with Data Unvertainty AAVGA (Adversarial Attention Variational Graph AutoEncoder) GSSNN (Graph Smoothing Splines Neural Networks) VHKRep (Variable Heat Kernel Representation) Hyperbolic (non-Euclidean) embeddings Embeddingの多くはEuclidean空間匂いて定義されているが，グラフにおけるEmbeddingに最適な空間に関する議論はあまり進んでいない．\nnon-Euclidean空間がモデルの精度に与える影響に関する研究 Kleinberg (2007) The link-prediction problem for social networks\nJ. Assoc. Inf. Sci. Technol.\nPaper Link\nInfluential Citation Count (240), SS-ID (996dfa43f6982bcbff862276ef80cbca7515985a)\nABSTRACT\nGiven a snapshot of a social network, can we infer which new interactions among its members are likely to occur in the near future? We formalize this question as the link prediction problem, and develop approaches to link prediction based on measures the \u0026ldquo;proximity\u0026rdquo; of nodes in a network. Experiments on large co-authorship networks suggest that information about future interactions can be extracted from network topology alone, and that fairly subtle measures for detecting node proximity can outperform more direct measures.\nShavitt \u0026amp; Tankel (2008) Y. Shavitt, Tomer Tankel. (2008)\nHyperbolic embedding of internet graph for distance estimation and overlay construction\nTNET\nPaper Link\nInfluential Citation Count (8), SS-ID (dd1d4e8acfabf225686d294660e0deb0059bdfd7)\nABSTRACT\nEstimating distances in the Internet has been studied in the recent years due to its ability to improve the performance of many applications, e.g., in the peer-to-peer realm. One scalable approach to estimate distances between nodes is to embed the nodes in some d dimensional geometric space and to use the pair distances in this space as the estimate for the real distances. Several algorithms were suggested in the past to do this in low dimensional Euclidean spaces. It was noted in recent years that the Internet structure has a highly connected core and long stretched tendrils, and that most of the routing paths between nodes in the tendrils pass through the core. Therefore, we suggest in this work, to embed the Internet distance metric in a hyperbolic space where routes are bent toward the center. We found that if the curvature, that defines the extend of the bending, is selected in the adequate range, the accuracy of Internet distance embedding can be improved. We demonstrate the strength of our hyperbolic embedding with two applications: selecting the closest server and building an application level multicast tree. For the latter, we present a distributed algorithm for building geometric multicast trees that achieve good trade-offs between delay (stretch) and load (stress). We also present a new efficient centralized embedding algorithm that enables the accurate embedding of short distances, something that have never been done before.\nKrioukov et al. (2009) Dmitri V. Krioukov, F. Papadopoulos, M. Boguñá, Amin Vahdat. (2009)\nGreedy forwarding in scale-free networks embedded in hyperbolic metric spaces\nSIGMETRICS Perform. Evaluation Rev.\nPaper Link\nInfluential Citation Count (4), SS-ID (f61005ce7db38553f2bf87be7c9fbce183b4c375)\nABSTRACT\nWe show that complex (scale-free) network topologies naturally emerge from hyperbolic metric spaces. Hyperbolic geometry facilitates maximally efficient greedy forwarding in these networks. Greedy forwarding is topology-oblivious. Nevertheless, greedy packets find their destinations with 100% probability following almost optimal shortest paths. This remarkable efficiency sustains even in highly dynamic networks. Our findings suggest that forwarding information through complex networks, such as the Internet, is possible without the overhead of existing routing protocols, and may also find practical applications in overlay networks for tasks such as application-level routing, information sharing, and data distribution.\nLaplacian-based Network Embedding Alanis-Lobato, Mier \u0026amp; Andrade-Navarro (2016) Gregorio Alanis-Lobato, Pablo Mier, Miguel Andrade. (2016)\nEfficient embedding of complex networks to hyperbolic space via their Laplacian\nScientific reports\nPaper Link\nInfluential Citation Count (4), SS-ID (559897d98f2c006d27fa09d7263c4a959d94eec3)\nABSTRACT\nThe different factors involved in the growth process of complex networks imprint valuable information in their observable topologies. How to exploit this information to accurately predict structural network changes is the subject of active research. A recent model of network growth sustains that the emergence of properties common to most complex systems is the result of certain trade-offs between node birth-time and similarity. This model has a geometric interpretation in hyperbolic space, where distances between nodes abstract this optimisation process. Current methods for network hyperbolic embedding search for node coordinates that maximise the likelihood that the network was produced by the afore-mentioned model. Here, a different strategy is followed in the form of the Laplacian-based Network Embedding, a simple yet accurate, efficient and data driven manifold learning approach, which allows for the quick geometric analysis of big networks. Comparisons against existing embedding and prediction techniques highlight its applicability to network evolution and link prediction.\nDeep learning-based approach Chamberlain, Clough \u0026amp; Deisenroth (2017) B. Chamberlain, J. Clough, M. Deisenroth. (2017)\nNeural Embeddings of Graphs in Hyperbolic Space\nArXiv\nPaper Link\nInfluential Citation Count (9), SS-ID (76ce8d30c6f72aa56ae02cd42a064e41b9ab9391)\nABSTRACT\nNeural embeddings have been used with great success in Natural Language Processing (NLP). They provide compact representations that encapsulate word similarity and attain state-of-the-art performance in a range of linguistic tasks. The success of neural embeddings has prompted significant amounts of research into applications in domains other than language. One such domain is graph-structured data, where embeddings of vertices can be learned that encapsulate vertex similarity and improve performance on tasks including edge prediction and vertex labelling. For both NLP and graph based tasks, embeddings have been learned in high-dimensional Euclidean spaces. However, recent work has shown that the appropriate isometric space for embedding complex networks is not the flat Euclidean space, but negatively curved, hyperbolic space. We present a new concept that exploits these recent insights and propose learning neural embeddings of graphs in hyperbolic space. We provide experimental evidence that embedding graphs in their natural geometry significantly improves performance on downstream tasks for several real-world public datasets.\nSpecific Embeddings Based on Network Types グラフデータには様々な種類のものが存在し，それぞれに対して特化したEmbeddingが研究されている．\nAttributed networks ノードやエッジに対して，特徴量が付加されたグラフ．\n特徴量は高次元ベクトルとして表現されることが多い．\nTADW (Text-Assocated DeepWalk) PLE PLDNE (Probabilistic Latent Document Network Embedding) Author2Vec ARE (Augmented Relation Embedding) Geng et al. (2015) Zhang et al. (2015) Zhang et al. (2017) CENE (Content-Enhanced Network Embedding) HSCA model (Homophily, Structure and Content-Augmented) DeepBrowse Tri-party Deep Network Representation GenVector SPE (Structure Preserving Embedding) M-NMF (Modularized Nonnegative Matrix Factorization) GEMSEC GENE (Incorporate Group Information to Enhance Network Embedding) Planetoid Max-margin DeepWalk LANE Heterogeneous networks Homogeneous Graph グラフを構成するノード・エッジが全て同じ性質を持っているようなグラフ\nHeterogeneous Graph グラフを構成するノードやエッジに複数の異なる性質を持つものが混在しているグラフ\nHeterogeneous Network Embeddings Li, Ritter \u0026amp; Jurafsky (2015) Zhao, Liu \u0026amp; Sun (2015) HNE (Heterogeneous Network Embedding) Tang \u0026amp; Liu (2011) EOE (Embedding of Embedding) LANE (Label Informed Attributed Network Embedding) Random-walk based Approach Metapath2Vec Huang \u0026amp; Mamoulis (2017) Chen \u0026amp; Sun (2016) Jacob, Denoyer \u0026amp; Gallinari (2014) GERM (Genetic Heterogeneous Graph Embedding) HeGAN (HIN Embedding Generative Adversarial Networks) CoGL (Co-Alignment Graph Convolutional Learning) Graph Attention Mecanism for Heterogeneous Graph Embedding CGAT MAGNN (Metapath Aggregated Graph Neural Network) DyHAN (Dynamic Heterogeneous Graph Embedding using Hierarchical Attentions) HDGAN (Heterogeneous Dynamic Graph Attention Network) Real-World Applications HetETA (Heterogeneous Estimated Time of Arrival) HeteGCN (Heterogeneous Graph Convolutional Networks) HGMF (Heterogeneous Graph-based Fusion) MIFHNE (Multi-source Information Fusion based Heterogeneous Network Embedding) Mg2Vec Signed networks Signed Network エッジの重み $w_i (1 \\le i \\le |\\mathcal{E}|) $ が $w_i \\in \\lbrace 1, -1\\rbrace$ であるようなグラフを Signed Graph/Network と呼ぶ．\nSiNE (Signed Network Embedding) SNE (Signed Network Embedding) SIDE (Signed Directed Networks) SIGNet (Scalable Embedding for Signed Networks) SSNE (Status Signed Network Embedding) Multi-layer networks Principled Multilayer Network Embedding EOE (Embedding of Embedding) IONE Zitnik \u0026amp; Leskovec (2017) Multi-Layered Network Embedding Temporal networks TemporalNode2Vec TGNs (Temporal Graph Networks) TemporalGAT EpiEm (Dynamics-Preserving Graph Embedding) Dynamic Graph Embedding CTGCN (K-core based Temporal GCN) DynGraph2Vec TigeCMN (Temporal Interaction Graph Embedding via Coupled Memory Networks) Cluster-GCN SIGN (Scalable Inception Graph Neural Networks) Large graphs Sampling based Approach GraphSAGE PinSAGE FastGCN Salha, Hennequin \u0026amp; Vazirgiannis (2020) GraphSAINT Locality Preserving Projection Approach ULGE (Unsupervised Large Graph Embedding) GOSH VERSE (Versatile Graph Embeddings from Similarity Measures) Atahan Akyildiz, Alabsi Aljundi \u0026amp; Kaya (2020) DGGAN Gallicchio \u0026amp; Micheli (2019) Lu \u0026amp; Chang (2020) Application of Graph Embeddings to Machine Learning Problems Node classification Definition 7 (Node Classification) For a given graph $G(V, E)$ with known labels for some of nodes from $V$, node classification is the task of predicting missing labels for existing or newly added nodes.\nPaper Approach Xiaojin \u0026amp; Zoubin (2002) Xiaojin Zhu, Zoubin Ghahramani. (2002)\nLearning from labeled and unlabeled data with label propagation\nPaper Link\nInfluential Citation Count (158), SS-ID (2a4ca461fa847e8433bab67e7bfe4620371c1f77)\nABSTRACT\nWe investigate the use of unlabeled data to help labeled data in cl ssification. We propose a simple iterative algorithm, label pro pagation, to propagate labels through the dataset along high density are as d fined by unlabeled data. We analyze the algorithm, show its solution , and its connection to several other algorithms. We also show how to lear n p ameters by minimum spanning tree heuristic and entropy minimiz ation, and the algorithm’s ability to perform feature selection. Expe riment results are promising.\nlabel propagation based on random walks statistics Azran (2007) Arik Azran. (2007)\nThe rendezvous algorithm: multiclass semi-supervised learning with Markov random walks\nICML \u0026lsquo;07\nPaper Link\nInfluential Citation Count (5), SS-ID (4e9585cd65c7e1a19ae16d8fed12c810070c65d3)\nABSTRACT\nWe consider the problem of multiclass classification where both labeled and unlabeled data points are given. We introduce and demonstrate a new approach for estimating a distribution over the missing labels where data points are viewed as nodes of a graph, and pairwise similarities are used to derive a transition probability matrix P for a Markov random walk between them. The algorithm associates each point with a particle which moves between points according to P. Labeled points are set to be absorbing states of the Markov random walk, and the probability of each particle to be absorbed by the different labeled points, as the number of steps increases, is then used to derive a distribution over the associated missing label. A computationally efficient algorithm to implement this is derived and demonstrated on both real and artificial data sets, including a numerical comparison with other methods.\nlabel propagation based on random walks statistics Baluja et al. (2008) S. Baluja, Rohan Seth, D. Sivakumar, Yushi Jing, J. Yagnik, Shankar Kumar, Deepak Ravichandran, M. Aly. (2008)\nVideo suggestion and discovery for youtube: taking random walks through the view graph\nWWW\nPaper Link\nInfluential Citation Count (34), SS-ID (f68ba8fe9fc9f7d8b7eb8c3d4a6d1046ee345e4b)\nABSTRACT\nThe rapid growth of the number of videos in YouTube provides enormous potential for users to find content of interest to them. Unfortunately, given the difficulty of searching videos, the size of the video repository also makes the discovery of new content a daunting task. In this paper, we present a novel method based upon the analysis of the entire user-video graph to provide personalized video suggestions for users. The resulting algorithm, termed Adsorption, provides a simple method to efficiently propagate preference information through a variety of graphs. We extensively test the results of the recommendations on a three month snapshot of live data from YouTube.\nlabel propagation based on random walks statistics Lu \u0026amp; Getoor (2003) Lu Q, Getoor L. (2003)\nLink-based classification\nProceedings of the 20th InternationalConference on Machine Learning (ICML-03).New York: ACM, 496–503.\nABSTRACT A key challenge for machine learning is tackling the problem of mining richly structured data sets, where the objects are linked in some way due to either an explicit or implicit relationship that exists between the objects. Links among the objects demonstrate certain patterns, which can be helpful for many machine learning tasks and are usually hard to capture with traditional statistical models. Recently there has been a surge of interest in this area, fueled largely by interest in web and hypertext mining, but also by interest in mining social networks, bibliographic citation data, epidemiological data and other domains best described using a linked or graph structure. In this paper we propose a framework for modeling link distributions, a link-based model that supports discriminative models describing both the link distributions and the attributes of linked objects. We use a structured logistic regression model, capturing both content and links. We systematically evaluate several variants of our link-based model on a range of data sets including both web and citation collections. In all cases, the use of the link distribution improves classification accuracy.\nunsupervised framework; each node is embedded in a low-dimensional space Bhagat et al. (2007) Smriti Bhagat, Irina Rozenbaum, Graham Cormode. (2007)\nApplying link-based classification to label blogs\nWebKDD/SNA-KDD \u0026lsquo;07\nPaper Link\nInfluential Citation Count (5), SS-ID (496d1a45eb511893a86dd7a8452a386aa5ce1657)\nABSTRACT\nIn analyzing data from social and communication networks, we encounter the problem of classifying objects where there is an explicit link structure amongst the objects. We study the problem of inferring the classification of all the objects from a labeled subset, using only the link-based information amongst the objects. We abstract the above as a labeling problem on multigraphs with weighted edges. We present two classes of algorithms, based on local and global similarities. Then we focus on multigraphs induced by blog data, and carefully apply our general algorithms to specifically infer labels such as age, gender and location associated with the blog based only on the link-structure amongst them. We perform a comprehensive set of experiments with real, large-scale blog data sets and show that significant accuracy is possible from little or no non-link information, and our methods scale to millions of nodes and edges.\nunsupervised framework; each node is embedded in a low-dimensional space Perozzi, Al-Rfou \u0026amp; Skiena (2014) Bryan Perozzi, Rami Al-Rfou, S. Skiena. (2014)\nDeepWalk: online learning of social representations\nKDD\nPaper Link\nInfluential Citation Count (1335), SS-ID (fff114cbba4f3ba900f33da574283e3de7f26c83)\nABSTRACT\nWe present DeepWalk, a novel approach for learning latent representations of vertices in a network. These latent representations encode social relations in a continuous vector space, which is easily exploited by statistical models. DeepWalk generalizes recent advancements in language modeling and unsupervised feature learning (or deep learning) from sequences of words to graphs. DeepWalk uses local information obtained from truncated random walks to learn latent representations by treating walks as the equivalent of sentences. We demonstrate DeepWalk\u0026rsquo;s latent representations on several multi-label network classification tasks for social networks such as BlogCatalog, Flickr, and YouTube. Our results show that DeepWalk outperforms challenging baselines which are allowed a global view of the network, especially in the presence of missing information. DeepWalk\u0026rsquo;s representations can provide F1 scores up to 10% higher than competing methods when labeled data is sparse. In some experiments, DeepWalk\u0026rsquo;s representations are able to outperform all baseline methods while using 60% less training data. DeepWalk is also scalable. It is an online learning algorithm which builds useful incremental results, and is trivially parallelizable. These qualities make it suitable for a broad class of real world applications such as network classification, and anomaly detection.\nlogistic regression Pimentel, Veloso \u0026amp; Ziviani (2017) Unsupervised and Scalable Algorithm for Learning Node Representations\nICLR\nPaper Link\nInfluential Citation Count (2), SS-ID (95a32bda5a743da698e062a5f5806ce5f22aef29)\nABSTRACT\nRepresentation learning is one of the foundations of Deep Learning and allowed big improvements on several Machine Learning fields, such as Neural Machine Translation, Question Answering and Speech Recognition. Recent works have proposed new methods for learning representations for nodes and edges in graphs. In this work, we propose a new unsupervised and efficient method, called here Neighborhood Based Node Embeddings (NBNE), capable of generating node embeddings for very large graphs. This method is based on SkipGram and uses nodes’ neighborhoods as contexts to generate representations. NBNE achieves results comparable or better than state-of-the-art feature learning algorithms in three different datasets and, differently from our main baseline (Node2Vec), which needs to have its parameters tuned in a validation set, is completely unsupervised.\nlogistic regression Wang, Cui \u0026amp; Zhu (2016) Structural Deep Network Embedding\nKDD\nPaper Link\nInfluential Citation Count (223), SS-ID (d0b7c8828f0fca4dd901674e8fb5bd464a187664)\nABSTRACT\nNetwork embedding is an important method to learn low-dimensional representations of vertexes in networks, aiming to capture and preserve the network structure. Almost all the existing network embedding methods adopt shallow models. However, since the underlying network structure is complex, shallow models cannot capture the highly non-linear network structure, resulting in sub-optimal network representations. Therefore, how to find a method that is able to effectively capture the highly non-linear network structure and preserve the global and local structure is an open yet important problem. To solve this problem, in this paper we propose a Structural Deep Network Embedding method, namely SDNE. More specifically, we first propose a semi-supervised deep model, which has multiple layers of non-linear functions, thereby being able to capture the highly non-linear network structure. Then we propose to exploit the first-order and second-order proximity jointly to preserve the network structure. The second-order proximity is used by the unsupervised component to capture the global network structure. While the first-order proximity is used as the supervised information in the supervised component to preserve the local network structure. By jointly optimizing them in the semi-supervised deep model, our method can preserve both the local and global network structure and is robust to sparse networks. Empirically, we conduct the experiments on five real-world networks, including a language network, a citation network and three social networks. The results show that compared to the baselines, our method can reconstruct the original network significantly better and achieves substantial gains in three applications, i.e. multi-label classification, link prediction and visualization.\nSVM Wang et al. (2017) Xiao Wang, Peng Cui, Jing Wang, J. Pei, Wenwu Zhu, Shiqiang Yang. (2017)\nCommunity Preserving Network Embedding\nAAAI\nPaper Link\nInfluential Citation Count (52), SS-ID (d3e0d596efd9d19b93d357565a68dfa925dce2bb)\nABSTRACT\nNetwork embedding, aiming to learn the low-dimensional representations of nodes in networks, is of paramount importance in many real applications. One basic requirement of network embedding is to preserve the structure and inherent properties of the networks. While previous network embedding methods primarily preserve the microscopic structure, such as the first- and second-order proximities of nodes, the mesoscopic community structure, which is one of the most prominent feature of networks, is largely ignored. In this paper, we propose a novel Modularized Nonnegative Matrix Factorization (M-NMF) model to incorporate the community structure into network embedding. We exploit the consensus relationship between the representations of nodes and community structure, and then jointly optimize NMF based representation learning model and modularity based community detection model in a unified framework, which enables the learned representations of nodes to preserve both of the microscopic and community structures. We also provide efficient updating rules to infer the parameters of our model, together with the correctness and convergence guarantees. Extensive experimental results on a variety of real-world networks show the superior performance of the proposed method over the state-of-the-arts.\nSVM Le \u0026amp; Lauw (2014) Tuan M. V. Le, Hady W. Lauw. (2014)\nProbabilistic Latent Document Network Embedding\n2014 IEEE International Conference on Data Mining\nPaper Link\nInfluential Citation Count (8), SS-ID (24f7d72e92cadfa5c84949537639ce084b9d2092)\nABSTRACT\nA document network refers to a data type that can be represented as a graph of vertices, where each vertex is associated with a text document. Examples of such a data type include hyperlinked Web pages, academic publications with citations, and user profiles in social networks. Such data have very high-dimensional representations, in terms of text as well as network connectivity. In this paper, we study the problem of embedding, or finding a low-dimensional representation of a document network that \u0026ldquo;preserves\u0026rdquo; the data as much as possible. These embedded representations are useful for various applications driven by dimensionality reduction, such as visualization or feature selection. While previous works in embedding have mostly focused on either the textual aspect or the network aspect, we advocate a holistic approach by finding a unified low-rank representation for both aspects. Moreover, to lend semantic interpretability to the low-rank representation, we further propose to integrate topic modeling and embedding within a joint model. The gist is to join the various representations of a document (words, links, topics, and coordinates) within a generative model, and to estimate the hidden representations through MAP estimation. We validate our model on real-life document networks, showing that it outperforms comparable baselines comprehensively on objective evaluation metrics.\nkNN Wilson et al. (2014) Richard C. Wilson, E. Hancock, E. Pekalska, R. Duin. (2014)\nSpherical and Hyperbolic Embeddings of Data\nIEEE Transactions on Pattern Analysis and Machine Intelligence\nPaper Link\nInfluential Citation Count (5), SS-ID (ab0e17513d180a68aad7680b3deea3844176cedc)\nABSTRACT\nMany computer vision and pattern recognition problems may be posed as the analysis of a set of dissimilarities between objects. For many types of data, these dissimilarities are not euclidean (i.e., they do not represent the distances between points in a euclidean space), and therefore cannot be isometrically embedded in a euclidean space. Examples include shape-dissimilarities, graph distances and mesh geodesic distances. In this paper, we provide a means of embedding such non-euclidean data onto surfaces of constant curvature. We aim to embed the data on a space whose radius of curvature is determined by the dissimilarity data. The space can be either of positive curvature (spherical) or of negative curvature (hyperbolic). We give an efficient method for solving the spherical and hyperbolic embedding problems on symmetric dissimilarity data. Our approach gives the radius of curvature and a method for approximating the objects as points on a hyperspherical manifold without optimisation. For objects which do not reside exactly on the manifold, we develop a optimisation-based procedure for approximate embedding on a hyperspherical manifold. We use the exponential map between the manifold and its local tangent space to solve the optimisation problem locally in the euclidean tangent space. This process is efficient enough to allow us to embed data sets of several thousand objects. We apply our method to a variety of data including time warping functions, shape similarities, graph similarity and gesture similarity data. In each case the embedding maintains the local structure of the data while placing the points in a metric space.\nkNN Makarov et al (2018) Ilya Makarov, Olga Gerasimova, Pavel Sulimov, L. Zhukov. (2018)\nRecommending Co-authorship via Network Embeddings and Feature Engineering: The case of National Research University Higher School of Economics\nJCDL\nPaper Link\nInfluential Citation Count (0), SS-ID (2b9501a2f4dfe1341bb272f157791a89d712ffd6)\nABSTRACT\nCo-authorship networks contain hidden structural patterns of research collaboration. While some people may argue that the process of writing joint papers depends on mutual friendship, research interests, and university policy, we show that, given a temporal co-authorship network, one could predict the quality and quantity of future research publications. We are working on the comparison of existing graph embedding and feature engineering methods, presenting combined approach for constructing co-author recommender system formulated as link prediction problem. We also present a new link embedding operator improving the quality of link prediction base don embedding feature space. We evaluate our research on a single university publication dataset, providing meaningful interpretation of the obtained results.\nrandom forest and xgboost Makarov et al. (2019) Ilya Makarov, Olga Gerasimova, Pavel Sulimov, L. Zhukov. (2019)\nDual network embedding for representing research interests in the link prediction problem on co-authorship networks\nPeerJ Comput. Sci.\nPaper Link\nInfluential Citation Count (0), SS-ID (894e35751609e1cd88265b055348ced09c8c9acd)\nABSTRACT\nWe present a study on co-authorship network representation based on network embedding together with additional information on topic modeling of research papers and new edge embedding operator. We use the link prediction (LP) model for constructing a recommender system for searching collaborators with similar research interests. Extracting topics for each paper, we construct keywords co-occurrence network and use its embedding for further generalizing author attributes. Standard graph feature engineering and network embedding methods were combined for constructing co-author recommender system formulated as LP problem and prediction of future graph structure. We evaluate our survey on the dataset containing temporal information on National Research University Higher School of Economics over 25 years of research articles indexed in Russian Science Citation Index and Scopus. Our model of network representation shows better performance for stated binary classification tasks on several co-authorship networks.\nrandom forest and xgboost Li, Zhu \u0026amp; Zhang (2016) Juzheng Li, Jun Zhu, Bo Zhang. (2016)\nDiscriminative Deep Random Walk for Network Classification\nACL\nPaper Link\nInfluential Citation Count (2), SS-ID (a6fd225417efdbf0bb9aef2ef2046335d2d0885e)\nABSTRACT\nDeep Random Walk (DeepWalk) can learn a latent space representation for describing the topological structure of a network. However, for relational network classification, DeepWalk can be suboptimal as it lacks a mechanism to optimize the objective of the target task. In this paper, we present Discriminative Deep Random Walk (DDRW), a novel method for relational network classification. By solving a joint optimization problem, DDRW can learn the latent space representations that well capture the topological structure and meanwhile are discriminative for the network classification task. Our experimental results on several real social networks demonstrate that DDRW significantly outperforms DeepWalk on multilabel network classification tasks, while retaining the topological structure in the latent space. DDRW is stable and consistently outperforms the baseline methods by various percentages of labeled data. DDRW is also an online method that is scalable and can be naturally parallelized. {\nsemi-supervised framework Yang, Cohen \u0026amp; Salakhutdinov (2016) Zhilin Yang, William W. Cohen, R. Salakhutdinov. (2016)\nRevisiting Semi-Supervised Learning with Graph Embeddings\nICML\nPaper Link\nInfluential Citation Count (178), SS-ID (3d846cb01f6a975554035d2210b578ca61344b22)\nABSTRACT\nWe present a semi-supervised learning framework based on graph embeddings. Given a graph between instances, we train an embedding for each instance to jointly predict the class label and the neighborhood context in the graph. We develop both transductive and inductive variants of our method. In the transductive variant of our method, the class labels are determined by both the learned embeddings and input feature vectors, while in the inductive variant, the embeddings are defined as a parametric function of the feature vectors, so predictions can be made on instances not seen during training. On a large and diverse set of benchmark tasks, including text classification, distantly supervised entity extraction, and entity classification, we show improved performance over many of the existing models.\nsemi-supervised framework Tu et al. (2016) Cunchao Tu, Weicheng Zhang, Zhiyuan Liu, Maosong Sun. (2016)\nMax-Margin DeepWalk: Discriminative Learning of Network Representation\nIJCAI\nPaper Link\nInfluential Citation Count (29), SS-ID (5d66991e1f541a08e81e59060cb0bb7f6931c2d9)\nABSTRACT\nDeepWalk is a typical representation learning method that learns low-dimensional representations for vertices in social networks. Similar to other network representation learning (NRL) models, it encodes the network structure into vertex representations and is learnt in unsupervised form. However, the learnt representations usually lack the ability of discrimination when applied to machine learning tasks, such as vertex classification. In this paper, we overcome this challenge by proposing a novel semi-supervised model, max-margin Deep-Walk (MMDW). MMDW is a unified NRL framework that jointly optimizes the max-margin classifier and the aimed social representation learning model. Influenced by the max-margin classifier, the learnt representations not only contain the network structure, but also have the characteristic of discrimination. The visualizations of learnt representations indicate that our model is more discriminative than unsupervised ones, and the experimental results on vertex classification demonstrate that our method achieves a significant improvement than other state-of-the-art methods. The source code can be obtained from https://github.com/thunlp/MMDW.\nsemi-supervised framework Kipf \u0026amp; Welling (2016) Thomas Kipf, M. Welling. (2016)\nSemi-Supervised Classification with Graph Convolutional Networks\nICLR\nPaper Link\nInfluential Citation Count (3139), SS-ID (36eff562f65125511b5dfab68ce7f7a943c27478)\nABSTRACT\nWe present a scalable approach for semi-supervised learning on graph-structured data that is based on an efficient variant of convolutional neural networks which operate directly on graphs. We motivate the choice of our convolutional architecture via a localized first-order approximation of spectral graph convolutions. Our model scales linearly in the number of graph edges and learns hidden layer representations that encode both local graph structure and features of nodes. In a number of experiments on citation networks and on a knowledge graph dataset we demonstrate that our approach outperforms related methods by a significant margin.\nsemi-supervised framework Monti et al. (2017) Federico Monti, D. Boscaini, Jonathan Masci, E. Rodolà, Jan Svoboda, M. Bronstein. (2016)\nGeometric Deep Learning on Graphs and Manifolds Using Mixture Model CNNs\n2017 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)\nPaper Link\nInfluential Citation Count (121), SS-ID (f09f7888aa5aeaf88a2a44aea768d9a8747e97d2)\nABSTRACT\nDeep learning has achieved a remarkable performance breakthrough in several fields, most notably in speech recognition, natural language processing, and computer vision. In particular, convolutional neural network (CNN) architectures currently produce state-of-the-art performance on a variety of image analysis tasks such as object detection and recognition. Most of deep learning research has so far focused on dealing with 1D, 2D, or 3D Euclidean-structured data such as acoustic signals, images, or videos. Recently, there has been an increasing interest in geometric deep learning, attempting to generalize deep learning methods to non-Euclidean structured data such as graphs and manifolds, with a variety of applications from the domains of network analysis, computational social science, or computer graphics. In this paper, we propose a unified framework allowing to generalize CNN architectures to non-Euclidean domains (graphs and manifolds) and learn local, stationary, and compositional task-specific features. We show that various non-Euclidean CNN methods previously proposed in the literature can be considered as particular instances of our framework. We test the proposed method on standard tasks from the realms of image-, graph-and 3D shape analysis and show that it consistently outperforms previous approaches.\nsemi-supervised framework Zhang, Zhou \u0026amp; Li (2020) H. Zhang, J. Zhou, R. Li. (2020)\nEnhanced Unsupervised Graph Embedding via Hierarchical Graph Convolution Network\nPaper Link\nInfluential Citation Count (0), SS-ID (f597a70c8708b7cda9766a403e3a2a67162d6973)\nABSTRACT\nGraph embedding aims to learn the low-dimensional representation of nodes in the network, which has been paid more and more attention in many graph-based tasks recently. Graph Convolution Network (GCN) is a typical deep semisupervised graph embedding model, which can acquire node representation from the complex network. However, GCN usually needs to use a lot of labeled data and additional expressive features in the graph embedding learning process, so the model cannot be effectively applied to undirected graphs with only network structure information. In this paper, we propose a novel unsupervised graph embedding method via hierarchical graph convolution network (HGCN). Firstly, HGCN builds the initial node embedding and pseudo-labels for the undirected graphs, and then further uses GCNs to learn the node embedding and update labels, finally combines HGCN output representation with the initial embedding to get the graph embedding. Furthermore, we improve the model to match the different undirected networks according to the number of network node label types. Comprehensive experiments demonstrate that our proposed HGCN and HGCN can significantly enhance the performance of the node classification task.\nhierarchical GCN and pseudo-labeling technique Liu et al. (2020) Xiaoming Liu, Qirui Li, Chao Shen, Xi Peng, Yadong Zhou, Guan Xiaohong. (2020)\nLearning by Sampling and Compressing: Efficient Graph Representation Learning with Extremely Limited Annotations\nPaper Link\nInfluential Citation Count (0), SS-ID (95555b454fc93ff6cab8ad8ee9bb3096d32e2b9c)\nABSTRACT\nGraph convolution network (GCN) attracts intensive research interest with broad applications. While existing work mainly focused on designing novel GCN architectures for better performance, few of them studied a practical yet challenging problem: How to learn GCNs from data with extremely limited annotation? In this paper, we propose a new learning method by sampling strategy and model compression to overcome this challenge. Our approach has multifold advantages: 1) the adaptive sampling strategy largely suppresses the GCN training deviation over uniform sampling; 2) compressed GCN-based methods with a smaller scale of parameters need fewer labeled data to train; 3) the smaller scale of training data is beneficial to reduce the human resource cost to label them. We choose six popular GCN baselines and conduct extensive experiments on three real-world datasets. The results show that by applying our method, all GCN baselines cut down the annotation requirement by as much as 90$%$ and compress the scale of parameters more than 6$\\times$ without sacrificing their strong performance. It verifies that the training method could extend the existing semi-supervised GCN-based methods to the scenarios with the extremely small scale of labeled data.\nsampling strategy and model compression for handling sparsity of labels Chen et al. (2020) Yujun Chen, Ke Sun, Juhua Pu, Zhang Xiong, Xiangliang Zhang. (2020)\nGraPASA: Parametric graph embedding via siamese architecture\nInf. Sci.\nPaper Link\nInfluential Citation Count (0), SS-ID (af46a816ad045238c1c8cca734ec9d1f48279d8f)\nABSTRACT\nGraph representation learning or graph embedding is a classical topic in data mining. Current embedding methods are mostly non-parametric, where all the embedding points are unconstrained free points in the target space. These approaches suffer from limited scalability and an over-flexible representation. In this paper, we propose a parametric graph embedding by fusing graph topology information and node content information. The embedding points are obtained through a highly flexible non-linear transformation from node content features to the target space. This transformation is learned using the contrastive loss function of the siamese network to preserve node adjacency in the input graph. On several benchmark network datasets, the proposed GraPASA method shows a significant margin over state-of-the-art techniques on benchmark graph representation tasks.\ncontrastive learning technique Zhu et al. (2020) Yanqiao Zhu, Yichen Xu, Feng Yu, Q. Liu, Shu Wu, Liang Wang. (2020)\nDeep Graph Contrastive Representation Learning\nArXiv\nPaper Link\nInfluential Citation Count (35), SS-ID (4bf76588122827157c43a59e656dccc6b6a22e90)\nABSTRACT\nGraph representation learning nowadays becomes fundamental in analyzing graph-structured data. Inspired by recent success of contrastive methods, in this paper, we propose a novel framework for unsupervised graph representation learning by leveraging a contrastive objective at the node level. Specifically, we generate two graph views by corruption and learn node representations by maximizing the agreement of node representations in these two views. To provide diverse node contexts for the contrastive objective, we propose a hybrid scheme for generating graph views on both structure and attribute levels. Besides, we provide theoretical justification behind our motivation from two perspectives, mutual information and the classical triplet loss. We perform empirical experiments on both transductive and inductive learning tasks using a variety of real-world datasets. Experimental experiments demonstrate that despite its simplicity, our proposed method consistently outperforms existing state-of-the-art methods by large margins. Moreover, our unsupervised method even surpasses its supervised counterparts on transductive tasks, demonstrating its great potential in real-world applications.\nmetric learning approach for corrupted graph substructures Nozza, Fersini \u0026amp; Messina (2020) Debora Nozza, E. Fersini, E. Messina. (2020)\nCAGE: Constrained deep Attributed Graph Embedding\nInf. Sci.\nPaper Link\nInfluential Citation Count (0), SS-ID (1f90f847e46bacc13364975166ff2c908436735d)\nABSTRACT\nIn this paper we deal with complex attributed graphs which can exhibit rich connectivity patterns and whose nodes are often associated with attributes, such as text or images. In order to analyze these graphs, the primary challenge is to find an effective way to represent them by preserving both structural properties and node attribute information. To create low-dimensional and meaningful embedded representations of these complex graphs, we propose a fully unsupervised model based on Deep Learning architectures, called Constrained Attributed Graph Embedding model (CAGE). The main contribution of the proposed model is the definition of a novel two-phase optimization problem that explicitly models node attributes to obtain a higher representation expressiveness while preserving the local and the global structural properties of the graph. We validated our approach on two different benchmark datasets for node classification. Experimental results demonstrate that this novel representation provides significant improvements compared to state of the art approaches, also showing higher robustness with respect to the size of the training data.\ntwo-phase optimization for attributed graph embedding Shi, Tang \u0026amp; Zhu (2020) Min Shi, Yufei Tang, Xingquan Zhu. (2020)\nTopology and Content Co-Alignment Graph Convolutional Learning\nIEEE transactions on neural networks and learning systems\nPaper Link\nInfluential Citation Count (0), SS-ID (249ce8e6bf5db2d0e12a5212330acdff3683550f)\nABSTRACT\nIn traditional graph neural networks (GNNs), graph convolutional learning is carried out through topology-driven recursive node content aggregation for network representation learning. In reality, network topology and node content each provide unique and important information, and they are not always consistent because of noise, irrelevance, or missing links between nodes. A pure topology-driven feature aggregation approach between unaligned neighborhoods may deteriorate learning from nodes with poor structure-content consistency, due to the propagation of incorrect messages over the whole network. Alternatively, in this brief, we advocate a co-alignment graph convolutional learning (CoGL) paradigm, by aligning topology and content networks to maximize consistency. Our theme is to enforce the learning from the topology network to be consistent with the content network while simultaneously optimizing the content network to comply with the topology for optimized representation learning. Given a network, CoGL first reconstructs a content network from node features then co-aligns the content network and the original network through a unified optimization goal with: 1) minimized content loss; 2) minimized classification loss; and 3) minimized adversarial loss. Experiments on six benchmarks demonstrate that CoGL achieves comparable and even better performance compared with existing state-of-the-art GNN models.\nalign topology of attribute content network to the corresponding graph Wang et al. (2020) Zheng Wang, Xiaojun Ye, Chaokun Wang, Jian Cui, Philip S. Yu. (2020)\nNetwork Embedding With Completely-Imbalanced Labels\nIEEE Transactions on Knowledge and Data Engineering\nPaper Link\nInfluential Citation Count (2), SS-ID (ece57b93c36325d909723564044f06986e5553ff)\nABSTRACT\nNetwork embedding, aiming to project a network into a low-dimensional space, is increasingly becoming a focus of network research. Semi-supervised network embedding takes advantage of labeled data, and has shown promising performance. However, existing semi-supervised methods would get unappealing results in the completely-imbalanced label setting where some classes have no labeled nodes at all. To alleviate this, we propose two novel semi-supervised network embedding methods. The first one is a shallow method named RSDNE. Specifically, to benefit from the completely-imbalanced labels, RSDNE guarantees both intra-class similarity and inter-class dissimilarity in an approximate way. The other method is RECT which is a new class of graph neural networks. Different from RSDNE, to benefit from the completely-imbalanced labels, RECT explores the class-semantic knowledge. This enables RECT to handle networks with node features and multi-label setting. Experimental results on several real-world datasets demonstrate the superiority of the proposed methods.\nproposed two models for the imbalanced scenarios Link prediction Definition 8 (Link Prediction Problem (LPP)) LPP is a task of completing missing edges in noisy graphs or predicting new edges in temporal network structures. Formally, LPP for given graph $G(V, E)$ with adjacency matrix $A$ is a task of learning such function $f$ that reconstruct or predict next adjacency matrix $A$ based on different graph features such as metrics (e.g. Jaccard, Adamic-Adar), graph embeddings.\nPaper Approach Grover \u0026amp; Leskovec (2016) Aditya Grover, J. Leskovec. (2016)\nnode2vec: Scalable Feature Learning for Networks\nKDD\nPaper Link\nInfluential Citation Count (1119), SS-ID (36ee2c8bd605afd48035d15fdc6b8c8842363376)\nABSTRACT\nPrediction tasks over nodes and edges in networks require careful effort in engineering features used by learning algorithms. Recent research in the broader field of representation learning has led to significant progress in automating prediction by learning the features themselves. However, present feature learning approaches are not expressive enough to capture the diversity of connectivity patterns observed in networks. Here we propose node2vec, an algorithmic framework for learning continuous feature representations for nodes in networks. In node2vec, we learn a mapping of nodes to a low-dimensional space of features that maximizes the likelihood of preserving network neighborhoods of nodes. We define a flexible notion of a node\u0026rsquo;s network neighborhood and design a biased random walk procedure, which efficiently explores diverse neighborhoods. Our algorithm generalizes prior work which is based on rigid notions of network neighborhoods, and we argue that the added flexibility in exploring neighborhoods is the key to learning richer representations. We demonstrate the efficacy of node2vec over existing state-of-the-art techniques on multi-label classification and link prediction in several real-world networks from diverse domains. Taken together, our work represents a new way for efficiently learning state-of-the-art task-independent representations in complex networks.\ncomponent-wise embeddings for constructing edge embedding in a non-direct combinatino of node embeddings Abu-El-Haija, Perozzi \u0026amp; Al-Rfou (2017) Sami Abu-El-Haija, Bryan Perozzi, Rami Al-Rfou, Alexander A. Alemi. (2017)\nWatch Your Step: Learning Node Embeddings via Graph Attention\nNeurIPS\nPaper Link\nInfluential Citation Count (13), SS-ID (49a5b5e65078eff512083d9de413d49a8aadc064)\nABSTRACT\nGraph embedding methods represent nodes in a continuous vector space, preserving different types of relational information from the graph. There are many hyper-parameters to these methods (e.g. the length of a random walk) which have to be manually tuned for every graph. In this paper, we replace previously fixed hyper-parameters with trainable ones that we automatically learn via backpropagation. In particular, we propose a novel attention model on the power series of the transition matrix, which guides the random walk to optimize an upstream objective. Unlike previous approaches to attention models, the method that we propose utilizes attention parameters exclusively on the data itself (e.g. on the random walk), and are not used by the model for inference. We experiment on link prediction tasks, as we aim to produce embeddings that best-preserve the graph structure, generalizing to unseen information. We improve state-of-the-art results on a comprehensive suite of real-world graph datasets including social, collaboration, and biological networks, where we observe that our graph attention model can reduce the error by up to 20%-40%. We show that our automatically-learned attention parameters can vary significantly per graph, and correspond to the optimal choice of hyper-parameter if we manually tune existing methods.\nbi-linear combination of compressed node embeddings Zitnik, Agrawal \u0026amp; Leskovec (2018) M. Zitnik, Monica Agrawal, J. Leskovec. (2018)\nModeling polypharmacy side effects with graph convolutional networks\nBioinform.\nPaper Link\nInfluential Citation Count (20), SS-ID (046c4276b72e21731150c0655519ec717d8f5bad)\nABSTRACT\nMotivation The use of drug combinations, termed polypharmacy, is common to treat patients with complex diseases or co‐existing conditions. However, a major consequence of polypharmacy is a much higher risk of adverse side effects for the patient. Polypharmacy side effects emerge because of drug‐drug interactions, in which activity of one drug may change, favorably or unfavorably, if taken with another drug. The knowledge of drug interactions is often limited because these complex relationships are rare, and are usually not observed in relatively small clinical testing. Discovering polypharmacy side effects thus remains an important challenge with significant implications for patient mortality and morbidity. Results Here, we present Decagon, an approach for modeling polypharmacy side effects. The approach constructs a multimodal graph of protein‐protein interactions, drug‐protein target interactions and the polypharmacy side effects, which are represented as drug‐drug interactions, where each side effect is an edge of a different type. Decagon is developed specifically to handle such multimodal graphs with a large number of edge types. Our approach develops a new graph convolutional neural network for multirelational link prediction in multimodal networks. Unlike approaches limited to predicting simple drug‐drug interaction values, Decagon can predict the exact side effect, if any, through which a given drug combination manifests clinically. Decagon accurately predicts polypharmacy side effects, outperforming baselines by up to 69%. We find that it automatically learns representations of side effects indicative of co‐occurrence of polypharmacy in patients. Furthermore, Decagon models particularly well polypharmacy side effects that have a strong molecular basis, while on predominantly non‐molecular side effects, it achieves good performance because of effective sharing of model parameters across edge types. Decagon opens up opportunities to use large pharmacogenomic and patient population data to flag and prioritize polypharmacy side effects for follow‐up analysis via formal pharmacological studies. Availability and implementation Source code and preprocessed datasets are at: http://snap.stanford.edu/decagon.\ndrug combinations Chen et al. (2018) Haochen Chen, Bryan Perozzi, Yifan Hu, S. Skiena. (2017)\nHARP: Hierarchical Representation Learning for Networks\nAAAI\nPaper Link\nInfluential Citation Count (32), SS-ID (ee9cc8e663d650ae96405ad680d6447066e6fb23)\nABSTRACT\nWe present HARP, a novel method for learning low dimensional embeddings of a graph\u0026rsquo;s nodes which preserves higher-order structural features. Our proposed method achieves this by compressing the input graph prior to embedding it, effectively avoiding troublesome embedding configurations (i.e. local minima) which can pose problems to non-convex optimization. HARP works by finding a smaller graph which approximates the global structure of its input. This simplified graph is used to learn a set of initial representations, which serve as good initializations for learning representations in the original, detailed graph. We inductively extend this idea, by decomposing a graph in a series of levels, and then embed the hierarchy of graphs from the coarsest one to the original graph. HARP is a general meta-strategy to improve all of the state-of-the-art neural algorithms for embedding graphs, including DeepWalk, LINE, and Node2vec. Indeed, we demonstrate that applying HARP\u0026rsquo;s hierarchical paradigm yields improved implementations for all three of these methods, as evaluated on both classification tasks on real-world graphs such as DBLP, BlogCatalog, CiteSeer, and Arxiv, where we achieve a performance gain over the original implementations by up to 14% Macro F1.\nHARP; incorporates several hierarchical layers Tu et al. (2017) Cunchao Tu, Han Liu, Zhiyuan Liu, Maosong Sun. (2017)\nCANE: Context-Aware Network Embedding for Relation Modeling\nACL\nPaper Link\nInfluential Citation Count (36), SS-ID (20bb300eb3400f1af766110ff51feada78170674)\nABSTRACT\nNetwork embedding (NE) is playing a critical role in network analysis, due to its ability to represent vertices with efficient low-dimensional embedding vectors. However, existing NE models aim to learn a fixed context-free embedding for each vertex and neglect the diverse roles when interacting with other vertices. In this paper, we assume that one vertex usually shows different aspects when interacting with different neighbor vertices, and should own different embeddings respectively. Therefore, we present Context-Aware Network Embedding (CANE), a novel NE model to address this issue. CANE learns context-aware embeddings for vertices with mutual attention mechanism and is expected to model the semantic relationships between vertices more precisely. In experiments, we compare our model with existing NE models on three real-world datasets. Experimental results show that CANE achieves significant improvement than state-of-the-art methods on link prediction and comparable performance on vertex classification. The source code and datasets can be obtained from https://github.com/thunlp/CANE.\nCANE; directly incorporating edge features and labels Huang, Li \u0026amp; Hu (2017) Xiao Huang, Jundong Li, Xia Hu. (2017)\nLabel Informed Attributed Network Embedding\nWSDM\nPaper Link\nInfluential Citation Count (45), SS-ID (44044556dae0e21cab058c18f704b15d33bd17c5)\nABSTRACT\nAttributed network embedding aims to seek low-dimensional vector representations for nodes in a network, such that original network topological structure and node attribute proximity can be preserved in the vectors. These learned representations have been demonstrated to be helpful in many learning tasks such as network clustering and link prediction. While existing algorithms follow an unsupervised manner, nodes in many real-world attributed networks are often associated with abundant label information, which is potentially valuable in seeking more effective joint vector representations. In this paper, we investigate how labels can be modeled and incorporated to improve attributed network embedding. This is a challenging task since label information could be noisy and incomplete. In addition, labels are completely distinct with the geometrical structure and node attributes. The bewildering combination of heterogeneous information makes the joint vector representation learning more difficult. To address these issues, we propose a novel Label informed Attributed Network Embedding (LANE) framework. It can smoothly incorporate label information into the attributed network embedding while preserving their correlations. Experiments on real-world datasets demonstrate that the proposed framework achieves significantly better performance compared with the state-of-the-art embedding algorithms.\nLANE; directly incorporating edge features and labels Monti et al. (2018) Federico Monti, Oleksandr Shchur, Aleksandar Bojchevski, O. Litany, Stephan Günnemann, M. Bronstein. (2018)\nDual-Primal Graph Convolutional Networks\nArXiv\nPaper Link\nInfluential Citation Count (1), SS-ID (980a4959ad4c81a61f4166b549157ddad1f7ddce)\nABSTRACT\nIn recent years, there has been a surge of interest in developing deep learning methods for non-Euclidean structured data such as graphs. In this paper, we propose Dual-Primal Graph CNN, a graph convolutional architecture that alternates convolution-like operations on the graph and its dual. Our approach allows to learn both vertex- and edge features and generalizes the previous graph attention (GAT) model. We provide extensive experimental validation showing state-of-the-art results on a variety of tasks tested on established graph benchmarks, including CORA and Citeseer citation networks as well as MovieLens, Flixter, Douban and Yahoo Music graph-guided recommender systems.\nDual-Primal GCN; joint node and edge structure learning Goyal et al. (2018) Palash Goyal, Homa Hosseinmardi, Emilio Ferrara, A. Galstyan. (2018)\nEmbedding Networks with Edge Attributes\nHT\nPaper Link\nInfluential Citation Count (0), SS-ID (e4853de6d86315073a9e9e5d8957500cd24402c1)\nABSTRACT\nPredicting links in information networks requires deep understanding and careful modeling of network structure. Network embedding, which aims to learn low-dimensional representations of nodes, has been used successfully for the task of link prediction in the past few decades. Existing methods utilize the observed edges in the network to model the interactions between nodes and learn representations which explain the behavior. In addition to the presence of edges, networks often have information which can be used to improve the embedding. For example, in author collaboration networks, the bag of words representing the abstract of co-authored paper can be used as edge attributes. In this paper, we propose a novel approach, which uses the edges and their associated labels to learn node embeddings. Our model jointly optimizes higher order node neighborhood, social roles and edge attributes reconstruction error using deep architecture which can model highly non-linear interactions. We demonstrate the efficacy of our model over existing state-of-the-art methods on two real world data sets. We observe that such attributes can improve the quality of embedding and yield better performance in link prediction.\nELAINE; joint node and edge structure learning Gui et al. (2016) Huan Gui, Jialu Liu, Fangbo Tao, Meng Jiang, Brandon Norick, Jiawei Han. (2016)\nLarge-Scale Embedding Learning in Heterogeneous Event Data\n2016 IEEE 16th International Conference on Data Mining (ICDM)\nPaper Link\nInfluential Citation Count (10), SS-ID (c18c30b9b1090e752031d23d219c1007b9954229)\nABSTRACT\nHeterogeneous events, which are defined as events connecting strongly-typed objects, are ubiquitous in the real world. We propose a HyperEdge-Based Embedding (Hebe) framework for heterogeneous event data, where a hyperedge represents the interaction among a set of involving objects in an event. The Hebe framework models the proximity among objects in an event by predicting a target object given the other participating objects in the event (hyperedge). Since each hyperedge encapsulates more information on a given event, Hebe is robust to data sparseness. In addition, Hebe is scalable when the data size spirals. Extensive experiments on large-scale real-world datasets demonstrate the efficacy and robustness of Hebe.\nHEBE; embedding event graphs in which event is described by several edges Wu et al. (2020) Chencheng Wu, Yinzuo Zhou, Lulu Tan, Cong Teng. (2020)\nLink Prediction Based on Graph Embedding Method in Unweighted Networks\n2020 39th Chinese Control Conference (CCC)\nPaper Link\nInfluential Citation Count (0), SS-ID (ba3159d8791903c7fcf0b6761cacf1be5b5ac927)\nABSTRACT\nThe index of link prediction based on random walk usually has the same transition probability in the process of particle transfer to its neighbor nodes, which has strong randomness and ignores the influence of the particularity of network topology on particle transition probability. In order to resolve this problem, this paper proposes a random walk with restart index based on graph embedding (GERWR). The algorithm uses graph embedding method to randomly sample network nodes and generate node representation vectors containing potential network structure information. By calculating the similarity of node vectors, it redefines a biased transition probability. We apply it to the process of random walk and explore the influence of the particularity of network topology on the transition during the particles walk. Finally, based on biased transition, the index proposed in this paper is compared with five classical similarity indexes in unweighted networks. The results show that the prediction algorithm based on graph embedding method with biased transfer has higher accuracy than other indexes.\nrandom walk with restart index Phuc, Yamada \u0026amp; Kashima (2020) Luu Huu Phuc, M. Yamada, H. Kashima. (2020)\nLink Prediction on Multiple Graphs with Graph Embedding and Optimal Transport\nPaper Link\nInfluential Citation Count (0), SS-ID (480ff986724acc27e096560f8d433847e86cbdb3)\nABSTRACT\nLink prediction is an extensively studied topic and various methods have been proposed to tackle the task in both heuristic and more sophisticated statistical learning approaches. However, most of them only focus on one single graph. In many scenarios, combining information on multiple graphs with similar topological structures can greatly improve the performance and robustness of link prediction. In this study, we propose a new framework for learning link prediction on two unaligned graphs simultaneously. We use the LINE method, although technically any embedding method is applicable, to embed nodes of each graph into low-dimensional vectors. Optimal Transport is then employed to supervise the node alignment via embedding vectors between the two graphs. The learned embedding vectors are employed for link prediction via a similarity score. Experiments have shown that node alignment using Optimal Transport is beneficial and greatly contributes to the favorable performance of the proposed method over the baseline in many settings.\nembeds several graphs with similar structural properties Keser et al. (2020) Reyhan Kevser Keser, Indrit Nallbani, Nurullah Çalik, Aydin Ayanzadeh, B. Töreyin. (2020)\nGraph Embedding For Link Prediction Using Residual Variational Graph Autoencoders\n2020 28th Signal Processing and Communications Applications Conference (SIU)\nPaper Link\nInfluential Citation Count (0), SS-ID (d94a322106c9161813360d8cfd108ec95e9fad67)\nABSTRACT\nGraphs are usually represented by high dimensional data. Hence, graph embedding is an essential task, which aims to represent a graph in a lower dimension while protecting the original graph\u0026rsquo;s properties. In this paper, we propose a novel graph embedding method called Residual Variational Graph Autoencoder (RVGAE), which boosts variational graph autoencoder\u0026rsquo;s performance utilizing residual connections. Our method\u0026rsquo;s performance is evaluated on the link prediction task. The results demonstrate that our model can achieve better results than graph convolutional neural network (GCN) and variational graph autoencoder (VGAE).\nemploy skip-connections in VGAE Adafre \u0026amp; de Rijke (2005) S. F. Adafre, M. de Rijke. (2005)\nDiscovering missing links in Wikipedia\nLinkKDD \u0026lsquo;05\nPaper Link\nInfluential Citation Count (12), SS-ID (6d9064ff94c5186e12c39ea2e9f3815004066e51)\nABSTRACT\nIn this paper we address the problem of discovering missing hypertext links in Wikipedia. The method we propose consists of two steps: first, we compute a cluster of highly similar pages around a given page, and then we identify candidate links from those similar pages that might be missing on the given page. The main innovation is in the algorithm that we use for identifying similar pages, LTRank, which ranks pages using co-citation and page title information. Both LTRank and the link discovery method are manually evaluated and show acceptable results, especially given the simplicity of the methods and conservativeness of the evaluation criteria.\nlink prediction in web linking Backstrom \u0026amp; Leskovec (2010) L. Backstrom, J. Leskovec. (2010)\nSupervised random walks: predicting and recommending links in social networks\nWSDM \u0026lsquo;11\nPaper Link\nInfluential Citation Count (79), SS-ID (29efbdf3f95cee97405accafdebd3bd374f1f003)\nABSTRACT\nPredicting the occurrence of links is a fundamental problem in networks. In the link prediction problem we are given a snapshot of a network and would like to infer which interactions among existing members are likely to occur in the near future or which existing interactions are we missing. Although this problem has been extensively studied, the challenge of how to effectively combine the information from the network structure with rich node and edge attribute data remains largely open. We develop an algorithm based on Supervised Random Walks that naturally combines the information from the network structure with node and edge level attributes. We achieve this by using these attributes to guide a random walk on the graph. We formulate a supervised learning task where the goal is to learn a function that assigns strengths to edges in the network such that a random walker is more likely to visit the nodes to which new links will be created in the future. We develop an efficient training algorithm to directly learn the edge strength estimation function. Our experiments on the Facebook social graph and large collaboration networks show that our approach outperforms state-of-the-art unsupervised approaches as well as approaches that are based on feature extraction.\nlink prediction in social dating services He et al. (2010) Qi He, J. Pei, Daniel Kifer, P. Mitra, C. Lee Giles. (2010)\nContext-aware citation recommendation\nWWW \u0026lsquo;10\nPaper Link\nInfluential Citation Count (32), SS-ID (3c0312918ac9fea614abaa0732d83f3e76c16f7d)\nABSTRACT\nWhen you write papers, how many times do you want to make some citations at a place but you are not sure which papers to cite? Do you wish to have a recommendation system which can recommend a small number of good candidates for every place that you want to make some citations? In this paper, we present our initiative of building a context-aware citation recommendation system. High quality citation recommendation is challenging: not only should the citations recommended be relevant to the paper under composition, but also should match the local contexts of the places citations are made. Moreover, it is far from trivial to model how the topic of the whole paper and the contexts of the citation places should affect the selection and ranking of citations. To tackle the problem, we develop a context-aware approach. The core idea is to design a novel non-parametric probabilistic model which can measure the context-based relevance between a citation context and a document. Our approach can recommend citations for a context effectively. Moreover, it can recommend a set of citations for a paper with high quality. We implement a prototype system in CiteSeerX. An extensive empirical evaluation in the CiteSeerX digital library against many baselines demonstrates the effectiveness and the scalability of our approach.\nlink prediction in paper recommender system for digital libraries Liben-Nowell \u0026amp; Kleinberg (2007) D. Liben-Nowell, J. Kleinberg. (2007)\nThe link-prediction problem for social networks\nJ. Assoc. Inf. Sci. Technol.\nPaper Link\nInfluential Citation Count (240), SS-ID (996dfa43f6982bcbff862276ef80cbca7515985a)\nABSTRACT\nGiven a snapshot of a social network, can we infer which new interactions among its members are likely to occur in the near future? We formalize this question as the link prediction problem, and develop approaches to link prediction based on measures the \u0026ldquo;proximity\u0026rdquo; of nodes in a network. Experiments on large co-authorship networks suggest that information about future interactions can be extracted from network topology alone, and that fairly subtle measures for detecting node proximity can outperform more direct measures.\nformulated LPP based on nodes pairwise similarity measures Adamic \u0026amp; Adar (2003) Lada A. Adamic, Eytan Adar. (2003)\nFriends and neighbors on the Web\nSoc. Networks\nPaper Link\nInfluential Citation Count (180), SS-ID (8dc9d11e3fc229a1b70bb00de72dc15d55848174)\nABSTRACT\nThe Internet has become a rich and large repository of information about us as individuals. Anything from the links and text on a user’s homepage to the mailing lists the user subscribes to are reflections of social interactions a user has in the real world. In this paper we devise techniques and tools to mine this information in order to extract social networks and the exogenous factors underlying the networks’ structure. In an analysis of two data sets, from Stanford University and the Massachusetts Institute of Technology (MIT), we show that some factors are better indicators of social connections than others, and that these indicators vary between user populations. Our techniques provide potential applications in automatically inferring real world connections and discovering, labeling, and characterizing communities.\nsimilarity based methods Clauset, Moore \u0026amp; Newman (2008) A. Clauset, C. Moore, M. Newman. (2008)\nHierarchical structure and the prediction of missing links in networks\nNature\nPaper Link\nInfluential Citation Count (83), SS-ID (00b7ffd43e9b6b70c80449872a8c9ec49c7d045a)\nABSTRACT\nNetworks have in recent years emerged as an invaluable tool for describing and quantifying complex systems in many branches of science. Recent studies suggest that networks often exhibit hierarchical organization, in which vertices divide into groups that further subdivide into groups of groups, and so forth over multiple scales. In many cases the groups are found to correspond to known functional units, such as ecological niches in food webs, modules in biochemical networks (protein interaction networks, metabolic networks or genetic regulatory networks) or communities in social networks. Here we present a general technique for inferring hierarchical structure from network data and show that the existence of hierarchy can simultaneously explain and quantitatively reproduce many commonly observed topological properties of networks, such as right-skewed degree distributions, high clustering coefficients and short path lengths. We further show that knowledge of hierarchical structure can be used to predict missing connections in partly known networks with high accuracy, and for more general network structures than competing techniques. Taken together, our results suggest that hierarchy is a central organizing principle of complex networks, capable of offering insight into many network phenomena.\nmaximum likelihood models Getoor \u0026amp; Taskar (2007) Getoor L, Taskar B (2007)\nStatistical relational learning\nhttps://mitpress.mit.edu/books/introduction-statistical-relational-learning.\nABSTRACT Advanced statistical modeling and knowledge representation techniques for a newly emerging area of machine learning and probabilistic reasoning; includes introductory material, tutorials for different proposed approaches, and applications. Handling inherent uncertainty and exploiting compositional structure are fundamental to understanding and designing large-scale systems. Statistical relational learning builds on ideas from probability theory and statistics to address uncertainty while incorporating tools from logic, databases and programming languages to represent structure. In Introduction to Statistical Relational Learning, leading researchers in this emerging area of machine learning describe current formalisms, models, and algorithms that enable effective and robust reasoning about richly structured systems and data. The early chapters provide tutorials for material used in later chapters, offering introductions to representation, inference and learning in graphical models, and logic. The book then describes object-oriented approaches, including probabilistic relational models, relational Markov networks, and probabilistic entity-relationship models as well as logic-based formalisms including Bayesian logic programs, Markov logic, and stochastic logic programs. Later chapters discuss such topics as probabilistic models with unknown objects, relational dependency networks, reinforcement learning in relational domains, and information extraction. By presenting a variety of approaches, the book highlights commonalities and clarifies important differences among proposed approaches and, along the way, identifies important representational and algorithmic issues. Numerous applications are provided throughout.\nprobabilistic models Heckerman, Meek \u0026amp; Koller (2004) D. Heckerman, Christopher Meek, D. Koller. (2004)\nProbabilistic Entity-Relationship Models, PRMs, and Plate Models\nPaper Link\nInfluential Citation Count (13), SS-ID (04757f50d0021c8351237fad2f4002e59d5d8430)\nABSTRACT\nWe introduce a graphical language for re- lational data called the probabilistic entity- relationship (PER) model. The model is an extension of the entity-relationship model, a common model for the abstract repre- sentation of database structure. We con- centrate on the directed version of this model—the directed acyclic probabilistic entity-relationship (DAPER) model. The DAPER model is closely related to the plate model and the probabilistic relational model (PRM), existing models for relational data. The DAPER model is more expressive than either existing model, and also helps to demonstrate their similarity. dinary graphical models (e.g., directed-acyclic graphs and undirected graphs) are to flat data. In this paper, we introduce a new graphical model for relational data—the probabilistic entity-relationship (PER) model. This model class is more expressive than either PRMs or plate models. We concentrate on a particular type of PER model—the directed acyclic probabilistic entity-relationship (DAPER) model—in which all probabilistic arcs are directed. It is this ver- sion of PER model that is most similar to the plate model and PRM. We define new versions of the plate model and PRM such their expressiveness is equivalent to the DAPER model, and then (in the expanded tech report, Heckerman, Meek, and Koller, 2004) compare the new and old definitions. Consequently, we both demonstrate the similarity among the original lan- guages as well as enhance their abilities to express con- ditional independence in relational data. Our hope is that this demonstration of similarity will foster greater communication and collaboration among statisticians who mostly use plate models and computer scientists who mostly use PRMs. We in fact began this work with an effort to unify traditional PRMs and plate models. In the process, we discovered that it was important to make both entities and relationships (concepts discussed in de- tail in the next section) first class objects in the lan- guage. We in turn discovered an existing language that does this—the entity-relationship (ER) model—a commonly used model for the abstract representation of database structure. We then extended this language to handle probabilistic relationships, creating the PER model. We should emphasize that the languages we discuss are neither meant to serve as a database schema nor meant to be built on top of one. In practice, database schemas are built up over a long period of time as the needs of the database consumers change. Conse-\nprobabilistic models Tang \u0026amp; Liu (2012) Jiliang Tang, Huan Liu. (2012)\nUnsupervised feature selection for linked social media data\nKDD\nPaper Link\nInfluential Citation Count (17), SS-ID (ec8c47ef5797976594c7b784dcad6776743ef014)\nABSTRACT\nThe prevalent use of social media produces mountains of unlabeled, high-dimensional data. Feature selection has been shown effective in dealing with high-dimensional data for efficient data mining. Feature selection for unlabeled data remains a challenging task due to the absence of label information by which the feature relevance can be assessed. The unique characteristics of social media data further complicate the already challenging problem of unsupervised feature selection, (e.g., part of social media data is linked, which makes invalid the independent and identically distributed assumption), bringing about new challenges to traditional unsupervised feature selection algorithms. In this paper, we study the differences between social media data and traditional attribute-value data, investigate if the relations revealed in linked data can be used to help select relevant features, and propose a novel unsupervised feature selection framework, LUFS, for linked social media data. We perform experiments with real-world social media datasets to evaluate the effectiveness of the proposed framework and probe the working of its key components.\nunsupervised approach for LPP Gao, Denoyer \u0026amp; Gallinari (2011) Sheng Gao, Ludovic Denoyer, P. Gallinari. (2011)\nTemporal link prediction by integrating content and structure information\nCIKM \u0026lsquo;11\nPaper Link\nInfluential Citation Count (4), SS-ID (8a634a82681897822b14de28849c6548346206a0)\nABSTRACT\nIn this paper we address the problem of temporal link prediction, i.e., predicting the apparition of new links, in time-evolving networks. This problem appears in applications such as recommender systems, social network analysis or citation analysis. Link prediction in time-evolving networks is usually based on the topological structure of the network only. We propose here a model which exploits multiple information sources in the network in order to predict link occurrence probabilities as a function of time. The model integrates three types of information: the global network structure, the content of nodes in the network if any, and the local or proximity information of a given vertex. The proposed model is based on a matrix factorization formulation of the problem with graph regularization. We derive an efficient optimization method to learn the latent factors of this model. Extensive experiments on several real world datasets suggest that our unified framework outperforms state-of-the-art methods for temporal link prediction tasks.\ntemporal link prediction based on matrix factorization and noise reduction in large networks Gao et al. (2015) F. Gao, Katarzyna Musial, C. Cooper, S. Tsoka. (2015)\nLink Prediction Methods and Their Accuracy for Different Social Networks and Network Metrics\nSci. Program.\nPaper Link\nInfluential Citation Count (2), SS-ID (d47e5c2dfb5dcd58e8d0f513807e5671e4607a35)\nABSTRACT\nCurrently, we are experiencing a rapid growth of the number of social-based online systems. The availability of the vast amounts of data gathered in those systems brings new challenges that we face when trying to analyse it. One of the intensively researched topics is the prediction of social connections between users. Although a lot of effort has been made to develop new prediction approaches, the existing methods are not comprehensively analysed. In this paper we investigate the correlation between network metrics and accuracy of different prediction methods. We selected six time-stamped real-world social networks and ten most widely used link prediction methods. The results of the experiments show that the performance of some methods has a strong correlation with certain network metrics. We managed to distinguish \u0026ldquo;prediction friendly\u0026rdquo; networks, for which most of the prediction methods give good performance, as well as \u0026ldquo;prediction unfriendly\u0026rdquo; networks, for which most of the methods result in high prediction error. Correlation analysis between network metrics and prediction accuracy of prediction methods may form the basis of a metalearning system where based on network characteristics it will be able to recommend the right prediction method for a given network.\ntemporal link prediction based on matrix factorization and noise reduction in large networks McPherson, Smith-Lovin \u0026amp; Cook (2001) M. McPherson, L. Smith-Lovin, J. Cook. (2001)\nBirds of a Feather: Homophily in Social Networks\nPaper Link\nInfluential Citation Count (673), SS-ID (228bafce55e6f1cbe2c1df75b1949a1fb9c93eb3)\nABSTRACT\nSimilarity breeds connection. This principle—the homophily principle—structures network ties of every type, including marriage, friendship, work, advice, support, information transfer, exchange, comembership, and other types of relationship. The result is that people\u0026rsquo;s personal networks are homogeneous with regard to many sociodemographic, behavioral, and intrapersonal characteristics. Homophily limits people\u0026rsquo;s social worlds in a way that has powerful implications for the information they receive, the attitudes they form, and the interactions they experience. Homophily in race and ethnicity creates the strongest divides in our personal environments, with age, religion, education, occupation, and gender following in roughly that order. Geographic propinquity, families, organizations, and isomorphic positions in social systems all create contexts in which homophilous relations form. Ties between nonsimilar individuals also dissolve at a higher rate, which sets the stage for the formation of niches (localize\u0026hellip;\nattribute-based link formation in social networks Robins et al. (2007) G. Robins, T. Snijders, Peng Wang, M. Handcock, P. Pattison. (2007)\nRecent developments in exponential random graph (p) models for social networks*\nSoc. Networks\nPaper Link\nInfluential Citation Count (58), SS-ID (00350a2b4adbaba0293ec10f73b759cfddde166e)\nABSTRACT\nThis article reviews new specifications for exponential random graph models proposed by Snijders et al. [Snijders, T.A.B., Pattison, P., Robins, G.L., Handcock, M., 2006. New specifications for exponential random graph models. Sociological Methodology] and demonstrates their improvement over homogeneous Markov random graph models in fitting empirical network data. Not only do the new specifications show improvements in goodness of fit for various data sets, but they also help to avoid the problem of near-degeneracy that often afflicts the fitting of Markov random graph models in practice, particularly to network data exhibiting high levels of transitivity. The inclusion of a new higher order transitivity statistic allows estimation of parameters of exponential graph models for many (but not all) cases where it is impossible to estimate parameters of homogeneous Markov graph models. The new specifications were used to model a large number of classical small-scale network data sets and showed a dramatically better performance than Markov graph models. We also review three current programs for obtaining maximum likelihood estimates of model parameters and we compare these Monte Carlo maximum likelihood estimates with less accurate pseudo-likelihood estimates. Finally, we discuss whether homogeneous Markov random graph models may be superseded by the new specifications, and how additional elaborations may further improve model performance.\nattribute-based link formation in social networks Liu et al. (2013) Feng Liu, Bingquan Liu, Chengjie Sun, Ming Liu, Xiaolong Wang. (2013)\nDeep Learning Approaches for Link Prediction in Social Network Services\nICONIP\nPaper Link\nInfluential Citation Count (3), SS-ID (dc995128c156b587d9b627e89d413563cd1e05df)\nABSTRACT\nWith the fast development of online Social Network ServicesSNS, social members get large amounts of interactions which can be presented as links with values. The link prediction problem is to estimate the values of unknown links by the known links\u0026rsquo; information. In this paper, based on deep learning approaches, methods for link prediction are proposed. Firstly, an unsupervised method that can works well with little samples is introduced. Secondly, we propose a feature representation method, and the represented features perform better than original ones for link prediction. Thirdly, based on Restricted Boltzmann Machine RBM that present the joint distribution of link samples and their values, we propose a method for link prediction. By the experiments\u0026rsquo; results, our method can predict links\u0026rsquo; values with high accuracy for data from SNS websites.\ndeep learning approaches for link formation in social networks Zhai \u0026amp; Zhang (2015) Shuangfei Zhai, Zhongfei Zhang. (2015)\nDropout Training of Matrix Factorization and Autoencoder for Link Prediction in Sparse Graphs\nSDM\nPaper Link\nInfluential Citation Count (3), SS-ID (1e79e7d3247c7fddebaf5242c661de79bf7f31a7)\nABSTRACT\nMatrix factorization (MF) and Autoencoder (AE) are among the most successful approaches of unsupervised learning. While MF based models have been extensively exploited in the graph modeling and link prediction literature, the AE family has not gained much attention. In this paper we investigate both MF and AE\u0026rsquo;s application to the link prediction problem in sparse graphs. We show the connection between AE and MF from the perspective of multiview learning, and further propose MF+AE: a model training MF and AE jointly with shared parameters. We apply dropout to training both the MF and AE parts, and show that it can significantly prevent overfitting by acting as an adaptive regularization. We conduct experiments on six real world sparse graph datasets, and show that MF+AE consistently outperforms the competing methods, especially on datasets that demonstrate strong non-cohesive structures.\ndeep learning approaches for link formation in social networks Berg, Kipf \u0026amp; Welling (2017) Rianne van den Berg, Thomas Kipf, M. Welling. (2017)\nGraph Convolutional Matrix Completion\nArXiv\nPaper Link\nInfluential Citation Count (121), SS-ID (c509de93b3d34ecd178f598814bd5177a0a29726)\nABSTRACT\nWe consider matrix completion for recommender systems from the point of view of link prediction on graphs. Interaction data such as movie ratings can be represented by a bipartite user-item graph with labeled edges denoting observed ratings. Building on recent progress in deep learning on graph-structured data, we propose a graph auto-encoder framework based on differentiable message passing on the bipartite interaction graph. Our model shows competitive performance on standard collaborative filtering benchmarks. In settings where complimentary feature information or structured data such as a social network is available, our framework outperforms recent state-of-the-art methods.\ndeep learning approaches for link formation in social networks Liu et al. (2017) Zemin Liu, V. Zheng, Zhou Zhao, Fanwei Zhu, K. Chang, Minghui Wu, Jing Ying. (2017)\nSemantic Proximity Search on Heterogeneous Graph by Proximity Embedding\nAAAI\nPaper Link\nInfluential Citation Count (3), SS-ID (f4ef2c9a97c183b24d08ca67f6f55b98d441e8e6)\nABSTRACT\nMany real-world networks have a rich collection of objects. The semantics of these objects allows us to capture different classes of proximities, thus enabling an important task of semantic proximity search. As the core of semantic proximity search, we have to measure the proximity on a heterogeneous graph, whose nodes are various types of objects. Most of the existing methods rely on engineering features about the graph structure between two nodes to measure their proximity. With recent development on graph embedding, we see a good chance to avoid feature engineering for semantic proximity search. There is very little work on using graph embedding for semantic proximity search. We also observe that graph embedding methods typically focus on embedding nodes, which is an “indirect” approach to learn the proximity. Thus, we introduce a new concept of proximity embedding, which directly embeds the network structure between two possibly distant nodes. We also design our proximity embedding, so as to flexibly support both symmetric and asymmetric proximities. Based on the proximity embedding, we can easily estimate the proximity score between two nodes and enable search on the graph. We evaluate our proximity embedding method on three real-world public data sets, and show it outperforms the state-of-the-art baselines. We release the code for proximity embedding.\nheterogeneous graph link prediction Liu et al. (2018) Zemin Liu, V. Zheng, Zhou Zhao, Fanwei Zhu, K. Chang, Minghui Wu, Jing Ying. (2018)\nDistance-Aware DAG Embedding for Proximity Search on Heterogeneous Graphs\nAAAI\nPaper Link\nInfluential Citation Count (3), SS-ID (6065a29041525360665320fab231dd9e5ca82ab8)\nABSTRACT\nProximity search on heterogeneous graphs aims to measure the proximity between two nodes on a graph w.r.t. some semantic relation for ranking. Pioneer work often tries to measure such proximity by paths connecting the two nodes. However, paths as linear sequences have limited expressiveness for the complex network connections. In this paper, we explore a more expressive DAG (directed acyclic graph) data structure for modeling the connections between two nodes. Particularly, we are interested in learning a representation for the DAGs to encode the proximity between two nodes. We face two challenges to use DAGs, including how to efficiently generate DAGs and how to effectively learn DAG embedding for proximity search. We find distance-awareness as important for proximity search and the key to solve the above challenges. Thus we develop a novel Distance-aware DAG Embedding (D2AGE) model. We evaluate D2AGE on three benchmark data sets with six semantic relations, and we show that D2AGE outperforms the state-of-the-art baselines. We release the code on https://github.com/shuaiOKshuai.\nheterogeneous graph link prediction Crichton et al. (2018) Gamal K. O. Crichton, Yufan Guo, Sampo Pyysalo, A. Korhonen. (2018)\nNeural networks for link prediction in realistic biomedical graphs: a multi-dimensional evaluation of graph embedding-based approaches\nBMC Bioinformatics\nPaper Link\nInfluential Citation Count (1), SS-ID (7b64c1527ed63b57c0c9fde327bba1529775c5d3)\nABSTRACT\nBackgroundLink prediction in biomedical graphs has several important applications including predicting Drug-Target Interactions (DTI), Protein-Protein Interaction (PPI) prediction and Literature-Based Discovery (LBD). It can be done using a classifier to output the probability of link formation between nodes. Recently several works have used neural networks to create node representations which allow rich inputs to neural classifiers. Preliminary works were done on this and report promising results. However they did not use realistic settings like time-slicing, evaluate performances with comprehensive metrics or explain when or why neural network methods outperform. We investigated how inputs from four node representation algorithms affect performance of a neural link predictor on random- and time-sliced biomedical graphs of real-world sizes (∼ 6 million edges) containing information relevant to DTI, PPI and LBD. We compared the performance of the neural link predictor to those of established baselines and report performance across five metrics.ResultsIn random- and time-sliced experiments when the neural network methods were able to learn good node representations and there was a negligible amount of disconnected nodes, those approaches outperformed the baselines. In the smallest graph (∼ 15,000 edges) and in larger graphs with approximately 14% disconnected nodes, baselines such as Common Neighbours proved a justifiable choice for link prediction. At low recall levels (∼ 0.3) the approaches were mostly equal, but at higher recall levels across all nodes and average performance at individual nodes, neural network approaches were superior. Analysis showed that neural network methods performed well on links between nodes with no previous common neighbours; potentially the most interesting links. Additionally, while neural network methods benefit from large amounts of data, they require considerable amounts of computational resources to utilise them.ConclusionsOur results indicate that when there is enough data for the neural network methods to use and there are a negligible amount of disconnected nodes, those approaches outperform the baselines. At low recall levels the approaches are mostly equal but at higher recall levels and average performance at individual nodes, neural network approaches are superior. Performance at nodes without common neighbours which indicate more unexpected and perhaps more useful links account for this.\nevaluation of link prediction models based on graph embeddings Node clustering Definition 9 (Node Clustering or Community Detection or Graph Partitioning Node Clustering or Community Detection or Graph Partitionin is the task of the partitioning of a graph $G(V, E)$ into several subgraphs $G_i(V_i, E_i)$ with a dense connection within groups and sparse connection between clusters.\nPaper Approach Zhou, Cheng \u0026amp; Yu (2009) Yang Zhou, Hong Cheng, J. Yu. (2009)\nGraph Clustering Based on Structural/Attribute Similarities\nProc. VLDB Endow.\nPaper Link\nInfluential Citation Count (58), SS-ID (3f397e7dab0e253e0859d18bb5711b5471c657fe)\nABSTRACT\nThe goal of graph clustering is to partition vertices in a large graph into different clusters based on various criteria such as vertex connectivity or neighborhood similarity. Graph clustering techniques are very useful for detecting densely connected groups in a large graph. Many existing graph clustering methods mainly focus on the topological structure for clustering, but largely ignore the vertex properties which are often heterogenous. In this paper, we propose a novel graph clustering algorithm, SA-Cluster, based on both structural and attribute similarities through a unified distance measure. Our method partitions a large graph associated with attributes into k clusters so that each cluster contains a densely connected subgraph with homogeneous attribute values. An effective method is proposed to automatically learn the degree of contributions of structural similarity and attribute similarity. Theoretical analysis is provided to show that SA-Cluster is converging. Extensive experimental results demonstrate the effectiveness of SA-Cluster through comparison with the state-of-the-art graph clustering and summarization methods.\nuse attributes for node clustering Newman \u0026amp; Girvan (2003) M. Newman, M. Girvan. (2003)\nFinding and evaluating community structure in networks.\nPhysical review. E, Statistical, nonlinear, and soft matter physics\nPaper Link\nInfluential Citation Count (1165), SS-ID (b222526a2990d9073d734e2a1830210ca14cd8bd)\nABSTRACT\nWe propose and study a set of algorithms for discovering community structure in networks-natural divisions of network nodes into densely connected subgroups. Our algorithms all share two definitive features: first, they involve iterative removal of edges from the network to split it into communities, the edges removed being identified using any one of a number of possible \u0026ldquo;betweenness\u0026rdquo; measures, and second, these measures are, crucially, recalculated after each removal. We also propose a measure for the strength of the community structure found by our algorithms, which gives us an objective metric for choosing the number of communities into which a network should be divided. We demonstrate that our algorithms are highly effective at discovering community structure in both computer-generated and real-world network data, and show how they can be used to shed light on the sometimes dauntingly complex structure of networked systems.\ncommunity detection Fortunato (2009) S. Fortunato. (2009)\nCommunity detection in graphs\nArXiv\nPaper Link\nInfluential Citation Count (717), SS-ID (9be428c9383d47b86570b1b9fc20faf006346c5d)\nABSTRACT\nThe modern science of networks has brought significant advances to our understanding of complex systems. One of the most relevant features of graphs representing real systems is community structure, or clustering, i. e. the organization of vertices in clusters, with many edges joining vertices of the same cluster and comparatively few edges joining vertices of different clusters. Such clusters, or communities, can be considered as fairly independent compartments of a graph, playing a similar role like, e. g., the tissues or the organs in the human body. Detecting communities is of great importance in sociology, biology and computer science, disciplines where systems are often represented as graphs. This problem is very hard and not yet satisfactorily solved, despite the huge effort of a large interdisciplinary community of scientists working on it over the past few years. We will attempt a thorough exposition of the topic, from the definition of the main elements of the problem, to the presentation of most methods developed, with a special focus on techniques designed by statistical physicists, from the discussion of crucial issues like the significance of clustering and how methods should be tested and compared against each other, to the description of applications to real networks.\ncommunity detection Xu et al. (2007) Xiaowei Xu, Nurcan Yuruk, Zhidan Feng, T. Schweiger. (2007)\nSCAN: a structural clustering algorithm for networks\nKDD \u0026lsquo;07\nPaper Link\nInfluential Citation Count (107), SS-ID (25dfac6955913c163a61bc6e2ae8c5c7f3ca8f87)\nABSTRACT\nNetwork clustering (or graph partitioning) is an important task for the discovery of underlying structures in networks. Many algorithms find clusters by maximizing the number of intra-cluster edges. While such algorithms find useful and interesting structures, they tend to fail to identify and isolate two kinds of vertices that play special roles - vertices that bridge clusters (hubs) and vertices that are marginally connected to clusters (outliers). Identifying hubs is useful for applications such as viral marketing and epidemiology since hubs are responsible for spreading ideas or disease. In contrast, outliers have little or no influence, and may be isolated as noise in the data. In this paper, we proposed a novel algorithm called SCAN (Structural Clustering Algorithm for Networks), which detects clusters, hubs and outliers in networks. It clusters vertices based on a structural similarity measure. The algorithm is fast and efficient, visiting each vertex only once. An empirical evaluation of the method using both synthetic and real datasets demonstrates superior performance over other methods such as the modularity-based algorithms.\nstructural equivalence Shi \u0026amp; Malik (1997) Jianbo Shi, J. Malik. (1997)\nNormalized cuts and image segmentation\nProceedings of IEEE Computer Society Conference on Computer Vision and Pattern Recognition\nPaper Link\nInfluential Citation Count (1462), SS-ID (b94c7ff9532ab26c3aedbee3988ec4c7a237c173)\nABSTRACT\nWe propose a novel approach for solving the perceptual grouping problem in vision. Rather than focusing on local features and their consistencies in the image data, our approach aims at extracting the global impression of an image. We treat image segmentation as a graph partitioning problem and propose a novel global criterion, the normalized cut, for segmenting the graph. The normalized cut criterion measures both the total dissimilarity between the different groups as well as the total similarity within the groups. We show that an efficient computational technique based on a generalized eigenvalue problem can be used to optimize this criterion. We have applied this approach to segmenting static images and found results very encouraging.\nconnumity as dense subgraph with a high number of edges inside subgraph Ding et al. (2001) C. Ding, Xiaofeng He, H. Zha, Ming Gu, H. Simon. (2001)\nA min-max cut algorithm for graph partitioning and data clustering\nProceedings 2001 IEEE International Conference on Data Mining\nPaper Link\nInfluential Citation Count (43), SS-ID (6ebb015ac7f7872ecadd75b837e859621abd0751)\nABSTRACT\nAn important application of graph partitioning is data clustering using a graph model - the pairwise similarities between all data objects form a weighted graph adjacency matrix that contains all necessary information for clustering. In this paper, we propose a new algorithm for graph partitioning with an objective function that follows the min-max clustering principle. The relaxed version of the optimization of the min-max cut objective function leads to the Fiedler vector in spectral graph partitioning. Theoretical analyses of min-max cut indicate that it leads to balanced partitions, and lower bounds are derived. The min-max cut algorithm is tested on newsgroup data sets and is found to out-perform other current popular partitioning/clustering methods. The linkage-based refinements to the algorithm further improve the quality of clustering substantially. We also demonstrate that a linearized search order based on linkage differential is better than that based on the Fiedler vector, providing another effective partitioning method.\nconnumity as dense subgraph with a high number of edges inside subgraph White \u0026amp; Smyth (2005) Scott White, Padhraic Smyth. (2005)\nA Spectral Clustering Approach To Finding Communities in Graph\nSDM\nPaper Link\nInfluential Citation Count (22), SS-ID (9a92300b0ecc33f8e55a8ac945a51aaade549013)\nABSTRACT\nClustering nodes in a graph is a useful general technique in data mining of large network data sets. In this context, Newman and Girvan [9] recently proposed an objective function for graph clustering called the Q function which allows automatic selection of the number of clusters. Empirically, higher values of the Q function have been shown to correlate well with good graph clusterings. In this paper we show how optimizing the Q function can be reformulated as a spectral relaxation problem and propose two new spectral clustering algorithms that seek to maximize Q. Experimental results indicate that the new algorithms are efficient and effective at finding both good clusterings and the appropriate number of clusters across a variety of real-world graph data sets. In addition, the spectral algorithms are much faster for large sparse graphs, scaling roughly linearly with the number of nodes n in the graph, compared to O(n) for previous clustering algorithms using the Q function.\nnode embedding with K-means or DBScan Tian et al. (2014) Fei Tian, Bin Gao, Qing Cui, Enhong Chen, Tie-Yan Liu. (2014)\nLearning Deep Representations for Graph Clustering\nAAAI\nPaper Link\nInfluential Citation Count (39), SS-ID (df787a974fff59f557ed1ec620fc345568aec491)\nABSTRACT\nRecently deep learning has been successfully adopted in many applications such as speech recognition and image classification. In this work, we explore the possibility of employing deep learning in graph clustering. We propose a simple method, which first learns a nonlinear embedding of the original graph by stacked autoencoder, and then runs k-means algorithm on the embedding to obtain clustering result. We show that this simple method has solid theoretical foundation, due to the similarity between autoencoder and spectral clustering in terms of what they actually optimize. Then, we demonstrate that the proposed method is more efficient and flexible than spectral clustering. First, the computational complexity of autoencoder is much lower than spectral clustering: the former can be linear to the number of nodes in a sparse graph while the latter is super quadratic due to eigenvalue decomposition. Second, when additional sparsity constraint is imposed, we can simply employ the sparse autoencoder developed in the literature of deep learning; however, it is nonstraightforward to implement a sparse spectral method. The experimental results on various graph datasets show that the proposed method significantly outperforms conventional spectral clustering, which clearly indicates the effectiveness of deep learning in graph clustering.\nnode embedding with K-means or DBScan Cao, Lu \u0026amp; Wu (2015) Shaosheng Cao, Wei Lu, Qiongkai Xu. (2015)\nGraRep: Learning Graph Representations with Global Structural Information\nCIKM\nPaper Link\nInfluential Citation Count (131), SS-ID (c2fd72cb2a77941e655b5d949d0d59b01e173c3b)\nABSTRACT\nIn this paper, we present {GraRep}, a novel model for learning vertex representations of weighted graphs. This model learns low dimensional vectors to represent vertices appearing in a graph and, unlike existing work, integrates global structural information of the graph into the learning process. We also formally analyze the connections between our work and several previous research efforts, including the DeepWalk model of Perozzi et al. as well as the skip-gram model with negative sampling of Mikolov et al. We conduct experiments on a language network, a social network as well as a citation network and show that our learned global representations can be effectively used as features in tasks such as clustering, classification and visualization. Empirical results demonstrate that our representation significantly outperforms other state-of-the-art methods in such tasks.\nnode embedding with K-means or DBScan Chen et al. (2015) Marcus Chen, I. Tsang, Mingkui Tan, T. Cham. (2015)\nA Unified Feature Selection Framework for Graph Embedding on High Dimensional Data\nIEEE Transactions on Knowledge and Data Engineering\nPaper Link\nInfluential Citation Count (3), SS-ID (dab795b562c7cc270c9099b925d685bea0abe82a)\nABSTRACT\nAlthough graph embedding has been a powerful tool for modeling data intrinsic structures, simply employing all features for data structure discovery may result in noise amplification. This is particularly severe for high dimensional data with small samples. To meet this challenge, this paper proposes a novel efficient framework to perform feature selection for graph embedding, in which a category of graph embedding methods is cast as a least squares regression problem. In this framework, a binary feature selector is introduced to naturally handle the feature cardinality in the least squares formulation. The resultant integral programming problem is then relaxed into a convex Quadratically Constrained Quadratic Program (QCQP) learning problem, which can be efficiently solved via a sequence of accelerated proximal gradient (APG) methods. Since each APG optimization is w.r.t. only a subset of features, the proposed method is fast and memory efficient. The proposed framework is applied to several graph embedding learning problems, including supervised, unsupervised, and semi-supervised graph embedding. Experimental results on several high dimensional data demonstrated that the proposed method outperformed the considered state-of-the-art methods.\nnode embedding with K-means or DBScan Cao, Lu \u0026amp; Xu (2016) Shaosheng Cao, Wei Lu, Qiongkai Xu. (2016)\nDeep Neural Networks for Learning Graph Representations\nAAAI\nPaper Link\nInfluential Citation Count (59), SS-ID (1a37f07606d60df365d74752857e8ce909f700b3)\nABSTRACT\nIn this paper, we propose a novel model for learning graph representations, which generates a low-dimensional vector representation for each vertex by capturing the graph structural information. Different from other previous research efforts, we adopt a random surfing model to capture graph structural information directly, instead of using the sampling-based method for generating linear sequences proposed by Perozzi et al. (2014). The advantages of our approach will be illustrated from both theorical and empirical perspectives. We also give a new perspective for the matrix factorization method proposed by Levy and Goldberg (2014), in which the pointwise mutual information (PMI) matrix is considered as an analytical solution to the objective function of the skip-gram model with negative sampling proposed by Mikolov et al. (2013). Unlike their approach which involves the use of the SVD for finding the low-dimensitonal projections from the PMI matrix, however, the stacked denoising autoencoder is introduced in our model to extract complex features and model non-linearities. To demonstrate the effectiveness of our model, we conduct experiments on clustering and visualization tasks, employing the learned vertex representations as features. Empirical results on datasets of varying sizes show that our model outperforms other stat-of-the-art models in such tasks.\nnode embedding with K-means or DBScan Nie, Zhu \u0026amp; Li (2017) F. Nie, Wei Zhu, Xuelong Li. (2017)\nUnsupervised Large Graph Embedding\nAAAI\nPaper Link\nInfluential Citation Count (5), SS-ID (9ad503ff70a2b3a1ddebc96683ed73c7fcd0840b)\nABSTRACT\nThere are many successful spectral based unsupervised dimensionality reduction methods, including Laplacian Eigenmap (LE), Locality Preserving Projection (LPP), Spectral Regression (SR), etc. LPP and SR are two different linear spectral based methods, however, we discover that LPP and SR are equivalent, if the symmetric similarity matrix is doubly stochastic, Positive Semi-Definite (PSD) and with rank p, where p is the reduced dimension. The discovery promotes us to seek low-rank and doubly stochastic similarity matrix, we then propose an unsupervised linear dimensionality reduction method, called Unsupervised Large Graph Embedding (ULGE). ULGE starts with similar idea as LPP, it adopts an efficient approach to construct similarity matrix and then performs spectral analysis efficiently, the computational complexity can reduce to O(ndm), which is a significant improvement compared to conventional spectral based methods which need O(nd) at least, where n, d and m are the number of samples, dimensions and anchors, respectively. Extensive experiments on several public available data sets demonstrate the efficiency and effectiveness of the proposed method.\nnode embedding with K-means or DBScan Tang, Nie \u0026amp; Jain (2016) Capped Lp-Norm Graph Embedding for Photo Clustering\nACM Multimedia\nPaper Link\nInfluential Citation Count (0), SS-ID (1cb5547c3f5ff42746bf9c4e083795aed3c8c609)\nABSTRACT\nPhotos are a predominant source of information on a global scale. Cluster analysis of photos can be applied to situation recognition and understanding cultural dynamics. Graph-based learning provides a current approach for modeling data in clustering problems. However, the performance of this framework depends heavily on initial graph construction by input data. Data outliers degrade graph quality, leading to poor clustering results. We designed a new capped lp-norm graph-based model to reduce the impact of outliers. This is accomplished by allowing the data graph to self adjust as part of the graph embedding. Furthermore, we derive an iterative algorithm to solve the objective function optimization problem. Experiments on four real-world benchmark data sets and Yahoo Flickr Creative Commons data set show the effectiveness of this new graph-based capped lp-norm clustering method.\njoint optimization of clustering and node embedding Wei et al. (2017) Xiaokai Wei, Linchuan Xu, Bokai Cao, Philip S. Yu. (2017)\nCross View Link Prediction by Learning Noise-resilient Representation Consensus\nWWW\nPaper Link\nInfluential Citation Count (3), SS-ID (c3d62bcb84fc3a2aa9b8f4691677d7c02738f1bc)\nABSTRACT\nLink Prediction has been an important task for social and information networks. Existing approaches usually assume the completeness of network structure. However, in many real-world networks, the links and node attributes can usually be partially observable. In this paper, we study the problem of Cross View Link Prediction (CVLP) on partially observable networks, where the focus is to recommend nodes with only links to nodes with only attributes (or vice versa). We aim to bridge the information gap by learning a robust consensus for link-based and attribute-based representations so that nodes become comparable in the latent space. Also, the link-based and attribute-based representations can lend strength to each other via this consensus learning. Moreover, attribute selection is performed jointly with the representation learning to alleviate the effect of noisy high-dimensional attributes. We present two instantiations of this framework with different loss functions and develop an alternating optimization framework to solve the problem. Experimental results on four real-world datasets show the proposed algorithm outperforms the baseline methods significantly for cross-view link prediction.\njoint optimization of clustering and node embedding Wang et al. (2017) Xiao Wang, Peng Cui, Jing Wang, J. Pei, Wenwu Zhu, Shiqiang Yang. (2017)\nCommunity Preserving Network Embedding\nAAAI\nPaper Link\nInfluential Citation Count (52), SS-ID (d3e0d596efd9d19b93d357565a68dfa925dce2bb)\nABSTRACT\nNetwork embedding, aiming to learn the low-dimensional representations of nodes in networks, is of paramount importance in many real applications. One basic requirement of network embedding is to preserve the structure and inherent properties of the networks. While previous network embedding methods primarily preserve the microscopic structure, such as the first- and second-order proximities of nodes, the mesoscopic community structure, which is one of the most prominent feature of networks, is largely ignored. In this paper, we propose a novel Modularized Nonnegative Matrix Factorization (M-NMF) model to incorporate the community structure into network embedding. We exploit the consensus relationship between the representations of nodes and community structure, and then jointly optimize NMF based representation learning model and modularity based community detection model in a unified framework, which enables the learned representations of nodes to preserve both of the microscopic and community structures. We also provide efficient updating rules to infer the parameters of our model, together with the correctness and convergence guarantees. Extensive experimental results on a variety of real-world networks show the superior performance of the proposed method over the state-of-the-arts.\nefficient iterative community aware network embedding Zheng et al. (2016) V. Zheng, Sandro Cavallari, Hongyun Cai, K. Chang, E. Cambria. (2016)\nFrom Node Embedding To Community Embedding\nArXiv\nPaper Link\nInfluential Citation Count (0), SS-ID (88dabd8d295ba9f727baccd73c214e094c6d134f)\nABSTRACT\nMost of the existing graph embedding methods focus on nodes, which aim to output a vector representation for each node in the graph such that two nodes being \u0026ldquo;close\u0026rdquo; on the graph are close too in the low-dimensional space. Despite the success of embedding individual nodes for graph analytics, we notice that an important concept of embedding communities (i.e., groups of nodes) is missing. Embedding communities is useful, not only for supporting various community-level applications, but also to help preserve community structure in graph embedding. In fact, we see community embedding as providing a higher-order proximity to define the node closeness, whereas most of the popular graph embedding methods focus on first-order and/or second-order proximities. To learn the community embedding, we hinge upon the insight that community embedding and node embedding reinforce with each other. As a result, we propose ComEmbed, the first community embedding method, which jointly optimizes the community embedding and node embedding together. We evaluate ComEmbed on real-world data sets. We show it outperforms the state-of-the-art baselines in both tasks of node classification and community prediction.\nefficient iterative community aware network embedding Cavallari et al. (2017) Sandro Cavallari, V. Zheng, Hongyun Cai, K. Chang, E. Cambria. (2017)\nLearning Community Embedding with Community Detection and Node Embedding on Graphs\nCIKM\nPaper Link\nInfluential Citation Count (24), SS-ID (c8cee328b1774c2d38bea10f9fe9d081d8074307)\nABSTRACT\nIn this paper, we study an important yet largely under-explored setting of graph embedding, i.e., embedding communities instead of each individual nodes. We find that community embedding is not only useful for community-level applications such as graph visualization, but also beneficial to both community detection and node classification. To learn such embedding, our insight hinges upon a closed loop among community embedding, community detection and node embedding. On the one hand, node embedding can help improve community detection, which outputs good communities for fitting better community embedding. On the other hand, community embedding can be used to optimize the node embedding by introducing a community-aware high-order proximity. Guided by this insight, we propose a novel community embedding framework that jointly solves the three tasks together. We evaluate such a framework on multiple real-world datasets, and show that it improves graph visualization and outperforms state-of-the-art baselines in various application tasks, e.g., community detection and node classification.\nefficient iterative community aware network embedding Teng \u0026amp; Liu (2020) Xiangyi Teng, Jing Liu. (2020)\nAtrributed Graph Embedding Based on Multiobjective Evolutionary Algorithm for Overlapping Community Detection\n2020 IEEE Congress on Evolutionary Computation (CEC)\nPaper Link\nInfluential Citation Count (0), SS-ID (b92a31918b95ae220d1b23f0ecc4f0f8cf00599f)\nABSTRACT\nGraph embedding methods aim to represent nodes in the network into a low-dimensional and continuous vector space while preserving the topological structure and varieties of relational information maximally. Nowadays the structural connections of networks and the attribute information about each node are more easily available than before. As a result, many community detection algorithms for attributed networks have been proposed. However, the majority of these methods cannot deal with the overlapping community detection problem, which is one of the most significant issues in the real-world complex network study. In addition, it is quite challenging to make full use of both structural and attribute information instead of only focusing on one part. To this end, in this paper we innovatively combine the graph embedding with multiobjective evolutionary algorithms (MOEAs) for overlapping community detection problems in attributed networks. As far as I am concerned, MOEA is first used to integrate with graph embedding methods for overlapping community detection. We term our method as MOEA-GEOV, which can automatically determine the number of communities without any prior knowledge and consider topological structure and vertex properties synchronously. In MOEA-GEOV, two objective functions concerning community structure and attribute similarity are carefully designed. Moreover, a heuristic initialization method is proposed to get a relatively good initial population. Then a novel encoding and decoding strategy is designed to efficiently represent the overlapping communities and corresponding embedded representation. In the experiments, the performance of MOEA-GEOV is validated on both single and multiple attribute real-world networks. The experimental results of community detection tasks demonstrate our method can effectively obtain overlapping community structures with practical significance.\nmulti-objective evolutionary algorithm for community detection Zhang, Shang \u0026amp; Jiao (2020) Complex network graph embedding method based on shortest path and MOEA/D for community detection\nAppl. Soft Comput.\nPaper Link\nInfluential Citation Count (0), SS-ID (322a2670adda4c595a6cae54801981c4fc9e005f)\nABSTRACT\nAs one of the main applications of graph embedding, community detection has always been a hot issue in the field of complex network data mining. This paper presents a complex network graph embedding method based on the shortest path matrix and decomposition multi-objective evolutionary algorithm (SP-MOEA/D) for community detection, which can better reflect the network structure at the level of network community structure. Firstly, by calculating the shortest path matrix between nodes in the network, the node relationship matrix is obtained by adding the node similarity. Next, aiming at the problem of community detection in disconnected networks, a decomposition-based multi-objective optimization method is proposed to assign distances to unrelated nodes. Then, the network similarity matrix is calculated based on the relationship matrix of network nodes, and the low-dimensional vector representation of nodes is obtained by random surfing strategy and multi-dimensional scaling method. Finally, the community structure of the network can be detected based on the obtained node representation structure. Starting from the essence of network structure and the tightness between nodes, this method can reflect the relationship characteristics of network nodes more effectively, and then obtain the vector representation of nodes which can more accurately reflect the information of community structure in networks. The test results on 11 networks show that the node vector representation results obtained by this method can better reflect the community structure information in complex networks.\nmulti-objective matrix factorization over several shortest path graphs and utilizes MOEA Salim, Shiju \u0026amp; Sumitra (2020) Asif Salim, S. Shiju, S. Sumitra. (2020)\nDesign of multi-view graph embedding using multiple kernel learning\nEng. Appl. Artif. Intell.\nPaper Link\nInfluential Citation Count (0), SS-ID (8ce7c67095d76da23897cc379c063986e9843a7c)\nABSTRACT\nThe graph embedding is the process of representing the graph in a vector space using properties of the graphs and this technique has now being widely used for analyzing the graph data using machine learning algorithms. The existing graph embeddings rely mostly on a single property of graphs for data representation which is found to be inappropriate to capture all the characteristics of the data. Hence we designed graph embedding using multi-view approach, where each view is an embedding of the graph using a graph property. The input space of multi-view learning is then taken as the direct sum of the subspaces in which the graph embedding lie. We did analysis on real world data by incorporating the proposed model on support vector machines (SVM). The reproducing kernel used in SVM is represented as the linear combination of the kernels defined on the individual embeddings. The optimization technique used in simple multiple kernel learning (simpleMKL) is used to find the parameters of the optimal kernel. To analyze the individual representation capability of the embeddings, an R-convolution graph kernel is designed over each of the views. In our experimental analysis, the multi-view graph embedding showed a superior performance in comparison with that of the state-of-the-art graph embeddings as well as graph kernels.\ntrain the embeddings on different views for preserving many properties of a given graph Quiring \u0026amp; Vassilevski (2020) Multilevel graph embedding\nNumer. Linear Algebra Appl.\nPaper Link\nInfluential Citation Count (0), SS-ID (412b0cf8d4a39634cb02235a1333ddf3bf792732)\nABSTRACT\nThe goal of the present paper is the design of embeddings of a general sparse graph into a set of points in ℝd for appropriate d ≥ 2. The embeddings that we are looking at aim to keep vertices that are grouped in communities together and keep the rest apart. To achieve this property, we utilize coarsening that respects possible community structures of the given graph. We employ a hierarchical multilevel coarsening approach that identifies communities (strongly connected groups of vertices) at every level. The multilevel strategy allows any given (presumably expensive) graph embedding algorithm to be made into a more scalable (and faster) algorithm. We demonstrate the presented approach on a number of given embedding algorithms and large‐scale graphs and achieve speed‐up over the methods in a recent paper.\nemploy hierarchical coarsening of the graph Subgraph (and graph) embedding Definition 10 (Line (Dual) Graph) For a graph $G=(V,E)$ defined as a set of vertices $V$ and a set of edges $E \\subseteq V \\times V$ without loops and multi-edges we denote by $G^{\\ast} = (V^{\\ast}, E^{\\ast})$ a Dual (Line) Graph the nodes of which are the edges of G and edges are nodes, in the sense that two adjacent nodes are connected by an edge if corresponding edges have a common node incident to them.\nPaper Approach Duvenaud et al. (2015) D. Duvenaud, D. Maclaurin, J. Aguilera-Iparraguirre, R. Gómez-Bombarelli, Timothy D. Hirzel, Alán Aspuru-Guzik, Ryan P. Adams. (2015)\nConvolutional Networks on Graphs for Learning Molecular Fingerprints\nNIPS\nPaper Link\nInfluential Citation Count (147), SS-ID (5d1bfeed240709725c78bc72ea40e55410b373dc)\nABSTRACT\nWe introduce a convolutional neural network that operates directly on graphs. These networks allow end-to-end learning of prediction pipelines whose inputs are graphs of arbitrary size and shape. The architecture we present generalizes standard molecular feature extraction methods based on circular fingerprints. We show that these data-driven features are more interpretable, and have better predictive performance on a variety of tasks.\nsum based approach over network embedding Dai, Dai \u0026amp; Song (2016) H. Dai, Bo Dai, Le Song. (2016)\nDiscriminative Embeddings of Latent Variable Models for Structured Data\nICML\nPaper Link\nInfluential Citation Count (51), SS-ID (322cf9bcde458a45eaeca989a1eec92f7c6db984)\nABSTRACT\nKernel classifiers and regressors designed for structured data, such as sequences, trees and graphs, have significantly advanced a number of interdisciplinary areas such as computational biology and drug design. Typically, kernels are designed beforehand for a data type which either exploit statistics of the structures or make use of probabilistic generative models, and then a discriminative classifier is learned based on the kernels via convex optimization. However, such an elegant two-stage approach also limited kernel methods from scaling up to millions of data points, and exploiting discriminative information to learn feature representations. We propose, structure2vec, an effective and scalable approach for structured data representation based on the idea of embedding latent variable models into feature spaces, and learning such feature spaces using discriminative information. Interestingly, structure2vec extracts features by performing a sequence of function mappings in a way similar to graphical model inference procedures, such as mean field and belief propagation. In applications involving millions of data points, we showed that structure2vec runs 2 times faster, produces models which are 10, 000 times smaller, while at the same time achieving the state-of-the-art predictive performance.\nneural network aggregation for constructing network embedding Bronstein et al. (2017) M. Bronstein, Joan Bruna, Yann LeCun, Arthur D. Szlam, P. Vandergheynst. (2016)\nGeometric Deep Learning: Going beyond Euclidean data\nIEEE Signal Processing Magazine\nPaper Link\nInfluential Citation Count (113), SS-ID (0e779fd59353a7f1f5b559b9d65fa4bfe367890c)\nABSTRACT\nMany scientific fields study data with an underlying structure that is non-Euclidean. Some examples include social networks in computational social sciences, sensor networks in communications, functional networks in brain imaging, regulatory networks in genetics, and meshed surfaces in computer graphics. In many applications, such geometric data are large and complex (in the case of social networks, on the scale of billions) and are natural targets for machine-learning techniques. In particular, we would like to use deep neural networks, which have recently proven to be powerful tools for a broad range of problems from computer vision, natural-language processing, and audio analysis. However, these tools have been most successful on data with an underlying Euclidean or grid-like structure and in cases where the invariances of these structures are built into networks used to model them.\napproximations of spectral graph decompositions Niepert, Ahmed \u0026amp; Kutzkov (2016) Mathias Niepert, Mohamed Ahmed, Konstantin Kutzkov. (2016)\nLearning Convolutional Neural Networks for Graphs\nICML\nPaper Link\nInfluential Citation Count (136), SS-ID (7c6de5a9e02a779e24504619050c6118f4eac181)\nABSTRACT\nNumerous important problems can be framed as learning from graph data. We propose a framework for learning convolutional neural networks for arbitrary graphs. These graphs may be undirected, directed, and with both discrete and continuous node and edge attributes. Analogous to image-based convolutional networks that operate on locally connected regions of the input, we present a general approach to extracting locally connected regions from graphs. Using established benchmark data sets, we demonstrate that the learned feature representations are competitive with state of the art graph kernels and that their computation is highly efficient.\nordered-based approach Kearnes et al. (2016) S. Kearnes, Kevin McCloskey, M. Berndl, V. Pande, Patrick F. Riley. (2016)\nMolecular graph convolutions: moving beyond fingerprints\nJournal of Computer-Aided Molecular Design\nPaper Link\nInfluential Citation Count (41), SS-ID (561c3fa53d36405186da9cab02bd68635c3738aa)\nABSTRACT\nMolecular “fingerprints” encoding structural information are the workhorse of cheminformatics and machine learning in drug discovery applications. However, fingerprint representations necessarily emphasize particular aspects of the molecular structure while ignoring others, rather than allowing the model to make data-driven decisions. We describe molecular graph convolutions, a machine learning architecture for learning from undirected graphs, specifically small molecules. Graph convolutions use a simple encoding of the molecular graph—atoms, bonds, distances, etc.—which allows the model to take greater advantage of information in the graph structure. Although graph convolutions do not outperform all fingerprint-based methods, they (along with other graph-based methods) represent a new paradigm in ligand-based virtual screening with exciting opportunities for future improvement.\nfuzzy-based approach Sun, Hoffmann \u0026amp; Tang (2019) Fan-Yun Sun, Jordan Hoffmann, Jian Tang. (2019)\nInfoGraph: Unsupervised and Semi-supervised Graph-Level Representation Learning via Mutual Information Maximization\nICLR\nPaper Link\nInfluential Citation Count (50), SS-ID (2fb59ebe271d6b007bb0429c1701fd1004782d1b)\nABSTRACT\nThis paper studies learning the representations of whole graphs in both unsupervised and semi-supervised scenarios. Graph-level representations are critical in a variety of real-world applications such as predicting the properties of molecules and community analysis in social networks. Traditional graph kernel based methods are simple, yet effective for obtaining fixed-length representations for graphs but they suffer from poor generalization due to hand-crafted designs. There are also some recent methods based on language models (e.g. graph2vec) but they tend to only consider certain substructures (e.g. subtrees) as graph representatives. Inspired by recent progress of unsupervised representation learning, in this paper we proposed a novel method called InfoGraph for learning graph-level representations. We maximize the mutual information between the graph-level representation and the representations of substructures of different scales (e.g., nodes, edges, triangles). By doing so, the graph-level representations encode aspects of the data that are shared across different scales of substructures. Furthermore, we further propose InfoGraph*, an extension of InfoGraph for semi-supervised scenarios. InfoGraph* maximizes the mutual information between unsupervised graph representations learned by InfoGraph and the representations learned by existing supervised methods. As a result, the supervised encoder learns from unlabeled data while preserving the latent semantic space favored by the current supervised task. Experimental results on the tasks of graph classification and molecular property prediction show that InfoGraph is superior to state-of-the-art baselines and InfoGraph* can achieve performance competitive with state-of-the-art semi-supervised models.\nmaximize the mutual information between embedding and different graph substructures Gilmer et al. (2017) J. Gilmer, S. Schoenholz, Patrick F. Riley, Oriol Vinyals, George E. Dahl. (2017)\nNeural Message Passing for Quantum Chemistry\nICML\nPaper Link\nInfluential Citation Count (440), SS-ID (e24cdf73b3e7e590c2fe5ecac9ae8aa983801367)\nABSTRACT\nSupervised learning on molecules has incredible potential to be useful in chemistry, drug discovery, and materials science. Luckily, several promising and closely related neural network models invariant to molecular symmetries have already been described in the literature. These models learn a message passing algorithm and aggregation procedure to compute a function of their entire input graph. At this point, the next step is to find a particularly effective variant of this general approach and apply it to chemical prediction benchmarks until we either solve them or reach the limits of the approach. In this paper, we reformulate existing models into a single common framework we call Message Passing Neural Networks (MPNNs) and explore additional novel variations within this framework. Using MPNNs we demonstrate state of the art results on an important molecular property prediction benchmark; these results are strong enough that we believe future work should focus on datasets with larger molecules or more accurate ground truth labels.\npooling-aggregation models Scarselli et al. (2009) F. Scarselli, M. Gori, A. Tsoi, M. Hagenbuchner, G. Monfardini. (2009)\nThe Graph Neural Network Model\nIEEE Transactions on Neural Networks\nPaper Link\nInfluential Citation Count (265), SS-ID (3efd851140aa28e95221b55fcc5659eea97b172d)\nABSTRACT\nMany underlying relationships among data in several areas of science and engineering, e.g., computer vision, molecular chemistry, molecular biology, pattern recognition, and data mining, can be represented in terms of graphs. In this paper, we propose a new neural network model, called graph neural network (GNN) model, that extends existing neural network methods for processing the data represented in graph domains. This GNN model, which can directly process most of the practically useful types of graphs, e.g., acyclic, cyclic, directed, and undirected, implements a function tau(G,n) isin IRm that maps a graph G and one of its nodes n into an m-dimensional Euclidean space. A supervised learning algorithm is derived to estimate the parameters of the proposed GNN model. The computational cost of the proposed algorithm is also considered. Some experimental results are shown to validate the proposed learning algorithm, and to demonstrate its generalization capabilities.\nadd super-node for whole graph embedding Lee, Rossi \u0026amp; Kong (2018) J. B. Lee, Ryan A. Rossi, Xiangnan Kong. (2018)\nGraph Classification using Structural Attention\nKDD\nPaper Link\nInfluential Citation Count (10), SS-ID (59d502851cd20f28af03eef1d15dc83d3a7bb300)\nABSTRACT\nGraph classification is a problem with practical applications in many different domains. To solve this problem, one usually calculates certain graph statistics (i.e., graph features) that help discriminate between graphs of different classes. When calculating such features, most existing approaches process the entire graph. In a graphlet-based approach, for instance, the entire graph is processed to get the total count of different graphlets or subgraphs. In many real-world applications, however, graphs can be noisy with discriminative patterns confined to certain regions in the graph only. In this work, we study the problem of attention-based graph classification. The use of attention allows us to focus on small but informative parts of the graph, avoiding noise in the rest of the graph. We present a novel RNN model, called the Graph Attention Model (GAM), that processes only a portion of the graph by adaptively selecting a sequence of \u0026ldquo;informative\u0026rdquo; nodes. Experimental results on multiple real-world datasets show that the proposed method is competitive against various well-known methods in graph classification even though our method is limited to only a portion of the graph.\napply attention mechanism to the graph classification task Shervashidze et al. (2011) N. Shervashidze, Pascal Schweitzer, E. J. V. Leeuwen, K. Mehlhorn, K. Borgwardt. (2011)\nWeisfeiler-Lehman Graph Kernels\nJ. Mach. Learn. Res.\nPaper Link\nInfluential Citation Count (183), SS-ID (7e1874986cf6433fabf96fff93ef42b60bdc49f8)\nABSTRACT\nIn this article, we propose a family of efficient kernels for large graphs with discrete node labels. Key to our method is a rapid feature extraction scheme based on the Weisfeiler-Lehman test of isomorphism on graphs. It maps the original graph to a sequence of graphs, whose node attributes capture topological and label information. A family of kernels can be defined based on this Weisfeiler-Lehman sequence of graphs, including a highly efficient kernel comparing subtree-like patterns. Its runtime scales only linearly in the number of edges of the graphs and the length of the Weisfeiler-Lehman graph sequence. In our experimental evaluation, our kernels outperform state-of-the-art graph kernels on several graph classification benchmark data sets in terms of accuracy and runtime. Our kernels open the door to large-scale applications of graph kernels in various disciplines such as computational biology and social network analysis.\nreconstruct sophisticated similarity metrics into vectors Niepert, Ahmed \u0026amp; Kutzkov (2016) Learning Convolutional Neural Networks for Graphs\nICML\nPaper Link\nInfluential Citation Count (136), SS-ID (7c6de5a9e02a779e24504619050c6118f4eac181)\nABSTRACT\nNumerous important problems can be framed as learning from graph data. We propose a framework for learning convolutional neural networks for arbitrary graphs. These graphs may be undirected, directed, and with both discrete and continuous node and edge attributes. Analogous to image-based convolutional networks that operate on locally connected regions of the input, we present a general approach to extracting locally connected regions from graphs. Using established benchmark data sets, we demonstrate that the learned feature representations are competitive with state of the art graph kernels and that their computation is highly efficient.\nreconstruct sophisticated similarity metrics into vectors Mousavi et al. (2017) S. F. Mousavi, M. Safayani, A. Mirzaei, Hoda Bahonar. (2017)\nHierarchical graph embedding in vector space by graph pyramid\nPattern Recognit.\nPaper Link\nInfluential Citation Count (5), SS-ID (c9f22dde51fb01322212708ef00a61ef580e58bd)\nABSTRACT\nLoss of information is the major challenge in graph embedding in vector space which reduces the impact of representational power of graphs in pattern recognition tasks. The objective of this article is to present a hierarchical framework which can decrease this loss in a reasonable computational time. Inspired by multi-resolution ideas in image processing, a graph pyramid is formed based on a selected graph summarization algorithm which can provide the required information for classification. All the pyramid levels or some of them are embedded into a vector through an available embedding method which constructs an informative description containing both local and global features. The experiments are conducted on graphs with numerical and categorical attributes. In the numerical case, a proposed summarization algorithm is applied while in the categorical case, k-SNAP graph summarization is applied. The results indicate that this new framework is efficient in terms of accuracy and time consumption in the context of classification problems. It is observed that this improvement is achieved regardless of selected embedding techniques.\nreconstruct sophisticated similarity metrics into vectors Yanardag \u0026amp; Vishwanathan (2015) Pinar Yanardag, S. Vishwanathan. (2015)\nDeep Graph Kernels\nKDD\nPaper Link\nInfluential Citation Count (160), SS-ID (00d736c540f80582279093cfc5ffe454a3226da9)\nABSTRACT\nIn this paper, we present Deep Graph Kernels, a unified framework to learn latent representations of sub-structures for graphs, inspired by latest advancements in language modeling and deep learning. Our framework leverages the dependency information between sub-structures by learning their latent representations. We demonstrate instances of our framework on three popular graph kernels, namely Graphlet kernels, Weisfeiler-Lehman subtree kernels, and Shortest-Path graph kernels. Our experiments on several benchmark datasets show that Deep Graph Kernels achieve significant improvements in classification accuracy over state-of-the-art graph kernels.\nreconstruct sophisticated similarity metrics into vectors Narayanan et al. (2016) A. Narayanan, Mahinthan Chandramohan, Lihui Chen, Yang Liu, S. Saminathan. (2016)\nsubgraph2vec: Learning Distributed Representations of Rooted Sub-graphs from Large Graphs\nArXiv\nPaper Link\nInfluential Citation Count (11), SS-ID (e02f59cf876cb40233573ff78a1609f969d301cc)\nABSTRACT\nIn this paper, we present subgraph2vec, a novel approach for learning latent representations of rooted subgraphs from large graphs inspired by recent advancements in Deep Learning and Graph Kernels. These latent representations encode semantic substructure dependencies in a continuous vector space, which is easily exploited by statistical models for tasks such as graph classification, clustering, link prediction and community detection. subgraph2vec leverages on local information obtained from neighbourhoods of nodes to learn their latent representations in an unsupervised fashion. We demonstrate that subgraph vectors learnt by our approach could be used in conjunction with classifiers such as CNNs, SVMs and relational data clustering algorithms to achieve significantly superior accuracies. Also, we show that the subgraph vectors could be used for building a deep learning variant of Weisfeiler-Lehman graph kernel. Our experiments on several benchmark and large-scale real-world datasets reveal that subgraph2vec achieves significant improvements in accuracies over existing graph kernels on both supervised and unsupervised learning tasks. Specifically, on two realworld program analysis tasks, namely, code clone and malware detection, subgraph2vec outperforms state-of-the-art kernels by more than 17% and 4%, respectively.\nreconstruct sophisticated similarity metrics into vectors Chen \u0026amp; Koga (2019) Hong Chen, H. Koga. (2019)\nGL2vec: Graph Embedding Enriched by Line Graphs with Edge Features\nICONIP\nPaper Link\nInfluential Citation Count (5), SS-ID (a7df35d17d05d69e7085d1cfa288a235a8a86be1)\nABSTRACT\nRecently, several techniques to learn the embedding for a given graph dataset have been proposed. Among them, Graph2vec is significant in that it unsupervisedly learns the embedding of entire graphs which is useful for graph classification. This paper develops an algorithm which improves Graph2vec. First, we point out two limitations of Graph2vec: (1) Edge labels cannot be handled and (2) Graph2vec does not always preserve structural information enough to evaluate the structural similarity, because it bundles the node label information and the structural information in extracting subgraphs. Our algorithm overcomes these limitations by exploiting the line graphs (edge-to-vertex dual graphs) of given graphs. Specifically, it complements either the edge label information or the structural information which Graph2vec misses with the embeddings of the line graphs. Our method is named as GL2vec (Graph and Line graph to vector) because it concatenates the embedding of an original graph to that of the corresponding line graph. Experimentally, GL2vec achieves significant improvements in graph classification task over Graph2vec for many benchmark datasets.\nGL2VEC; extends Narayanan et al. (2016) model with edge features by utilizing the line graph Johansson \u0026amp; Dubhashi (2015) Fredrik D. Johansson, Devdatt P. Dubhashi. (2015)\nLearning with Similarity Functions on Graphs using Matchings of Geometric Embeddings\nKDD\nPaper Link\nInfluential Citation Count (1), SS-ID (e8f16ec1024a6cffbb4e0d57529e9432207d4a5c)\nABSTRACT\nWe develop and apply the Balcan-Blum-Srebro (BBS) theory of classification via similarity functions (which are not necessarily kernels) to the problem of graph classification. First we place the BBS theory into the unifying framework of optimal transport theory. This also opens the way to exploit coupling methods for establishing properties required of a good similarity function as per their definition. Next, we use the approach to the problem of graph classification via geometric embeddings such as the Laplacian, pseudo-inverse Laplacian and the Lovász orthogonal labellings. We consider the similarity function given by optimal and near\u0026ndash;optimal matchings with respect to Euclidean distance of the corresponding embeddings of the graphs in high dimensions. We use optimal couplings to rigorously establish that this yields a \u0026ldquo;good\u0026rdquo; similarity measure in the BBS sense for two well known families of graphs. Further, we show that the similarity yields better classification accuracy in practice, on these families, than matchings of other well-known graph embeddings. Finally we perform an extensive empirical evaluation on benchmark data sets where we show that classifying graphs using matchings of geometric embeddings outperforms the previous state-of-the-art methods.\nmatching node embedding / graph kernels Nikolentzos, Meladianos \u0026amp; Vazirgiannis (2017) Giannis Nikolentzos, Polykarpos Meladianos, M. Vazirgiannis. (2017)\nMatching Node Embeddings for Graph Similarity\nAAAI\nPaper Link\nInfluential Citation Count (8), SS-ID (0f3d2a17809f999cd4ab9d97fd5eb71086580685)\nABSTRACT\nGraph kernels have emerged as a powerful tool for graph comparison. Most existing graph kernels focus on local properties of graphs and ignore global structure. In this paper, we compare graphs based on their global properties as these are captured by the eigenvectors of their adjacency matrices. We present two algorithms for both labeled and unlabeled graph comparison. These algorithms represent each graph as a set of vectors corresponding to the embeddings of its vertices. The similarity between two graphs is then determined using the Earth Mover’s Distance metric. These similarities do not yield a positive semidefinite matrix. To address for this, we employ an algorithm for SVM classification using indefinite kernels. We also present a graph kernel based on the Pyramid Match kernel that finds an approximate correspondence between the sets of vectors of the two graphs. We further improve the proposed kernel using the Weisfeiler-Lehman framework. We evaluate the proposed methods on several benchmark datasets for graph classification and compare their performance to state-of-the-art graph kernels. In most cases, the proposed algorithms outperform the competing methods, while their time complexity remains very attractive.\nmatching node embedding / graph kernels Donnat \u0026amp; Holmes (2018) C. Donnat, S. Holmes. (2018)\nTracking network dynamics: A survey using graph distances\nThe Annals of Applied Statistics\nPaper Link\nInfluential Citation Count (2), SS-ID (64aa05ee62ed2c55e002acdcdeadd29daefe9426)\nABSTRACT\nFrom longitudinal biomedical studies to social networks, graphs have emerged as essential objects for describing evolving interactions between agents in complex systems. In such studies, after pre-processing, the data are encoded by a set of graphs, each representing a system’s state at a different point in time or space. The analysis of the system’s dynamics depends on the selection of the appropriate analytical tools. In particular, after specifying properties characterizing similarities between states, a critical step lies in the choice of a distance between graphs capable of reflecting such similarities. While the literature offers a number of distances to choose from, their properties have been little investigated and no guidelines regarding the choice of such a distance have yet been provided. In particular, most graph distances consider that the nodes are exchangeable—ignoring node “identities.” Alignment of the graphs according to identified nodes enables us to enhance these distances’ sensitivity to perturbations in the network and detect important changes in graph dynamics. Thus the selection of an adequate metric is a decisive—yet delicate—practical matter. In the spirit of Goldenberg et al.’s seminal 2009 review [Found. Trends Mach. Learn. 2 (2010) 129–233], this article provides an overview of commonly-used graph distances and an explicit characterization of the structural changes that they are best able to capture. We show how these choices affect real-life situations, and we use these distances to analyze both a longitudinal microbiome dataset and a brain fMRI study. One contribution of the present study is a coordinated suite of data analytic techniques, displays and statistical tests using “metagraphs”: a graph of graphs based on a chosen metric. Permutation tests can uncover the effects of covariates on the graphs’ variability. Furthermore, synthetic examples provide intuition as to the qualities and drawbacks of the different distances. Above all, we provide some guidance on choosing one distance over another in different contexts. Finally, we extend the scope of our analyses from temporal to spatial dynamics and apply these different distances to a network created from worldwide recipes.\ngraph-based distance methods for a temporal graph of bio-medical surveys Yang \u0026amp; Wang (2018) Yan Yang, Hao Wang. (2018)\nMulti-view clustering: A survey\nBig Data Min. Anal.\nPaper Link\nInfluential Citation Count (3), SS-ID (9404cc4488ae98babf17b286a20e7baa6ef5d398)\nABSTRACT\nIn the big data era, the data are generated from different sources or observed from different views. These data are referred to as multi-view data. Unleashing the power of knowledge in multi-view data is very important in big data mining and analysis. This calls for advanced techniques that consider the diversity of different views, while fusing these data. Multi-view Clustering (MvC) has attracted increasing attention in recent years by aiming to exploit complementary and consensus information across multiple views. This paper summarizes a large number of multi-view clustering algorithms, provides a taxonomy according to the mechanisms and principles involved, and classifies these algorithms into five categories, namely, co-training style algorithms, multi-kernel learning, multiview graph clustering, multi-view subspace clustering, and multi-task multi-view clustering. Therein, multi-view graph clustering is further categorized as graph-based, network-based, and spectral-based methods. Multi-view subspace clustering is further divided into subspace learning-based, and non-negative matrix factorization-based methods. This paper does not only introduce the mechanisms for each category of methods, but also gives a few examples for how these techniques are used. In addition, it lists some publically available multi-view datasets. Overall, this paper serves as an introductory text and survey for multi-view clustering.\nhierarchical clustering and fusion of different network representations Serra, Greco \u0026amp; Tagliaferri (2015) Angela Serra, D. Greco, R. Tagliaferri. (2015)\nImpact of different metrics on multi-view clustering\n2015 International Joint Conference on Neural Networks (IJCNN)\nPaper Link\nInfluential Citation Count (0), SS-ID (294b25ce7576ab5cc59ab0de1d36425cae7fab2a)\nABSTRACT\nClustering of patients allows to find groups of subjects with similar characteristics. This categorization can facilitate diagnosis, treatment decision and prognosis prediction. Heterogeneous genome-wide data sources capture different biological aspects that can be integrated in order to better categorize the patients. Clustering methods work by comparing how patients are similar or dissimilar in a suitable similarity space. While several clustering methods have been proposed, there is no systematic comparative study concerning the impact of similarity metrics on the cluster quality. We compared seven popular similarity measures (Pearson, Spearman and Kendall Correlations; Euclidean, Canberra, Minkowski and Manhattan Distances) in conjunction with two classical single-view clustering algorithms and a late integration approach (partitioning around medoids, hierarchical clustering and matrix factorization approaches), on high dimensional multi-view cancer data coming from the TCGA repository. Performance was measured against tumour subcategories classification. Only Euclidean and Minkowski distances showed similar results in terms of clustering similarity indexes. On the other hand, an absolute best similarity measure did not emerge in terms of misclassification, but it strongly depends on the data.\nfusion of different similarity representations of a network as different graphs Xue et al. (2015) Zhe Xue, Guorong Li, Shuhui Wang, Chunjie Zhang, W. Zhang, Qingming Huang. (2015)\nGOMES: A group-aware multi-view fusion approach towards real-world image clustering\n2015 IEEE International Conference on Multimedia and Expo (ICME)\nPaper Link\nInfluential Citation Count (1), SS-ID (394ba1a52e3cd59974f4277ef1ae987bc3500870)\nABSTRACT\nDifferent features describe different views of visual appearance, multi-view based methods can integrate the information contained in each view and improve the image clustering performance. Most of the existing methods assume that the importance of one type of feature is the same to all the data. However, the visual appearance of images are different, so the description abilities of different features vary with different images. To solve this problem, we propose a group-aware multi-view fusion approach. Images are partitioned into groups which consist of several images sharing similar visual appearance. We assign different weights to evaluate the pairwise similarity between different groups. Then the clustering results and the fusion weights are learned by an iterative optimization procedure. Experimental results indicate that our approach achieves promising clustering performance compared with the existing methods.\nfusion of different similarity representations of a network as different graph Hou et al. (2017) Chenping Hou, F. Nie, Hong Tao, Dong-yun Yi. (2017)\nMulti-View Unsupervised Feature Selection with Adaptive Similarity and View Weight\nIEEE Transactions on Knowledge and Data Engineering\nPaper Link\nInfluential Citation Count (5), SS-ID (2ea8d4cfb92d6354caa76a7070a3a5e053e1b066)\nABSTRACT\nWith the advent of multi-view data, multi-view learning has become an important research direction in both machine learning and data mining. Considering the difficulty of obtaining labeled data in many real applications, we focus on the multi-view unsupervised feature selection problem. Traditional approaches all characterize the similarity by fixed and pre-defined graph Laplacian in each view separately and ignore the underlying common structures across different views. In this paper, we propose an algorithm named Multi-view Unsupervised Feature Selection with Adaptive Similarity and View Weight (ASVW) to overcome the above mentioned problems. Specifically, by leveraging the learning mechanism to characterize the common structures adaptively, we formulate the objective function by a common graph Laplacian across different views, together with the sparse $\\ell _{2,p}$ -norm constraint designed for feature selection. We develop an efficient algorithm to address the non-smooth minimization problem and prove that the algorithm will converge. To validate the effectiveness of ASVW, comparisons are made with some benchmark methods on real-world datasets. We also evaluate our method in the real sports action recognition task. The experimental results demonstrate the effectiveness of our proposed algorithm.\nfusion of different similarity representations of a network as different graph preserving graph structure Nie, Cai \u0026amp; Li (2017) F. Nie, Guohao Cai, Xuelong Li. (2017)\nMulti-View Clustering and Semi-Supervised Classification with Adaptive Neighbours\nAAAI\nPaper Link\nInfluential Citation Count (34), SS-ID (62b5d514ec49173af59cab6f0dfdc7f280d53f36)\nABSTRACT\nDue to the efficiency of learning relationships and complex structures hidden in data, graph-oriented methods have been widely investigated and achieve promising performance in multi-view learning. Generally, these learning algorithms construct informative graph for each view or fuse different views to one graph, on which the following procedure are based. However, in many real world dataset, original data always contain noise and outlying entries that result in unreliable and inaccurate graphs, which cannot be ameliorated in the previous methods. In this paper, we propose a novel multi-view learning model which performs clustering/semi-supervised classification and local structure learning simultaneously. The obtained optimal graph can be partitioned into specific clusters directly. Moreover, our model can allocate ideal weight for each view automatically without additional weight and penalty parameters. An efficient algorithm is proposed to optimize this model. Extensive experimental results on different real-world datasets show that the proposed model outperforms other state-of-the-art multi-view algorithms.\nfusion of different similarity representations of a network as different graph simultaneously performing semi-supervised classification Cheng et al. (2013) Wei Cheng, X. Zhang, Zhishan Guo, Yubao Wu, P. Sullivan, Wei Wang. (2013)\nFlexible and robust co-regularized multi-domain graph clustering\nKDD\nPaper Link\nInfluential Citation Count (8), SS-ID (75938c4300e464f901a15332540d6500d957db91)\nABSTRACT\nMulti-view graph clustering aims to enhance clustering performance by integrating heterogeneous information collected in different domains. Each domain provides a different view of the data instances. Leveraging cross-domain information has been demonstrated an effective way to achieve better clustering results. Despite the previous success, existing multi-view graph clustering methods usually assume that different views are available for the same set of instances. Thus instances in different domains can be treated as having strict one-to-one relationship. In many real-life applications, however, data instances in one domain may correspond to multiple instances in another domain. Moreover, relationships between instances in different domains may be associated with weights based on prior (partial) knowledge. In this paper, we propose a flexible and robust framework, CGC (Co-regularized Graph Clustering), based on non-negative matrix factorization (NMF), to tackle these challenges. CGC has several advantages over the existing methods. First, it supports many-to-many cross-domain instance relationship. Second, it incorporates weight on cross-domain relationship. Third, it allows partial cross-domain mapping so that graphs in different domains may have different sizes. Finally, it provides users with the extent to which the cross-domain instance relationship violates the in-domain clustering structure, and thus enables users to re-evaluate the consistency of the relationship. Extensive experimental results on UCI benchmark data sets, newsgroup data sets and biological interaction networks demonstrate the effectiveness of our approach.\ndifferent domain network clustering Ni et al. (2016) Jingchao Ni, Wei Cheng, Wei Fan, X. Zhang. (2016)\nSelf-Grouping Multi-network Clustering\n2016 IEEE 16th International Conference on Data Mining (ICDM)\nPaper Link\nInfluential Citation Count (0), SS-ID (fabfba8835470ba7a33dfc25e50ef83a5be7eae0)\nABSTRACT\nJoint clustering of multiple networks has been shown to be more accurate than performing clustering on individual networks separately. Many multi-view and multi-domain network clustering methods have been developed for joint multi-network clustering. These methods typically assume there is a common clustering structure shared by all networks, and different networks can provide complementary information on this underlying clustering structure. However, this assumption is too strict to hold in many emerging real-life applications, where multiple networks have diverse data distributions. More popularly, the networks in consideration belong to different underlying groups. Only networks in the same underlying group share similar clustering structures. Better clustering performance can be achieved by considering such groups differently. As a result, an ideal method should be able to automatically detect network groups so that networks in the same group share a common clustering structure. To address this problem, we propose a novel method, ComClus, to simultaneously group and cluster multiple networks. ComClus treats node clusters as features of networks and uses them to differentiate different network groups. Network grouping and clustering are coupled and mutually enhanced during the learning process. Extensive experimental evaluation on a variety of synthetic and real datasets demonstrates the effectiveness of our method.\nfusion of different not-synchronized networks with different structures Liu et al. (2015) R. Liu, Wei Cheng, Hanghang Tong, Wei Wang, X. Zhang. (2015)\nRobust Multi-Network Clustering via Joint Cross-Domain Cluster Alignment\n2015 IEEE International Conference on Data Mining\nPaper Link\nInfluential Citation Count (1), SS-ID (7dd2ad1f992808d04356e8d6e7e5614166f34a85)\nABSTRACT\nNetwork clustering is an important problem thathas recently drawn a lot of attentions. Most existing workfocuses on clustering nodes within a single network. In manyapplications, however, there exist multiple related networks, inwhich each network may be constructed from a different domainand instances in one domain may be related to instances in otherdomains. In this paper, we propose a robust algorithm, MCA, formulti-network clustering that takes into account cross-domain relationshipsbetween instances. MCA has several advantages overthe existing single network clustering methods. First, it is ableto detect associations between clusters from different domains, which, however, is not addressed by any existing methods. Second, it achieves more consistent clustering results on multiple networksby leveraging the duality between clustering individual networksand inferring cross-network cluster alignment. Finally, it providesa multi-network clustering solution that is more robust to noiseand errors. We perform extensive experiments on a variety ofreal and synthetic networks to demonstrate the effectiveness andefficiency of MCA.\ncross-domain associations Li et al. (2015) Yeqing Li, F. Nie, Heng Huang, Junzhou Huang. (2015)\nLarge-Scale Multi-View Spectral Clustering via Bipartite Graph\nAAAI\nPaper Link\nInfluential Citation Count (33), SS-ID (9383f08c697b8aa43782e16c9a57e089911584d8)\nABSTRACT\nIn this paper, we address the problem of large-scale multi-view spectral clustering. In many real-world applications, data can be represented in various heterogeneous features or views. Different views often provide different aspects of information that are complementary to each other. Several previous methods of clustering have demonstrated that better accuracy can be achieved using integrated information of all the views than just using each view individually. One important class of such methods is multi-view spectral clustering, which is based on graph Laplacian. However, existing methods are not applicable to large-scale problem for their high computational complexity. To this end, we propose a novel large-scale multi-view spectral clustering approach based on the bipartite graph. Our method uses local manifold fusion to integrate heterogeneous features. To improve efficiency, we approximate the similarity graphs using bipartite graphs. Furthermore, we show that our method can be easily extended to handle the out-of-sample problem. Extensive experimental results on five benchmark datasets demonstrate the effectiveness and efficiency of the proposed method, where our method runs up to nearly 3000 times faster than the state-of-the-art methods.\nmulti-view spectral clustering Khasahmadi et al. (2020) Amir Hosein Khas Ahmadi, Kaveh Hassani, Parsa Moradi, Leo Lee, Q. Morris. (2020)\nMemory-Based Graph Networks\nICLR\nPaper Link\nInfluential Citation Count (6), SS-ID (47f01fd4f0c9c77058a966d3f17dbc09cf7ef42a)\nABSTRACT\nGraph Neural Networks (GNNs) are a class of deep models that operates on data with arbitrary topology and order-invariant structure represented as graphs. We introduce an efficient memory layer for GNNs that can learn to jointly perform graph representation learning and graph pooling. We also introduce two new networks based on our memory layer: Memory-Based Graph Neural Network (MemGNN) and Graph Memory Network (GMN) that can learn hierarchical graph representations by coarsening the graph throughout the layers of memory. The experimental results demonstrate that the proposed models achieve state-of-the-art results in six out of seven graph classification and regression benchmarks. We also show that the learned representations could correspond to chemical features in the molecule data.\nmemory layer for graphs that can efficiently learn graph hierarchical representations Tsitsulin, Munkhoeva \u0026amp; Perozzi (2020) Anton Tsitsulin, Marina Munkhoeva, Bryan Perozzi. (2020)\nJust SLaQ When You Approximate: Accurate Spectral Distances for Web-Scale Graphs\nWWW\nPaper Link\nInfluential Citation Count (3), SS-ID (6bcea47afc6fcdada957e8d72b9b27b7866bf535)\nABSTRACT\nGraph comparison is a fundamental operation in data mining and information retrieval. Due to the combinatorial nature of graphs, it is hard to balance the expressiveness of the similarity measure and its scalability. Spectral analysis provides quintessential tools for studying the multi-scale structure of graphs and is a well-suited foundation for reasoning about differences between graphs. However, computing full spectrum of large graphs is computationally prohibitive; thus, spectral graph comparison methods often rely on rough approximation techniques with weak error guarantees. In this work, we propose SLaQ , an efficient and effective approximation technique for computing spectral distances between graphs with billions of nodes and edges. We derive the corresponding error bounds and demonstrate that accurate computation is possible in time linear in the number of graph edges. In a thorough experimental evaluation, we show that SLaQ outperforms existing methods, oftentimes by several orders of magnitude in approximation accuracy, and maintains comparable performance, allowing to compare million-scale graphs in a matter of minutes on a single machine.\naltorithm for efficient calculation of spectral distances for large graphs Kolouri et al. (2020) S. Kolouri, Navid Naderializadeh, G. Rohde, Heiko Hoffmann. (2020)\nWasserstein Embedding for Graph Learning\nICLR\nPaper Link\nInfluential Citation Count (1), SS-ID (463f490d3bded6e527b0838da8495ed6441da25a)\nABSTRACT\nWe present Wasserstein Embedding for Graph Learning (WEGL), a novel and fast framework for embedding entire graphs in a vector space, in which various machine learning models are applicable for graph-level prediction tasks. We leverage new insights on defining similarity between graphs as a function of the similarity between their node embedding distributions. Specifically, we use the Wasserstein distance to measure the dissimilarity between node embeddings of different graphs. Different from prior work, we avoid pairwise calculation of distances between graphs and reduce the computational complexity from quadratic to linear in the number of graphs. WEGL calculates Monge maps from a reference distribution to each node embedding and, based on these maps, creates a fixed-sized vector representation of the graph. We evaluate our new graph embedding approach on various benchmark graph-property prediction tasks, showing state-of-the-art classification performance, while having superior computational efficiency.\nembedding preserving Wasserstein distance with linear complexity Qin et al. (2020) Jian Qin, Li Liu, Hui Shen, D. Hu. (2020)\nUniform Pooling for Graph Networks\nPaper Link\nInfluential Citation Count (0), SS-ID (d83c64f96d9a904280534bc3e0c5bd702aab5d94)\nABSTRACT\nThe graph convolution network has received a lot of attention because it extends the convolution to non-Euclidean domains. However, the graph pooling method is still less concerned, which can learn coarse graph embedding to facilitate graph classification. Previous pooling methods were based on assigning a score to each node and then pooling only the highest-scoring nodes, which might throw away whole neighbourhoods of nodes and therefore information. Here, we proposed a novel pooling method UGPool with a new point-of-view on selecting nodes. UGPool learns node scores based on node features and uniformly pools neighboring nodes instead of top nodes in the score-space, resulting in a uniformly coarsened graph. In multiple graph classification tasks, including the protein graphs, the biological graphs and the brain connectivity graphs, we demonstrated that UGPool outperforms other graph pooling methods while maintaining high efficiency. Moreover, we also show that UGPool can be integrated with multiple graph convolution networks to effectively improve performance compared to no pooling.\none more graph pooling technique that uniformly aggregates neighborhood Baldini, Martino \u0026amp; Rizzi (2020) L. Baldini, A. Martino, A. Rizzi. (2020)\nExploiting Cliques for Granular Computing-based Graph Classification\n2020 International Joint Conference on Neural Networks (IJCNN)\nPaper Link\nInfluential Citation Count (0), SS-ID (414c510f5b932d86e68b81044a8a18a46a46e007)\nABSTRACT\nThe most fascinating aspect of graphs is their ability to encode the information contained in the inner structural organization between its constituting elements. Learning from graphs belong to the so-called Structural Pattern Recognition, from which Graph Embedding emerged as a successful method for processing graphs by evaluating their dissimilarity in a suitable geometric space. In this paper, we investigate the possibility to perform the embedding into a geometric space by leveraging to peculiar constituent graph substructures extracted from training set, namely the maximal cliques, and providing the performances obtained under three main aspects concerning classification capabilities, running times and model complexity. Thanks to a Granular Computing approach, the employed methodology can be seen as a powerful framework able to synthesize models suitable to be interpreted by field-experts, pushing the boundary towards new frontiers in the field of explainable AI and knowledge discovery also in big data contexts.\nembed maximal cliques to preserve structural similarities between graphs Yan \u0026amp; Wang (2020) Bencheng Yan, Chaokun Wang. (2020)\nGraphAE: Adaptive Embedding across Graphs\n2020 IEEE 36th International Conference on Data Engineering (ICDE)\nPaper Link\nInfluential Citation Count (0), SS-ID (7ddb8bdbab7f5aa644569c71d09d0a669af3615e)\nABSTRACT\nRecently, learning embedding of nodes in graphs has attracted increasing research attention. There are two main kinds of graph embedding methods, i.e., the transductive embedding methods and the inductive embedding methods. The former focuses on directly optimizing the embedding vectors, and the latter tries to learn a mapping function for the given nodes and features. However, few works focus on applying the learned model from one graph to another, which is a pervasive idea in Computer Version or Natural Language Processing. Although some of the graph neural networks (GNNs) present similar motivation, none of them considers the graph bias among graphs. In this paper, we present an interesting graph embedding problem called Adaptive Task (AT), and propose a unified framework for this adaptive task, which introduces two types of alignment to learn adaptive node embedding across graphs. Then, based on the proposed framework, a novel graph adaptive embedding network is designed to address the adaptive task. Extensive experimental results demonstrate that our model significantly outperforms the state-of-the-art methods.\nstates the problem of transfer learning suggesting the framework for graph alignment and further adaptation learning for GNNs Network visualization Paper Approach Le \u0026amp; Lauw (2014) Tuan M. V. Le, Hady W. Lauw. (2014)\nProbabilistic Latent Document Network Embedding\n2014 IEEE International Conference on Data Mining\nPaper Link\nInfluential Citation Count (8), SS-ID (24f7d72e92cadfa5c84949537639ce084b9d2092)\nABSTRACT\nA document network refers to a data type that can be represented as a graph of vertices, where each vertex is associated with a text document. Examples of such a data type include hyperlinked Web pages, academic publications with citations, and user profiles in social networks. Such data have very high-dimensional representations, in terms of text as well as network connectivity. In this paper, we study the problem of embedding, or finding a low-dimensional representation of a document network that \u0026ldquo;preserves\u0026rdquo; the data as much as possible. These embedded representations are useful for various applications driven by dimensionality reduction, such as visualization or feature selection. While previous works in embedding have mostly focused on either the textual aspect or the network aspect, we advocate a holistic approach by finding a unified low-rank representation for both aspects. Moreover, to lend semantic interpretability to the low-rank representation, we further propose to integrate topic modeling and embedding within a joint model. The gist is to join the various representations of a document (words, links, topics, and coordinates) within a generative model, and to estimate the hidden representations through MAP estimation. We validate our model on real-life document networks, showing that it outperforms comparable baselines comprehensively on objective evaluation metrics.\n2D vectors Wang, Cui \u0026amp; Zhu (2016) Daixin Wang, Peng Cui, Wenwu Zhu. (2016)\nStructural Deep Network Embedding\nKDD\nPaper Link\nInfluential Citation Count (223), SS-ID (d0b7c8828f0fca4dd901674e8fb5bd464a187664)\nABSTRACT\nNetwork embedding is an important method to learn low-dimensional representations of vertexes in networks, aiming to capture and preserve the network structure. Almost all the existing network embedding methods adopt shallow models. However, since the underlying network structure is complex, shallow models cannot capture the highly non-linear network structure, resulting in sub-optimal network representations. Therefore, how to find a method that is able to effectively capture the highly non-linear network structure and preserve the global and local structure is an open yet important problem. To solve this problem, in this paper we propose a Structural Deep Network Embedding method, namely SDNE. More specifically, we first propose a semi-supervised deep model, which has multiple layers of non-linear functions, thereby being able to capture the highly non-linear network structure. Then we propose to exploit the first-order and second-order proximity jointly to preserve the network structure. The second-order proximity is used by the unsupervised component to capture the global network structure. While the first-order proximity is used as the supervised information in the supervised component to preserve the local network structure. By jointly optimizing them in the semi-supervised deep model, our method can preserve both the local and global network structure and is robust to sparse networks. Empirically, we conduct the experiments on five real-world networks, including a language network, a citation network and three social networks. The results show that compared to the baselines, our method can reconstruct the original network significantly better and achieves substantial gains in three applications, i.e. multi-label classification, link prediction and visualization.\n2D vectors Cao, Lu \u0026amp; Xu (2016) Shaosheng Cao, Wei Lu, Qiongkai Xu. (2016)\nDeep Neural Networks for Learning Graph Representations\nAAAI\nPaper Link\nInfluential Citation Count (59), SS-ID (1a37f07606d60df365d74752857e8ce909f700b3)\nABSTRACT\nIn this paper, we propose a novel model for learning graph representations, which generates a low-dimensional vector representation for each vertex by capturing the graph structural information. Different from other previous research efforts, we adopt a random surfing model to capture graph structural information directly, instead of using the sampling-based method for generating linear sequences proposed by Perozzi et al. (2014). The advantages of our approach will be illustrated from both theorical and empirical perspectives. We also give a new perspective for the matrix factorization method proposed by Levy and Goldberg (2014), in which the pointwise mutual information (PMI) matrix is considered as an analytical solution to the objective function of the skip-gram model with negative sampling proposed by Mikolov et al. (2013). Unlike their approach which involves the use of the SVD for finding the low-dimensitonal projections from the PMI matrix, however, the stacked denoising autoencoder is introduced in our model to extract complex features and model non-linearities. To demonstrate the effectiveness of our model, we conduct experiments on clustering and visualization tasks, employing the learned vertex representations as features. Empirical results on datasets of varying sizes show that our model outperforms other stat-of-the-art models in such tasks.\n2D vectors Tu et al. (2016) Cunchao Tu, Weicheng Zhang, Zhiyuan Liu, Maosong Sun. (2016)\nMax-Margin DeepWalk: Discriminative Learning of Network Representation\nIJCAI\nPaper Link\nInfluential Citation Count (29), SS-ID (5d66991e1f541a08e81e59060cb0bb7f6931c2d9)\nABSTRACT\nDeepWalk is a typical representation learning method that learns low-dimensional representations for vertices in social networks. Similar to other network representation learning (NRL) models, it encodes the network structure into vertex representations and is learnt in unsupervised form. However, the learnt representations usually lack the ability of discrimination when applied to machine learning tasks, such as vertex classification. In this paper, we overcome this challenge by proposing a novel semi-supervised model, max-margin Deep-Walk (MMDW). MMDW is a unified NRL framework that jointly optimizes the max-margin classifier and the aimed social representation learning model. Influenced by the max-margin classifier, the learnt representations not only contain the network structure, but also have the characteristic of discrimination. The visualizations of learnt representations indicate that our model is more discriminative than unsupervised ones, and the experimental results on vertex classification demonstrate that our method achieves a significant improvement than other state-of-the-art methods. The source code can be obtained from https://github.com/thunlp/MMDW.\n2D vectors Niepert, Ahmed \u0026amp; Kutzkov (2016) Mathias Niepert, Mohamed Ahmed, Konstantin Kutzkov. (2016)\nLearning Convolutional Neural Networks for Graphs\nICML\nPaper Link\nInfluential Citation Count (136), SS-ID (7c6de5a9e02a779e24504619050c6118f4eac181)\nABSTRACT\nNumerous important problems can be framed as learning from graph data. We propose a framework for learning convolutional neural networks for arbitrary graphs. These graphs may be undirected, directed, and with both discrete and continuous node and edge attributes. Analogous to image-based convolutional networks that operate on locally connected regions of the input, we present a general approach to extracting locally connected regions from graphs. Using established benchmark data sets, we demonstrate that the learned feature representations are competitive with state of the art graph kernels and that their computation is highly efficient.\n2D vectors Pan et al. (2016) Shirui Pan, Jia Wu, Xingquan Zhu, Chengqi Zhang, Yang Wang. (2016)\nTri-Party Deep Network Representation\nIJCAI\nPaper Link\nInfluential Citation Count (32), SS-ID (8ba7631515d5e7e0c451af1c4772507f41540a5e)\nABSTRACT\nInformation network mining often requires examination of linkage relationships between nodes for analysis. Recently, network representation has emerged to represent each node in a vector format, embedding network structure, so off-the-shelf machine learning methods can be directly applied for analysis. To date, existing methods only focus on one aspect of node information and cannot leverage node labels. In this paper, we propose TriDNR, a tri-party deep network representation model, using information from three parties: node structure, node content, and node labels (if available) to jointly learn optimal node representation. TriDNR is based on our new coupled deep natural language module, whose learning is enforced at three levels: (1) at the network structure level, TriDNR exploits inter-node relationship by maximizing the probability of observing surrounding nodes given a node in random walks; (2) at the node content level, TriDNR captures node-word correlation by maximizing the co-occurrence of word sequence given a node; and (3) at the node label level, TriDNR models label-word correspondence by maximizing the probability of word sequence given a class label. The tri-party information is jointly fed into the neural network model to mutually enhance each other to learn optimal representation, and results in up to 79% classification accuracy gain, compared to state-of-the-art methods.\n2D vectors Herman, Melançon \u0026amp; Marshall (2000) I. Herman, G. Melançon, M. S. Marshall. (2000)\nGraph Visualization and Navigation in Information Visualization: A Survey\nIEEE Trans. Vis. Comput. Graph.\nPaper Link\nInfluential Citation Count (76), SS-ID (2bbb5387adb3bd725069b1914609dc08c4ed8571)\nABSTRACT\nThis is a survey on graph visualization and navigation techniques, as used in information visualization. Graphs appear in numerous applications such as Web browsing, state-transition diagrams, and data structures. The ability to visualize and to navigate in these potentially large, abstract graphs is often a crucial part of an application. Information visualization has specific requirements, which means that this survey approaches the results of traditional graph drawing from a different perspective.\nPCA Maaten \u0026amp; Hinton (2008) L. V. D. Maaten, Geoffrey E. Hinton. (2008)\nVisualizing Data using t-SNE\nPaper Link\nInfluential Citation Count (826), SS-ID (1c46943103bd7b7a2c7be86859995a4144d1938b)\nABSTRACT\nWe present a new technique called “t-SNE” that visualizes high-dimensional data by giving each datapoint a location in a two or three-dimensional map. The technique is a variation of Stochastic Neighbor Embedding (Hinton and Roweis, 2002) that is much easier to optimize, and produces significantly better visualizations by reducing the tendency to crowd points together in the center of the map. t-SNE is better than existing techniques at creating a single map that reveals structure at many different scales. This is particularly important for high-dimensional data that lie on several different, but related, low-dimensional manifolds, such as images of objects from multiple classes seen from multiple viewpoints. For visualizing the structure of very large datasets, we show how t-SNE can use random walks on neighborhood graphs to allow the implicit structure of all of the data to influence the way in which a subset of the data is displayed. We illustrate the performance of t-SNE on a wide variety of datasets and compare it with many other non-parametric visualization techniques, including Sammon mapping, Isomap, and Locally Linear Embedding. The visualizations produced by t-SNE are significantly better than those produced by the other techniques on almost all of the datasets.\nt-SNE Tenenbaum, De Silva \u0026amp; Langford (2000) J. Tenenbaum, V. De Silva, J. Langford. (2000)\nA global geometric framework for nonlinear dimensionality reduction.\nScience\nPaper Link\nInfluential Citation Count (1143), SS-ID (3537fcd0ff99a3b3cb3d279012df826358420556)\nABSTRACT\nScientists working with large volumes of high-dimensional data, such as global climate patterns, stellar spectra, or human gene distributions, regularly confront the problem of dimensionality reduction: finding meaningful low-dimensional structures hidden in their high-dimensional observations. The human brain confronts the same problem in everyday perception, extracting from its high-dimensional sensory inputs-30,000 auditory nerve fibers or 10(6) optic nerve fibers-a manageably small number of perceptually relevant features. Here we describe an approach to solving dimensionality reduction problems that uses easily measured local metric information to learn the underlying global geometry of a data set. Unlike classical techniques such as principal component analysis (PCA) and multidimensional scaling (MDS), our approach is capable of discovering the nonlinear degrees of freedom that underlie complex natural observations, such as human handwriting or images of a face under different viewing conditions. In contrast to previous algorithms for nonlinear dimensionality reduction, ours efficiently computes a globally optimal solution, and, for an important class of data manifolds, is guaranteed to converge asymptotically to the true structure.\nother dimension reduction frameworks De Oliveira \u0026amp; Levkowitz (2003) M. C. Oliveira, H. Levkowitz. (2003)\nFrom Visual Data Exploration to Visual Data Mining: A Survey\nIEEE Trans. Vis. Comput. Graph.\nPaper Link\nInfluential Citation Count (22), SS-ID (1e008a1f5484094eb5794672d7c7318dd86f4fb5)\nABSTRACT\nWe survey work on the different uses of graphical mapping and interaction techniques for visual data mining of large data sets represented as table data. Basic terminology related to data mining, data sets, and visualization is introduced. Previous work on information visualization is reviewed in light of different categorizations of techniques and systems. The role of interaction techniques is discussed, in addition to work addressing the question of selecting and evaluating visualization techniques. We review some representative work on the use of information visualization techniques in the context of mining data. This includes both visual data exploration and visually expressing the outcome of specific mining algorithms. We also review recent innovative approaches that attempt to integrate visualization into the DM/KDD process, using it to enhance user interaction and comprehension.\nother dimension reduction frameworks Perozzi, Al-Rfou \u0026amp; Skiena (2014) Bryan Perozzi, Rami Al-Rfou, S. Skiena. (2014)\nDeepWalk: online learning of social representations\nKDD\nPaper Link\nInfluential Citation Count (1335), SS-ID (fff114cbba4f3ba900f33da574283e3de7f26c83)\nABSTRACT\nWe present DeepWalk, a novel approach for learning latent representations of vertices in a network. These latent representations encode social relations in a continuous vector space, which is easily exploited by statistical models. DeepWalk generalizes recent advancements in language modeling and unsupervised feature learning (or deep learning) from sequences of words to graphs. DeepWalk uses local information obtained from truncated random walks to learn latent representations by treating walks as the equivalent of sentences. We demonstrate DeepWalk\u0026rsquo;s latent representations on several multi-label network classification tasks for social networks such as BlogCatalog, Flickr, and YouTube. Our results show that DeepWalk outperforms challenging baselines which are allowed a global view of the network, especially in the presence of missing information. DeepWalk\u0026rsquo;s representations can provide F1 scores up to 10% higher than competing methods when labeled data is sparse. In some experiments, DeepWalk\u0026rsquo;s representations are able to outperform all baseline methods while using 60% less training data. DeepWalk is also scalable. It is an online learning algorithm which builds useful incremental results, and is trivially parallelizable. These qualities make it suitable for a broad class of real world applications such as network classification, and anomaly detection.\nembedded nodes visualization Grover \u0026amp; Leskovec (2016) Aditya Grover, J. Leskovec. (2016)\nnode2vec: Scalable Feature Learning for Networks\nKDD\nPaper Link\nInfluential Citation Count (1119), SS-ID (36ee2c8bd605afd48035d15fdc6b8c8842363376)\nABSTRACT\nPrediction tasks over nodes and edges in networks require careful effort in engineering features used by learning algorithms. Recent research in the broader field of representation learning has led to significant progress in automating prediction by learning the features themselves. However, present feature learning approaches are not expressive enough to capture the diversity of connectivity patterns observed in networks. Here we propose node2vec, an algorithmic framework for learning continuous feature representations for nodes in networks. In node2vec, we learn a mapping of nodes to a low-dimensional space of features that maximizes the likelihood of preserving network neighborhoods of nodes. We define a flexible notion of a node\u0026rsquo;s network neighborhood and design a biased random walk procedure, which efficiently explores diverse neighborhoods. Our algorithm generalizes prior work which is based on rigid notions of network neighborhoods, and we argue that the added flexibility in exploring neighborhoods is the key to learning richer representations. We demonstrate the efficacy of node2vec over existing state-of-the-art techniques on multi-label classification and link prediction in several real-world networks from diverse domains. Taken together, our work represents a new way for efficiently learning state-of-the-art task-independent representations in complex networks.\nembedded nodes visualization Tang et al. (2015) Jian Tang, Meng Qu, Mingzhe Wang, Ming Zhang, Jun Yan, Q. Mei. (2015)\nLINE: Large-scale Information Network Embedding\nWWW\nPaper Link\nInfluential Citation Count (832), SS-ID (0834e74304b547c9354b6d7da6fa78ef47a48fa8)\nABSTRACT\nThis paper studies the problem of embedding very large information networks into low-dimensional vector spaces, which is useful in many tasks such as visualization, node classification, and link prediction. Most existing graph embedding methods do not scale for real world information networks which usually contain millions of nodes. In this paper, we propose a novel network embedding method called the ``LINE,\u0026rsquo;\u0026rsquo; which is suitable for arbitrary types of information networks: undirected, directed, and/or weighted. The method optimizes a carefully designed objective function that preserves both the local and global network structures. An edge-sampling algorithm is proposed that addresses the limitation of the classical stochastic gradient descent and improves both the effectiveness and the efficiency of the inference. Empirical experiments prove the effectiveness of the LINE on a variety of real-world information networks, including language networks, social networks, and citation networks. The algorithm is very efficient, which is able to learn the embedding of a network with millions of vertices and billions of edges in a few hours on a typical single machine. The source code of the LINE is available online\\footnote{\\url{https://github.com/tangjianpku/LINE}}.\nembedded nodes visualization Ou et al. (2016) Mingdong Ou, Peng Cui, J. Pei, Ziwei Zhang, Wenwu Zhu. (2016)\nAsymmetric Transitivity Preserving Graph Embedding\nKDD\nPaper Link\nInfluential Citation Count (111), SS-ID (07627bf7eb649220ffbcdf6bf233e3a4a76e8590)\nABSTRACT\nGraph embedding algorithms embed a graph into a vector space where the structure and the inherent properties of the graph are preserved. The existing graph embedding methods cannot preserve the asymmetric transitivity well, which is a critical property of directed graphs. Asymmetric transitivity depicts the correlation among directed edges, that is, if there is a directed path from u to v, then there is likely a directed edge from u to v. Asymmetric transitivity can help in capturing structures of graphs and recovering from partially observed graphs. To tackle this challenge, we propose the idea of preserving asymmetric transitivity by approximating high-order proximity which are based on asymmetric transitivity. In particular, we develop a novel graph embedding algorithm, High-Order Proximity preserved Embedding (HOPE for short), which is scalable to preserve high-order proximities of large scale graphs and capable of capturing the asymmetric transitivity. More specifically, we first derive a general formulation that cover multiple popular high-order proximity measurements, then propose a scalable embedding algorithm to approximate the high-order proximity measurements based on their general formulation. Moreover, we provide a theoretical upper bound on the RMSE (Root Mean Squared Error) of the approximation. Our empirical experiments on a synthetic dataset and three real-world datasets demonstrate that HOPE can approximate the high-order proximities significantly better than the state-of-art algorithms and outperform the state-of-art algorithms in tasks of reconstruction, link prediction and vertex recommendation.\nembedded nodes visualization Wang, Cui \u0026amp; Zhu (2016) Daixin Wang, Peng Cui, Wenwu Zhu. (2016)\nStructural Deep Network Embedding\nKDD\nPaper Link\nInfluential Citation Count (223), SS-ID (d0b7c8828f0fca4dd901674e8fb5bd464a187664)\nABSTRACT\nNetwork embedding is an important method to learn low-dimensional representations of vertexes in networks, aiming to capture and preserve the network structure. Almost all the existing network embedding methods adopt shallow models. However, since the underlying network structure is complex, shallow models cannot capture the highly non-linear network structure, resulting in sub-optimal network representations. Therefore, how to find a method that is able to effectively capture the highly non-linear network structure and preserve the global and local structure is an open yet important problem. To solve this problem, in this paper we propose a Structural Deep Network Embedding method, namely SDNE. More specifically, we first propose a semi-supervised deep model, which has multiple layers of non-linear functions, thereby being able to capture the highly non-linear network structure. Then we propose to exploit the first-order and second-order proximity jointly to preserve the network structure. The second-order proximity is used by the unsupervised component to capture the global network structure. While the first-order proximity is used as the supervised information in the supervised component to preserve the local network structure. By jointly optimizing them in the semi-supervised deep model, our method can preserve both the local and global network structure and is robust to sparse networks. Empirically, we conduct the experiments on five real-world networks, including a language network, a citation network and three social networks. The results show that compared to the baselines, our method can reconstruct the original network significantly better and achieves substantial gains in three applications, i.e. multi-label classification, link prediction and visualization.\nembedded nodes visualization Tang et al. (2016) Jian Tang, J. Liu, Ming Zhang, Q. Mei. (2016)\nVisualizing Large-scale and High-dimensional Data\nWWW\nPaper Link\nInfluential Citation Count (31), SS-ID (30d0f3ec0f80439f561f9912831ea7f3ccf8133c)\nABSTRACT\nWe study the problem of visualizing large-scale and high-dimensional data in a low-dimensional (typically 2D or 3D) space. Much success has been reported recently by techniques that first compute a similarity structure of the data points and then project them into a low-dimensional space with the structure preserved. These two steps suffer from considerable computational costs, preventing the state-of-the-art methods such as the t-SNE from scaling to large-scale and high-dimensional data (e.g., millions of data points and hundreds of dimensions). We propose the LargeVis, a technique that first constructs an accurately approximated K-nearest neighbor graph from the data and then layouts the graph in the low-dimensional space. Comparing to t-SNE, LargeVis significantly reduces the computational cost of the graph construction step and employs a principled probabilistic model for the visualization step, the objective of which can be effectively optimized through asynchronous stochastic gradient descent with a linear time complexity. The whole procedure thus easily scales to millions of high-dimensional data points. Experimental results on real-world data sets demonstrate that the LargeVis outperforms the state-of-the-art methods in both efficiency and effectiveness. The hyper-parameters of LargeVis are also much more stable over different data sets.\nevaluation of graph embeddings for large structural data visualization Didimo, Liotta \u0026amp; Montecchiani (2018) W. Didimo, G. Liotta, Fabrizio Montecchiani. (2018)\nA Survey on Graph Drawing Beyond Planarity\nACM Comput. Surv.\nPaper Link\nInfluential Citation Count (2), SS-ID (2900ef06167eb5684020db9ccfcb9fe42a07a919)\nABSTRACT\nGraph Drawing Beyond Planarity is a rapidly growing research area that classifies and studies geometric representations of nonplanar graphs in terms of forbidden crossing configurations. The aim of this survey is to describe the main research directions in this area, the most prominent known results, and some of the most challenging open problems.\ngraph visualization techniques beyond planar mappings Network compression Definition 11 (Network Compression, Simplification or Sparsification) Network Compression, Simplification or Sparsification is a task of reducing the number of nodes and edges in a graph, for further efficient application of graph algorithms.\nPaper Approach As Feder \u0026amp; Motwani (1991) T. Feder, R. Motwani. (1991)\nClique partitions, graph compression and speeding-up algorithms\nSTOC \u0026lsquo;91\nPaper Link\nInfluential Citation Count (18), SS-ID (e527be9afd581b7e2a4e5b6e6a802be7d7590373)\nABSTRACT\nWe first consider the problem of partitioning the edges of a graph ~ into bipartite cliques such that the total order of the cliques is minimized, where the order of a clique is the number of vertices in it. It is shown that the problem is NP-complete. We then prove the existence of a partition of small total order in a sufficiently dense graph and devise an efilcient algorithm to compute such a partition. It turns out that our algorithm exhibits a trade-off between the total order of the partition and the running time. Next, we define the notion of a compression of a graph ~ and use the result on graph partitioning to efficiently compute an optimal compression for graphs of a given size. An interesting application of the graph compression result arises from the fact that several graph algorithms can be adapted to work with the compressed rep~esentation of the input graph, thereby improving the bound on their running times particularly on dense graphs. This makes use of the trade-off result we obtain from our partitioning algorithm. The algorithms analyzed include those for matchings, vertex connectivity, edge connectivity and shortest paths. In each case, we improve upon the running times of the best-known algorithms for these problems.\nfirst introduced the concept of network compression Pardalos \u0026amp; Xue (1994) P. Pardalos, J. Xue. (1994)\nThe maximum clique problem\nJ. Glob. Optim.\nPaper Link\nInfluential Citation Count (38), SS-ID (8306882ebcb8066cfbfe984bfe804c3f78d40559)\nABSTRACT\nIn this paper we present a survey of results concerning algorithms, complexity, and applications of the maximum clique problem. We discuss enumerative and exact algorithms, heuristics, and a variety of other proposed methods. An up to date bibliography on the maximum clique and related problems is also provided.\ndivide the graph into groups of nodes and edges and encode them Tian, Hankins \u0026amp; Patel (2008) Yuanyuan Tian, R. Hankins, J. Patel. (2008)\nEfficient aggregation for graph summarization\nSIGMOD Conference\nPaper Link\nInfluential Citation Count (28), SS-ID (6e9cf091dd709b557b32e7239647753680f0645b)\nABSTRACT\nGraphs are widely used to model real world objects and their relationships, and large graph datasets are common in many application domains. To understand the underlying characteristics of large graphs, graph summarization techniques are critical. However, existing graph summarization methods are mostly statistical (studying statistics such as degree distributions, hop-plots and clustering coefficients). These statistical methods are very useful, but the resolutions of the summaries are hard to control. In this paper, we introduce two database-style operations to summarize graphs. Like the OLAP-style aggregation methods that allow users to drill-down or roll-up to control the resolution of summarization, our methods provide an analogous functionality for large graph datasets. The first operation, called SNAP, produces a summary graph by grouping nodes based on user-selected node attributes and relationships. The second operation, called k-SNAP, further allows users to control the resolutions of summaries and provides the \u0026ldquo;drill-down\u0026rdquo; and \u0026ldquo;roll-up\u0026rdquo; abilities to navigate through summaries with different resolutions. We propose an efficient algorithm to evaluate the SNAP operation. In addition, we prove that the k-SNAP computation is NP-complete. We propose two heuristic methods to approximate the k-SNAP results. Through extensive experiments on a variety of real and synthetic datasets, we demonstrate the effectiveness and efficiency of the proposed methods.\ndivide the graph into groups of nodes and edges and encode them Toivonen et al. (2011) Hannu (TT) Toivonen, Fang Zhou, Aleksi Hartikainen, Atte Hinkka. (2011)\nCompression of weighted graphs\nKDD\nPaper Link\nInfluential Citation Count (14), SS-ID (a8b6b6baaa0d81ed01bb5f387b7ab14f7f234393)\nABSTRACT\nWe propose to compress weighted graphs (networks), motivated by the observation that large networks of social, biological, or other relations can be complex to handle and visualize. In the process also known as graph simplification, nodes and (unweighted) edges are grouped to supernodes and superedges, respectively, to obtain a smaller graph. We propose models and algorithms for weighted graphs. The interpretation (i.e. decompression) of a compressed, weighted graph is that a pair of original nodes is connected by an edge if their supernodes are connected by one, and that the weight of an edge is approximated to be the weight of the superedge. The compression problem now consists of choosing supernodes, superedges, and superedge weights so that the approximation error is minimized while the amount of compression is maximized. In this paper, we formulate this task as the \u0026lsquo;simple weighted graph compression problem\u0026rsquo;. We then propose a much wider class of tasks under the name of \u0026lsquo;generalized weighted graph compression problem\u0026rsquo;. The generalized task extends the optimization to preserve longer-range connectivities between nodes, not just individual edge weights. We study the properties of these problems and propose a range of algorithms to solve them, with different balances between complexity and quality of the result. We evaluate the problems and algorithms experimentally on real networks. The results indicate that weighted graphs can be compressed efficiently with relatively little compression error.\ndivide the graph into groups of nodes and edges and encode them Navlakha, Rastogi \u0026amp; Shrivastava (2008) S. Navlakha, R. Rastogi, Nisheeth Shrivastava. (2008)\nGraph summarization with bounded error\nSIGMOD Conference\nPaper Link\nInfluential Citation Count (49), SS-ID (c948d5342f4ffe8163fc91893a100c9617a2a305)\nABSTRACT\nWe propose a highly compact two-part representation of a given graph G consisting of a graph summary and a set of corrections. The graph summary is an aggregate graph in which each node corresponds to a set of nodes in G, and each edge represents the edges between all pair of nodes in the two sets. On the other hand, the corrections portion specifies the list of edge-corrections that should be applied to the summary to recreate G. Our representations allow for both lossless and lossy graph compression with bounds on the introduced error. Further, in combination with the MDL principle, they yield highly intuitive coarse-level summaries of the input graph G. We develop algorithms to construct highly compressed graph representations with small sizes and guaranteed accuracy, and validate our approach through an extensive set of experiments with multiple real-life graph data sets. To the best of our knowledge, this is the first work to compute graph summaries using the MDL principle, and use the summaries (along with corrections) to compress graphs with bounded error.\nMinimum Description Length (MDL) Ou et al. (2016) Mingdong Ou, Peng Cui, J. Pei, Ziwei Zhang, Wenwu Zhu. (2016)\nAsymmetric Transitivity Preserving Graph Embedding\nKDD\nPaper Link\nInfluential Citation Count (111), SS-ID (07627bf7eb649220ffbcdf6bf233e3a4a76e8590)\nABSTRACT\nGraph embedding algorithms embed a graph into a vector space where the structure and the inherent properties of the graph are preserved. The existing graph embedding methods cannot preserve the asymmetric transitivity well, which is a critical property of directed graphs. Asymmetric transitivity depicts the correlation among directed edges, that is, if there is a directed path from u to v, then there is likely a directed edge from u to v. Asymmetric transitivity can help in capturing structures of graphs and recovering from partially observed graphs. To tackle this challenge, we propose the idea of preserving asymmetric transitivity by approximating high-order proximity which are based on asymmetric transitivity. In particular, we develop a novel graph embedding algorithm, High-Order Proximity preserved Embedding (HOPE for short), which is scalable to preserve high-order proximities of large scale graphs and capable of capturing the asymmetric transitivity. More specifically, we first derive a general formulation that cover multiple popular high-order proximity measurements, then propose a scalable embedding algorithm to approximate the high-order proximity measurements based on their general formulation. Moreover, we provide a theoretical upper bound on the RMSE (Root Mean Squared Error) of the approximation. Our empirical experiments on a synthetic dataset and three real-world datasets demonstrate that HOPE can approximate the high-order proximities significantly better than the state-of-art algorithms and outperform the state-of-art algorithms in tasks of reconstruction, link prediction and vertex recommendation.\ncompression using graph embeddings Wang, Cui \u0026amp; Zhu (2016) Daixin Wang, Peng Cui, Wenwu Zhu. (2016)\nStructural Deep Network Embedding\nKDD\nPaper Link\nInfluential Citation Count (223), SS-ID (d0b7c8828f0fca4dd901674e8fb5bd464a187664)\nABSTRACT\nNetwork embedding is an important method to learn low-dimensional representations of vertexes in networks, aiming to capture and preserve the network structure. Almost all the existing network embedding methods adopt shallow models. However, since the underlying network structure is complex, shallow models cannot capture the highly non-linear network structure, resulting in sub-optimal network representations. Therefore, how to find a method that is able to effectively capture the highly non-linear network structure and preserve the global and local structure is an open yet important problem. To solve this problem, in this paper we propose a Structural Deep Network Embedding method, namely SDNE. More specifically, we first propose a semi-supervised deep model, which has multiple layers of non-linear functions, thereby being able to capture the highly non-linear network structure. Then we propose to exploit the first-order and second-order proximity jointly to preserve the network structure. The second-order proximity is used by the unsupervised component to capture the global network structure. While the first-order proximity is used as the supervised information in the supervised component to preserve the local network structure. By jointly optimizing them in the semi-supervised deep model, our method can preserve both the local and global network structure and is robust to sparse networks. Empirically, we conduct the experiments on five real-world networks, including a language network, a citation network and three social networks. The results show that compared to the baselines, our method can reconstruct the original network significantly better and achieves substantial gains in three applications, i.e. multi-label classification, link prediction and visualization.\ncompression using graph embeddings Khalil et al. (2017) Elias Boutros Khalil, H. Dai, Yuyu Zhang, B. Dilkina, Le Song. (2017)\nLearning Combinatorial Optimization Algorithms over Graphs\nNIPS\nPaper Link\nInfluential Citation Count (90), SS-ID (f306b1a973d9fa8c693036ca75fa8e30ad709635)\nABSTRACT\nThe design of good heuristics or approximation algorithms for NP-hard combinatorial optimization problems often requires significant specialized knowledge and trial-and-error. Can we automate this challenging, tedious process, and learn the algorithms instead? In many real-world applications, it is typically the case that the same optimization problem is solved again and again on a regular basis, maintaining the same problem structure but differing in the data. This provides an opportunity for learning heuristic algorithms that exploit the structure of such recurring problems. In this paper, we propose a unique combination of reinforcement learning and graph embedding to address this challenge. The learned greedy policy behaves like a meta-algorithm that incrementally constructs a solution, and the action is determined by the output of a graph embedding network capturing the current state of the solution. We show that our framework can be applied to a diverse range of optimization problems over graphs, and learns effective algorithms for the Minimum Vertex Cover, Maximum Cut and Traveling Salesman problems.\ngraph compression for constructing graph-based heuristics Applications to Real-World Problems Field Paper Topic Computer Vision Monti et al. (2017) Federico Monti, D. Boscaini, Jonathan Masci, E. Rodolà, Jan Svoboda, M. Bronstein. (2016)\nGeometric Deep Learning on Graphs and Manifolds Using Mixture Model CNNs\n2017 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)\nPaper Link\nInfluential Citation Count (121), SS-ID (f09f7888aa5aeaf88a2a44aea768d9a8747e97d2)\nABSTRACT\nDeep learning has achieved a remarkable performance breakthrough in several fields, most notably in speech recognition, natural language processing, and computer vision. In particular, convolutional neural network (CNN) architectures currently produce state-of-the-art performance on a variety of image analysis tasks such as object detection and recognition. Most of deep learning research has so far focused on dealing with 1D, 2D, or 3D Euclidean-structured data such as acoustic signals, images, or videos. Recently, there has been an increasing interest in geometric deep learning, attempting to generalize deep learning methods to non-Euclidean structured data such as graphs and manifolds, with a variety of applications from the domains of network analysis, computational social science, or computer graphics. In this paper, we propose a unified framework allowing to generalize CNN architectures to non-Euclidean domains (graphs and manifolds) and learn local, stationary, and compositional task-specific features. We show that various non-Euclidean CNN methods previously proposed in the literature can be considered as particular instances of our framework. We test the proposed method on standard tasks from the realms of image-, graph-and 3D shape analysis and show that it consistently outperforms previous approaches.\n3D shape reconstruction Computer Vision Chen et al. (2019) Yunpeng Chen, Marcus Rohrbach, Zhicheng Yan, Shuicheng Yan, Jiashi Feng, Yannis Kalantidis. (2018)\nGraph-Based Global Reasoning Networks\n2019 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)\nPaper Link\nInfluential Citation Count (32), SS-ID (1eaee16f6395c9602ad1dc17e69a6e235ec9ddd6)\nABSTRACT\nGlobally modeling and reasoning over relations between regions can be beneficial for many computer vision tasks on both images and videos. Convolutional Neural Networks (CNNs) excel at modeling local relations by convolution operations, but they are typically inefficient at capturing global relations between distant regions and require stacking multiple convolution layers. In this work, we propose a new approach for reasoning globally in which a set of features are globally aggregated over the coordinate space and then projected to an interaction space where relational reasoning can be efficiently computed. After reasoning, relation-aware features are distributed back to the original coordinate space for down-stream tasks. We further present a highly efficient instantiation of the proposed approach and introduce the Global Reasoning unit (GloRe unit) that implements the coordinate-interaction space mapping by weighted global pooling and weighted broadcasting, and the relation reasoning via graph convolution on a small graph in interaction space. The proposed GloRe unit is lightweight, end-to-end trainable and can be easily plugged into existing CNNs for a wide range of tasks. Extensive experiments show our GloRe unit can consistently boost the performance of state-of-the-art backbone architectures, including ResNet, ResNeXt, SE-Net and DPN, for both 2D and 3D CNNs, on image classification, semantic segmentation and video action recognition task.\nGloRe; applies GCNs over interaction data Computer Vision Wang et al. (2018) Peng Wang, Qi Wu, Jiewei Cao, Chunhua Shen, Lianli Gao, A. V. Hengel. (2018)\nNeighbourhood Watch: Referring Expression Comprehension via Language-Guided Graph Attention Networks\n2019 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)\nPaper Link\nInfluential Citation Count (12), SS-ID (8ca91ad7763be4da05238aa17a9e5628f619dc0b)\nABSTRACT\nThe task in referring expression comprehension is to localize the object instance in an image described by a referring expression phrased in natural language. As a language-to-vision matching task, the key to this problem is to learn a discriminative object feature that can adapt to the expression used. To avoid ambiguity, the expression normally tends to describe not only the properties of the referent itself, but also its relationships to its neighbourhood. To capture and exploit this important information we propose a graph-based, language-guided attention mechanism. Being composed of node attention component and edge attention component, the proposed graph attention mechanism explicitly represents inter-object relationships, and properties with a flexibility and power impossible with competing approaches. Furthermore, the proposed graph attention mechanism enables the comprehension decision to be visualizable and explainable. Experiments on three referring expression comprehension datasets show the advantage of the proposed approach.\nbuild relation graph of image objects for localizing object instance from natural language expression Computer Vision Yang et al. (2019) Lei Yang, Xiaohang Zhan, Dapeng Chen, Junjie Yan, Chen Change Loy, Dahua Lin. (2019)\nLearning to Cluster Faces on an Affinity Graph\n2019 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)\nPaper Link\nInfluential Citation Count (16), SS-ID (32873f6111963607d3f768f4685fe8137fdd1253)\nABSTRACT\nFace recognition sees remarkable progress in recent years, and its performance has reached a very high level. Taking it to a next level requires substantially larger data, which would involve prohibitive annotation cost. Hence, exploiting unlabeled data becomes an appealing alternative. Recent works have shown that clustering unlabeled faces is a promising approach, often leading to notable performance gains. Yet, how to effectively cluster, especially on a large-scale (i.e. million-level or above) dataset, remains an open question. A key challenge lies in the complex variations of cluster patterns, which make it difficult for conventional clustering methods to meet the needed accuracy. This work explores a novel approach, namely, learning to cluster instead of relying on hand-crafted criteria. Specifically, we propose a framework based on graph convolutional network, which combines a detection and a segmentation module to pinpoint face clusters. Experiments show that our method yields significantly more accurate face clusters, which, as a result, also lead to further performance gain in face recognition.\nface clustering with metric learning Computer Vision Wang et al. (2019) Zhongdao Wang, Liang Zheng, Yali Li, Shengjin Wang. (2019)\nLinkage Based Face Clustering via Graph Convolution Network\n2019 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)\nPaper Link\nInfluential Citation Count (18), SS-ID (6834b6a529c969e5feb1fb77713eff8f19704b31)\nABSTRACT\nIn this paper, we present an accurate and scalable approach to the face clustering task. We aim at grouping a set of faces by their potential identities. We formulate this task as a link prediction problem: a link exists between two faces if they are of the same identity. The key idea is that we find the local context in the feature space around an instance (face) contains rich information about the linkage relationship between this instance and its neighbors. By constructing sub-graphs around each instance as input data, which depict the local context, we utilize the graph convolution network (GCN) to perform reasoning and infer the likelihood of linkage between pairs in the sub-graphs. Experiments show that our method is more robust to the complex distribution of faces than conventional methods, yielding favorably comparable results to state-of-the-art methods on standard face clustering benchmarks, and is scalable to large datasets. Furthermore, we show that the proposed method does not need the number of clusters as prior, is aware of noises and outliers, and can be extended to a multi-view version for more accurate clustering accuracy.\nface clustering with metric learnin Computer Vision Kim et al. (2019) Daesik Kim, Seonhoon Kim, Nojun Kwak. (2018)\nTextbook Question Answering with Knowledge Graph Understanding and Unsupervised Open-set Text Comprehension\nArXiv\nPaper Link\nInfluential Citation Count (0), SS-ID (b22ce969f203fb548c42034ae7fc78cc043fdc16)\nABSTRACT\nIn this work, we introduce a novel algorithm for solving the textbook question answering (TQA) task which describes more realistic QA problems compared to other recent tasks. We mainly focus on two related issues with analysis of TQA dataset. First, it requires to comprehend long lessons to extract knowledge. To tackle this issue of extracting knowledge features from long lessons, we establish knowledge graph from texts and incorporate graph convolutional network (GCN). Second, scientific terms are not spread over the chapters and data splits in TQA dataset. To overcome this so called `out-of-domain\u0026rsquo; issue, we add novel unsupervised text learning process without any annotations before learning QA problems. The experimental results show that our model significantly outperforms prior state-of-the-art methods. Moreover, ablation studies validate that both methods of incorporating GCN for extracting knowledge from long lessons and our newly proposed unsupervised learning process are meaningful to solve this problem.\nfew-shot learning classification Computer Vision Shi et al. (2019) Lei Shi, Yifan Zhang, Jian Cheng, Hanqing Lu. (2019)\nSkeleton-Based Action Recognition With Directed Graph Neural Networks\n2019 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)\nPaper Link\nInfluential Citation Count (34), SS-ID (68a024d7b70ef3989a6751678f635cbe754440fc)\nABSTRACT\nThe skeleton data have been widely used for the action recognition tasks since they can robustly accommodate dynamic circumstances and complex backgrounds. In existing methods, both the joint and bone information in skeleton data have been proved to be of great help for action recognition tasks. However, how to incorporate these two types of data to best take advantage of the relationship between joints and bones remains a problem to be solved. In this work, we represent the skeleton data as a directed acyclic graph based on the kinematic dependency between the joints and bones in the natural human body. A novel directed graph neural network is designed specially to extract the information of joints, bones and their relations and make prediction based on the extracted features. In addition, to better fit the action recognition task, the topological structure of the graph is made adaptive based on the training process, which brings notable improvement. Moreover, the motion information of the skeleton sequence is exploited and combined with the spatial information to further enhance the performance in a two-stream framework. Our final model is tested on two large-scale datasets, NTU-RGBD and Skeleton-Kinetics, and exceeds state-of-the-art performance on both of them.\nhuman skeleton graph Computer Vision Si et al. (2019) Chenyang Si, Wentao Chen, Wei Wang, Liang Wang, T. Tan. (2019)\nAn Attention Enhanced Graph Convolutional LSTM Network for Skeleton-Based Action Recognition\n2019 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)\nPaper Link\nInfluential Citation Count (29), SS-ID (074611d0c9f527bc0ad06f00df779f3361e38b83)\nABSTRACT\nSkeleton-based action recognition is an important task that requires the adequate understanding of movement characteristics of a human action from the given skeleton sequence. Recent studies have shown that exploring spatial and temporal features of the skeleton sequence is vital for this task. Nevertheless, how to effectively extract discriminative spatial and temporal features is still a challenging problem. In this paper, we propose a novel Attention Enhanced Graph Convolutional LSTM Network (AGC-LSTM) for human action recognition from skeleton data. The proposed AGC-LSTM can not only capture discriminative features in spatial configuration and temporal dynamics but also explore the co-occurrence relationship between spatial and temporal domains. We also present a temporal hierarchical architecture to increase temporal receptive fields of the top AGC-LSTM layer, which boosts the ability to learn the high-level semantic representation and significantly reduces the computation cost. Furthermore, to select discriminative spatial information, the attention mechanism is employed to enhance information of key joints in each AGC-LSTM layer. Experimental results on two datasets are provided: NTU RGB+D dataset and Northwestern-UCLA dataset. The comparison results demonstrate the effectiveness of our approach and show that our approach outperforms the state-of-the-art methods on both datasets.\nhuman skeleton graph Computer Vision Li et al. (2019) Maosen Li, Siheng Chen, Xu Chen, Ya Zhang, Yanfeng Wang, Qi Tian. (2019)\nActional-Structural Graph Convolutional Networks for Skeleton-Based Action Recognition\n2019 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)\nPaper Link\nInfluential Citation Count (40), SS-ID (814b70cd133f97ef039bcc44124d9344dd8b3f64)\nABSTRACT\nAction recognition with skeleton data has recently attracted much attention in computer vision. Previous studies are mostly based on fixed skeleton graphs, only capturing local physical dependencies among joints, which may miss implicit joint correlations. To capture richer dependencies, we introduce an encoder-decoder structure, called A-link inference module, to capture action-specific latent dependencies, i.e. actional links, directly from actions. We also extend the existing skeleton graphs to represent higher-order dependencies, i.e. structural links. Combing the two types of links into a generalized skeleton graph, We further propose the actional-structural graph convolution network (AS-GCN), which stacks actional-structural graph convolution and temporal convolution as a basic building block, to learn both spatial and temporal features for action recognition. A future pose prediction head is added in parallel to the recognition head to help capture more detailed action patterns through self-supervision. We validate AS-GCN in action recognition using two skeleton data sets, NTU-RGB+D and Kinetics. The proposed AS-GCN achieves consistently large improvement compared to the state-of-the-art methods. As a side product, AS-GCN also shows promising results for future pose prediction.\nhuman skeleton graph Computer Vision Zhang et al. (2018) Da Zhang, Xiyang Dai, Xin Eric Wang, Yuan-fang Wang, L. Davis. (2018)\nMAN: Moment Alignment Network for Natural Language Moment Retrieval via Iterative Graph Adjustment\n2019 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)\nPaper Link\nInfluential Citation Count (42), SS-ID (613f59279586bd53aed57bc133246a4eb3c38977)\nABSTRACT\nThis research strives for natural language moment retrieval in long, untrimmed video streams. The problem is not trivial especially when a video contains multiple moments of interests and the language describes complex temporal dependencies, which often happens in real scenarios. We identify two crucial challenges: semantic misalignment and structural misalignment. However, existing approaches treat different moments separately and do not explicitly model complex moment-wise temporal relations. In this paper, we present Moment Alignment Network (MAN), a novel framework that unifies the candidate moment encoding and temporal structural reasoning in a single-shot feed-forward network. MAN naturally assigns candidate moment representations aligned with language semantics over different temporal locations and scales. Most importantly, we propose to explicitly model moment-wise temporal relations as a structured graph and devise an iterative graph adjustment network to jointly learn the best structure in an end-to-end manner. We evaluate the proposed approach on two challenging public benchmarks DiDeMo and Charades-STA, where our MAN significantly outperforms the state-of-the-art by a large margin.\nvideo tracking and classsification Computer Vision Gao Zhang \u0026amp; Xu (2019) Junyu Gao, Tianzhu Zhang, Changsheng Xu. (2019)\nGraph Convolutional Tracking\n2019 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)\nPaper Link\nInfluential Citation Count (13), SS-ID (53970ae69a73f547a56661fd25f6711746d277fb)\nABSTRACT\nTracking by siamese networks has achieved favorable performance in recent years. However, most of existing siamese methods do not take full advantage of spatial-temporal target appearance modeling under different contextual situations. In fact, the spatial-temporal information can provide diverse features to enhance the target representation, and the context information is important for online adaption of target localization. To comprehensively leverage the spatial-temporal structure of historical target exemplars and get benefit from the context information, in this work, we present a novel Graph Convolutional Tracking (GCT) method for high-performance visual tracking. Specifically, the GCT jointly incorporates two types of Graph Convolutional Networks (GCNs) into a siamese framework for target appearance modeling. Here, we adopt a spatial-temporal GCN to model the structured representation of historical target exemplars. Furthermore, a context GCN is designed to utilize the context of the current frame to learn adaptive features for target localization. Extensive results on 4 challenging benchmarks show that our GCT method performs favorably against state-of-the-art trackers while running around 50 frames per second.\nvideo tracking and classsification Computer Vision Zhong et al. (2019) Jia-Xing Zhong, Nannan Li, Weijie Kong, Shan Liu, Thomas H. Li, Ge Li. (2019)\nGraph Convolutional Label Noise Cleaner: Train a Plug-And-Play Action Classifier for Anomaly Detection\n2019 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)\nPaper Link\nInfluential Citation Count (22), SS-ID (a03bda078490e8ee991a1f86b53f27df7cf93a14)\nABSTRACT\nVideo anomaly detection under weak labels is formulated as a typical multiple-instance learning problem in previous works. In this paper, we provide a new perspective, i.e., a supervised learning task under noisy labels. In such a viewpoint, as long as cleaning away label noise, we can directly apply fully supervised action classifiers to weakly supervised anomaly detection, and take maximum advantage of these well-developed classifiers. For this purpose, we devise a graph convolutional network to correct noisy labels. Based upon feature similarity and temporal consistency, our network propagates supervisory signals from high-confidence snippets to low-confidence ones. In this manner, the network is capable of providing cleaned supervision for action classifiers. During the test phase, we only need to obtain snippet-wise predictions from the action classifier without any extra post-processing. Extensive experiments on 3 datasets at different scales with 2 types of action classifiers demonstrate the efficacy of our method. Remarkably, we obtain the frame-level AUC score of 82.12% on UCF-Crime.\nvideo tracking and classsification Natural Language Processing Marcheggiani \u0026amp; Titov (2017) Diego Marcheggiani, Ivan Titov. (2017)\nEncoding Sentences with Graph Convolutional Networks for Semantic Role Labeling\nEMNLP\nPaper Link\nInfluential Citation Count (79), SS-ID (c3a3c163f25b9181f1fb7e71a32482a7393d2088)\nABSTRACT\nSemantic role labeling (SRL) is the task of identifying the predicate-argument structure of a sentence. It is typically regarded as an important step in the standard NLP pipeline. As the semantic representations are closely related to syntactic ones, we exploit syntactic information in our model. We propose a version of graph convolutional networks (GCNs), a recent class of neural networks operating on graphs, suited to model syntactic dependency graphs. GCNs over syntactic dependency trees are used as sentence encoders, producing latent feature representations of words in a sentence. We observe that GCN layers are complementary to LSTM ones: when we stack both GCN and LSTM layers, we obtain a substantial improvement over an already state-of-the-art LSTM SRL model, resulting in the best reported scores on the standard benchmark (CoNLL-2009) both for Chinese and English.\nassign semantic roles by encoding sentences with the graph convolutional network Natural Language Processing Marcheggiani, Bastings \u0026amp; Titov (2018) Diego Marcheggiani, Jasmijn Bastings, Ivan Titov. (2018)\nExploiting Semantics in Neural Machine Translation with Graph Convolutional Networks\nNAACL\nPaper Link\nInfluential Citation Count (8), SS-ID (6411da05a0e6f3e38bcac0ce57c28038ff08081c)\nABSTRACT\nSemantic representations have long been argued as potentially useful for enforcing meaning preservation and improving generalization performance of machine translation methods. In this work, we are the first to incorporate information about predicate-argument structure of source sentences (namely, semantic-role representations) into neural machine translation. We use Graph Convolutional Networks (GCNs) to inject a semantic bias into sentence encoders and achieve improvements in BLEU scores over the linguistic-agnostic and syntax-aware versions on the English–German language pair.\nmachine trainslation using GCN Natural Language Processing Zhao et al. (2019) Guoshuai Zhao, Jun Yu Li, Lu Wang, Xueming Qian, Y. Fu. (2018)\nGraphSeq2Seq: Graph-Sequence-to-Sequence for Neural Machine Translation\nPaper Link\nInfluential Citation Count (1), SS-ID (5f2a156909e2550cdc09b7d3d3d503ec5d52b1d7)\nABSTRACT\nSequence-to-Sequence (Seq2Seq) neural models have become popular for text generation problems, e.g. neural machine translation (NMT) (Bahdanau et al.,2014; Britz et al., 2017), text summarization (Nallapati et al., 2017; Wang \u0026amp;Ling, 2016), and image captioning (Venugopalan et al., 2015; Liu et al., 2017). Though sequential modeling has been shown to be effective, the dependency graph among words contains additional semantic information and thus can be utilized for sentence modeling. In this paper, we propose a Graph-Sequence-to-Sequence(GraphSeq2Seq) model to fuse the dependency graph among words into the traditional Seq2Seq framework. For each sample, the sub-graph of each word is encoded to a graph representation, which is then utilized to sequential encoding. At last, a sequence decoder is leveraged for output generation. Since above model fuses different features by contacting them together to encode, we also propose a variant of our model that regards the graph representations as additional annotations in attention mechanism (Bahdanau et al., 2014) by separately encoding different features. Experiments on several translation benchmarks show that our models can outperform existing state-of-the-art methods, demonstrating the effectiveness of the combination of Graph2Seq and Seq2Seq.\nmachine translation using GCN Natural Language Processing Sevgili, Panchenko \u0026amp; Biemann (2019) Özge Sevgili, Alexander Panchenko, Chris Biemann. (2019)\nImproving Neural Entity Disambiguation with Graph Embeddings\nACL\nPaper Link\nInfluential Citation Count (1), SS-ID (540a140e4b8576e0b4edaefd5cee9d9c55da0e1d)\nABSTRACT\nEntity Disambiguation (ED) is the task of linking an ambiguous entity mention to a corresponding entry in a knowledge base. Current methods have mostly focused on unstructured text data to learn representations of entities, however, there is structured information in the knowledge base itself that should be useful to disambiguate entities. In this work, we propose a method that uses graph embeddings for integrating structured information from the knowledge base with unstructured information from text-based representations. Our experiments confirm that graph embeddings trained on a graph of hyperlinks between Wikipedia articles improve the performances of simple feed-forward neural ED model and a state-of-the-art neural ED system.\nuse the Wikipedia link graph between entities to improve the quality of entity disambiguation task Natural Language Processing Luo et al. (2019) Hongyin Luo, Yichen Li, Jie Fu, James R. Glass. (2018)\nLanguage Modeling with Graph Temporal Convolutional Networks\nPaper Link\nInfluential Citation Count (0), SS-ID (de23b3889d121102e463853269ec0bfa7cf4332f)\nABSTRACT\nRecently, there have been some attempts to use non-recurrent neural models for language modeling. However, a noticeable performance gap still remains. We propose a non-recurrent neural language model, dubbed graph temporal convolutional network (GTCN), that relies on graph neural network blocks and convolution operations. While the standard recurrent neural network language models encode sentences sequentially without modeling higher-level structural information, our model regards sentences as graphs and processes input words within a message propagation framework, aiming to learn better syntactic information by inferring skip-word connections. Specifically, the graph network blocks operate in parallel and learn the underlying graph structures in sentences without any additional annotation pertaining to structure knowledge. Experiments demonstrate that the model without recurrence can achieve comparable perplexity results in language modeling tasks and successfully learn syntactic information.\nextract syntactic and semantic information Natural Language Processing Vashishth et al. (2018) Shikhar Vashishth, Manik Bhandari, Prateek Yadav, Piyush Rai, C. Bhattacharyya, P. Talukdar. (2018)\nIncorporating Syntactic and Semantic Information in Word Embeddings using Graph Convolutional Networks\nACL\nPaper Link\nInfluential Citation Count (9), SS-ID (ab571a354f0847677862da027a69db9531eb08e8)\nABSTRACT\nWord embeddings have been widely adopted across several NLP applications. Most existing word embedding methods utilize sequential context of a word to learn its embedding. While there have been some attempts at utilizing syntactic context of a word, such methods result in an explosion of the vocabulary size. In this paper, we overcome this problem by proposing SynGCN, a flexible Graph Convolution based method for learning word embeddings. SynGCN utilizes the dependency context of a word without increasing the vocabulary size. Word embeddings learned by SynGCN outperform existing methods on various intrinsic and extrinsic tasks and provide an advantage when used with ELMo. We also propose SemGCN, an effective framework for incorporating diverse semantic knowledge for further enhancing learned word representations. We make the source code of both models available to encourage reproducible research.\nextract synactic and semantic information Natural Language Processing Veyseh, Nguyen \u0026amp; Dou (2019) Amir Pouran Ben Veyseh, T. Nguyen, D. Dou. (2019)\nGraph based Neural Networks for Event Factuality Prediction using Syntactic and Semantic Structures\nACL\nPaper Link\nInfluential Citation Count (1), SS-ID (37d8e064df4e921bcb7b80b6d4c3ee7488a027e0)\nABSTRACT\nEvent factuality prediction (EFP) is the task of assessing the degree to which an event mentioned in a sentence has happened. For this task, both syntactic and semantic information are crucial to identify the important context words. The previous work for EFP has only combined these information in a simple way that cannot fully exploit their coordination. In this work, we introduce a novel graph-based neural network for EFP that can integrate the semantic and syntactic information more effectively. Our experiments demonstrate the advantage of the proposed model for EFP.\nextract syntactic and semantic information Natural Language Processing Zhu et al. (2019) Hao Zhu, Yankai Lin, Zhiyuan Liu, Jie Fu, Tat-Seng Chua, Maosong Sun. (2019)\nGraph Neural Networks with Generated Parameters for Relation Extraction\nACL\nPaper Link\nInfluential Citation Count (4), SS-ID (352ac73b7d92afa915c06026a4336927d550cec3)\nABSTRACT\nIn this paper, we propose a novel graph neural network with generated parameters (GP-GNNs). The parameters in the propagation module, i.e. the transition matrices used in message passing procedure, are produced by a generator taking natural language sentences as inputs. We verify GP-GNNs in relation extraction from text, both on bag- and instance-settings. Experimental results on a human-annotated dataset and two distantly supervised datasets show that multi-hop reasoning mechanism yields significant improvements. We also perform a qualitative analysis to demonstrate that our model could discover more accurate relations by multi-hop relational reasoning.\nproposed the Generated Parameters GNN for the Relation Extraction task Natural Language Processing Guo, Zhang \u0026amp; Lu (2019) Zhijiang Guo, Yan Zhang, Wei Lu. (2019)\nAttention Guided Graph Convolutional Networks for Relation Extraction\nACL\nPaper Link\nInfluential Citation Count (45), SS-ID (e4363d077a890c8d5c5e66b82fe69a1bbbdd5c80)\nABSTRACT\nDependency trees convey rich structural information that is proven useful for extracting relations among entities in text. However, how to effectively make use of relevant information while ignoring irrelevant information from the dependency trees remains a challenging research question. Existing approaches employing rule based hard-pruning strategies for selecting relevant partial dependency structures may not always yield optimal results. In this work, we propose Attention Guided Graph Convolutional Networks (AGGCNs), a novel model which directly takes full dependency trees as inputs. Our model can be understood as a soft-pruning approach that automatically learns how to selectively attend to the relevant sub-structures useful for the relation extraction task. Extensive results on various tasks including cross-sentence n-ary relation extraction and large-scale sentence-level relation extraction show that our model is able to better leverage the structural information of the full dependency trees, giving significantly better results than previous approaches.\nused Graph Attention Models to encode dependency tree information Natural Language Processing Sahu et al. (2019) Sunil Kumar Sahu, Fenia Christopoulou, Makoto Miwa, S. Ananiadou. (2019)\nInter-sentence Relation Extraction with Document-level Graph Convolutional Neural Network\nACL\nPaper Link\nInfluential Citation Count (13), SS-ID (358ca777d9992bdc06fdcc1940e3b18a8da68878)\nABSTRACT\nInter-sentence relation extraction deals with a number of complex semantic relationships in documents, which require local, non-local, syntactic and semantic dependencies. Existing methods do not fully exploit such dependencies. We present a novel inter-sentence relation extraction model that builds a labelled edge graph convolutional neural network model on a document-level graph. The graph is constructed using various inter- and intra-sentence dependencies to capture local and non-local dependency information. In order to predict the relation of an entity pair, we utilise multi-instance learning with bi-affine pairwise scoring. Experimental results show that our model achieves comparable performance to the state-of-the-art neural models on two biochemistry datasets. Our analysis shows that all the types in the graph are effective for inter-sentence relation extraction.\nused dependency graph for relation extraction tasks Natural Language Processing Banerjee \u0026amp; Khapra (2019) Suman Banerjee, Mitesh M. Khapra. (2019)\nGraph Convolutional Network with Sequential Attention for Goal-Oriented Dialogue Systems\nTransactions of the Association for Computational Linguistics\nPaper Link\nInfluential Citation Count (0), SS-ID (a9c895dc9d6443588ffd9d6c748215d8c48209a0)\nABSTRACT\nAbstract Domain-specific goal-oriented dialogue systems typically require modeling three types of inputs, namely, (i) the knowledge-base associated with the domain, (ii) the history of the conversation, which is a sequence of utterances, and (iii) the current utterance for which the response needs to be generated. While modeling these inputs, current state-of-the-art models such as Mem2Seq typically ignore the rich structure inherent in the knowledge graph and the sentences in the conversation context. Inspired by the recent success of structure-aware Graph Convolutional Networks (GCNs) for various NLP tasks such as machine translation, semantic role labeling, and document dating, we propose a memory-augmented GCN for goal-oriented dialogues. Our model exploits (i) the entity relation graph in a knowledge-base and (ii) the dependency graph associated with an utterance to compute richer representations for words and entities. Further, we take cognizance of the fact that in certain situations, such as when the conversation is in a code-mixed language, dependency parsers may not be available. We show that in such situations we could use the global word co-occurrence graph to enrich the representations of utterances. We experiment with four datasets: (i) the modified DSTC2 dataset, (ii) recently released code-mixed versions of DSTC2 dataset in four languages, (iii) Wizard-of-Oz style CAM676 dataset, and (iv) Wizard-of-Oz style MultiWOZ dataset. On all four datasets our method outperforms existing methods, on a wide range of evaluation metrics.\nused GNN for question answering task, comment teneration and dialog systems Natural Language Processing Kim, Kim \u0026amp; Kwak (2018) Daesik Kim, Seonhoon Kim, Nojun Kwak. (2018)\nTextbook Question Answering with Knowledge Graph Understanding and Unsupervised Open-set Text Comprehension\nArXiv\nPaper Link\nInfluential Citation Count (0), SS-ID (b22ce969f203fb548c42034ae7fc78cc043fdc16)\nABSTRACT\nIn this work, we introduce a novel algorithm for solving the textbook question answering (TQA) task which describes more realistic QA problems compared to other recent tasks. We mainly focus on two related issues with analysis of TQA dataset. First, it requires to comprehend long lessons to extract knowledge. To tackle this issue of extracting knowledge features from long lessons, we establish knowledge graph from texts and incorporate graph convolutional network (GCN). Second, scientific terms are not spread over the chapters and data splits in TQA dataset. To overcome this so called `out-of-domain\u0026rsquo; issue, we add novel unsupervised text learning process without any annotations before learning QA problems. The experimental results show that our model significantly outperforms prior state-of-the-art methods. Moreover, ablation studies validate that both methods of incorporating GCN for extracting knowledge from long lessons and our newly proposed unsupervised learning process are meaningful to solve this problem.\nused GNN for question answering task, comment teneration and dialog systems Natural Language Processing Li et al. (2019) Wei Li, Jingjing Xu, Yancheng He, Shengli Yan, Yunfang Wu, Xu Sun. (2019)\nCoherent Comments Generation for Chinese Articles with a Graph-to-Sequence Model\nACL\nPaper Link\nInfluential Citation Count (6), SS-ID (b2125d912941244c243a33e31b01e34467cea457)\nABSTRACT\nAutomatic article commenting is helpful in encouraging user engagement on online news platforms. However, the news documents are usually too long for models under traditional encoder-decoder frameworks, which often results in general and irrelevant comments. In this paper, we propose to generate comments with a graph-to-sequence model that models the input news as a topic interaction graph. By organizing the article into graph structure, our model can better understand the internal structure of the article and the connection between topics, which makes it better able to generate coherent and informative comments. We collect and release a large scale news-comment corpus from a popular Chinese online news platform Tencent Kuaibao. Extensive experiment results show that our model can generate much more coherent and informative comments compared with several strong baseline models.\nused graph models based on news interaction graphs Knowledge Graph Completion Knowledge Graph Completion Knowledge Graph Completion Knowledge Graph Completion Knowledge Graph Completion Knowledge Graph Completion Knowledge Graph Completion Knowledge Graph Completion Knowledge Graph Completion Knowledge Graph Completion Knowledge Graph Completion Knowledge Graph Completion Knowledge Graph Completion Knowledge Graph Completion Knowledge Graph Completion Knowledge Graph Completion Knowledge Graph Completion Knowledge Graph Completion Knowledge Graph Completion Knowledge Graph Completion Knowledge Graph Completion Knowledge Graph Completion Knowledge Graph Completion Data Minig Data Minig Data Minig Data Minig Data Minig Recommender systems Recommender systems Recommender systems Recommender systems Recommender systems Recommender systems Recommender systems Recommender systems Recommender systems Recommender systems Recommender systems Recommender systems Recommender systems Recommender systems Recommender systems Recommender systems Recommender systems Recommender systems Recommender systems Recommender systems Recommender systems Recommender systems Recommender systems Recommender systems Recommender systems Recommender systems Recommender systems Reinforcement Learning Reinforcement Learning Reinforcement Learning Reinforcement Learning Reinforcement Learning Reinforcement Learning Open Problems Model Comparison Data Metrics Evaluation pipeline Models Results Node clustering Node classification Link prediction Graph visualization Random graphs Conclusion List of Methods MDS Kruskal J et al. (1978) Kruskal J, Wish M. (1978)\nMultidimensional Scaling\nNew York: SAGE Publications LSI Deerwester et al. (1990) S. Deerwester, S. Dumais, G. Furnas, T. Landauer, R. Harshman. (1990)\nIndexing by Latent Semantic Analysis\nPaper Link\nInfluential Citation Count (950), SS-ID (e5305866d701a2c102c5f81fbbf48bf6ac29f252)\nABSTRACT\nA new method for automatic indexing and retrieval is described. The approach is to take advantage of implicit higher-order structure in the association of terms with documents (“semantic structure”) in order to improve the detection of relevant documents on the basis of terms found in queries. The particular technique used is singular-value decomposition, in which a large term by document matrix is decomposed into a set of ca. 100 orthogonal factors from which the original matrix can be approximated by linear combination. Documents are represented by ca. 100 item vectors of factor weights. Queries are represented as pseudo-document vectors formed from weighted combinations of terms, and documents with supra-threshold cosine values are returned. initial tests find this completely automatic method for retrieval to be promising.\nLDA Martinez \u0026amp; Kak (2001) Aleix M. Martinez, A. Kak. (2001)\nPCA versus LDA\nIEEE Trans. Pattern Anal. Mach. Intell.\nPaper Link\nInfluential Citation Count (241), SS-ID (d544475dc01daa0c4f9847ef72adb8878df8ce99)\nABSTRACT\nIn the context of the appearance-based paradigm for object recognition, it is generally believed that algorithms based on LDA (linear discriminant analysis) are superior to those based on PCA (principal components analysis). In this communication, we show that this is not always the case. We present our case first by using intuitively plausible arguments and, then, by showing actual results on a face database. Our overall conclusion is that when the training data set is small, PCA can outperform LDA and, also, that PCA is less sensitive to different training data sets.\nISOMAP Tenenbaum, De Silva \u0026amp; Langford (2000) J. Tenenbaum, V. De Silva, J. Langford. (2000)\nA global geometric framework for nonlinear dimensionality reduction.\nScience\nPaper Link\nInfluential Citation Count (1143), SS-ID (3537fcd0ff99a3b3cb3d279012df826358420556)\nABSTRACT\nScientists working with large volumes of high-dimensional data, such as global climate patterns, stellar spectra, or human gene distributions, regularly confront the problem of dimensionality reduction: finding meaningful low-dimensional structures hidden in their high-dimensional observations. The human brain confronts the same problem in everyday perception, extracting from its high-dimensional sensory inputs-30,000 auditory nerve fibers or 10(6) optic nerve fibers-a manageably small number of perceptually relevant features. Here we describe an approach to solving dimensionality reduction problems that uses easily measured local metric information to learn the underlying global geometry of a data set. Unlike classical techniques such as principal component analysis (PCA) and multidimensional scaling (MDS), our approach is capable of discovering the nonlinear degrees of freedom that underlie complex natural observations, such as human handwriting or images of a face under different viewing conditions. In contrast to previous algorithms for nonlinear dimensionality reduction, ours efficiently computes a globally optimal solution, and, for an important class of data manifolds, is guaranteed to converge asymptotically to the true structure.\nLLE Roweis \u0026amp; Saul (2000) S. Roweis, L. Saul. (2000)\nNonlinear dimensionality reduction by locally linear embedding.\nScience\nPaper Link\nInfluential Citation Count (1523), SS-ID (afcd6da7637ddeef6715109aca248da7a24b1c65)\nABSTRACT\nMany areas of science depend on exploratory data analysis and visualization. The need to analyze large amounts of multivariate data raises the fundamental problem of dimensionality reduction: how to discover compact representations of high-dimensional data. Here, we introduce locally linear embedding (LLE), an unsupervised learning algorithm that computes low-dimensional, neighborhood-preserving embeddings of high-dimensional inputs. Unlike clustering methods for local dimensionality reduction, LLE maps its inputs into a single global coordinate system of lower dimensionality, and its optimizations do not involve local minima. By exploiting the local symmetries of linear reconstructions, LLE is able to learn the global structure of nonlinear manifolds, such as those generated by images of faces or documents of text.\nLPP He \u0026amp; Niyogi (2004) Xiaofei He, P. Niyogi. (2003)\nLocality Preserving Projections\nNIPS\nPaper Link\nInfluential Citation Count (791), SS-ID (75335244b49f4d1bb27aa51f1690bbefbbe1c3d1)\nABSTRACT\nMany problems in information processing involve some form of dimensionality reduction. In this paper, we introduce Locality Preserving Projections (LPP). These are linear projective maps that arise by solving a variational problem that optimally preserves the neighborhood structure of the data set. LPP should be seen as an alternative to Principal Component Analysis (PCA) – a classical linear technique that projects the data along the directions of maximal variance. When the high dimensional data lies on a low dimensional manifold embedded in the ambient space, the Locality Preserving Projections are obtained by finding the optimal linear approximations to the eigenfunctions of the Laplace Beltrami operator on the manifold. As a result, LPP shares many of the data representation properties of nonlinear techniques such as Laplacian Eigenmaps or Locally Linear Embedding. Yet LPP is linear and more crucially is defined everywhere in ambient space rather than just on the training data points. This is borne out by illustrative examples on some high dimensional data sets.\nLE Belkin \u0026amp; Niyogi (2002) Mikhail Belkin, P. Niyogi. (2001)\nLaplacian Eigenmaps and Spectral Techniques for Embedding and Clustering\nNIPS\nPaper Link\nInfluential Citation Count (356), SS-ID (9d16c547d15a08091e68c86a99731b14366e3f0d)\nABSTRACT\nDrawing on the correspondence between the graph Laplacian, the Laplace-Beltrami operator on a manifold, and the connections to the heat equation, we propose a geometrically motivated algorithm for constructing a representation for data sampled from a low dimensional manifold embedded in a higher dimensional space. The algorithm provides a computationally efficient approach to nonlinear dimensionality reduction that has locality preserving properties and a natural connection to clustering. Several applications are considered.\nKernel Eigenmaps Brand (2003) M. Brand. (2003)\nContinuous nonlinear dimensionality reduction by kernel Eigenmaps\nIJCAI\nPaper Link\nInfluential Citation Count (5), SS-ID (99cd988b104202887ad9657b8a61baa7ff0581c1)\nABSTRACT\nWe equate nonlinear dimensionality reduction (NLDR) to graph embedding with side information about the vertices, and derive a solution to either problem in the form of a kernel-based mixture of affine maps from the ambient space to the target space. Unlike most spectral NLDR methods, the central eigenproblem can be made relatively small, and the result is a continuous mapping defined over the entire space, not just the datapoints. A demonstration is made to visualizing the distribution of word usages (as a proxy to word meanings) in a sample of the machine learning literature.\nCauchy Graph Embedding Luo et al. (2011) Dijun Luo, C. Ding, F. Nie, Heng Huang. (2011)\nCauchy Graph Embedding\nICML\nPaper Link\nInfluential Citation Count (3), SS-ID (6f390eee4c9a082e02843fb34046f653624e9b76)\nABSTRACT\nLaplacian embedding provides a low-dimensional representation for the nodes of a graph where the edge weights denote pair-wise similarity among the node objects. It is commonly assumed that the Laplacian embedding results preserve the local topology of the original data on the low-dimensional projected subspaces, i.e., for any pair of graph nodes with large similarity, they should be embedded closely in the embedded space. However, in this paper, we will show that the Laplacian embedding often cannot preserve local topology well as we expected. To enhance the local topology preserving property in graph embedding, we propose a novel Cauchy graph embedding which preserves the similarity relationships of the original data in the embedded space via a new objective. Consequentially the machine learning tasks (such as k Nearest Neighbor type classifications) can be easily conducted on the embedded data with better performance. The experimental results on both synthetic and real world benchmark data sets demonstrate the usefulness of this new type of embedding.\nStructure Preserving Embedding Shaw \u0026amp; Jebara (2009) B. Shaw, T. Jebara. (2009)\nStructure preserving embedding\nICML \u0026lsquo;09\nPaper Link\nInfluential Citation Count (4), SS-ID (df30fe0aeac5a530c9499598251a3854fe45ee94)\nABSTRACT\nStructure Preserving Embedding (SPE) is an algorithm for embedding graphs in Euclidean space such that the embedding is low-dimensional and preserves the global topological properties of the input graph. Topology is preserved if a connectivity algorithm, such as k-nearest neighbors, can easily recover the edges of the input graph from only the coordinates of the nodes after embedding. SPE is formulated as a semidefinite program that learns a low-rank kernel matrix constrained by a set of linear inequalities which captures the connectivity structure of the input graph. Traditional graph embedding algorithms do not preserve structure according to our definition, and thus the resulting visualizations can be misleading or less informative. SPE provides significant improvements in terms of visualization and lossless compression of graphs, outperforming popular methods such as spectral embedding and Laplacian eigen-maps. We find that many classical graphs and networks can be properly embedded using only a few dimensions. Furthermore, introducing structure preserving constraints into dimensionality reduction algorithms produces more accurate representations of high-dimensional data.\nGraph Factorization Ahmed et al. (2013) Amr Ahmed, N. Shervashidze, Shravan M. Narayanamurthy, V. Josifovski, Alex Smola. (2013)\nDistributed large-scale natural graph factorization\nWWW\nPaper Link\nInfluential Citation Count (30), SS-ID (952bc3bc999be86d4b03a9c4af94c555c822aa11)\nABSTRACT\nNatural graphs, such as social networks, email graphs, or instant messaging patterns, have become pervasive through the internet. These graphs are massive, often containing hundreds of millions of nodes and billions of edges. While some theoretical models have been proposed to study such graphs, their analysis is still difficult due to the scale and nature of the data. We propose a framework for large-scale graph decomposition and inference. To resolve the scale, our framework is distributed so that the data are partitioned over a shared-nothing set of machines. We propose a novel factorization technique that relies on partitioning a graph so as to minimize the number of neighboring vertices rather than edges across partitions. Our decomposition is based on a streaming algorithm. It is network-aware as it adapts to the network topology of the underlying computational hardware. We use local copies of the variables and an efficient asynchronous communication protocol to synchronize the replicated values in order to perform most of the computation without having to incur the cost of network communication. On a graph of 200 million vertices and 10 billion edges, derived from an email communication network, our algorithm retains convergence properties while allowing for almost linear scalability in the number of computers.\nGraRep Cao, Lu \u0026amp; Xu (2015) Shaosheng Cao, Wei Lu, Qiongkai Xu. (2015)\nGraRep: Learning Graph Representations with Global Structural Information\nCIKM\nPaper Link\nInfluential Citation Count (131), SS-ID (c2fd72cb2a77941e655b5d949d0d59b01e173c3b)\nABSTRACT\nIn this paper, we present {GraRep}, a novel model for learning vertex representations of weighted graphs. This model learns low dimensional vectors to represent vertices appearing in a graph and, unlike existing work, integrates global structural information of the graph into the learning process. We also formally analyze the connections between our work and several previous research efforts, including the DeepWalk model of Perozzi et al. as well as the skip-gram model with negative sampling of Mikolov et al. We conduct experiments on a language network, a social network as well as a citation network and show that our learned global representations can be effectively used as features in tasks such as clustering, classification and visualization. Empirical results demonstrate that our representation significantly outperforms other state-of-the-art methods in such tasks.\nHOPE Ou et al. (2016) Mingdong Ou, Peng Cui, J. Pei, Ziwei Zhang, Wenwu Zhu. (2016)\nAsymmetric Transitivity Preserving Graph Embedding\nKDD\nPaper Link\nInfluential Citation Count (111), SS-ID (07627bf7eb649220ffbcdf6bf233e3a4a76e8590)\nABSTRACT\nGraph embedding algorithms embed a graph into a vector space where the structure and the inherent properties of the graph are preserved. The existing graph embedding methods cannot preserve the asymmetric transitivity well, which is a critical property of directed graphs. Asymmetric transitivity depicts the correlation among directed edges, that is, if there is a directed path from u to v, then there is likely a directed edge from u to v. Asymmetric transitivity can help in capturing structures of graphs and recovering from partially observed graphs. To tackle this challenge, we propose the idea of preserving asymmetric transitivity by approximating high-order proximity which are based on asymmetric transitivity. In particular, we develop a novel graph embedding algorithm, High-Order Proximity preserved Embedding (HOPE for short), which is scalable to preserve high-order proximities of large scale graphs and capable of capturing the asymmetric transitivity. More specifically, we first derive a general formulation that cover multiple popular high-order proximity measurements, then propose a scalable embedding algorithm to approximate the high-order proximity measurements based on their general formulation. Moreover, we provide a theoretical upper bound on the RMSE (Root Mean Squared Error) of the approximation. Our empirical experiments on a synthetic dataset and three real-world datasets demonstrate that HOPE can approximate the high-order proximities significantly better than the state-of-art algorithms and outperform the state-of-art algorithms in tasks of reconstruction, link prediction and vertex recommendation.\nModularized Nonnegative Matrix Factorization Wang et al. (2017) Xiao Wang, Peng Cui, Jing Wang, J. Pei, Wenwu Zhu, Shiqiang Yang. (2017)\nCommunity Preserving Network Embedding\nAAAI\nPaper Link\nInfluential Citation Count (52), SS-ID (d3e0d596efd9d19b93d357565a68dfa925dce2bb)\nABSTRACT\nNetwork embedding, aiming to learn the low-dimensional representations of nodes in networks, is of paramount importance in many real applications. One basic requirement of network embedding is to preserve the structure and inherent properties of the networks. While previous network embedding methods primarily preserve the microscopic structure, such as the first- and second-order proximities of nodes, the mesoscopic community structure, which is one of the most prominent feature of networks, is largely ignored. In this paper, we propose a novel Modularized Nonnegative Matrix Factorization (M-NMF) model to incorporate the community structure into network embedding. We exploit the consensus relationship between the representations of nodes and community structure, and then jointly optimize NMF based representation learning model and modularity based community detection model in a unified framework, which enables the learned representations of nodes to preserve both of the microscopic and community structures. We also provide efficient updating rules to infer the parameters of our model, together with the correctness and convergence guarantees. Extensive experimental results on a variety of real-world networks show the superior performance of the proposed method over the state-of-the-arts.\nATP (Asymmetric Transitivity Preservation) Sun et al. (2018) Jiankai Sun, Bortik Bandyopadhyay, Armin Bashizade, Jiongqian Liang, P. Sadayappan, S. Parthasarathy. (2018)\nATP: Directed Graph Embedding with Asymmetric Transitivity Preservation\nAAAI\nPaper Link\nInfluential Citation Count (4), SS-ID (b764d0070d07957d4b9621988ea3d020e9ecbe36)\nABSTRACT\nDirected graphs have been widely used in Community Question Answering services (CQAs) to model asymmetric relationships among different types of nodes in CQA graphs, e.g., question, answer, user. Asymmetric transitivity is an essential property of directed graphs, since it can play an important role in downstream graph inference and analysis. Question difficulty and user expertise follow the characteristic of asymmetric transitivity. Maintaining such properties, while reducing the graph to a lower dimensional vector embedding space, has been the focus of much recent research. In this paper, we tackle the challenge of directed graph embedding with asymmetric transitivity preservation and then leverage the proposed embedding method to solve a fundamental task in CQAs: how to appropriately route and assign newly posted questions to users with the suitable expertise and interest in CQAs. The technique incorporates graph hierarchy and reachability information naturally by relying on a nonlinear transformation that operates on the core reachability and implicit hierarchy within such graphs. Subsequently, the methodology levers a factorization-based approach to generate two embedding vectors for each node within the graph, to capture the asymmetric transitivity. Extensive experiments show that our framework consistently and significantly outperforms the state-of-the-art baselines on three diverse realworld tasks: link prediction, and question difficulty estimation and expert finding in online forums like Stack Exchange. Particularly, our framework can support inductive embedding learning for newly posted questions (unseen nodes during training), and therefore can properly route and assign these kinds of questions to experts in CQAs.\nSDNE (Structural Deep Network Embedding) Wang, Cui \u0026amp; Zhu (2016) Daixin Wang, Peng Cui, Wenwu Zhu. (2016)\nStructural Deep Network Embedding\nKDD\nPaper Link\nInfluential Citation Count (223), SS-ID (d0b7c8828f0fca4dd901674e8fb5bd464a187664)\nABSTRACT\nNetwork embedding is an important method to learn low-dimensional representations of vertexes in networks, aiming to capture and preserve the network structure. Almost all the existing network embedding methods adopt shallow models. However, since the underlying network structure is complex, shallow models cannot capture the highly non-linear network structure, resulting in sub-optimal network representations. Therefore, how to find a method that is able to effectively capture the highly non-linear network structure and preserve the global and local structure is an open yet important problem. To solve this problem, in this paper we propose a Structural Deep Network Embedding method, namely SDNE. More specifically, we first propose a semi-supervised deep model, which has multiple layers of non-linear functions, thereby being able to capture the highly non-linear network structure. Then we propose to exploit the first-order and second-order proximity jointly to preserve the network structure. The second-order proximity is used by the unsupervised component to capture the global network structure. While the first-order proximity is used as the supervised information in the supervised component to preserve the local network structure. By jointly optimizing them in the semi-supervised deep model, our method can preserve both the local and global network structure and is robust to sparse networks. Empirically, we conduct the experiments on five real-world networks, including a language network, a citation network and three social networks. The results show that compared to the baselines, our method can reconstruct the original network significantly better and achieves substantial gains in three applications, i.e. multi-label classification, link prediction and visualization.\nNode2Vec Grover \u0026amp; Leskovec (2016) Aditya Grover, J. Leskovec. (2016)\nnode2vec: Scalable Feature Learning for Networks\nKDD\nPaper Link\nInfluential Citation Count (1119), SS-ID (36ee2c8bd605afd48035d15fdc6b8c8842363376)\nABSTRACT\nPrediction tasks over nodes and edges in networks require careful effort in engineering features used by learning algorithms. Recent research in the broader field of representation learning has led to significant progress in automating prediction by learning the features themselves. However, present feature learning approaches are not expressive enough to capture the diversity of connectivity patterns observed in networks. Here we propose node2vec, an algorithmic framework for learning continuous feature representations for nodes in networks. In node2vec, we learn a mapping of nodes to a low-dimensional space of features that maximizes the likelihood of preserving network neighborhoods of nodes. We define a flexible notion of a node\u0026rsquo;s network neighborhood and design a biased random walk procedure, which efficiently explores diverse neighborhoods. Our algorithm generalizes prior work which is based on rigid notions of network neighborhoods, and we argue that the added flexibility in exploring neighborhoods is the key to learning richer representations. We demonstrate the efficacy of node2vec over existing state-of-the-art techniques on multi-label classification and link prediction in several real-world networks from diverse domains. Taken together, our work represents a new way for efficiently learning state-of-the-art task-independent representations in complex networks.\nDeepWalk Perozzi, Al-Rfou \u0026amp; Skiena (2014) Bryan Perozzi, Rami Al-Rfou, S. Skiena. (2014)\nDeepWalk: online learning of social representations\nKDD\nPaper Link\nInfluential Citation Count (1335), SS-ID (fff114cbba4f3ba900f33da574283e3de7f26c83)\nABSTRACT\nWe present DeepWalk, a novel approach for learning latent representations of vertices in a network. These latent representations encode social relations in a continuous vector space, which is easily exploited by statistical models. DeepWalk generalizes recent advancements in language modeling and unsupervised feature learning (or deep learning) from sequences of words to graphs. DeepWalk uses local information obtained from truncated random walks to learn latent representations by treating walks as the equivalent of sentences. We demonstrate DeepWalk\u0026rsquo;s latent representations on several multi-label network classification tasks for social networks such as BlogCatalog, Flickr, and YouTube. Our results show that DeepWalk outperforms challenging baselines which are allowed a global view of the network, especially in the presence of missing information. DeepWalk\u0026rsquo;s representations can provide F1 scores up to 10% higher than competing methods when labeled data is sparse. In some experiments, DeepWalk\u0026rsquo;s representations are able to outperform all baseline methods while using 60% less training data. DeepWalk is also scalable. It is an online learning algorithm which builds useful incremental results, and is trivially parallelizable. These qualities make it suitable for a broad class of real world applications such as network classification, and anomaly detection.\nLINE Tang et al. (2015) Jian Tang, Meng Qu, Mingzhe Wang, Ming Zhang, Jun Yan, Q. Mei. (2015)\nLINE: Large-scale Information Network Embedding\nWWW\nPaper Link\nInfluential Citation Count (832), SS-ID (0834e74304b547c9354b6d7da6fa78ef47a48fa8)\nABSTRACT\nThis paper studies the problem of embedding very large information networks into low-dimensional vector spaces, which is useful in many tasks such as visualization, node classification, and link prediction. Most existing graph embedding methods do not scale for real world information networks which usually contain millions of nodes. In this paper, we propose a novel network embedding method called the ``LINE,\u0026rsquo;\u0026rsquo; which is suitable for arbitrary types of information networks: undirected, directed, and/or weighted. The method optimizes a carefully designed objective function that preserves both the local and global network structures. An edge-sampling algorithm is proposed that addresses the limitation of the classical stochastic gradient descent and improves both the effectiveness and the efficiency of the inference. Empirical experiments prove the effectiveness of the LINE on a variety of real-world information networks, including language networks, social networks, and citation networks. The algorithm is very efficient, which is able to learn the embedding of a network with millions of vertices and billions of edges in a few hours on a typical single machine. The source code of the LINE is available online\\footnote{\\url{https://github.com/tangjianpku/LINE}}.\nDiff2Vec Rozemberczki \u0026amp; Sarkar (2018) Benedek Rozemberczki, R. Sarkar. (2018)\nFast Sequence-Based Embedding with Diffusion Graphs\nArXiv\nPaper Link\nInfluential Citation Count (5), SS-ID (d1764864dc0a676ff1732972e179fb2d8d4f564b)\nABSTRACT\nA graph embedding is a representation of graph vertices in a low- dimensional space, which approximately preserves properties such as distances between nodes. Vertex sequence-based embedding procedures use features extracted from linear sequences of nodes to create embeddings using a neural network. In this paper, we propose diffusion graphs as a method to rapidly generate vertex sequences for network embedding. Its computational efficiency is superior to previous methods due to simpler sequence generation, and it produces more accurate results. In experiments, we found that the performance relative to other methods improves with increasing edge density in the graph. In a community detection task, clustering nodes in the embedding space produces better results compared to other sequence-based embedding methods.\nWalklets Perozzi, Kulkarni \u0026amp; Skiena (2016) Walklets: Multiscale Graph Embeddings for Interpretable Network Classification\nArXiv\nPaper Link\nInfluential Citation Count (11), SS-ID (37cf46e45777e67676f80c9110bed675a9840590)\nABSTRACT\nWe present Walklets, a novel approach for learning multiscale representations of vertices in a network. These representations clearly encode multiscale vertex relationships in a continuous vector space suitable for multi-label classification problems. Unlike previous work, the latent features generated using Walklets are analytically derivable, and human interpretable. Walklets uses the offsets between vertices observed in a random walk to learn a series of latent representations, each which captures successively larger relationships. This variety of dependency information allows the same representation strategy to model phenomenon which occur at different scales. We demonstrate Walklets\u0026rsquo; latent representations on several multi-label network classification tasks for social networks such as BlogCatalog, Flickr, and YouTube. Our results show that Walklets outperforms new methods based on neural matrix factorization, and can scale to graphs with millions of vertices and edges.\nHARP Chen et al. (2018) Haochen Chen, Bryan Perozzi, Yifan Hu, S. Skiena. (2017)\nHARP: Hierarchical Representation Learning for Networks\nAAAI\nPaper Link\nInfluential Citation Count (32), SS-ID (ee9cc8e663d650ae96405ad680d6447066e6fb23)\nABSTRACT\nWe present HARP, a novel method for learning low dimensional embeddings of a graph\u0026rsquo;s nodes which preserves higher-order structural features. Our proposed method achieves this by compressing the input graph prior to embedding it, effectively avoiding troublesome embedding configurations (i.e. local minima) which can pose problems to non-convex optimization. HARP works by finding a smaller graph which approximates the global structure of its input. This simplified graph is used to learn a set of initial representations, which serve as good initializations for learning representations in the original, detailed graph. We inductively extend this idea, by decomposing a graph in a series of levels, and then embed the hierarchy of graphs from the coarsest one to the original graph. HARP is a general meta-strategy to improve all of the state-of-the-art neural algorithms for embedding graphs, including DeepWalk, LINE, and Node2vec. Indeed, we demonstrate that applying HARP\u0026rsquo;s hierarchical paradigm yields improved implementations for all three of these methods, as evaluated on both classification tasks on real-world graphs such as DBLP, BlogCatalog, CiteSeer, and Arxiv, where we achieve a performance gain over the original implementations by up to 14% Macro F1.\nTang \u0026amp; Liu (2009) Lei Tang, Huan Liu. (2009)\nRelational learning via latent social dimensions\nKDD\nPaper Link\nInfluential Citation Count (72), SS-ID (a505e4c2bf30cd88afe483f7541409e2ba5ab3d4)\nABSTRACT\nSocial media such as blogs, Facebook, Flickr, etc., presents data in a network format rather than classical IID distribution. To address the interdependency among data instances, relational learning has been proposed, and collective inference based on network connectivity is adopted for prediction. However, connections in social media are often multi-dimensional. An actor can connect to another actor for different reasons, e.g., alumni, colleagues, living in the same city, sharing similar interests, etc. Collective inference normally does not differentiate these connections. In this work, we propose to extract latent social dimensions based on network information, and then utilize them as features for discriminative learning. These social dimensions describe diverse affiliations of actors hidden in the network, and the discriminative learning can automatically determine which affiliations are better aligned with the class labels. Such a scheme is preferred when multiple diverse relations are associated with the same network. We conduct extensive experiments on social media data (one from a real-world blog site and the other from a popular content sharing site). Our model outperforms representative relational learning methods based on collective inference, especially when few labeled data are available. The sensitivity of this model and its connection to existing methods are also examined.\nFeng et al. (2017) Rui Feng, Yang Yang, Wenjie Hu, Fei Wu, Yueting Zhuang. (2017)\nRepresentation Learning for Scale-free Networks\nAAAI\nPaper Link\nInfluential Citation Count (3), SS-ID (464a60d8e67ab42d360c9be2d29f919d30312315)\nABSTRACT\nNetwork embedding aims to learn the low-dimensional representations of vertexes in a network, while structure and inherent properties of the network is preserved. Existing network embedding works primarily focus on preserving the microscopic structure, such as the first- and second-order proximity of vertexes, while the macroscopic scale-free property is largely ignored. Scale-free property depicts the fact that vertex degrees follow a heavy-tailed distribution (i.e., only a few vertexes have high degrees) and is a critical property of real-world networks, such as social networks. In this paper, we study the problem of learning representations for scale-free networks. We first theoretically analyze the difficulty of embedding and reconstructing a scale-free network in the Euclidean space, by converting our problem to the sphere packing problem. Then, we propose the \u0026ldquo;degree penalty\u0026rdquo; principle for designing scale-free property preserving network embedding algorithm: punishing the proximity between high-degree vertexes. We introduce two implementations of our principle by utilizing the spectral techniques and a skip-gram model respectively. Extensive experiments on six datasets show that our algorithms are able to not only reconstruct heavy-tailed distributed degree distribution, but also outperform state-of-the-art embedding models in various network mining tasks, such as vertex classification and link prediction.\nStruct2Vec Ribeiro, Saverese \u0026amp; Figueiredo (2017) Leonardo F. R. Ribeiro, Pedro H. P. Saverese, Daniel R. Figueiredo. (2017)\nstruc2vec: Learning Node Representations from Structural Identity\nKDD\nPaper Link\nInfluential Citation Count (87), SS-ID (0f7f5679615effcc4c9b98cf2deb17c30744a6d7)\nABSTRACT\nStructural identity is a concept of symmetry in which network nodes are identified according to the network structure and their relationship to other nodes. Structural identity has been studied in theory and practice over the past decades, but only recently has it been addressed with representational learning techniques. This work presents struc2vec, a novel and flexible framework for learning latent representations for the structural identity of nodes. struc2vec uses a hierarchy to measure node similarity at different scales, and constructs a multilayer graph to encode structural similarities and generate structural context for nodes. Numerical experiments indicate that state-of-the-art techniques for learning node representations fail in capturing stronger notions of structural identity, while struc2vec exhibits much superior performance in this task, as it overcomes limitations of prior approaches. As a consequence, numerical experiments indicate that struc2vec improves performance on classification tasks that depend more on structural identity.\nBiased-Graph2Vec Liu et al. (2020) Yan Liu, Xiaokun Zhang, Lian Liu, Gaojian Li. (2020)\nGraph Embedding Based on Characteristic of Rooted Subgraph Structure\nKSEM\nPaper Link\nInfluential Citation Count (0), SS-ID (60e8a34070dbbb8ef1b3ca4e789d20dd7c826ded)\nABSTRACT\nGiven the problem that currently distributed graph embedding models have not yet been effectively modeled of substructure similarity, biased-graph2vec, a graph embedding model based on structural characteristics of rooted subgraphs is proposed in this paper. This model, based on the distributed representation model of the graph, has modified its original random walk process and converted it to a random walk with weight bias based on structural similarity. The appropriate context is generated for all substructures. Based on preserving the tag features of the nodes and edges in the substructure, the representation of the substructure in the feature space depends more on the structural similarity itself. Biased-graph2vec calculates the graph representations with unsupervised algorithm and could build the model for both graphs and substructures via universal models, leaving complex feature engineering behind and has functional mobility. Meanwhile, this method models similar information among substructures, solving the problem that typical random walk strategies could not capture similarities of substructures with long distance. The experiments of graph classification are carried out on six open benchmark datasets. The comparison among our method, the graph kernel method, and the baseline method without considering the structural similarity of long-distance ions is made. Experiments show that the method this paper proposed has varying degrees inordinately improved the accuracy of classification tasks.\nGraphWave Donnat et al. (2017) C. Donnat, M. Zitnik, David Hallac, J. Leskovec. (2017)\nSpectral Graph Wavelets for Structural Role Similarity in Networks\nArXiv\nPaper Link\nInfluential Citation Count (9), SS-ID (ded841318dbc807c47608a697629fdc4fa3f01da)\nABSTRACT\nNodes residing in different parts of a graph can have similar structural roles within their local network topology. The identification of such roles provides key insight into the organization of networks and can also be used to inform machine learning on graphs. However, learning structural representations of nodes is a challenging unsupervised-learning task, which typically involves manually specifying and tailoring topological features for each node. Here we develop GRAPHWAVE, a method that represents each node’s local network neighborhood via a low-dimensional embedding by leveraging spectral graph wavelet diffusion patterns. We prove that nodes with similar local network neighborhoods will have similar GRAPHWAVE embeddings even though these nodes may reside in very different parts of the network. Our method scales linearly with the number of edges and does not require any hand-tailoring of topological features. We evaluate performance on both synthetic and real-world datasets, obtaining improvements of up to 71% over state-of-the-art baselines.\nGAT (Graph Attention) Abu-El-Haija et al. (2017) Sami Abu-El-Haija, Bryan Perozzi, Rami Al-Rfou, Alexander A. Alemi. (2017)\nWatch Your Step: Learning Node Embeddings via Graph Attention\nNeurIPS\nPaper Link\nInfluential Citation Count (13), SS-ID (49a5b5e65078eff512083d9de413d49a8aadc064)\nABSTRACT\nGraph embedding methods represent nodes in a continuous vector space, preserving different types of relational information from the graph. There are many hyper-parameters to these methods (e.g. the length of a random walk) which have to be manually tuned for every graph. In this paper, we replace previously fixed hyper-parameters with trainable ones that we automatically learn via backpropagation. In particular, we propose a novel attention model on the power series of the transition matrix, which guides the random walk to optimize an upstream objective. Unlike previous approaches to attention models, the method that we propose utilizes attention parameters exclusively on the data itself (e.g. on the random walk), and are not used by the model for inference. We experiment on link prediction tasks, as we aim to produce embeddings that best-preserve the graph structure, generalizing to unseen information. We improve state-of-the-art results on a comprehensive suite of real-world graph datasets including social, collaboration, and biological networks, where we observe that our graph attention model can reduce the error by up to 20%-40%. We show that our automatically-learned attention parameters can vary significantly per graph, and correspond to the optimal choice of hyper-parameter if we manually tune existing methods.\nVelickovic et al. (2017) Petar Velickovic, Guillem Cucurull, Arantxa Casanova, Adriana Romero, P. Lio’, Yoshua Bengio. (2017)\nGraph Attention Networks\nICLR\nPaper Link\nInfluential Citation Count (1371), SS-ID (33998aff64ce51df8dee45989cdca4b6b1329ec4)\nABSTRACT\nWe present graph attention networks (GATs), novel neural network architectures that operate on graph-structured data, leveraging masked self-attentional layers to address the shortcomings of prior methods based on graph convolutions or their approximations. By stacking layers in which nodes are able to attend over their neighborhoods\u0026rsquo; features, we enable (implicitly) specifying different weights to different nodes in a neighborhood, without requiring any kind of costly matrix operation (such as inversion) or depending on knowing the graph structure upfront. In this way, we address several key challenges of spectral-based graph neural networks simultaneously, and make our model readily applicable to inductive as well as transductive problems. Our GAT models have achieved or matched state-of-the-art results across four established transductive and inductive graph benchmarks: the Cora, Citeseer and Pubmed citation network datasets, as well as a protein-protein interaction dataset (wherein test graphs remain unseen during training).\nLiu et al. (2018) Ziqi Liu, Chaochao Chen, Longfei Li, Jun Zhou, Xiaolong Li, Le Song. (2018)\nGeniePath: Graph Neural Networks with Adaptive Receptive Paths\nAAAI\nPaper Link\nInfluential Citation Count (18), SS-ID (127af6effc74f073ac2442f6d82c944f562e2c0f)\nABSTRACT\nWe present, GeniePath, a scalable approach for learning adaptive receptive fields of neural networks defined on permutation invariant graph data. In GeniePath, we propose an adaptive path layer consists of two complementary functions designed for breadth and depth exploration respectively, where the former learns the importance of different sized neighborhoods, while the latter extracts and filters signals aggregated from neighbors of different hops away. Our method works in both transductive and inductive settings, and extensive experiments compared with competitive methods show that our approaches yield state-of-the-art results on large graphs.\nLee et al. (2018) J. B. Lee, Ryan A. Rossi, Sungchul Kim, Nesreen Ahmed, Eunyee Koh. (2018)\nAttention Models in Graphs\nACM Trans. Knowl. Discov. Data\nPaper Link\nInfluential Citation Count (1), SS-ID (cc23c580b7d8063415fb6eb512053d1079b849de)\nABSTRACT\nGraph-structured data arise naturally in many different application domains. By representing data as graphs, we can capture entities (i.e., nodes) as well as their relationships (i.e., edges) with each other. Many useful insights can be derived from graph-structured data as demonstrated by an ever-growing body of work focused on graph mining. However, in the real-world, graphs can be both large—with many complex patterns—and noisy, which can pose a problem for effective graph mining. An effective way to deal with this issue is to incorporate “attention” into graph mining solutions. An attention mechanism allows a method to focus on task-relevant parts of the graph, helping it to make better decisions. In this work, we conduct a comprehensive and focused survey of the literature on the emerging field of graph attention models. We introduce three intuitive taxonomies to group existing work. These are based on problem setting (type of input and output), the type of attention mechanism used, and the task (e.g., graph classification, link prediction). We motivate our taxonomies through detailed examples and use each to survey competing approaches from a unique standpoint. Finally, we highlight several challenges in the area and discuss promising directions for future work.\nMetapath2Vec Dong, Chawla \u0026amp; Swami (2017) Yuxiao Dong, N. Chawla, A. Swami. (2017)\nmetapath2vec: Scalable Representation Learning for Heterogeneous Networks\nKDD\nPaper Link\nInfluential Citation Count (164), SS-ID (c0af91371f426ff92117d2ccdadb2032bec23d2c)\nABSTRACT\nWe study the problem of representation learning in heterogeneous networks. Its unique challenges come from the existence of multiple types of nodes and links, which limit the feasibility of the conventional network embedding techniques. We develop two scalable representation learning models, namely metapath2vec and metapath2vec++. The metapath2vec model formalizes meta-path-based random walks to construct the heterogeneous neighborhood of a node and then leverages a heterogeneous skip-gram model to perform node embeddings. The metapath2vec++ model further enables the simultaneous modeling of structural and semantic correlations in heterogeneous networks. Extensive experiments show that metapath2vec and metapath2vec++ are able to not only outperform state-of-the-art embedding models in various heterogeneous network mining tasks, such as node classification, clustering, and similarity search, but also discern the structural and semantic correlations between diverse network objects.\nGenVector Yang, Tang \u0026amp; Cohen (2015) Zhilin Yang, Jie Tang, William W. Cohen. (2015)\nMulti-Modal Bayesian Embeddings for Learning Social Knowledge Graphs\nIJCAI\nPaper Link\nInfluential Citation Count (3), SS-ID (695d4c04f6e4f7ba5f771ac7853fdbaa81713ae8)\nABSTRACT\nWe study the extent to which online social networks can be connected to open knowledge bases. The problem is referred to as learning social knowledge graphs. We propose a multi-modal Bayesian embedding model, GenVector, to learn latent topics that generate word and network embeddings. GenVector leverages large-scale unlabeled data with embeddings and represents data of two modalities\u0026mdash;i.e., social network users and knowledge concepts\u0026mdash;in a shared latent topic space. Experiments on three datasets show that the proposed method clearly outperforms state-of-the-art methods. We then deploy the method on AMiner, a large-scale online academic search system with a network of 38,049,189 researchers with a knowledge base with 35,415,011 concepts. Our method significantly decreases the error rate in an online A/B test with live users.\nGEMSEC Rozemberczki et al. (2018) Benedek Rozemberczki, Ryan Davies, R. Sarkar, Charles Sutton. (2018)\nGEMSEC: Graph Embedding with Self Clustering\n2019 IEEE/ACM International Conference on Advances in Social Networks Analysis and Mining (ASONAM)\nPaper Link\nInfluential Citation Count (16), SS-ID (59be148a4b5f7e05cb3cb24afa1f6adad2cdfa29)\nABSTRACT\nModern graph embedding procedures can efficiently process graphs with millions of nodes. In this paper, we propose GEMSEC - a graph embedding algorithm which learns a clustering of the nodes simultaneously with computing their embedding. GEMSEC is a general extension of earlier work in the domain of sequence-based graph embedding. GEMSEC places nodes in an abstract feature space where the vertex features minimize the negative log-likelihood of preserving sampled vertex neighborhoods, and it incorporates known social network properties through a machine learning regularization. We present two new social network datasets and show that by simultaneously considering the embedding and clustering problems with respect to social properties, GEMSEC extracts high-quality clusters competitive with or superior to other community detection algorithms. In experiments, the method is found to be computationally efficient and robust to the choice of hyperparameters.\nDDRW (Discriminative Deep Random Walk) Li Zhu \u0026amp; Zhang (2016) Juzheng Li, Jun Zhu, Bo Zhang. (2016)\nDiscriminative Deep Random Walk for Network Classification\nACL\nPaper Link\nInfluential Citation Count (2), SS-ID (a6fd225417efdbf0bb9aef2ef2046335d2d0885e)\nABSTRACT\nDeep Random Walk (DeepWalk) can learn a latent space representation for describing the topological structure of a network. However, for relational network classification, DeepWalk can be suboptimal as it lacks a mechanism to optimize the objective of the target task. In this paper, we present Discriminative Deep Random Walk (DDRW), a novel method for relational network classification. By solving a joint optimization problem, DDRW can learn the latent space representations that well capture the topological structure and meanwhile are discriminative for the network classification task. Our experimental results on several real social networks demonstrate that DDRW significantly outperforms DeepWalk on multilabel network classification tasks, while retaining the topological structure in the latent space. DDRW is stable and consistently outperforms the baseline methods by various percentages of labeled data. DDRW is also an online method that is scalable and can be naturally parallelized.\nExponential Family Graph Embedding Çelikkanat \u0026amp; Malliaros (2019) Abdulkadir Çelikkanat, Fragkiskos D. Malliaros. (2019)\nExponential Family Graph Embeddings\nAAAI\nPaper Link\nInfluential Citation Count (0), SS-ID (b176355c33564beb8c7864572877ee4c7dcb40c4)\nABSTRACT\nRepresenting networks in a low dimensional latent space is a crucial task with many interesting applications in graph learning problems, such as link prediction and node classification. A widely applied network representation learning paradigm is based on the combination of random walks for sampling context nodes and the traditional \\textit{Skip-Gram} model to capture center-context node relationships. In this paper, we emphasize on exponential family distributions to capture rich interaction patterns between nodes in random walk sequences. We introduce the generic \\textit{exponential family graph embedding} model, that generalizes random walk-based network representation learning techniques to exponential family conditional distributions. We study three particular instances of this model, analyzing their properties and showing their relationship to existing unsupervised learning models. Our experimental evaluation on real-world datasets demonstrates that the proposed techniques outperform well-known baseline methods in two downstream machine learning tasks.\nDNGR (Deep Neural networks for learning Graph Representations) Cao, Lu \u0026amp; Xu (2016) Shaosheng Cao, Wei Lu, Qiongkai Xu. (2016)\nDeep Neural Networks for Learning Graph Representations\nAAAI\nPaper Link\nInfluential Citation Count (59), SS-ID (1a37f07606d60df365d74752857e8ce909f700b3)\nABSTRACT\nIn this paper, we propose a novel model for learning graph representations, which generates a low-dimensional vector representation for each vertex by capturing the graph structural information. Different from other previous research efforts, we adopt a random surfing model to capture graph structural information directly, instead of using the sampling-based method for generating linear sequences proposed by Perozzi et al. (2014). The advantages of our approach will be illustrated from both theorical and empirical perspectives. We also give a new perspective for the matrix factorization method proposed by Levy and Goldberg (2014), in which the pointwise mutual information (PMI) matrix is considered as an analytical solution to the objective function of the skip-gram model with negative sampling proposed by Mikolov et al. (2013). Unlike their approach which involves the use of the SVD for finding the low-dimensitonal projections from the PMI matrix, however, the stacked denoising autoencoder is introduced in our model to extract complex features and model non-linearities. To demonstrate the effectiveness of our model, we conduct experiments on clustering and visualization tasks, employing the learned vertex representations as features. Empirical results on datasets of varying sizes show that our model outperforms other stat-of-the-art models in such tasks.\nGCN (Graph Convolutional Network) Kipf \u0026amp; Welling (2016) Thomas Kipf, M. Welling. (2016)\nSemi-Supervised Classification with Graph Convolutional Networks\nICLR\nPaper Link\nInfluential Citation Count (3139), SS-ID (36eff562f65125511b5dfab68ce7f7a943c27478)\nABSTRACT\nWe present a scalable approach for semi-supervised learning on graph-structured data that is based on an efficient variant of convolutional neural networks which operate directly on graphs. We motivate the choice of our convolutional architecture via a localized first-order approximation of spectral graph convolutions. Our model scales linearly in the number of graph edges and learns hidden layer representations that encode both local graph structure and features of nodes. In a number of experiments on citation networks and on a knowledge graph dataset we demonstrate that our approach outperforms related methods by a significant margin.\nImprovements of GCN Chen, Zhu \u0026amp; Song (2017) Jianfei Chen, Jun Zhu, Le Song. (2017)\nStochastic Training of Graph Convolutional Networks with Variance Reduction\nICML\nPaper Link\nInfluential Citation Count (44), SS-ID (a60c69c2fae27ebbb73c87f7f2a4765556bd7f9f)\nABSTRACT\nGraph convolutional networks (GCNs) are powerful deep neural networks for graph-structured data. However, GCN computes the representation of a node recursively from its neighbors, making the receptive field size grow exponentially with the number of layers. Previous attempts on reducing the receptive field size by subsampling neighbors do not have a convergence guarantee, and their receptive field size per node is still in the order of hundreds. In this paper, we develop control variate based algorithms which allow sampling an arbitrarily small neighbor size. Furthermore, we prove new theoretical guarantee for our algorithms to converge to a local optimum of GCN. Empirical results show that our algorithms enjoy a similar convergence with the exact algorithm using only two neighbors per node. The runtime of our algorithms on a large Reddit dataset is only one seventh of previous neighbor sampling algorithms.\nChen, Ma \u0026amp; Xiao (2018) Jing Chen, Tengfei Ma, Cao Xiao. (2018)\nFastGCN: Fast Learning with Graph Convolutional Networks via Importance Sampling\nICLR\nPaper Link\nInfluential Citation Count (118), SS-ID (f19d3e0956d0f2daa3396fc6e9e7554a78a90710)\nABSTRACT\nThe graph convolutional networks (GCN) recently proposed by Kipf and Welling are an effective graph model for semi-supervised learning. This model, however, was originally designed to be learned with the presence of both training and test data. Moreover, the recursive neighborhood expansion across layers poses time and memory challenges for training with large, dense graphs. To relax the requirement of simultaneous availability of test data, we interpret graph convolutions as integral transforms of embedding functions under probability measures. Such an interpretation allows for the use of Monte Carlo approaches to consistently estimate the integrals, which in turn leads to a batched training scheme as we propose in this work\u0026mdash;FastGCN. Enhanced with importance sampling, FastGCN not only is efficient for training but also generalizes well for inference. We show a comprehensive set of experiments to demonstrate its effectiveness compared with GCN and related models. In particular, training is orders of magnitude more efficient while predictions remain comparably accurate.\nLei, Shi \u0026amp; Niu (2018) Minglong Lei, Yong Shi, Lingfeng Niu. (2018)\nThe Applications of Stochastic Models in Network Embedding: A Survey\n2018 IEEE/WIC/ACM International Conference on Web Intelligence (WI)\nPaper Link\nInfluential Citation Count (0), SS-ID (dbc0c4e613d2ae942694058861dd2a4aae6ff117)\nABSTRACT\nNetwork embedding is a promising topic that maps the vertices to the latent space while keeps the structural proximity in the original space. The network embedding task is difficult since the network vertices have no specific time or space orders. Models that used to extract information from images and texts with regular space or time structures can not be directly applied in network heading. The key feature of network embedding methods should be further exploited. Previous network embedding reviews mainly focus on the models and algorithms used in different methods. In this survey, we review the network embedding works in the stochastic perspective either in data side or model side. Roughly, the network embedding methods fall into three main categories: matrix based methods, random walk based methods and aggregated based methods. We focus on the applications of stochastic models in solving the challenges of network embedding in data processing and modeling following the line of the three categories.\nGraphSAINT Zeng et al. (2019) Hanqing Zeng, Hongkuan Zhou, Ajitesh Srivastava, R. Kannan, V. Prasanna. (2019)\nGraphSAINT: Graph Sampling Based Inductive Learning Method\nICLR\nPaper Link\nInfluential Citation Count (85), SS-ID (d589e4018278e219733b156d44d0ba881a32195e)\nABSTRACT\nGraph Convolutional Networks (GCNs) are powerful models for learning representations of attributed this http URL scale GCNs to large graphs, state-of-the-art methods use various layer sampling techniques to alleviate the \u0026ldquo;neighbor explosion\u0026rdquo; problem during minibatch training. Here we proposeGraphSAINT, a graph sampling based inductive learning method that improves training efficiency in a fundamentally different way. By a change of perspective, GraphSAINT constructs minibatches by sampling the training graph, rather than the nodes or edges across GCN layers. Each iteration, a complete GCN is built from the properly sampled subgraph. Thus, we ensure fixed number of well-connected nodes in all layers. We further propose normalization technique to eliminate bias, and sampling algorithms for variance reduction. Importantly, we can decouple the sampling process from the forward and backward propagation of training, and extend GraphSAINT with other graph samplers and GCN variants. Comparing with strong baselines using layer sampling, GraphSAINT demonstrates superior performance in both accuracy and training time on four large graphs.\nVGAE (Variational Graph AutoEncoder) Kipf \u0026amp; Welling (2016) Thomas Kipf, M. Welling. (2016)\nVariational Graph Auto-Encoders\nArXiv\nPaper Link\nInfluential Citation Count (347), SS-ID (54906484f42e871f7c47bbfe784a358b1448231f)\nABSTRACT\nWe introduce the variational graph auto-encoder (VGAE), a framework for unsupervised learning on graph-structured data based on the variational auto-encoder (VAE). This model makes use of latent variables and is capable of learning interpretable latent representations for undirected graphs. We demonstrate this model using a graph convolutional network (GCN) encoder and a simple inner product decoder. Our model achieves competitive results on a link prediction task in citation networks. In contrast to most existing models for unsupervised learning on graph-structured data and link prediction, our model can naturally incorporate node features, which significantly improves predictive performance on a number of benchmark datasets.\nGraphSAGE Hamilton, Ying \u0026amp; Leskovec (2017) Inductive Representation Learning on Large Graphs\nNIPS\nPaper Link\nInfluential Citation Count (1254), SS-ID (6b7d6e6416343b2a122f8416e69059ce919026ef)\nABSTRACT\nLow-dimensional embeddings of nodes in large graphs have proved extremely useful in a variety of prediction tasks, from content recommendation to identifying protein functions. However, most existing approaches require that all nodes in the graph are present during training of the embeddings; these previous approaches are inherently transductive and do not naturally generalize to unseen nodes. Here we present GraphSAGE, a general, inductive framework that leverages node feature information (e.g., text attributes) to efficiently generate node embeddings for previously unseen data. Instead of training individual embeddings for each node, we learn a function that generates embeddings by sampling and aggregating features from a node\u0026rsquo;s local neighborhood. Our algorithm outperforms strong baselines on three inductive node-classification benchmarks: we classify the category of unseen nodes in evolving information graphs based on citation and Reddit post data, and we show that our algorithm generalizes to completely unseen graphs using a multi-graph dataset of protein-protein interactions.\nPinSAGE Ying et al. (2018) Rex Ying, Ruining He, Kaifeng Chen, Pong Eksombatchai, William L. Hamilton, J. Leskovec. (2018)\nGraph Convolutional Neural Networks for Web-Scale Recommender Systems\nKDD\nPaper Link\nInfluential Citation Count (128), SS-ID (6c96c2d4a3fbd572fef2d59cb856521ee1746789)\nABSTRACT\nRecent advancements in deep neural networks for graph-structured data have led to state-of-the-art performance on recommender system benchmarks. However, making these methods practical and scalable to web-scale recommendation tasks with billions of items and hundreds of millions of users remains an unsolved challenge. Here we describe a large-scale deep recommendation engine that we developed and deployed at Pinterest. We develop a data-efficient Graph Convolutional Network (GCN) algorithm, which combines efficient random walks and graph convolutions to generate embeddings of nodes (i.e., items) that incorporate both graph structure as well as node feature information. Compared to prior GCN approaches, we develop a novel method based on highly efficient random walks to structure the convolutions and design a novel training strategy that relies on harder-and-harder training examples to improve robustness and convergence of the model. We also develop an efficient MapReduce model inference algorithm to generate embeddings using a trained model. Overall, we can train on and embed graphs that are four orders of magnitude larger than typical GCN implementations. We show how GCN embeddings can be used to make high-quality recommendations in various settings at Pinterest, which has a massive underlying graph with 3 billion nodes representing pins and boards, and 17 billion edges. According to offline metrics, user studies, as well as A/B tests, our approach generates higher-quality recommendations than comparable deep learning based systems. To our knowledge, this is by far the largest application of deep graph embeddings to date and paves the way for a new generation of web-scale recommender systems based on graph convolutional architectures.\nGeniepath Liu et al. (2018) Ziqi Liu, Chaochao Chen, Longfei Li, Jun Zhou, Xiaolong Li, Le Song. (2018)\nGeniePath: Graph Neural Networks with Adaptive Receptive Paths\nAAAI\nPaper Link\nInfluential Citation Count (18), SS-ID (127af6effc74f073ac2442f6d82c944f562e2c0f)\nABSTRACT\nWe present, GeniePath, a scalable approach for learning adaptive receptive fields of neural networks defined on permutation invariant graph data. In GeniePath, we propose an adaptive path layer consists of two complementary functions designed for breadth and depth exploration respectively, where the former learns the importance of different sized neighborhoods, while the latter extracts and filters signals aggregated from neighbors of different hops away. Our method works in both transductive and inductive settings, and extensive experiments compared with competitive methods show that our approaches yield state-of-the-art results on large graphs.\nMPNN (Message Passing Neural Network) Gilmer et al. (2017) J. Gilmer, S. Schoenholz, Patrick F. Riley, Oriol Vinyals, George E. Dahl. (2017)\nNeural Message Passing for Quantum Chemistry\nICML\nPaper Link\nInfluential Citation Count (440), SS-ID (e24cdf73b3e7e590c2fe5ecac9ae8aa983801367)\nABSTRACT\nSupervised learning on molecules has incredible potential to be useful in chemistry, drug discovery, and materials science. Luckily, several promising and closely related neural network models invariant to molecular symmetries have already been described in the literature. These models learn a message passing algorithm and aggregation procedure to compute a function of their entire input graph. At this point, the next step is to find a particularly effective variant of this general approach and apply it to chemical prediction benchmarks until we either solve them or reach the limits of the approach. In this paper, we reformulate existing models into a single common framework we call Message Passing Neural Networks (MPNNs) and explore additional novel variations within this framework. Using MPNNs we demonstrate state of the art results on an important molecular property prediction benchmark; these results are strong enough that we believe future work should focus on datasets with larger molecules or more accurate ground truth labels.\nGraph Generative Adversarial Networks Ding, Tang \u0026amp; Zhang (2018) Ming Ding, Jie Tang, Jie Zhang. (2018)\nSemi-supervised Learning on Graphs with Generative Adversarial Nets\nCIKM\nPaper Link\nInfluential Citation Count (5), SS-ID (b8da4337c92acda632e8138be1b525a3aef54b85)\nABSTRACT\nWe investigate how generative adversarial nets (GANs) can help semi-supervised learning on graphs. We first provide insights on working principles of adversarial learning over graphs and then present GraphSGAN, a novel approach to semi-supervised learning on graphs. In GraphSGAN, generator and classifier networks play a novel competitive game. At equilibrium, generator generates fake samples in low-density areas between subgraphs. In order to discriminate fake samples from the real, classifier implicitly takes the density property of subgraph into consideration. An efficient adversarial learning algorithm has been developed to improve traditional normalized graph Laplacian regularization with a theoretical guarantee. Experimental results on several different genres of datasets show that the proposed GraphSGAN significantly outperforms several state-of-the-art methods. GraphSGAN can be also trained using mini-batch, thus enjoys the scalability advantage.\nYu et al. (2018) Wenchao Yu, Cheng Zheng, Wei Cheng, C. Aggarwal, Dongjin Song, Bo Zong, Haifeng Chen, Wei Wang. (2018)\nLearning Deep Network Representations with Adversarially Regularized Autoencoders\nKDD\nPaper Link\nInfluential Citation Count (6), SS-ID (dbf125bfe07856a63d4aab612c0063fc8c7b6484)\nABSTRACT\nThe problem of network representation learning, also known as network embedding, arises in many machine learning tasks assuming that there exist a small number of variabilities in the vertex representations which can capture the \u0026ldquo;semantics\u0026rdquo; of the original network structure. Most existing network embedding models, with shallow or deep architectures, learn vertex representations from the sampled vertex sequences such that the low-dimensional embeddings preserve the locality property and/or global reconstruction capability. The resultant representations, however, are difficult for model generalization due to the intrinsic sparsity of sampled sequences from the input network. As such, an ideal approach to address the problem is to generate vertex representations by learning a probability density function over the sampled sequences. However, in many cases, such a distribution in a low-dimensional manifold may not always have an analytic form. In this study, we propose to learn the network representations with adversarially regularized autoencoders (NetRA). NetRA learns smoothly regularized vertex representations that well capture the network structure through jointly considering both locality-preserving and global reconstruction constraints. The joint inference is encapsulated in a generative adversarial training process to circumvent the requirement of an explicit prior distribution, and thus obtains better generalization performance. We demonstrate empirically how well key properties of the network structure are captured and the effectiveness of NetRA on a variety of tasks, including network reconstruction, link prediction, and multi-label classification.\nARVGA (Adversarially Regularized Variational Graph AutoEncoder) Pan et al. (2019) Shirui Pan, Ruiqi Hu, S. Fung, Guodong Long, Jing Jiang, Chengqi Zhang. (2019)\nLearning Graph Embedding With Adversarial Training Methods\nIEEE Transactions on Cybernetics\nPaper Link\nInfluential Citation Count (11), SS-ID (914fbae74420475d54c8099c5921b5f799c1c6c7)\nABSTRACT\nGraph embedding aims to transfer a graph into vectors to facilitate subsequent graph-analytics tasks like link prediction and graph clustering. Most approaches on graph embedding focus on preserving the graph structure or minimizing the reconstruction errors for graph data. They have mostly overlooked the embedding distribution of the latent codes, which unfortunately may lead to inferior representation in many cases. In this article, we present a novel adversarially regularized framework for graph embedding. By employing the graph convolutional network as an encoder, our framework embeds the topological information and node content into a vector representation, from which a graph decoder is further built to reconstruct the input graph. The adversarial training principle is applied to enforce our latent codes to match a prior Gaussian or uniform distribution. Based on this framework, we derive two variants of the adversarial models, the adversarially regularized graph autoencoder (ARGA) and its variational version, and adversarially regularized variational graph autoencoder (ARVGA), to learn the graph embedding effectively. We also exploit other potential variations of ARGA and ARVGA to get a deeper understanding of our designs. Experimental results that compared 12 algorithms for link prediction and 20 algorithms for graph clustering validate our solutions.\nDGGAN Zhu et al. (2020) Shijie Zhu, Jianxin Li, Hao Peng, Senzhang Wang, Philip S. Yu, Lifang He. (2020)\nAdversarial Directed Graph Embedding\nAAAI\nPaper Link\nInfluential Citation Count (0), SS-ID (0d4677ce389c1c1ef02c7d4e206d902c4f51bdb3)\nABSTRACT\nNode representation learning for directed graphs is critically important to facilitate many graph mining tasks. To capture the directed edges between nodes, existing methods mostly learn two embedding vectors for each node, source vector and target vector. However, these methods learn the source and target vectors separately. For the node with very low indegree or outdegree, the corresponding target vector or source vector cannot be effectively learned. In this paper, we propose a novel Directed Graph embedding framework based on Generative Adversarial Network, called DGGAN. The main idea is to use adversarial mechanisms to deploy a discriminator and two generators that jointly learn each node\u0026rsquo;s source and target vectors. For a given node, the two generators are trained to generate its fake target and source neighbor nodes from the same underlying distribution, and the discriminator aims to distinguish whether a neighbor node is real or fake. The two generators are formulated into a unified framework and could mutually reinforce each other to learn more robust source and target vectors. Extensive experiments show that DGGAN consistently and significantly outperforms existing state-of-the-art methods across multiple graph mining tasks on directed graphs.\nAnonymized GCN Liu (2020) Ao Liu. (2020)\nAnonymized GCN: A Novel Robust Graph Embedding Method via Hiding Node Position in Noise\nArXiv\nPaper Link\nInfluential Citation Count (0), SS-ID (9bad9deef8ebd658417d038849f3ca25b94f136b)\nABSTRACT\nGraph convolution network (GCN) have achieved state-of-the-art performance in the task of node prediction in the graph structure. However, with the gradual various of graph attack methods, there are lack of research on the robustness of GCN. At this paper, we will design a robust GCN method for node prediction tasks. Considering the graph structure contains two types of information: node information and connection information, and attackers usually modify the connection information to complete the interference with the prediction results of the node, we first proposed a method to hide the connection information in the generator, named Anonymized GCN (AN-GCN). By hiding the connection information in the graph structure in the generator through adversarial training, the accurate node prediction can be completed only by the node number rather than its specific position in the graph. Specifically, we first demonstrated the key to determine the embedding of a specific node: the row corresponding to the node of the eigenmatrix of the Laplace matrix, by target it as the output of the generator, we designed a method to hide the node number in the noise. Take the corresponding noise as input, we will obtain the connection structure of the node instead of directly obtaining. Then the encoder and decoder are spliced both in discriminator, so that after adversarial training, the generator and discriminator can cooperate to complete the encoding and decoding of the graph, then complete the node prediction. Finally, All node positions can generated by noise at the same time, that is to say, the generator will hides all the connection information of the graph structure. The evaluation shows that we only need to obtain the initial features and node numbers of the nodes to complete the node prediction, and the accuracy did not decrease, but increased by 0.0293.\nRASE Hettige et al. (2020) B. Hettige, Weiqing Wang, Yuan-Fang Li, Wray L. Buntine. (2020)\nRobust Attribute and Structure Preserving Graph Embedding\nPAKDD\nPaper Link\nInfluential Citation Count (0), SS-ID (b40f3e3b7bb11949b26fc97febdc2c0d973b8021)\nABSTRACT\nGraph embedding methods are useful for a wide range of graph analysis tasks including link prediction and node classification. Most graph embedding methods learn only the topological structure of graphs. Nevertheless, it has been shown that the incorporation of node attributes is beneficial in improving the expressive power of node embeddings. However, real-world graphs are often noisy in terms of structure and/or attributes (missing and/or erroneous edges/attributes). Most existing graph embedding methods are susceptible to this noise, as they do not consider uncertainty during the modelling process. In this paper, we introduce RASE, a Robust Attribute and Structure preserving graph Embedding model. RASE is a novel graph representation learning model which effectively preserves both graph structure and node attributes through a unified loss function. To be robust, RASE uses a denoising attribute auto-encoder to deal with node attribute noise, and models uncertainty in the embedding space as Gaussians to cope with graph structure noise. We evaluate the performance of RASE through an extensive experimental study on various real-world datasets. Results demonstrate that RASE outperforms state-of-the-art embedding methods on multiple graph analysis tasks and is robust to both structure and attribute noise.\nGraph Embedding with Data Uncertainty Laakom et al. (2020) Firas Laakom, Jenni Raitoharju, N. Passalis, Alexandros Iosifidis, M. Gabbouj. (2020)\nGraph Embedding With Data Uncertainty\nIEEE Access\nPaper Link\nInfluential Citation Count (0), SS-ID (021e3e3f63194c5508e71706122372e96fdb1cdd)\nABSTRACT\nSpectral-based subspace learning is a common data preprocessing step in many machine learning pipelines. The main aim is to learn a meaningful low dimensional embedding of the data. However, most subspace learning methods do not take into consideration possible measurement inaccuracies or artifacts that can lead to data with high uncertainty. Thus, learning directly from raw data can be misleading and can negatively impact the accuracy. In this paper, we propose to model artifacts in training data using probability distributions; each data point is represented by a Gaussian distribution centered at the original data point and having a variance modeling its uncertainty. We reformulate the Graph Embedding framework to make it suitable for learning from distributions and we study as special cases the Linear Discriminant Analysis and the Marginal Fisher Analysis techniques. Furthermore, we propose two schemes for modeling data uncertainty based on pair-wise distances in an unsupervised and a supervised contexts.\nAAVGA (Adversarial Attention Variational Graph AutoEncoder) Weng, Zhang \u0026amp; Dou (2020) Ziqiang Weng, Weiyu Zhang, Wei Dou. (2020)\nAdversarial Attention-Based Variational Graph Autoencoder\nIEEE Access\nPaper Link\nInfluential Citation Count (0), SS-ID (989afdf64a0df329004de086cbc9057a9d8634f4)\nABSTRACT\nAutoencoders have been successfully used for graph embedding, and many variants have been proven to effectively express graph data and conduct graph analysis in low-dimensional space. However, previous methods ignore the structure and properties of the reconstructed graph, or they do not consider the potential data distribution in the graph, which typically leads to unsatisfactory graph embedding performance. In this paper, we propose the adversarial attention variational graph autoencoder (AAVGA), which is a novel framework that incorporates attention networks into the encoder part and uses an adversarial mechanism in embedded training. The encoder involves node neighbors in the representation of nodes by stacking attention layers, which can further improve the graph embedding performance of the encoder. At the same time, due to the adversarial mechanism, the distribution of the potential features that are generated by the encoder are closer to the actual distribution of the original graph data; thus, the decoder generates a graph that is closer to the original graph. Experimental results prove that AAVGA performs competitively with state-of-the-art popular graph encoders on three citation datasets.\nGSSNN (Graph Smoothing Splines Neural Networks) Zhu et al. (2020) Shichao Zhu, Lewei Zhou, Shirui Pan, Chuan Zhou, Guiying Yan, Bin Wang. (2020)\nGSSNN: Graph Smoothing Splines Neural Networks\nAAAI\nPaper Link\nInfluential Citation Count (0), SS-ID (2a3e3607fb9fbfa0d637946ca48035e68e7fee45)\nABSTRACT\nGraph Neural Networks (GNNs) have achieved state-of-the-art performance in many graph data analysis tasks. However, they still suffer from two limitations for graph representation learning. First, they exploit non-smoothing node features which may result in suboptimal embedding and degenerated performance for graph classification. Second, they only exploit neighbor information but ignore global topological knowledge. Aiming to overcome these limitations simultaneously, in this paper, we propose a novel, flexible, and end-to-end framework, Graph Smoothing Splines Neural Networks (GSSNN), for graph classification. By exploiting the smoothing splines, which are widely used to learn smoothing fitting function in regression, we develop an effective feature smoothing and enhancement module Scaled Smoothing Splines (S3) to learn graph embedding. To integrate global topological information, we design a novel scoring module, which exploits closeness, degree, as well as self-attention values, to select important node features as knots for smoothing splines. These knots can be potentially used for interpreting classification results. In extensive experiments on biological and social datasets, we demonstrate that our model achieves state-of-the-arts and GSSNN is superior in learning more robust graph representations. Furthermore, we show that S3 module is easily plugged into existing GNNs to improve their performance.\nVHKRep (Variable Heat Kernel Representation) Jing et al. (2020) Yongjun Jing, Hao Wang, Kun Shao, X. Huo, Yangyang Zhang. (2020)\nUnsupervised Graph Representation Learning With Variable Heat Kernel\nIEEE Access\nPaper Link\nInfluential Citation Count (1), SS-ID (b48fa95aa2a63466c87d176ee2caf4e5b975c085)\nABSTRACT\nGraph representation learning aims to learn a low-dimension latent representation of nodes, and the learned representation is used for downstream graph analysis tasks. However, most of the existing graph embedding models focus on how to aggregate all the neighborhood node features to encode the semantic information into the representation and neglect the global structural features of the node such as community structure and centrality. In the paper, we propose a novel unsupervised graph representation learning method (VHKRep), where a variable heat kernel is designed to better capture implicit global features via heat diffusion with the different time scale and generate the robust node representation. We conduct extensive experiment on three real-world datasets for node classification and link prediction tasks. Compared with the state-of-the-art seven models, the experimental results demonstrate the effectiveness of our proposed method on both node classification and link prediction tasks.\nTADW (Text-Associated DeepWalk) Yang et al. (2015) Cheng Yang, Zhiyuan Liu, Deli Zhao, Maosong Sun, Edward Y. Chang. (2015)\nNetwork Representation Learning with Rich Text Information\nIJCAI\nPaper Link\nInfluential Citation Count (162), SS-ID (fce14c6aa64e888456256ac6796744683165a0ff)\nABSTRACT\nRepresentation learning has shown its effectiveness in many tasks such as image classification and text mining. Network representation learning aims at learning distributed vector representation for each vertex in a network, which is also increasingly recognized as an important aspect for network analysis. Most network representation learning methods investigate network structures for learning. In reality, network vertices contain rich information (such as text), which cannot be well applied with algorithmic frameworks of typical representation learning methods. By proving that DeepWalk, a state-of-the-art network representation method, is actually equivalent to matrix factorization (MF), we propose text-associated DeepWalk (TADW). TADW incorporates text features of vertices into network representation learning under the framework of matrix factorization. We evaluate our method and various baseline methods by applying them to the task of multi-class classification of vertices. The experimental results show that, our method outperforms other baselines on all three datasets, especially when networks are noisy and training ratio is small. The source code of this paper can be obtained from https://github.com/albertyang33/TADW.\nPLE Ren et al. (2016) Xiang Ren, Wenqi He, Meng Qu, Clare R. Voss, Heng Ji, Jiawei Han. (2016)\nLabel Noise Reduction in Entity Typing by Heterogeneous Partial-Label Embedding\nKDD\nPaper Link\nInfluential Citation Count (18), SS-ID (2a1d2b775997d6e2e42a054ea0ed456af1060796)\nABSTRACT\nCurrent systems of fine-grained entity typing use distant supervision in conjunction with existing knowledge bases to assign categories (type labels) to entity mentions. However, the type labels so obtained from knowledge bases are often noisy (i.e., incorrect for the entity mention\u0026rsquo;s local context). We define a new task, Label Noise Reduction in Entity Typing (LNR), to be the automatic identification of correct type labels (type-paths) for training examples, given the set of candidate type labels obtained by distant supervision with a given type hierarchy. The unknown type labels for individual entity mentions and the semantic similarity between entity types pose unique challenges for solving the LNR task. We propose a general framework, called PLE, to jointly embed entity mentions, text features and entity types into the same low-dimensional space where, in that space, objects whose types are semantically close have similar representations. Then we estimate the type-path for each training example in a top-down manner using the learned embeddings. We formulate a global objective for learning the embeddings from text corpora and knowledge bases, which adopts a novel margin-based loss that is robust to noisy labels and faithfully models type correlation derived from knowledge bases. Our experiments on three public typing datasets demonstrate the effectiveness and robustness of PLE, with an average of 25% improvement in accuracy compared to next best method.\nRTM (Relational Topic Model) Chang \u0026amp; Blei (2009) Jonathan Chang, D. Blei. (2009)\nRelational Topic Models for Document Networks\nAISTATS\nPaper Link\nInfluential Citation Count (82), SS-ID (9f68d27df3a4c4be8636f376cb15f77e55a2f496)\nABSTRACT\nWe develop the relational topic model (RTM), a model of documents and the links between them. For each pair of documents, the RTM models their link as a binary random variable that is conditioned on their contents. The model can be used to summarize a network of documents, predict links between them, and predict words within them. We derive efficient inference and learning algorithms based on variational methods and evaluate the predictive performance of the RTM for large networks of scientific abstracts and web documents.\nPLDNE (Probabilistic Latent Document Netowrk Embedding) Le \u0026amp; Lauw (2014) Tuan M. V. Le, Hady W. Lauw. (2014)\nProbabilistic Latent Document Network Embedding\n2014 IEEE International Conference on Data Mining\nPaper Link\nInfluential Citation Count (8), SS-ID (24f7d72e92cadfa5c84949537639ce084b9d2092)\nABSTRACT\nA document network refers to a data type that can be represented as a graph of vertices, where each vertex is associated with a text document. Examples of such a data type include hyperlinked Web pages, academic publications with citations, and user profiles in social networks. Such data have very high-dimensional representations, in terms of text as well as network connectivity. In this paper, we study the problem of embedding, or finding a low-dimensional representation of a document network that \u0026ldquo;preserves\u0026rdquo; the data as much as possible. These embedded representations are useful for various applications driven by dimensionality reduction, such as visualization or feature selection. While previous works in embedding have mostly focused on either the textual aspect or the network aspect, we advocate a holistic approach by finding a unified low-rank representation for both aspects. Moreover, to lend semantic interpretability to the low-rank representation, we further propose to integrate topic modeling and embedding within a joint model. The gist is to join the various representations of a document (words, links, topics, and coordinates) within a generative model, and to estimate the hidden representations through MAP estimation. We validate our model on real-life document networks, showing that it outperforms comparable baselines comprehensively on objective evaluation metrics.\nAuthor2Vec Ganguly et al. (2016) Ganesh Jawahar, S. Ganguly, Manish Gupta, Vasudeva Varma, Vikram Pudi. (2016)\nAuthor2Vec: Learning Author Representations by Combining Content and Link Information\nWWW\nPaper Link\nInfluential Citation Count (3), SS-ID (aee808e9c5fb20b2dd1a51bb020112cdb908d80b)\nABSTRACT\nIn this paper, we consider the problem of learning representations for authors from bibliographic co-authorship networks. Existing methods for deep learning on graphs, such as DeepWalk, suffer from link sparsity problem as they focus on modeling the link information only. We hypothesize that capturing both the content and link information in a unified way will help mitigate the sparsity problem. To this end, we present a novel model \u0026lsquo;Author2Vec\u0026rsquo;, which learns low-dimensional author representations such that authors who write similar content and share similar network structure are closer in vector space. Such embeddings are useful in a variety of applications such as link prediction, node classification, recommendation and visualization. The author embeddings we learn are empirically shown to outperform DeepWalk by 2.35% and 0.83% for link prediction and clustering task respectively.\nARE (Augmented Relation Embedding) Lin, Liu \u0026amp; Chen (2005) Yen-Yu Lin, Tyng-Luh Liu, Hwann-Tzong Chen. (2005)\nSemantic manifold learning for image retrieval\nMULTIMEDIA \u0026lsquo;05\nPaper Link\nInfluential Citation Count (12), SS-ID (7438604d467c64156fcb3e86556d80f0ca72342d)\nABSTRACT\nLearning the user\u0026rsquo;s semantics for CBIR involves two different sources of information: the similarity relations entailed by the content-based features, and the relevance relations specified in the feedback. Given that, we propose an augmented relation embedding (ARE) to map the image space into a semantic manifold that faithfully grasps the user\u0026rsquo;s preferences. Besides ARE, we also look into the issues of selecting a good feature set for improving the retrieval performance. With these two aspects of efforts we have established a system that yields far better results than those previously reported. Overall, our approach can be characterized by three key properties: 1) The framework uses one relational graph to describe the similarity relations, and the other two to encode the relevant/irrelevant relations indicated in the feedback. 2) With the relational graphs so defined, learning a semantic manifold can be transformed into solving a constrained optimization problem, and is reduced to the ARE algorithm accounting for both the representation and the classification points of views. 3) An image representation based on augmented features is introduced to couple with the ARE learning. The use of these features is significant in capturing the semantics concerning different scales of image regions. We conclude with experimental results and comparisons to demonstrate the effectiveness of our method.\nLearning Image and User Features for Recommendation Geng et al. (2015) Xue Geng, Hanwang Zhang, Jingwen Bian, Tat-Seng Chua. (2015)\nLearning Image and User Features for Recommendation in Social Networks\n2015 IEEE International Conference on Computer Vision (ICCV)\nPaper Link\nInfluential Citation Count (11), SS-ID (15f5721502c2905c555a4eb0a110d6fc211c1fb2)\nABSTRACT\nGood representations of data do help in many machine learning tasks such as recommendation. It is often a great challenge for traditional recommender systems to learn representative features of both users and images in large social networks, in particular, social curation networks, which are characterized as the extremely sparse links between users and images, and the extremely diverse visual contents of images. To address the challenges, we propose a novel deep model which learns the unified feature representations for both users and images. This is done by transforming the heterogeneous user-image networks into homogeneous low-dimensional representations, which facilitate a recommender to trivially recommend images to users by feature similarity. We also develop a fast online algorithm that can be easily scaled up to large networks in an asynchronously parallel way. We conduct extensive experiments on a representative subset of Pinterest, containing 1,456,540 images and 1,000,000 users. Results of image recommendation experiments demonstrate that our feature learning approach significantly outperforms other state-of-the-art recommendation methods.\nLearning Features from Large-Scale, Noisy and Social Image-Tag Collection Zhang et al. (2015) Hanwang Zhang, Xindi Shang, Huanbo Luan, Yang Yang, Tat-Seng Chua. (2015)\nLearning Features from Large-Scale, Noisy and Social Image-Tag Collection\nACM Multimedia\nPaper Link\nInfluential Citation Count (1), SS-ID (7449864adc5d491fd0b2abf83a218429ce7834d4)\nABSTRACT\nFeature representation for multimedia content is the key to the progress of many fundamental multimedia tasks. Although recent advances in deep feature learning offer a promising route towards these tasks, they are limited in application to domains where high-quality and large-scale training data are hard to obtain. In this paper, we propose a novel deep feature learning paradigm based on large, noisy and social image-tag collections, which can be acquired from the inexhaustible social multimedia content on the Web. Instead of learning features from high-quality image-label supervision, we propose to learn from the image-word semantic relations, in a way of seeking a unified image-word embedding space, where the pairwise feature similarities preserve the semantic relations in the original image-word pairs. We offer an easy-to-use implementation for the proposed paradigm, which is fast and compatible for integrating into any state-of-the-art deep architectures. Experiments on NUSWIDE benchmark demonstrate that the features learned by our method significantly outperforms other state-of-the-art ones.\nLearning from Collective Intelligence Zhang et al. (2017) Hanwang Zhang, Xindi Shang, Huanbo Luan, Meng Wang, Tat-Seng Chua. (2016)\nLearning from Collective Intelligence\nACM Trans. Multim. Comput. Commun. Appl.\nPaper Link\nInfluential Citation Count (4), SS-ID (4f3417e73528025a5429547814e5a2fd91deb818)\nABSTRACT\nFeature representation for visual content is the key to the progress of many fundamental applications such as annotation and cross-modal retrieval. Although recent advances in deep feature learning offer a promising route towards these tasks, they are limited in application domains where high-quality and large-scale training data are expensive to obtain. In this article, we propose a novel deep feature learning paradigm based on social collective intelligence, which can be acquired from the inexhaustible social multimedia content on the Web, in particular, largely social images and tags. Differing from existing feature learning approaches that rely on high-quality image-label supervision, our weak supervision is acquired by mining the visual-semantic embeddings from noisy, sparse, and diverse social image collections. The resultant image-word embedding space can be used to (1) fine-tune deep visual models for low-level feature extractions and (2) seek sparse representations as high-level cross-modal features for both image and text. We offer an easy-to-use implementation for the proposed paradigm, which is fast and compatible with any state-of-the-art deep architectures. Extensive experiments on several benchmarks demonstrate that the cross-modal features learned by our paradigm significantly outperforms others in various applications such as content-based retrieval, classification, and image captioning.\nCENE (Content-Enhanced Network Embedding) Sun et al. (2016) Xiaofei Sun, Jiang Guo, Xiao Ding, Ting Liu. (2016)\nA General Framework for Content-enhanced Network Representation Learning\nArXiv\nPaper Link\nInfluential Citation Count (11), SS-ID (1268d2ae95f0b128678d6ce033ba8ea7f0d98be1)\nABSTRACT\nThis paper investigates the problem of network embedding, which aims at learning low-dimensional vector representation of nodes in networks. Most existing network embedding methods rely solely on the network structure, i.e., the linkage relationships between nodes, but ignore the rich content information associated with it, which is common in real world networks and beneficial to describing the characteristics of a node. In this paper, we propose content-enhanced network embedding (CENE), which is capable of jointly leveraging the network structure and the content information. Our approach integrates text modeling and structure modeling in a general framework by treating the content information as a special kind of node. Experiments on several real world net- works with application to node classification show that our models outperform all existing network embedding methods, demonstrating the merits of content information and joint learning.\nHSCA model (Homophily, Structure and Content Augmented) Zhang et al. (2016) Daokun Zhang, Jie Yin, Xingquan Zhu, Chengqi Zhang. (2016)\nHomophily, Structure, and Content Augmented Network Representation Learning\n2016 IEEE 16th International Conference on Data Mining (ICDM)\nPaper Link\nInfluential Citation Count (4), SS-ID (4cc10f77819ad376ea539074c2de14a8999e3269)\nABSTRACT\nAdvances in social networking and communication technologies have witnessed an increasing number of applications where data is not only characterized by rich content information, but also connected with complex relationships representing social roles and dependencies between individuals. To enable knowledge discovery from such networked data, network representation learning (NRL) aims to learn vector representations for network nodes, such that off-the-shelf machine learning algorithms can be directly applied. To date, existing NRL methods either primarily focus on network structure or simply combine node content and topology for learning. We argue that in information networks, information is mainly originated from three sources: (1) homophily, (2) topology structure, and (3) node content. Homophily states social phenomenon where individuals sharing similar attributes (content) tend to be directly connected through local relational ties, while topology structure emphasizes more on global connections. To ensure effective network representation learning, we propose to augment three information sources into one learning objective function, so that the interplay roles between three parties are enforced by requiring the learned network representations (1) being consistent with node content and topology structure, and also (2) following the social homophily constraints in the learned space. Experiments on multi-class node classification demonstrate that the representations learned by the proposed method consistently outperform state-of-the-art NRL methods, especially for very sparsely labeled networks.\nDeepBrowse Chen, Anantharam \u0026amp; Skiena (2017) Haochen Chen, Arvind Ram Anantharam, S. Skiena. (2017)\nDeepBrowse: Similarity-Based Browsing Through Large Lists (Extended Abstract)\nSISAP\nPaper Link\nInfluential Citation Count (0), SS-ID (562d08ed73dad28c989b6a04fa1e389b0125ba59)\nABSTRACT\nWe propose a new approach for browsing through large lists in the absence of a predefined hierarchy. DeepBrowse is defined by the interaction of two fixed, globally-defined permutations on the space of objects: one ordering the items by similarity, the second based on magnitude or importance. We demonstrate this paradigm through our WikiBrowse app for discovering interesting Wikipedia pages, which enables the user to scan similar related entities and then increase depth once a region of interest has been found.\nTri-party Deep Network Representation Pan et al. (2016) Shirui Pan, Jia Wu, Xingquan Zhu, Chengqi Zhang, Yang Wang. (2016)\nTri-Party Deep Network Representation\nIJCAI\nPaper Link\nInfluential Citation Count (32), SS-ID (8ba7631515d5e7e0c451af1c4772507f41540a5e)\nABSTRACT\nInformation network mining often requires examination of linkage relationships between nodes for analysis. Recently, network representation has emerged to represent each node in a vector format, embedding network structure, so off-the-shelf machine learning methods can be directly applied for analysis. To date, existing methods only focus on one aspect of node information and cannot leverage node labels. In this paper, we propose TriDNR, a tri-party deep network representation model, using information from three parties: node structure, node content, and node labels (if available) to jointly learn optimal node representation. TriDNR is based on our new coupled deep natural language module, whose learning is enforced at three levels: (1) at the network structure level, TriDNR exploits inter-node relationship by maximizing the probability of observing surrounding nodes given a node in random walks; (2) at the node content level, TriDNR captures node-word correlation by maximizing the co-occurrence of word sequence given a node; and (3) at the node label level, TriDNR models label-word correspondence by maximizing the probability of word sequence given a class label. The tri-party information is jointly fed into the neural network model to mutually enhance each other to learn optimal representation, and results in up to 79% classification accuracy gain, compared to state-of-the-art methods.\nGENE (Incorporate Group Information to Enhance Network Embedding) Chen, Zhang \u0026amp; Huang (2016) Incorporate Group Information to Enhance Network Embedding\nCIKM\nPaper Link\nInfluential Citation Count (4), SS-ID (332ec914469af4ecbc4ada0631773febc030406e)\nABSTRACT\nThe problem of representing large-scale networks with low-dimensional vectors has received considerable attention in recent years. Except the networks that include only vertices and edges, a variety of networks contain information about groups or communities. For example, on Facebook, in addition to users and the follower-followee relations between them, users can also create and join groups. However, previous studies have rarely utilized this valuable information to generate embeddings of vertices. In this paper, we investigate a novel method for learning the network embeddings with valuable group information for large-scale networks. The proposed methods take both the inner structures of the groups and the information across groups into consideration. Experimental results demonstrate that the embeddings generated by the proposed methods significantly outperform state-of-the-art network embedding methods on two different scale real-world network\nPlanetoid Yang, Cohen \u0026amp; Salakhutdinov (2016) Zhilin Yang, William W. Cohen, R. Salakhutdinov. (2016)\nRevisiting Semi-Supervised Learning with Graph Embeddings\nICML\nPaper Link\nInfluential Citation Count (178), SS-ID (3d846cb01f6a975554035d2210b578ca61344b22)\nABSTRACT\nWe present a semi-supervised learning framework based on graph embeddings. Given a graph between instances, we train an embedding for each instance to jointly predict the class label and the neighborhood context in the graph. We develop both transductive and inductive variants of our method. In the transductive variant of our method, the class labels are determined by both the learned embeddings and input feature vectors, while in the inductive variant, the embeddings are defined as a parametric function of the feature vectors, so predictions can be made on instances not seen during training. On a large and diverse set of benchmark tasks, including text classification, distantly supervised entity extraction, and entity classification, we show improved performance over many of the existing models.\nMax-margin DeepWalk Tu et al. (2016) Cunchao Tu, Weicheng Zhang, Zhiyuan Liu, Maosong Sun. (2016)\nMax-Margin DeepWalk: Discriminative Learning of Network Representation\nIJCAI\nPaper Link\nInfluential Citation Count (29), SS-ID (5d66991e1f541a08e81e59060cb0bb7f6931c2d9)\nABSTRACT\nDeepWalk is a typical representation learning method that learns low-dimensional representations for vertices in social networks. Similar to other network representation learning (NRL) models, it encodes the network structure into vertex representations and is learnt in unsupervised form. However, the learnt representations usually lack the ability of discrimination when applied to machine learning tasks, such as vertex classification. In this paper, we overcome this challenge by proposing a novel semi-supervised model, max-margin Deep-Walk (MMDW). MMDW is a unified NRL framework that jointly optimizes the max-margin classifier and the aimed social representation learning model. Influenced by the max-margin classifier, the learnt representations not only contain the network structure, but also have the characteristic of discrimination. The visualizations of learnt representations indicate that our model is more discriminative than unsupervised ones, and the experimental results on vertex classification demonstrate that our method achieves a significant improvement than other state-of-the-art methods. The source code can be obtained from https://github.com/thunlp/MMDW.\nLANE (Label Informed Attributed Network Embedding) Huang, Le \u0026amp; Hu (2017) Xiao Huang, Jundong Li, Xia Hu. (2017)\nLabel Informed Attributed Network Embedding\nWSDM\nPaper Link\nInfluential Citation Count (45), SS-ID (44044556dae0e21cab058c18f704b15d33bd17c5)\nABSTRACT\nAttributed network embedding aims to seek low-dimensional vector representations for nodes in a network, such that original network topological structure and node attribute proximity can be preserved in the vectors. These learned representations have been demonstrated to be helpful in many learning tasks such as network clustering and link prediction. While existing algorithms follow an unsupervised manner, nodes in many real-world attributed networks are often associated with abundant label information, which is potentially valuable in seeking more effective joint vector representations. In this paper, we investigate how labels can be modeled and incorporated to improve attributed network embedding. This is a challenging task since label information could be noisy and incomplete. In addition, labels are completely distinct with the geometrical structure and node attributes. The bewildering combination of heterogeneous information makes the joint vector representation learning more difficult. To address these issues, we propose a novel Label informed Attributed Network Embedding (LANE) framework. It can smoothly incorporate label information into the attributed network embedding while preserving their correlations. Experiments on real-world datasets demonstrate that the proposed framework achieves significantly better performance compared with the state-of-the-art embedding algorithms.\nLi, Ritter \u0026amp; Jurafsky (2015) Li, Ritter \u0026amp; Jurafsky (2015) Learning multi-faceted representations of individuals from heterogeneous evidence using neural networks\nArXiv\nPaper Link\nInfluential Citation Count (2), SS-ID (2dde8f7171522243870fef46a0c93e5bf7be45b9)\nABSTRACT\nInferring latent attributes of people online is an important social computing task, but requires integrating the many heterogeneous sources of information available on the web. We propose learning individual representations of people using neural nets to integrate rich linguistic and network evidence gathered from social media. The algorithm is able to combine diverse cues, such as the text a person writes, their attributes (e.g. gender, employer, education, location) and social relations to other people. We show that by integrating both textual and network evidence, these representations offer improved performance at four important tasks in social media inference on Twitter: predicting (1) gender, (2) occupation, (3) location, and (4) friendships for users. Our approach scales to large datasets and the learned representations can be used as general features in and have the potential to benefit a large number of downstream tasks including link prediction, community detection, or probabilistic reasoning over social networks.\nZhao, Liu \u0026amp; Sun (2015) Zhao, Liu \u0026amp; Sun (2015) Yu Zhao, Zhiyuan Liu, Maosong Sun. (2015)\nRepresentation Learning for Measuring Entity Relatedness with Rich Information\nIJCAI\nPaper Link\nInfluential Citation Count (3), SS-ID (5c560cdfbfa48ed570b9b11e1a2f15e371e635f4)\nABSTRACT\nIncorporating multiple types of relational information from heterogeneous networks has been proved effective in data mining. Although Wikipedia is one of the most famous heterogeneous network, previous works of semantic analysis on Wikipedia are mostly limited on single type of relations. In this paper, we aim at incorporating multiple types of relations to measure the semantic relatedness between Wikipedia entities. We propose a framework of coordinate matrix factorization to construct lowdimensional continuous representation for entities, categories and words in the same semantic space. We formulate this task as the completion of a sparse entity-entity association matrix, in which each entry quantifies the strength of relatedness between corresponding entities. We evaluate our model on the task of judging pair-wise word similarity. Experiment result shows that our model outperforms both traditional entity relatedness algorithms and other representation learning models.\nHNE (Heterogeneous Network Embedding) Chang et al. (2015) Shiyu Chang, Wei Han, Jiliang Tang, Guo-Jun Qi, C. Aggarwal, Thomas S. Huang. (2015)\nHeterogeneous Network Embedding via Deep Architectures\nKDD\nPaper Link\nInfluential Citation Count (35), SS-ID (f7172f95a3c0aa4fddfaadbce9908ce20cbf50ef)\nABSTRACT\nData embedding is used in many machine learning applications to create low-dimensional feature representations, which preserves the structure of data points in their original space. In this paper, we examine the scenario of a heterogeneous network with nodes and content of various types. Such networks are notoriously difficult to mine because of the bewildering combination of heterogeneous contents and structures. The creation of a multidimensional embedding of such data opens the door to the use of a wide variety of off-the-shelf mining techniques for multidimensional data. Despite the importance of this problem, limited efforts have been made on embedding a network of scalable, dynamic and heterogeneous data. In such cases, both the content and linkage structure provide important cues for creating a unified feature representation of the underlying network. In this paper, we design a deep embedding algorithm for networked data. A highly nonlinear multi-layered embedding function is used to capture the complex interactions between the heterogeneous data in a network. Our goal is to create a multi-resolution deep embedding function, that reflects both the local and global network structures, and makes the resulting embedding useful for a variety of data mining tasks. In particular, we demonstrate that the rich content and linkage information in a heterogeneous network can be captured by such an approach, so that similarities among cross-modal data can be measured directly in a common embedding space. Once this goal has been achieved, a wide variety of data mining problems can be solved by applying off-the-shelf algorithms designed for handling vector representations. Our experiments on real-world network datasets show the effectiveness and scalability of the proposed algorithm as compared to the state-of-the-art embedding methods.\nTang \u0026amp; Liu (2011) Tang \u0026amp; Liu (2011) Lei Tang, Huan Liu. (2011)\nLeveraging social media networks for classification\nData Mining and Knowledge Discovery\nPaper Link\nInfluential Citation Count (26), SS-ID (3f9df5c77af49d5b1b19eac9b82cb430b50f482d)\nABSTRACT\nSocial media has reshaped the way in which people interact with each other. The rapid development of participatory web and social networking sites like YouTube, Twitter, and Facebook, also brings about many data mining opportunities and novel challenges. In particular, we focus on classification tasks with user interaction information in a social network. Networks in social media are heterogeneous, consisting of various relations. Since the relation-type information may not be available in social media, most existing approaches treat these inhomogeneous connections homogeneously, leading to an unsatisfactory classification performance. In order to handle the network heterogeneity, we propose the concept of social dimension to represent actors’ latent affiliations, and develop a classification framework based on that. The proposed framework, SocioDim, first extracts social dimensions based on the network structure to accurately capture prominent interaction patterns between actors, then learns a discriminative classifier to select relevant social dimensions. SocioDim, by differentiating different types of network connections, outperforms existing representative methods of classification in social media, and offers a simple yet effective approach to integrating two types of seemingly orthogonal information: the network of actors and their attributes.\nEOE (Embedding of Embedding) Xu et al. (2017) Linchuan Xu, Xiaokai Wei, Jiannong Cao, Philip S. Yu. (2017)\nEmbedding of Embedding (EOE): Joint Embedding for Coupled Heterogeneous Networks\nWSDM\nPaper Link\nInfluential Citation Count (14), SS-ID (688f937ddeed178802c53963743d1801a778614e)\nABSTRACT\nNetwork embedding is increasingly employed to assist network analysis as it is effective to learn latent features that encode linkage information. Various network embedding methods have been proposed, but they are only designed for a single network scenario. In the era of big data, different types of related information can be fused together to form a coupled heterogeneous network, which consists of two different but related sub-networks connected by inter-network edges. In this scenario, the inter-network edges can act as comple- mentary information in the presence of intra-network ones. This complementary information is important because it can make latent features more comprehensive and accurate. And it is more important when the intra-network edges are ab- sent, which can be referred to as the cold-start problem. In this paper, we thus propose a method named embedding of embedding (EOE) for coupled heterogeneous networks. In the EOE, latent features encode not only intra-network edges, but also inter-network ones. To tackle the challenge of heterogeneities of two networks, the EOE incorporates a harmonious embedding matrix to further embed the em- beddings that only encode intra-network edges. Empirical experiments on a variety of real-world datasets demonstrate the EOE outperforms consistently single network embedding methods in applications including visualization, link prediction multi-class classification, and multi-label classification.\nHuang \u0026amp; Mamoulis (2017) Huang \u0026amp; Mamoulis (2017) Heterogeneous Information Network Embedding for Meta Path based Proximity\nArXiv\nPaper Link\nInfluential Citation Count (14), SS-ID (52a150d6a098ef142bece099dadaa613fddbae50)\nABSTRACT\nA network embedding is a representation of a large graph in a low-dimensional space, where vertices are modeled as vectors. The objective of a good embedding is to preserve the proximity between vertices in the original graph. This way, typical search and mining methods can be applied in the embedded space with the help of off-the-shelf multidimensional indexing approaches. Existing network embedding techniques focus on homogeneous networks, where all vertices are considered to belong to a single class.\nChen \u0026amp; Sun (2016) Chen \u0026amp; Sun (2016) Ting Chen, Yizhou Sun. (2016)\nTask-Guided and Path-Augmented Heterogeneous Network Embedding for Author Identification\nWSDM\nPaper Link\nInfluential Citation Count (13), SS-ID (6b183d2297cb493a57dbc875689ab2430d870043)\nABSTRACT\nIn this paper, we study the problem of author identification under double-blind review setting, which is to identify potential authors given information of an anonymized paper. Different from existing approaches that rely heavily on feature engineering, we propose to use network embedding approach to address the problem, which can automatically represent nodes into lower dimensional feature vectors. However, there are two major limitations in recent studies on network embedding: (1) they are usually general-purpose embedding methods, which are independent of the specific tasks; and (2) most of these approaches can only deal with homogeneous networks, where the heterogeneity of the network is ignored. Hence, challenges faced here are two folds: (1) how to embed the network under the guidance of the author identification task, and (2) how to select the best type of information due to the heterogeneity of the network. To address the challenges, we propose a task-guided and path-augmented heterogeneous network embedding model. In our model, nodes are first embedded as vectors in latent feature space. Embeddings are then shared and jointly trained according to task-specific and network-general objectives. We extend the existing unsupervised network embedding to incorporate meta paths in heterogeneous networks, and select paths according to the specific task. The guidance from author identification task for network embedding is provided both explicitly in joint training and implicitly during meta path selection. Our experiments demonstrate that by using path-augmented network embedding with task guidance, our model can obtain significantly better accuracy at identifying the true authors comparing to existing methods.\nJacob, Denoyer \u0026amp; Gallinari (2014) Jacob, Denoyer \u0026amp; Gallinari (2014) Yann Jacob, Ludovic Denoyer, P. Gallinari. (2014)\nLearning latent representations of nodes for classifying in heterogeneous social networks\nWSDM\nPaper Link\nInfluential Citation Count (6), SS-ID (030d436cb0465fd6cec0d5140b2534a8f1b8aeca)\nABSTRACT\nSocial networks are heterogeneous systems composed of different types of nodes (e.g. users, content, groups, etc.) and relations (e.g. social or similarity relations). While learning and performing inference on homogeneous networks have motivated a large amount of research, few work exists on heterogeneous networks and there are open and challenging issues for existing methods that were previously developed for homogeneous networks. We address here the specific problem of nodes classification and tagging in heterogeneous social networks, where different types of nodes are considered, each type with its own label or tag set. We propose a new method for learning node representations onto a latent space, common to all the different node types. Inference is then performed in this latent space. In this framework, two nodes connected in the network will tend to share similar representations regardless of their types. This allows bypassing limitations of the methods based on direct extensions of homogenous frameworks and exploiting the dependencies and correlations between the different node types. The proposed method is tested on two representative datasets and compared to state-of-the-art methods and to baselines.\nGERM (Genetic Heterogeneous Graph Embedding) Jiang et al. (2020) Zhuoren Jiang, Zheng Gao, Jinjiong Lan, Hongxia Yang, Yao Lu, Xiaozhong Liu. (2020)\nTask-Oriented Genetic Activation for Large-Scale Complex Heterogeneous Graph Embedding\nWWW\nPaper Link\nInfluential Citation Count (1), SS-ID (3e98d1b468304ef11b6cceb07d6d6b94d36ef7bc)\nABSTRACT\nThe recent success of deep graph embedding innovates the graphical information characterization methodologies. However, in real-world applications, such a method still struggles with the challenges of heterogeneity, scalability, and multiplex. To address these challenges, in this study, we propose a novel solution, Genetic hEterogeneous gRaph eMbedding (GERM), which enables flexible and efficient task-driven vertex embedding in a complex heterogeneous graph. Unlike prior efforts for this track of studies, we employ a task-oriented genetic activation strategy to efficiently generate the “Edge Type Activated Vector” (ETAV) over the edge types in the graph. The generated ETAV can not only reduce the incompatible noise and navigate the heterogeneous graph random walk at the graph-schema level, but also activate an optimized subgraph for efficient representation learning. By revealing the correlation between the graph structure and task information, the model interpretability can be enhanced as well. Meanwhile, an activated heterogeneous skip-gram framework is proposed to encapsulate both topological and task-specific information of a given heterogeneous graph. Through extensive experiments on both scholarly and e-commerce datasets, we demonstrate the efficacy and scalability of the proposed methods via various search/recommendation tasks. GERM can significantly reduces the running time and remove expert-intervention without sacrificing the performance (or even modestly improve) by comparing with baselines.\nHeGAN (HIN Embedding Generative Adversarial Networks) Hu, Fang \u0026amp; Shi (2019) Adversarial Learning on Heterogeneous Information Networks\nKDD\nPaper Link\nInfluential Citation Count (8), SS-ID (721902635d4480b4e4a64e36441a0cf527f2dd02)\nABSTRACT\nNetwork embedding, which aims to represent network data in a low-dimensional space, has been commonly adopted for analyzing heterogeneous information networks (HIN). Although exiting HIN embedding methods have achieved performance improvement to some extent, they still face a few major weaknesses. Most importantly, they usually adopt negative sampling to randomly select nodes from the network, and they do not learn the underlying distribution for more robust embedding. Inspired by generative adversarial networks (GAN), we develop a novel framework HeGAN for HIN embedding, which trains both a discriminator and a generator in a minimax game. Compared to existing HIN embedding methods, our generator would learn the node distribution to generate better negative samples. Compared to GANs on homogeneous networks, our discriminator and generator are designed to be relation-aware in order to capture the rich semantics on HINs. Furthermore, towards more effective and efficient sampling, we propose a generalized generator, which samples \u0026ldquo;latent\u0026rdquo; nodes directly from a continuous distribution, not confined to the nodes in the original network as existing methods are. Finally, we conduct extensive experiments on four real-world datasets. Results show that we consistently and significantly outperform state-of-the-art baselines across all datasets and tasks.\nCoGL (Co-Alignment Graph Convolutional Learning) Shi et al. (2020) Min Shi, Yufei Tang, Xingquan Zhu. (2020)\nTopology and Content Co-Alignment Graph Convolutional Learning\nIEEE transactions on neural networks and learning systems\nPaper Link\nInfluential Citation Count (0), SS-ID (249ce8e6bf5db2d0e12a5212330acdff3683550f)\nABSTRACT\nIn traditional graph neural networks (GNNs), graph convolutional learning is carried out through topology-driven recursive node content aggregation for network representation learning. In reality, network topology and node content each provide unique and important information, and they are not always consistent because of noise, irrelevance, or missing links between nodes. A pure topology-driven feature aggregation approach between unaligned neighborhoods may deteriorate learning from nodes with poor structure-content consistency, due to the propagation of incorrect messages over the whole network. Alternatively, in this brief, we advocate a co-alignment graph convolutional learning (CoGL) paradigm, by aligning topology and content networks to maximize consistency. Our theme is to enforce the learning from the topology network to be consistent with the content network while simultaneously optimizing the content network to comply with the topology for optimized representation learning. Given a network, CoGL first reconstructs a content network from node features then co-aligns the content network and the original network through a unified optimization goal with: 1) minimized content loss; 2) minimized classification loss; and 3) minimized adversarial loss. Experiments on six benchmarks demonstrate that CoGL achieves comparable and even better performance compared with existing state-of-the-art GNN models.\nCGAT Cao et al. (2020) Meng Cao, Xiying Ma, Kai Zhu, Ming Xu, Chong-Jun Wang. (2020)\nHeterogeneous Information Network Embedding with Convolutional Graph Attention Networks\n2020 International Joint Conference on Neural Networks (IJCNN)\nPaper Link\nInfluential Citation Count (0), SS-ID (3569199f440cc0178d5522644266c4b9b443e8ce)\nABSTRACT\nHeterogeneous Information Networks (HINs) are prevalent in our daily life, such as social networks and bibliography networks, which contain multiple types of nodes and links. Heterogeneous information network embedding is an effective HIN analysis method, it aims at projecting network elements into a lower-dimensional vector space for further machine learning related evaluations, such as node classification, node clustering, and so on. However, existing HIN embedding methods mainly focus on extracting the semantic-related information or close neighboring relations, while the high-level proximity of the network is also important but not preserved. To address the problem, in this paper we propose CGAT, a semi-supervised heterogeneous information network embedding method. We optimize the graph attention network by adding additional convolution layers, thereby we can extract multiple types of semantics and preserve high-level information in HIN embedding at the same time. Also, we utilize label information in HINs for semi-supervised training to better obtain the model parameters and HIN embeddings. Experimental results on real-world datasets demonstrate the effectiveness and efficiency of the proposed model.\nMAGNN (Metapath Aggregated Graph Neural Network) Fu et al. (2020) Xinyu Fu, Jiani Zhang, Ziqiao Meng, Irwin King. (2020)\nMAGNN: Metapath Aggregated Graph Neural Network for Heterogeneous Graph Embedding\nWWW\nPaper Link\nInfluential Citation Count (42), SS-ID (c7fd29fdd2e0b50a571db4f607eab138e9ecb644)\nABSTRACT\nA large number of real-world graphs or networks are inherently heterogeneous, involving a diversity of node types and relation types. Heterogeneous graph embedding is to embed rich structural and semantic information of a heterogeneous graph into low-dimensional node representations. Existing models usually define multiple metapaths in a heterogeneous graph to capture the composite relations and guide neighbor selection. However, these models either omit node content features, discard intermediate nodes along the metapath, or only consider one metapath. To address these three limitations, we propose a new model named Metapath Aggregated Graph Neural Network (MAGNN) to boost the final performance. Specifically, MAGNN employs three major components, i.e., the node content transformation to encapsulate input node attributes, the intra-metapath aggregation to incorporate intermediate semantic nodes, and the inter-metapath aggregation to combine messages from multiple metapaths. Extensive experiments on three real-world heterogeneous graph datasets for node classification, node clustering, and link prediction show that MAGNN achieves more accurate prediction results than state-of-the-art baselines.\nDyHAN (Dynamic Heterogeneous Graph Embedding using Hierarchical Attentions) Yang et al. (2020) Luwei Yang, Zhibo Xiao, Wen Jiang, Yi Wei, Y. Hu, Hao Wang. (2020)\nDynamic Heterogeneous Graph Embedding Using Hierarchical Attentions\nECIR\nPaper Link\nInfluential Citation Count (1), SS-ID (ffe5b25c6cf8de37823907c3aed7738ea393902e)\nABSTRACT\nGraph embedding has attracted many research interests. Existing works mainly focus on static homogeneous/heterogeneous networks or dynamic homogeneous networks. However, dynamic heterogeneous networks are more ubiquitous in reality, e.g. social network, e-commerce network, citation network, etc. There is still a lack of research on dynamic heterogeneous graph embedding. In this paper, we propose a novel dynamic heterogeneous graph embedding method using hierarchical attentions (DyHAN) that learns node embeddings leveraging both structural heterogeneity and temporal evolution. We evaluate our method on three real-world datasets. The results show that DyHAN outperforms various state-of-the-art baselines in terms of link prediction task.\nHDGAN (Heterogeneous Dynamic Graph Attention Network) Li et al. (2020) Qiuyan Li, Yanlei Shang, Xiuquan Qiao, Wei Dai. (2020)\nHeterogeneous Dynamic Graph Attention Network\n2020 IEEE International Conference on Knowledge Graph (ICKG)\nPaper Link\nInfluential Citation Count (1), SS-ID (57512101d4d64e7ec715a50eaba2e3e479239c64)\nABSTRACT\nNetwork embedding (graph embedding) has become the focus of studying graph structure in recent years. In addition to the research on homogeneous networks and heterogeneous networks, there are also some methods to attempt to solve the problem of dynamic network embedding. However, in dynamic networks, there is no research method specifically for heterogeneous networks. Therefore, this paper proposes a heterogeneous dynamic graph attention network (HDGAN), which attempts to use the attention mechanism to take the heterogeneity and dynamics of the network into account at the same time, so as to better learn network embedding. Our method is based on three levels of attention, namely structural-level attention, semantic-level attention and time-level attention. Structural-level attention pays attention to the network structure itself, and obtains the representation of structural-level nodes by learning the attention coefficients of neighbor nodes. Semantic-level attention integrates semantic information into the representation of nodes by learning the optimal weighted combination of different meta-paths. Time-level attention is based on the time decay effect, and the time feature is introduced into the node representation by neighborhood formation sequence. Through the above three levels of attention mechanism, the final network embedding can be obtained.Through experiments on two real-world heterogeneous dynamic networks, our models have the best results, proving the effectiveness of the HDGAN model.\nHetETA (Heterogeneous Estimated Time of Arrival) Hong et al. (2020) Huiting Hong, Yucheng Lin, Xiaoqing Yang, Zang Li, Kun Fu, Zheng Wang, X. Qie, Jieping Ye. (2020)\nHetETA: Heterogeneous Information Network Embedding for Estimating Time of Arrival\nKDD\nPaper Link\nInfluential Citation Count (1), SS-ID (364b6a10a827a6ba994d17baab2b2a2f1271dc29)\nABSTRACT\nThe estimated time of arrival (ETA) is a critical task in the intelligent transportation system, which involves the spatiotemporal data. Despite a significant amount of prior efforts have been made to design efficient and accurate systems for ETA task, few of them take structural graph data into account, much less the heterogeneous information network. In this paper, we propose HetETA to leverage heterogeneous information graph in ETA task. Specifically, we translate the road map into a multi-relational network and introduce a vehicle-trajectories based network to jointly consider the traffic behavior pattern. Moreover, we employ three components to model temporal information from recent periods, daily periods and weekly periods respectively. Each component comprises temporal convolutions and graph convolutions to learn representations of the spatiotemporal heterogeneous information for ETA task. Experiments on large-scale datasets illustrate the effectiveness of the proposed HetETA beyond the state-of-the-art methods, and show the importance of representation learning of heterogeneous information networks for ETA task.\nHeteGCN (Heterogeneous Graph Convolutional Networks) Ragesh et al. (2020) Rahul Ragesh, Sundararajan Sellamanickam, Arun Iyer, Ramakrishna Bairi, Vijay Lingam. (2020)\nHeteGCN: Heterogeneous Graph Convolutional Networks for Text Classification\nWSDM\nPaper Link\nInfluential Citation Count (3), SS-ID (9a6935328336b05fb95a47916eccf7b3c50b2f97)\nABSTRACT\nWe consider the problem of learning efficient and inductive graph convolutional networks for text classification with a large number of examples and features. Existing state-of-the-art graph embedding based methods such as predictive text embedding (PTE) and TextGCN have shortcomings in terms of predictive performance, scalability and inductive capability. To address these limitations, we propose a heterogeneous graph convolutional network (HeteGCN) modeling approach that unites the best aspects of PTE and TextGCN together. The main idea is to learn feature embeddings and derive document embeddings using a HeteGCN architecture with different graphs used across layers. We simplify TextGCN by dissecting into several HeteGCN models which (a) helps to study the usefulness of individual models and (b) offers flexibility in fusing learned embeddings from different models. In effect, the number of model parameters is reduced significantly, enabling faster training and improving performance in small labeled training set scenario. Our detailed experimental studies demonstrate the efficacy of the proposed approach.\nHGMF (Heterogeneous Graph-based Fusion) Chen \u0026amp; Zhang (2020) HGMF: Heterogeneous Graph-based Fusion for Multimodal Data with Incompleteness\nKDD\nPaper Link\nInfluential Citation Count (2), SS-ID (5d24501a99d05306817171a744878315c31a880b)\nABSTRACT\nWith the advances in data collection techniques, large amounts of multimodal data collected from multiple sources are becoming available. Such multimodal data can provide complementary information that can reveal fundamental characteristics of real-world subjects. Thus, multimodal machine learning has become an active research area. Extensive works have been developed to exploit multimodal interactions and integrate multi-source information. However, multimodal data in the real world usually comes with missing modalities due to various reasons, such as sensor damage, data corruption, and human mistakes in recording. Effectively integrating and analyzing multimodal data with incompleteness remains a challenging problem. We propose a Heterogeneous Graph-based Multimodal Fusion (HGMF) approach to enable multimodal fusion of incomplete data within a heterogeneous graph structure. The proposed approach develops a unique strategy for learning on incomplete multimodal data without data deletion or data imputation. More specifically, we construct a heterogeneous hypernode graph to model the multimodal data having different combinations of missing modalities, and then we formulate a graph neural network based transductive learning framework to project the heterogeneous incomplete data onto a unified embedding space, and multi-modalities are fused along the way. The learning framework captures modality interactions from available data, and leverages the relationships between different incompleteness patterns. Our experimental results demonstrate that the proposed method outperforms existing graph-based as well as non-graph based baselines on three different datasets.\nMIFHNE (Multi-source Information Fusion based Heterogeneous Network Embedding) Li et al. (2020) Bentian Li, D. Pi, Yunxia Lin, I. A. Khan, Lin Cui. (2020)\nMulti-source information fusion based heterogeneous network embedding\nInf. Sci.\nPaper Link\nInfluential Citation Count (0), SS-ID (be7bdd550f75acfbdc435e2ca75252779ba9b871)\nAbstract\nHeterogeneous network embedding aims to learn a mapping between network data in original topological space and vectored data in low dimensional latent space, while encoding valuable information, such as structural and semantic information. The resulting vector representation has shown promising performance for extensive real-world applications, such as node classification and node clustering. However, most of existing methods merely focus on modeling network structural information, ignoring the rich multi-source information of different types of nodes. In this paper, we propose a novel Multi-source Information Fusion based Heterogeneous Network Embedding (MIFHNE) approach. We first capture the semantic information using the strategy of meta-graph based random walk. Subsequently, we jointly model the structural proximity, attribute information and label information in the framework of Nonnegative Matrix Factorization (NMF). Theoretical proofs and comprehensive experiments on two real-world heterogeneous network datasets demonstrate the feasibility and effectiveness of our approach.\nMg2Vec Zhang et al (2020) Wentao Zhang, Yuan Fang, Zemin Liu, Min Wu, Xinming Zhang. (2020)\nmg2vec: Learning Relationship-Preserving Heterogeneous Graph Representations via Metagraph Embedding\nIEEE Transactions on Knowledge and Data Engineering\nPaper Link\nInfluential Citation Count (0), SS-ID (00a33da57a6beef0abb5e315a2018433e8659429)\nABSTRACT\nGiven that heterogeneous information networks (HIN) encompass nodes and edges belonging to different semantic types, they can model complex data in real-world scenarios. Thus, HIN embedding has received increasing attention, which aims to learn node representations in a low-dimensional space, in order to preserve the structural and semantic information on the HIN. In this regard, metagraphs, which model common and recurring patterns on HINs, emerge as a powerful tool to capture semantic-rich and often latent relationships on HINs. Although metagraphs have been employed to address several specific data mining tasks, they have not been thoroughly explored for the more general HIN embedding. In this paper, we leverage metagraphs to learn relationship-preserving HIN embedding in a self-supervised setting, to support various relationship mining tasks. In particular, we observe that most of the current approaches often under-utilize metagraphs, which are only applied in a pre-processing step and do not actively guide representation learning afterwards. Thus, we propose the novel framework of mg2vec, which learns the embeddings for metagraphs and nodes jointly. That is, metagraphs actively participates in the learning process by mapping themselves to the same embedding space as the nodes do. Moreover, metagraphs guide the learning through both first- and second-order constraints on node embeddings, to model not only latent relationships between a pair of nodes, but also individual preferences of each node. Finally, we conduct extensive experiments on three public datasets. Results show that mg2vec significantly outperforms a suite of state-of-the-art baselines in relationship mining tasks including relationship prediction, search and visualization.\nSiNE (Signed Network Embedding) Wang et al. (2017) Suhang Wang, Jiliang Tang, C. Aggarwal, Yi Chang, Huan Liu. (2017)\nSigned Network Embedding in Social Media\nSDM\nPaper Link\nInfluential Citation Count (22), SS-ID (c34336d3bfb7a3c22caa7958779f40bb2ab70a3d)\nABSTRACT\nNetwork embedding is to learn low-dimensional vector representations for nodes of a given social network, facilitating many tasks in social network analysis such as link prediction. The vast majority of existing embedding algorithms are designed for unsigned social networks or social networks with only positive links. However, networks in social media could have both positive and negative links, and little work exists for signed social networks. From recent findings of signed network analysis, it is evident that negative links have distinct properties and added value besides positive links, which brings about both challenges and opportunities for signed network embedding. In this paper, we propose a deep learning framework SiNE for signed network embedding. The framework optimizes an objective function guided by social theories that provide a fundamental understanding of signed social networks. Experimental results on two realworld datasets of social media demonstrate the effectiveness of the proposed framework SiNE.\nSNE (Signed Network Embedding) Yuan, Wu \u0026amp; Xiang (2017) Shuhan Yuan, Xintao Wu, Yang Xiang. (2017)\nSNE: Signed Network Embedding\nPAKDD\nPaper Link\nInfluential Citation Count (13), SS-ID (feee6ea8961398e599577f9f793230d391985b88)\nABSTRACT\nSeveral network embedding models have been developed for unsigned networks. However, these models based on skip-gram cannot be applied to signed networks because they can only deal with one type of link. In this paper, we present our signed network embedding model called SNE. Our SNE adopts the log-bilinear model, uses node representations of all nodes along a given path, and further incorporates two signed-type vectors to capture the positive or negative relationship of each edge along the path. We conduct two experiments, node classification and link prediction, on both directed and undirected signed networks and compare with four baselines including a matrix factorization method and three state-of-the-art unsigned network embedding models. The experimental results demonstrate the effectiveness of our signed network embedding.\nSIDE (Signed Directed Networks) Kim et al. (2018) Junghwan Kim, Haekyu Park, Ji-Eun Lee, U. Kang. (2018)\nSIDE: Representation Learning in Signed Directed Networks\nWWW\nPaper Link\nInfluential Citation Count (21), SS-ID (a0da1be7b7665b8c23d80ad2b03815dd708cd7b9)\nABSTRACT\nGiven a signed directed network, how can we learn node representations which fully encode structural information of the network including sign and direction of edges? Node representation learning or network embedding learns a mapping of each node to a vector. The mapping encodes structural information on network, providing low-dimensional dense node features for general machine learning and data mining frameworks. Since many social networks allow trust (friend) and distrust (enemy) relationships described by signed and directed edges, generalizing network embedding method to learn from sign and direction information in networks is crucial. In addition, social theories are critical tool in signed network analysis. However, none of the existing methods supports all of the desired properties: considering sign, direction, and social theoretical interpretation. In this paper, we propose SIDE, a general network embedding method that represents both sign and direction of edges in the embedding space. SIDE carefully formulates and optimizes likelihood over both direct and indirect signed connections. We provide socio-psychological interpretation for each component of likelihood function. We prove linear scalability of our algorithm and propose additional optimization techniques to reduce the training time and improve accuracy. Through extensive experiments on real-world signed directed networks, we show that SIDE effectively encodes structural information into the learned embedding.\nSIGNet (Scalable Embedding for Signed Networks) Islam, Prakash \u0026amp; Ramakrishnan (2018) SIGNet: Scalable Embeddings for Signed Networks\nPAKDD\nPaper Link\nInfluential Citation Count (3), SS-ID (21bcb27995ae1007f4dabe5973c5fa6df7706f3e)\nABSTRACT\nRecent successes in word embedding and document embedding have motivated researchers to explore similar representations for networks and to use such representations for tasks such as edge prediction, node label prediction, and community detection. Such network embedding methods are largely focused on finding distributed representations for unsigned networks and are unable to discover embeddings that respect polarities inherent in edges. We propose SIGNet, a fast scalable embedding method suitable for signed networks. Our proposed objective function aims to carefully model the social structure implicit in signed networks by reinforcing the principles of social balance theory. Our method builds upon the traditional word2vec family of embedding approaches and adds a new targeted node sampling strategy to maintain structural balance in higher-order neighborhoods. We demonstrate the superiority of SIGNet over state-of-the-art methods proposed for both signed and unsigned networks on several real world datasets from different domains. In particular, SIGNet offers an approach to generate a richer vocabulary of features of signed networks to support representation and reasoning.\nSSNE (Status Signed Network Embedding) Lu et al. (2019) Chunyu Lu, Pengfei Jiao, Hongtao Liu, Yaping Wang, Hongyan Xu, Wenjun Wang. (2019)\nSSNE: Status Signed Network Embedding\nPAKDD\nPaper Link\nInfluential Citation Count (0), SS-ID (f429e69863223ca62d2fa1fd667b18ddac0cb3de)\nABSTRACT\nThis work studies the problem of signed network embedding, which aims to obtain low-dimensional vectors for nodes in signed networks. Existing works mostly focus on learning representations via characterizing the social structural balance theory in signed networks. However, structural balance theory could not well satisfy some of the fundamental phenomena in real-world signed networks such as the direction of links. As a result, in this paper we integrate another theory Status Theory into signed network embedding since status theory can better explain the social mechanisms of signed networks. To be specific, we characterize the status of nodes in the semantic vector space and well design different ranking objectives for positive and negative links respectively. Besides, we utilize graph attention to assemble the information of neighborhoods. We conduct extensive experiments on three real-world datasets and the results show that our model can achieve a significant improvement compared with baselines.\nPrincipled Multilayer Network Embedding Liu et al (2017) Weiyi Liu, Pin-Yu Chen, S. Yeung, T. Suzumura, Lingli Chen. (2017)\nPrincipled Multilayer Network Embedding\n2017 IEEE International Conference on Data Mining Workshops (ICDMW)\nPaper Link\nInfluential Citation Count (14), SS-ID (e445ce942f2cd572aed76160febe35973e0fc42f)\nABSTRACT\nMultilayer network analysis has become a vital tool for understanding different relationships and their interactions in a complex system, where each layer in a multilayer network depicts the topological structure of a group of nodes corresponding to a particular relationship. The interactions among different layers imply how the interplay of different relations on the topology of each layer. For a single-layer network, network embedding methods have been proposed to project the nodes in a network into a continuous vector space with a relatively small number of dimensions, where the space embeds the social representations among nodes. These algorithms have been proved to have a better performance on a variety of regular graph analysis tasks, such as link prediction, or multi-label classification. In this paper, by extending a standard graph mining into multilayer network, we have proposed three methods (\u0026ldquo;network aggregation,\u0026rdquo; \u0026ldquo;results aggregation\u0026rdquo; and \u0026ldquo;layer co-analysis\u0026rdquo;) to project a multilayer network into a continuous vector space. On one hand, without leveraging interactions among layers, \u0026ldquo;network aggregation\u0026rdquo; and \u0026ldquo;results aggregation\u0026rdquo; apply the standard network embedding method on the merged graph or each layer to find a vector space for multilayer network. On the other hand, in order to consider the influence of interactions among layers, \u0026ldquo;layer co-analysis\u0026rdquo; expands any single-layer network embedding method to a multilayer network. By introducing the link transition probability based on information distance, this method not only uses the first and second order random walk to traverse on a layer, but also has the ability to traverse between layers by leveraging interactions. From the evaluation, we have proved that comparing with regular link prediction methods, \u0026ldquo;layer co-analysis\u0026rdquo; achieved the best performance on most of the datasets, while \u0026ldquo;network aggregation\u0026rdquo; and \u0026ldquo;results aggregation\u0026rdquo; also have better performance than regular link prediction methods.\nIONE Liu et al. (2016) Li Liu, W. K. Cheung, Xin Li, L. Liao. (2016)\nAligning Users across Social Networks Using Network Embedding\nIJCAI\nPaper Link\nInfluential Citation Count (36), SS-ID (da7ee47ee1ccee8080f5827c3c8ee60af90e5fa0)\nABSTRACT\nIn this paper, we adopt the representation learning approach to align users across multiple social networks where the social structures of the users are exploited. In particular, we propose to learn a network embedding with the followership/ followee-ship of each user explicitly modeled as input/output context vector representations so as to preserve the proximity of users with \u0026ldquo;similar\u0026rdquo; followers/followees in the embedded space. For the alignment, we add both known and potential anchor users across the networks to facilitate the transfer of context information across networks. We solve both the network embedding problem and the user alignment problem simultaneously under a unified optimization framework. The stochastic gradient descent and negative sampling algorithms are used to address scalability issues. Extensive experiments on real social network datasets demonstrate the effectiveness and efficiency of the proposed approach compared with several state-of-the-art methods.\nZitnik \u0026amp; Leskovec (2017) Zitnik \u0026amp; Leskovec (2017) M. Zitnik, J. Leskovec. (2017)\nPredicting multicellular function through multi-layer tissue networks\nBioinform.\nPaper Link\nInfluential Citation Count (19), SS-ID (b7c4570d7d97f327e7f82fe28100172ec5e94cac)\nABSTRACT\nMotivation: Understanding functions of proteins in specific human tissues is essential for insights into disease diagnostics and therapeutics, yet prediction of tissue‐specific cellular function remains a critical challenge for biomedicine. Results: Here, we present OhmNet, a hierarchy‐aware unsupervised node feature learning approach for multi‐layer networks. We build a multi‐layer network, where each layer represents molecular interactions in a different human tissue. OhmNet then automatically learns a mapping of proteins, represented as nodes, to a neural embedding‐based low‐dimensional space of features. OhmNet encourages sharing of similar features among proteins with similar network neighborhoods and among proteins activated in similar tissues. The algorithm generalizes prior work, which generally ignores relationships between tissues, by modeling tissue organization with a rich multiscale tissue hierarchy. We use OhmNet to study multicellular function in a multi‐layer protein interaction network of 107 human tissues. In 48 tissues with known tissue‐specific cellular functions, OhmNet provides more accurate predictions of cellular function than alternative approaches, and also generates more accurate hypotheses about tissue‐specific protein actions. We show that taking into account the tissue hierarchy leads to improved predictive power. Remarkably, we also demonstrate that it is possible to leverage the tissue hierarchy in order to effectively transfer cellular functions to a functionally uncharacterized tissue. Overall, OhmNet moves from flat networks to multiscale models able to predict a range of phenotypes spanning cellular subsystems. Availability and implementation: Source code and datasets are available at http://snap.stanford.edu/ohmnet. Contact: jure@cs.stanford.edu\nMulti-Layered Network Embedding Li et al. (2018) Jundong Li, C. Chen, Hanghang Tong, Huan Liu. (2018)\nMulti-Layered Network Embedding\nSDM\nPaper Link\nInfluential Citation Count (5), SS-ID (7c28b81dff1899e5a148ff57888faacc9945ab22)\nABSTRACT\nNetwork embedding has gained more attentions in recent years. It has been shown that the learned lowdimensional node vector representations could advance a myriad of graph mining tasks such as node classification, community detection, and link prediction. A vast majority of the existing efforts are overwhelmingly devoted to single-layered networks or homogeneous networks with a single type of nodes and node interactions. However, in many real-world applications, a variety of networks could be abstracted and presented in a multilayered fashion. Typical multi-layered networks include critical infrastructure systems, collaboration platforms, social recommender systems, to name a few. Despite the widespread use of multi-layered networks, it remains a daunting task to learn vector representations of different types of nodes due to the bewildering combination of both within-layer connections and cross-layer network dependencies. In this paper, we study a novel problem of multi-layered network embedding. In particular, we propose a principled framework MANE to model both within-layer connections and cross-layer network dependencies simultaneously in a unified optimization framework for embedding representation learning. Experiments on real-world multi-layered networks corroborate the effectiveness of the proposed framework.\nTemporalNode2Vec Haddad et al. (2019) Mounir Haddad, Cécile Bothorel, P. Lenca, Dominique Bedart. (2019)\nTemporalNode2vec: Temporal Node Embedding in Temporal Networks\nCOMPLEX NETWORKS\nPaper Link\nInfluential Citation Count (0), SS-ID (ad43d8ba1b9619211052615f24da3ecb3c8519db)\nABSTRACT\nThe goal of graph embedding is to learn a representation of graphs vertices in a latent low-dimensional space in order to encode the structural information that lies in graphs. While real-world networks evolve over time, the majority of research focuses on static networks, ignoring local and global evolution patterns. A simplistic approach consists of learning nodes embeddings independently for each time step. This can cause unstable and inefficient representations over time.\nTGNs (Temporal Graph Networks) Rossi et al. (2020) Emanuele Rossi, B. Chamberlain, F. Frasca, D. Eynard, Federico Monti, M. Bronstein. (2020)\nTemporal Graph Networks for Deep Learning on Dynamic Graphs\nArXiv\nPaper Link\nInfluential Citation Count (26), SS-ID (150f95f9c73820e0a0fa1546140e9f2bdfd25954)\nABSTRACT\nGraph Neural Networks (GNNs) have recently become increasingly popular due to their ability to learn complex systems of relations or interactions arising in a broad spectrum of problems ranging from biology and particle physics to social networks and recommendation systems. Despite the plethora of different models for deep learning on graphs, few approaches have been proposed thus far for dealing with graphs that present some sort of dynamic nature (e.g. evolving features or connectivity over time). In this paper, we present Temporal Graph Networks (TGNs), a generic, efficient framework for deep learning on dynamic graphs represented as sequences of timed events. Thanks to a novel combination of memory modules and graph-based operators, TGNs are able to significantly outperform previous approaches being at the same time more computationally efficient. We furthermore show that several previous models for learning on dynamic graphs can be cast as specific instances of our framework. We perform a detailed ablation study of different components of our framework and devise the best configuration that achieves state-of-the-art performance on several transductive and inductive prediction tasks for dynamic graphs.\nTemporalGAT Fathy \u0026amp; Li (2020) A. Fathy, Kan Li. (2020)\nTemporalGAT: Attention-Based Dynamic Graph Representation Learning\nPAKDD\nPaper Link\nInfluential Citation Count (0), SS-ID (c06fc165523554b79ce59db9a8ce113b074359a0)\nABSTRACT\nLearning representations for dynamic graphs is fundamental as it supports numerous graph analytic tasks such as dynamic link prediction, node classification, and visualization. Real-world dynamic graphs are continuously evolved where new nodes and edges are introduced or removed during graph evolution. Most existing dynamic graph representation learning methods focus on modeling dynamic graphs with fixed nodes due to the complexity of modeling dynamic graphs, and therefore, cannot efficiently learn the evolutionary patterns of real-world evolving graphs. Moreover, existing methods generally model the structural information of evolving graphs separately from temporal information. This leads to the loss of important structural and temporal information that could cause the degradation of predictive performance of the model. By employing an innovative neural network architecture based on graph attention networks and temporal convolutions, our framework jointly learns graph representations contemplating evolving graph structure and temporal patterns. We propose a deep attention model to learn low-dimensional feature representations which preserves the graph structure and features among series of graph snapshots over time. Experimental results on multiple real-world dynamic graph datasets show that, our proposed method is competitive against various state-of-the-art methods.\nEpiEm (Dynamics-Preserving Graph Embedding) Zhong, Qiu \u0026amp; Shi (2020) Jianan Zhong, Hongjun Qiu, B. Shi. (2020)\nDynamics-Preserving Graph Embedding for Community Mining and Network Immunization\nInf.\nPaper Link\nInfluential Citation Count (0), SS-ID (ebbe61c75100df486632a9518b4c04ff5795aea9)\nABSTRACT\nIn recent years, the graph embedding approach has drawn a lot of attention in the field of network representation and analytics, the purpose of which is to automatically encode network elements into a low-dimensional vector space by preserving certain structural properties. On this basis, downstream machine learning methods can be implemented to solve static network analytic tasks, for example, node clustering based on community-preserving embeddings. However, by focusing only on structural properties, it would be difficult to characterize and manipulate various dynamics operating on the network. In the field of complex networks, epidemic spreading is one of the most typical dynamics in networks, while network immunization is one of the effective methods to suppress the epidemics. Accordingly, in this paper, we present a dynamics-preserving graph embedding method (EpiEm) to preserve the property of epidemic dynamics on networks, i.e., the infectiousness and vulnerability of network nodes. Specifically, we first generate a set of propagation sequences through simulating the Susceptible-Infectious process on a network. Then, we learn node embeddings from an influence matrix using a singular value decomposition method. Finally, we show that the node embeddings can be used to solve epidemics-related community mining and network immunization problems. The experimental results in real-world networks show that the proposed embedding method outperforms several benchmark methods with respect to both community mining and network immunization. The proposed method offers new insights into the exploration of other collective dynamics in complex networks using the graph embedding approach, such as opinion formation in social networks.\nDynamic Graph Embedding Rokka, Chhetri \u0026amp; Al Faruque (2020) Dynamic Graph Embedding\nPaper Link\nInfluential Citation Count (0), SS-ID (d28823f812b83ac957ac5077216766cba29d211d)\nABSTRACT\nIn Chap. 9, we presented a structural graph convolutional neural network which is capable of performing supervising learning to estimate a function between non-euclidean data and categorical data. In this chapter, we focus on non-euclidean data which are evolving over time. In the cyber-physical system, most of the non-euclidean data (such as engineering data, energy, and signal flow graph, call graph of the firmware, etc.) are always evolving. Hence, it is necessary to utilize algorithms that are capable of handling such temporally evolving non-euclidean data. In this chapter, we present a novel dynamic graph embedding algorithm to handle this issue. In the rest of the chapter, we consider temporally evolving graphs as the non-euclidean data and present an algorithm capable of capturing the pattern of time-varying links.\nCTGCN (K-core based Temporal GCN) Liu et al. (2020) Jingxin Liu, Chang Xu, Chang Yin, Weiqiang Wu, You Song. (2020)\nK-Core based Temporal Graph Convolutional Network for Dynamic Graphs\nArXiv\nPaper Link\nInfluential Citation Count (1), SS-ID (4fda7672f67a8872902dee92e4c1bcf2c833a2b1)\nABSTRACT\nGraph representation learning is a fundamental task in various applications that strives to learn low-dimensional embeddings for nodes that can preserve graph topology information. However, many existing methods focus on static graphs while ignoring evolving graph patterns. Inspired by the success of graph convolutional networks(GCNs) in static graph embedding, we propose a novel k-core based temporal graph convolutional network, the CTGCN, to learn node representations for dynamic graphs. In contrast to previous dynamic graph embedding methods, CTGCN can preserve both local connective proximity and global structural similarity while simultaneously capturing graph dynamics. In the proposed framework, the traditional graph convolution is generalized into two phases, feature transformation and feature aggregation, which gives the CTGCN more flexibility and enables the CTGCN to learn connective and structural information under the same framework. Experimental results on 7 real-world graphs demonstrate that the CTGCN outperforms existing state-of-the-art graph embedding methods in several tasks, including link prediction and structural role classification. The source code of this work can be obtained from this https URL.\nDynGraph2Vec Goyal, Chhetri \u0026amp; Canedo (2020) dyngraph2vec: Capturing Network Dynamics using Dynamic Graph Representation Learning\nKnowl. Based Syst.\nPaper Link\nInfluential Citation Count (23), SS-ID (f6e59062382fdec9b95c3abef1c27efc3b2ec1c7)\nABSTRACT\nLearning graph representations is a fundamental task aimed at capturing various properties of graphs in vector space. The most recent methods learn such representations for static networks. However, real-world networks evolve over time and have varying dynamics. Capturing such evolution is key to predicting the properties of unseen networks. To understand how the network dynamics affect the prediction performance, we propose an embedding approach which learns the structure of evolution in dynamic graphs and can predict unseen links with higher precision. Our model, dyngraph2vec, learns the temporal transitions in the network using a deep architecture composed of dense and recurrent layers. We motivate the need for capturing dynamics for the prediction on a toy dataset created using stochastic block models. We then demonstrate the efficacy of dyngraph2vec over existing state-of-the-art methods on two real-world datasets. We observe that learning dynamics can improve the quality of embedding and yield better performance in link prediction.\nTigeCMN (Temporal Interaction Graph Embedding via Coupled Memory Networks) Zhang et al. (2020) Zhen Zhang, Jiajun Bu, Martin Ester, Jianfeng Zhang, Chengwei Yao, Z. Li, Can Wang. (2020)\nLearning Temporal Interaction Graph Embedding via Coupled Memory Networks\nWWW\nPaper Link\nInfluential Citation Count (1), SS-ID (1184a394fa785a61e125128e699950d42df22c37)\nABSTRACT\nGraph embedding has become the research focus in both academic and industrial communities due to its powerful capabilities. The majority of existing work overwhelmingly learn node embeddings in the context of static, plain or attributed, homogeneous graphs. However, many real-world applications frequently involve bipartite graphs with temporal and attributed interaction edges, named temporal interaction graphs. The temporal interactions usually imply different facets of interest and might even evolve over time, thus putting forward huge challenges in learning effective node representations. In this paper, we propose a novel framework named TigeCMN to learn node representations from a sequence of temporal interactions. Specifically, we devise two coupled memory networks to store and update node embeddings in external matrices explicitly and dynamically, which forms deep matrix representations and could enhance the expressiveness of the node embeddings. We conduct experiments on two real-world datasets and the experimental results empirically demonstrate that TigeCMN can outperform the state-of-the-arts with different gains.\nCluster-GCN Chiang et al. (2019) Wei-Lin Chiang, Xuanqing Liu, Si Si, Yang Li, Samy Bengio, Cho-Jui Hsieh. (2019)\nCluster-GCN: An Efficient Algorithm for Training Deep and Large Graph Convolutional Networks\nKDD\nPaper Link\nInfluential Citation Count (65), SS-ID (05c4eb154ad9512a69569c18d68bc4428ee8bb83)\nABSTRACT\nGraph convolutional network (GCN) has been successfully applied to many graph-based applications; however, training a large-scale GCN remains challenging. Current SGD-based algorithms suffer from either a high computational cost that exponentially grows with number of GCN layers, or a large space requirement for keeping the entire graph and the embedding of each node in memory. In this paper, we propose Cluster-GCN, a novel GCN algorithm that is suitable for SGD-based training by exploiting the graph clustering structure. Cluster-GCN works as the following: at each step, it samples a block of nodes that associate with a dense subgraph identified by a graph clustering algorithm, and restricts the neighborhood search within this subgraph. This simple but effective strategy leads to significantly improved memory and computational efficiency while being able to achieve comparable test accuracy with previous algorithms. To test the scalability of our algorithm, we create a new Amazon2M data with 2 million nodes and 61 million edges which is more than 5 times larger than the previous largest publicly available dataset (Reddit). For training a 3-layer GCN on this data, Cluster-GCN is faster than the previous state-of-the-art VR-GCN (1523 seconds vs 1961 seconds) and using much less memory (2.2GB vs 11.2GB). Furthermore, for training 4 layer GCN on this data, our algorithm can finish in around 36 minutes while all the existing GCN training algorithms fail to train due to the out-of-memory issue. Furthermore, Cluster-GCN allows us to train much deeper GCN without much time and memory overhead, which leads to improved prediction accuracy\u0026mdash;using a 5-layer Cluster-GCN, we achieve state-of-the-art test F1 score 99.36 on the PPI dataset, while the previous best result was 98.71 by~\\citezhang2018gaan.\nSIGN (Scalable Inception Graph Neural Networks) Rossi et al. (2020) Emanuele Rossi, F. Frasca, B. Chamberlain, D. Eynard, M. Bronstein, Federico Monti. (2020)\nSIGN: Scalable Inception Graph Neural Networks\nArXiv\nPaper Link\nInfluential Citation Count (23), SS-ID (993377a3fc8334558463b82053904e3d684f29c0)\nABSTRACT\nGraph representation learning has recently been applied to a broad spectrum of problems ranging from computer graphics and chemistry to high energy physics and social media. The popularity of graph neural networks has sparked interest, both in academia and in industry, in developing methods that scale to very large graphs such as Facebook or Twitter social networks. In most of these approaches, the computational cost is alleviated by a sampling strategy retaining a subset of node neighbors or subgraphs at training time. In this paper we propose a new, efficient and scalable graph deep learning architecture which sidesteps the need for graph sampling by using graph convolutional filters of different size that are amenable to efficient precomputation, allowing extremely fast training and inference. Our architecture allows using different local graph operators (e.g. motif-induced adjacency matrices or Personalized Page Rank diffusion matrix) to best suit the task at hand. We conduct extensive experimental evaluation on various open benchmarks and show that our approach is competitive with other state-of-the-art architectures, while requiring a fraction of the training and inference time.\nFastGCN Chen, Ma \u0026amp; Xiao (2018) Jing Chen, Tengfei Ma, Cao Xiao. (2018)\nFastGCN: Fast Learning with Graph Convolutional Networks via Importance Sampling\nICLR\nPaper Link\nInfluential Citation Count (118), SS-ID (f19d3e0956d0f2daa3396fc6e9e7554a78a90710)\nABSTRACT\nThe graph convolutional networks (GCN) recently proposed by Kipf and Welling are an effective graph model for semi-supervised learning. This model, however, was originally designed to be learned with the presence of both training and test data. Moreover, the recursive neighborhood expansion across layers poses time and memory challenges for training with large, dense graphs. To relax the requirement of simultaneous availability of test data, we interpret graph convolutions as integral transforms of embedding functions under probability measures. Such an interpretation allows for the use of Monte Carlo approaches to consistently estimate the integrals, which in turn leads to a batched training scheme as we propose in this work\u0026mdash;FastGCN. Enhanced with importance sampling, FastGCN not only is efficient for training but also generalizes well for inference. We show a comprehensive set of experiments to demonstrate its effectiveness compared with GCN and related models. In particular, training is orders of magnitude more efficient while predictions remain comparably accurate.\nSalha, Hennequin \u0026amp; Vazirgiannis (2020) Salha, Hennequin \u0026amp; Vazirgiannis (2020) Guillaume Salha-Galvan, Romain Hennequin, M. Vazirgiannis. (2020)\nSimple and Effective Graph Autoencoders with One-Hop Linear Models\nECML/PKDD\nPaper Link\nInfluential Citation Count (2), SS-ID (8380ce56e614d047cf2c5c6106dcfc00beed5b6f)\nABSTRACT\nOver the last few years, graph autoencoders (AE) and variational autoencoders (VAE) emerged as powerful node embedding methods, with promising performances on challenging tasks such as link prediction and node clustering. Graph AE, VAE and most of their extensions rely on multi-layer graph convolutional networks (GCN) encoders to learn vector space representations of nodes. In this paper, we show that GCN encoders are actually unnecessarily complex for many applications. We propose to replace them by significantly simpler and more interpretable linear models w.r.t. the direct neighborhood (one-hop) adjacency matrix of the graph, involving fewer operations, fewer parameters and no activation function. For the two aforementioned tasks, we show that this simpler approach consistently reaches competitive performances w.r.t. GCN-based graph AE and VAE for numerous real-world graphs, including all benchmark datasets commonly used to evaluate graph AE and VAE. Based on these results, we also question the relevance of repeatedly using these datasets to compare complex graph AE and VAE.\nULGE (Unsupervised Large Graph Embedding) Nie, Zhu \u0026amp; Li (2020) F. Nie, Wei Zhu, Xuelong Li. (2020)\nUnsupervised Large Graph Embedding Based on Balanced and Hierarchical K-Means\nIEEE Transactions on Knowledge and Data Engineering\nPaper Link\nInfluential Citation Count (0), SS-ID (894e66e457482d8b658dfc1d1f4d6f532357b400)\nABSTRACT\nThere are many successful spectral based unsupervised dimensionality reduction methods, including Laplacian Eigenmap (LE), Locality Preserving Projection (LPP), Spectral Regression (SR), etc. We find that LPP and SR are equivalent if the symmetric similarity matrix is doubly stochastic, Positive Semi-Definite (PSD) and with rank $p$mml:mathmml:mip\u0026lt;/mml:mi\u0026gt;\u0026lt;/mml:math\u0026gt;, where $p$mml:mathmml:mip\u0026lt;/mml:mi\u0026gt;\u0026lt;/mml:math\u0026gt; is the reduced dimension. Since solving SR is believed faster than solving LPP based on some related literature, the discovery promotes us to seek to construct such specific similarity matrix to speed up LPP solving procedures. We then propose an unsupervised linear method called Unsupervised Large Graph Embedding (ULGE). ULGE starts with a similar idea as LPP but adopts an efficient approach to construct anchor-based similarity matrix and then performs spectral analysis on it. Moreover, since conventional anchor generation strategies suffer kinds of problems, we propose an efficient and effective anchor generation strategy, called Balanced $K$mml:mathmml:miK\u0026lt;/mml:mi\u0026gt;\u0026lt;/mml:math\u0026gt;-means based Hierarchical $K$mml:mathmml:miK\u0026lt;/mml:mi\u0026gt;\u0026lt;/mml:math\u0026gt;-means (BHKH). The computational complexity of ULGE can reduce to $O(ndm)$mml:mathmml:mrowmml:miO\u0026lt;/mml:mi\u0026gt;mml:mo(\u0026lt;/mml:mo\u0026gt;mml:min\u0026lt;/mml:mi\u0026gt;mml:mid\u0026lt;/mml:mi\u0026gt;mml:mim\u0026lt;/mml:mi\u0026gt;mml:mo)\u0026lt;/mml:mo\u0026gt;\u0026lt;/mml:mrow\u0026gt;\u0026lt;/mml:math\u0026gt;, which is a significant improvement compared to conventional methods need $O(n^2d)$mml:mathmml:mrowmml:miO\u0026lt;/mml:mi\u0026gt;mml:mo(\u0026lt;/mml:mo\u0026gt;mml:msupmml:min\u0026lt;/mml:mi\u0026gt;mml:mn2\u0026lt;/mml:mn\u0026gt;\u0026lt;/mml:msup\u0026gt;mml:mid\u0026lt;/mml:mi\u0026gt;mml:mo)\u0026lt;/mml:mo\u0026gt;\u0026lt;/mml:mrow\u0026gt;\u0026lt;/mml:math\u0026gt; at least, where $n$mml:mathmml:min\u0026lt;/mml:mi\u0026gt;\u0026lt;/mml:math\u0026gt;, $d$mml:mathmml:mid\u0026lt;/mml:mi\u0026gt;\u0026lt;/mml:math\u0026gt; and $m$mml:mathmml:mim\u0026lt;/mml:mi\u0026gt;\u0026lt;/mml:math\u0026gt; are the number of samples, dimensions, and anchors, respectively. Extensive experiments on several publicly available datasets demonstrate the efficiency and effectiveness of the proposed method.\nGOSH Akyildiz, Aljundi \u0026amp; Kaya (2020) Taha Atahan Akyildiz, Amro Alabsi Aljundi, K. Kaya. (2020)\nGOSH: Embedding Big Graphs on Small Hardware\nICPP\nPaper Link\nInfluential Citation Count (1), SS-ID (9c1d6253cf83028e00a3d120777263ac2882ad29)\nABSTRACT\nIn graph embedding, the connectivity information of a graph is used to represent each vertex as a point in a d-dimensional space. Unlike the original, irregular structural information, such a representation can be used for a multitude of machine learning tasks. Although the process is extremely useful in practice, it is indeed expensive and unfortunately, the graphs are becoming larger and harder to embed. Attempts at scaling up the process to larger graphs have been successful but often at a steep price in hardware requirements. We present Gosh, an approach for embedding graphs of arbitrary sizes on a single GPU with minimum constraints. Gosh utilizes a novel graph coarsening approach to compress the graph and minimize the work required for embedding, delivering high-quality embeddings at a fraction of the time compared to the state-of-the-art. In addition to this, it incorporates a decomposition schema that enables any arbitrarily large graph to be embedded using a single GPU with minimum constraints on the memory size. With these techniques, Gosh is able to embed a graph with over 65 million vertices and 1.8 billion edges in less than an hour on a single GPU and obtains a 93% AUCROC for link-prediction which can be increased to 95% by running the tool for 80 minutes.\nVERSE (Versatile Graph Embeddings from Similarity Measures) Tsitsulin et al. (2018) Anton Tsitsulin, D. Mottin, P. Karras, Emmanuel Müller. (2018)\nVERSE: Versatile Graph Embeddings from Similarity Measures\nWWW\nPaper Link\nInfluential Citation Count (46), SS-ID (2a2ec58c7813820592cd487d66ed0b249b846eb0)\nABSTRACT\nEmbedding a web-scale information network into a low-dimensional vector space facilitates tasks such as link prediction, classification, and visualization. Past research has addressed the problem of extracting such embeddings by adopting methods from words to graphs, without defining a clearly comprehensible graph-related objective. Yet, as we show, the objectives used in past works implicitly utilize similarity measures among graph nodes. In this paper, we carry the similarity orientation of previous works to its logical conclusion; we propose VERtex Similarity Embeddings (VERSE), a simple, versatile, and memory-efficient method that derives graph embeddings explicitly calibrated to preserve the distributions of a selected vertex-to-vertex similarity measure. VERSE learns such embeddings by training a single-layer neural network. While its default, scalable version does so via sampling similarity information, we also develop a variant using the full information per vertex. Our experimental study on standard benchmarks and real-world datasets demonstrates that VERSE, instantiated with diverse similarity measures, outperforms state-of-the-art methods in terms of precision and recall in major data mining tasks and supersedes them in time and space efficiency, while the scalable sampling-based variant achieves equally good result as the non-scalable full variant.\nAtahan Akyildiz, Alabsi Aljundi \u0026amp; Kaya (2020) Atahan Akyildiz, Alabsi Aljundi \u0026amp; Kaya (2020) Taha Atahan Akyildiz, Amro Alabsi Aljundi, K. Kaya. (2020)\nUnderstanding Coarsening for Embedding Large-Scale Graphs\n2020 IEEE International Conference on Big Data (Big Data)\nPaper Link\nInfluential Citation Count (0), SS-ID (c23308cf3cfc42002fcb212bcc6f5c9cd3f5d09e)\nABSTRACT\nA significant portion of the data today, e.g, social networks, web connections, etc., can be modeled by graphs. A proper analysis of graphs with Machine Learning (ML) algorithms has the potential to yield far-reaching insights into many areas of research and industry. However, the irregular structure of graph data constitutes an obstacle for running ML tasks on graphs such as link prediction, node classification, and anomaly detection. Graph embedding is a compute-intensive process of representing graphs as a set of vectors in a d-dimensional space, which in turn makes it amenable to ML tasks. Many approaches have been proposed in the literature to improve the performance of graph embedding, e.g., using distributed algorithms, accelerators, and pre-processing techniques. Graph coarsening, which can be considered a pre-processing step, is a structural approximation of a given, large graph with a smaller one. As the literature suggests, the cost of embedding significantly decreases when coarsening is employed. In this work, we thoroughly analyze the impact of the coarsening quality on the embedding performance both in terms of speed and accuracy. Our experiments with a state-of-the-art, fast graph embedding tool show that there is an interplay between the coarsening decisions taken and the embedding quality.\nGallicchio \u0026amp; Micheli (2019) Gallicchio \u0026amp; Micheli (2019) C. Gallicchio, A. Micheli. (2019)\nFast and Deep Graph Neural Networks\nAAAI\nPaper Link\nInfluential Citation Count (4), SS-ID (cc56d1210f4ee7a5a351cf64eb3bbed18b48b22f)\nABSTRACT\nWe address the efficiency issue for the construction of a deep graph neural network (GNN). The approach exploits the idea of representing each input graph as a fixed point of a dynamical system (implemented through a recurrent neural network), and leverages a deep architectural organization of the recurrent units. Efficiency is gained by many aspects, including the use of small and very sparse networks, where the weights of the recurrent units are left untrained under the stability condition introduced in this work. This can be viewed as a way to study the intrinsic power of the architecture of a deep GNN, and also to provide insights for the set-up of more complex fully-trained models. Through experimental results, we show that even without training of the recurrent connections, the architecture of small deep GNN is surprisingly able to achieve or improve the state-of-the-art performance on a significant set of tasks in the field of graphs classification.\nLu \u0026amp; Chang (2020) Lu \u0026amp; Chang (2020) Ping-En Lu, Cheng-Shang Chang. (2020)\nExplainable, Stable, and Scalable Graph Convolutional Networks for Learning Graph Representation\nArXiv\nPaper Link\nInfluential Citation Count (0), SS-ID (af4b880f6b30b5510cc78092dcf71d3ea52329e0)\nABSTRACT\nThe network embedding problem that maps nodes in a graph to vectors in Euclidean space can be very useful for addressing several important tasks on a graph. Recently, graph neural networks (GNNs) have been proposed for solving such a problem. However, most embedding algorithms and GNNs are difficult to interpret and do not scale well to handle millions of nodes. In this paper, we tackle the problem from a new perspective based on the equivalence of three constrained optimization problems: the network embedding problem, the trace maximization problem of the modularity matrix in a sampled graph, and the matrix factorization problem of the modularity matrix in a sampled graph. The optimal solutions to these three problems are the dominant eigenvectors of the modularity matrix. We proposed two algorithms that belong to a special class of graph convolutional networks (GCNs) for solving these problems: (i) Clustering As Feature Embedding GCN (CAFE-GCN) and (ii) sphere-GCN. Both algorithms are stable trace maximization algorithms, and they yield good approximations of dominant eigenvectors. Moreover, there are linear-time implementations for sparse graphs. In addition to solving the network embedding problem, both proposed GCNs are capable of performing dimensionality reduction. Various experiments are conducted to evaluate our proposed GCNs and show that our proposed GCNs outperform almost all the baseline methods. Moreover, CAFE-GCN could be benefited from the labeled data and have tremendous improvements in various performance metrics.\nELAINE Goyal et al. (2018) Palash Goyal, Homa Hosseinmardi, Emilio Ferrara, A. Galstyan. (2018)\nEmbedding Networks with Edge Attributes\nHT\nPaper Link\nInfluential Citation Count (0), SS-ID (e4853de6d86315073a9e9e5d8957500cd24402c1)\nABSTRACT\nPredicting links in information networks requires deep understanding and careful modeling of network structure. Network embedding, which aims to learn low-dimensional representations of nodes, has been used successfully for the task of link prediction in the past few decades. Existing methods utilize the observed edges in the network to model the interactions between nodes and learn representations which explain the behavior. In addition to the presence of edges, networks often have information which can be used to improve the embedding. For example, in author collaboration networks, the bag of words representing the abstract of co-authored paper can be used as edge attributes. In this paper, we propose a novel approach, which uses the edges and their associated labels to learn node embeddings. Our model jointly optimizes higher order node neighborhood, social roles and edge attributes reconstruction error using deep architecture which can model highly non-linear interactions. We demonstrate the efficacy of our model over existing state-of-the-art methods on two real world data sets. We observe that such attributes can improve the quality of embedding and yield better performance in link prediction.\nHEBE Gui et al. (2016) Huan Gui, Jialu Liu, Fangbo Tao, Meng Jiang, Brandon Norick, Jiawei Han. (2016)\nLarge-Scale Embedding Learning in Heterogeneous Event Data\n2016 IEEE 16th International Conference on Data Mining (ICDM)\nPaper Link\nInfluential Citation Count (10), SS-ID (c18c30b9b1090e752031d23d219c1007b9954229)\nABSTRACT\nHeterogeneous events, which are defined as events connecting strongly-typed objects, are ubiquitous in the real world. We propose a HyperEdge-Based Embedding (Hebe) framework for heterogeneous event data, where a hyperedge represents the interaction among a set of involving objects in an event. The Hebe framework models the proximity among objects in an event by predicting a target object given the other participating objects in the event (hyperedge). Since each hyperedge encapsulates more information on a given event, Hebe is robust to data sparseness. In addition, Hebe is scalable when the data size spirals. Extensive experiments on large-scale real-world datasets demonstrate the efficacy and robustness of Hebe.\nReferences Recent developments in exponential random graph (p*) models for social networks (G. Robins et al., 2007) G. Robins, T. Snijders, Peng Wang, M. Handcock, P. Pattison. (2007)\nRecent developments in exponential random graph (p) models for social networks*\nSoc. Networks\nPaper Link\nInfluential Citation Count (58), SS-ID (00350a2b4adbaba0293ec10f73b759cfddde166e)\nABSTRACT\nThis article reviews new specifications for exponential random graph models proposed by Snijders et al. [Snijders, T.A.B., Pattison, P., Robins, G.L., Handcock, M., 2006. New specifications for exponential random graph models. Sociological Methodology] and demonstrates their improvement over homogeneous Markov random graph models in fitting empirical network data. Not only do the new specifications show improvements in goodness of fit for various data sets, but they also help to avoid the problem of near-degeneracy that often afflicts the fitting of Markov random graph models in practice, particularly to network data exhibiting high levels of transitivity. The inclusion of a new higher order transitivity statistic allows estimation of parameters of exponential graph models for many (but not all) cases where it is impossible to estimate parameters of homogeneous Markov graph models. The new specifications were used to model a large number of classical small-scale network data sets and showed a dramatically better performance than Markov graph models. We also review three current programs for obtaining maximum likelihood estimates of model parameters and we compare these Monte Carlo maximum likelihood estimates with less accurate pseudo-likelihood estimates. Finally, we discuss whether homogeneous Markov random graph models may be superseded by the new specifications, and how additional elaborations may further improve model performance.\nA Comprehensive Survey of Graph Embedding: Problems, Techniques, and Applications (Hongyun Cai et al., 2017) Hongyun Cai, V. Zheng, K. Chang. (2017)\nA Comprehensive Survey of Graph Embedding: Problems, Techniques, and Applications\nIEEE Transactions on Knowledge and Data Engineering\nPaper Link\nInfluential Citation Count (42), SS-ID (006906b6bbe5c1f378cde9fd86de1ce9e6b131da)\nABSTRACT\nGraph is an important data representation which appears in a wide diversity of real-world scenarios. Effective graph analytics provides users a deeper understanding of what is behind the data, and thus can benefit a lot of useful applications such as node classification, node recommendation, link prediction, etc. However, most graph analytics methods suffer the high computation and space cost. Graph embedding is an effective yet efficient way to solve the graph analytics problem. It converts the graph data into a low dimensional space in which the graph structural information and graph properties are maximumly preserved. In this survey, we conduct a comprehensive review of the literature in graph embedding. We first introduce the formal definition of graph embedding as well as the related concepts. After that, we propose two taxonomies of graph embedding which correspond to what challenges exist in different graph embedding problem settings and how the existing work addresses these challenges in their solutions. Finally, we summarize the applications that graph embedding enables and suggest four promising future research directions in terms of computation efficiency, problem settings, techniques, and application scenarios.\nmg2vec: Learning Relationship-Preserving Heterogeneous Graph Representations via Metagraph Embedding (Wentao Zhang et al., 2020) Wentao Zhang, Yuan Fang, Zemin Liu, Min Wu, Xinming Zhang. (2020)\nmg2vec: Learning Relationship-Preserving Heterogeneous Graph Representations via Metagraph Embedding\nIEEE Transactions on Knowledge and Data Engineering\nPaper Link\nInfluential Citation Count (0), SS-ID (00a33da57a6beef0abb5e315a2018433e8659429)\nABSTRACT\nGiven that heterogeneous information networks (HIN) encompass nodes and edges belonging to different semantic types, they can model complex data in real-world scenarios. Thus, HIN embedding has received increasing attention, which aims to learn node representations in a low-dimensional space, in order to preserve the structural and semantic information on the HIN. In this regard, metagraphs, which model common and recurring patterns on HINs, emerge as a powerful tool to capture semantic-rich and often latent relationships on HINs. Although metagraphs have been employed to address several specific data mining tasks, they have not been thoroughly explored for the more general HIN embedding. In this paper, we leverage metagraphs to learn relationship-preserving HIN embedding in a self-supervised setting, to support various relationship mining tasks. In particular, we observe that most of the current approaches often under-utilize metagraphs, which are only applied in a pre-processing step and do not actively guide representation learning afterwards. Thus, we propose the novel framework of mg2vec, which learns the embeddings for metagraphs and nodes jointly. That is, metagraphs actively participates in the learning process by mapping themselves to the same embedding space as the nodes do. Moreover, metagraphs guide the learning through both first- and second-order constraints on node embeddings, to model not only latent relationships between a pair of nodes, but also individual preferences of each node. Finally, we conduct extensive experiments on three public datasets. Results show that mg2vec significantly outperforms a suite of state-of-the-art baselines in relationship mining tasks including relationship prediction, search and visualization.\nHierarchical structure and the prediction of missing links in networks (A. Clauset et al., 2008) A. Clauset, C. Moore, M. Newman. (2008)\nHierarchical structure and the prediction of missing links in networks\nNature\nPaper Link\nInfluential Citation Count (83), SS-ID (00b7ffd43e9b6b70c80449872a8c9ec49c7d045a)\nABSTRACT\nNetworks have in recent years emerged as an invaluable tool for describing and quantifying complex systems in many branches of science. Recent studies suggest that networks often exhibit hierarchical organization, in which vertices divide into groups that further subdivide into groups of groups, and so forth over multiple scales. In many cases the groups are found to correspond to known functional units, such as ecological niches in food webs, modules in biochemical networks (protein interaction networks, metabolic networks or genetic regulatory networks) or communities in social networks. Here we present a general technique for inferring hierarchical structure from network data and show that the existence of hierarchy can simultaneously explain and quantitatively reproduce many commonly observed topological properties of networks, such as right-skewed degree distributions, high clustering coefficients and short path lengths. We further show that knowledge of hierarchical structure can be used to predict missing connections in partly known networks with high accuracy, and for more general network structures than competing techniques. Taken together, our results suggest that hierarchy is a central organizing principle of complex networks, capable of offering insight into many network phenomena.\nDeep Graph Kernels (Pinar Yanardag et al., 2015) Pinar Yanardag, S. Vishwanathan. (2015)\nDeep Graph Kernels\nKDD\nPaper Link\nInfluential Citation Count (160), SS-ID (00d736c540f80582279093cfc5ffe454a3226da9)\nABSTRACT\nIn this paper, we present Deep Graph Kernels, a unified framework to learn latent representations of sub-structures for graphs, inspired by latest advancements in language modeling and deep learning. Our framework leverages the dependency information between sub-structures by learning their latent representations. We demonstrate instances of our framework on three popular graph kernels, namely Graphlet kernels, Weisfeiler-Lehman subtree kernels, and Shortest-Path graph kernels. Our experiments on several benchmark datasets show that Deep Graph Kernels achieve significant improvements in classification accuracy over state-of-the-art graph kernels.\nGraph Embedding With Data Uncertainty (Firas Laakom et al., 2020) Firas Laakom, Jenni Raitoharju, N. Passalis, Alexandros Iosifidis, M. Gabbouj. (2020)\nGraph Embedding With Data Uncertainty\nIEEE Access\nPaper Link\nInfluential Citation Count (0), SS-ID (021e3e3f63194c5508e71706122372e96fdb1cdd)\nABSTRACT\nSpectral-based subspace learning is a common data preprocessing step in many machine learning pipelines. The main aim is to learn a meaningful low dimensional embedding of the data. However, most subspace learning methods do not take into consideration possible measurement inaccuracies or artifacts that can lead to data with high uncertainty. Thus, learning directly from raw data can be misleading and can negatively impact the accuracy. In this paper, we propose to model artifacts in training data using probability distributions; each data point is represented by a Gaussian distribution centered at the original data point and having a variance modeling its uncertainty. We reformulate the Graph Embedding framework to make it suitable for learning from distributions and we study as special cases the Linear Discriminant Analysis and the Marginal Fisher Analysis techniques. Furthermore, we propose two schemes for modeling data uncertainty based on pair-wise distances in an unsupervised and a supervised contexts.\nLearning to Represent Knowledge Graphs with Gaussian Embedding (Shizhu He et al., 2015) Shizhu He, Kang Liu, Guoliang Ji, Jun Zhao. (2015)\nLearning to Represent Knowledge Graphs with Gaussian Embedding\nCIKM\nPaper Link\nInfluential Citation Count (30), SS-ID (02e2059c328bd9fad4e676266435199663bed804)\nABSTRACT\nThe representation of a knowledge graph (KG) in a latent space recently has attracted more and more attention. To this end, some proposed models (e.g., TransE) embed entities and relations of a KG into a \u0026ldquo;point\u0026rdquo; vector space by optimizing a global loss function which ensures the scores of positive triplets are higher than negative ones. We notice that these models always regard all entities and relations in a same manner and ignore their (un)certainties. In fact, different entities and relations may contain different certainties, which makes identical certainty insufficient for modeling. Therefore, this paper switches to density-based embedding and propose KG2E for explicitly modeling the certainty of entities and relations, which learn the representations of KGs in the space of multi-dimensional Gaussian distributions. Each entity/relation is represented by a Gaussian distribution, where the mean denotes its position and the covariance (currently with diagonal covariance) can properly represent its certainty. In addition, compared with the symmetric measures used in point-based methods, we employ the KL-divergence for scoring triplets, which is a natural asymmetry function for effectively modeling multiple types of relations. We have conducted extensive experiments on link prediction and triplet classification with multiple benchmark datasets (WordNet and Freebase). Our experimental results demonstrate that our method can effectively model the (un)certainties of entities and relations in a KG, and it significantly outperforms state-of-the-art methods (including TransH and TransR).\nInductive matrix completion for predicting gene–disease associations (Nagarajan Natarajan et al., 2014) Nagarajan Natarajan, I. Dhillon. (2014)\nInductive matrix completion for predicting gene–disease associations\nBioinform.\nPaper Link\nInfluential Citation Count (30), SS-ID (02e34d24ebab52ee516c2ab50d93d360bde68187)\nABSTRACT\nMotivation: Most existing methods for predicting causal disease genes rely on specific type of evidence, and are therefore limited in terms of applicability. More often than not, the type of evidence available for diseases varies—for example, we may know linked genes, keywords associated with the disease obtained by mining text, or co-occurrence of disease symptoms in patients. Similarly, the type of evidence available for genes varies—for example, specific microarray probes convey information only for certain sets of genes. In this article, we apply a novel matrix-completion method called Inductive Matrix Completion to the problem of predicting gene-disease associations; it combines multiple types of evidence (features) for diseases and genes to learn latent factors that explain the observed gene–disease associations. We construct features from different biological sources such as microarray expression data and disease-related textual data. A crucial advantage of the method is that it is inductive; it can be applied to diseases not seen at training time, unlike traditional matrix-completion approaches and network-based inference methods that are transductive. Results: Comparison with state-of-the-art methods on diseases from the Online Mendelian Inheritance in Man (OMIM) database shows that the proposed approach is substantially better—it has close to one-in-four chance of recovering a true association in the top 100 predictions, compared to the recently proposed Catapult method (second best) that has \u0026lt;15% chance. We demonstrate that the inductive method is particularly effective for a query disease with no previously known gene associations, and for predicting novel genes, i.e. genes that are previously not linked to diseases. Thus the method is capable of predicting novel genes even for well-characterized diseases. We also validate the novelty of predictions by evaluating the method on recently reported OMIM associations and on associations recently reported in the literature. Availability: Source code and datasets can be downloaded from http://bigdata.ices.utexas.edu/project/gene-disease. Contact: naga86@cs.utexas.edu\nLearning latent representations of nodes for classifying in heterogeneous social networks (Yann Jacob et al., 2014) Yann Jacob, Ludovic Denoyer, P. Gallinari. (2014)\nLearning latent representations of nodes for classifying in heterogeneous social networks\nWSDM\nPaper Link\nInfluential Citation Count (6), SS-ID (030d436cb0465fd6cec0d5140b2534a8f1b8aeca)\nABSTRACT\nSocial networks are heterogeneous systems composed of different types of nodes (e.g. users, content, groups, etc.) and relations (e.g. social or similarity relations). While learning and performing inference on homogeneous networks have motivated a large amount of research, few work exists on heterogeneous networks and there are open and challenging issues for existing methods that were previously developed for homogeneous networks. We address here the specific problem of nodes classification and tagging in heterogeneous social networks, where different types of nodes are considered, each type with its own label or tag set. We propose a new method for learning node representations onto a latent space, common to all the different node types. Inference is then performed in this latent space. In this framework, two nodes connected in the network will tend to share similar representations regardless of their types. This allows bypassing limitations of the methods based on direct extensions of homogenous frameworks and exploiting the dependencies and correlations between the different node types. The proposed method is tested on two representative datasets and compared to state-of-the-art methods and to baselines.\nA Review of Relational Machine Learning for Knowledge Graphs (Maximilian Nickel et al., 2015) Maximilian Nickel, K. Murphy, Volker Tresp, E. Gabrilovich. (2015)\nA Review of Relational Machine Learning for Knowledge Graphs\nProceedings of the IEEE\nPaper Link\nInfluential Citation Count (111), SS-ID (033f25ad905ef2ed32a8331cf38b83953ff15922)\nABSTRACT\nRelational machine learning studies methods for the statistical analysis of relational, or graph-structured, data. In this paper, we provide a review of how such statistical models can be “trained” on large knowledge graphs, and then used to predict new facts about the world (which is equivalent to predicting new edges in the graph). In particular, we discuss two fundamentally different kinds of statistical relational models, both of which can scale to massive data sets. The first is based on latent feature models such as tensor factorization and multiway neural networks. The second is based on mining observable patterns in the graph. We also show how to combine these latent and observable models to get improved modeling power at decreased computational cost. Finally, we discuss how such statistical models of graphs can be combined with text-based information extraction methods for automatically constructing knowledge graphs from the Web. To this end, we also discuss Google\u0026rsquo;s knowledge vault project as an example of such combination.\nDistDGL: Distributed Graph Neural Network Training for Billion-Scale Graphs (Da Zheng et al., 2020) Da Zheng, Chao Ma, Minjie Wang, Jinjing Zhou, Qidong Su, Xiang Song, Quan Gan, Zheng Zhang, G. Karypis. (2020)\nDistDGL: Distributed Graph Neural Network Training for Billion-Scale Graphs\n2020 IEEE/ACM 10th Workshop on Irregular Applications: Architectures and Algorithms (IA3)\nPaper Link\nInfluential Citation Count (9), SS-ID (037df1500b9b8d4a57455b7ad205f86cc94a0b13)\nABSTRACT\nGraph neural networks (GNN) have shown great success in learning from graph-structured data. They are widely used in various applications, such as recommendation, fraud detection, and search. In these domains, the graphs are typically large, containing hundreds of millions of nodes and several billions of edges. To tackle this challenge, we develop DistDGL, a system for training GNNs in a mini-batch fashion on a cluster of machines. DistDGL is based on the Deep Graph Library (DGL), a popular GNN development framework. DistDGL distributes the graph and its associated data (initial features and embeddings) across the machines and uses this distribution to derive a computational decomposition by following an owner-compute rule. DistDGL follows a synchronous training approach and allows ego-networks forming the mini-batches to include non-local nodes. To minimize the overheads associated with distributed computations, DistDGL uses a high-quality and light-weight min-cut graph partitioning algorithm along with multiple balancing constraints. This allows it to reduce communication overheads and statically balance the computations. It further reduces the communication by replicating halo nodes and by using sparse embedding updates. The combination of these design choices allows DistDGL to train high-quality models while achieving high parallel efficiency and memory scalability. We demonstrate our optimizations on both inductive and transductive GNN models. Our results show that DistDGL achieves linear speedup without compromising model accuracy and requires only 13 seconds to complete a training epoch for a graph with 100 million nodes and 3 billion edges on a cluster with 16 machines.\nDual Graph Attention Networks for Deep Latent Representation of Multifaceted Social Effects in Recommender Systems (Qitian Wu et al., 2019) Qitian Wu, Hengrui Zhang, Xiaofeng Gao, Peng He, Paul Weng, Han Gao, Guihai Chen. (2019)\nDual Graph Attention Networks for Deep Latent Representation of Multifaceted Social Effects in Recommender Systems\nWWW\nPaper Link\nInfluential Citation Count (20), SS-ID (03ed44b85886a7a95d1533fb1d1a142e60ae292c)\nABSTRACT\nSocial recommendation leverages social information to solve data sparsity and cold-start problems in traditional collaborative filtering methods. However, most existing models assume that social effects from friend users are static and under the forms of constant weights or fixed constraints. To relax this strong assumption, in this paper, we propose dual graph attention networks to collaboratively learn representations for two-fold social effects, where one is modeled by a user-specific attention weight and the other is modeled by a dynamic and context-aware attention weight. We also extend the social effects in user domain to item domain, so that information from related items can be leveraged to further alleviate the data sparsity problem. Furthermore, considering that different social effects in two domains could interact with each other and jointly influence users\u0026rsquo; preferences for items, we propose a new policy-based fusion strategy based on contextual multi-armed bandit to weigh interactions of various social effects. Experiments on one benchmark dataset and a commercial dataset verify the efficacy of the key components in our model. The results show that our model achieves great improvement for recommendation accuracy compared with other state-of-the-art social recommendation methods.\nPrincipal component analysis (S. Wold et al., 1987) S. Wold, K. Esbensen, P. Geladi. (1987)\nPrincipal component analysis\nPaper Link\nInfluential Citation Count (338), SS-ID (040777d8e65e94a525a4e1cb778bb2a747ae8cb8)\nABSTRACT\nModeling polypharmacy side effects with graph convolutional networks (M. Zitnik et al., 2018) M. Zitnik, Monica Agrawal, J. Leskovec. (2018)\nModeling polypharmacy side effects with graph convolutional networks\nBioinform.\nPaper Link\nInfluential Citation Count (20), SS-ID (046c4276b72e21731150c0655519ec717d8f5bad)\nABSTRACT\nMotivation The use of drug combinations, termed polypharmacy, is common to treat patients with complex diseases or co‐existing conditions. However, a major consequence of polypharmacy is a much higher risk of adverse side effects for the patient. Polypharmacy side effects emerge because of drug‐drug interactions, in which activity of one drug may change, favorably or unfavorably, if taken with another drug. The knowledge of drug interactions is often limited because these complex relationships are rare, and are usually not observed in relatively small clinical testing. Discovering polypharmacy side effects thus remains an important challenge with significant implications for patient mortality and morbidity. Results Here, we present Decagon, an approach for modeling polypharmacy side effects. The approach constructs a multimodal graph of protein‐protein interactions, drug‐protein target interactions and the polypharmacy side effects, which are represented as drug‐drug interactions, where each side effect is an edge of a different type. Decagon is developed specifically to handle such multimodal graphs with a large number of edge types. Our approach develops a new graph convolutional neural network for multirelational link prediction in multimodal networks. Unlike approaches limited to predicting simple drug‐drug interaction values, Decagon can predict the exact side effect, if any, through which a given drug combination manifests clinically. Decagon accurately predicts polypharmacy side effects, outperforming baselines by up to 69%. We find that it automatically learns representations of side effects indicative of co‐occurrence of polypharmacy in patients. Furthermore, Decagon models particularly well polypharmacy side effects that have a strong molecular basis, while on predominantly non‐molecular side effects, it achieves good performance because of effective sharing of model parameters across edge types. Decagon opens up opportunities to use large pharmacogenomic and patient population data to flag and prioritize polypharmacy side effects for follow‐up analysis via formal pharmacological studies. Availability and implementation Source code and preprocessed datasets are at: http://snap.stanford.edu/decagon.\nProbabilistic Entity-Relationship Models, PRMs, and Plate Models (D. Heckerman et al., 2004) D. Heckerman, Christopher Meek, D. Koller. (2004)\nProbabilistic Entity-Relationship Models, PRMs, and Plate Models\nPaper Link\nInfluential Citation Count (13), SS-ID (04757f50d0021c8351237fad2f4002e59d5d8430)\nABSTRACT\nWe introduce a graphical language for re- lational data called the probabilistic entity- relationship (PER) model. The model is an extension of the entity-relationship model, a common model for the abstract repre- sentation of database structure. We con- centrate on the directed version of this model—the directed acyclic probabilistic entity-relationship (DAPER) model. The DAPER model is closely related to the plate model and the probabilistic relational model (PRM), existing models for relational data. The DAPER model is more expressive than either existing model, and also helps to demonstrate their similarity. dinary graphical models (e.g., directed-acyclic graphs and undirected graphs) are to flat data. In this paper, we introduce a new graphical model for relational data—the probabilistic entity-relationship (PER) model. This model class is more expressive than either PRMs or plate models. We concentrate on a particular type of PER model—the directed acyclic probabilistic entity-relationship (DAPER) model—in which all probabilistic arcs are directed. It is this ver- sion of PER model that is most similar to the plate model and PRM. We define new versions of the plate model and PRM such their expressiveness is equivalent to the DAPER model, and then (in the expanded tech report, Heckerman, Meek, and Koller, 2004) compare the new and old definitions. Consequently, we both demonstrate the similarity among the original lan- guages as well as enhance their abilities to express con- ditional independence in relational data. Our hope is that this demonstration of similarity will foster greater communication and collaboration among statisticians who mostly use plate models and computer scientists who mostly use PRMs. We in fact began this work with an effort to unify traditional PRMs and plate models. In the process, we discovered that it was important to make both entities and relationships (concepts discussed in de- tail in the next section) first class objects in the lan- guage. We in turn discovered an existing language that does this—the entity-relationship (ER) model—a commonly used model for the abstract representation of database structure. We then extended this language to handle probabilistic relationships, creating the PER model. We should emphasize that the languages we discuss are neither meant to serve as a database schema nor meant to be built on top of one. In practice, database schemas are built up over a long period of time as the needs of the database consumers change. Conse-\nDeep Reinforcement Learning for Electric Vehicle Routing Problem with Time Windows (Bo Lin et al., 2020) Bo Lin, Bissan Ghaddar, J. Nathwani. (2020)\nDeep Reinforcement Learning for Electric Vehicle Routing Problem with Time Windows\nArXiv\nPaper Link\nInfluential Citation Count (1), SS-ID (05b919f0ff46a9c3828d0899275a003bdcb1039d)\nABSTRACT\nThe past decade has seen a rapid penetration of electric vehicles (EV) in the market, more and more logistics and transportation companies start to deploy EVs for service provision. In order to model the operations of a commercial EV fleet, we utilize the EV routing problem with time windows (EVRPTW). In this research, we propose an end-to-end deep reinforcement learning framework to solve the EVRPTW. In particular, we develop an attention model incorporating the pointer network and a graph embedding technique to parameterize a stochastic policy for solving the EVRPTW. The model is then trained using policy gradient with rollout baseline. Our numerical studies show that the proposed model is able to efficiently solve EVRPTW instances of large sizes that are not solvable with any existing approaches.\nCluster-GCN: An Efficient Algorithm for Training Deep and Large Graph Convolutional Networks (Wei-Lin Chiang et al., 2019) Wei-Lin Chiang, Xuanqing Liu, Si Si, Yang Li, Samy Bengio, Cho-Jui Hsieh. (2019)\nCluster-GCN: An Efficient Algorithm for Training Deep and Large Graph Convolutional Networks\nKDD\nPaper Link\nInfluential Citation Count (65), SS-ID (05c4eb154ad9512a69569c18d68bc4428ee8bb83)\nABSTRACT\nGraph convolutional network (GCN) has been successfully applied to many graph-based applications; however, training a large-scale GCN remains challenging. Current SGD-based algorithms suffer from either a high computational cost that exponentially grows with number of GCN layers, or a large space requirement for keeping the entire graph and the embedding of each node in memory. In this paper, we propose Cluster-GCN, a novel GCN algorithm that is suitable for SGD-based training by exploiting the graph clustering structure. Cluster-GCN works as the following: at each step, it samples a block of nodes that associate with a dense subgraph identified by a graph clustering algorithm, and restricts the neighborhood search within this subgraph. This simple but effective strategy leads to significantly improved memory and computational efficiency while being able to achieve comparable test accuracy with previous algorithms. To test the scalability of our algorithm, we create a new Amazon2M data with 2 million nodes and 61 million edges which is more than 5 times larger than the previous largest publicly available dataset (Reddit). For training a 3-layer GCN on this data, Cluster-GCN is faster than the previous state-of-the-art VR-GCN (1523 seconds vs 1961 seconds) and using much less memory (2.2GB vs 11.2GB). Furthermore, for training 4 layer GCN on this data, our algorithm can finish in around 36 minutes while all the existing GCN training algorithms fail to train due to the out-of-memory issue. Furthermore, Cluster-GCN allows us to train much deeper GCN without much time and memory overhead, which leads to improved prediction accuracy\u0026mdash;using a 5-layer Cluster-GCN, we achieve state-of-the-art test F1 score 99.36 on the PPI dataset, while the previous best result was 98.71 by~\\citezhang2018gaan.\nCommunity-Based Question Answering via Heterogeneous Social Network Learning (Hanyin Fang et al., 2016) Hanyin Fang, Fei Wu, Zhou Zhao, Xinyu Duan, Yueting Zhuang, Martin Ester. (2016)\nCommunity-Based Question Answering via Heterogeneous Social Network Learning\nAAAI\nPaper Link\nInfluential Citation Count (9), SS-ID (06b0e8c067e249a2e71897c00730ec734d18c922)\nABSTRACT\nCommunity-based question answering (cQA) sites have accumulated vast amount of questions and corresponding crowdsourced answers over time. How to efficiently share the underlying information and knowledge from reliable (usually highly-reputable) answerers has become an increasingly popular research topic. A major challenge in cQA tasks is the accurate matching of high-quality answers w.r.t given questions. Many of traditional approaches likely recommend corresponding answers merely depending on the content similarity between questions and answers, therefore suffer from the sparsity bottleneck of cQA data. In this paper, we propose a novel framework which encodes not only the contents of question-answer(Q-A) but also the social interaction cues in the community to boost the cQA tasks. More specifically, our framework collaboratively utilizes the rich interaction among questions, answers and answerers to learn the relative quality rank of different answers w.r.t a same question. Moreover, the information in heterogeneous social networks is comprehensively employed to enhance the quality of question-answering (QA) matching by our deep random walk learning framework. Extensive experiments on a large-scale dataset from a real world cQA site show that leveraging the heterogeneous social information indeed achieves better performance than other state-of-the-art cQA methods.\nAn Attention Enhanced Graph Convolutional LSTM Network for Skeleton-Based Action Recognition (Chenyang Si et al., 2019) Chenyang Si, Wentao Chen, Wei Wang, Liang Wang, T. Tan. (2019)\nAn Attention Enhanced Graph Convolutional LSTM Network for Skeleton-Based Action Recognition\n2019 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)\nPaper Link\nInfluential Citation Count (29), SS-ID (074611d0c9f527bc0ad06f00df779f3361e38b83)\nABSTRACT\nSkeleton-based action recognition is an important task that requires the adequate understanding of movement characteristics of a human action from the given skeleton sequence. Recent studies have shown that exploring spatial and temporal features of the skeleton sequence is vital for this task. Nevertheless, how to effectively extract discriminative spatial and temporal features is still a challenging problem. In this paper, we propose a novel Attention Enhanced Graph Convolutional LSTM Network (AGC-LSTM) for human action recognition from skeleton data. The proposed AGC-LSTM can not only capture discriminative features in spatial configuration and temporal dynamics but also explore the co-occurrence relationship between spatial and temporal domains. We also present a temporal hierarchical architecture to increase temporal receptive fields of the top AGC-LSTM layer, which boosts the ability to learn the high-level semantic representation and significantly reduces the computation cost. Furthermore, to select discriminative spatial information, the attention mechanism is employed to enhance information of key joints in each AGC-LSTM layer. Experimental results on two datasets are provided: NTU RGB+D dataset and Northwestern-UCLA dataset. The comparison results demonstrate the effectiveness of our approach and show that our approach outperforms the state-of-the-art methods on both datasets.\nAsymmetric Transitivity Preserving Graph Embedding (Mingdong Ou et al., 2016) Mingdong Ou, Peng Cui, J. Pei, Ziwei Zhang, Wenwu Zhu. (2016)\nAsymmetric Transitivity Preserving Graph Embedding\nKDD\nPaper Link\nInfluential Citation Count (111), SS-ID (07627bf7eb649220ffbcdf6bf233e3a4a76e8590)\nABSTRACT\nGraph embedding algorithms embed a graph into a vector space where the structure and the inherent properties of the graph are preserved. The existing graph embedding methods cannot preserve the asymmetric transitivity well, which is a critical property of directed graphs. Asymmetric transitivity depicts the correlation among directed edges, that is, if there is a directed path from u to v, then there is likely a directed edge from u to v. Asymmetric transitivity can help in capturing structures of graphs and recovering from partially observed graphs. To tackle this challenge, we propose the idea of preserving asymmetric transitivity by approximating high-order proximity which are based on asymmetric transitivity. In particular, we develop a novel graph embedding algorithm, High-Order Proximity preserved Embedding (HOPE for short), which is scalable to preserve high-order proximities of large scale graphs and capable of capturing the asymmetric transitivity. More specifically, we first derive a general formulation that cover multiple popular high-order proximity measurements, then propose a scalable embedding algorithm to approximate the high-order proximity measurements based on their general formulation. Moreover, we provide a theoretical upper bound on the RMSE (Root Mean Squared Error) of the approximation. Our empirical experiments on a synthetic dataset and three real-world datasets demonstrate that HOPE can approximate the high-order proximities significantly better than the state-of-art algorithms and outperform the state-of-art algorithms in tasks of reconstruction, link prediction and vertex recommendation.\nLINE: Large-scale Information Network Embedding (Jian Tang et al., 2015) Jian Tang, Meng Qu, Mingzhe Wang, Ming Zhang, Jun Yan, Q. Mei. (2015)\nLINE: Large-scale Information Network Embedding\nWWW\nPaper Link\nInfluential Citation Count (832), SS-ID (0834e74304b547c9354b6d7da6fa78ef47a48fa8)\nABSTRACT\nThis paper studies the problem of embedding very large information networks into low-dimensional vector spaces, which is useful in many tasks such as visualization, node classification, and link prediction. Most existing graph embedding methods do not scale for real world information networks which usually contain millions of nodes. In this paper, we propose a novel network embedding method called the ``LINE,\u0026rsquo;\u0026rsquo; which is suitable for arbitrary types of information networks: undirected, directed, and/or weighted. The method optimizes a carefully designed objective function that preserves both the local and global network structures. An edge-sampling algorithm is proposed that addresses the limitation of the classical stochastic gradient descent and improves both the effectiveness and the efficiency of the inference. Empirical experiments prove the effectiveness of the LINE on a variety of real-world information networks, including language networks, social networks, and citation networks. The algorithm is very efficient, which is able to learn the embedding of a network with millions of vertices and billions of edges in a few hours on a typical single machine. The source code of the LINE is available online\\footnote{\\url{https://github.com/tangjianpku/LINE}}.\nData Poisoning Attack against Unsupervised Node Embedding Methods (Mingjie Sun et al., 2018) Mingjie Sun, Jian Tang, Huichen Li, Bo Li, Chaowei Xiao, Yao Chen, D. Song. (2018)\nData Poisoning Attack against Unsupervised Node Embedding Methods\nArXiv\nPaper Link\nInfluential Citation Count (8), SS-ID (088569b34d7f58bf4525ade7f391de98d62d601a)\nABSTRACT\nUnsupervised node embedding methods (e.g., DeepWalk, LINE, and node2vec) have attracted growing interests given their simplicity and effectiveness. However, although these methods have been proved effective in a variety of applications, none of the existing work has analyzed the robustness of them. This could be very risky if these methods are attacked by an adversarial party. In this paper, we take the task of link prediction as an example, which is one of the most fundamental problems for graph analysis, and introduce a data positioning attack to node embedding methods. We give a complete characterization of attacker\u0026rsquo;s utilities and present efficient solutions to adversarial attacks for two popular node embedding methods: DeepWalk and LINE. We evaluate our proposed attack model on multiple real-world graphs. Experimental results show that our proposed model can significantly affect the results of link prediction by slightly changing the graph structures (e.g., adding or removing a few edges). We also show that our proposed model is very general and can be transferable across different embedding methods. Finally, we conduct a case study on a coauthor network to better understand our attack method.\nEdge-Labeling Graph Neural Network for Few-Shot Learning (Jongmin Kim et al., 2019) Jongmin Kim, Taesup Kim, Sungwoong Kim, C. Yoo. (2019)\nEdge-Labeling Graph Neural Network for Few-Shot Learning\n2019 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)\nPaper Link\nInfluential Citation Count (29), SS-ID (098b138f58e43338248e3bc35cb36adfed8008d1)\nABSTRACT\nIn this paper, we propose a novel edge-labeling graph neural network (EGNN), which adapts a deep neural network on the edge-labeling graph, for few-shot learning. The previous graph neural network (GNN) approaches in few-shot learning have been based on the node-labeling framework, which implicitly models the intra-cluster similarity and the inter-cluster dissimilarity. In contrast, the proposed EGNN learns to predict the edge-labels rather than the node-labels on the graph that enables the evolution of an explicit clustering by iteratively updating the edge-labels with direct exploitation of both intra-cluster similarity and the inter-cluster dissimilarity. It is also well suited for performing on various numbers of classes without retraining, and can be easily extended to perform a transductive inference. The parameters of the EGNN are learned by episodic training with an edge-labeling loss to obtain a well-generalizable model for unseen low-data problem. On both of the supervised and semi-supervised few-shot image classification tasks with two benchmark datasets, the proposed EGNN significantly improves the performances over the existing GNNs.\nA measure of betweenness centrality based on random walks (M. Newman, 2003) M. Newman. (2003)\nA measure of betweenness centrality based on random walks\nSoc. Networks\nPaper Link\nInfluential Citation Count (123), SS-ID (0a575498f9e6bc0cc43b977c6e952101f89be90c)\nABSTRACT\nBootstrap Methods: Another Look at the Jackknife (D. Hinkley, 2008) D. Hinkley. (2008)\nBootstrap Methods: Another Look at the Jackknife\nPaper Link\nInfluential Citation Count (704), SS-ID (0ae3682872d58216559f7d69de1537a1b15a9592)\nABSTRACT\nGNN Explainer: A Tool for Post-hoc Explanation of Graph Neural Networks (Rex Ying et al., 2019) Rex Ying, Dylan Bourgeois, Jiaxuan You, M. Zitnik, J. Leskovec. (2019)\nGNN Explainer: A Tool for Post-hoc Explanation of Graph Neural Networks\nArXiv\nPaper Link\nInfluential Citation Count (13), SS-ID (0b00413174f2474d72cfc5c3e248b958ddcc8ee1)\nABSTRACT\nGraph Neural Networks (GNNs) are a powerful tool for machine learning on graphs. GNNs combine node feature information with the graph structure by using neural networks to pass messages through edges in the graph. However, incorporating both graph structure and feature information leads to complex non-linear models and explaining predictions made by GNNs remains to be a challenging task. Here we propose GnnExplainer, a general model-agnostic approach for providing interpretable explanations for predictions of any GNN-based model on any graph-based machine learning task (node and graph classification, link prediction). In order to explain a given node\u0026rsquo;s predicted label, GnnExplainer provides a local interpretation by highlighting relevant features as well as an important subgraph structure by identifying the edges that are most relevant to the prediction. Additionally, the model provides single-instance explanations when given a single prediction as well as multi-instance explanations that aim to explain predictions for an entire class of instances/nodes. We formalize GnnExplainer as an optimization task that maximizes the mutual information between the prediction of the full model and the prediction of simplified explainer model. We experiment on synthetic as well as real-world data. On synthetic data we demonstrate that our approach is able to highlight relevant topological structures from noisy graphs. We also demonstrate GnnExplainer to provide a better understanding of pre-trained models on real-world tasks. GnnExplainer provides a variety of benefits, from the identification of semantically relevant structures to explain predictions to providing guidance when debugging faulty graph neural network models.\nAdversarial Directed Graph Embedding (Shijie Zhu et al., 2020) Shijie Zhu, Jianxin Li, Hao Peng, Senzhang Wang, Philip S. Yu, Lifang He. (2020)\nAdversarial Directed Graph Embedding\nAAAI\nPaper Link\nInfluential Citation Count (0), SS-ID (0d4677ce389c1c1ef02c7d4e206d902c4f51bdb3)\nABSTRACT\nNode representation learning for directed graphs is critically important to facilitate many graph mining tasks. To capture the directed edges between nodes, existing methods mostly learn two embedding vectors for each node, source vector and target vector. However, these methods learn the source and target vectors separately. For the node with very low indegree or outdegree, the corresponding target vector or source vector cannot be effectively learned. In this paper, we propose a novel Directed Graph embedding framework based on Generative Adversarial Network, called DGGAN. The main idea is to use adversarial mechanisms to deploy a discriminator and two generators that jointly learn each node\u0026rsquo;s source and target vectors. For a given node, the two generators are trained to generate its fake target and source neighbor nodes from the same underlying distribution, and the discriminator aims to distinguish whether a neighbor node is real or fake. The two generators are formulated into a unified framework and could mutually reinforce each other to learn more robust source and target vectors. Extensive experiments show that DGGAN consistently and significantly outperforms existing state-of-the-art methods across multiple graph mining tasks on directed graphs.\nTransition-based Knowledge Graph Embedding with Relational Mapping Properties (M. Fan et al., 2014) M. Fan, Qiang Zhou, E. Chang, T. Zheng. (2014)\nTransition-based Knowledge Graph Embedding with Relational Mapping Properties\nPACLIC\nPaper Link\nInfluential Citation Count (7), SS-ID (0dddf37145689e5f2899f8081d9971882e6ff1e9)\nABSTRACT\nMany knowledge repositories nowadays contain billions of triplets, i.e. (head-entity, relationship, tail-entity), as relation instances. These triplets form a directed graph with entities as nodes and relationships as edges. However, this kind of symbolic and discrete storage structure makes it difficult for us to exploit the knowledge to enhance other intelligenceacquired applications (e.g. the QuestionAnswering System), as many AI-related algorithms prefer conducting computation on continuous data. Therefore, a series of emerging approaches have been proposed to facilitate knowledge computing via encoding the knowledge graph into a low-dimensional embedding space. TransE is the latest and most promising approach among them, and can achieve a higher performance with fewer parameters by modeling the relationship as a transitional vector from the head entity to the tail entity. Unfortunately, it is not flexible enough to tackle well with the various mapping properties of triplets, even though its authors spot the harm on performance. In this paper, we thus propose a superior model called TransM to leverage the structure of the knowledge graph via pre-calculating the distinct weight for each training triplet according to its relational mapping property. In this way, the optimal function deals with each triplet depending on its own weight. We carry out extensive experiments to compare TransM with the state-of-the-art method TransE and other prior arts. The performance of each approach is evaluated within two different application scenarios on several benchmark datasets. Results show that the model we proposed significantly outperforms the former ones with lower parameter complexity as TransE.\nGeometric Deep Learning: Going beyond Euclidean data (M. Bronstein et al., 2016) M. Bronstein, Joan Bruna, Yann LeCun, Arthur D. Szlam, P. Vandergheynst. (2016)\nGeometric Deep Learning: Going beyond Euclidean data\nIEEE Signal Processing Magazine\nPaper Link\nInfluential Citation Count (113), SS-ID (0e779fd59353a7f1f5b559b9d65fa4bfe367890c)\nABSTRACT\nMany scientific fields study data with an underlying structure that is non-Euclidean. Some examples include social networks in computational social sciences, sensor networks in communications, functional networks in brain imaging, regulatory networks in genetics, and meshed surfaces in computer graphics. In many applications, such geometric data are large and complex (in the case of social networks, on the scale of billions) and are natural targets for machine-learning techniques. In particular, we would like to use deep neural networks, which have recently proven to be powerful tools for a broad range of problems from computer vision, natural-language processing, and audio analysis. However, these tools have been most successful on data with an underlying Euclidean or grid-like structure and in cases where the invariances of these structures are built into networks used to model them.\nGraph Kernels (S. Vishwanathan et al., 2008) S. Vishwanathan, N. Schraudolph, R. Kondor, K. Borgwardt. (2008)\nGraph Kernels\nJ. Mach. Learn. Res.\nPaper Link\nInfluential Citation Count (43), SS-ID (0ed97826dec2ae59a10da5dd5b9bae8e0164b624)\nABSTRACT\nWe present a unified framework to study graph kernels, special cases of which include the random walk (Gartner et al., 2003; Borgwardt et al., 2005) and marginalized (Kashima et al., 2003, 2004; Mahet al., 2004) graph kernels. Through reduction to a Sylvester equation we improve the time complexity of kernel computation between unlabeled graphs with n vertices from O(n6) to O(n3). We find a spectral decomposition approach even more efficient when computing entire kernel matrices. For labeled graphs we develop conjugate gradient and fixed-point methods that take O(dn3) time per iteration, where d is the size of the label set. By extending the necessary linear algebra to Reproducing Kernel Hilbert Spaces (RKHS) we obtain the same result for d-dimensional edge kernels, and O(n4) in the infinite-dimensional case; on sparse graphs these algorithms only take O(n2) time per iteration in all cases. Experiments on graphs from bioinformatics and other application domains show that these techniques can speed up computation of the kernel by an order of magnitude or more. We also show that certain rational kernels (Cortes et al., 2002, 2003, 2004) when specialized to graphs reduce to our random walk graph kernel. Finally, we relate our framework to R-convolution kernels (Haussler, 1999) and provide a kernel that is close to the optimal assignment kernel of kernel of Frohlich et al. (2006) yet provably positive semi-definite.\nMatching Node Embeddings for Graph Similarity (Giannis Nikolentzos et al., 2017) Giannis Nikolentzos, Polykarpos Meladianos, M. Vazirgiannis. (2017)\nMatching Node Embeddings for Graph Similarity\nAAAI\nPaper Link\nInfluential Citation Count (8), SS-ID (0f3d2a17809f999cd4ab9d97fd5eb71086580685)\nABSTRACT\nGraph kernels have emerged as a powerful tool for graph comparison. Most existing graph kernels focus on local properties of graphs and ignore global structure. In this paper, we compare graphs based on their global properties as these are captured by the eigenvectors of their adjacency matrices. We present two algorithms for both labeled and unlabeled graph comparison. These algorithms represent each graph as a set of vectors corresponding to the embeddings of its vertices. The similarity between two graphs is then determined using the Earth Mover’s Distance metric. These similarities do not yield a positive semidefinite matrix. To address for this, we employ an algorithm for SVM classification using indefinite kernels. We also present a graph kernel based on the Pyramid Match kernel that finds an approximate correspondence between the sets of vectors of the two graphs. We further improve the proposed kernel using the Weisfeiler-Lehman framework. We evaluate the proposed methods on several benchmark datasets for graph classification and compare their performance to state-of-the-art graph kernels. In most cases, the proposed algorithms outperform the competing methods, while their time complexity remains very attractive.\nstruc2vec: Learning Node Representations from Structural Identity (Leonardo F. R. Ribeiro et al., 2017) Leonardo F. R. Ribeiro, Pedro H. P. Saverese, Daniel R. Figueiredo. (2017)\nstruc2vec: Learning Node Representations from Structural Identity\nKDD\nPaper Link\nInfluential Citation Count (87), SS-ID (0f7f5679615effcc4c9b98cf2deb17c30744a6d7)\nABSTRACT\nStructural identity is a concept of symmetry in which network nodes are identified according to the network structure and their relationship to other nodes. Structural identity has been studied in theory and practice over the past decades, but only recently has it been addressed with representational learning techniques. This work presents struc2vec, a novel and flexible framework for learning latent representations for the structural identity of nodes. struc2vec uses a hierarchy to measure node similarity at different scales, and constructs a multilayer graph to encode structural similarities and generate structural context for nodes. Numerical experiments indicate that state-of-the-art techniques for learning node representations fail in capturing stronger notions of structural identity, while struc2vec exhibits much superior performance in this task, as it overcomes limitations of prior approaches. As a consequence, numerical experiments indicate that struc2vec improves performance on classification tasks that depend more on structural identity.\nAdversarial Attacks on Classification Models for Graphs (Daniel Zügner et al., 2018) Daniel Zügner, Amir Akbarnejad, Stephan Günnemann. (2018)\nAdversarial Attacks on Classification Models for Graphs\nPaper Link\nInfluential Citation Count (4), SS-ID (0fc40cdd2ddecf98511a4fc2dc1f0bca6e4bae47)\nABSTRACT\nDeep learning models for graphs have achieved strong performance for the task of node classification. Despite their proliferation, currently there is no study of their robustness to adversarial attacks. Yet, in domains where they are likely to be used, e.g. the web, adversaries are common. Can deep learning models for graphs be easily fooled? In this work, we introduce the first study of adversarial attacks on attributed graphs, specifically focusing on models exploiting ideas of graph convolutions. We generate adversarial perturbations targeting the node’s features and the graph structure, thus, taking the dependencies between instances in account. To cope with the underlying discrete domain we propose an efficient algorithm Nettack exploiting incremental computations. Our experimental study shows that accuracy of node classification significantly drops even when performing only few perturbations. Even more, our attacks are transferable: the learned attacks generalize to other state-of-the-art node classification models.\nLearning Temporal Interaction Graph Embedding via Coupled Memory Networks (Zhen Zhang et al., 2020) Zhen Zhang, Jiajun Bu, Martin Ester, Jianfeng Zhang, Chengwei Yao, Z. Li, Can Wang. (2020)\nLearning Temporal Interaction Graph Embedding via Coupled Memory Networks\nWWW\nPaper Link\nInfluential Citation Count (1), SS-ID (1184a394fa785a61e125128e699950d42df22c37)\nABSTRACT\nGraph embedding has become the research focus in both academic and industrial communities due to its powerful capabilities. The majority of existing work overwhelmingly learn node embeddings in the context of static, plain or attributed, homogeneous graphs. However, many real-world applications frequently involve bipartite graphs with temporal and attributed interaction edges, named temporal interaction graphs. The temporal interactions usually imply different facets of interest and might even evolve over time, thus putting forward huge challenges in learning effective node representations. In this paper, we propose a novel framework named TigeCMN to learn node representations from a sequence of temporal interactions. Specifically, we devise two coupled memory networks to store and update node embeddings in external matrices explicitly and dynamically, which forms deep matrix representations and could enhance the expressiveness of the node embeddings. We conduct experiments on two real-world datasets and the experimental results empirically demonstrate that TigeCMN can outperform the state-of-the-arts with different gains.\nA General Framework for Content-enhanced Network Representation Learning (Xiaofei Sun et al., 2016) Xiaofei Sun, Jiang Guo, Xiao Ding, Ting Liu. (2016)\nA General Framework for Content-enhanced Network Representation Learning\nArXiv\nPaper Link\nInfluential Citation Count (11), SS-ID (1268d2ae95f0b128678d6ce033ba8ea7f0d98be1)\nABSTRACT\nThis paper investigates the problem of network embedding, which aims at learning low-dimensional vector representation of nodes in networks. Most existing network embedding methods rely solely on the network structure, i.e., the linkage relationships between nodes, but ignore the rich content information associated with it, which is common in real world networks and beneficial to describing the characteristics of a node. In this paper, we propose content-enhanced network embedding (CENE), which is capable of jointly leveraging the network structure and the content information. Our approach integrates text modeling and structure modeling in a general framework by treating the content information as a special kind of node. Experiments on several real world net- works with application to node classification show that our models outperform all existing network embedding methods, demonstrating the merits of content information and joint learning.\nGeniePath: Graph Neural Networks with Adaptive Receptive Paths (Ziqi Liu et al., 2018) Ziqi Liu, Chaochao Chen, Longfei Li, Jun Zhou, Xiaolong Li, Le Song. (2018)\nGeniePath: Graph Neural Networks with Adaptive Receptive Paths\nAAAI\nPaper Link\nInfluential Citation Count (18), SS-ID (127af6effc74f073ac2442f6d82c944f562e2c0f)\nABSTRACT\nWe present, GeniePath, a scalable approach for learning adaptive receptive fields of neural networks defined on permutation invariant graph data. In GeniePath, we propose an adaptive path layer consists of two complementary functions designed for breadth and depth exploration respectively, where the former learns the importance of different sized neighborhoods, while the latter extracts and filters signals aggregated from neighbors of different hops away. Our method works in both transductive and inductive settings, and extensive experiments compared with competitive methods show that our approaches yield state-of-the-art results on large graphs.\nApplications of Link Prediction (V. Srinivas et al., 2016) V. Srinivas, Pabitra Mitra. (2016)\nApplications of Link Prediction\nPaper Link\nInfluential Citation Count (0), SS-ID (1303eb6de99d55c8046bf286a0d341fa614d71d0)\nABSTRACT\nLink prediction has a wide variety of applications. Graphs provide a natural abstraction to represent interactions between different entities in a network. We can have graphs representing social networks, transportation networks, disease networks, email/telephone calls network to list a few. Link prediction can specifically be applied on these networks to analyze and solve interesting problems like predicting outbreak of a disease, controlling privacy in networks, detecting spam emails, suggesting alternative routes for possible navigation based on the current traffic patterns, etc.\nGeometric Matrix Completion with Recurrent Multi-Graph Neural Networks (Federico Monti et al., 2017) Federico Monti, M. Bronstein, X. Bresson. (2017)\nGeometric Matrix Completion with Recurrent Multi-Graph Neural Networks\nNIPS\nPaper Link\nInfluential Citation Count (51), SS-ID (137bbe604334584fd4a1d6eb9218a588ae3dda3e)\nABSTRACT\nMatrix completion models are among the most common formulations of recommender systems. Recent works have showed a boost of performance of these techniques when introducing the pairwise relationships between users/items in the form of graphs, and imposing smoothness priors on these graphs. However, such techniques do not fully exploit the local stationarity structures of user/item graphs, and the number of parameters to learn is linear w.r.t. the number of users and items. We propose a novel approach to overcome these limitations by using geometric deep learning on graphs. Our matrix completion architecture combines graph convolutional neural networks and recurrent neural networks to learn meaningful statistical graph-structured patterns and the non-linear diffusion process that generates the known ratings. This neural network system requires a constant number of parameters independent of the matrix size. We apply our method on both synthetic and real datasets, showing that it outperforms state-of-the-art techniques.\nTemporal Graph Networks for Deep Learning on Dynamic Graphs (Emanuele Rossi et al., 2020) Emanuele Rossi, B. Chamberlain, F. Frasca, D. Eynard, Federico Monti, M. Bronstein. (2020)\nTemporal Graph Networks for Deep Learning on Dynamic Graphs\nArXiv\nPaper Link\nInfluential Citation Count (26), SS-ID (150f95f9c73820e0a0fa1546140e9f2bdfd25954)\nABSTRACT\nGraph Neural Networks (GNNs) have recently become increasingly popular due to their ability to learn complex systems of relations or interactions arising in a broad spectrum of problems ranging from biology and particle physics to social networks and recommendation systems. Despite the plethora of different models for deep learning on graphs, few approaches have been proposed thus far for dealing with graphs that present some sort of dynamic nature (e.g. evolving features or connectivity over time). In this paper, we present Temporal Graph Networks (TGNs), a generic, efficient framework for deep learning on dynamic graphs represented as sequences of timed events. Thanks to a novel combination of memory modules and graph-based operators, TGNs are able to significantly outperform previous approaches being at the same time more computationally efficient. We furthermore show that several previous models for learning on dynamic graphs can be cast as specific instances of our framework. We perform a detailed ablation study of different components of our framework and devise the best configuration that achieves state-of-the-art performance on several transductive and inductive prediction tasks for dynamic graphs.\nLearning Image and User Features for Recommendation in Social Networks (Xue Geng et al., 2015) Xue Geng, Hanwang Zhang, Jingwen Bian, Tat-Seng Chua. (2015)\nLearning Image and User Features for Recommendation in Social Networks\n2015 IEEE International Conference on Computer Vision (ICCV)\nPaper Link\nInfluential Citation Count (11), SS-ID (15f5721502c2905c555a4eb0a110d6fc211c1fb2)\nABSTRACT\nGood representations of data do help in many machine learning tasks such as recommendation. It is often a great challenge for traditional recommender systems to learn representative features of both users and images in large social networks, in particular, social curation networks, which are characterized as the extremely sparse links between users and images, and the extremely diverse visual contents of images. To address the challenges, we propose a novel deep model which learns the unified feature representations for both users and images. This is done by transforming the heterogeneous user-image networks into homogeneous low-dimensional representations, which facilitate a recommender to trivially recommend images to users by feature similarity. We also develop a fast online algorithm that can be easily scaled up to large networks in an asynchronously parallel way. We conduct extensive experiments on a representative subset of Pinterest, containing 1,456,540 images and 1,000,000 users. Results of image recommendation experiments demonstrate that our feature learning approach significantly outperforms other state-of-the-art recommendation methods.\nA Tutorial on Network Embeddings (Haochen Chen et al., 2018) Haochen Chen, Bryan Perozzi, Rami Al-Rfou, S. Skiena. (2018)\nA Tutorial on Network Embeddings\nArXiv\nPaper Link\nInfluential Citation Count (1), SS-ID (1706a4ef5556ecdd680416d46e033e0476290361)\nABSTRACT\nNetwork embedding methods aim at learning low-dimensional latent representation of nodes in a network. These representations can be used as features for a wide range of tasks on graphs such as classification, clustering, link prediction, and visualization. In this survey, we give an overview of network embeddings by summarizing and categorizing recent advancements in this research field. We first discuss the desirable properties of network embeddings and briefly introduce the history of network embedding algorithms. Then, we discuss network embedding methods under different scenarios, such as supervised versus unsupervised learning, learning embeddings for homogeneous networks versus for heterogeneous networks, etc. We further demonstrate the applications of network embeddings, and conclude the survey with future work in this area.\nDiffusion-Convolutional Neural Networks (James Atwood et al., 2015) James Atwood, D. Towsley. (2015)\nDiffusion-Convolutional Neural Networks\nNIPS\nPaper Link\nInfluential Citation Count (69), SS-ID (18b47b83a373f33d6b902a3615f42c10f7600d72)\nABSTRACT\nWe present diffusion-convolutional neural networks (DCNNs), a new model for graph-structured data. Through the introduction of a diffusion-convolution operation, we show how diffusion-based representations can be learned from graph-structured data and used as an effective basis for node classification. DCNNs have several attractive qualities, including a latent representation for graphical data that is invariant under isomorphism, as well as polynomial-time prediction and learning that can be represented as tensor operations and efficiently implemented on the GPU. Through several experiments with real structured datasets, we demonstrate that DCNNs are able to outperform probabilistic relational models and kernel-on-graph methods at relational node classification tasks.\nAutomatic Virtual Network Embedding: A Deep Reinforcement Learning Approach With Graph Convolutional Networks (Zhongxia Yan et al., 2020) Zhongxia Yan, Jingguo Ge, Yulei Wu, Liangxiong Li, Tong Li. (2020)\nAutomatic Virtual Network Embedding: A Deep Reinforcement Learning Approach With Graph Convolutional Networks\nIEEE Journal on Selected Areas in Communications\nPaper Link\nInfluential Citation Count (7), SS-ID (18b619339f0abfdae1edb19abb11f43ca4f90842)\nABSTRACT\nVirtual network embedding arranges virtual network services onto substrate network components. The performance of embedding algorithms determines the effectiveness and efficiency of a virtualized network, making it a critical part of the network virtualization technology. To achieve better performance, the algorithm needs to automatically detect the network status which is complicated and changes in a time-varying manner, and to dynamically provide solutions that can best fit the current network status. However, most existing algorithms fail to provide automatic embedding solutions in an acceptable running time. In this paper, we combine deep reinforcement learning with a novel neural network structure based on graph convolutional networks, and propose a new and efficient algorithm for automatic virtual network embedding. In addition, a parallel reinforcement learning framework is used in training along with a newly-designed multi-objective reward function, which has proven beneficial to the proposed algorithm for automatic embedding of virtual networks. Extensive simulation results under different scenarios show that our algorithm achieves best performance on most metrics compared with the existing state-of-the-art solutions, with upto 39.6% and 70.6% improvement on acceptance ratio and average revenue, respectively. Moreover, the results also demonstrate that the proposed solution possesses good robustness.\nKnowledge Graph Embedding via Dynamic Mapping Matrix (Guoliang Ji et al., 2015) Guoliang Ji, Shizhu He, Liheng Xu, Kang Liu, Jun Zhao. (2015)\nKnowledge Graph Embedding via Dynamic Mapping Matrix\nACL\nPaper Link\nInfluential Citation Count (130), SS-ID (18bd7cd489874ed9976b4f87a6a558f9533316e0)\nABSTRACT\nKnowledge graphs are useful resources for numerous AI applications, but they are far from completeness. Previous work such as TransE, TransH and TransR/CTransR regard a relation as translation from head entity to tail entity and the CTransR achieves state-of-the-art performance. In this paper, we propose a more fine-grained model named TransD, which is an improvement of TransR/CTransR. In TransD, we use two vectors to represent a named symbol object (entity and relation). The first one represents the meaning of a(n) entity (relation), the other one is used to construct mapping matrix dynamically. Compared with TransR/CTransR, TransD not only considers the diversity of relations, but also entities. TransD has less parameters and has no matrix-vector multiplication operations, which makes it can be applied on large scale graphs. In Experiments, we evaluate our model on two typical tasks including triplets classification and link prediction. Evaluation results show that our approach outperforms state-of-the-art methods.\nDeep Neural Networks for Learning Graph Representations (Shaosheng Cao et al., 2016) Shaosheng Cao, Wei Lu, Qiongkai Xu. (2016)\nDeep Neural Networks for Learning Graph Representations\nAAAI\nPaper Link\nInfluential Citation Count (59), SS-ID (1a37f07606d60df365d74752857e8ce909f700b3)\nABSTRACT\nIn this paper, we propose a novel model for learning graph representations, which generates a low-dimensional vector representation for each vertex by capturing the graph structural information. Different from other previous research efforts, we adopt a random surfing model to capture graph structural information directly, instead of using the sampling-based method for generating linear sequences proposed by Perozzi et al. (2014). The advantages of our approach will be illustrated from both theorical and empirical perspectives. We also give a new perspective for the matrix factorization method proposed by Levy and Goldberg (2014), in which the pointwise mutual information (PMI) matrix is considered as an analytical solution to the objective function of the skip-gram model with negative sampling proposed by Mikolov et al. (2013). Unlike their approach which involves the use of the SVD for finding the low-dimensitonal projections from the PMI matrix, however, the stacked denoising autoencoder is introduced in our model to extract complex features and model non-linearities. To demonstrate the effectiveness of our model, we conduct experiments on clustering and visualization tasks, employing the learned vertex representations as features. Empirical results on datasets of varying sizes show that our model outperforms other stat-of-the-art models in such tasks.\nVisualizing Data using t-SNE (L. V. D. Maaten et al., 2008) L. V. D. Maaten, Geoffrey E. Hinton. (2008)\nVisualizing Data using t-SNE\nPaper Link\nInfluential Citation Count (826), SS-ID (1c46943103bd7b7a2c7be86859995a4144d1938b)\nABSTRACT\nWe present a new technique called “t-SNE” that visualizes high-dimensional data by giving each datapoint a location in a two or three-dimensional map. The technique is a variation of Stochastic Neighbor Embedding (Hinton and Roweis, 2002) that is much easier to optimize, and produces significantly better visualizations by reducing the tendency to crowd points together in the center of the map. t-SNE is better than existing techniques at creating a single map that reveals structure at many different scales. This is particularly important for high-dimensional data that lie on several different, but related, low-dimensional manifolds, such as images of objects from multiple classes seen from multiple viewpoints. For visualizing the structure of very large datasets, we show how t-SNE can use random walks on neighborhood graphs to allow the implicit structure of all of the data to influence the way in which a subset of the data is displayed. We illustrate the performance of t-SNE on a wide variety of datasets and compare it with many other non-parametric visualization techniques, including Sammon mapping, Isomap, and Locally Linear Embedding. The visualizations produced by t-SNE are significantly better than those produced by the other techniques on almost all of the datasets.\nCapped Lp-Norm Graph Embedding for Photo Clustering (Mengfan Tang et al., 2016) Mengfan Tang, F. Nie, R. Jain. (2016)\nCapped Lp-Norm Graph Embedding for Photo Clustering\nACM Multimedia\nPaper Link\nInfluential Citation Count (0), SS-ID (1cb5547c3f5ff42746bf9c4e083795aed3c8c609)\nABSTRACT\nPhotos are a predominant source of information on a global scale. Cluster analysis of photos can be applied to situation recognition and understanding cultural dynamics. Graph-based learning provides a current approach for modeling data in clustering problems. However, the performance of this framework depends heavily on initial graph construction by input data. Data outliers degrade graph quality, leading to poor clustering results. We designed a new capped lp-norm graph-based model to reduce the impact of outliers. This is accomplished by allowing the data graph to self adjust as part of the graph embedding. Furthermore, we derive an iterative algorithm to solve the objective function optimization problem. Experiments on four real-world benchmark data sets and Yahoo Flickr Creative Commons data set show the effectiveness of this new graph-based capped lp-norm clustering method.\nFrom Visual Data Exploration to Visual Data Mining: A Survey (M. C. Oliveira et al., 2003) M. C. Oliveira, H. Levkowitz. (2003)\nFrom Visual Data Exploration to Visual Data Mining: A Survey\nIEEE Trans. Vis. Comput. Graph.\nPaper Link\nInfluential Citation Count (22), SS-ID (1e008a1f5484094eb5794672d7c7318dd86f4fb5)\nABSTRACT\nWe survey work on the different uses of graphical mapping and interaction techniques for visual data mining of large data sets represented as table data. Basic terminology related to data mining, data sets, and visualization is introduced. Previous work on information visualization is reviewed in light of different categorizations of techniques and systems. The role of interaction techniques is discussed, in addition to work addressing the question of selecting and evaluating visualization techniques. We review some representative work on the use of information visualization techniques in the context of mining data. This includes both visual data exploration and visually expressing the outcome of specific mining algorithms. We also review recent innovative approaches that attempt to integrate visualization into the DM/KDD process, using it to enhance user interaction and comprehension.\nDropout Training of Matrix Factorization and Autoencoder for Link Prediction in Sparse Graphs (Shuangfei Zhai et al., 2015) Shuangfei Zhai, Zhongfei Zhang. (2015)\nDropout Training of Matrix Factorization and Autoencoder for Link Prediction in Sparse Graphs\nSDM\nPaper Link\nInfluential Citation Count (3), SS-ID (1e79e7d3247c7fddebaf5242c661de79bf7f31a7)\nABSTRACT\nMatrix factorization (MF) and Autoencoder (AE) are among the most successful approaches of unsupervised learning. While MF based models have been extensively exploited in the graph modeling and link prediction literature, the AE family has not gained much attention. In this paper we investigate both MF and AE\u0026rsquo;s application to the link prediction problem in sparse graphs. We show the connection between AE and MF from the perspective of multiview learning, and further propose MF+AE: a model training MF and AE jointly with shared parameters. We apply dropout to training both the MF and AE parts, and show that it can significantly prevent overfitting by acting as an adaptive regularization. We conduct experiments on six real world sparse graph datasets, and show that MF+AE consistently outperforms the competing methods, especially on datasets that demonstrate strong non-cohesive structures.\nGraph-Based Global Reasoning Networks (Yunpeng Chen et al., 2018) Yunpeng Chen, Marcus Rohrbach, Zhicheng Yan, Shuicheng Yan, Jiashi Feng, Yannis Kalantidis. (2018)\nGraph-Based Global Reasoning Networks\n2019 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)\nPaper Link\nInfluential Citation Count (32), SS-ID (1eaee16f6395c9602ad1dc17e69a6e235ec9ddd6)\nABSTRACT\nGlobally modeling and reasoning over relations between regions can be beneficial for many computer vision tasks on both images and videos. Convolutional Neural Networks (CNNs) excel at modeling local relations by convolution operations, but they are typically inefficient at capturing global relations between distant regions and require stacking multiple convolution layers. In this work, we propose a new approach for reasoning globally in which a set of features are globally aggregated over the coordinate space and then projected to an interaction space where relational reasoning can be efficiently computed. After reasoning, relation-aware features are distributed back to the original coordinate space for down-stream tasks. We further present a highly efficient instantiation of the proposed approach and introduce the Global Reasoning unit (GloRe unit) that implements the coordinate-interaction space mapping by weighted global pooling and weighted broadcasting, and the relation reasoning via graph convolution on a small graph in interaction space. The proposed GloRe unit is lightweight, end-to-end trainable and can be easily plugged into existing CNNs for a wide range of tasks. Extensive experiments show our GloRe unit can consistently boost the performance of state-of-the-art backbone architectures, including ResNet, ResNeXt, SE-Net and DPN, for both 2D and 3D CNNs, on image classification, semantic segmentation and video action recognition task.\nLearning Structured Embeddings of Knowledge Bases (Antoine Bordes et al., 2011) Antoine Bordes, J. Weston, Ronan Collobert, Yoshua Bengio. (2011)\nLearning Structured Embeddings of Knowledge Bases\nAAAI\nPaper Link\nInfluential Citation Count (81), SS-ID (1f4a4769e4d2fb846e59c2f185e0377190739f18)\nABSTRACT\nMany Knowledge Bases (KBs) are now readily available and encompass colossal quantities of information thanks to either a long-term funding effort (e.g. WordNet, OpenCyc) or a collaborative process (e.g. Freebase, DBpedia). However, each of them is based on a different rigid symbolic framework which makes it hard to use their data in other systems. It is unfortunate because such rich structured knowledge might lead to a huge leap forward in many other areas of AI like natural language processing (word-sense disambiguation, natural language understanding, \u0026hellip;), vision (scene classification, image semantic annotation, \u0026hellip;) or collaborative filtering. In this paper, we present a learning process based on an innovative neural network architecture designed to embed any of these symbolic representations into a more flexible continuous vector space in which the original knowledge is kept and enhanced. These learnt embeddings would allow data from any KB to be easily used in recent machine learning methods for prediction and information retrieval. We illustrate our method on WordNet and Freebase and also present a way to adapt it to knowledge extraction from raw text.\nCAGE: Constrained deep Attributed Graph Embedding (Debora Nozza et al., 2020) Debora Nozza, E. Fersini, E. Messina. (2020)\nCAGE: Constrained deep Attributed Graph Embedding\nInf. Sci.\nPaper Link\nInfluential Citation Count (0), SS-ID (1f90f847e46bacc13364975166ff2c908436735d)\nABSTRACT\nIn this paper we deal with complex attributed graphs which can exhibit rich connectivity patterns and whose nodes are often associated with attributes, such as text or images. In order to analyze these graphs, the primary challenge is to find an effective way to represent them by preserving both structural properties and node attribute information. To create low-dimensional and meaningful embedded representations of these complex graphs, we propose a fully unsupervised model based on Deep Learning architectures, called Constrained Attributed Graph Embedding model (CAGE). The main contribution of the proposed model is the definition of a novel two-phase optimization problem that explicitly models node attributes to obtain a higher representation expressiveness while preserving the local and the global structural properties of the graph. We validated our approach on two different benchmark datasets for node classification. Experimental results demonstrate that this novel representation provides significant improvements compared to state of the art approaches, also showing higher robustness with respect to the size of the training data.\nAttention is All you Need (Ashish Vaswani et al., 2017) Ashish Vaswani, Noam M. Shazeer, Niki Parmar, Jakob Uszkoreit, Llion Jones, Aidan N. Gomez, Lukasz Kaiser, Illia Polosukhin. (2017)\nAttention is All you Need\nNIPS\nPaper Link\nInfluential Citation Count (7570), SS-ID (204e3073870fae3d05bcbc2f6a8e263d9b72e776)\nABSTRACT\nThe dominant sequence transduction models are based on complex recurrent or convolutional neural networks in an encoder-decoder configuration. The best performing models also connect the encoder and decoder through an attention mechanism. We propose a new simple network architecture, the Transformer, based solely on attention mechanisms, dispensing with recurrence and convolutions entirely. Experiments on two machine translation tasks show these models to be superior in quality while being more parallelizable and requiring significantly less time to train. Our model achieves 28.4 BLEU on the WMT 2014 English-to-German translation task, improving over the existing best results, including ensembles by over 2 BLEU. On the WMT 2014 English-to-French translation task, our model establishes a new single-model state-of-the-art BLEU score of 41.8 after training for 3.5 days on eight GPUs, a small fraction of the training costs of the best models from the literature. We show that the Transformer generalizes well to other tasks by applying it successfully to English constituency parsing both with large and limited training data.\nCANE: Context-Aware Network Embedding for Relation Modeling (Cunchao Tu et al., 2017) Cunchao Tu, Han Liu, Zhiyuan Liu, Maosong Sun. (2017)\nCANE: Context-Aware Network Embedding for Relation Modeling\nACL\nPaper Link\nInfluential Citation Count (36), SS-ID (20bb300eb3400f1af766110ff51feada78170674)\nABSTRACT\nNetwork embedding (NE) is playing a critical role in network analysis, due to its ability to represent vertices with efficient low-dimensional embedding vectors. However, existing NE models aim to learn a fixed context-free embedding for each vertex and neglect the diverse roles when interacting with other vertices. In this paper, we assume that one vertex usually shows different aspects when interacting with different neighbor vertices, and should own different embeddings respectively. Therefore, we present Context-Aware Network Embedding (CANE), a novel NE model to address this issue. CANE learns context-aware embeddings for vertices with mutual attention mechanism and is expected to model the semantic relationships between vertices more precisely. In experiments, we compare our model with existing NE models on three real-world datasets. Experimental results show that CANE achieves significant improvement than state-of-the-art methods on link prediction and comparable performance on vertex classification. The source code and datasets can be obtained from https://github.com/thunlp/CANE.\nPredicting MicroRNA-Disease Associations Using Network Topological Similarity Based on DeepWalk (Guanghui Li et al., 2017) Guanghui Li, Jiawei Luo, Qiu Xiao, C. Liang, Pingjian Ding, Buwen Cao. (2017)\nPredicting MicroRNA-Disease Associations Using Network Topological Similarity Based on DeepWalk\nIEEE Access\nPaper Link\nInfluential Citation Count (0), SS-ID (21b9fda2ae02e36e57b5727b9da8be3eda36a7d9)\nABSTRACT\nRecently, increasing experimental studies have shown that microRNAs (miRNAs) involved in multiple physiological processes are connected with several complex human diseases. Identifying human disease-related miRNAs will be useful in uncovering novel prognostic markers for cancer. Currently, several computational approaches have been developed for miRNA-disease association prediction based on the integration of additional biological information of diseases and miRNAs, such as disease semantic similarity and miRNA functional similarity. However, these methods do not work well when this information is unavailable. In this paper, we present a similarity-based miRNA-disease prediction method that enhances the existing association discovery methods through a topology-based similarity measure. DeepWalk, a deep learning method, is utilized in this paper to calculate similarities within a miRNA-disease association network. It shows superior predictive performance for 22 complex diseases, with area under the ROC curve scores ranging from 0.805 to 0.937 by using five-fold cross-validation. In addition, case studies on breast cancer, lung cancer, and prostatic cancer further justify the use of our method to discover latent miRNA-disease pairs.\nSIGNet: Scalable Embeddings for Signed Networks (Mohammad Raihanul Islam et al., 2017) Mohammad Raihanul Islam, B. Prakash, Naren Ramakrishnan. (2017)\nSIGNet: Scalable Embeddings for Signed Networks\nPAKDD\nPaper Link\nInfluential Citation Count (3), SS-ID (21bcb27995ae1007f4dabe5973c5fa6df7706f3e)\nABSTRACT\nRecent successes in word embedding and document embedding have motivated researchers to explore similar representations for networks and to use such representations for tasks such as edge prediction, node label prediction, and community detection. Such network embedding methods are largely focused on finding distributed representations for unsigned networks and are unable to discover embeddings that respect polarities inherent in edges. We propose SIGNet, a fast scalable embedding method suitable for signed networks. Our proposed objective function aims to carefully model the social structure implicit in signed networks by reinforcing the principles of social balance theory. Our method builds upon the traditional word2vec family of embedding approaches and adds a new targeted node sampling strategy to maintain structural balance in higher-order neighborhoods. We demonstrate the superiority of SIGNet over state-of-the-art methods proposed for both signed and unsigned networks on several real world datasets from different domains. In particular, SIGNet offers an approach to generate a richer vocabulary of features of signed networks to support representation and reasoning.\nBirds of a Feather: Homophily in Social Networks (M. McPherson et al., 2001) M. McPherson, L. Smith-Lovin, J. Cook. (2001)\nBirds of a Feather: Homophily in Social Networks\nPaper Link\nInfluential Citation Count (673), SS-ID (228bafce55e6f1cbe2c1df75b1949a1fb9c93eb3)\nABSTRACT\nSimilarity breeds connection. This principle—the homophily principle—structures network ties of every type, including marriage, friendship, work, advice, support, information transfer, exchange, comembership, and other types of relationship. The result is that people\u0026rsquo;s personal networks are homogeneous with regard to many sociodemographic, behavioral, and intrapersonal characteristics. Homophily limits people\u0026rsquo;s social worlds in a way that has powerful implications for the information they receive, the attitudes they form, and the interactions they experience. Homophily in race and ethnicity creates the strongest divides in our personal environments, with age, religion, education, occupation, and gender following in roughly that order. Geographic propinquity, families, organizations, and isomorphic positions in social systems all create contexts in which homophilous relations form. Ties between nonsimilar individuals also dissolve at a higher rate, which sets the stage for the formation of niches (localize\u0026hellip;\nTopology and Content Co-Alignment Graph Convolutional Learning (Min Shi et al., 2020) Min Shi, Yufei Tang, Xingquan Zhu. (2020)\nTopology and Content Co-Alignment Graph Convolutional Learning\nIEEE transactions on neural networks and learning systems\nPaper Link\nInfluential Citation Count (0), SS-ID (249ce8e6bf5db2d0e12a5212330acdff3683550f)\nABSTRACT\nIn traditional graph neural networks (GNNs), graph convolutional learning is carried out through topology-driven recursive node content aggregation for network representation learning. In reality, network topology and node content each provide unique and important information, and they are not always consistent because of noise, irrelevance, or missing links between nodes. A pure topology-driven feature aggregation approach between unaligned neighborhoods may deteriorate learning from nodes with poor structure-content consistency, due to the propagation of incorrect messages over the whole network. Alternatively, in this brief, we advocate a co-alignment graph convolutional learning (CoGL) paradigm, by aligning topology and content networks to maximize consistency. Our theme is to enforce the learning from the topology network to be consistent with the content network while simultaneously optimizing the content network to comply with the topology for optimized representation learning. Given a network, CoGL first reconstructs a content network from node features then co-aligns the content network and the original network through a unified optimization goal with: 1) minimized content loss; 2) minimized classification loss; and 3) minimized adversarial loss. Experiments on six benchmarks demonstrate that CoGL achieves comparable and even better performance compared with existing state-of-the-art GNN models.\nProbabilistic Latent Document Network Embedding (Tuan M. V. Le et al., 2014) Tuan M. V. Le, Hady W. Lauw. (2014)\nProbabilistic Latent Document Network Embedding\n2014 IEEE International Conference on Data Mining\nPaper Link\nInfluential Citation Count (8), SS-ID (24f7d72e92cadfa5c84949537639ce084b9d2092)\nABSTRACT\nA document network refers to a data type that can be represented as a graph of vertices, where each vertex is associated with a text document. Examples of such a data type include hyperlinked Web pages, academic publications with citations, and user profiles in social networks. Such data have very high-dimensional representations, in terms of text as well as network connectivity. In this paper, we study the problem of embedding, or finding a low-dimensional representation of a document network that \u0026ldquo;preserves\u0026rdquo; the data as much as possible. These embedded representations are useful for various applications driven by dimensionality reduction, such as visualization or feature selection. While previous works in embedding have mostly focused on either the textual aspect or the network aspect, we advocate a holistic approach by finding a unified low-rank representation for both aspects. Moreover, to lend semantic interpretability to the low-rank representation, we further propose to integrate topic modeling and embedding within a joint model. The gist is to join the various representations of a document (words, links, topics, and coordinates) within a generative model, and to estimate the hidden representations through MAP estimation. We validate our model on real-life document networks, showing that it outperforms comparable baselines comprehensively on objective evaluation metrics.\nTranslating Embeddings for Modeling Multi-relational Data (Antoine Bordes et al., 2013) Antoine Bordes, Nicolas Usunier, Alberto García-Durán, J. Weston, Oksana Yakhnenko. (2013)\nTranslating Embeddings for Modeling Multi-relational Data\nNIPS\nPaper Link\nInfluential Citation Count (1287), SS-ID (2582ab7c70c9e7fcb84545944eba8f3a7f253248)\nABSTRACT\nWe consider the problem of embedding entities and relationships of multi-relational data in low-dimensional vector spaces. Our objective is to propose a canonical model which is easy to train, contains a reduced number of parameters and can scale up to very large databases. Hence, we propose TransE, a method which models relationships by interpreting them as translations operating on the low-dimensional embeddings of the entities. Despite its simplicity, this assumption proves to be powerful since extensive experiments show that TransE significantly outperforms state-of-the-art methods in link prediction on two knowledge bases. Besides, it can be successfully trained on a large scale data set with 1M entities, 25k relationships and more than 17M training samples.\nSCAN: a structural clustering algorithm for networks (Xiaowei Xu et al., 2007) Xiaowei Xu, Nurcan Yuruk, Zhidan Feng, T. Schweiger. (2007)\nSCAN: a structural clustering algorithm for networks\nKDD \u0026lsquo;07\nPaper Link\nInfluential Citation Count (107), SS-ID (25dfac6955913c163a61bc6e2ae8c5c7f3ca8f87)\nABSTRACT\nNetwork clustering (or graph partitioning) is an important task for the discovery of underlying structures in networks. Many algorithms find clusters by maximizing the number of intra-cluster edges. While such algorithms find useful and interesting structures, they tend to fail to identify and isolate two kinds of vertices that play special roles - vertices that bridge clusters (hubs) and vertices that are marginally connected to clusters (outliers). Identifying hubs is useful for applications such as viral marketing and epidemiology since hubs are responsible for spreading ideas or disease. In contrast, outliers have little or no influence, and may be isolated as noise in the data. In this paper, we proposed a novel algorithm called SCAN (Structural Clustering Algorithm for Networks), which detects clusters, hubs and outliers in networks. It clusters vertices based on a structural similarity measure. The algorithm is fast and efficient, visiting each vertex only once. An empirical evaluation of the method using both synthetic and real datasets demonstrates superior performance over other methods such as the modularity-based algorithms.\nA Survey on Graph Drawing Beyond Planarity (W. Didimo et al., 2018) W. Didimo, G. Liotta, Fabrizio Montecchiani. (2018)\nA Survey on Graph Drawing Beyond Planarity\nACM Comput. Surv.\nPaper Link\nInfluential Citation Count (2), SS-ID (2900ef06167eb5684020db9ccfcb9fe42a07a919)\nABSTRACT\nGraph Drawing Beyond Planarity is a rapidly growing research area that classifies and studies geometric representations of nonplanar graphs in terms of forbidden crossing configurations. The aim of this survey is to describe the main research directions in this area, the most prominent known results, and some of the most challenging open problems.\nImpact of different metrics on multi-view clustering (Angela Serra et al., 2015) Angela Serra, D. Greco, R. Tagliaferri. (2015)\nImpact of different metrics on multi-view clustering\n2015 International Joint Conference on Neural Networks (IJCNN)\nPaper Link\nInfluential Citation Count (0), SS-ID (294b25ce7576ab5cc59ab0de1d36425cae7fab2a)\nABSTRACT\nClustering of patients allows to find groups of subjects with similar characteristics. This categorization can facilitate diagnosis, treatment decision and prognosis prediction. Heterogeneous genome-wide data sources capture different biological aspects that can be integrated in order to better categorize the patients. Clustering methods work by comparing how patients are similar or dissimilar in a suitable similarity space. While several clustering methods have been proposed, there is no systematic comparative study concerning the impact of similarity metrics on the cluster quality. We compared seven popular similarity measures (Pearson, Spearman and Kendall Correlations; Euclidean, Canberra, Minkowski and Manhattan Distances) in conjunction with two classical single-view clustering algorithms and a late integration approach (partitioning around medoids, hierarchical clustering and matrix factorization approaches), on high dimensional multi-view cancer data coming from the TCGA repository. Performance was measured against tumour subcategories classification. Only Euclidean and Minkowski distances showed similar results in terms of clustering similarity indexes. On the other hand, an absolute best similarity measure did not emerge in terms of misclassification, but it strongly depends on the data.\nSupervised random walks: predicting and recommending links in social networks (L. Backstrom et al., 2010) L. Backstrom, J. Leskovec. (2010)\nSupervised random walks: predicting and recommending links in social networks\nWSDM \u0026lsquo;11\nPaper Link\nInfluential Citation Count (79), SS-ID (29efbdf3f95cee97405accafdebd3bd374f1f003)\nABSTRACT\nPredicting the occurrence of links is a fundamental problem in networks. In the link prediction problem we are given a snapshot of a network and would like to infer which interactions among existing members are likely to occur in the near future or which existing interactions are we missing. Although this problem has been extensively studied, the challenge of how to effectively combine the information from the network structure with rich node and edge attribute data remains largely open. We develop an algorithm based on Supervised Random Walks that naturally combines the information from the network structure with node and edge level attributes. We achieve this by using these attributes to guide a random walk on the graph. We formulate a supervised learning task where the goal is to learn a function that assigns strengths to edges in the network such that a random walker is more likely to visit the nodes to which new links will be created in the future. We develop an efficient training algorithm to directly learn the edge strength estimation function. Our experiments on the Facebook social graph and large collaboration networks show that our approach outperforms state-of-the-art unsupervised approaches as well as approaches that are based on feature extraction.\nLabel Noise Reduction in Entity Typing by Heterogeneous Partial-Label Embedding (Xiang Ren et al., 2016) Xiang Ren, Wenqi He, Meng Qu, Clare R. Voss, Heng Ji, Jiawei Han. (2016)\nLabel Noise Reduction in Entity Typing by Heterogeneous Partial-Label Embedding\nKDD\nPaper Link\nInfluential Citation Count (18), SS-ID (2a1d2b775997d6e2e42a054ea0ed456af1060796)\nABSTRACT\nCurrent systems of fine-grained entity typing use distant supervision in conjunction with existing knowledge bases to assign categories (type labels) to entity mentions. However, the type labels so obtained from knowledge bases are often noisy (i.e., incorrect for the entity mention\u0026rsquo;s local context). We define a new task, Label Noise Reduction in Entity Typing (LNR), to be the automatic identification of correct type labels (type-paths) for training examples, given the set of candidate type labels obtained by distant supervision with a given type hierarchy. The unknown type labels for individual entity mentions and the semantic similarity between entity types pose unique challenges for solving the LNR task. We propose a general framework, called PLE, to jointly embed entity mentions, text features and entity types into the same low-dimensional space where, in that space, objects whose types are semantically close have similar representations. Then we estimate the type-path for each training example in a top-down manner using the learned embeddings. We formulate a global objective for learning the embeddings from text corpora and knowledge bases, which adopts a novel margin-based loss that is robust to noisy labels and faithfully models type correlation derived from knowledge bases. Our experiments on three public typing datasets demonstrate the effectiveness and robustness of PLE, with an average of 25% improvement in accuracy compared to next best method.\nVERSE: Versatile Graph Embeddings from Similarity Measures (Anton Tsitsulin et al., 2018) Anton Tsitsulin, D. Mottin, P. Karras, Emmanuel Müller. (2018)\nVERSE: Versatile Graph Embeddings from Similarity Measures\nWWW\nPaper Link\nInfluential Citation Count (46), SS-ID (2a2ec58c7813820592cd487d66ed0b249b846eb0)\nABSTRACT\nEmbedding a web-scale information network into a low-dimensional vector space facilitates tasks such as link prediction, classification, and visualization. Past research has addressed the problem of extracting such embeddings by adopting methods from words to graphs, without defining a clearly comprehensible graph-related objective. Yet, as we show, the objectives used in past works implicitly utilize similarity measures among graph nodes. In this paper, we carry the similarity orientation of previous works to its logical conclusion; we propose VERtex Similarity Embeddings (VERSE), a simple, versatile, and memory-efficient method that derives graph embeddings explicitly calibrated to preserve the distributions of a selected vertex-to-vertex similarity measure. VERSE learns such embeddings by training a single-layer neural network. While its default, scalable version does so via sampling similarity information, we also develop a variant using the full information per vertex. Our experimental study on standard benchmarks and real-world datasets demonstrates that VERSE, instantiated with diverse similarity measures, outperforms state-of-the-art methods in terms of precision and recall in major data mining tasks and supersedes them in time and space efficiency, while the scalable sampling-based variant achieves equally good result as the non-scalable full variant.\nGSSNN: Graph Smoothing Splines Neural Networks (Shichao Zhu et al., 2020) Shichao Zhu, Lewei Zhou, Shirui Pan, Chuan Zhou, Guiying Yan, Bin Wang. (2020)\nGSSNN: Graph Smoothing Splines Neural Networks\nAAAI\nPaper Link\nInfluential Citation Count (0), SS-ID (2a3e3607fb9fbfa0d637946ca48035e68e7fee45)\nABSTRACT\nGraph Neural Networks (GNNs) have achieved state-of-the-art performance in many graph data analysis tasks. However, they still suffer from two limitations for graph representation learning. First, they exploit non-smoothing node features which may result in suboptimal embedding and degenerated performance for graph classification. Second, they only exploit neighbor information but ignore global topological knowledge. Aiming to overcome these limitations simultaneously, in this paper, we propose a novel, flexible, and end-to-end framework, Graph Smoothing Splines Neural Networks (GSSNN), for graph classification. By exploiting the smoothing splines, which are widely used to learn smoothing fitting function in regression, we develop an effective feature smoothing and enhancement module Scaled Smoothing Splines (S3) to learn graph embedding. To integrate global topological information, we design a novel scoring module, which exploits closeness, degree, as well as self-attention values, to select important node features as knots for smoothing splines. These knots can be potentially used for interpreting classification results. In extensive experiments on biological and social datasets, we demonstrate that our model achieves state-of-the-arts and GSSNN is superior in learning more robust graph representations. Furthermore, we show that S3 module is easily plugged into existing GNNs to improve their performance.\nKnowledge Graph Embedding by Translating on Hyperplanes (Zhen Wang et al., 2014) Zhen Wang, Jianwen Zhang, Jianlin Feng, Zheng Chen. (2014)\nKnowledge Graph Embedding by Translating on Hyperplanes\nAAAI\nPaper Link\nInfluential Citation Count (372), SS-ID (2a3f862199883ceff5e3c74126f0c80770653e05)\nABSTRACT\nWe deal with embedding a large scale knowledge graph composed of entities and relations into a continuous vector space. TransE is a promising method proposed recently, which is very efficient while achieving state-of-the-art predictive performance. We discuss some mapping properties of relations which should be considered in embedding, such as reflexive, one-to-many, many-to-one, and many-to-many. We note that TransE does not do well in dealing with these properties. Some complex models are capable of preserving these mapping properties but sacrifice efficiency in the process. To make a good trade-off between model capacity and efficiency, in this paper we propose TransH which models a relation as a hyperplane together with a translation operation on it. In this way, we can well preserve the above mapping properties of relations with almost the same model complexity of TransE. Additionally, as a practical knowledge graph is often far from completed, how to construct negative examples to reduce false negative labels in training is very important. Utilizing the one-to-many/many-to-one mapping property of a relation, we propose a simple trick to reduce the possibility of false negative labeling. We conduct extensive experiments on link prediction, triplet classification and fact extraction on benchmark datasets like WordNet and Freebase. Experiments show TransH delivers significant improvements over TransE on predictive accuracy with comparable capability to scale up.\nLearning from labeled and unlabeled data with label propagation (Xiaojin Zhu et al., 2002) Xiaojin Zhu, Zoubin Ghahramani. (2002)\nLearning from labeled and unlabeled data with label propagation\nPaper Link\nInfluential Citation Count (158), SS-ID (2a4ca461fa847e8433bab67e7bfe4620371c1f77)\nABSTRACT\nWe investigate the use of unlabeled data to help labeled data in cl ssification. We propose a simple iterative algorithm, label pro pagation, to propagate labels through the dataset along high density are as d fined by unlabeled data. We analyze the algorithm, show its solution , and its connection to several other algorithms. We also show how to lear n p ameters by minimum spanning tree heuristic and entropy minimiz ation, and the algorithm’s ability to perform feature selection. Expe riment results are promising.\nGraphRNN: A Deep Generative Model for Graphs (Jiaxuan You et al., 2018) Jiaxuan You, Rex Ying, Xiang Ren, William L. Hamilton, J. Leskovec. (2018)\nGraphRNN: A Deep Generative Model for Graphs\nICML 2018\nPaper Link\nInfluential Citation Count (18), SS-ID (2afa9966c37b7747d954a4dcd61e986247783683)\nABSTRACT\nModeling and generating graphs is fundamental for studying networks in biology, engineering, and social sciences. However, modeling complex distributions over graphs and then efficiently sampling from these distributions is challenging due to the non-unique, high-dimensional nature of graphs and the complex, non-local dependencies that exist between edges in a given graph. Here we propose GraphRNN, a deep autoregressive model that addresses the above challenges and approximates any distribution of graphs with minimal assumptions about their structure. GraphRNN learns to generate graphs by training on a representative set of graphs and decomposes the graph generation process into a sequence of node and edge formations, conditioned on the graph structure generated so far. In order to quantitatively evaluate the performance of GraphRNN, we introduce a benchmark suite of datasets, baselines and novel evaluation metrics based on Maximum Mean Discrepancy, which measure distances between sets of graphs. Our experiments show that GraphRNN significantly outperforms all baselines, learning to generate diverse graphs that match the structural characteristics of a target set, while also scaling to graphs 50 times larger than previous deep models.\nRecommending Co-authorship via Network Embeddings and Feature Engineering: The case of National Research University Higher School of Economics (Ilya Makarov et al., 2018) Ilya Makarov, Olga Gerasimova, Pavel Sulimov, L. Zhukov. (2018)\nRecommending Co-authorship via Network Embeddings and Feature Engineering: The case of National Research University Higher School of Economics\nJCDL\nPaper Link\nInfluential Citation Count (0), SS-ID (2b9501a2f4dfe1341bb272f157791a89d712ffd6)\nABSTRACT\nCo-authorship networks contain hidden structural patterns of research collaboration. While some people may argue that the process of writing joint papers depends on mutual friendship, research interests, and university policy, we show that, given a temporal co-authorship network, one could predict the quality and quantity of future research publications. We are working on the comparison of existing graph embedding and feature engineering methods, presenting combined approach for constructing co-author recommender system formulated as link prediction problem. We also present a new link embedding operator improving the quality of link prediction base don embedding feature space. We evaluate our research on a single university publication dataset, providing meaningful interpretation of the obtained results.\nGraph Visualization and Navigation in Information Visualization: A Survey (I. Herman et al., 2000) I. Herman, G. Melançon, M. S. Marshall. (2000)\nGraph Visualization and Navigation in Information Visualization: A Survey\nIEEE Trans. Vis. Comput. Graph.\nPaper Link\nInfluential Citation Count (76), SS-ID (2bbb5387adb3bd725069b1914609dc08c4ed8571)\nABSTRACT\nThis is a survey on graph visualization and navigation techniques, as used in information visualization. Graphs appear in numerous applications such as Web browsing, state-transition diagrams, and data structures. The ability to visualize and to navigate in these potentially large, abstract graphs is often a crucial part of an application. Information visualization has specific requirements, which means that this survey approaches the results of traditional graph drawing from a different perspective.\nLearning multi-faceted representations of individuals from heterogeneous evidence using neural networks (Jiwei Li et al., 2015) Jiwei Li, Alan Ritter, Dan Jurafsky. (2015)\nLearning multi-faceted representations of individuals from heterogeneous evidence using neural networks\nArXiv\nPaper Link\nInfluential Citation Count (2), SS-ID (2dde8f7171522243870fef46a0c93e5bf7be45b9)\nABSTRACT\nInferring latent attributes of people online is an important social computing task, but requires integrating the many heterogeneous sources of information available on the web. We propose learning individual representations of people using neural nets to integrate rich linguistic and network evidence gathered from social media. The algorithm is able to combine diverse cues, such as the text a person writes, their attributes (e.g. gender, employer, education, location) and social relations to other people. We show that by integrating both textual and network evidence, these representations offer improved performance at four important tasks in social media inference on Twitter: predicting (1) gender, (2) occupation, (3) location, and (4) friendships for users. Our approach scales to large datasets and the learned representations can be used as general features in and have the potential to benefit a large number of downstream tasks including link prediction, community detection, or probabilistic reasoning over social networks.\nMulti-View Unsupervised Feature Selection with Adaptive Similarity and View Weight (Chenping Hou et al., 2017) Chenping Hou, F. Nie, Hong Tao, Dong-yun Yi. (2017)\nMulti-View Unsupervised Feature Selection with Adaptive Similarity and View Weight\nIEEE Transactions on Knowledge and Data Engineering\nPaper Link\nInfluential Citation Count (5), SS-ID (2ea8d4cfb92d6354caa76a7070a3a5e053e1b066)\nABSTRACT\nWith the advent of multi-view data, multi-view learning has become an important research direction in both machine learning and data mining. Considering the difficulty of obtaining labeled data in many real applications, we focus on the multi-view unsupervised feature selection problem. Traditional approaches all characterize the similarity by fixed and pre-defined graph Laplacian in each view separately and ignore the underlying common structures across different views. In this paper, we propose an algorithm named Multi-view Unsupervised Feature Selection with Adaptive Similarity and View Weight (ASVW) to overcome the above mentioned problems. Specifically, by leveraging the learning mechanism to characterize the common structures adaptively, we formulate the objective function by a common graph Laplacian across different views, together with the sparse $\\ell _{2,p}$ -norm constraint designed for feature selection. We develop an efficient algorithm to address the non-smooth minimization problem and prove that the algorithm will converge. To validate the effectiveness of ASVW, comparisons are made with some benchmark methods on real-world datasets. We also evaluate our method in the real sports action recognition task. The experimental results demonstrate the effectiveness of our proposed algorithm.\nAdversarial Attacks on Node Embeddings (Aleksandar Bojchevski et al., 2018) Aleksandar Bojchevski, Stephan Günnemann. (2018)\nAdversarial Attacks on Node Embeddings\nICML 2019\nPaper Link\nInfluential Citation Count (6), SS-ID (2fae42932811ff9307b6b4a5059c2300f3587b53)\nABSTRACT\nThe goal of network representation learning is to learn low-dimensional node embeddings that capture the graph structure and are useful for solving downstream tasks. However, despite the proliferation of such methods there is currently no study of their robustness to adversarial attacks. We provide the first adversarial vulnerability analysis on the widely used family of methods based on random walks. We derive efficient adversarial perturbations that poison the network structure and have a negative effect on both the quality of the embeddings and the downstream tasks. We further show that our attacks are transferable – they generalize to many models – and are successful even when the attacker has restricted actions.\nInfoGraph: Unsupervised and Semi-supervised Graph-Level Representation Learning via Mutual Information Maximization (Fan-Yun Sun et al., 2019) Fan-Yun Sun, Jordan Hoffmann, Jian Tang. (2019)\nInfoGraph: Unsupervised and Semi-supervised Graph-Level Representation Learning via Mutual Information Maximization\nICLR\nPaper Link\nInfluential Citation Count (50), SS-ID (2fb59ebe271d6b007bb0429c1701fd1004782d1b)\nABSTRACT\nThis paper studies learning the representations of whole graphs in both unsupervised and semi-supervised scenarios. Graph-level representations are critical in a variety of real-world applications such as predicting the properties of molecules and community analysis in social networks. Traditional graph kernel based methods are simple, yet effective for obtaining fixed-length representations for graphs but they suffer from poor generalization due to hand-crafted designs. There are also some recent methods based on language models (e.g. graph2vec) but they tend to only consider certain substructures (e.g. subtrees) as graph representatives. Inspired by recent progress of unsupervised representation learning, in this paper we proposed a novel method called InfoGraph for learning graph-level representations. We maximize the mutual information between the graph-level representation and the representations of substructures of different scales (e.g., nodes, edges, triangles). By doing so, the graph-level representations encode aspects of the data that are shared across different scales of substructures. Furthermore, we further propose InfoGraph*, an extension of InfoGraph for semi-supervised scenarios. InfoGraph* maximizes the mutual information between unsupervised graph representations learned by InfoGraph and the representations learned by existing supervised methods. As a result, the supervised encoder learns from unlabeled data while preserving the latent semantic space favored by the current supervised task. Experimental results on the tasks of graph classification and molecular property prediction show that InfoGraph is superior to state-of-the-art baselines and InfoGraph* can achieve performance competitive with state-of-the-art semi-supervised models.\nKnowledge Graph Embedding: A Survey of Approaches and Applications (Quan Wang et al., 2017) Quan Wang, Zhendong Mao, Bin Wang, Li Guo. (2017)\nKnowledge Graph Embedding: A Survey of Approaches and Applications\nIEEE Transactions on Knowledge and Data Engineering\nPaper Link\nInfluential Citation Count (100), SS-ID (30321b036607a7936221235ea8ec7cf7c1627100)\nABSTRACT\nKnowledge graph (KG) embedding is to embed components of a KG including entities and relations into continuous vector spaces, so as to simplify the manipulation while preserving the inherent structure of the KG. It can benefit a variety of downstream tasks such as KG completion and relation extraction, and hence has quickly gained massive attention. In this article, we provide a systematic review of existing techniques, including not only the state-of-the-arts but also those with latest trends. Particularly, we make the review based on the type of information used in the embedding task. Techniques that conduct embedding using only facts observed in the KG are first introduced. We describe the overall framework, specific model design, typical training procedures, as well as pros and cons of such techniques. After that, we discuss techniques that further incorporate additional information besides facts. We focus specifically on the use of entity types, relation paths, textual descriptions, and logical rules. Finally, we briefly introduce how KG embedding can be applied to and benefit a wide variety of downstream tasks such as KG completion, relation extraction, question answering, and so forth.\nExplainable Recommendation: A Survey and New Perspectives (Yongfeng Zhang et al., 2018) Yongfeng Zhang, Xu Chen. (2018)\nExplainable Recommendation: A Survey and New Perspectives\nFound. Trends Inf. Retr.\nPaper Link\nInfluential Citation Count (11), SS-ID (303b260d5bef9b5c87c868110ec429fe5ea934ad)\nABSTRACT\nExplainable recommendation attempts to develop models that generate not only high-quality recommendations but also intuitive explanations. The explanations may either be post-hoc or directly come from an explainable model (also called interpretable or transparent model in some contexts). Explainable recommendation tries to address the problem of why: by providing explanations to users or system designers, it helps humans to understand why certain items are recommended by the algorithm, where the human can either be users or system designers. Explainable recommendation helps to improve the transparency, persuasiveness, effectiveness, trustworthiness, and satisfaction of recommendation systems. It also facilitates system designers for better system debugging. In recent years, a large number of explainable recommendation approaches \u0026ndash; especially model-based methods \u0026ndash; have been proposed and applied in real-world systems. In this survey, we provide a comprehensive review for the explainable recommendation research. We first highlight the position of explainable recommendation in recommender system research by categorizing recommendation problems into the 5W, i.e., what, when, who, where, and why. We then conduct a comprehensive survey of explainable recommendation on three perspectives: 1) We provide a chronological research timeline of explainable recommendation. 2) We provide a two-dimensional taxonomy to classify existing explainable recommendation research. 3) We summarize how explainable recommendation applies to different recommendation tasks. We also devote a chapter to discuss the explanation perspectives in broader IR and AI/ML research. We end the survey by discussing potential future directions to promote the explainable recommendation research area and beyond.\nDeep Learning on Graphs: A Survey (Ziwei Zhang et al., 2018) Ziwei Zhang, Peng Cui, Wenwu Zhu. (2018)\nDeep Learning on Graphs: A Survey\nIEEE Transactions on Knowledge and Data Engineering\nPaper Link\nInfluential Citation Count (23), SS-ID (30b38ca8151bbd5a5ff45bce94297d1248ff58b5)\nABSTRACT\nDeep learning has been shown to be successful in a number of domains, ranging from acoustics, images, to natural language processing. However, applying deep learning to the ubiquitous graph data is non-trivial because of the unique characteristics of graphs. Recently, substantial research efforts have been devoted to applying deep learning methods to graphs, resulting in beneficial advances in graph analysis techniques. In this survey, we comprehensively review the different types of deep learning methods on graphs. We divide the existing methods into five categories based on their model architectures and training strategies: graph recurrent neural networks, graph convolutional networks, graph autoencoders, graph reinforcement learning, and graph adversarial methods. We then provide a comprehensive overview of these methods in a systematic manner mainly by following their development history. We also analyze the differences and compositions of different methods. Finally, we briefly outline the applications in which they have been used and discuss potential future research directions.\nVisualizing Large-scale and High-dimensional Data (Jian Tang et al., 2016) Jian Tang, J. Liu, Ming Zhang, Q. Mei. (2016)\nVisualizing Large-scale and High-dimensional Data\nWWW\nPaper Link\nInfluential Citation Count (31), SS-ID (30d0f3ec0f80439f561f9912831ea7f3ccf8133c)\nABSTRACT\nWe study the problem of visualizing large-scale and high-dimensional data in a low-dimensional (typically 2D or 3D) space. Much success has been reported recently by techniques that first compute a similarity structure of the data points and then project them into a low-dimensional space with the structure preserved. These two steps suffer from considerable computational costs, preventing the state-of-the-art methods such as the t-SNE from scaling to large-scale and high-dimensional data (e.g., millions of data points and hundreds of dimensions). We propose the LargeVis, a technique that first constructs an accurately approximated K-nearest neighbor graph from the data and then layouts the graph in the low-dimensional space. Comparing to t-SNE, LargeVis significantly reduces the computational cost of the graph construction step and employs a principled probabilistic model for the visualization step, the objective of which can be effectively optimized through asynchronous stochastic gradient descent with a linear time complexity. The whole procedure thus easily scales to millions of high-dimensional data points. Experimental results on real-world data sets demonstrate that the LargeVis outperforms the state-of-the-art methods in both efficiency and effectiveness. The hyper-parameters of LargeVis are also much more stable over different data sets.\nComplex network graph embedding method based on shortest path and MOEA/D for community detection (Weitong Zhang et al., 2020) Weitong Zhang, Ronghua Shang, L. Jiao. (2020)\nComplex network graph embedding method based on shortest path and MOEA/D for community detection\nAppl. Soft Comput.\nPaper Link\nInfluential Citation Count (0), SS-ID (322a2670adda4c595a6cae54801981c4fc9e005f)\nABSTRACT\nAs one of the main applications of graph embedding, community detection has always been a hot issue in the field of complex network data mining. This paper presents a complex network graph embedding method based on the shortest path matrix and decomposition multi-objective evolutionary algorithm (SP-MOEA/D) for community detection, which can better reflect the network structure at the level of network community structure. Firstly, by calculating the shortest path matrix between nodes in the network, the node relationship matrix is obtained by adding the node similarity. Next, aiming at the problem of community detection in disconnected networks, a decomposition-based multi-objective optimization method is proposed to assign distances to unrelated nodes. Then, the network similarity matrix is calculated based on the relationship matrix of network nodes, and the low-dimensional vector representation of nodes is obtained by random surfing strategy and multi-dimensional scaling method. Finally, the community structure of the network can be detected based on the obtained node representation structure. Starting from the essence of network structure and the tightness between nodes, this method can reflect the relationship characteristics of network nodes more effectively, and then obtain the vector representation of nodes which can more accurately reflect the information of community structure in networks. The test results on 11 networks show that the node vector representation results obtained by this method can better reflect the community structure information in complex networks.\nDiscriminative Embeddings of Latent Variable Models for Structured Data (H. Dai et al., 2016) H. Dai, Bo Dai, Le Song. (2016)\nDiscriminative Embeddings of Latent Variable Models for Structured Data\nICML\nPaper Link\nInfluential Citation Count (51), SS-ID (322cf9bcde458a45eaeca989a1eec92f7c6db984)\nABSTRACT\nKernel classifiers and regressors designed for structured data, such as sequences, trees and graphs, have significantly advanced a number of interdisciplinary areas such as computational biology and drug design. Typically, kernels are designed beforehand for a data type which either exploit statistics of the structures or make use of probabilistic generative models, and then a discriminative classifier is learned based on the kernels via convex optimization. However, such an elegant two-stage approach also limited kernel methods from scaling up to millions of data points, and exploiting discriminative information to learn feature representations. We propose, structure2vec, an effective and scalable approach for structured data representation based on the idea of embedding latent variable models into feature spaces, and learning such feature spaces using discriminative information. Interestingly, structure2vec extracts features by performing a sequence of function mappings in a way similar to graphical model inference procedures, such as mean field and belief propagation. In applications involving millions of data points, we showed that structure2vec runs 2 times faster, produces models which are 10, 000 times smaller, while at the same time achieving the state-of-the-art predictive performance.\nLearning to Cluster Faces on an Affinity Graph (Lei Yang et al., 2019) Lei Yang, Xiaohang Zhan, Dapeng Chen, Junjie Yan, Chen Change Loy, Dahua Lin. (2019)\nLearning to Cluster Faces on an Affinity Graph\n2019 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)\nPaper Link\nInfluential Citation Count (16), SS-ID (32873f6111963607d3f768f4685fe8137fdd1253)\nABSTRACT\nFace recognition sees remarkable progress in recent years, and its performance has reached a very high level. Taking it to a next level requires substantially larger data, which would involve prohibitive annotation cost. Hence, exploiting unlabeled data becomes an appealing alternative. Recent works have shown that clustering unlabeled faces is a promising approach, often leading to notable performance gains. Yet, how to effectively cluster, especially on a large-scale (i.e. million-level or above) dataset, remains an open question. A key challenge lies in the complex variations of cluster patterns, which make it difficult for conventional clustering methods to meet the needed accuracy. This work explores a novel approach, namely, learning to cluster instead of relying on hand-crafted criteria. Specifically, we propose a framework based on graph convolutional network, which combines a detection and a segmentation module to pinpoint face clusters. Experiments show that our method yields significantly more accurate face clusters, which, as a result, also lead to further performance gain in face recognition.\nLarge-scale structural and textual similarity-based mining of knowledge graph to predict drug-drug interactions (I. Abdelaziz et al., 2017) I. Abdelaziz, Achille Fokoue, O. Hassanzadeh, Ping Zhang, Mohammad Sadoghi. (2017)\nLarge-scale structural and textual similarity-based mining of knowledge graph to predict drug-drug interactions\nJ. Web Semant.\nPaper Link\nInfluential Citation Count (3), SS-ID (328aa2ad73e4aa715fecc1cd41c82f69c337562a)\nABSTRACT\nAdversarial Attack and Defense on Graph Data: A Survey (Lichao Sun et al., 2018) Lichao Sun, Yingtong Dou, Ji Wang, Philip S. Yu, B. Li. (2018)\nAdversarial Attack and Defense on Graph Data: A Survey\nArXiv\nPaper Link\nInfluential Citation Count (8), SS-ID (32fc920df7bb39acc34a9284e62a19438934f2d8)\nABSTRACT\nDeep neural networks (DNNs) have been widely applied to various applications including image classification, text generation, audio recognition, and graph data analysis. However, recent studies have shown that DNNs are vulnerable to adversarial attacks. Though there are several works studying adversarial attack and defense strategies on domains such as images and natural language processing, it is still difficult to directly transfer the learned knowledge to graph structure data due to its representation challenges. Given the importance of graph analysis, an increasing number of works start to analyze the robustness of machine learning models on graph data. Nevertheless, current studies considering adversarial behaviors on graph data usually focus on specific types of attacks with certain assumptions. In addition, each work proposes its own mathematical formulation which makes the comparison among different methods difficult. Therefore, in this paper, we aim to survey existing adversarial learning strategies on graph data and first provide a unified formulation for adversarial learning on graph data which covers most adversarial learning studies on graph. Moreover, we also compare different attacks and defenses on graph data and discuss their corresponding contributions and limitations. In this work, we systemically organize the considered works based on the features of each topic. This survey not only serves as a reference for the research community, but also brings a clear image researchers outside this research domain. Besides, we also create an online resource and keep updating the relevant papers during the last two years. More details of the comparisons of various studies based on this survey are open-sourced at this https URL.\nIncorporate Group Information to Enhance Network Embedding (Jifan Chen et al., 2016) Jifan Chen, Qi Zhang, Xuanjing Huang. (2016)\nIncorporate Group Information to Enhance Network Embedding\nCIKM\nPaper Link\nInfluential Citation Count (4), SS-ID (332ec914469af4ecbc4ada0631773febc030406e)\nABSTRACT\nThe problem of representing large-scale networks with low-dimensional vectors has received considerable attention in recent years. Except the networks that include only vertices and edges, a variety of networks contain information about groups or communities. For example, on Facebook, in addition to users and the follower-followee relations between them, users can also create and join groups. However, previous studies have rarely utilized this valuable information to generate embeddings of vertices. In this paper, we investigate a novel method for learning the network embeddings with valuable group information for large-scale networks. The proposed methods take both the inner structures of the groups and the information across groups into consideration. Experimental results demonstrate that the embeddings generated by the proposed methods significantly outperform state-of-the-art network embedding methods on two different scale real-world network\nArtificial Intelligence Scientific Documentation Dataset for Recommender Systems (F. Ortega et al., 2018) F. Ortega, J. Bobadilla, A. Gutiérrez, R. Hurtado, Xin Li. (2018)\nArtificial Intelligence Scientific Documentation Dataset for Recommender Systems\nIEEE Access\nPaper Link\nInfluential Citation Count (1), SS-ID (333037df391e5e82e67fbd75be9e5a98dd2d73eb)\nABSTRACT\nThe existing scientific documentation-based recommender systems focus on exploiting the citations and references information included in each research paper and also the lists of co-authors. In this way, it can be addressed the recommendation of related papers and even related authors. The approach we propose is original because instead of using each paper citations and co-authors, we relate each of the papers with their main research topics. This approach provides a semantic level superior to that currently used, which allows us to obtain useful results. We can use collaborative filtering recommender systems to recommend research topics related to each paper and also to recommend papers related to each research topic. In order to face this innovative proposal, we have solved a series of challenges that allow us to offer various resources and results in the paper. Our main contributions are: 1) making a data mining of scientific documentation; 2) creating and publishing an open database containing the data mining results; 3) extracting the research topics from the available scientific documentation; 4) creating and publishing a recommender system data set obtained from the database and the research topics; 5) testing the data set through a complete set of collaborative filtering methods and quality measures; and 6) selecting and showing the best methods and results, obtained using the open data set, in the context of scientific documentation recommendations. Results of the paper show the suitability of the provided data set in collaborative filtering processes, as well as the superiority of the model-based methods to face scientific documentation recommendations.\nGraph Attention Networks (Petar Velickovic et al., 2017) Petar Velickovic, Guillem Cucurull, Arantxa Casanova, Adriana Romero, P. Lio’, Yoshua Bengio. (2017)\nGraph Attention Networks\nICLR\nPaper Link\nInfluential Citation Count (1371), SS-ID (33998aff64ce51df8dee45989cdca4b6b1329ec4)\nABSTRACT\nWe present graph attention networks (GATs), novel neural network architectures that operate on graph-structured data, leveraging masked self-attentional layers to address the shortcomings of prior methods based on graph convolutions or their approximations. By stacking layers in which nodes are able to attend over their neighborhoods\u0026rsquo; features, we enable (implicitly) specifying different weights to different nodes in a neighborhood, without requiring any kind of costly matrix operation (such as inversion) or depending on knowing the graph structure upfront. In this way, we address several key challenges of spectral-based graph neural networks simultaneously, and make our model readily applicable to inductive as well as transductive problems. Our GAT models have achieved or matched state-of-the-art results across four established transductive and inductive graph benchmarks: the Cora, Citeseer and Pubmed citation network datasets, as well as a protein-protein interaction dataset (wherein test graphs remain unseen during training).\nIdentification of pathways associated with chemosensitivity through network embedding (Sheng Wang et al., 2019) Sheng Wang, Edward W. Huang, J. Cairns, Jian Peng, Liewei Wang, S. Sinha. (2019)\nIdentification of pathways associated with chemosensitivity through network embedding\nPLoS Comput. Biol.\nPaper Link\nInfluential Citation Count (0), SS-ID (33f7bc1fa413a47727d4cd741ffe1e7f95030604)\nABSTRACT\nBasal gene expression levels have been shown to be predictive of cellular response to cytotoxic treatments. However, such analyses do not fully reveal complex genotype- phenotype relationships, which are partly encoded in highly interconnected molecular networks. Biological pathways provide a complementary way of understanding drug response variation among individuals. In this study, we integrate chemosensitivity data from a large-scale pharmacogenomics study with basal gene expression data from the CCLE project and prior knowledge of molecular networks to identify specific pathways mediating chemical response. We first develop a computational method called PACER, which ranks pathways for enrichment in a given set of genes using a novel network embedding method. It examines a molecular network that encodes known gene-gene as well as gene-pathway relationships, and determines a vector representation of each gene and pathway in the same low-dimensional vector space. The relevance of a pathway to the given gene set is then captured by the similarity between the pathway vector and gene vectors. To apply this approach to chemosensitivity data, we identify genes whose basal expression levels in a panel of cell lines are correlated with cytotoxic response to a compound, and then rank pathways for relevance to these response-correlated genes using PACER. Extensive evaluation of this approach on benchmarks constructed from databases of compound target genes and large collections of drug response signatures demonstrates its advantages in identifying compound-pathway associations compared to existing statistical methods of pathway enrichment analysis. The associations identified by PACER can serve as testable hypotheses on chemosensitivity pathways and help further study the mechanisms of action of specific cytotoxic drugs. More broadly, PACER represents a novel technique of identifying enriched properties of any gene set of interest while also taking into account networks of known gene-gene relationships and interactions.\nGraph Neural Networks with Generated Parameters for Relation Extraction (Hao Zhu et al., 2019) Hao Zhu, Yankai Lin, Zhiyuan Liu, Jie Fu, Tat-Seng Chua, Maosong Sun. (2019)\nGraph Neural Networks with Generated Parameters for Relation Extraction\nACL\nPaper Link\nInfluential Citation Count (4), SS-ID (352ac73b7d92afa915c06026a4336927d550cec3)\nABSTRACT\nIn this paper, we propose a novel graph neural network with generated parameters (GP-GNNs). The parameters in the propagation module, i.e. the transition matrices used in message passing procedure, are produced by a generator taking natural language sentences as inputs. We verify GP-GNNs in relation extraction from text, both on bag- and instance-settings. Experimental results on a human-annotated dataset and two distantly supervised datasets show that multi-hop reasoning mechanism yields significant improvements. We also perform a qualitative analysis to demonstrate that our model could discover more accurate relations by multi-hop relational reasoning.\nA global geometric framework for nonlinear dimensionality reduction. (J. Tenenbaum et al., 2000) J. Tenenbaum, V. De Silva, J. Langford. (2000)\nA global geometric framework for nonlinear dimensionality reduction.\nScience\nPaper Link\nInfluential Citation Count (1143), SS-ID (3537fcd0ff99a3b3cb3d279012df826358420556)\nABSTRACT\nScientists working with large volumes of high-dimensional data, such as global climate patterns, stellar spectra, or human gene distributions, regularly confront the problem of dimensionality reduction: finding meaningful low-dimensional structures hidden in their high-dimensional observations. The human brain confronts the same problem in everyday perception, extracting from its high-dimensional sensory inputs-30,000 auditory nerve fibers or 10(6) optic nerve fibers-a manageably small number of perceptually relevant features. Here we describe an approach to solving dimensionality reduction problems that uses easily measured local metric information to learn the underlying global geometry of a data set. Unlike classical techniques such as principal component analysis (PCA) and multidimensional scaling (MDS), our approach is capable of discovering the nonlinear degrees of freedom that underlie complex natural observations, such as human handwriting or images of a face under different viewing conditions. In contrast to previous algorithms for nonlinear dimensionality reduction, ours efficiently computes a globally optimal solution, and, for an important class of data manifolds, is guaranteed to converge asymptotically to the true structure.\nHeterogeneous Information Network Embedding with Convolutional Graph Attention Networks (Meng Cao et al., 2020) Meng Cao, Xiying Ma, Kai Zhu, Ming Xu, Chong-Jun Wang. (2020)\nHeterogeneous Information Network Embedding with Convolutional Graph Attention Networks\n2020 International Joint Conference on Neural Networks (IJCNN)\nPaper Link\nInfluential Citation Count (0), SS-ID (3569199f440cc0178d5522644266c4b9b443e8ce)\nABSTRACT\nHeterogeneous Information Networks (HINs) are prevalent in our daily life, such as social networks and bibliography networks, which contain multiple types of nodes and links. Heterogeneous information network embedding is an effective HIN analysis method, it aims at projecting network elements into a lower-dimensional vector space for further machine learning related evaluations, such as node classification, node clustering, and so on. However, existing HIN embedding methods mainly focus on extracting the semantic-related information or close neighboring relations, while the high-level proximity of the network is also important but not preserved. To address the problem, in this paper we propose CGAT, a semi-supervised heterogeneous information network embedding method. We optimize the graph attention network by adding additional convolution layers, thereby we can extract multiple types of semantics and preserve high-level information in HIN embedding at the same time. Also, we utilize label information in HINs for semi-supervised training to better obtain the model parameters and HIN embeddings. Experimental results on real-world datasets demonstrate the effectiveness and efficiency of the proposed model.\nInter-sentence Relation Extraction with Document-level Graph Convolutional Neural Network (Sunil Kumar Sahu et al., 2019) Sunil Kumar Sahu, Fenia Christopoulou, Makoto Miwa, S. Ananiadou. (2019)\nInter-sentence Relation Extraction with Document-level Graph Convolutional Neural Network\nACL\nPaper Link\nInfluential Citation Count (13), SS-ID (358ca777d9992bdc06fdcc1940e3b18a8da68878)\nABSTRACT\nInter-sentence relation extraction deals with a number of complex semantic relationships in documents, which require local, non-local, syntactic and semantic dependencies. Existing methods do not fully exploit such dependencies. We present a novel inter-sentence relation extraction model that builds a labelled edge graph convolutional neural network model on a document-level graph. The graph is constructed using various inter- and intra-sentence dependencies to capture local and non-local dependency information. In order to predict the relation of an entity pair, we utilise multi-instance learning with bi-affine pairwise scoring. Experimental results show that our model achieves comparable performance to the state-of-the-art neural models on two biochemistry datasets. Our analysis shows that all the types in the graph are effective for inter-sentence relation extraction.\nHetETA: Heterogeneous Information Network Embedding for Estimating Time of Arrival (Huiting Hong et al., 2020) Huiting Hong, Yucheng Lin, Xiaoqing Yang, Zang Li, Kun Fu, Zheng Wang, X. Qie, Jieping Ye. (2020)\nHetETA: Heterogeneous Information Network Embedding for Estimating Time of Arrival\nKDD\nPaper Link\nInfluential Citation Count (1), SS-ID (364b6a10a827a6ba994d17baab2b2a2f1271dc29)\nABSTRACT\nThe estimated time of arrival (ETA) is a critical task in the intelligent transportation system, which involves the spatiotemporal data. Despite a significant amount of prior efforts have been made to design efficient and accurate systems for ETA task, few of them take structural graph data into account, much less the heterogeneous information network. In this paper, we propose HetETA to leverage heterogeneous information graph in ETA task. Specifically, we translate the road map into a multi-relational network and introduce a vehicle-trajectories based network to jointly consider the traffic behavior pattern. Moreover, we employ three components to model temporal information from recent periods, daily periods and weekly periods respectively. Each component comprises temporal convolutions and graph convolutions to learn representations of the spatiotemporal heterogeneous information for ETA task. Experiments on large-scale datasets illustrate the effectiveness of the proposed HetETA beyond the state-of-the-art methods, and show the importance of representation learning of heterogeneous information networks for ETA task.\nGraph Signal Processing: Overview, Challenges, and Applications (Antonio Ortega et al., 2017) Antonio Ortega, P. Frossard, J. Kovacevic, J. Moura, P. Vandergheynst. (2017)\nGraph Signal Processing: Overview, Challenges, and Applications\nProceedings of the IEEE\nPaper Link\nInfluential Citation Count (87), SS-ID (36d442f59c61ea2912d227c24dee76778c546b0a)\nABSTRACT\nResearch in graph signal processing (GSP) aims to develop tools for processing data defined on irregular graph domains. In this paper, we first provide an overview of core ideas in GSP and their connection to conventional digital signal processing, along with a brief historical perspective to highlight how concepts recently developed in GSP build on top of prior research in other areas. We then summarize recent advances in developing basic GSP tools, including methods for sampling, filtering, or graph learning. Next, we review progress in several application areas using GSP, including processing and analysis of sensor network data, biological data, and applications to image processing and machine learning.\nDetecting Changes of Functional Connectivity by Dynamic Graph Embedding Learning (Yi Lin et al., 2020) Yi Lin, J. Hou, P. Laurienti, Guorong Wu. (2020)\nDetecting Changes of Functional Connectivity by Dynamic Graph Embedding Learning\nMICCAI\nPaper Link\nInfluential Citation Count (0), SS-ID (36e12c48cf33d7097386fc93f091dd22d7349535)\nABSTRACT\nOur current understandings reach the unanimous consensus that the brain functions and cognitive states are dynamically changing even in the resting state rather than remaining at a single constant state. Due to the low signal-to-noise ratio and high vertex-time dependency in BOLD (blood oxygen level dependent) signals, however, it is challenging to detect the dynamic behavior in connectivity without requiring prior knowledge of the experimental design. Like the Fourier bases in signal processing, each brain network can be summarized by a set of harmonic bases (Eigensystem) which are derived from its latent Laplacian matrix. In this regard, we propose to establish a subject-specific spectrum domain, where the learned orthogonal harmonic-Fourier bases allow us to detect the changes of functional connectivity more accurately than using the BOLD signals in an arbitrary sliding window. To do so, we first present a novel dynamic graph learning method to simultaneously estimate the intrinsic BOLD signals and learn the joint harmonic-Fourier bases for the underlying functional connectivity network. Then, we project the BOLD signals to the spectrum domain spanned by learned network harmonic and Fourier bases, forming the new system-level fluctuation patterns, called dynamic graph embeddings. We employ the classic clustering approach to identify the changes of functional connectivity using the novel dynamic graph embedding vectors. Our method has been evaluated on working memory task-based fMRI dataset and comparisons with state-of-the-art methods, where our joint harmonic-Fourier bases achieves higher accuracy in detecting multiple cognitive states.\nnode2vec: Scalable Feature Learning for Networks (Aditya Grover et al., 2016) Aditya Grover, J. Leskovec. (2016)\nnode2vec: Scalable Feature Learning for Networks\nKDD\nPaper Link\nInfluential Citation Count (1119), SS-ID (36ee2c8bd605afd48035d15fdc6b8c8842363376)\nABSTRACT\nPrediction tasks over nodes and edges in networks require careful effort in engineering features used by learning algorithms. Recent research in the broader field of representation learning has led to significant progress in automating prediction by learning the features themselves. However, present feature learning approaches are not expressive enough to capture the diversity of connectivity patterns observed in networks. Here we propose node2vec, an algorithmic framework for learning continuous feature representations for nodes in networks. In node2vec, we learn a mapping of nodes to a low-dimensional space of features that maximizes the likelihood of preserving network neighborhoods of nodes. We define a flexible notion of a node\u0026rsquo;s network neighborhood and design a biased random walk procedure, which efficiently explores diverse neighborhoods. Our algorithm generalizes prior work which is based on rigid notions of network neighborhoods, and we argue that the added flexibility in exploring neighborhoods is the key to learning richer representations. We demonstrate the efficacy of node2vec over existing state-of-the-art techniques on multi-label classification and link prediction in several real-world networks from diverse domains. Taken together, our work represents a new way for efficiently learning state-of-the-art task-independent representations in complex networks.\nSemi-Supervised Classification with Graph Convolutional Networks (Thomas Kipf et al., 2016) Thomas Kipf, M. Welling. (2016)\nSemi-Supervised Classification with Graph Convolutional Networks\nICLR\nPaper Link\nInfluential Citation Count (3139), SS-ID (36eff562f65125511b5dfab68ce7f7a943c27478)\nABSTRACT\nWe present a scalable approach for semi-supervised learning on graph-structured data that is based on an efficient variant of convolutional neural networks which operate directly on graphs. We motivate the choice of our convolutional architecture via a localized first-order approximation of spectral graph convolutions. Our model scales linearly in the number of graph edges and learns hidden layer representations that encode both local graph structure and features of nodes. In a number of experiments on citation networks and on a knowledge graph dataset we demonstrate that our approach outperforms related methods by a significant margin.\nGraph Embedding Techniques, Applications, and Performance: A Survey (Palash Goyal et al., 2017) Palash Goyal, Emilio Ferrara. (2017)\nGraph Embedding Techniques, Applications, and Performance: A Survey\nKnowl. Based Syst.\nPaper Link\nInfluential Citation Count (40), SS-ID (374b4409f6a1d2d853af31e329f025da239d375f)\nABSTRACT\nWalklets: Multiscale Graph Embeddings for Interpretable Network Classification (Bryan Perozzi et al., 2016) Bryan Perozzi, Vivek Kulkarni, S. Skiena. (2016)\nWalklets: Multiscale Graph Embeddings for Interpretable Network Classification\nArXiv\nPaper Link\nInfluential Citation Count (11), SS-ID (37cf46e45777e67676f80c9110bed675a9840590)\nABSTRACT\nWe present Walklets, a novel approach for learning multiscale representations of vertices in a network. These representations clearly encode multiscale vertex relationships in a continuous vector space suitable for multi-label classification problems. Unlike previous work, the latent features generated using Walklets are analytically derivable, and human interpretable. Walklets uses the offsets between vertices observed in a random walk to learn a series of latent representations, each which captures successively larger relationships. This variety of dependency information allows the same representation strategy to model phenomenon which occur at different scales. We demonstrate Walklets\u0026rsquo; latent representations on several multi-label network classification tasks for social networks such as BlogCatalog, Flickr, and YouTube. Our results show that Walklets outperforms new methods based on neural matrix factorization, and can scale to graphs with millions of vertices and edges.\nGraph based Neural Networks for Event Factuality Prediction using Syntactic and Semantic Structures (Amir Pouran Ben Veyseh et al., 2019) Amir Pouran Ben Veyseh, T. Nguyen, D. Dou. (2019)\nGraph based Neural Networks for Event Factuality Prediction using Syntactic and Semantic Structures\nACL\nPaper Link\nInfluential Citation Count (1), SS-ID (37d8e064df4e921bcb7b80b6d4c3ee7488a027e0)\nABSTRACT\nEvent factuality prediction (EFP) is the task of assessing the degree to which an event mentioned in a sentence has happened. For this task, both syntactic and semantic information are crucial to identify the important context words. The previous work for EFP has only combined these information in a simple way that cannot fully exploit their coordination. In this work, we introduce a novel graph-based neural network for EFP that can integrate the semantic and syntactic information more effectively. Our experiments demonstrate the advantage of the proposed model for EFP.\nScalable Graph Embedding for Asymmetric Proximity (Chang Zhou et al., 2017) Chang Zhou, Yuqiong Liu, Xiaofei Liu, Zhongyi Liu, Jun Gao. (2017)\nScalable Graph Embedding for Asymmetric Proximity\nAAAI\nPaper Link\nInfluential Citation Count (28), SS-ID (390bc9d41c1169d316accd993fc715b8ed17f269)\nABSTRACT\nGraph Embedding methods are aimed at mapping each vertex into a low dimensional vector space, which preserves certain structural relationships among the vertices in the original graph. Recently, several works have been proposed to learn embeddings based on sampled paths from the graph, e.g., DeepWalk, Line, Node2Vec. However, their methods only preserve symmetric proximities, which could be insufficient in many applications, even the underlying graph is undirected. Besides, they lack of theoretical analysis of what exactly the relationships they preserve in their embedding space. In this paper, we propose an asymmetric proximity preserving (APP) graph embedding method via random walk with restart, which captures both asymmetric and high-order similarities between node pairs. We give theoretical analysis that our method implicitly preserves the Rooted PageRank score for any two vertices. We conduct extensive experiments on tasks of link prediction and node recommendation on open source datasets, as well as online recommendation services in Alibaba Group, in which the training graph has over 290 million vertices and 18 billion edges, showing our method to be highly scalable and effective.\nGOMES: A group-aware multi-view fusion approach towards real-world image clustering (Zhe Xue et al., 2015) Zhe Xue, Guorong Li, Shuhui Wang, Chunjie Zhang, W. Zhang, Qingming Huang. (2015)\nGOMES: A group-aware multi-view fusion approach towards real-world image clustering\n2015 IEEE International Conference on Multimedia and Expo (ICME)\nPaper Link\nInfluential Citation Count (1), SS-ID (394ba1a52e3cd59974f4277ef1ae987bc3500870)\nABSTRACT\nDifferent features describe different views of visual appearance, multi-view based methods can integrate the information contained in each view and improve the image clustering performance. Most of the existing methods assume that the importance of one type of feature is the same to all the data. However, the visual appearance of images are different, so the description abilities of different features vary with different images. To solve this problem, we propose a group-aware multi-view fusion approach. Images are partitioned into groups which consist of several images sharing similar visual appearance. We assign different weights to evaluate the pairwise similarity between different groups. Then the clustering results and the fusion weights are learned by an iterative optimization procedure. Experimental results indicate that our approach achieves promising clustering performance compared with the existing methods.\nThe emerging field of signal processing on graphs: Extending high-dimensional data analysis to networks and other irregular domains (D. Shuman et al., 2012) D. Shuman, S. K. Narang, P. Frossard, Antonio Ortega, P. Vandergheynst. (2012)\nThe emerging field of signal processing on graphs: Extending high-dimensional data analysis to networks and other irregular domains\nIEEE Signal Processing Magazine\nPaper Link\nInfluential Citation Count (361), SS-ID (39e223e6b5a6f8727e9f60b8b7c7720dc40a5dbc)\nABSTRACT\nIn applications such as social, energy, transportation, sensor, and neuronal networks, high-dimensional data naturally reside on the vertices of weighted graphs. The emerging field of signal processing on graphs merges algebraic and spectral graph theoretic concepts with computational harmonic analysis to process such signals on graphs. In this tutorial overview, we outline the main challenges of the area, discuss different ways to define graph spectral domains, which are the analogs to the classical frequency domain, and highlight the importance of incorporating the irregular structures of graph data domains when processing signals on graphs. We then review methods to generalize fundamental operations such as filtering, translation, modulation, dilation, and downsampling to the graph setting and survey the localized, multiscale transforms that have been proposed to efficiently extract information from high-dimensional data on graphs. We conclude with a brief discussion of open issues and possible extensions.\nUMAP: Uniform Manifold Approximation and Projection for Dimension Reduction (Leland McInnes et al., 2018) Leland McInnes, John Healy. (2018)\nUMAP: Uniform Manifold Approximation and Projection for Dimension Reduction\nArXiv\nPaper Link\nInfluential Citation Count (641), SS-ID (3a288c63576fc385910cb5bc44eaea75b442e62e)\nABSTRACT\nUMAP (Uniform Manifold Approximation and Projection) is a novel manifold learning technique for dimension reduction. UMAP is constructed from a theoretical framework based in Riemannian geometry and algebraic topology. The result is a practical scalable algorithm that applies to real world data. The UMAP algorithm is competitive with t-SNE for visualization quality, and arguably preserves more of the global structure with superior run time performance. Furthermore, UMAP has no computational restrictions on embedding dimension, making it viable as a general purpose dimension reduction technique for machine learning.\nOut-of-sample Node Representation Learning for Heterogeneous Graph in Real-time Android Malware Detection (Yanfang Ye et al., 2019) Yanfang Ye, Shifu Hou, Lingwei Chen, Jingwei Lei, Wenqiang Wan, Jiabin Wang, Qi Xiong, Fudong Shao. (2019)\nOut-of-sample Node Representation Learning for Heterogeneous Graph in Real-time Android Malware Detection\nIJCAI\nPaper Link\nInfluential Citation Count (2), SS-ID (3adf4438aca17918622483593431c47fc5fd97cb)\nABSTRACT\nThe increasingly sophisticated Android malware calls for new defensive techniques that are capable of protecting mobile users against novel threats. In this paper, we first extract the runtime Application Programming Interface (API) call sequences from Android apps, and then analyze higher-level semantic relations within the ecosystem to comprehensively characterize the apps. To model different types of entities (i.e., app, API, device, signature, affiliation) and rich relations among them, we present a structured heterogeneous graph (HG) for modeling. To efficiently classify nodes (e.g., apps) in the constructed HG, we propose the HG-Learning method to first obtain in-sample node embeddings and then learn representations of out-of-sample nodes without rerunning/adjusting HG embeddings at the first attempt. We later design a deep neural network classifier taking the learned HG representations as inputs for real-time Android malware detection. Comprehensive experiments on large-scale and real sample collections from Tencent Security Lab are performed to compare various baselines. Promising results demonstrate that our developed system AiDroid which integrates our proposed method outperforms others in real-time Android malware detection.\nContext-aware citation recommendation (Qi He et al., 2010) Qi He, J. Pei, Daniel Kifer, P. Mitra, C. Lee Giles. (2010)\nContext-aware citation recommendation\nWWW \u0026lsquo;10\nPaper Link\nInfluential Citation Count (32), SS-ID (3c0312918ac9fea614abaa0732d83f3e76c16f7d)\nABSTRACT\nWhen you write papers, how many times do you want to make some citations at a place but you are not sure which papers to cite? Do you wish to have a recommendation system which can recommend a small number of good candidates for every place that you want to make some citations? In this paper, we present our initiative of building a context-aware citation recommendation system. High quality citation recommendation is challenging: not only should the citations recommended be relevant to the paper under composition, but also should match the local contexts of the places citations are made. Moreover, it is far from trivial to model how the topic of the whole paper and the contexts of the citation places should affect the selection and ranking of citations. To tackle the problem, we develop a context-aware approach. The core idea is to design a novel non-parametric probabilistic model which can measure the context-based relevance between a citation context and a document. Our approach can recommend citations for a context effectively. Moreover, it can recommend a set of citations for a paper with high quality. We implement a prototype system in CiteSeerX. An extensive empirical evaluation in the CiteSeerX digital library against many baselines demonstrates the effectiveness and the scalability of our approach.\nLRBM: A Restricted Boltzmann Machine Based Approach for Representation Learning on Linked Data (Kang Li et al., 2014) Kang Li, Jing Gao, Suxin Guo, Nan Du, Xiaoyi Li, A. Zhang. (2014)\nLRBM: A Restricted Boltzmann Machine Based Approach for Representation Learning on Linked Data\n2014 IEEE International Conference on Data Mining\nPaper Link\nInfluential Citation Count (3), SS-ID (3ce947f68c2c4061736a8b4363ebf84f48c572c9)\nABSTRACT\nLinked data consist of both node attributes, e.g., Preferences, posts and degrees, and links which describe the connections between nodes. They have been widely used to represent various network systems, such as social networks, biological networks and etc. Knowledge discovery on linked data is of great importance to many real applications. One of the major challenges of learning linked data is how to effectively and efficiently extract useful information from both node attributes and links in linked data. Current studies on this topic either use selected topological statistics to represent network structures, or linearly map node attributes and network structures to a shared latent feature space. However, while approaches based on statistics may miss critical patterns in network structure, approaches based on linear mappings may not be sufficient to capture the non-linear characteristics of nodes and links. To handle the challenge, we propose, to our knowledge, the first deep learning method to learn from linked data. A restricted Boltzmann machine model named LRBM is developed for representation learning on linked data. In LRBM, we aim to extract the latent feature representation of each node from both node attributes and network structures, non-linearly map each pair of nodes to the links, and use hidden units to control the mapping. The details of how to adapt LRBM for link prediction and node classification on linked data have also been presented. In the experiments, we test the performance of LRBM as well as other baselines on link prediction and node classification. Overall, the extensive experimental evaluations confirm the effectiveness of the proposed LRBM model in mining linked data.\nRevisiting Semi-Supervised Learning with Graph Embeddings (Zhilin Yang et al., 2016) Zhilin Yang, William W. Cohen, R. Salakhutdinov. (2016)\nRevisiting Semi-Supervised Learning with Graph Embeddings\nICML\nPaper Link\nInfluential Citation Count (178), SS-ID (3d846cb01f6a975554035d2210b578ca61344b22)\nABSTRACT\nWe present a semi-supervised learning framework based on graph embeddings. Given a graph between instances, we train an embedding for each instance to jointly predict the class label and the neighborhood context in the graph. We develop both transductive and inductive variants of our method. In the transductive variant of our method, the class labels are determined by both the learned embeddings and input feature vectors, while in the inductive variant, the embeddings are defined as a parametric function of the feature vectors, so predictions can be made on instances not seen during training. On a large and diverse set of benchmark tasks, including text classification, distantly supervised entity extraction, and entity classification, we show improved performance over many of the existing models.\nTask-Oriented Genetic Activation for Large-Scale Complex Heterogeneous Graph Embedding (Zhuoren Jiang et al., 2020) Zhuoren Jiang, Zheng Gao, Jinjiong Lan, Hongxia Yang, Yao Lu, Xiaozhong Liu. (2020)\nTask-Oriented Genetic Activation for Large-Scale Complex Heterogeneous Graph Embedding\nWWW\nPaper Link\nInfluential Citation Count (1), SS-ID (3e98d1b468304ef11b6cceb07d6d6b94d36ef7bc)\nABSTRACT\nThe recent success of deep graph embedding innovates the graphical information characterization methodologies. However, in real-world applications, such a method still struggles with the challenges of heterogeneity, scalability, and multiplex. To address these challenges, in this study, we propose a novel solution, Genetic hEterogeneous gRaph eMbedding (GERM), which enables flexible and efficient task-driven vertex embedding in a complex heterogeneous graph. Unlike prior efforts for this track of studies, we employ a task-oriented genetic activation strategy to efficiently generate the “Edge Type Activated Vector” (ETAV) over the edge types in the graph. The generated ETAV can not only reduce the incompatible noise and navigate the heterogeneous graph random walk at the graph-schema level, but also activate an optimized subgraph for efficient representation learning. By revealing the correlation between the graph structure and task information, the model interpretability can be enhanced as well. Meanwhile, an activated heterogeneous skip-gram framework is proposed to encapsulate both topological and task-specific information of a given heterogeneous graph. Through extensive experiments on both scholarly and e-commerce datasets, we demonstrate the efficacy and scalability of the proposed methods via various search/recommendation tasks. GERM can significantly reduces the running time and remove expert-intervention without sacrificing the performance (or even modestly improve) by comparing with baselines.\nLink Prediction Adversarial Attack (Jinyin Chen et al., 2018) Jinyin Chen, Ziqiang Shi, Yangyang Wu, Xuanheng Xu, Haibin Zheng. (2018)\nLink Prediction Adversarial Attack\nArXiv\nPaper Link\nInfluential Citation Count (2), SS-ID (3ed0205a0c99302455fb15348c99ef0511ffab91)\nABSTRACT\nDeep neural network has shown remarkable performance in solving computer vision and some graph evolved tasks, such as node classification and link prediction. However, the vulnerability of deep model has also been revealed by carefully designed adversarial examples generated by various adversarial attack methods. With the wider application of deep model in complex network analysis, in this paper we define and formulate the link prediction adversarial attack problem and put forward a novel iterative gradient attack (IGA) based on the gradient information in trained graph auto-encoder (GAE). To our best knowledge, it is the first time link prediction adversarial attack problem is defined and attack method is brought up. Not surprisingly, GAE was easily fooled by adversarial network with only a few links perturbed on the clean network. By conducting comprehensive experiments on different real-world data sets, we can conclude that most deep model based and other state-of-art link prediction algorithms cannot escape the adversarial attack just like GAE. We can benefit the attack as an efficient privacy protection tool from link prediction unknown violation, on the other hand, link prediction attack can be a robustness evaluation metric for current link prediction algorithm in attack defensibility.\nThe Graph Neural Network Model (F. Scarselli et al., 2009) F. Scarselli, M. Gori, A. Tsoi, M. Hagenbuchner, G. Monfardini. (2009)\nThe Graph Neural Network Model\nIEEE Transactions on Neural Networks\nPaper Link\nInfluential Citation Count (265), SS-ID (3efd851140aa28e95221b55fcc5659eea97b172d)\nABSTRACT\nMany underlying relationships among data in several areas of science and engineering, e.g., computer vision, molecular chemistry, molecular biology, pattern recognition, and data mining, can be represented in terms of graphs. In this paper, we propose a new neural network model, called graph neural network (GNN) model, that extends existing neural network methods for processing the data represented in graph domains. This GNN model, which can directly process most of the practically useful types of graphs, e.g., acyclic, cyclic, directed, and undirected, implements a function tau(G,n) isin IRm that maps a graph G and one of its nodes n into an m-dimensional Euclidean space. A supervised learning algorithm is derived to estimate the parameters of the proposed GNN model. The computational cost of the proposed algorithm is also considered. Some experimental results are shown to validate the proposed learning algorithm, and to demonstrate its generalization capabilities.\nGraph Clustering Based on Structural/Attribute Similarities (Yang Zhou et al., 2009) Yang Zhou, Hong Cheng, J. Yu. (2009)\nGraph Clustering Based on Structural/Attribute Similarities\nProc. VLDB Endow.\nPaper Link\nInfluential Citation Count (58), SS-ID (3f397e7dab0e253e0859d18bb5711b5471c657fe)\nABSTRACT\nThe goal of graph clustering is to partition vertices in a large graph into different clusters based on various criteria such as vertex connectivity or neighborhood similarity. Graph clustering techniques are very useful for detecting densely connected groups in a large graph. Many existing graph clustering methods mainly focus on the topological structure for clustering, but largely ignore the vertex properties which are often heterogenous. In this paper, we propose a novel graph clustering algorithm, SA-Cluster, based on both structural and attribute similarities through a unified distance measure. Our method partitions a large graph associated with attributes into k clusters so that each cluster contains a densely connected subgraph with homogeneous attribute values. An effective method is proposed to automatically learn the degree of contributions of structural similarity and attribute similarity. Theoretical analysis is provided to show that SA-Cluster is converging. Extensive experimental results demonstrate the effectiveness of SA-Cluster through comparison with the state-of-the-art graph clustering and summarization methods.\nLeveraging social media networks for classification (Lei Tang et al., 2011) Lei Tang, Huan Liu. (2011)\nLeveraging social media networks for classification\nData Mining and Knowledge Discovery\nPaper Link\nInfluential Citation Count (26), SS-ID (3f9df5c77af49d5b1b19eac9b82cb430b50f482d)\nABSTRACT\nSocial media has reshaped the way in which people interact with each other. The rapid development of participatory web and social networking sites like YouTube, Twitter, and Facebook, also brings about many data mining opportunities and novel challenges. In particular, we focus on classification tasks with user interaction information in a social network. Networks in social media are heterogeneous, consisting of various relations. Since the relation-type information may not be available in social media, most existing approaches treat these inhomogeneous connections homogeneously, leading to an unsatisfactory classification performance. In order to handle the network heterogeneity, we propose the concept of social dimension to represent actors’ latent affiliations, and develop a classification framework based on that. The proposed framework, SocioDim, first extracts social dimensions based on the network structure to accurately capture prominent interaction patterns between actors, then learns a discriminative classifier to select relevant social dimensions. SocioDim, by differentiating different types of network connections, outperforms existing representative methods of classification in social media, and offers a simple yet effective approach to integrating two types of seemingly orthogonal information: the network of actors and their attributes.\nWhich way? Direction-Aware Attributed Graph Embedding (Zekarias T. Kefato et al., 2020) Zekarias T. Kefato, Nasrullah Sheikh, A. Montresor. (2020)\nWhich way? Direction-Aware Attributed Graph Embedding\nArXiv\nPaper Link\nInfluential Citation Count (0), SS-ID (403cc71d267960ae325173868180aaafec3b4b9b)\nABSTRACT\nGraph embedding algorithms are used to efficiently represent (encode) a graph in a low-dimensional continuous vector space that preserves the most important properties of the graph. One aspect that is often overlooked is whether the graph is directed or not. Most studies ignore the directionality, so as to learn high-quality representations optimized for node classification. On the other hand, studies that capture directionality are usually effective on link prediction but do not perform well on other tasks. This preliminary study presents a novel text-enriched, direction-aware algorithm called DIAGRAM , based on a carefully designed multi-objective model to learn embeddings that preserve the direction of edges, textual features and graph context of nodes. As a result, our algorithm does not have to trade one property for another and jointly learns high-quality representations for multiple network analysis tasks. We empirically show that DIAGRAM significantly outperforms six state-of-the-art baselines, both direction-aware and oblivious ones,on link prediction and network reconstruction experiments using two popular datasets. It also achieves a comparable performance on node classification experiments against these baselines using the same datasets.\nMultilevel graph embedding (Benjamin Quiring et al., 2020) Benjamin Quiring, P. Vassilevski. (2020)\nMultilevel graph embedding\nNumer. Linear Algebra Appl.\nPaper Link\nInfluential Citation Count (0), SS-ID (412b0cf8d4a39634cb02235a1333ddf3bf792732)\nABSTRACT\nThe goal of the present paper is the design of embeddings of a general sparse graph into a set of points in ℝd for appropriate d ≥ 2. The embeddings that we are looking at aim to keep vertices that are grouped in communities together and keep the rest apart. To achieve this property, we utilize coarsening that respects possible community structures of the given graph. We employ a hierarchical multilevel coarsening approach that identifies communities (strongly connected groups of vertices) at every level. The multilevel strategy allows any given (presumably expensive) graph embedding algorithm to be made into a more scalable (and faster) algorithm. We demonstrate the presented approach on a number of given embedding algorithms and large‐scale graphs and achieve speed‐up over the methods in a recent paper.\nExploiting Cliques for Granular Computing-based Graph Classification (L. Baldini et al., 2020) L. Baldini, A. Martino, A. Rizzi. (2020)\nExploiting Cliques for Granular Computing-based Graph Classification\n2020 International Joint Conference on Neural Networks (IJCNN)\nPaper Link\nInfluential Citation Count (0), SS-ID (414c510f5b932d86e68b81044a8a18a46a46e007)\nABSTRACT\nThe most fascinating aspect of graphs is their ability to encode the information contained in the inner structural organization between its constituting elements. Learning from graphs belong to the so-called Structural Pattern Recognition, from which Graph Embedding emerged as a successful method for processing graphs by evaluating their dissimilarity in a suitable geometric space. In this paper, we investigate the possibility to perform the embedding into a geometric space by leveraging to peculiar constituent graph substructures extracted from training set, namely the maximal cliques, and providing the performances obtained under three main aspects concerning classification capabilities, running times and model complexity. Thanks to a Granular Computing approach, the employed methodology can be seen as a powerful framework able to synthesize models suitable to be interpreted by field-experts, pushing the boundary towards new frontiers in the field of explainable AI and knowledge discovery also in big data contexts.\nOn the properties of small-world network models (A. Barrat et al., 1999) A. Barrat, M. Weigt. (1999)\nOn the properties of small-world network models\nPaper Link\nInfluential Citation Count (21), SS-ID (421a56ce3c6627da87efa298d90d15f90642272d)\nABSTRACT\nAbstract:We study the small-world networks recently introduced by Watts and Strogatz [Nature 393, 440 (1998)], using analytical as well as numerical tools. We characterize the geometrical properties resulting from the coexistence of a local structure and random long-range connections, and we examine their evolution with size and disorder strength. We show that any finite value of the disorder is able to trigger a “small-world” behaviour as soon as the initial lattice is big enough, and study the crossover between a regular lattice and a “small-world” one. These results are corroborated by the investigation of an Ising model defined on the network, showing for every finite disorder fraction a crossover from a high-temperature region dominated by the underlying one-dimensional structure to a mean-field like low-temperature region. In particular there exists a finite-temperature ferromagnetic phase transition as soon as the disorder strength is finite. [0.5cm]\nLabel Informed Attributed Network Embedding (Xiao Huang et al., 2017) Xiao Huang, Jundong Li, Xia Hu. (2017)\nLabel Informed Attributed Network Embedding\nWSDM\nPaper Link\nInfluential Citation Count (45), SS-ID (44044556dae0e21cab058c18f704b15d33bd17c5)\nABSTRACT\nAttributed network embedding aims to seek low-dimensional vector representations for nodes in a network, such that original network topological structure and node attribute proximity can be preserved in the vectors. These learned representations have been demonstrated to be helpful in many learning tasks such as network clustering and link prediction. While existing algorithms follow an unsupervised manner, nodes in many real-world attributed networks are often associated with abundant label information, which is potentially valuable in seeking more effective joint vector representations. In this paper, we investigate how labels can be modeled and incorporated to improve attributed network embedding. This is a challenging task since label information could be noisy and incomplete. In addition, labels are completely distinct with the geometrical structure and node attributes. The bewildering combination of heterogeneous information makes the joint vector representation learning more difficult. To address these issues, we propose a novel Label informed Attributed Network Embedding (LANE) framework. It can smoothly incorporate label information into the attributed network embedding while preserving their correlations. Experiments on real-world datasets demonstrate that the proposed framework achieves significantly better performance compared with the state-of-the-art embedding algorithms.\nDeep Belief Network-Based Approaches for Link Prediction in Signed Social Networks (Feng Liu et al., 2015) Feng Liu, Bingquan Liu, Chengjie Sun, Ming Liu, Xiaolong Wang. (2015)\nDeep Belief Network-Based Approaches for Link Prediction in Signed Social Networks\nEntropy\nPaper Link\nInfluential Citation Count (2), SS-ID (45cb1ff9e1221b52ba3c26e33e98550f6117ae5a)\nABSTRACT\nIn some online social network services (SNSs), the members are allowed to label their relationships with others, and such relationships can be represented as the links with signed values (positive or negative). The networks containing such relations are named signed social networks (SSNs), and some real-world complex systems can be also modeled with SSNs. Given the information of the observed structure of an SSN, the link prediction aims to estimate the values of the unobserved links. Noticing that most of the previous approaches for link prediction are based on the members’ similarity and the supervised learning method, however, research work on the investigation of the hidden principles that drive the behaviors of social members are rarely conducted. In this paper, the deep belief network (DBN)-based approaches for link prediction are proposed. Including an unsupervised link prediction model, a feature representation method and a DBN-based link prediction method are introduced. The experiments are done on the datasets from three SNSs (social networking services) in different domains, and the results show that our methods can predict the values of the links with high performance and have a good generalization ability across these datasets.\nWasserstein Embedding for Graph Learning (S. Kolouri et al., 2020) S. Kolouri, Navid Naderializadeh, G. Rohde, Heiko Hoffmann. (2020)\nWasserstein Embedding for Graph Learning\nICLR\nPaper Link\nInfluential Citation Count (1), SS-ID (463f490d3bded6e527b0838da8495ed6441da25a)\nABSTRACT\nWe present Wasserstein Embedding for Graph Learning (WEGL), a novel and fast framework for embedding entire graphs in a vector space, in which various machine learning models are applicable for graph-level prediction tasks. We leverage new insights on defining similarity between graphs as a function of the similarity between their node embedding distributions. Specifically, we use the Wasserstein distance to measure the dissimilarity between node embeddings of different graphs. Different from prior work, we avoid pairwise calculation of distances between graphs and reduce the computational complexity from quadratic to linear in the number of graphs. WEGL calculates Monge maps from a reference distribution to each node embedding and, based on these maps, creates a fixed-sized vector representation of the graph. We evaluate our new graph embedding approach on various benchmark graph-property prediction tasks, showing state-of-the-art classification performance, while having superior computational efficiency.\nRepresentation Learning for Scale-free Networks (Rui Feng et al., 2017) Rui Feng, Yang Yang, Wenjie Hu, Fei Wu, Yueting Zhuang. (2017)\nRepresentation Learning for Scale-free Networks\nAAAI\nPaper Link\nInfluential Citation Count (3), SS-ID (464a60d8e67ab42d360c9be2d29f919d30312315)\nABSTRACT\nNetwork embedding aims to learn the low-dimensional representations of vertexes in a network, while structure and inherent properties of the network is preserved. Existing network embedding works primarily focus on preserving the microscopic structure, such as the first- and second-order proximity of vertexes, while the macroscopic scale-free property is largely ignored. Scale-free property depicts the fact that vertex degrees follow a heavy-tailed distribution (i.e., only a few vertexes have high degrees) and is a critical property of real-world networks, such as social networks. In this paper, we study the problem of learning representations for scale-free networks. We first theoretically analyze the difficulty of embedding and reconstructing a scale-free network in the Euclidean space, by converting our problem to the sphere packing problem. Then, we propose the \u0026ldquo;degree penalty\u0026rdquo; principle for designing scale-free property preserving network embedding algorithm: punishing the proximity between high-degree vertexes. We introduce two implementations of our principle by utilizing the spectral techniques and a skip-gram model respectively. Extensive experiments on six datasets show that our algorithms are able to not only reconstruct heavy-tailed distributed degree distribution, but also outperform state-of-the-art embedding models in various network mining tasks, such as vertex classification and link prediction.\nA latent factor model for highly multi-relational data (Rodolphe Jenatton et al., 2012) Rodolphe Jenatton, Nicolas Le Roux, Antoine Bordes, G. Obozinski. (2012)\nA latent factor model for highly multi-relational data\nNIPS\nPaper Link\nInfluential Citation Count (35), SS-ID (473b3f2cc2c942c0116d980fe5b36a338f6017de)\nABSTRACT\nMany data such as social networks, movie preferences or knowledge bases are multi-relational, in that they describe multiple relations between entities. While there is a large body of work focused on modeling these data, modeling these multiple types of relations jointly remains challenging. Further, existing approaches tend to breakdown when the number of these types grows. In this paper, we propose a method for modeling large multi-relational datasets, with possibly thousands of relations. Our model is based on a bilinear structure, which captures various orders of interaction of the data, and also shares sparse latent factors across different relations. We illustrate the performance of our approach on standard tensor-factorization datasets where we attain, or outperform, state-of-the-art results. Finally, a NLP application demonstrates our scalability and the ability of our model to learn efficient and semantically meaningful verb representations.\nRandom-Walk Computation of Similarities between Nodes of a Graph with Application to Collaborative Recommendation (François Fouss et al., 2007) François Fouss, A. Pirotte, J. Renders, Marco Saerens. (2007)\nRandom-Walk Computation of Similarities between Nodes of a Graph with Application to Collaborative Recommendation\nIEEE Transactions on Knowledge and Data Engineering\nPaper Link\nInfluential Citation Count (84), SS-ID (474db64356d6c9c82fe2a8604cd6c13bc17bae78)\nABSTRACT\nThis work presents a new perspective on characterizing the similarity between elements of a database or, more generally, nodes of a weighted and undirected graph. It is based on a Markov-chain model of random walk through the database. More precisely, we compute quantities (the average commute time, the pseudoinverse of the Laplacian matrix of the graph, etc.) that provide similarities between any pair of nodes, having the nice property of increasing when the number of paths connecting those elements increases and when the \u0026ldquo;length\u0026rdquo; of paths decreases. It turns out that the square root of the average commute time is a Euclidean distance and that the pseudoinverse of the Laplacian matrix is a kernel matrix (its elements are inner products closely related to commute times). A principal component analysis (PCA) of the graph is introduced for computing the subspace projection of the node vectors in a manner that preserves as much variance as possible in terms of the Euclidean commute-time distance. This graph PCA provides a nice interpretation to the \u0026ldquo;Fiedler vector,\u0026rdquo; widely used for graph partitioning. The model is evaluated on a collaborative-recommendation task where suggestions are made about which movies people should watch based upon what they watched in the past. Experimental results on the MovieLens database show that the Laplacian-based similarities perform well in comparison with other methods. The model, which nicely fits into the so-called \u0026ldquo;statistical relational learning\u0026rdquo; framework, could also be used to compute document or word similarities, and, more generally, it could be applied to machine-learning and pattern-recognition tasks involving a relational database\nMemory-Based Graph Networks (Amir Hosein Khas Ahmadi et al., 2020) Amir Hosein Khas Ahmadi, Kaveh Hassani, Parsa Moradi, Leo Lee, Q. Morris. (2020)\nMemory-Based Graph Networks\nICLR\nPaper Link\nInfluential Citation Count (6), SS-ID (47f01fd4f0c9c77058a966d3f17dbc09cf7ef42a)\nABSTRACT\nGraph Neural Networks (GNNs) are a class of deep models that operates on data with arbitrary topology and order-invariant structure represented as graphs. We introduce an efficient memory layer for GNNs that can learn to jointly perform graph representation learning and graph pooling. We also introduce two new networks based on our memory layer: Memory-Based Graph Neural Network (MemGNN) and Graph Memory Network (GMN) that can learn hierarchical graph representations by coarsening the graph throughout the layers of memory. The experimental results demonstrate that the proposed models achieve state-of-the-art results in six out of seven graph classification and regression benchmarks. We also show that the learned representations could correspond to chemical features in the molecule data.\nLink Prediction on Multiple Graphs with Graph Embedding and Optimal Transport (Luu Huu Phuc et al., 2020) Luu Huu Phuc, M. Yamada, H. Kashima. (2020)\nLink Prediction on Multiple Graphs with Graph Embedding and Optimal Transport\nPaper Link\nInfluential Citation Count (0), SS-ID (480ff986724acc27e096560f8d433847e86cbdb3)\nABSTRACT\nLink prediction is an extensively studied topic and various methods have been proposed to tackle the task in both heuristic and more sophisticated statistical learning approaches. However, most of them only focus on one single graph. In many scenarios, combining information on multiple graphs with similar topological structures can greatly improve the performance and robustness of link prediction. In this study, we propose a new framework for learning link prediction on two unaligned graphs simultaneously. We use the LINE method, although technically any embedding method is applicable, to embed nodes of each graph into low-dimensional vectors. Optimal Transport is then employed to supervise the node alignment via embedding vectors between the two graphs. The learned embedding vectors are employed for link prediction via a similarity score. Experiments have shown that node alignment using Optimal Transport is beneficial and greatly contributes to the favorable performance of the proposed method over the baseline in many settings.\nDeepGO: predicting protein functions from sequence and interactions using a deep ontology-aware classifier (Maxat Kulmanov et al., 2017) Maxat Kulmanov, Mohammed Asif Khan, R. Hoehndorf. (2017)\nDeepGO: predicting protein functions from sequence and interactions using a deep ontology-aware classifier\nBioinform.\nPaper Link\nInfluential Citation Count (25), SS-ID (48326bdcbb094fce48b17390f7743c23cd0a1ebc)\nABSTRACT\nAbstract Motivation A large number of protein sequences are becoming available through the application of novel high-throughput sequencing technologies. Experimental functional characterization of these proteins is time-consuming and expensive, and is often only done rigorously for few selected model organisms. Computational function prediction approaches have been suggested to fill this gap. The functions of proteins are classified using the Gene Ontology (GO), which contains over 40 000 classes. Additionally, proteins have multiple functions, making function prediction a large-scale, multi-class, multi-label problem. Results We have developed a novel method to predict protein function from sequence. We use deep learning to learn features from protein sequences as well as a cross-species protein–protein interaction network. Our approach specifically outputs information in the structure of the GO and utilizes the dependencies between GO classes as background information to construct a deep learning model. We evaluate our method using the standards established by the Computational Assessment of Function Annotation (CAFA) and demonstrate a significant improvement over baseline methods such as BLAST, in particular for predicting cellular locations. Availability and implementation Web server: http://deepgo.bio2vec.net, Source code: https://github.com/bio-ontology-research-group/deepgo Supplementary information Supplementary data are available at Bioinformatics online.\nGated Graph Sequence Neural Networks (Yujia Li et al., 2015) Yujia Li, Daniel Tarlow, Marc Brockschmidt, R. Zemel. (2015)\nGated Graph Sequence Neural Networks\nICLR\nPaper Link\nInfluential Citation Count (280), SS-ID (492f57ee9ceb61fb5a47ad7aebfec1121887a175)\nABSTRACT\nAbstract: Graph-structured data appears frequently in domains including chemistry, natural language semantics, social networks, and knowledge bases. In this work, we study feature learning techniques for graph-structured inputs. Our starting point is previous work on Graph Neural Networks (Scarselli et al., 2009), which we modify to use gated recurrent units and modern optimization techniques and then extend to output sequences. The result is a flexible and broadly useful class of neural network models that has favorable inductive biases relative to purely sequence-based models (e.g., LSTMs) when the problem is graph-structured. We demonstrate the capabilities on some simple AI (bAbI) and graph algorithm learning tasks. We then show it achieves state-of-the-art performance on a problem from program verification, in which subgraphs need to be matched to abstract data structures.\nApplying link-based classification to label blogs (Smriti Bhagat et al., 2007) Smriti Bhagat, Irina Rozenbaum, Graham Cormode. (2007)\nApplying link-based classification to label blogs\nWebKDD/SNA-KDD \u0026lsquo;07\nPaper Link\nInfluential Citation Count (5), SS-ID (496d1a45eb511893a86dd7a8452a386aa5ce1657)\nABSTRACT\nIn analyzing data from social and communication networks, we encounter the problem of classifying objects where there is an explicit link structure amongst the objects. We study the problem of inferring the classification of all the objects from a labeled subset, using only the link-based information amongst the objects. We abstract the above as a labeling problem on multigraphs with weighted edges. We present two classes of algorithms, based on local and global similarities. Then we focus on multigraphs induced by blog data, and carefully apply our general algorithms to specifically infer labels such as age, gender and location associated with the blog based only on the link-structure amongst them. We perform a comprehensive set of experiments with real, large-scale blog data sets and show that significant accuracy is possible from little or no non-link information, and our methods scale to millions of nodes and edges.\nSupport and Centrality: Learning Weights for Knowledge Graph Embedding Models (Gengchen Mai et al., 2018) Gengchen Mai, K. Janowicz, Bo Yan. (2018)\nSupport and Centrality: Learning Weights for Knowledge Graph Embedding Models\nEKAW\nPaper Link\nInfluential Citation Count (0), SS-ID (49899fd94cd272914f7d1e81b0915058c25bb665)\nABSTRACT\nComputing knowledge graph (KG) embeddings is a technique to learn distributional representations for components of a knowledge graph while preserving structural information. The learned embeddings can be used in multiple downstream tasks such as question answering, information extraction, query expansion, semantic similarity, and information retrieval. Over the past years, multiple embedding techniques have been proposed based on different underlying assumptions. The most actively researched models are translation-based which treat relations as translation operations in a shared (or relation-specific) space. Interestingly, almost all KG embedding models treat each triple equally, regardless of the fact that the contribution of each triple to the global information content differs substantially. Many triples can be inferred from others, while some triples are the foundational (basis) statements that constitute a knowledge graph, thereby supporting other triples. Hence, in order to learn a suitable embedding model, each triple should be treated differently with respect to its information content. Here, we propose a data-driven approach to measure the information content of each triple with respect to the whole knowledge graph by using rule mining and PageRank. We show how to compute triple-specific weights to improve the performance of three KG embedding models (TransE, TransR and HolE). Link prediction tasks on two standard datasets, FB15K and WN18, show the effectiveness of our weighted KG embedding model over other more complex models. In fact, for FB15K our TransE-RW embeddings model outperforms models such as TransE, TransM, TransH, and TransR by at least 12.98% for measuring the Mean Rank and at least 1.45% for HIT@10. Our HolE-RW model also outperforms HolE and ComplEx by at least 14.3% for MRR and about 30.4% for HIT@1 on FB15K. Finally, TransR-RW show an improvement over TransR by 3.90% for Mean Rank and 0.87% for HIT@10.\nWatch Your Step: Learning Node Embeddings via Graph Attention (Sami Abu-El-Haija et al., 2017) Sami Abu-El-Haija, Bryan Perozzi, Rami Al-Rfou, Alexander A. Alemi. (2017)\nWatch Your Step: Learning Node Embeddings via Graph Attention\nNeurIPS\nPaper Link\nInfluential Citation Count (13), SS-ID (49a5b5e65078eff512083d9de413d49a8aadc064)\nABSTRACT\nGraph embedding methods represent nodes in a continuous vector space, preserving different types of relational information from the graph. There are many hyper-parameters to these methods (e.g. the length of a random walk) which have to be manually tuned for every graph. In this paper, we replace previously fixed hyper-parameters with trainable ones that we automatically learn via backpropagation. In particular, we propose a novel attention model on the power series of the transition matrix, which guides the random walk to optimize an upstream objective. Unlike previous approaches to attention models, the method that we propose utilizes attention parameters exclusively on the data itself (e.g. on the random walk), and are not used by the model for inference. We experiment on link prediction tasks, as we aim to produce embeddings that best-preserve the graph structure, generalizing to unseen information. We improve state-of-the-art results on a comprehensive suite of real-world graph datasets including social, collaboration, and biological networks, where we observe that our graph attention model can reduce the error by up to 20%-40%. We show that our automatically-learned attention parameters can vary significantly per graph, and correspond to the optimal choice of hyper-parameter if we manually tune existing methods.\nDeep Graph Contrastive Representation Learning (Yanqiao Zhu et al., 2020) Yanqiao Zhu, Yichen Xu, Feng Yu, Q. Liu, Shu Wu, Liang Wang. (2020)\nDeep Graph Contrastive Representation Learning\nArXiv\nPaper Link\nInfluential Citation Count (35), SS-ID (4bf76588122827157c43a59e656dccc6b6a22e90)\nABSTRACT\nGraph representation learning nowadays becomes fundamental in analyzing graph-structured data. Inspired by recent success of contrastive methods, in this paper, we propose a novel framework for unsupervised graph representation learning by leveraging a contrastive objective at the node level. Specifically, we generate two graph views by corruption and learn node representations by maximizing the agreement of node representations in these two views. To provide diverse node contexts for the contrastive objective, we propose a hybrid scheme for generating graph views on both structure and attribute levels. Besides, we provide theoretical justification behind our motivation from two perspectives, mutual information and the classical triplet loss. We perform empirical experiments on both transductive and inductive learning tasks using a variety of real-world datasets. Experimental experiments demonstrate that despite its simplicity, our proposed method consistently outperforms existing state-of-the-art methods by large margins. Moreover, our unsupervised method even surpasses its supervised counterparts on transductive tasks, demonstrating its great potential in real-world applications.\nHomophily, Structure, and Content Augmented Network Representation Learning (Daokun Zhang et al., 2016) Daokun Zhang, Jie Yin, Xingquan Zhu, Chengqi Zhang. (2016)\nHomophily, Structure, and Content Augmented Network Representation Learning\n2016 IEEE 16th International Conference on Data Mining (ICDM)\nPaper Link\nInfluential Citation Count (4), SS-ID (4cc10f77819ad376ea539074c2de14a8999e3269)\nABSTRACT\nAdvances in social networking and communication technologies have witnessed an increasing number of applications where data is not only characterized by rich content information, but also connected with complex relationships representing social roles and dependencies between individuals. To enable knowledge discovery from such networked data, network representation learning (NRL) aims to learn vector representations for network nodes, such that off-the-shelf machine learning algorithms can be directly applied. To date, existing NRL methods either primarily focus on network structure or simply combine node content and topology for learning. We argue that in information networks, information is mainly originated from three sources: (1) homophily, (2) topology structure, and (3) node content. Homophily states social phenomenon where individuals sharing similar attributes (content) tend to be directly connected through local relational ties, while topology structure emphasizes more on global connections. To ensure effective network representation learning, we propose to augment three information sources into one learning objective function, so that the interplay roles between three parties are enforced by requiring the learned network representations (1) being consistent with node content and topology structure, and also (2) following the social homophily constraints in the learned space. Experiments on multi-class node classification demonstrate that the representations learned by the proposed method consistently outperform state-of-the-art NRL methods, especially for very sparsely labeled networks.\nThe rendezvous algorithm: multiclass semi-supervised learning with Markov random walks (Arik Azran, 2007) Arik Azran. (2007)\nThe rendezvous algorithm: multiclass semi-supervised learning with Markov random walks\nICML \u0026lsquo;07\nPaper Link\nInfluential Citation Count (5), SS-ID (4e9585cd65c7e1a19ae16d8fed12c810070c65d3)\nABSTRACT\nWe consider the problem of multiclass classification where both labeled and unlabeled data points are given. We introduce and demonstrate a new approach for estimating a distribution over the missing labels where data points are viewed as nodes of a graph, and pairwise similarities are used to derive a transition probability matrix P for a Markov random walk between them. The algorithm associates each point with a particle which moves between points according to P. Labeled points are set to be absorbing states of the Markov random walk, and the probability of each particle to be absorbed by the different labeled points, as the number of steps increases, is then used to derive a distribution over the associated missing label. A computationally efficient algorithm to implement this is derived and demonstrated on both real and artificial data sets, including a numerical comparison with other methods.\nLearning from Collective Intelligence (Hanwang Zhang et al., 2016) Hanwang Zhang, Xindi Shang, Huanbo Luan, Meng Wang, Tat-Seng Chua. (2016)\nLearning from Collective Intelligence\nACM Trans. Multim. Comput. Commun. Appl.\nPaper Link\nInfluential Citation Count (4), SS-ID (4f3417e73528025a5429547814e5a2fd91deb818)\nABSTRACT\nFeature representation for visual content is the key to the progress of many fundamental applications such as annotation and cross-modal retrieval. Although recent advances in deep feature learning offer a promising route towards these tasks, they are limited in application domains where high-quality and large-scale training data are expensive to obtain. In this article, we propose a novel deep feature learning paradigm based on social collective intelligence, which can be acquired from the inexhaustible social multimedia content on the Web, in particular, largely social images and tags. Differing from existing feature learning approaches that rely on high-quality image-label supervision, our weak supervision is acquired by mining the visual-semantic embeddings from noisy, sparse, and diverse social image collections. The resultant image-word embedding space can be used to (1) fine-tune deep visual models for low-level feature extractions and (2) seek sparse representations as high-level cross-modal features for both image and text. We offer an easy-to-use implementation for the proposed paradigm, which is fast and compatible with any state-of-the-art deep architectures. Extensive experiments on several benchmarks demonstrate that the cross-modal features learned by our paradigm significantly outperforms others in various applications such as content-based retrieval, classification, and image captioning.\nK-Core based Temporal Graph Convolutional Network for Dynamic Graphs (Jingxin Liu et al., 2020) Jingxin Liu, Chang Xu, Chang Yin, Weiqiang Wu, You Song. (2020)\nK-Core based Temporal Graph Convolutional Network for Dynamic Graphs\nArXiv\nPaper Link\nInfluential Citation Count (1), SS-ID (4fda7672f67a8872902dee92e4c1bcf2c833a2b1)\nABSTRACT\nGraph representation learning is a fundamental task in various applications that strives to learn low-dimensional embeddings for nodes that can preserve graph topology information. However, many existing methods focus on static graphs while ignoring evolving graph patterns. Inspired by the success of graph convolutional networks(GCNs) in static graph embedding, we propose a novel k-core based temporal graph convolutional network, the CTGCN, to learn node representations for dynamic graphs. In contrast to previous dynamic graph embedding methods, CTGCN can preserve both local connective proximity and global structural similarity while simultaneously capturing graph dynamics. In the proposed framework, the traditional graph convolution is generalized into two phases, feature transformation and feature aggregation, which gives the CTGCN more flexibility and enables the CTGCN to learn connective and structural information under the same framework. Experimental results on 7 real-world graphs demonstrate that the CTGCN outperforms existing state-of-the-art graph embedding methods in several tasks, including link prediction and structural role classification. The source code of this work can be obtained from this https URL.\nReasoning With Neural Tensor Networks for Knowledge Base Completion (R. Socher et al., 2013) R. Socher, Danqi Chen, Christopher D. Manning, A. Ng. (2013)\nReasoning With Neural Tensor Networks for Knowledge Base Completion\nNIPS\nPaper Link\nInfluential Citation Count (277), SS-ID (50d53cc562225549457cbc782546bfbe1ac6f0cf)\nABSTRACT\nKnowledge bases are an important resource for question answering and other tasks but often suffer from incompleteness and lack of ability to reason over their discrete entities and relationships. In this paper we introduce an expressive neural tensor network suitable for reasoning over relationships between two entities. Previous work represented entities as either discrete atomic units or with a single entity vector representation. We show that performance can be improved when entities are represented as an average of their constituting word vectors. This allows sharing of statistical strength between, for instance, facts involving the \u0026ldquo;Sumatran tiger\u0026rdquo; and \u0026ldquo;Bengal tiger.\u0026rdquo; Lastly, we demonstrate that all models improve when these word vectors are initialized with vectors learned from unsupervised large corpora. We assess the model by considering the problem of predicting additional true relations between entities given a subset of the knowledge base. Our model outperforms previous models and can classify unseen relationships in WordNet and FreeBase with an accuracy of 86.2% and 90.0%, respectively.\nLearning network representations (L. G. Moyano, 2017) L. G. Moyano. (2017)\nLearning network representations\nPaper Link\nInfluential Citation Count (0), SS-ID (51a748c8d7b780c2bb863a2259598a3a216330f1)\nABSTRACT\nAbstract In this review I present several representation learning methods, and discuss the latest advancements with emphasis in applications to network science. Representation learning is a set of techniques that has the goal of efficiently mapping data structures into convenient latent spaces. Either for dimensionality reduction or for gaining semantic content, this type of feature embeddings has demonstrated to be useful, for example, for node classification or link prediction tasks, among many other relevant applications to networks. I provide a description of the state-of-the-art of network representation learning as well as a detailed account of the connections with other fields of study such as continuous word embeddings and deep learning architectures. Finally, I provide a broad view of several applications of these techniques to networks in various domains.\nLink prediction approach to collaborative filtering (Zan Huang et al., 2005) Zan Huang, Xin Li, Hsinchun Chen. (2005)\nLink prediction approach to collaborative filtering\nProceedings of the 5th ACM/IEEE-CS Joint Conference on Digital Libraries (JCDL \u0026lsquo;05)\nPaper Link\nInfluential Citation Count (19), SS-ID (5257c7ddcf1d0b51596524eea9f54942f124e0ec)\nABSTRACT\nRecommender systems can provide valuable services in a digital library environment, as demonstrated by its commercial success in book, movie, and music industries. One of the most commonly-used and successful recommendation algorithms is collaborative filtering, which explores the correlations within user-item interactions to infer user interests and preferences. However, the recommendation quality of collaborative filtering approaches is greatly limited by the data sparsity problem. To alleviate this problem we have previously proposed graph-based algorithms to explore transitive user-item associations. In this paper, we extend the idea of analyzing user-item interactions as graphs and employ link prediction approaches proposed in the recent network modeling literature for making collaborative filtering recommendations. We have adapted a wide range of linkage measures for making recommendations. Our preliminary experimental results based on a book recommendation dataset show that some of these measures achieved significantly better performance than standard collaborative filtering algorithms\nHeterogeneous Information Network Embedding for Meta Path based Proximity (Zhipeng Huang et al., 2017) Zhipeng Huang, N. Mamoulis. (2017)\nHeterogeneous Information Network Embedding for Meta Path based Proximity\nArXiv\nPaper Link\nInfluential Citation Count (14), SS-ID (52a150d6a098ef142bece099dadaa613fddbae50)\nABSTRACT\nA network embedding is a representation of a large graph in a low-dimensional space, where vertices are modeled as vectors. The objective of a good embedding is to preserve the proximity between vertices in the original graph. This way, typical search and mining methods can be applied in the embedded space with the help of off-the-shelf multidimensional indexing approaches. Existing network embedding techniques focus on homogeneous networks, where all vertices are considered to belong to a single class.\nGraph Convolutional Tracking (Junyu Gao et al., 2019) Junyu Gao, Tianzhu Zhang, Changsheng Xu. (2019)\nGraph Convolutional Tracking\n2019 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)\nPaper Link\nInfluential Citation Count (13), SS-ID (53970ae69a73f547a56661fd25f6711746d277fb)\nABSTRACT\nTracking by siamese networks has achieved favorable performance in recent years. However, most of existing siamese methods do not take full advantage of spatial-temporal target appearance modeling under different contextual situations. In fact, the spatial-temporal information can provide diverse features to enhance the target representation, and the context information is important for online adaption of target localization. To comprehensively leverage the spatial-temporal structure of historical target exemplars and get benefit from the context information, in this work, we present a novel Graph Convolutional Tracking (GCT) method for high-performance visual tracking. Specifically, the GCT jointly incorporates two types of Graph Convolutional Networks (GCNs) into a siamese framework for target appearance modeling. Here, we adopt a spatial-temporal GCN to model the structured representation of historical target exemplars. Furthermore, a context GCN is designed to utilize the context of the current frame to learn adaptive features for target localization. Extensive results on 4 challenging benchmarks show that our GCT method performs favorably against state-of-the-art trackers while running around 50 frames per second.\nImproving Neural Entity Disambiguation with Graph Embeddings (Özge Sevgili et al., 2019) Özge Sevgili, Alexander Panchenko, Chris Biemann. (2019)\nImproving Neural Entity Disambiguation with Graph Embeddings\nACL\nPaper Link\nInfluential Citation Count (1), SS-ID (540a140e4b8576e0b4edaefd5cee9d9c55da0e1d)\nABSTRACT\nEntity Disambiguation (ED) is the task of linking an ambiguous entity mention to a corresponding entry in a knowledge base. Current methods have mostly focused on unstructured text data to learn representations of entities, however, there is structured information in the knowledge base itself that should be useful to disambiguate entities. In this work, we propose a method that uses graph embeddings for integrating structured information from the knowledge base with unstructured information from text-based representations. Our experiments confirm that graph embeddings trained on a graph of hyperlinks between Wikipedia articles improve the performances of simple feed-forward neural ED model and a state-of-the-art neural ED system.\nVariational Graph Auto-Encoders (Thomas Kipf et al., 2016) Thomas Kipf, M. Welling. (2016)\nVariational Graph Auto-Encoders\nArXiv\nPaper Link\nInfluential Citation Count (347), SS-ID (54906484f42e871f7c47bbfe784a358b1448231f)\nABSTRACT\nWe introduce the variational graph auto-encoder (VGAE), a framework for unsupervised learning on graph-structured data based on the variational auto-encoder (VAE). This model makes use of latent variables and is capable of learning interpretable latent representations for undirected graphs. We demonstrate this model using a graph convolutional network (GCN) encoder and a simple inner product decoder. Our model achieves competitive results on a link prediction task in citation networks. In contrast to most existing models for unsupervised learning on graph-structured data and link prediction, our model can naturally incorporate node features, which significantly improves predictive performance on a number of benchmark datasets.\nEfficient embedding of complex networks to hyperbolic space via their Laplacian (Gregorio Alanis-Lobato et al., 2016) Gregorio Alanis-Lobato, Pablo Mier, Miguel Andrade. (2016)\nEfficient embedding of complex networks to hyperbolic space via their Laplacian\nScientific reports\nPaper Link\nInfluential Citation Count (4), SS-ID (559897d98f2c006d27fa09d7263c4a959d94eec3)\nABSTRACT\nThe different factors involved in the growth process of complex networks imprint valuable information in their observable topologies. How to exploit this information to accurately predict structural network changes is the subject of active research. A recent model of network growth sustains that the emergence of properties common to most complex systems is the result of certain trade-offs between node birth-time and similarity. This model has a geometric interpretation in hyperbolic space, where distances between nodes abstract this optimisation process. Current methods for network hyperbolic embedding search for node coordinates that maximise the likelihood that the network was produced by the afore-mentioned model. Here, a different strategy is followed in the form of the Laplacian-based Network Embedding, a simple yet accurate, efficient and data driven manifold learning approach, which allows for the quick geometric analysis of big networks. Comparisons against existing embedding and prediction techniques highlight its applicability to network evolution and link prediction.\nMolecular graph convolutions: moving beyond fingerprints (S. Kearnes et al., 2016) S. Kearnes, Kevin McCloskey, M. Berndl, V. Pande, Patrick F. Riley. (2016)\nMolecular graph convolutions: moving beyond fingerprints\nJournal of Computer-Aided Molecular Design\nPaper Link\nInfluential Citation Count (41), SS-ID (561c3fa53d36405186da9cab02bd68635c3738aa)\nABSTRACT\nMolecular “fingerprints” encoding structural information are the workhorse of cheminformatics and machine learning in drug discovery applications. However, fingerprint representations necessarily emphasize particular aspects of the molecular structure while ignoring others, rather than allowing the model to make data-driven decisions. We describe molecular graph convolutions, a machine learning architecture for learning from undirected graphs, specifically small molecules. Graph convolutions use a simple encoding of the molecular graph—atoms, bonds, distances, etc.—which allows the model to take greater advantage of information in the graph structure. Although graph convolutions do not outperform all fingerprint-based methods, they (along with other graph-based methods) represent a new paradigm in ligand-based virtual screening with exciting opportunities for future improvement.\nDeepBrowse: Similarity-Based Browsing Through Large Lists (Extended Abstract) (Haochen Chen et al., 2017) Haochen Chen, Arvind Ram Anantharam, S. Skiena. (2017)\nDeepBrowse: Similarity-Based Browsing Through Large Lists (Extended Abstract)\nSISAP\nPaper Link\nInfluential Citation Count (0), SS-ID (562d08ed73dad28c989b6a04fa1e389b0125ba59)\nABSTRACT\nWe propose a new approach for browsing through large lists in the absence of a predefined hierarchy. DeepBrowse is defined by the interaction of two fixed, globally-defined permutations on the space of objects: one ordering the items by similarity, the second based on magnitude or importance. We demonstrate this paradigm through our WikiBrowse app for discovering interesting Wikipedia pages, which enables the user to scan similar related entities and then increase depth once a region of interest has been found.\nDrug-target interaction prediction using ensemble learning and dimensionality reduction. (Ali Ezzat et al., 2017) Ali Ezzat, Min Wu, Xiaoli Li, C. Kwoh. (2017)\nDrug-target interaction prediction using ensemble learning and dimensionality reduction.\nMethods\nPaper Link\nInfluential Citation Count (5), SS-ID (57068d32847df76f2d5ba6bea4df0fef8fac0f30)\nABSTRACT\nHeterogeneous Dynamic Graph Attention Network (Qiuyan Li et al., 2020) Qiuyan Li, Yanlei Shang, Xiuquan Qiao, Wei Dai. (2020)\nHeterogeneous Dynamic Graph Attention Network\n2020 IEEE International Conference on Knowledge Graph (ICKG)\nPaper Link\nInfluential Citation Count (1), SS-ID (57512101d4d64e7ec715a50eaba2e3e479239c64)\nABSTRACT\nNetwork embedding (graph embedding) has become the focus of studying graph structure in recent years. In addition to the research on homogeneous networks and heterogeneous networks, there are also some methods to attempt to solve the problem of dynamic network embedding. However, in dynamic networks, there is no research method specifically for heterogeneous networks. Therefore, this paper proposes a heterogeneous dynamic graph attention network (HDGAN), which attempts to use the attention mechanism to take the heterogeneity and dynamics of the network into account at the same time, so as to better learn network embedding. Our method is based on three levels of attention, namely structural-level attention, semantic-level attention and time-level attention. Structural-level attention pays attention to the network structure itself, and obtains the representation of structural-level nodes by learning the attention coefficients of neighbor nodes. Semantic-level attention integrates semantic information into the representation of nodes by learning the optimal weighted combination of different meta-paths. Time-level attention is based on the time decay effect, and the time feature is introduced into the node representation by neighborhood formation sequence. Through the above three levels of attention mechanism, the final network embedding can be obtained.Through experiments on two real-world heterogeneous dynamic networks, our models have the best results, proving the effectiveness of the HDGAN model.\nRecognizing Mentions of Adverse Drug Reaction in Social Media Using Knowledge-Infused Recurrent Models (Gabriel Stanovsky et al., 2017) Gabriel Stanovsky, D. Gruhl, Pablo N. Mendes. (2017)\nRecognizing Mentions of Adverse Drug Reaction in Social Media Using Knowledge-Infused Recurrent Models\nEACL\nPaper Link\nInfluential Citation Count (4), SS-ID (583aef90d21360c2a406af2f2323b7cfa86be532)\nABSTRACT\nRecognizing mentions of Adverse Drug Reactions (ADR) in social media is challenging: ADR mentions are context-dependent and include long, varied and unconventional descriptions as compared to more formal medical symptom terminology. We use the CADEC corpus to train a recurrent neural network (RNN) transducer, integrated with knowledge graph embeddings of DBpedia, and show the resulting model to be highly accurate (93.4 F1). Furthermore, even when lacking high quality expert annotations, we show that by employing an active learning technique and using purpose built annotation tools, we can train the RNN to perform well (83.9 F1).\nGEMSEC: Graph Embedding with Self Clustering (Benedek Rozemberczki et al., 2018) Benedek Rozemberczki, Ryan Davies, R. Sarkar, Charles Sutton. (2018)\nGEMSEC: Graph Embedding with Self Clustering\n2019 IEEE/ACM International Conference on Advances in Social Networks Analysis and Mining (ASONAM)\nPaper Link\nInfluential Citation Count (16), SS-ID (59be148a4b5f7e05cb3cb24afa1f6adad2cdfa29)\nABSTRACT\nModern graph embedding procedures can efficiently process graphs with millions of nodes. In this paper, we propose GEMSEC - a graph embedding algorithm which learns a clustering of the nodes simultaneously with computing their embedding. GEMSEC is a general extension of earlier work in the domain of sequence-based graph embedding. GEMSEC places nodes in an abstract feature space where the vertex features minimize the negative log-likelihood of preserving sampled vertex neighborhoods, and it incorporates known social network properties through a machine learning regularization. We present two new social network datasets and show that by simultaneously considering the embedding and clustering problems with respect to social properties, GEMSEC extracts high-quality clusters competitive with or superior to other community detection algorithms. In experiments, the method is found to be computationally efficient and robust to the choice of hyperparameters.\nGraph Classification using Structural Attention (J. B. Lee et al., 2018) J. B. Lee, Ryan A. Rossi, Xiangnan Kong. (2018)\nGraph Classification using Structural Attention\nKDD\nPaper Link\nInfluential Citation Count (10), SS-ID (59d502851cd20f28af03eef1d15dc83d3a7bb300)\nABSTRACT\nGraph classification is a problem with practical applications in many different domains. To solve this problem, one usually calculates certain graph statistics (i.e., graph features) that help discriminate between graphs of different classes. When calculating such features, most existing approaches process the entire graph. In a graphlet-based approach, for instance, the entire graph is processed to get the total count of different graphlets or subgraphs. In many real-world applications, however, graphs can be noisy with discriminative patterns confined to certain regions in the graph only. In this work, we study the problem of attention-based graph classification. The use of attention allows us to focus on small but informative parts of the graph, avoiding noise in the rest of the graph. We present a novel RNN model, called the Graph Attention Model (GAM), that processes only a portion of the graph by adaptively selecting a sequence of \u0026ldquo;informative\u0026rdquo; nodes. Experimental results on multiple real-world datasets show that the proposed method is competitive against various well-known methods in graph classification even though our method is limited to only a portion of the graph.\nFast Gradient Attack on Network Embedding (Jinyin Chen et al., 2018) Jinyin Chen, Yangyang Wu, Xuanheng Xu, Yixian Chen, Haibin Zheng, Qi Xuan. (2018)\nFast Gradient Attack on Network Embedding\nArXiv\nPaper Link\nInfluential Citation Count (14), SS-ID (5c0fe48ce1530d9757efca49d78709fc77caaf6c)\nABSTRACT\nNetwork embedding maps a network into a low-dimensional Euclidean space, and thus facilitate many network analysis tasks, such as node classification, link prediction and community detection etc, by utilizing machine learning methods. In social networks, we may pay special attention to user privacy, and would like to prevent some target nodes from being identified by such network analysis methods in certain cases. Inspired by successful adversarial attack on deep learning models, we propose a framework to generate adversarial networks based on the gradient information in Graph Convolutional Network (GCN). In particular, we extract the gradient of pairwise nodes based on the adversarial network, and select the pair of nodes with maximum absolute gradient to realize the Fast Gradient Attack (FGA) and update the adversarial network. This process is implemented iteratively and terminated until certain condition is satisfied, i.e., the number of modified links reaches certain predefined value. Comprehensive attacks, including unlimited attack, direct attack and indirect attack, are performed on six well-known network embedding methods. The experiments on real-world networks suggest that our proposed FGA behaves better than some baseline methods, i.e., the network embedding can be easily disturbed using FGA by only rewiring few links, achieving state-of-the-art attack performance.\nRepresentation Learning for Measuring Entity Relatedness with Rich Information (Yu Zhao et al., 2015) Yu Zhao, Zhiyuan Liu, Maosong Sun. (2015)\nRepresentation Learning for Measuring Entity Relatedness with Rich Information\nIJCAI\nPaper Link\nInfluential Citation Count (3), SS-ID (5c560cdfbfa48ed570b9b11e1a2f15e371e635f4)\nABSTRACT\nIncorporating multiple types of relational information from heterogeneous networks has been proved effective in data mining. Although Wikipedia is one of the most famous heterogeneous network, previous works of semantic analysis on Wikipedia are mostly limited on single type of relations. In this paper, we aim at incorporating multiple types of relations to measure the semantic relatedness between Wikipedia entities. We propose a framework of coordinate matrix factorization to construct lowdimensional continuous representation for entities, categories and words in the same semantic space. We formulate this task as the completion of a sparse entity-entity association matrix, in which each entry quantifies the strength of relatedness between corresponding entities. We evaluate our model on the task of judging pair-wise word similarity. Experiment result shows that our model outperforms both traditional entity relatedness algorithms and other representation learning models.\nCombining content and link for classification using matrix factorization (Shenghuo Zhu et al., 2007) Shenghuo Zhu, Kai Yu, Yun Chi, Yihong Gong. (2007)\nCombining content and link for classification using matrix factorization\nSIGIR\nPaper Link\nInfluential Citation Count (19), SS-ID (5c58ad9a6c09782814a7d048bebd6ef1609c0fb4)\nABSTRACT\nThe world wide web contains rich textual contents that areinterconnected via complex hyperlinks. This huge database violates the assumption held by most of conventional statistical methods that each web page is considered as an independent and identical sample. It is thus difficult to apply traditional mining or learning methods for solving web mining problems, e.g., web page classification, by exploiting both the content and the link structure. The research in this direction has recently received considerable attention but are still in an early stage. Though a few methods exploit both the link structure or the content information, some of them combine the only authority information with the content information, and the others first decompose the link structure into hub and authority features, then apply them as additional document features. Being practically attractive for its great simplicity, this paper aims to design an algorithm that exploits both the content and linkage information, by carrying out a joint factorization on both the linkage adjacency matrix and the document-term matrix, and derives a new representation for web pages in a low-dimensional factor space, without explicitly separating them as content, hub or authority factors. Further analysis can be performed based on the compact representation of web pages. In the experiments, the proposed method is compared with state-of-the-art methods and demonstrates an excellent accuracy in hypertext classification on the WebKB and Cora benchmarks.\nConvolutional Networks on Graphs for Learning Molecular Fingerprints (D. Duvenaud et al., 2015) D. Duvenaud, D. Maclaurin, J. Aguilera-Iparraguirre, R. Gómez-Bombarelli, Timothy D. Hirzel, Alán Aspuru-Guzik, Ryan P. Adams. (2015)\nConvolutional Networks on Graphs for Learning Molecular Fingerprints\nNIPS\nPaper Link\nInfluential Citation Count (147), SS-ID (5d1bfeed240709725c78bc72ea40e55410b373dc)\nABSTRACT\nWe introduce a convolutional neural network that operates directly on graphs. These networks allow end-to-end learning of prediction pipelines whose inputs are graphs of arbitrary size and shape. The architecture we present generalizes standard molecular feature extraction methods based on circular fingerprints. We show that these data-driven features are more interpretable, and have better predictive performance on a variety of tasks.\nHGMF: Heterogeneous Graph-based Fusion for Multimodal Data with Incompleteness (Jiayi Chen et al., 2020) Jiayi Chen, Aidong Zhang. (2020)\nHGMF: Heterogeneous Graph-based Fusion for Multimodal Data with Incompleteness\nKDD\nPaper Link\nInfluential Citation Count (2), SS-ID (5d24501a99d05306817171a744878315c31a880b)\nABSTRACT\nWith the advances in data collection techniques, large amounts of multimodal data collected from multiple sources are becoming available. Such multimodal data can provide complementary information that can reveal fundamental characteristics of real-world subjects. Thus, multimodal machine learning has become an active research area. Extensive works have been developed to exploit multimodal interactions and integrate multi-source information. However, multimodal data in the real world usually comes with missing modalities due to various reasons, such as sensor damage, data corruption, and human mistakes in recording. Effectively integrating and analyzing multimodal data with incompleteness remains a challenging problem. We propose a Heterogeneous Graph-based Multimodal Fusion (HGMF) approach to enable multimodal fusion of incomplete data within a heterogeneous graph structure. The proposed approach develops a unique strategy for learning on incomplete multimodal data without data deletion or data imputation. More specifically, we construct a heterogeneous hypernode graph to model the multimodal data having different combinations of missing modalities, and then we formulate a graph neural network based transductive learning framework to project the heterogeneous incomplete data onto a unified embedding space, and multi-modalities are fused along the way. The learning framework captures modality interactions from available data, and leverages the relationships between different incompleteness patterns. Our experimental results demonstrate that the proposed method outperforms existing graph-based as well as non-graph based baselines on three different datasets.\nMax-Margin DeepWalk: Discriminative Learning of Network Representation (Cunchao Tu et al., 2016) Cunchao Tu, Weicheng Zhang, Zhiyuan Liu, Maosong Sun. (2016)\nMax-Margin DeepWalk: Discriminative Learning of Network Representation\nIJCAI\nPaper Link\nInfluential Citation Count (29), SS-ID (5d66991e1f541a08e81e59060cb0bb7f6931c2d9)\nABSTRACT\nDeepWalk is a typical representation learning method that learns low-dimensional representations for vertices in social networks. Similar to other network representation learning (NRL) models, it encodes the network structure into vertex representations and is learnt in unsupervised form. However, the learnt representations usually lack the ability of discrimination when applied to machine learning tasks, such as vertex classification. In this paper, we overcome this challenge by proposing a novel semi-supervised model, max-margin Deep-Walk (MMDW). MMDW is a unified NRL framework that jointly optimizes the max-margin classifier and the aimed social representation learning model. Influenced by the max-margin classifier, the learnt representations not only contain the network structure, but also have the characteristic of discrimination. The visualizations of learnt representations indicate that our model is more discriminative than unsupervised ones, and the experimental results on vertex classification demonstrate that our method achieves a significant improvement than other state-of-the-art methods. The source code can be obtained from https://github.com/thunlp/MMDW.\nOpenGraphGym: A Parallel Reinforcement Learning Framework for Graph Optimization Problems (Weijian Zheng et al., 2020) Weijian Zheng, Dali Wang, Fengguang Song. (2020)\nOpenGraphGym: A Parallel Reinforcement Learning Framework for Graph Optimization Problems\nICCS\nPaper Link\nInfluential Citation Count (1), SS-ID (5e46f4d777670116523ab4c6cb9d58cf20c38e73)\nABSTRACT\nThis paper presents an open-source, parallel AI environment (named OpenGraphGym) to facilitate the application of reinforcement learning (RL) algorithms to address combinatorial graph optimization problems. This environment incorporates a basic deep reinforcement learning method, and several graph embeddings to capture graph features, it also allows users to rapidly plug in and test new RL algorithms and graph embeddings for graph optimization problems. This new open-source RL framework is targeted at achieving both high performance and high quality of the computed graph solutions. This RL framework forms the foundation of several ongoing research directions, including 1) benchmark works on different RL algorithms and embedding methods for classic graph problems; 2) advanced parallel strategies for extreme-scale graph computations, as well as 3) performance evaluation on real-world graph solutions.\nSpectral Networks and Locally Connected Networks on Graphs (Joan Bruna et al., 2013) Joan Bruna, Wojciech Zaremba, Arthur D. Szlam, Yann LeCun. (2013)\nSpectral Networks and Locally Connected Networks on Graphs\nICLR\nPaper Link\nInfluential Citation Count (262), SS-ID (5e925a9f1e20df61d1e860a7aa71894b35a1c186)\nABSTRACT\nConvolutional Neural Networks are extremely efficient architectures in image and audio recognition tasks, thanks to their ability to exploit the local translational invariance of signal classes over their domain. In this paper we consider possible generalizations of CNNs to signals defined on more general domains without the action of a translation group. In particular, we propose two constructions, one based upon a hierarchical clustering of the domain, and another based on the spectrum of the graph Laplacian. We show through experiments that for low-dimensional graphs it is possible to learn convolutional layers with a number of parameters independent of the input size, resulting in efficient deep architectures.\nGraphSeq2Seq: Graph-Sequence-to-Sequence for Neural Machine Translation (Guoshuai Zhao et al., 2018) Guoshuai Zhao, Jun Yu Li, Lu Wang, Xueming Qian, Y. Fu. (2018)\nGraphSeq2Seq: Graph-Sequence-to-Sequence for Neural Machine Translation\nPaper Link\nInfluential Citation Count (1), SS-ID (5f2a156909e2550cdc09b7d3d3d503ec5d52b1d7)\nABSTRACT\nGuoshuai Zhao, Jun Yu Li, Lu Wang, Xueming Qian, Y. Fu. (2018)\nGraphSeq2Seq: Graph-Sequence-to-Sequence for Neural Machine Translation\nPaper Link\nInfluential Citation Count (1), SS-ID (5f2a156909e2550cdc09b7d3d3d503ec5d52b1d7)\nABSTRACT\nAuto-Encoding Variational Bayes (Diederik P. Kingma et al., 2013) Diederik P. Kingma, M. Welling. (2013)\nAuto-Encoding Variational Bayes\nICLR\nPaper Link\nInfluential Citation Count (3503), SS-ID (5f5dc5b9a2ba710937e2c413b37b053cd673df02)\nABSTRACT\nAbstract: How can we perform efficient inference and learning in directed probabilistic models, in the presence of continuous latent variables with intractable posterior distributions, and large datasets? We introduce a stochastic variational inference and learning algorithm that scales to large datasets and, under some mild differentiability conditions, even works in the intractable case. Our contributions is two-fold. First, we show that a reparameterization of the variational lower bound yields a lower bound estimator that can be straightforwardly optimized using standard stochastic gradient methods. Second, we show that for i.i.d. datasets with continuous latent variables per datapoint, posterior inference can be made especially efficient by fitting an approximate inference model (also called a recognition model) to the intractable posterior using the proposed lower bound estimator. Theoretical advantages are reflected in experimental results.\nDistance-Aware DAG Embedding for Proximity Search on Heterogeneous Graphs (Zemin Liu et al., 2018) Zemin Liu, V. Zheng, Zhou Zhao, Fanwei Zhu, K. Chang, Minghui Wu, Jing Ying. (2018)\nDistance-Aware DAG Embedding for Proximity Search on Heterogeneous Graphs\nAAAI\nPaper Link\nInfluential Citation Count (3), SS-ID (6065a29041525360665320fab231dd9e5ca82ab8)\nABSTRACT\nProximity search on heterogeneous graphs aims to measure the proximity between two nodes on a graph w.r.t. some semantic relation for ranking. Pioneer work often tries to measure such proximity by paths connecting the two nodes. However, paths as linear sequences have limited expressiveness for the complex network connections. In this paper, we explore a more expressive DAG (directed acyclic graph) data structure for modeling the connections between two nodes. Particularly, we are interested in learning a representation for the DAGs to encode the proximity between two nodes. We face two challenges to use DAGs, including how to efficiently generate DAGs and how to effectively learn DAG embedding for proximity search. We find distance-awareness as important for proximity search and the key to solve the above challenges. Thus we develop a novel Distance-aware DAG Embedding (D2AGE) model. We evaluate D2AGE on three benchmark data sets with six semantic relations, and we show that D2AGE outperforms the state-of-the-art baselines. We release the code on https://github.com/shuaiOKshuai.\nComplex and Holographic Embeddings of Knowledge Graphs: A Comparison (Théo Trouillon et al., 2017) Théo Trouillon, Maximilian Nickel. (2017)\nComplex and Holographic Embeddings of Knowledge Graphs: A Comparison\nArXiv\nPaper Link\nInfluential Citation Count (6), SS-ID (607e0bafc04bcc93089d25fed6d2ba1a41637ed7)\nABSTRACT\nEmbeddings of knowledge graphs have received significant attention due to their excellent performance for tasks like link prediction and entity resolution. In this short paper, we are providing a comparison of two state-of-the-art knowledge graph embeddings for which their equivalence has recently been established, i.e., ComplEx and HolE [Nickel, Rosasco, and Poggio, 2016; Trouillon et al., 2016; Hayashi and Shimbo, 2017]. First, we briefly review both models and discuss how their scoring functions are equivalent. We then analyze the discrepancy of results reported in the original articles, and show experimentally that they are likely due to the use of different loss functions. In further experiments, we evaluate the ability of both models to embed symmetric and antisymmetric patterns. Finally, we discuss advantages and disadvantages of both models and under which conditions one would be preferable to the other.\nGraph Embedding Based on Characteristic of Rooted Subgraph Structure (Yan Liu et al., 2020) Yan Liu, Xiaokun Zhang, Lian Liu, Gaojian Li. (2020)\nGraph Embedding Based on Characteristic of Rooted Subgraph Structure\nKSEM\nPaper Link\nInfluential Citation Count (0), SS-ID (60e8a34070dbbb8ef1b3ca4e789d20dd7c826ded)\nABSTRACT\nGiven the problem that currently distributed graph embedding models have not yet been effectively modeled of substructure similarity, biased-graph2vec, a graph embedding model based on structural characteristics of rooted subgraphs is proposed in this paper. This model, based on the distributed representation model of the graph, has modified its original random walk process and converted it to a random walk with weight bias based on structural similarity. The appropriate context is generated for all substructures. Based on preserving the tag features of the nodes and edges in the substructure, the representation of the substructure in the feature space depends more on the structural similarity itself. Biased-graph2vec calculates the graph representations with unsupervised algorithm and could build the model for both graphs and substructures via universal models, leaving complex feature engineering behind and has functional mobility. Meanwhile, this method models similar information among substructures, solving the problem that typical random walk strategies could not capture similarities of substructures with long distance. The experiments of graph classification are carried out on six open benchmark datasets. The comparison among our method, the graph kernel method, and the baseline method without considering the structural similarity of long-distance ions is made. Experiments show that the method this paper proposed has varying degrees inordinately improved the accuracy of classification tasks.\nMAN: Moment Alignment Network for Natural Language Moment Retrieval via Iterative Graph Adjustment (Da Zhang et al., 2018) Da Zhang, Xiyang Dai, Xin Eric Wang, Yuan-fang Wang, L. Davis. (2018)\nMAN: Moment Alignment Network for Natural Language Moment Retrieval via Iterative Graph Adjustment\n2019 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)\nPaper Link\nInfluential Citation Count (42), SS-ID (613f59279586bd53aed57bc133246a4eb3c38977)\nABSTRACT\nThis research strives for natural language moment retrieval in long, untrimmed video streams. The problem is not trivial especially when a video contains multiple moments of interests and the language describes complex temporal dependencies, which often happens in real scenarios. We identify two crucial challenges: semantic misalignment and structural misalignment. However, existing approaches treat different moments separately and do not explicitly model complex moment-wise temporal relations. In this paper, we present Moment Alignment Network (MAN), a novel framework that unifies the candidate moment encoding and temporal structural reasoning in a single-shot feed-forward network. MAN naturally assigns candidate moment representations aligned with language semantics over different temporal locations and scales. Most importantly, we propose to explicitly model moment-wise temporal relations as a structured graph and devise an iterative graph adjustment network to jointly learn the best structure in an end-to-end manner. We evaluate the proposed approach on two challenging public benchmarks DiDeMo and Charades-STA, where our MAN significantly outperforms the state-of-the-art by a large margin.\nMulti-View Clustering and Semi-Supervised Classification with Adaptive Neighbours (F. Nie et al., 2017) F. Nie, Guohao Cai, Xuelong Li. (2017)\nMulti-View Clustering and Semi-Supervised Classification with Adaptive Neighbours\nAAAI\nPaper Link\nInfluential Citation Count (34), SS-ID (62b5d514ec49173af59cab6f0dfdc7f280d53f36)\nABSTRACT\nDue to the efficiency of learning relationships and complex structures hidden in data, graph-oriented methods have been widely investigated and achieve promising performance in multi-view learning. Generally, these learning algorithms construct informative graph for each view or fuse different views to one graph, on which the following procedure are based. However, in many real world dataset, original data always contain noise and outlying entries that result in unreliable and inaccurate graphs, which cannot be ameliorated in the previous methods. In this paper, we propose a novel multi-view learning model which performs clustering/semi-supervised classification and local structure learning simultaneously. The obtained optimal graph can be partitioned into specific clusters directly. Moreover, our model can allocate ideal weight for each view automatically without additional weight and penalty parameters. An efficient algorithm is proposed to optimize this model. Extensive experimental results on different real-world datasets show that the proposed model outperforms other state-of-the-art multi-view algorithms.\nExploiting Semantics in Neural Machine Translation with Graph Convolutional Networks (Diego Marcheggiani et al., 2018) Diego Marcheggiani, Jasmijn Bastings, Ivan Titov. (2018)\nExploiting Semantics in Neural Machine Translation with Graph Convolutional Networks\nNAACL\nPaper Link\nInfluential Citation Count (8), SS-ID (6411da05a0e6f3e38bcac0ce57c28038ff08081c)\nABSTRACT\nSemantic representations have long been argued as potentially useful for enforcing meaning preservation and improving generalization performance of machine translation methods. In this work, we are the first to incorporate information about predicate-argument structure of source sentences (namely, semantic-role representations) into neural machine translation. We use Graph Convolutional Networks (GCNs) to inject a semantic bias into sentence encoders and achieve improvements in BLEU scores over the linguistic-agnostic and syntax-aware versions on the English–German language pair.\nTracking network dynamics: A survey using graph distances (C. Donnat et al., 2018) C. Donnat, S. Holmes. (2018)\nTracking network dynamics: A survey using graph distances\nThe Annals of Applied Statistics\nPaper Link\nInfluential Citation Count (2), SS-ID (64aa05ee62ed2c55e002acdcdeadd29daefe9426)\nABSTRACT\nFrom longitudinal biomedical studies to social networks, graphs have emerged as essential objects for describing evolving interactions between agents in complex systems. In such studies, after pre-processing, the data are encoded by a set of graphs, each representing a system’s state at a different point in time or space. The analysis of the system’s dynamics depends on the selection of the appropriate analytical tools. In particular, after specifying properties characterizing similarities between states, a critical step lies in the choice of a distance between graphs capable of reflecting such similarities. While the literature offers a number of distances to choose from, their properties have been little investigated and no guidelines regarding the choice of such a distance have yet been provided. In particular, most graph distances consider that the nodes are exchangeable—ignoring node “identities.” Alignment of the graphs according to identified nodes enables us to enhance these distances’ sensitivity to perturbations in the network and detect important changes in graph dynamics. Thus the selection of an adequate metric is a decisive—yet delicate—practical matter. In the spirit of Goldenberg et al.’s seminal 2009 review [Found. Trends Mach. Learn. 2 (2010) 129–233], this article provides an overview of commonly-used graph distances and an explicit characterization of the structural changes that they are best able to capture. We show how these choices affect real-life situations, and we use these distances to analyze both a longitudinal microbiome dataset and a brain fMRI study. One contribution of the present study is a coordinated suite of data analytic techniques, displays and statistical tests using “metagraphs”: a graph of graphs based on a chosen metric. Permutation tests can uncover the effects of covariates on the graphs’ variability. Furthermore, synthetic examples provide intuition as to the qualities and drawbacks of the different distances. Above all, we provide some guidance on choosing one distance over another in different contexts. Finally, we extend the scope of our analyses from temporal to spatial dynamics and apply these different distances to a network created from worldwide recipes.\nLinkage Based Face Clustering via Graph Convolution Network (Zhongdao Wang et al., 2019) Zhongdao Wang, Liang Zheng, Yali Li, Shengjin Wang. (2019)\nLinkage Based Face Clustering via Graph Convolution Network\n2019 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)\nPaper Link\nInfluential Citation Count (18), SS-ID (6834b6a529c969e5feb1fb77713eff8f19704b31)\nABSTRACT\nIn this paper, we present an accurate and scalable approach to the face clustering task. We aim at grouping a set of faces by their potential identities. We formulate this task as a link prediction problem: a link exists between two faces if they are of the same identity. The key idea is that we find the local context in the feature space around an instance (face) contains rich information about the linkage relationship between this instance and its neighbors. By constructing sub-graphs around each instance as input data, which depict the local context, we utilize the graph convolution network (GCN) to perform reasoning and infer the likelihood of linkage between pairs in the sub-graphs. Experiments show that our method is more robust to the complex distribution of faces than conventional methods, yielding favorably comparable results to state-of-the-art methods on standard face clustering benchmarks, and is scalable to large datasets. Furthermore, we show that the proposed method does not need the number of clusters as prior, is aware of noises and outliers, and can be extended to a multi-view version for more accurate clustering accuracy.\nEmbedding of Embedding (EOE): Joint Embedding for Coupled Heterogeneous Networks (Linchuan Xu et al., 2017) Linchuan Xu, Xiaokai Wei, Jiannong Cao, Philip S. Yu. (2017)\nEmbedding of Embedding (EOE): Joint Embedding for Coupled Heterogeneous Networks\nWSDM\nPaper Link\nInfluential Citation Count (14), SS-ID (688f937ddeed178802c53963743d1801a778614e)\nABSTRACT\nNetwork embedding is increasingly employed to assist network analysis as it is effective to learn latent features that encode linkage information. Various network embedding methods have been proposed, but they are only designed for a single network scenario. In the era of big data, different types of related information can be fused together to form a coupled heterogeneous network, which consists of two different but related sub-networks connected by inter-network edges. In this scenario, the inter-network edges can act as comple- mentary information in the presence of intra-network ones. This complementary information is important because it can make latent features more comprehensive and accurate. And it is more important when the intra-network edges are ab- sent, which can be referred to as the cold-start problem. In this paper, we thus propose a method named embedding of embedding (EOE) for coupled heterogeneous networks. In the EOE, latent features encode not only intra-network edges, but also inter-network ones. To tackle the challenge of heterogeneities of two networks, the EOE incorporates a harmonious embedding matrix to further embed the em- beddings that only encode intra-network edges. Empirical experiments on a variety of real-world datasets demonstrate the EOE outperforms consistently single network embedding methods in applications including visualization, link prediction multi-class classification, and multi-label classification.\nSkeleton-Based Action Recognition With Directed Graph Neural Networks (Lei Shi et al., 2019) Lei Shi, Yifan Zhang, Jian Cheng, Hanqing Lu. (2019)\nSkeleton-Based Action Recognition With Directed Graph Neural Networks\n2019 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)\nPaper Link\nInfluential Citation Count (34), SS-ID (68a024d7b70ef3989a6751678f635cbe754440fc)\nABSTRACT\nThe skeleton data have been widely used for the action recognition tasks since they can robustly accommodate dynamic circumstances and complex backgrounds. In existing methods, both the joint and bone information in skeleton data have been proved to be of great help for action recognition tasks. However, how to incorporate these two types of data to best take advantage of the relationship between joints and bones remains a problem to be solved. In this work, we represent the skeleton data as a directed acyclic graph based on the kinematic dependency between the joints and bones in the natural human body. A novel directed graph neural network is designed specially to extract the information of joints, bones and their relations and make prediction based on the extracted features. In addition, to better fit the action recognition task, the topological structure of the graph is made adaptive based on the training process, which brings notable improvement. Moreover, the motion information of the skeleton sequence is exploited and combined with the spatial information to further enhance the performance in a two-stream framework. Our final model is tested on two large-scale datasets, NTU-RGBD and Skeleton-Kinetics, and exceeds state-of-the-art performance on both of them.\nMulti-Modal Bayesian Embeddings for Learning Social Knowledge Graphs (Zhilin Yang et al., 2015) Zhilin Yang, Jie Tang, William W. Cohen. (2015)\nMulti-Modal Bayesian Embeddings for Learning Social Knowledge Graphs\nIJCAI\nPaper Link\nInfluential Citation Count (3), SS-ID (695d4c04f6e4f7ba5f771ac7853fdbaa81713ae8)\nABSTRACT\nWe study the extent to which online social networks can be connected to open knowledge bases. The problem is referred to as learning social knowledge graphs. We propose a multi-modal Bayesian embedding model, GenVector, to learn latent topics that generate word and network embeddings. GenVector leverages large-scale unlabeled data with embeddings and represents data of two modalities\u0026mdash;i.e., social network users and knowledge concepts\u0026mdash;in a shared latent topic space. Experiments on three datasets show that the proposed method clearly outperforms state-of-the-art methods. We then deploy the method on AMiner, a large-scale online academic search system with a network of 38,049,189 researchers with a knowledge base with 35,415,011 concepts. Our method significantly decreases the error rate in an online A/B test with live users.\nTask-Guided and Path-Augmented Heterogeneous Network Embedding for Author Identification (Ting Chen et al., 2016) Ting Chen, Yizhou Sun. (2016)\nTask-Guided and Path-Augmented Heterogeneous Network Embedding for Author Identification\nWSDM\nPaper Link\nInfluential Citation Count (13), SS-ID (6b183d2297cb493a57dbc875689ab2430d870043)\nABSTRACT\nIn this paper, we study the problem of author identification under double-blind review setting, which is to identify potential authors given information of an anonymized paper. Different from existing approaches that rely heavily on feature engineering, we propose to use network embedding approach to address the problem, which can automatically represent nodes into lower dimensional feature vectors. However, there are two major limitations in recent studies on network embedding: (1) they are usually general-purpose embedding methods, which are independent of the specific tasks; and (2) most of these approaches can only deal with homogeneous networks, where the heterogeneity of the network is ignored. Hence, challenges faced here are two folds: (1) how to embed the network under the guidance of the author identification task, and (2) how to select the best type of information due to the heterogeneity of the network. To address the challenges, we propose a task-guided and path-augmented heterogeneous network embedding model. In our model, nodes are first embedded as vectors in latent feature space. Embeddings are then shared and jointly trained according to task-specific and network-general objectives. We extend the existing unsupervised network embedding to incorporate meta paths in heterogeneous networks, and select paths according to the specific task. The guidance from author identification task for network embedding is provided both explicitly in joint training and implicitly during meta path selection. Our experiments demonstrate that by using path-augmented network embedding with task guidance, our model can obtain significantly better accuracy at identifying the true authors comparing to existing methods.\nInductive Representation Learning on Large Graphs (William L. Hamilton et al., 2017) William L. Hamilton, Z. Ying, J. Leskovec. (2017)\nInductive Representation Learning on Large Graphs\nNIPS\nPaper Link\nInfluential Citation Count (1254), SS-ID (6b7d6e6416343b2a122f8416e69059ce919026ef)\nABSTRACT\nLow-dimensional embeddings of nodes in large graphs have proved extremely useful in a variety of prediction tasks, from content recommendation to identifying protein functions. However, most existing approaches require that all nodes in the graph are present during training of the embeddings; these previous approaches are inherently transductive and do not naturally generalize to unseen nodes. Here we present GraphSAGE, a general, inductive framework that leverages node feature information (e.g., text attributes) to efficiently generate node embeddings for previously unseen data. Instead of training individual embeddings for each node, we learn a function that generates embeddings by sampling and aggregating features from a node\u0026rsquo;s local neighborhood. Our algorithm outperforms strong baselines on three inductive node-classification benchmarks: we classify the category of unseen nodes in evolving information graphs based on citation and Reddit post data, and we show that our algorithm generalizes to completely unseen graphs using a multi-graph dataset of protein-protein interactions.\nJust SLaQ When You Approximate: Accurate Spectral Distances for Web-Scale Graphs (Anton Tsitsulin et al., 2020) Anton Tsitsulin, Marina Munkhoeva, Bryan Perozzi. (2020)\nJust SLaQ When You Approximate: Accurate Spectral Distances for Web-Scale Graphs\nWWW\nPaper Link\nInfluential Citation Count (3), SS-ID (6bcea47afc6fcdada957e8d72b9b27b7866bf535)\nABSTRACT\nGraph comparison is a fundamental operation in data mining and information retrieval. Due to the combinatorial nature of graphs, it is hard to balance the expressiveness of the similarity measure and its scalability. Spectral analysis provides quintessential tools for studying the multi-scale structure of graphs and is a well-suited foundation for reasoning about differences between graphs. However, computing full spectrum of large graphs is computationally prohibitive; thus, spectral graph comparison methods often rely on rough approximation techniques with weak error guarantees. In this work, we propose SLaQ , an efficient and effective approximation technique for computing spectral distances between graphs with billions of nodes and edges. We derive the corresponding error bounds and demonstrate that accurate computation is possible in time linear in the number of graph edges. In a thorough experimental evaluation, we show that SLaQ outperforms existing methods, oftentimes by several orders of magnitude in approximation accuracy, and maintains comparable performance, allowing to compare million-scale graphs in a matter of minutes on a single machine.\nStructPool: Structured Graph Pooling via Conditional Random Fields (Hao Yuan et al., 2020) Hao Yuan, Shuiwang Ji. (2020)\nStructPool: Structured Graph Pooling via Conditional Random Fields\nICLR\nPaper Link\nInfluential Citation Count (9), SS-ID (6c252187647a437b32b163a295d62b65cda6e0fe)\nABSTRACT\nLearning high-level representations for graphs is of great importance for graph analysis tasks. In addition to graph convolution, graph pooling is an important but less explored research area. In particular, most of existing graph pooling techniques do not consider the graph structural information explicitly. We argue that such information is important and develop a novel graph pooling technique, know as the StructPool, in this work. We consider the graph pooling as a node clustering problem, which requires the learning of a cluster assignment matrix. We propose to formulate it as a structured prediction problem and employ conditional random fields to capture the relationships among assignments of different nodes. We also generalize our method to incorporate graph topological information in designing the Gibbs energy function. Experimental results on multiple datasets demonstrate the effectiveness of our proposed StructPool.\nGraph Convolutional Neural Networks for Web-Scale Recommender Systems (Rex Ying et al., 2018) Rex Ying, Ruining He, Kaifeng Chen, Pong Eksombatchai, William L. Hamilton, J. Leskovec. (2018)\nGraph Convolutional Neural Networks for Web-Scale Recommender Systems\nKDD\nPaper Link\nInfluential Citation Count (128), SS-ID (6c96c2d4a3fbd572fef2d59cb856521ee1746789)\nABSTRACT\nRecent advancements in deep neural networks for graph-structured data have led to state-of-the-art performance on recommender system benchmarks. However, making these methods practical and scalable to web-scale recommendation tasks with billions of items and hundreds of millions of users remains an unsolved challenge. Here we describe a large-scale deep recommendation engine that we developed and deployed at Pinterest. We develop a data-efficient Graph Convolutional Network (GCN) algorithm, which combines efficient random walks and graph convolutions to generate embeddings of nodes (i.e., items) that incorporate both graph structure as well as node feature information. Compared to prior GCN approaches, we develop a novel method based on highly efficient random walks to structure the convolutions and design a novel training strategy that relies on harder-and-harder training examples to improve robustness and convergence of the model. We also develop an efficient MapReduce model inference algorithm to generate embeddings using a trained model. Overall, we can train on and embed graphs that are four orders of magnitude larger than typical GCN implementations. We show how GCN embeddings can be used to make high-quality recommendations in various settings at Pinterest, which has a massive underlying graph with 3 billion nodes representing pins and boards, and 17 billion edges. According to offline metrics, user studies, as well as A/B tests, our approach generates higher-quality recommendations than comparable deep learning based systems. To our knowledge, this is by far the largest application of deep graph embeddings to date and paves the way for a new generation of web-scale recommender systems based on graph convolutional architectures.\nA General View for Network Embedding as Matrix Factorization (Xin Liu et al., 2019) Xin Liu, T. Murata, Kyoung-Sook Kim, Chatchawan Kotarasu, Chenyi Zhuang. (2019)\nA General View for Network Embedding as Matrix Factorization\nWSDM\nPaper Link\nInfluential Citation Count (1), SS-ID (6cb5a18edade451793d6958bc3e2a16b938dc48d)\nABSTRACT\nWe propose a general view that demonstrates the relationship between network embedding approaches and matrix factorization. Unlike previous works that present the equivalence for the approaches from a skip-gram model perspective, we provide a more fundamental connection from an optimization (objective function) perspective. We demonstrate that matrix factorization is equivalent to optimizing two objectives: one is for bringing together the embeddings of similar nodes; the other is for separating the embeddings of distant nodes. The matrix to be factorized has a general form: S-β. The elements of $\\mathbfS $ indicate pairwise node similarities. They can be based on any user-defined similarity/distance measure or learned from random walks on networks. The shift number β is related to a parameter that balances the two objectives. More importantly, the resulting embeddings are sensitive to β and we can improve the embeddings by tuning β. Experiments show that matrix factorization based on a new proposed similarity measure and β-tuning strategy significantly outperforms existing matrix factorization approaches on a range of benchmark networks.\nDiscovering missing links in Wikipedia (S. F. Adafre et al., 2005) S. F. Adafre, M. de Rijke. (2005)\nDiscovering missing links in Wikipedia\nLinkKDD \u0026lsquo;05\nPaper Link\nInfluential Citation Count (12), SS-ID (6d9064ff94c5186e12c39ea2e9f3815004066e51)\nABSTRACT\nIn this paper we address the problem of discovering missing hypertext links in Wikipedia. The method we propose consists of two steps: first, we compute a cluster of highly similar pages around a given page, and then we identify candidate links from those similar pages that might be missing on the given page. The main innovation is in the algorithm that we use for identifying similar pages, LTRank, which ranks pages using co-citation and page title information. Both LTRank and the link discovery method are manually evaluated and show acceptable results, especially given the simplicity of the methods and conservativeness of the evaluation criteria.\nNode Classification in Social Networks (Smriti Bhagat et al., 2011) Smriti Bhagat, Graham Cormode, S. Muthukrishnan. (2011)\nNode Classification in Social Networks\nSocial Network Data Analytics\nPaper Link\nInfluential Citation Count (11), SS-ID (6e45220c1f3a8a8cbf176a2fc722c7e8380d5dd4)\nABSTRACT\nWhen dealing with large graphs, such as those that arise in the context of online social networks, a subset of nodes may be labeled. These labels can indicate demographic values, interest, beliefs or other characteristics of the nodes (users). A core problem is to use this information to extend the labeling so that all nodes are assigned a label (or labels).\nEfficient aggregation for graph summarization (Yuanyuan Tian et al., 2008) Yuanyuan Tian, R. Hankins, J. Patel. (2008)\nEfficient aggregation for graph summarization\nSIGMOD Conference\nPaper Link\nInfluential Citation Count (28), SS-ID (6e9cf091dd709b557b32e7239647753680f0645b)\nABSTRACT\nGraphs are widely used to model real world objects and their relationships, and large graph datasets are common in many application domains. To understand the underlying characteristics of large graphs, graph summarization techniques are critical. However, existing graph summarization methods are mostly statistical (studying statistics such as degree distributions, hop-plots and clustering coefficients). These statistical methods are very useful, but the resolutions of the summaries are hard to control. In this paper, we introduce two database-style operations to summarize graphs. Like the OLAP-style aggregation methods that allow users to drill-down or roll-up to control the resolution of summarization, our methods provide an analogous functionality for large graph datasets. The first operation, called SNAP, produces a summary graph by grouping nodes based on user-selected node attributes and relationships. The second operation, called k-SNAP, further allows users to control the resolutions of summaries and provides the \u0026ldquo;drill-down\u0026rdquo; and \u0026ldquo;roll-up\u0026rdquo; abilities to navigate through summaries with different resolutions. We propose an efficient algorithm to evaluate the SNAP operation. In addition, we prove that the k-SNAP computation is NP-complete. We propose two heuristic methods to approximate the k-SNAP results. Through extensive experiments on a variety of real and synthetic datasets, we demonstrate the effectiveness and efficiency of the proposed methods.\nA min-max cut algorithm for graph partitioning and data clustering (C. Ding et al., 2001) C. Ding, Xiaofeng He, H. Zha, Ming Gu, H. Simon. (2001)\nA min-max cut algorithm for graph partitioning and data clustering\nProceedings 2001 IEEE International Conference on Data Mining\nPaper Link\nInfluential Citation Count (43), SS-ID (6ebb015ac7f7872ecadd75b837e859621abd0751)\nABSTRACT\nAn important application of graph partitioning is data clustering using a graph model - the pairwise similarities between all data objects form a weighted graph adjacency matrix that contains all necessary information for clustering. In this paper, we propose a new algorithm for graph partitioning with an objective function that follows the min-max clustering principle. The relaxed version of the optimization of the min-max cut objective function leads to the Fiedler vector in spectral graph partitioning. Theoretical analyses of min-max cut indicate that it leads to balanced partitions, and lower bounds are derived. The min-max cut algorithm is tested on newsgroup data sets and is found to out-perform other current popular partitioning/clustering methods. The linkage-based refinements to the algorithm further improve the quality of clustering substantially. We also demonstrate that a linearized search order based on linkage differential is better than that based on the Fiedler vector, providing another effective partitioning method.\nmiRNA-Disease Association Prediction with Collaborative Matrix Factorization (Zhen Shen et al., 2017) Zhen Shen, You-Hua Zhang, Kyungsook Han, A. Nandi, B. Honig, De-shuang Huang. (2017)\nmiRNA-Disease Association Prediction with Collaborative Matrix Factorization\nComplex.\nPaper Link\nInfluential Citation Count (3), SS-ID (6ececc7f15b281f1116f8197fc174f1c6f8b0e51)\nABSTRACT\nAs one of the factors in the noncoding RNA family, microRNAs (miRNAs) are involved in the development and progression of various complex diseases. Experimental identification of miRNA-disease association is expensive and time-consuming. Therefore, it is necessary to design efficient algorithms to identify novel miRNA-disease association. In this paper, we developed the computational method of Collaborative Matrix Factorization for miRNA-Disease Association prediction (CMFMDA) to identify potential miRNA-disease associations by integrating miRNA functional similarity, disease semantic similarity, and experimentally verified miRNA-disease associations. Experiments verified that CMFMDA achieves intended purpose and application values with its short consuming-time and high prediction accuracy. In addition, we used CMFMDA on Esophageal Neoplasms and Kidney Neoplasms to reveal their potential related miRNAs. As a result, 84% and 82% of top 50 predicted miRNA-disease pairs for these two diseases were confirmed by experiment. Not only this, but also CMFMDA could be applied to new diseases and new miRNAs without any known associations, which overcome the defects of many previous computational methods.\nCan Adversarial Network Attack be Defended? (Jinyin Chen et al., 2019) Jinyin Chen, Yangyang Wu, Xiang Lin, Qi Xuan. (2019)\nCan Adversarial Network Attack be Defended?\nArXiv\nPaper Link\nInfluential Citation Count (2), SS-ID (6ee2ac6e7179fe30065fbf60f8eff329624b9e85)\nABSTRACT\nMachine learning has been successfully applied to complex network analysis in various areas, and graph neural networks (GNNs) based methods outperform others. Recently, adversarial attack on networks has attracted special attention since carefully crafted adversarial networks with slight perturbations on clean network may invalid lots of network applications, such as node classification, link prediction, and community detection etc. Such attacks are easily constructed with serious security threat to various analyze methods, including traditional methods and deep models. To the best of our knowledge, it is the first time that defense method against network adversarial attack is discussed. In this paper, we are interested in the possibility of defense against adversarial attack on network, and propose defense strategies for GNNs against attacks. First, we propose novel adversarial training strategies to improve GNNs\u0026rsquo; defensibility against attacks. Then, we analytically investigate the robustness properties for GNNs granted by the use of smooth defense, and propose two special smooth defense strategies: smoothing distillation and smoothing cross-entropy loss function. Both of them are capable of smoothing gradient of GNNs, and consequently reduce the amplitude of adversarial gradients, which benefits gradient masking from attackers. The comprehensive experiments show that our proposed strategies have great defensibility against different adversarial attacks on four real-world networks in different network analyze tasks.\nCauchy Graph Embedding (Dijun Luo et al., 2011) Dijun Luo, C. Ding, F. Nie, Heng Huang. (2011)\nCauchy Graph Embedding\nICML\nPaper Link\nInfluential Citation Count (3), SS-ID (6f390eee4c9a082e02843fb34046f653624e9b76)\nABSTRACT\nLaplacian embedding provides a low-dimensional representation for the nodes of a graph where the edge weights denote pair-wise similarity among the node objects. It is commonly assumed that the Laplacian embedding results preserve the local topology of the original data on the low-dimensional projected subspaces, i.e., for any pair of graph nodes with large similarity, they should be embedded closely in the embedded space. However, in this paper, we will show that the Laplacian embedding often cannot preserve local topology well as we expected. To enhance the local topology preserving property in graph embedding, we propose a novel Cauchy graph embedding which preserves the similarity relationships of the original data in the embedded space via a new objective. Consequentially the machine learning tasks (such as k Nearest Neighbor type classifications) can be easily conducted on the embedded data with better performance. The experimental results on both synthetic and real world benchmark data sets demonstrate the usefulness of this new type of embedding.\nLearning Edge Representations via Low-Rank Asymmetric Projections (Sami Abu-El-Haija et al., 2017) Sami Abu-El-Haija, Bryan Perozzi, Rami Al-Rfou. (2017)\nLearning Edge Representations via Low-Rank Asymmetric Projections\nCIKM\nPaper Link\nInfluential Citation Count (6), SS-ID (6fcd6f350571ae102fea5315ecd3e9ca18814de6)\nABSTRACT\nWe propose a new method for embedding graphs while preserving directed edge information. Learning such continuous-space vector representations (or embeddings) of nodes in a graph is an important first step for using network information (from social networks, user-item graphs, knowledge bases, etc.) in many machine learning tasks. Unlike previous work, we (1) explicitly model an edge as a function of node embeddings, and we (2) propose a novel objective, the graph likelihood, which contrasts information from sampled random walks with non-existent edges. Individually, both of these contributions improve the learned representations, especially when there are memory constraints on the total size of the embeddings. When combined, our contributions enable us to significantly improve the state-of-the-art by learning more concise representations that better preserve the graph structure. We evaluate our method on a variety of link-prediction task including social networks, collaboration networks, and protein interactions, showing that our proposed method learn representations with error reductions of up to 76% and 55%, on directed and undirected graphs. In addition, we show that the representations learned by our method are quite space efficient, producing embeddings which have higher structure-preserving accuracy but are 10 times smaller.\nAdversarial Learning on Heterogeneous Information Networks (Binbin Hu et al., 2019) Binbin Hu, Yuan Fang, C. Shi. (2019)\nAdversarial Learning on Heterogeneous Information Networks\nKDD\nPaper Link\nInfluential Citation Count (8), SS-ID (721902635d4480b4e4a64e36441a0cf527f2dd02)\nABSTRACT\nNetwork embedding, which aims to represent network data in a low-dimensional space, has been commonly adopted for analyzing heterogeneous information networks (HIN). Although exiting HIN embedding methods have achieved performance improvement to some extent, they still face a few major weaknesses. Most importantly, they usually adopt negative sampling to randomly select nodes from the network, and they do not learn the underlying distribution for more robust embedding. Inspired by generative adversarial networks (GAN), we develop a novel framework HeGAN for HIN embedding, which trains both a discriminator and a generator in a minimax game. Compared to existing HIN embedding methods, our generator would learn the node distribution to generate better negative samples. Compared to GANs on homogeneous networks, our discriminator and generator are designed to be relation-aware in order to capture the rich semantics on HINs. Furthermore, towards more effective and efficient sampling, we propose a generalized generator, which samples \u0026ldquo;latent\u0026rdquo; nodes directly from a continuous distribution, not confined to the nodes in the original network as existing methods are. Finally, we conduct extensive experiments on four real-world datasets. Results show that we consistently and significantly outperform state-of-the-art baselines across all datasets and tasks.\nVOPRec: Vector Representation Learning of Papers with Text Information and Structural Identity for Recommendation (Xiangjie Kong et al., 2021) Xiangjie Kong, Mengyi Mao, Wei Wang, Jiaying Liu, Bo Xu. (2021)\nVOPRec: Vector Representation Learning of Papers with Text Information and Structural Identity for Recommendation\nIEEE Transactions on Emerging Topics in Computing\nPaper Link\nInfluential Citation Count (1), SS-ID (722b747700f5f878af41570ee8b2a1c57baced45)\nABSTRACT\nFinding relevant papers is a non-trivial problem for scholars due to the tremendous amount of academic information in the era of scholarly big data. Scientific paper recommendation systems have been developed to solve such problem by recommending relevant papers to scholars. However, previous paper recommendations calculate paper similarity based on hand-engineered features which are inflexible. To address this problem, we develop a scientific paper recommendation system, namely VOPRec, by vector representation learning of paper in citation networks. VOPRec takes advantages of recent research in both text and network representation learning for unsupervised feature design. In VOPRec, the text information is represented with word embedding to find papers of similar research interest. Then, the structural identity is converted into vectors to find papers of similar network topology. After bridging text information and structural identity with the citation network, vector representation of paper can be learned with network embedding. Finally, top-$Q$mml:mathmml:miQ\u0026lt;/mml:mi\u0026gt;\u0026lt;/mml:math\u0026gt; recommendation list is generated based on the similarity calculated with paper vectors. Through the APS data set, we show that VOPRec outperforms state-of-the-art paper recommendation baselines measured by precision, recall, F1, and NDCG.\nQuery-based Music Recommendations via Preference Embedding (Chih-Ming Chen et al., 2016) Chih-Ming Chen, Ming-Feng Tsai, Yu-Ching Lin, Yi-Hsuan Yang. (2016)\nQuery-based Music Recommendations via Preference Embedding\nRecSys\nPaper Link\nInfluential Citation Count (1), SS-ID (72728023c99d35fa884062841fd86661d296758b)\nABSTRACT\nA common scenario considered in recommender systems is to predict a user\u0026rsquo;s preferences on unseen items based on his/her preferences on observed items. A major limitation of this scenario is that a user might be interested in different things each time when using the system, but there is no way to allow the user to actively alter or adjust the recommended results. To address this issue, we propose the idea of \u0026ldquo;query-based recommendation\u0026rdquo; that allows a user to specify his/her search intention while exploring new items, thereby incorporating the concept of information retrieval into recommendation systems. Moreover, the idea is more desirable when the user intention can be expressed in different ways. Take music recommendation as an example: the proposed system allows a user to explore new song tracks by specifying either a track, an album, or an artist. To enable such heterogeneous queries in a recommender system, we present a novel technique called \u0026ldquo;Heterogeneous Preference Embedding\u0026rdquo; to encode user preference and query intention into low-dimensional vector spaces. Then, with simple search methods or similarity calculations, we can use the encoded representation of queries to generate recommendations. This method is fairly flexible and it is easy to add other types of information when available. Evaluations on three music listening datasets confirm the effectiveness of the proposed method over the state-of-the-art matrix factorization and network embedding methods.\nSemantic manifold learning for image retrieval (Yen-Yu Lin et al., 2005) Yen-Yu Lin, Tyng-Luh Liu, Hwann-Tzong Chen. (2005)\nSemantic manifold learning for image retrieval\nMULTIMEDIA \u0026lsquo;05\nPaper Link\nInfluential Citation Count (12), SS-ID (7438604d467c64156fcb3e86556d80f0ca72342d)\nABSTRACT\nLearning the user\u0026rsquo;s semantics for CBIR involves two different sources of information: the similarity relations entailed by the content-based features, and the relevance relations specified in the feedback. Given that, we propose an augmented relation embedding (ARE) to map the image space into a semantic manifold that faithfully grasps the user\u0026rsquo;s preferences. Besides ARE, we also look into the issues of selecting a good feature set for improving the retrieval performance. With these two aspects of efforts we have established a system that yields far better results than those previously reported. Overall, our approach can be characterized by three key properties: 1) The framework uses one relational graph to describe the similarity relations, and the other two to encode the relevant/irrelevant relations indicated in the feedback. 2) With the relational graphs so defined, learning a semantic manifold can be transformed into solving a constrained optimization problem, and is reduced to the ARE algorithm accounting for both the representation and the classification points of views. 3) An image representation based on augmented features is introduced to couple with the ARE learning. The use of these features is significant in capturing the semantics concerning different scales of image regions. We conclude with experimental results and comparisons to demonstrate the effectiveness of our method.\nLearning Features from Large-Scale, Noisy and Social Image-Tag Collection (Hanwang Zhang et al., 2015) Hanwang Zhang, Xindi Shang, Huanbo Luan, Yang Yang, Tat-Seng Chua. (2015)\nLearning Features from Large-Scale, Noisy and Social Image-Tag Collection\nACM Multimedia\nPaper Link\nInfluential Citation Count (1), SS-ID (7449864adc5d491fd0b2abf83a218429ce7834d4)\nABSTRACT\nFeature representation for multimedia content is the key to the progress of many fundamental multimedia tasks. Although recent advances in deep feature learning offer a promising route towards these tasks, they are limited in application to domains where high-quality and large-scale training data are hard to obtain. In this paper, we propose a novel deep feature learning paradigm based on large, noisy and social image-tag collections, which can be acquired from the inexhaustible social multimedia content on the Web. Instead of learning features from high-quality image-label supervision, we propose to learn from the image-word semantic relations, in a way of seeking a unified image-word embedding space, where the pairwise feature similarities preserve the semantic relations in the original image-word pairs. We offer an easy-to-use implementation for the proposed paradigm, which is fast and compatible for integrating into any state-of-the-art deep architectures. Experiments on NUSWIDE benchmark demonstrate that the features learned by our method significantly outperforms other state-of-the-art ones.\nLocality Preserving Projections (Xiaofei He et al., 2003) Xiaofei He, P. Niyogi. (2003)\nLocality Preserving Projections\nNIPS\nPaper Link\nInfluential Citation Count (791), SS-ID (75335244b49f4d1bb27aa51f1690bbefbbe1c3d1)\nABSTRACT\nMany problems in information processing involve some form of dimensionality reduction. In this paper, we introduce Locality Preserving Projections (LPP). These are linear projective maps that arise by solving a variational problem that optimally preserves the neighborhood structure of the data set. LPP should be seen as an alternative to Principal Component Analysis (PCA) – a classical linear technique that projects the data along the directions of maximal variance. When the high dimensional data lies on a low dimensional manifold embedded in the ambient space, the Locality Preserving Projections are obtained by finding the optimal linear approximations to the eigenfunctions of the Laplace Beltrami operator on the manifold. As a result, LPP shares many of the data representation properties of nonlinear techniques such as Laplacian Eigenmaps or Locally Linear Embedding. Yet LPP is linear and more crucially is defined everywhere in ambient space rather than just on the training data points. This is borne out by illustrative examples on some high dimensional data sets.\nKnowledge Graph Embedding Based Question Answering (Xiao Huang et al., 2019) Xiao Huang, Jingyuan Zhang, Dingcheng Li, Ping Li. (2019)\nKnowledge Graph Embedding Based Question Answering\nWSDM\nPaper Link\nInfluential Citation Count (12), SS-ID (7572aefcd241ec76341addcb2e2e417587cb2e4c)\nABSTRACT\nQuestion answering over knowledge graph (QA-KG) aims to use facts in the knowledge graph (KG) to answer natural language questions. It helps end users more efficiently and more easily access the substantial and valuable knowledge in the KG, without knowing its data structures. QA-KG is a nontrivial problem since capturing the semantic meaning of natural language is difficult for a machine. Meanwhile, many knowledge graph embedding methods have been proposed. The key idea is to represent each predicate/entity as a low-dimensional vector, such that the relation information in the KG could be preserved. The learned vectors could benefit various applications such as KG completion and recommender systems. In this paper, we explore to use them to handle the QA-KG problem. However, this remains a challenging task since a predicate could be expressed in different ways in natural language questions. Also, the ambiguity of entity names and partial names makes the number of possible answers large. To bridge the gap, we propose an effective Knowledge Embedding based Question Answering (KEQA) framework. We focus on answering the most common types of questions, i.e., simple questions, in which each question could be answered by the machine straightforwardly if its single head entity and single predicate are correctly identified. To answer a simple question, instead of inferring its head entity and predicate directly, KEQA targets at jointly recovering the question\u0026rsquo;s head entity, predicate, and tail entity representations in the KG embedding spaces. Based on a carefully-designed joint distance metric, the three learned vectors\u0026rsquo; closest fact in the KG is returned as the answer. Experiments on a widely-adopted benchmark demonstrate that the proposed KEQA outperforms the state-of-the-art QA-KG methods.\nFlexible and robust co-regularized multi-domain graph clustering (Wei Cheng et al., 2013) Wei Cheng, X. Zhang, Zhishan Guo, Yubao Wu, P. Sullivan, Wei Wang. (2013)\nFlexible and robust co-regularized multi-domain graph clustering\nKDD\nPaper Link\nInfluential Citation Count (8), SS-ID (75938c4300e464f901a15332540d6500d957db91)\nABSTRACT\nMulti-view graph clustering aims to enhance clustering performance by integrating heterogeneous information collected in different domains. Each domain provides a different view of the data instances. Leveraging cross-domain information has been demonstrated an effective way to achieve better clustering results. Despite the previous success, existing multi-view graph clustering methods usually assume that different views are available for the same set of instances. Thus instances in different domains can be treated as having strict one-to-one relationship. In many real-life applications, however, data instances in one domain may correspond to multiple instances in another domain. Moreover, relationships between instances in different domains may be associated with weights based on prior (partial) knowledge. In this paper, we propose a flexible and robust framework, CGC (Co-regularized Graph Clustering), based on non-negative matrix factorization (NMF), to tackle these challenges. CGC has several advantages over the existing methods. First, it supports many-to-many cross-domain instance relationship. Second, it incorporates weight on cross-domain relationship. Third, it allows partial cross-domain mapping so that graphs in different domains may have different sizes. Finally, it provides users with the extent to which the cross-domain instance relationship violates the in-domain clustering structure, and thus enables users to re-evaluate the consistency of the relationship. Extensive experimental results on UCI benchmark data sets, newsgroup data sets and biological interaction networks demonstrate the effectiveness of our approach.\nNeural Embeddings of Graphs in Hyperbolic Space (B. Chamberlain et al., 2017) B. Chamberlain, J. Clough, M. Deisenroth. (2017)\nNeural Embeddings of Graphs in Hyperbolic Space\nArXiv\nPaper Link\nInfluential Citation Count (9), SS-ID (76ce8d30c6f72aa56ae02cd42a064e41b9ab9391)\nABSTRACT\nNeural embeddings have been used with great success in Natural Language Processing (NLP). They provide compact representations that encapsulate word similarity and attain state-of-the-art performance in a range of linguistic tasks. The success of neural embeddings has prompted significant amounts of research into applications in domains other than language. One such domain is graph-structured data, where embeddings of vertices can be learned that encapsulate vertex similarity and improve performance on tasks including edge prediction and vertex labelling. For both NLP and graph based tasks, embeddings have been learned in high-dimensional Euclidean spaces. However, recent work has shown that the appropriate isometric space for embedding complex networks is not the flat Euclidean space, but negatively curved, hyperbolic space. We present a new concept that exploits these recent insights and propose learning neural embeddings of graphs in hyperbolic space. We provide experimental evidence that embedding graphs in their natural geometry significantly improves performance on downstream tasks for several real-world public datasets.\nNeural networks for link prediction in realistic biomedical graphs: a multi-dimensional evaluation of graph embedding-based approaches (Gamal K. O. Crichton et al., 2018) Gamal K. O. Crichton, Yufan Guo, Sampo Pyysalo, A. Korhonen. (2018)\nNeural networks for link prediction in realistic biomedical graphs: a multi-dimensional evaluation of graph embedding-based approaches\nBMC Bioinformatics\nPaper Link\nInfluential Citation Count (1), SS-ID (7b64c1527ed63b57c0c9fde327bba1529775c5d3)\nABSTRACT\nBackgroundLink prediction in biomedical graphs has several important applications including predicting Drug-Target Interactions (DTI), Protein-Protein Interaction (PPI) prediction and Literature-Based Discovery (LBD). It can be done using a classifier to output the probability of link formation between nodes. Recently several works have used neural networks to create node representations which allow rich inputs to neural classifiers. Preliminary works were done on this and report promising results. However they did not use realistic settings like time-slicing, evaluate performances with comprehensive metrics or explain when or why neural network methods outperform. We investigated how inputs from four node representation algorithms affect performance of a neural link predictor on random- and time-sliced biomedical graphs of real-world sizes (∼ 6 million edges) containing information relevant to DTI, PPI and LBD. We compared the performance of the neural link predictor to those of established baselines and report performance across five metrics.ResultsIn random- and time-sliced experiments when the neural network methods were able to learn good node representations and there was a negligible amount of disconnected nodes, those approaches outperformed the baselines. In the smallest graph (∼ 15,000 edges) and in larger graphs with approximately 14% disconnected nodes, baselines such as Common Neighbours proved a justifiable choice for link prediction. At low recall levels (∼ 0.3) the approaches were mostly equal, but at higher recall levels across all nodes and average performance at individual nodes, neural network approaches were superior. Analysis showed that neural network methods performed well on links between nodes with no previous common neighbours; potentially the most interesting links. Additionally, while neural network methods benefit from large amounts of data, they require considerable amounts of computational resources to utilise them.ConclusionsOur results indicate that when there is enough data for the neural network methods to use and there are a negligible amount of disconnected nodes, those approaches outperform the baselines. At low recall levels the approaches are mostly equal but at higher recall levels and average performance at individual nodes, neural network approaches are superior. Performance at nodes without common neighbours which indicate more unexpected and perhaps more useful links account for this.\nSocial Attentional Memory Network: Modeling Aspect- and Friend-Level Differences in Recommendation (Chong Chen et al., 2019) Chong Chen, Min Zhang, Yiqun Liu, Shaoping Ma. (2019)\nSocial Attentional Memory Network: Modeling Aspect- and Friend-Level Differences in Recommendation\nWSDM\nPaper Link\nInfluential Citation Count (12), SS-ID (7c0afa4c7196474ff3b8c360bd6d4888f2417eed)\nABSTRACT\nSocial connections are known to be helpful for modeling users\u0026rsquo; potential preferences and improving the performance of recommender systems. However, in social-aware recommendations, there are two issues which influence the inference of users\u0026rsquo; preferences, and haven\u0026rsquo;t been well-studied in most existing methods: First, the preferences of a user may only partially match that of his friends in certain aspects, especially when considering a user with diverse interests. Second, for an individual, the influence strength of his friends might be different, as not all friends are equally helpful for modeling his preferences in the system. To address the above issues, in this paper, we propose a novel Social Attentional Memory Network (SAMN) for social-aware recommendation. Specifically, we first design an attention-based memory module to learn user-friend relation vectors, which can capture the varying aspect attentions that a user share with his different friends. Then we build a friend-level attention component to adaptively select informative friends for user modeling. The two components are fused together to mutually enhance each other and lead to a finer extended model. Experimental results on three publicly available datasets show that the proposed SAMN model consistently and significantly outperforms the state-of-the-art recommendation methods. Furthermore, qualitative studies have been made to explore what the proposed attention-based memory module and friend-level attention have learnt, which provide insights into the model\u0026rsquo;s learning process.\nMulti-Layered Network Embedding (Jundong Li et al., 2018) Jundong Li, C. Chen, Hanghang Tong, Huan Liu. (2018)\nMulti-Layered Network Embedding\nSDM\nPaper Link\nInfluential Citation Count (5), SS-ID (7c28b81dff1899e5a148ff57888faacc9945ab22)\nABSTRACT\nNetwork embedding has gained more attentions in recent years. It has been shown that the learned lowdimensional node vector representations could advance a myriad of graph mining tasks such as node classification, community detection, and link prediction. A vast majority of the existing efforts are overwhelmingly devoted to single-layered networks or homogeneous networks with a single type of nodes and node interactions. However, in many real-world applications, a variety of networks could be abstracted and presented in a multilayered fashion. Typical multi-layered networks include critical infrastructure systems, collaboration platforms, social recommender systems, to name a few. Despite the widespread use of multi-layered networks, it remains a daunting task to learn vector representations of different types of nodes due to the bewildering combination of both within-layer connections and cross-layer network dependencies. In this paper, we study a novel problem of multi-layered network embedding. In particular, we propose a principled framework MANE to model both within-layer connections and cross-layer network dependencies simultaneously in a unified optimization framework for embedding representation learning. Experiments on real-world multi-layered networks corroborate the effectiveness of the proposed framework.\nLearning Convolutional Neural Networks for Graphs (Mathias Niepert et al., 2016) Mathias Niepert, Mohamed Ahmed, Konstantin Kutzkov. (2016)\nLearning Convolutional Neural Networks for Graphs\nICML\nPaper Link\nInfluential Citation Count (136), SS-ID (7c6de5a9e02a779e24504619050c6118f4eac181)\nABSTRACT\nNumerous important problems can be framed as learning from graph data. We propose a framework for learning convolutional neural networks for arbitrary graphs. These graphs may be undirected, directed, and with both discrete and continuous node and edge attributes. Analogous to image-based convolutional networks that operate on locally connected regions of the input, we present a general approach to extracting locally connected regions from graphs. Using established benchmark data sets, we demonstrate that the learned feature representations are competitive with state of the art graph kernels and that their computation is highly efficient.\nRobust Multi-Network Clustering via Joint Cross-Domain Cluster Alignment (R. Liu et al., 2015) R. Liu, Wei Cheng, Hanghang Tong, Wei Wang, X. Zhang. (2015)\nRobust Multi-Network Clustering via Joint Cross-Domain Cluster Alignment\n2015 IEEE International Conference on Data Mining\nPaper Link\nInfluential Citation Count (1), SS-ID (7dd2ad1f992808d04356e8d6e7e5614166f34a85)\nABSTRACT\nNetwork clustering is an important problem thathas recently drawn a lot of attentions. Most existing workfocuses on clustering nodes within a single network. In manyapplications, however, there exist multiple related networks, inwhich each network may be constructed from a different domainand instances in one domain may be related to instances in otherdomains. In this paper, we propose a robust algorithm, MCA, formulti-network clustering that takes into account cross-domain relationshipsbetween instances. MCA has several advantages overthe existing single network clustering methods. First, it is ableto detect associations between clusters from different domains, which, however, is not addressed by any existing methods. Second, it achieves more consistent clustering results on multiple networksby leveraging the duality between clustering individual networksand inferring cross-network cluster alignment. Finally, it providesa multi-network clustering solution that is more robust to noiseand errors. We perform extensive experiments on a variety ofreal and synthetic networks to demonstrate the effectiveness andefficiency of MCA.\nGraphAE: Adaptive Embedding across Graphs (Bencheng Yan et al., 2020) Bencheng Yan, Chaokun Wang. (2020)\nGraphAE: Adaptive Embedding across Graphs\n2020 IEEE 36th International Conference on Data Engineering (ICDE)\nPaper Link\nInfluential Citation Count (0), SS-ID (7ddb8bdbab7f5aa644569c71d09d0a669af3615e)\nABSTRACT\nRecently, learning embedding of nodes in graphs has attracted increasing research attention. There are two main kinds of graph embedding methods, i.e., the transductive embedding methods and the inductive embedding methods. The former focuses on directly optimizing the embedding vectors, and the latter tries to learn a mapping function for the given nodes and features. However, few works focus on applying the learned model from one graph to another, which is a pervasive idea in Computer Version or Natural Language Processing. Although some of the graph neural networks (GNNs) present similar motivation, none of them considers the graph bias among graphs. In this paper, we present an interesting graph embedding problem called Adaptive Task (AT), and propose a unified framework for this adaptive task, which introduces two types of alignment to learn adaptive node embedding across graphs. Then, based on the proposed framework, a novel graph adaptive embedding network is designed to address the adaptive task. Extensive experimental results demonstrate that our model significantly outperforms the state-of-the-art methods.\nWeisfeiler-Lehman Graph Kernels (N. Shervashidze et al., 2011) N. Shervashidze, Pascal Schweitzer, E. J. V. Leeuwen, K. Mehlhorn, K. Borgwardt. (2011)\nWeisfeiler-Lehman Graph Kernels\nJ. Mach. Learn. Res.\nPaper Link\nInfluential Citation Count (183), SS-ID (7e1874986cf6433fabf96fff93ef42b60bdc49f8)\nABSTRACT\nIn this article, we propose a family of efficient kernels for large graphs with discrete node labels. Key to our method is a rapid feature extraction scheme based on the Weisfeiler-Lehman test of isomorphism on graphs. It maps the original graph to a sequence of graphs, whose node attributes capture topological and label information. A family of kernels can be defined based on this Weisfeiler-Lehman sequence of graphs, including a highly efficient kernel comparing subtree-like patterns. Its runtime scales only linearly in the number of edges of the graphs and the length of the Weisfeiler-Lehman graph sequence. In our experimental evaluation, our kernels outperform state-of-the-art graph kernels on several graph classification benchmark data sets in terms of accuracy and runtime. Our kernels open the door to large-scale applications of graph kernels in various disciplines such as computational biology and social network analysis.\nOn the Embeddability of Random Walk Distances (Xiaohan Zhao et al., 2013) Xiaohan Zhao, Adelbert Chang, Atish Das Sarma, Haitao Zheng, Ben Y. Zhao. (2013)\nOn the Embeddability of Random Walk Distances\nProc. VLDB Endow.\nPaper Link\nInfluential Citation Count (2), SS-ID (7f2f0d84da4194f048827c9aafd24e2efab8f09f)\nABSTRACT\nAnalysis of large graphs is critical to the ongoing growth of search engines and social networks. One class of queries centers around node affinity, often quantified by random-walk distances between node pairs, including hitting time, commute time, and personalized PageRank (PPR). Despite the potential of these \u0026ldquo;metrics,\u0026rdquo; they are rarely, if ever, used in practice, largely due to extremely high computational costs. In this paper, we investigate methods to scalably and efficiently compute random-walk distances, by \u0026ldquo;embedding\u0026rdquo; graphs and distances into points and distances in geometric coordinate spaces. We show that while existing graph coordinate systems (GCS) can accurately estimate shortest path distances, they produce significant errors when embedding random-walk distances. Based on our observations, we propose a new graph embedding system that explicitly accounts for per-node graph properties that affect random walk. Extensive experiments on a range of graphs show that our new approach can accurately estimate both symmetric and asymmetric random-walk distances. Once a graph is embedded, our system can answer queries between any two nodes in 8 microseconds, orders of magnitude faster than existing methods. Finally, we show that our system produces estimates that can replace ground truth in applications with minimal impact on application output.\nAdversarial Attack on Graph Structured Data (H. Dai et al., 2018) H. Dai, Hui Li, Tian Tian, Xin Huang, L. Wang, Jun Zhu, Le Song. (2018)\nAdversarial Attack on Graph Structured Data\nICML\nPaper Link\nInfluential Citation Count (75), SS-ID (7f77058976e2fe75e98280371962c43d98c98321)\nABSTRACT\nDeep learning on graph structures has shown exciting results in various applications. However, few attentions have been paid to the robustness of such models, in contrast to numerous research work for image or text adversarial attack and defense. In this paper, we focus on the adversarial attacks that fool the model by modifying the combinatorial structure of data. We first propose a reinforcement learning based attack method that learns the generalizable attack policy, while only requiring prediction labels from the target classifier. Also, variants of genetic algorithms and gradient methods are presented in the scenario where prediction confidence or gradients are available. We use both synthetic and real-world data to show that, a family of Graph Neural Network models are vulnerable to these attacks, in both graph-level and node-level classification tasks. We also show such attacks can be used to diagnose the learned classifiers.\nActional-Structural Graph Convolutional Networks for Skeleton-Based Action Recognition (Maosen Li et al., 2019) Maosen Li, Siheng Chen, Xu Chen, Ya Zhang, Yanfeng Wang, Qi Tian. (2019)\nActional-Structural Graph Convolutional Networks for Skeleton-Based Action Recognition\n2019 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)\nPaper Link\nInfluential Citation Count (40), SS-ID (814b70cd133f97ef039bcc44124d9344dd8b3f64)\nABSTRACT\nAction recognition with skeleton data has recently attracted much attention in computer vision. Previous studies are mostly based on fixed skeleton graphs, only capturing local physical dependencies among joints, which may miss implicit joint correlations. To capture richer dependencies, we introduce an encoder-decoder structure, called A-link inference module, to capture action-specific latent dependencies, i.e. actional links, directly from actions. We also extend the existing skeleton graphs to represent higher-order dependencies, i.e. structural links. Combing the two types of links into a generalized skeleton graph, We further propose the actional-structural graph convolution network (AS-GCN), which stacks actional-structural graph convolution and temporal convolution as a basic building block, to learn both spatial and temporal features for action recognition. A future pose prediction head is added in parallel to the recognition head to help capture more detailed action patterns through self-supervision. We validate AS-GCN in action recognition using two skeleton data sets, NTU-RGB+D and Kinetics. The proposed AS-GCN achieves consistently large improvement compared to the state-of-the-art methods. As a side product, AS-GCN also shows promising results for future pose prediction.\nA Comprehensive Survey on Graph Neural Networks (Zonghan Wu et al., 2019) Zonghan Wu, Shirui Pan, Fengwen Chen, Guodong Long, Chengqi Zhang, Philip S. Yu. (2019)\nA Comprehensive Survey on Graph Neural Networks\nIEEE Transactions on Neural Networks and Learning Systems\nPaper Link\nInfluential Citation Count (197), SS-ID (81a4fd3004df0eb05d6c1cef96ad33d5407820df)\nABSTRACT\nDeep learning has revolutionized many machine learning tasks in recent years, ranging from image classification and video processing to speech recognition and natural language understanding. The data in these tasks are typically represented in the Euclidean space. However, there is an increasing number of applications, where data are generated from non-Euclidean domains and are represented as graphs with complex relationships and interdependency between objects. The complexity of graph data has imposed significant challenges on the existing machine learning algorithms. Recently, many studies on extending deep learning approaches for graph data have emerged. In this article, we provide a comprehensive overview of graph neural networks (GNNs) in data mining and machine learning fields. We propose a new taxonomy to divide the state-of-the-art GNNs into four categories, namely, recurrent GNNs, convolutional GNNs, graph autoencoders, and spatial–temporal GNNs. We further discuss the applications of GNNs across various domains and summarize the open-source codes, benchmark data sets, and model evaluation of GNNs. Finally, we propose potential research directions in this rapidly growing field.\nDeep Reinforcement Learning with Graph-based State Representations (Vikram Waradpande et al., 2020) Vikram Waradpande, D. Kudenko, Megha Khosla. (2020)\nDeep Reinforcement Learning with Graph-based State Representations\nArXiv\nPaper Link\nInfluential Citation Count (0), SS-ID (82b794ae070245a7264a13c0a2006685670bc551)\nABSTRACT\nDeep RL approaches build much of their success on the ability of the deep neural network to generate useful internal representations. Nevertheless, they suffer from a high sample-complexity and starting with a good input representation can have a significant impact on the performance. In this paper, we exploit the fact that the underlying Markov decision process (MDP) represents a graph, which enables us to incorporate the topological information for effective state representation learning. Motivated by the recent success of node representations for several graph analytical tasks we specifically investigate the capability of node representation learning methods to effectively encode the topology of the underlying MDP in Deep RL. To this end we perform a comparative analysis of several models chosen from 4 different classes of representation learning algorithms for policy learning in grid-world navigation tasks, which are representative of a large class of RL problems. We find that all embedding methods outperform the commonly used matrix representation of grid-world environments in all of the studied cases. Moreoever, graph convolution based methods are outperformed by simpler random walk based methods and graph linear autoencoders.\nHEAM: Heterogeneous Network Embedding with Automatic Meta-path Construction (Ruicong Shi et al., 2020) Ruicong Shi, Tao Liang, Huailiang Peng, Lei Jiang, Qiong Dai. (2020)\nHEAM: Heterogeneous Network Embedding with Automatic Meta-path Construction\nKSEM\nPaper Link\nInfluential Citation Count (0), SS-ID (82eb1da1515172ab7d814320d9666b14b17e2467)\nABSTRACT\nHeterogeneous information network (HIN) embedding is widely used in many real-world applications. Meta-path used in HINs can effectively extract semantic information among objects. However, the meta-path faces challenges on the construction and selection. Most of the current works construct dataset-specific meta-paths manually, which rely on the prior knowledge from domain experts. In addition, existing approaches select a few explicit meta-paths, which lack of much subtle semantic information among objects. To tackle the problems, we propose a model with automatic meta-path construction. We develop a hierarchical aggregation to learn effective heterogeneous embeddings with meta-path based proximity. We employ a multi-layer network framework to mine long meta-paths based information implicitly. To demonstrate the effectiveness of our model, we apply it to two real-world datasets and show the performance improvements over state-of-the-art methods.\nThe maximum clique problem (P. Pardalos et al., 1994) P. Pardalos, J. Xue. (1994)\nThe maximum clique problem\nJ. Glob. Optim.\nPaper Link\nInfluential Citation Count (38), SS-ID (8306882ebcb8066cfbfe984bfe804c3f78d40559)\nABSTRACT\nIn this paper we present a survey of results concerning algorithms, complexity, and applications of the maximum clique problem. We discuss enumerative and exact algorithms, heuristics, and a variety of other proposed methods. An up to date bibliography on the maximum clique and related problems is also provided.\nNetwork embedding-based representation learning for single cell RNA-seq data (Xiangyu Li et al., 2017) Xiangyu Li, Weizheng Chen, Yang Chen, Xuegong Zhang, Jin Gu, Michael Q. Zhang. (2017)\nNetwork embedding-based representation learning for single cell RNA-seq data\nNucleic acids research\nPaper Link\nInfluential Citation Count (2), SS-ID (83416dea7fd1d3b91ec854d8c4b634926fea77e1)\nABSTRACT\nAbstract Single cell RNA-seq (scRNA-seq) techniques can reveal valuable insights of cell-to-cell heterogeneities. Projection of high-dimensional data into a low-dimensional subspace is a powerful strategy in general for mining such big data. However, scRNA-seq suffers from higher noise and lower coverage than traditional bulk RNA-seq, hence bringing in new computational difficulties. One major challenge is how to deal with the frequent drop-out events. The events, usually caused by the stochastic burst effect in gene transcription and the technical failure of RNA transcript capture, often render traditional dimension reduction methods work inefficiently. To overcome this problem, we have developed a novel Single Cell Representation Learning (SCRL) method based on network embedding. This method can efficiently implement data-driven non-linear projection and incorporate prior biological knowledge (such as pathway information) to learn more meaningful low-dimensional representations for both cells and genes. Benchmark results show that SCRL outperforms other dimensional reduction methods on several recent scRNA-seq datasets.\nSimple and Effective Graph Autoencoders with One-Hop Linear Models (Guillaume Salha-Galvan et al., 2020) Guillaume Salha-Galvan, Romain Hennequin, M. Vazirgiannis. (2020)\nSimple and Effective Graph Autoencoders with One-Hop Linear Models\nECML/PKDD\nPaper Link\nInfluential Citation Count (2), SS-ID (8380ce56e614d047cf2c5c6106dcfc00beed5b6f)\nABSTRACT\nOver the last few years, graph autoencoders (AE) and variational autoencoders (VAE) emerged as powerful node embedding methods, with promising performances on challenging tasks such as link prediction and node clustering. Graph AE, VAE and most of their extensions rely on multi-layer graph convolutional networks (GCN) encoders to learn vector space representations of nodes. In this paper, we show that GCN encoders are actually unnecessarily complex for many applications. We propose to replace them by significantly simpler and more interpretable linear models w.r.t. the direct neighborhood (one-hop) adjacency matrix of the graph, involving fewer operations, fewer parameters and no activation function. For the two aforementioned tasks, we show that this simpler approach consistently reaches competitive performances w.r.t. GCN-based graph AE and VAE for numerous real-world graphs, including all benchmark datasets commonly used to evaluate graph AE and VAE. Based on these results, we also question the relevance of repeatedly using these datasets to compare complex graph AE and VAE.\nEmbedding Entities and Relations for Learning and Inference in Knowledge Bases (Bishan Yang et al., 2014) Bishan Yang, Wen-tau Yih, Xiaodong He, Jianfeng Gao, L. Deng. (2014)\nEmbedding Entities and Relations for Learning and Inference in Knowledge Bases\nICLR\nPaper Link\nInfluential Citation Count (417), SS-ID (86412306b777ee35aba71d4795b02915cb8a04c3)\nABSTRACT\nAbstract: We consider learning representations of entities and relations in KBs using the neural-embedding approach. We show that most existing models, including NTN (Socher et al., 2013) and TransE (Bordes et al., 2013b), can be generalized under a unified learning framework, where entities are low-dimensional vectors learned from a neural network and relations are bilinear and/or linear mapping functions. Under this framework, we compare a variety of embedding models on the link prediction task. We show that a simple bilinear formulation achieves new state-of-the-art results for the task (achieving a top-10 accuracy of 73.2% vs. 54.7% by TransE on Freebase). Furthermore, we introduce a novel approach that utilizes the learned relation embeddings to mine logical rules such as \u0026ldquo;BornInCity(a,b) and CityInCountry(b,c) =\u0026gt; Nationality(a,c)\u0026rdquo;. We find that embeddings learned from the bilinear objective are particularly good at capturing relational semantics and that the composition of relations is characterized by matrix multiplication. More interestingly, we demonstrate that our embedding-based rule extraction approach successfully outperforms a state-of-the-art confidence-based rule mining approach in mining Horn rules that involve compositional reasoning.\nClustering and Community Detection in Directed Networks: A Survey (Fragkiskos D. Malliaros et al., 2013) Fragkiskos D. Malliaros, M. Vazirgiannis. (2013)\nClustering and Community Detection in Directed Networks: A Survey\nArXiv\nPaper Link\nInfluential Citation Count (23), SS-ID (86be7f7c5888013068ccac9095ed7da6282216b7)\nABSTRACT\nDistributed Representations of Words and Phrases and their Compositionality (Tomas Mikolov et al., 2013) Tomas Mikolov, Ilya Sutskever, Kai Chen, G. Corrado, J. Dean. (2013)\nDistributed Representations of Words and Phrases and their Compositionality\nNIPS\nPaper Link\nInfluential Citation Count (3587), SS-ID (87f40e6f3022adbc1f1905e3e506abad05a9964f)\nABSTRACT\nThe recently introduced continuous Skip-gram model is an efficient method for learning high-quality distributed vector representations that capture a large number of precise syntactic and semantic word relationships. In this paper we present several extensions that improve both the quality of the vectors and the training speed. By subsampling of the frequent words we obtain significant speedup and also learn more regular word representations. We also describe a simple alternative to the hierarchical softmax called negative sampling. An inherent limitation of word representations is their indifference to word order and their inability to represent idiomatic phrases. For example, the meanings of \u0026ldquo;Canada\u0026rdquo; and \u0026ldquo;Air\u0026rdquo; cannot be easily combined to obtain \u0026ldquo;Air Canada\u0026rdquo;. Motivated by this example, we present a simple method for finding phrases in text, and show that learning good vector representations for millions of phrases is possible.\nFrom Node Embedding To Community Embedding (V. Zheng et al., 2016) V. Zheng, Sandro Cavallari, Hongyun Cai, K. Chang, E. Cambria. (2016)\nFrom Node Embedding To Community Embedding\nArXiv\nPaper Link\nInfluential Citation Count (0), SS-ID (88dabd8d295ba9f727baccd73c214e094c6d134f)\nABSTRACT\nMost of the existing graph embedding methods focus on nodes, which aim to output a vector representation for each node in the graph such that two nodes being \u0026ldquo;close\u0026rdquo; on the graph are close too in the low-dimensional space. Despite the success of embedding individual nodes for graph analytics, we notice that an important concept of embedding communities (i.e., groups of nodes) is missing. Embedding communities is useful, not only for supporting various community-level applications, but also to help preserve community structure in graph embedding. In fact, we see community embedding as providing a higher-order proximity to define the node closeness, whereas most of the popular graph embedding methods focus on first-order and/or second-order proximities. To learn the community embedding, we hinge upon the insight that community embedding and node embedding reinforce with each other. As a result, we propose ComEmbed, the first community embedding method, which jointly optimizes the community embedding and node embedding together. We evaluate ComEmbed on real-world data sets. We show it outperforms the state-of-the-art baselines in both tasks of node classification and community prediction.\nDual network embedding for representing research interests in the link prediction problem on co-authorship networks (Ilya Makarov et al., 2019) Ilya Makarov, Olga Gerasimova, Pavel Sulimov, L. Zhukov. (2019)\nDual network embedding for representing research interests in the link prediction problem on co-authorship networks\nPeerJ Comput. Sci.\nPaper Link\nInfluential Citation Count (0), SS-ID (894e35751609e1cd88265b055348ced09c8c9acd)\nABSTRACT\nWe present a study on co-authorship network representation based on network embedding together with additional information on topic modeling of research papers and new edge embedding operator. We use the link prediction (LP) model for constructing a recommender system for searching collaborators with similar research interests. Extracting topics for each paper, we construct keywords co-occurrence network and use its embedding for further generalizing author attributes. Standard graph feature engineering and network embedding methods were combined for constructing co-author recommender system formulated as LP problem and prediction of future graph structure. We evaluate our survey on the dataset containing temporal information on National Research University Higher School of Economics over 25 years of research articles indexed in Russian Science Citation Index and Scopus. Our model of network representation shows better performance for stated binary classification tasks on several co-authorship networks.\nUnsupervised Large Graph Embedding Based on Balanced and Hierarchical K-Means (F. Nie et al., 2020) F. Nie, Wei Zhu, Xuelong Li. (2020)\nUnsupervised Large Graph Embedding Based on Balanced and Hierarchical K-Means\nIEEE Transactions on Knowledge and Data Engineering\nPaper Link\nInfluential Citation Count (0), SS-ID (894e66e457482d8b658dfc1d1f4d6f532357b400)\nABSTRACT\nThere are many successful spectral based unsupervised dimensionality reduction methods, including Laplacian Eigenmap (LE), Locality Preserving Projection (LPP), Spectral Regression (SR), etc. We find that LPP and SR are equivalent if the symmetric similarity matrix is doubly stochastic, Positive Semi-Definite (PSD) and with rank $p$mml:mathmml:mip\u0026lt;/mml:mi\u0026gt;\u0026lt;/mml:math\u0026gt;, where $p$mml:mathmml:mip\u0026lt;/mml:mi\u0026gt;\u0026lt;/mml:math\u0026gt; is the reduced dimension. Since solving SR is believed faster than solving LPP based on some related literature, the discovery promotes us to seek to construct such specific similarity matrix to speed up LPP solving procedures. We then propose an unsupervised linear method called Unsupervised Large Graph Embedding (ULGE). ULGE starts with a similar idea as LPP but adopts an efficient approach to construct anchor-based similarity matrix and then performs spectral analysis on it. Moreover, since conventional anchor generation strategies suffer kinds of problems, we propose an efficient and effective anchor generation strategy, called Balanced $K$mml:mathmml:miK\u0026lt;/mml:mi\u0026gt;\u0026lt;/mml:math\u0026gt;-means based Hierarchical $K$mml:mathmml:miK\u0026lt;/mml:mi\u0026gt;\u0026lt;/mml:math\u0026gt;-means (BHKH). The computational complexity of ULGE can reduce to $O(ndm)$mml:mathmml:mrowmml:miO\u0026lt;/mml:mi\u0026gt;mml:mo(\u0026lt;/mml:mo\u0026gt;mml:min\u0026lt;/mml:mi\u0026gt;mml:mid\u0026lt;/mml:mi\u0026gt;mml:mim\u0026lt;/mml:mi\u0026gt;mml:mo)\u0026lt;/mml:mo\u0026gt;\u0026lt;/mml:mrow\u0026gt;\u0026lt;/mml:math\u0026gt;, which is a significant improvement compared to conventional methods need $O(n^2d)$mml:mathmml:mrowmml:miO\u0026lt;/mml:mi\u0026gt;mml:mo(\u0026lt;/mml:mo\u0026gt;mml:msupmml:min\u0026lt;/mml:mi\u0026gt;mml:mn2\u0026lt;/mml:mn\u0026gt;\u0026lt;/mml:msup\u0026gt;mml:mid\u0026lt;/mml:mi\u0026gt;mml:mo)\u0026lt;/mml:mo\u0026gt;\u0026lt;/mml:mrow\u0026gt;\u0026lt;/mml:math\u0026gt; at least, where $n$mml:mathmml:min\u0026lt;/mml:mi\u0026gt;\u0026lt;/mml:math\u0026gt;, $d$mml:mathmml:mid\u0026lt;/mml:mi\u0026gt;\u0026lt;/mml:math\u0026gt; and $m$mml:mathmml:mim\u0026lt;/mml:mi\u0026gt;\u0026lt;/mml:math\u0026gt; are the number of samples, dimensions, and anchors, respectively. Extensive experiments on several publicly available datasets demonstrate the efficiency and effectiveness of the proposed method.\nGraph HyperNetworks for Neural Architecture Search (Chris Zhang et al., 2018) Chris Zhang, Mengye Ren, R. Urtasun. (2018)\nGraph HyperNetworks for Neural Architecture Search\nICLR\nPaper Link\nInfluential Citation Count (17), SS-ID (89c10e08902cb90abbe1276a3042b93c2f9c78b4)\nABSTRACT\nNeural architecture search (NAS) automatically finds the best task-specific neural network topology, outperforming many manual architecture designs. However, it can be prohibitively expensive as the search requires training thousands of different networks, while each can last for hours. In this work, we propose the Graph HyperNetwork (GHN) to amortize the search cost: given an architecture, it directly generates the weights by running inference on a graph neural network. GHNs model the topology of an architecture and therefore can predict network performance more accurately than regular hypernetworks and premature early stopping. To perform NAS, we randomly sample architectures and use the validation accuracy of networks with GHN generated weights as the surrogate search signal. GHNs are fast \u0026ndash; they can search nearly 10 times faster than other random search methods on CIFAR-10 and ImageNet. GHNs can be further extended to the anytime prediction setting, where they have found networks with better speed-accuracy tradeoff than the state-of-the-art manual designs.\nTemporal link prediction by integrating content and structure information (Sheng Gao et al., 2011) Sheng Gao, Ludovic Denoyer, P. Gallinari. (2011)\nTemporal link prediction by integrating content and structure information\nCIKM \u0026lsquo;11\nPaper Link\nInfluential Citation Count (4), SS-ID (8a634a82681897822b14de28849c6548346206a0)\nABSTRACT\nIn this paper we address the problem of temporal link prediction, i.e., predicting the apparition of new links, in time-evolving networks. This problem appears in applications such as recommender systems, social network analysis or citation analysis. Link prediction in time-evolving networks is usually based on the topological structure of the network only. We propose here a model which exploits multiple information sources in the network in order to predict link occurrence probabilities as a function of time. The model integrates three types of information: the global network structure, the content of nodes in the network if any, and the local or proximity information of a given vertex. The proposed model is based on a matrix factorization formulation of the problem with graph regularization. We derive an efficient optimization method to learn the latent factors of this model. Extensive experiments on several real world datasets suggest that our unified framework outperforms state-of-the-art methods for temporal link prediction tasks.\nSingular value decomposition and least squares solutions (G. Golub et al., 1970) G. Golub, C. Reinsch. (1970)\nSingular value decomposition and least squares solutions\nMilestones in Matrix Computation\nPaper Link\nInfluential Citation Count (202), SS-ID (8ae0cbae42a5fb9b340adaed9ed39569eb96b42d)\nABSTRACT\nLet A be a real m×n matrix with m≧n. It is well known (cf. [4]) that $$A = U\\sum {V^T}$$ (1) where $${U^T}U = {V^T}V = V{V^T} = {I_n}{\\text{ and }}\\sum {\\text{ = diag(}}{\\sigma _{\\text{1}}}{\\text{,}} \\ldots {\\text{,}}{\\sigma _n}{\\text{)}}{\\text{.}}$$ The matrix U consists of n orthonormalized eigenvectors associated with the n largest eigenvalues of AA T , and the matrix V consists of the orthonormalized eigenvectors of A T A. The diagonal elements of ∑ are the non-negative square roots of the eigenvalues of A T A; they are called singular values. We shall assume that $${\\sigma _1} \\geqq {\\sigma _2} \\geqq \\cdots \\geqq {\\sigma _n} \\geqq 0.$$ Thus if rank(A)=r, σ r+1 = σ r+2=⋯=σ n = 0. The decomposition (1) is called the singular value decomposition (SVD).\nTri-Party Deep Network Representation (Shirui Pan et al., 2016) Shirui Pan, Jia Wu, Xingquan Zhu, Chengqi Zhang, Yang Wang. (2016)\nTri-Party Deep Network Representation\nIJCAI\nPaper Link\nInfluential Citation Count (32), SS-ID (8ba7631515d5e7e0c451af1c4772507f41540a5e)\nABSTRACT\nInformation network mining often requires examination of linkage relationships between nodes for analysis. Recently, network representation has emerged to represent each node in a vector format, embedding network structure, so off-the-shelf machine learning methods can be directly applied for analysis. To date, existing methods only focus on one aspect of node information and cannot leverage node labels. In this paper, we propose TriDNR, a tri-party deep network representation model, using information from three parties: node structure, node content, and node labels (if available) to jointly learn optimal node representation. TriDNR is based on our new coupled deep natural language module, whose learning is enforced at three levels: (1) at the network structure level, TriDNR exploits inter-node relationship by maximizing the probability of observing surrounding nodes given a node in random walks; (2) at the node content level, TriDNR captures node-word correlation by maximizing the co-occurrence of word sequence given a node; and (3) at the node label level, TriDNR models label-word correspondence by maximizing the probability of word sequence given a class label. The tri-party information is jointly fed into the neural network model to mutually enhance each other to learn optimal representation, and results in up to 79% classification accuracy gain, compared to state-of-the-art methods.\nNeighbourhood Watch: Referring Expression Comprehension via Language-Guided Graph Attention Networks (Peng Wang et al., 2018) Peng Wang, Qi Wu, Jiewei Cao, Chunhua Shen, Lianli Gao, A. V. Hengel. (2018)\nNeighbourhood Watch: Referring Expression Comprehension via Language-Guided Graph Attention Networks\n2019 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)\nPaper Link\nInfluential Citation Count (12), SS-ID (8ca91ad7763be4da05238aa17a9e5628f619dc0b)\nABSTRACT\nThe task in referring expression comprehension is to localize the object instance in an image described by a referring expression phrased in natural language. As a language-to-vision matching task, the key to this problem is to learn a discriminative object feature that can adapt to the expression used. To avoid ambiguity, the expression normally tends to describe not only the properties of the referent itself, but also its relationships to its neighbourhood. To capture and exploit this important information we propose a graph-based, language-guided attention mechanism. Being composed of node attention component and edge attention component, the proposed graph attention mechanism explicitly represents inter-object relationships, and properties with a flexibility and power impossible with competing approaches. Furthermore, the proposed graph attention mechanism enables the comprehension decision to be visualizable and explainable. Experiments on three referring expression comprehension datasets show the advantage of the proposed approach.\nLink Prediction in Complex Networks: A Survey (Linyuan Lu et al., 2010) Linyuan Lu, T. Zhou. (2010)\nLink Prediction in Complex Networks: A Survey\nArXiv\nPaper Link\nInfluential Citation Count (191), SS-ID (8cd9aa720a3a2f9dcb52ad9eb1bf258a80ce0648)\nABSTRACT\nDesign of multi-view graph embedding using multiple kernel learning (Asif Salim et al., 2020) Asif Salim, S. Shiju, S. Sumitra. (2020)\nDesign of multi-view graph embedding using multiple kernel learning\nEng. Appl. Artif. Intell.\nPaper Link\nInfluential Citation Count (0), SS-ID (8ce7c67095d76da23897cc379c063986e9843a7c)\nABSTRACT\nThe graph embedding is the process of representing the graph in a vector space using properties of the graphs and this technique has now being widely used for analyzing the graph data using machine learning algorithms. The existing graph embeddings rely mostly on a single property of graphs for data representation which is found to be inappropriate to capture all the characteristics of the data. Hence we designed graph embedding using multi-view approach, where each view is an embedding of the graph using a graph property. The input space of multi-view learning is then taken as the direct sum of the subspaces in which the graph embedding lie. We did analysis on real world data by incorporating the proposed model on support vector machines (SVM). The reproducing kernel used in SVM is represented as the linear combination of the kernels defined on the individual embeddings. The optimization technique used in simple multiple kernel learning (simpleMKL) is used to find the parameters of the optimal kernel. To analyze the individual representation capability of the embeddings, an R-convolution graph kernel is designed over each of the views. In our experimental analysis, the multi-view graph embedding showed a superior performance in comparison with that of the state-of-the-art graph embeddings as well as graph kernels.\nFriends and neighbors on the Web (Lada A. Adamic et al., 2003) Lada A. Adamic, Eytan Adar. (2003)\nFriends and neighbors on the Web\nSoc. Networks\nPaper Link\nInfluential Citation Count (180), SS-ID (8dc9d11e3fc229a1b70bb00de72dc15d55848174)\nABSTRACT\nThe Internet has become a rich and large repository of information about us as individuals. Anything from the links and text on a user’s homepage to the mailing lists the user subscribes to are reflections of social interactions a user has in the real world. In this paper we devise techniques and tools to mine this information in order to extract social networks and the exogenous factors underlying the networks’ structure. In an analysis of two data sets, from Stanford University and the Massachusetts Institute of Technology (MIT), we show that some factors are better indicators of social connections than others, and that these indicators vary between user populations. Our techniques provide potential applications in automatically inferring real world connections and discovering, labeling, and characterizing communities.\nNot All Links Are Created Equal: An Adaptive Embedding Approach for Social Personalized Ranking (Qing Zhang et al., 2016) Qing Zhang, Houfeng Wang. (2016)\nNot All Links Are Created Equal: An Adaptive Embedding Approach for Social Personalized Ranking\nSIGIR\nPaper Link\nInfluential Citation Count (2), SS-ID (8e1d196f5e7d4b8c24a5970a9052fa57d7f805a7)\nABSTRACT\nWith a large amount of complex network data available, most existing recommendation models consider exploiting rich user social relations for better interest targeting. In these approaches, the underlying assumption is that similar users in social networks would prefer similar items. However, in practical scenarios, social link may not be formed by common interest. For example, one general collected social network might be used for various specific recommendation scenarios. The problem of noisy social relations without interest relevance will arise to hurt the performance. Moreover, the sparsity problem of social network makes it much more challenging, due to the two-fold problem needed to be solved simultaneously, for effectively incorporating social information to benefit recommendation. To address this challenge, we propose an adaptive embedding approach to solve the both jointly for better recommendation in real world setting. Experiments conducted on real world datasets show that our approach outperforms current methods.\nAn Overview of Microsoft Academic Service (MAS) and Applications (Arnab Sinha et al., 2015) Arnab Sinha, Zhihong Shen, Yang Song, Hao Ma, Darrin Eide, B. Hsu, Kuansan Wang. (2015)\nAn Overview of Microsoft Academic Service (MAS) and Applications\nWWW\nPaper Link\nInfluential Citation Count (119), SS-ID (8ebc4145aef6a575cbaffcfeec56b20586db573a)\nABSTRACT\nIn this paper we describe a new release of a Web scale entity graph that serves as the backbone of Microsoft Academic Service (MAS), a major production effort with a broadened scope to the namesake vertical search engine that has been publicly available since 2008 as a research prototype. At the core of MAS is a heterogeneous entity graph comprised of six types of entities that model the scholarly activities: field of study, author, institution, paper, venue, and event. In addition to obtaining these entities from the publisher feeds as in the previous effort, we in this version include data mining results from the Web index and an in-house knowledge base from Bing, a major commercial search engine. As a result of the Bing integration, the new MAS graph sees significant increase in size, with fresh information streaming in automatically following their discoveries by the search engine. In addition, the rich entity relations included in the knowledge base provide additional signals to disambiguate and enrich the entities within and beyond the academic domain. The number of papers indexed by MAS, for instance, has grown from low tens of millions to 83 million while maintaining an above 95% accuracy based on test data sets derived from academic activities at Microsoft Research. Based on the data set, we demonstrate two scenarios in this work: a knowledge driven, highly interactive dialog that seamlessly combines reactive search and proactive suggestion experience, and a proactive heterogeneous entity recommendation.\nPredicting Drug–Target Interactions Using Probabilistic Matrix Factorization (M. Çobanoğlu et al., 2013) M. Çobanoğlu, Chang Liu, F. Hu, Z. Oltvai, I. Bahar. (2013)\nPredicting Drug–Target Interactions Using Probabilistic Matrix Factorization\nJ. Chem. Inf. Model.\nPaper Link\nInfluential Citation Count (8), SS-ID (8ebdcddbb9c8b3140c3d88cb479ac8468109ce21)\nABSTRACT\nQuantitative analysis of known drug–target interactions emerged in recent years as a useful approach for drug repurposing and assessing side effects. In the present study, we present a method that uses probabilistic matrix factorization (PMF) for this purpose, which is particularly useful for analyzing large interaction networks. DrugBank drugs clustered based on PMF latent variables show phenotypic similarity even in the absence of 3D shape similarity. Benchmarking computations show that the method outperforms those recently introduced provided that the input data set of known interactions is sufficiently large—which is the case for enzymes and ion channels, but not for G-protein coupled receptors (GPCRs) and nuclear receptors. Runs performed on DrugBank after hiding 70% of known interactions show that, on average, 88 of the top 100 predictions hit the hidden interactions. De novo predictions permit us to identify new potential interactions. Drug–target pairs implicated in neurobiological disorders are overrepresented among de novo predictions.\nDeep mining heterogeneous networks of biomedical linked data to predict novel drug‐target associations (Nansu Zong et al., 2017) Nansu Zong, Hyeon-eui Kim, Victoria Ngo, O. Harismendy. (2017)\nDeep mining heterogeneous networks of biomedical linked data to predict novel drug‐target associations\nBioinform.\nPaper Link\nInfluential Citation Count (6), SS-ID (8ef131f8e043a47aebe50dae449ed42843a9749d)\nABSTRACT\nMotivation: A heterogeneous network topology possessing abundant interactions between biomedical entities has yet to be utilized in similarity‐based methods for predicting drug‐target associations based on the array of varying features of drugs and their targets. Deep learning reveals features of vertices of a large network that can be adapted in accommodating the similarity‐based solutions to provide a flexible method of drug‐target prediction. Results: We propose a similarity‐based drug‐target prediction method that enhances existing association discovery methods by using a topology‐based similarity measure. DeepWalk, a deep learning method, is adopted in this study to calculate the similarities within Linked Tripartite Network (LTN), a heterogeneous network generated from biomedical linked datasets. This proposed method shows promising results for drug‐target association prediction: 98.96% AUC ROC score with a 10‐fold cross‐validation and 99.25% AUC ROC score with a Monte Carlo cross‐validation with LTN. By utilizing DeepWalk, we demonstrate that: (i) this method outperforms other existing topology‐based similarity computation methods, (ii) the performance is better for tripartite than with bipartite networks and (iii) the measure of similarity using network topology outperforms the ones derived from chemical structure (drugs) or genomic sequence (targets). Our proposed methodology proves to be capable of providing a promising solution for drug‐target prediction based on topological similarity with a heterogeneous network, and may be readily re‐purposed and adapted in the existing of similarity‐based methodologies. Availability and Implementation: The proposed method has been developed in JAVA and it is available, along with the data at the following URL: https://github.com/zongnansu1982/drug‐target‐prediction. Contact: nazong@ucsd.edu Supplementary information: Supplementary data are available at Bioinformatics online.\nSession-Based Social Recommendation via Dynamic Graph Attention Networks (Weiping Song et al., 2019) Weiping Song, Zhiping Xiao, Yifan Wang, Laurent Charlin, Ming Zhang, Jian Tang. (2019)\nSession-Based Social Recommendation via Dynamic Graph Attention Networks\nWSDM\nPaper Link\nInfluential Citation Count (13), SS-ID (901a6ad54f3bfc0ca6671f4e492703c671475288)\nABSTRACT\nOnline communities such as Facebook and Twitter are enormously popular and have become an essential part of the daily life of many of their users. Through these platforms, users can discover and create information that others will then consume. In that context, recommending relevant information to users becomes critical for viability. However, recommendation in online communities is a challenging problem: 1) users\u0026rsquo; interests are dynamic, and 2) users are influenced by their friends. Moreover, the influencers may be context-dependent. That is, different friends may be relied upon for different topics. Modeling both signals is therefore essential for recommendations. We propose a recommender system for online communities based on a dynamic-graph-attention neural network. We model dynamic user behaviors with a recurrent neural network, and context-dependent social influence with a graph-attention neural network, which dynamically infers the influencers based on users\u0026rsquo; current interests. The whole model can be efficiently fit on large-scale data. Experimental results on several real-world data sets demonstrate the effectiveness of our proposed approach over several competitive baselines including state-of-the-art models.\nLearning Graph Embedding With Adversarial Training Methods (Shirui Pan et al., 2019) Shirui Pan, Ruiqi Hu, S. Fung, Guodong Long, Jing Jiang, Chengqi Zhang. (2019)\nLearning Graph Embedding With Adversarial Training Methods\nIEEE Transactions on Cybernetics\nPaper Link\nInfluential Citation Count (11), SS-ID (914fbae74420475d54c8099c5921b5f799c1c6c7)\nABSTRACT\nGraph embedding aims to transfer a graph into vectors to facilitate subsequent graph-analytics tasks like link prediction and graph clustering. Most approaches on graph embedding focus on preserving the graph structure or minimizing the reconstruction errors for graph data. They have mostly overlooked the embedding distribution of the latent codes, which unfortunately may lead to inferior representation in many cases. In this article, we present a novel adversarially regularized framework for graph embedding. By employing the graph convolutional network as an encoder, our framework embeds the topological information and node content into a vector representation, from which a graph decoder is further built to reconstruct the input graph. The adversarial training principle is applied to enforce our latent codes to match a prior Gaussian or uniform distribution. Based on this framework, we derive two variants of the adversarial models, the adversarially regularized graph autoencoder (ARGA) and its variational version, and adversarially regularized variational graph autoencoder (ARVGA), to learn the graph embedding effectively. We also exploit other potential variations of ARGA and ARVGA to get a deeper understanding of our designs. Experimental results that compared 12 algorithms for link prediction and 20 algorithms for graph clustering validate our solutions.\nLink-Based Classification (, 2014) . (2014)\nLink-Based Classification\nEncyclopedia of Social Network Analysis and Mining\nPaper Link\nInfluential Citation Count (48), SS-ID (91bf323aec3270df0ec8082389119d536c395655)\nABSTRACT\nPredicting who rated what in large-scale datasets (Yan Liu et al., 2007) Yan Liu, Zhenzhen Kou. (2007)\nPredicting who rated what in large-scale datasets\nSKDD\nPaper Link\nInfluential Citation Count (1), SS-ID (92b5c2a83183c7d2c7c6e2bea6994730e42f975e)\nABSTRACT\nKDD Cup 2007 focuses on movie rating behaviors. The goal of the task \u0026ldquo;Who Rated What\u0026rdquo; is to predict whether \u0026ldquo;existing\u0026rdquo; users will review \u0026ldquo;existing\u0026rdquo; movies in the future. We cast the task as a link prediction problem and address it via a simple classification approach. Compared with other applications for link prediction, there are two major challenges in our task: (1) the huge size of the Netflix data; (2) the prediction target is complicated by many factors, such as a general decrease of interest in old movies and more tendency to review more movies by Netflix users due to the success of the internet DVD rental industries. We address the first challenge by \u0026ldquo;selective\u0026rdquo; subsampling and the second by combining information from the review scores, movie contents and graph topology effectively.\nCollaborative matrix factorization with multiple similarities for predicting drug-target interactions (Xiaodong Zheng et al., 2013) Xiaodong Zheng, Hao Ding, Hiroshi Mamitsuka, Shanfeng Zhu. (2013)\nCollaborative matrix factorization with multiple similarities for predicting drug-target interactions\nKDD\nPaper Link\nInfluential Citation Count (30), SS-ID (92e8f21bcf8437b6e6b7e43d4c2e9bd717e41673)\nABSTRACT\nWe address the problem of predicting new drug-target interactions from three inputs: known interactions, similarities over drugs and those over targets. This setting has been considered by many methods, which however have a common problem of allowing to have only one similarity matrix over drugs and that over targets. The key idea of our approach is to use more than one similarity matrices over drugs as well as those over targets, where weights over the multiple similarity matrices are estimated from data to automatically select similarities, which are effective for improving the performance of predicting drug-target interactions. We propose a factor model, named Multiple Similarities Collaborative Matrix Factorization(MSCMF), which projects drugs and targets into a common low-rank feature space, which is further consistent with weighted similarity matrices over drugs and those over targets. These two low-rank matrices and weights over similarity matrices are estimated by an alternating least squares algorithm. Our approach allows to predict drug-target interactions by the two low-rank matrices collaboratively and to detect similarities which are important for predicting drug-target interactions. This approach is general and applicable to any binary relations with similarities over elements, being found in many applications, such as recommender systems. In fact, MSCMF is an extension of weighted low-rank approximation for one-class collaborative filtering. We extensively evaluated the performance of MSCMF by using both synthetic and real datasets. Experimental results showed nice properties of MSCMF on selecting similarities useful in improving the predictive performance and the performance advantage of MSCMF over six state-of-the-art methods for predicting drug-target interactions.\nLarge-Scale Multi-View Spectral Clustering via Bipartite Graph (Yeqing Li et al., 2015) Yeqing Li, F. Nie, Heng Huang, Junzhou Huang. (2015)\nLarge-Scale Multi-View Spectral Clustering via Bipartite Graph\nAAAI\nPaper Link\nInfluential Citation Count (33), SS-ID (9383f08c697b8aa43782e16c9a57e089911584d8)\nABSTRACT\nIn this paper, we address the problem of large-scale multi-view spectral clustering. In many real-world applications, data can be represented in various heterogeneous features or views. Different views often provide different aspects of information that are complementary to each other. Several previous methods of clustering have demonstrated that better accuracy can be achieved using integrated information of all the views than just using each view individually. One important class of such methods is multi-view spectral clustering, which is based on graph Laplacian. However, existing methods are not applicable to large-scale problem for their high computational complexity. To this end, we propose a novel large-scale multi-view spectral clustering approach based on the bipartite graph. Our method uses local manifold fusion to integrate heterogeneous features. To improve efficiency, we approximate the similarity graphs using bipartite graphs. Furthermore, we show that our method can be easily extended to handle the out-of-sample problem. Extensive experimental results on five benchmark datasets demonstrate the effectiveness and efficiency of the proposed method, where our method runs up to nearly 3000 times faster than the state-of-the-art methods.\nMulti-view clustering: A survey (Yan Yang et al., 2018) Yan Yang, Hao Wang. (2018)\nMulti-view clustering: A survey\nBig Data Min. Anal.\nPaper Link\nInfluential Citation Count (3), SS-ID (9404cc4488ae98babf17b286a20e7baa6ef5d398)\nABSTRACT\nIn the big data era, the data are generated from different sources or observed from different views. These data are referred to as multi-view data. Unleashing the power of knowledge in multi-view data is very important in big data mining and analysis. This calls for advanced techniques that consider the diversity of different views, while fusing these data. Multi-view Clustering (MvC) has attracted increasing attention in recent years by aiming to exploit complementary and consensus information across multiple views. This paper summarizes a large number of multi-view clustering algorithms, provides a taxonomy according to the mechanisms and principles involved, and classifies these algorithms into five categories, namely, co-training style algorithms, multi-kernel learning, multiview graph clustering, multi-view subspace clustering, and multi-task multi-view clustering. Therein, multi-view graph clustering is further categorized as graph-based, network-based, and spectral-based methods. Multi-view subspace clustering is further divided into subspace learning-based, and non-negative matrix factorization-based methods. This paper does not only introduce the mechanisms for each category of methods, but also gives a few examples for how these techniques are used. In addition, it lists some publically available multi-view datasets. Overall, this paper serves as an introductory text and survey for multi-view clustering.\nDINIES: drug–target interaction network inference engine based on supervised analysis (Yoshihiro Yamanishi et al., 2014) Yoshihiro Yamanishi, Masaaki Kotera, Yuki Moriya, Ryusuke Sawada, M. Kanehisa, S. Goto. (2014)\nDINIES: drug–target interaction network inference engine based on supervised analysis\nNucleic Acids Res.\nPaper Link\nInfluential Citation Count (2), SS-ID (952719f09792f25e66079cc0edd370ffb166caf8)\nABSTRACT\nDINIES (drug–target interaction network inference engine based on supervised analysis) is a web server for predicting unknown drug–target interaction networks from various types of biological data (e.g. chemical structures, drug side effects, amino acid sequences and protein domains) in the framework of supervised network inference. The originality of DINIES lies in prediction with state-of-the-art machine learning methods, in the integration of heterogeneous biological data and in compatibility with the KEGG database. The DINIES server accepts any ‘profiles’ or precalculated similarity matrices (or ‘kernels’) of drugs and target proteins in tab-delimited file format. When a training data set is submitted to learn a predictive model, users can select either known interaction information in the KEGG DRUG database or their own interaction data. The user can also select an algorithm for supervised network inference, select various parameters in the method and specify weights for heterogeneous data integration. The server can provide integrative analyses with useful components in KEGG, such as biological pathways, functional hierarchy and human diseases. DINIES (http://www.genome.jp/tools/dinies/) is publicly available as one of the genome analysis tools in GenomeNet.\nDistributed large-scale natural graph factorization (Amr Ahmed et al., 2013) Amr Ahmed, N. Shervashidze, Shravan M. Narayanamurthy, V. Josifovski, Alex Smola. (2013)\nDistributed large-scale natural graph factorization\nWWW\nPaper Link\nInfluential Citation Count (30), SS-ID (952bc3bc999be86d4b03a9c4af94c555c822aa11)\nABSTRACT\nNatural graphs, such as social networks, email graphs, or instant messaging patterns, have become pervasive through the internet. These graphs are massive, often containing hundreds of millions of nodes and billions of edges. While some theoretical models have been proposed to study such graphs, their analysis is still difficult due to the scale and nature of the data. We propose a framework for large-scale graph decomposition and inference. To resolve the scale, our framework is distributed so that the data are partitioned over a shared-nothing set of machines. We propose a novel factorization technique that relies on partitioning a graph so as to minimize the number of neighboring vertices rather than edges across partitions. Our decomposition is based on a streaming algorithm. It is network-aware as it adapts to the network topology of the underlying computational hardware. We use local copies of the variables and an efficient asynchronous communication protocol to synchronize the replicated values in order to perform most of the computation without having to incur the cost of network communication. On a graph of 200 million vertices and 10 billion edges, derived from an email communication network, our algorithm retains convergence properties while allowing for almost linear scalability in the number of computers.\nLearning by Sampling and Compressing: Efficient Graph Representation Learning with Extremely Limited Annotations (Xiaoming Liu et al., 2020) Xiaoming Liu, Qirui Li, Chao Shen, Xi Peng, Yadong Zhou, Guan Xiaohong. (2020)\nLearning by Sampling and Compressing: Efficient Graph Representation Learning with Extremely Limited Annotations\nPaper Link\nInfluential Citation Count (0), SS-ID (95555b454fc93ff6cab8ad8ee9bb3096d32e2b9c)\nABSTRACT\nGraph convolution network (GCN) attracts intensive research interest with broad applications. While existing work mainly focused on designing novel GCN architectures for better performance, few of them studied a practical yet challenging problem: How to learn GCNs from data with extremely limited annotation? In this paper, we propose a new learning method by sampling strategy and model compression to overcome this challenge. Our approach has multifold advantages: 1) the adaptive sampling strategy largely suppresses the GCN training deviation over uniform sampling; 2) compressed GCN-based methods with a smaller scale of parameters need fewer labeled data to train; 3) the smaller scale of training data is beneficial to reduce the human resource cost to label them. We choose six popular GCN baselines and conduct extensive experiments on three real-world datasets. The results show that by applying our method, all GCN baselines cut down the annotation requirement by as much as 90$%$ and compress the scale of parameters more than 6$\\times$ without sacrificing their strong performance. It verifies that the training method could extend the existing semi-supervised GCN-based methods to the scenarios with the extremely small scale of labeled data.\nHolographic Embeddings of Knowledge Graphs (Maximilian Nickel et al., 2015) Maximilian Nickel, L. Rosasco, T. Poggio. (2015)\nHolographic Embeddings of Knowledge Graphs\nAAAI\nPaper Link\nInfluential Citation Count (139), SS-ID (955fe2ee26d888ae22749b0853981b8b581b133d)\nABSTRACT\nLearning embeddings of entities and relations is an efficient and versatile method to perform machine learning on relational data such as knowledge graphs. In this work, we propose holographic embeddings (HOLE) to learn compositional vector space representations of entire knowledge graphs. The proposed method is related to holographic models of associative memory in that it employs circular correlation to create compositional representations. By using correlation as the compositional operator, HOLE can capture rich interactions but simultaneously remains efficient to compute, easy to train, and scalable to very large datasets. Experimentally, we show that holographic embeddings are able to outperform state-of-the-art methods for link prediction on knowledge graphs and relational learning benchmark datasets.\nUnsupervised and Scalable Algorithm for Learning Node Representations (Tiago Pimentel et al., 2017) Tiago Pimentel, Adriano Veloso, N. Ziviani. (2017)\nUnsupervised and Scalable Algorithm for Learning Node Representations\nICLR\nPaper Link\nInfluential Citation Count (2), SS-ID (95a32bda5a743da698e062a5f5806ce5f22aef29)\nABSTRACT\nRepresentation learning is one of the foundations of Deep Learning and allowed big improvements on several Machine Learning fields, such as Neural Machine Translation, Question Answering and Speech Recognition. Recent works have proposed new methods for learning representations for nodes and edges in graphs. In this work, we propose a new unsupervised and efficient method, called here Neighborhood Based Node Embeddings (NBNE), capable of generating node embeddings for very large graphs. This method is based on SkipGram and uses nodes’ neighborhoods as contexts to generate representations. NBNE achieves results comparable or better than state-of-the-art feature learning algorithms in three different datasets and, differently from our main baseline (Node2Vec), which needs to have its parameters tuned in a validation set, is completely unsupervised.\nDual-Primal Graph Convolutional Networks (Federico Monti et al., 2018) Federico Monti, Oleksandr Shchur, Aleksandar Bojchevski, O. Litany, Stephan Günnemann, M. Bronstein. (2018)\nDual-Primal Graph Convolutional Networks\nArXiv\nPaper Link\nInfluential Citation Count (1), SS-ID (980a4959ad4c81a61f4166b549157ddad1f7ddce)\nABSTRACT\nIn recent years, there has been a surge of interest in developing deep learning methods for non-Euclidean structured data such as graphs. In this paper, we propose Dual-Primal Graph CNN, a graph convolutional architecture that alternates convolution-like operations on the graph and its dual. Our approach allows to learn both vertex- and edge features and generalizes the previous graph attention (GAT) model. We provide extensive experimental validation showing state-of-the-art results on a variety of tasks tested on established graph benchmarks, including CORA and Citeseer citation networks as well as MovieLens, Flixter, Douban and Yahoo Music graph-guided recommender systems.\nCollective Pairwise Classification for Multi-Way Analysis of Disease and Drug Data (M. Zitnik et al., 2016) M. Zitnik, B. Zupan. (2016)\nCollective Pairwise Classification for Multi-Way Analysis of Disease and Drug Data\nPSB\nPaper Link\nInfluential Citation Count (1), SS-ID (982d4c371d4ea37f9438eb58d788c1d183300f99)\nABSTRACT\nInteractions between drugs, drug targets or diseases can be predicted on the basis of molecular, clinical and genomic features by, for example, exploiting similarity of disease pathways, chemical structures, activities across cell lines or clinical manifestations of diseases. A successful way to better understand complex interactions in biomedical systems is to employ collective relational learning approaches that can jointly model diverse relationships present in multiplex data. We propose a novel collective pairwise classification approach for multi-way data analysis. Our model leverages the superiority of latent factor models and classifies relationships in a large relational data domain using a pairwise ranking loss. In contrast to current approaches, our method estimates probabilities, such that probabilities for existing relationships are higher than for assumed-to-be-negative relationships. Although our method bears correspondence with the maximization of non-differentiable area under the ROC curve, we were able to design a learning algorithm that scales well on multi-relational data encoding interactions between thousands of entities.We use the new method to infer relationships from multiplex drug data and to predict connections between clinical manifestations of diseases and their underlying molecular signatures. Our method achieves promising predictive performance when compared to state-of-the-art alternative approaches and can make \u0026ldquo;category-jumping\u0026rdquo; predictions about diseases from genomic and clinical data generated far outside the molecular context.\nAdversarial Attention-Based Variational Graph Autoencoder (Ziqiang Weng et al., 2020) Ziqiang Weng, Weiyu Zhang, Wei Dou. (2020)\nAdversarial Attention-Based Variational Graph Autoencoder\nIEEE Access\nPaper Link\nInfluential Citation Count (0), SS-ID (989afdf64a0df329004de086cbc9057a9d8634f4)\nABSTRACT\nAutoencoders have been successfully used for graph embedding, and many variants have been proven to effectively express graph data and conduct graph analysis in low-dimensional space. However, previous methods ignore the structure and properties of the reconstructed graph, or they do not consider the potential data distribution in the graph, which typically leads to unsatisfactory graph embedding performance. In this paper, we propose the adversarial attention variational graph autoencoder (AAVGA), which is a novel framework that incorporates attention networks into the encoder part and uses an adversarial mechanism in embedded training. The encoder involves node neighbors in the representation of nodes by stacking attention layers, which can further improve the graph embedding performance of the encoder. At the same time, due to the adversarial mechanism, the distribution of the potential features that are generated by the encoder are closer to the actual distribution of the original graph data; thus, the decoder generates a graph that is closer to the original graph. Experimental results prove that AAVGA performs competitively with state-of-the-art popular graph encoders on three citation datasets.\nSIGN: Scalable Inception Graph Neural Networks (Emanuele Rossi et al., 2020) Emanuele Rossi, F. Frasca, B. Chamberlain, D. Eynard, M. Bronstein, Federico Monti. (2020)\nSIGN: Scalable Inception Graph Neural Networks\nArXiv\nPaper Link\nInfluential Citation Count (23), SS-ID (993377a3fc8334558463b82053904e3d684f29c0)\nABSTRACT\nGraph representation learning has recently been applied to a broad spectrum of problems ranging from computer graphics and chemistry to high energy physics and social media. The popularity of graph neural networks has sparked interest, both in academia and in industry, in developing methods that scale to very large graphs such as Facebook or Twitter social networks. In most of these approaches, the computational cost is alleviated by a sampling strategy retaining a subset of node neighbors or subgraphs at training time. In this paper we propose a new, efficient and scalable graph deep learning architecture which sidesteps the need for graph sampling by using graph convolutional filters of different size that are amenable to efficient precomputation, allowing extremely fast training and inference. Our architecture allows using different local graph operators (e.g. motif-induced adjacency matrices or Personalized Page Rank diffusion matrix) to best suit the task at hand. We conduct extensive experimental evaluation on various open benchmarks and show that our approach is competitive with other state-of-the-art architectures, while requiring a fraction of the training and inference time.\nLearning Entity and Relation Embeddings for Knowledge Graph Completion (Yankai Lin et al., 2015) Yankai Lin, Zhiyuan Liu, Maosong Sun, Yang Liu, Xuan Zhu. (2015)\nLearning Entity and Relation Embeddings for Knowledge Graph Completion\nAAAI\nPaper Link\nInfluential Citation Count (363), SS-ID (994afdf0db0cb0456f4f76468380822c2f532726)\nABSTRACT\nKnowledge graph completion aims to perform link prediction between entities. In this paper, we consider the approach of knowledge graph embeddings. Recently, models such as TransE and TransH build entity and relation embeddings by regarding a relation as translation from head entity to tail entity. We note that these models simply put both entities and relations within the same semantic space. In fact, an entity may have multiple aspects and various relations may focus on different aspects of entities, which makes a common space insufficient for modeling. In this paper, we propose TransR to build entity and relation embeddings in separate entity space and relation spaces. Afterwards, we learn embeddings by first projecting entities from entity space to corresponding relation space and then building translations between projected entities. In experiments, we evaluate our models on three tasks including link prediction, triple classification and relational fact extraction. Experimental results show significant and consistent improvements compared to state-of-the-art baselines including TransE and TransH. The source code of this paper can be obtained from https://github.com/mrlyk423/relation_extraction.\nThe link-prediction problem for social networks (D. Liben-Nowell et al., 2007) D. Liben-Nowell, J. Kleinberg. (2007)\nThe link-prediction problem for social networks\nJ. Assoc. Inf. Sci. Technol.\nPaper Link\nInfluential Citation Count (240), SS-ID (996dfa43f6982bcbff862276ef80cbca7515985a)\nABSTRACT\nGiven a snapshot of a social network, can we infer which new interactions among its members are likely to occur in the near future? We formalize this question as the link prediction problem, and develop approaches to link prediction based on measures the \u0026ldquo;proximity\u0026rdquo; of nodes in a network. Experiments on large co-authorship networks suggest that information about future interactions can be extracted from network topology alone, and that fairly subtle measures for detecting node proximity can outperform more direct measures.\nContinuous nonlinear dimensionality reduction by kernel Eigenmaps (M. Brand, 2003) M. Brand. (2003)\nContinuous nonlinear dimensionality reduction by kernel Eigenmaps\nIJCAI\nPaper Link\nInfluential Citation Count (5), SS-ID (99cd988b104202887ad9657b8a61baa7ff0581c1)\nABSTRACT\nWe equate nonlinear dimensionality reduction (NLDR) to graph embedding with side information about the vertices, and derive a solution to either problem in the form of a kernel-based mixture of affine maps from the ambient space to the target space. Unlike most spectral NLDR methods, the central eigenproblem can be made relatively small, and the result is a continuous mapping defined over the entire space, not just the datapoints. A demonstration is made to visualizing the distribution of word usages (as a proxy to word meanings) in a sample of the machine learning literature.\nHeteGCN: Heterogeneous Graph Convolutional Networks for Text Classification (Rahul Ragesh et al., 2020) Rahul Ragesh, Sundararajan Sellamanickam, Arun Iyer, Ramakrishna Bairi, Vijay Lingam. (2020)\nHeteGCN: Heterogeneous Graph Convolutional Networks for Text Classification\nWSDM\nPaper Link\nInfluential Citation Count (3), SS-ID (9a6935328336b05fb95a47916eccf7b3c50b2f97)\nABSTRACT\nWe consider the problem of learning efficient and inductive graph convolutional networks for text classification with a large number of examples and features. Existing state-of-the-art graph embedding based methods such as predictive text embedding (PTE) and TextGCN have shortcomings in terms of predictive performance, scalability and inductive capability. To address these limitations, we propose a heterogeneous graph convolutional network (HeteGCN) modeling approach that unites the best aspects of PTE and TextGCN together. The main idea is to learn feature embeddings and derive document embeddings using a HeteGCN architecture with different graphs used across layers. We simplify TextGCN by dissecting into several HeteGCN models which (a) helps to study the usefulness of individual models and (b) offers flexibility in fusing learned embeddings from different models. In effect, the number of model parameters is reduced significantly, enabling faster training and improving performance in small labeled training set scenario. Our detailed experimental studies demonstrate the efficacy of the proposed approach.\nA Spectral Clustering Approach To Finding Communities in Graph (Scott White et al., 2005) Scott White, Padhraic Smyth. (2005)\nA Spectral Clustering Approach To Finding Communities in Graph\nSDM\nPaper Link\nInfluential Citation Count (22), SS-ID (9a92300b0ecc33f8e55a8ac945a51aaade549013)\nABSTRACT\nClustering nodes in a graph is a useful general technique in data mining of large network data sets. In this context, Newman and Girvan [9] recently proposed an objective function for graph clustering called the Q function which allows automatic selection of the number of clusters. Empirically, higher values of the Q function have been shown to correlate well with good graph clusterings. In this paper we show how optimizing the Q function can be reformulated as a spectral relaxation problem and propose two new spectral clustering algorithms that seek to maximize Q. Experimental results indicate that the new algorithms are efficient and effective at finding both good clusterings and the appropriate number of clusters across a variety of real-world graph data sets. In addition, the spectral algorithms are much faster for large sparse graphs, scaling roughly linearly with the number of nodes n in the graph, compared to O(n) for previous clustering algorithms using the Q function.\nUnsupervised Large Graph Embedding (F. Nie et al., 2017) F. Nie, Wei Zhu, Xuelong Li. (2017)\nUnsupervised Large Graph Embedding\nAAAI\nPaper Link\nInfluential Citation Count (5), SS-ID (9ad503ff70a2b3a1ddebc96683ed73c7fcd0840b)\nABSTRACT\nThere are many successful spectral based unsupervised dimensionality reduction methods, including Laplacian Eigenmap (LE), Locality Preserving Projection (LPP), Spectral Regression (SR), etc. LPP and SR are two different linear spectral based methods, however, we discover that LPP and SR are equivalent, if the symmetric similarity matrix is doubly stochastic, Positive Semi-Definite (PSD) and with rank p, where p is the reduced dimension. The discovery promotes us to seek low-rank and doubly stochastic similarity matrix, we then propose an unsupervised linear dimensionality reduction method, called Unsupervised Large Graph Embedding (ULGE). ULGE starts with similar idea as LPP, it adopts an efficient approach to construct similarity matrix and then performs spectral analysis efficiently, the computational complexity can reduce to O(ndm), which is a significant improvement compared to conventional spectral based methods which need O(nd) at least, where n, d and m are the number of samples, dimensions and anchors, respectively. Extensive experiments on several public available data sets demonstrate the efficiency and effectiveness of the proposed method.\nRecommendation as link prediction: a graph kernel-based machine learning approach (Xin Li et al., 2009) Xin Li, Hsinchun Chen. (2009)\nRecommendation as link prediction: a graph kernel-based machine learning approach\nJCDL \u0026lsquo;09\nPaper Link\nInfluential Citation Count (4), SS-ID (9b194ee4c71eb526078627bf7da9b9275b0e421b)\nABSTRACT\nRecommender systems have demonstrated commercial success in multiple industries. In digital libraries they have the potential to be used as a support tool for traditional information retrieval functions. Among the major recommendation algorithms, the successful collaborative filtering (CF) methods explore the use of user-item interactions to infer user interests. Based on the finding that transitive user-item associations can alleviate the data sparsity problem in CF, multiple heuristic algorithms were designed to take advantage of the user-item interaction networks with both direct and indirect interactions. However, the use of such graph representation was still limited in learning-based algorithms. In this paper, we propose a graph kernel-based recommendation framework. For each user-item pair, we inspect its associative interaction graph (AIG) that contains the users, items, and interactions n steps away from the pair. We design a novel graph kernel to capture the AIG structures and use them to predict possible user-item interactions. The framework demonstrates improved performance on an online bookstore dataset, especially when a large number of suggestions are needed.\nDiffusion Convolutional Recurrent Neural Network: Data-Driven Traffic Forecasting (Yaguang Li et al., 2017) Yaguang Li, Rose Yu, C. Shahabi, Yan Liu. (2017)\nDiffusion Convolutional Recurrent Neural Network: Data-Driven Traffic Forecasting\nICLR\nPaper Link\nInfluential Citation Count (211), SS-ID (9ba0186ed40656329c421f55ada7313293e13f17)\nABSTRACT\nSpatiotemporal forecasting has various applications in neuroscience, climate and transportation domain. Traffic forecasting is one canonical example of such learning task. The task is challenging due to (1) complex spatial dependency on road networks, (2) non-linear temporal dynamics with changing road conditions and (3) inherent difficulty of long-term forecasting. To address these challenges, we propose to model the traffic flow as a diffusion process on a directed graph and introduce Diffusion Convolutional Recurrent Neural Network (DCRNN), a deep learning framework for traffic forecasting that incorporates both spatial and temporal dependency in the traffic flow. Specifically, DCRNN captures the spatial dependency using bidirectional random walks on the graph, and the temporal dependency using the encoder-decoder architecture with scheduled sampling. We evaluate the framework on two real-world large scale road network traffic datasets and observe consistent improvement of 12% - 15% over state-of-the-art baselines.\nAnonymized GCN: A Novel Robust Graph Embedding Method via Hiding Node Position in Noise (Ao Liu, 2020) Ao Liu. (2020)\nAnonymized GCN: A Novel Robust Graph Embedding Method via Hiding Node Position in Noise\nArXiv\nPaper Link\nInfluential Citation Count (0), SS-ID (9bad9deef8ebd658417d038849f3ca25b94f136b)\nABSTRACT\nGraph convolution network (GCN) have achieved state-of-the-art performance in the task of node prediction in the graph structure. However, with the gradual various of graph attack methods, there are lack of research on the robustness of GCN. At this paper, we will design a robust GCN method for node prediction tasks. Considering the graph structure contains two types of information: node information and connection information, and attackers usually modify the connection information to complete the interference with the prediction results of the node, we first proposed a method to hide the connection information in the generator, named Anonymized GCN (AN-GCN). By hiding the connection information in the graph structure in the generator through adversarial training, the accurate node prediction can be completed only by the node number rather than its specific position in the graph. Specifically, we first demonstrated the key to determine the embedding of a specific node: the row corresponding to the node of the eigenmatrix of the Laplace matrix, by target it as the output of the generator, we designed a method to hide the node number in the noise. Take the corresponding noise as input, we will obtain the connection structure of the node instead of directly obtaining. Then the encoder and decoder are spliced both in discriminator, so that after adversarial training, the generator and discriminator can cooperate to complete the encoding and decoding of the graph, then complete the node prediction. Finally, All node positions can generated by noise at the same time, that is to say, the generator will hides all the connection information of the graph structure. The evaluation shows that we only need to obtain the initial features and node numbers of the nodes to complete the node prediction, and the accuracy did not decrease, but increased by 0.0293.\nCommunity detection in graphs (S. Fortunato, 2009) S. Fortunato. (2009)\nCommunity detection in graphs\nArXiv\nPaper Link\nInfluential Citation Count (717), SS-ID (9be428c9383d47b86570b1b9fc20faf006346c5d)\nABSTRACT\nThe modern science of networks has brought significant advances to our understanding of complex systems. One of the most relevant features of graphs representing real systems is community structure, or clustering, i. e. the organization of vertices in clusters, with many edges joining vertices of the same cluster and comparatively few edges joining vertices of different clusters. Such clusters, or communities, can be considered as fairly independent compartments of a graph, playing a similar role like, e. g., the tissues or the organs in the human body. Detecting communities is of great importance in sociology, biology and computer science, disciplines where systems are often represented as graphs. This problem is very hard and not yet satisfactorily solved, despite the huge effort of a large interdisciplinary community of scientists working on it over the past few years. We will attempt a thorough exposition of the topic, from the definition of the main elements of the problem, to the presentation of most methods developed, with a special focus on techniques designed by statistical physicists, from the discussion of crucial issues like the significance of clustering and how methods should be tested and compared against each other, to the description of applications to real networks.\nGOSH: Embedding Big Graphs on Small Hardware (Taha Atahan Akyildiz et al., 2020) Taha Atahan Akyildiz, Amro Alabsi Aljundi, K. Kaya. (2020)\nGOSH: Embedding Big Graphs on Small Hardware\nICPP\nPaper Link\nInfluential Citation Count (1), SS-ID (9c1d6253cf83028e00a3d120777263ac2882ad29)\nABSTRACT\nIn graph embedding, the connectivity information of a graph is used to represent each vertex as a point in a d-dimensional space. Unlike the original, irregular structural information, such a representation can be used for a multitude of machine learning tasks. Although the process is extremely useful in practice, it is indeed expensive and unfortunately, the graphs are becoming larger and harder to embed. Attempts at scaling up the process to larger graphs have been successful but often at a steep price in hardware requirements. We present Gosh, an approach for embedding graphs of arbitrary sizes on a single GPU with minimum constraints. Gosh utilizes a novel graph coarsening approach to compress the graph and minimize the work required for embedding, delivering high-quality embeddings at a fraction of the time compared to the state-of-the-art. In addition to this, it incorporates a decomposition schema that enables any arbitrarily large graph to be embedded using a single GPU with minimum constraints on the memory size. With these techniques, Gosh is able to embed a graph with over 65 million vertices and 1.8 billion edges in less than an hour on a single GPU and obtains a 93% AUCROC for link-prediction which can be increased to 95% by running the tool for 80 minutes.\nLaplacian Eigenmaps and Spectral Techniques for Embedding and Clustering (Mikhail Belkin et al., 2001) Mikhail Belkin, P. Niyogi. (2001)\nLaplacian Eigenmaps and Spectral Techniques for Embedding and Clustering\nNIPS\nPaper Link\nInfluential Citation Count (356), SS-ID (9d16c547d15a08091e68c86a99731b14366e3f0d)\nABSTRACT\nDrawing on the correspondence between the graph Laplacian, the Laplace-Beltrami operator on a manifold, and the connections to the heat equation, we propose a geometrically motivated algorithm for constructing a representation for data sampled from a low dimensional manifold embedded in a higher dimensional space. The algorithm provides a computationally efficient approach to nonlinear dimensionality reduction that has locality preserving properties and a natural connection to clustering. Several applications are considered.\nRelational Topic Models for Document Networks (Jonathan Chang et al., 2009) Jonathan Chang, D. Blei. (2009)\nRelational Topic Models for Document Networks\nAISTATS\nPaper Link\nInfluential Citation Count (82), SS-ID (9f68d27df3a4c4be8636f376cb15f77e55a2f496)\nABSTRACT\nWe develop the relational topic model (RTM), a model of documents and the links between them. For each pair of documents, the RTM models their link as a binary random variable that is conditioned on their contents. The model can be used to summarize a network of documents, predict links between them, and predict words within them. We derive efficient inference and learning algorithms based on variational methods and evaluate the predictive performance of the RTM for large networks of scientific abstracts and web documents.\nPredicting Rich Drug-Drug Interactions via Biomedical Knowledge Graphs and Text Jointly Embedding (M. Wang et al., 2017) M. Wang, Yihe Chen, B. Qian, Jun Liu, Sen Wang, Guodong Long, Fei Wang. (2017)\nPredicting Rich Drug-Drug Interactions via Biomedical Knowledge Graphs and Text Jointly Embedding\nArXiv\nPaper Link\nInfluential Citation Count (0), SS-ID (a0344c4d7720757a24932b2d8a1486ff9fddf5d3)\nABSTRACT\nMinimizing adverse reactions caused by drug-drug interactions has always been a momentous research topic in clinical pharmacology. Detecting all possible interactions through clinical studies before a drug is released to the market is a demanding task. The power of big data is opening up new approaches to discover various drug-drug interactions. However, these discoveries contain a huge amount of noise and provide knowledge bases far from complete and trustworthy ones to be utilized. Most existing studies focus on predicting binary drug-drug interactions between drug pairs but ignore other interactions. In this paper, we propose a novel framework, called PRD, to predict drug-drug interactions. The framework uses the graph embedding that can overcome data incompleteness and sparsity issues to achieve multiple DDI label prediction. First, a large-scale drug knowledge graph is generated from different sources. Then, the knowledge graph is embedded with comprehensive biomedical text into a common low dimensional space. Finally, the learned embeddings are used to efficiently compute rich DDI information through a link prediction process. To validate the effectiveness of the proposed framework, extensive experiments were conducted on real-world datasets. The results demonstrate that our model outperforms several state-of-the-art baseline methods in terms of capability and accuracy.\nGraph Convolutional Label Noise Cleaner: Train a Plug-And-Play Action Classifier for Anomaly Detection (Jia-Xing Zhong et al., 2019) Jia-Xing Zhong, Nannan Li, Weijie Kong, Shan Liu, Thomas H. Li, Ge Li. (2019)\nGraph Convolutional Label Noise Cleaner: Train a Plug-And-Play Action Classifier for Anomaly Detection\n2019 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)\nPaper Link\nInfluential Citation Count (22), SS-ID (a03bda078490e8ee991a1f86b53f27df7cf93a14)\nABSTRACT\nVideo anomaly detection under weak labels is formulated as a typical multiple-instance learning problem in previous works. In this paper, we provide a new perspective, i.e., a supervised learning task under noisy labels. In such a viewpoint, as long as cleaning away label noise, we can directly apply fully supervised action classifiers to weakly supervised anomaly detection, and take maximum advantage of these well-developed classifiers. For this purpose, we devise a graph convolutional network to correct noisy labels. Based upon feature similarity and temporal consistency, our network propagates supervisory signals from high-confidence snippets to low-confidence ones. In this manner, the network is capable of providing cleaned supervision for action classifiers. During the test phase, we only need to obtain snippet-wise predictions from the action classifier without any extra post-processing. Extensive experiments on 3 datasets at different scales with 2 types of action classifiers demonstrate the efficacy of our method. Remarkably, we obtain the frame-level AUC score of 82.12% on UCF-Crime.\nSIDE: Representation Learning in Signed Directed Networks (Junghwan Kim et al., 2018) Junghwan Kim, Haekyu Park, Ji-Eun Lee, U. Kang. (2018)\nSIDE: Representation Learning in Signed Directed Networks\nWWW\nPaper Link\nInfluential Citation Count (21), SS-ID (a0da1be7b7665b8c23d80ad2b03815dd708cd7b9)\nABSTRACT\nGiven a signed directed network, how can we learn node representations which fully encode structural information of the network including sign and direction of edges? Node representation learning or network embedding learns a mapping of each node to a vector. The mapping encodes structural information on network, providing low-dimensional dense node features for general machine learning and data mining frameworks. Since many social networks allow trust (friend) and distrust (enemy) relationships described by signed and directed edges, generalizing network embedding method to learn from sign and direction information in networks is crucial. In addition, social theories are critical tool in signed network analysis. However, none of the existing methods supports all of the desired properties: considering sign, direction, and social theoretical interpretation. In this paper, we propose SIDE, a general network embedding method that represents both sign and direction of edges in the embedding space. SIDE carefully formulates and optimizes likelihood over both direct and indirect signed connections. We provide socio-psychological interpretation for each component of likelihood function. We prove linear scalability of our algorithm and propose additional optimization techniques to reduce the training time and improve accuracy. Through extensive experiments on real-world signed directed networks, we show that SIDE effectively encodes structural information into the learned embedding.\nA Survey on Heterogeneous Graph Embedding: Methods, Techniques, Applications and Sources (Xiao Wang et al., 2020) Xiao Wang, Deyu Bo, C. Shi, Shaohua Fan, Yanfang Ye, Philip S. Yu. (2020)\nA Survey on Heterogeneous Graph Embedding: Methods, Techniques, Applications and Sources\nArXiv\nPaper Link\nInfluential Citation Count (0), SS-ID (a11828bb8b2e5f1644360567f0e46d20de342ad6)\nABSTRACT\nHeterogeneous graphs (HGs) also known as heterogeneous information networks have become ubiquitous in real-world scenarios; therefore, HG embedding, which aims to learn representations in a lower-dimension space while preserving the heterogeneous structures and semantics for downstream tasks (e.g., node/graph classification, node clustering, link prediction), has drawn considerable attentions in recent years. In this survey, we perform a comprehensive review of the recent development on HG embedding methods and techniques. We first introduce the basic concepts of HG and discuss the unique challenges brought by the heterogeneity for HG embedding in comparison with homogeneous graph representation learning; and then we systemically survey and categorize the state-of-the-art HG embedding methods based on the information they used in the learning process to address the challenges posed by the HG heterogeneity. In particular, for each representative HG embedding method, we provide detailed introduction and further analyze its pros and cons; meanwhile, we also explore the transformativeness and applicability of different types of HG embedding methods in the real-world industrial environments for the first time. In addition, we further present several widely deployed systems that have demonstrated the success of HG embedding techniques in resolving real-world application problems with broader impacts. To facilitate future research and applications in this area, we also summarize the open-source code, existing graph learning platforms and benchmark datasets. Finally, we explore the additional issues and challenges of HG embedding and forecast the future research directions in this field.\nSTAR-GCN: Stacked and Reconstructed Graph Convolutional Networks for Recommender Systems (Jiani Zhang et al., 2019) Jiani Zhang, Xingjian Shi, Shenglin Zhao, Irwin King. (2019)\nSTAR-GCN: Stacked and Reconstructed Graph Convolutional Networks for Recommender Systems\nIJCAI\nPaper Link\nInfluential Citation Count (10), SS-ID (a3c6926a1d90385b746a16cbb9f0ad6fe714dc1c)\nABSTRACT\nWe propose a new STAcked and Reconstructed Graph Convolutional Networks (STAR-GCN) architecture to learn node representations for boosting the performance in recommender systems, especially in the cold start scenario. STAR-GCN employs a stack of GCN encoder-decoders combined with intermediate supervision to improve the final prediction performance. Unlike the graph convolutional matrix completion model with one-hot encoding node inputs, our STAR-GCN learns low-dimensional user and item latent factors as the input to restrain the model space complexity. Moreover, our STAR-GCN can produce node embeddings for new nodes by reconstructing masked input node embeddings, which essentially tackles the cold start problem. Furthermore, we discover a label leakage issue when training GCN-based models for link prediction tasks and propose a training strategy to avoid the issue. Empirical results on multiple rating prediction benchmarks demonstrate our model achieves state-of-the-art performance in four out of five real-world datasets and significant improvements in predicting ratings in the cold start scenario. The code implementation is available in https://github.com/jennyzhang0215/STAR-GCN.\nLearning Graph-based POI Embedding for Location-based Recommendation (M. Xie et al., 2016) M. Xie, Hongzhi Yin, Hao Wang, Fanjiang Xu, Weitong Chen, Sen Wang. (2016)\nLearning Graph-based POI Embedding for Location-based Recommendation\nCIKM\nPaper Link\nInfluential Citation Count (18), SS-ID (a468d2f55cddbf87c3caf1f9ce45b838e24a8ac7)\nABSTRACT\nWith the rapid prevalence of smart mobile devices and the dramatic proliferation of location-based social networks (LBSNs), location-based recommendation has become an important means to help people discover attractive and interesting points of interest (POIs). However, the extreme sparsity of user-POI matrix and cold-start issue create severe challenges, causing CF-based methods to degrade significantly in their recommendation performance. Moreover, location-based recommendation requires spatiotemporal context awareness and dynamic tracking of the user\u0026rsquo;s latest preferences in a real-time manner. To address these challenges, we stand on recent advances in embedding learning techniques and propose a generic graph-based embedding model, called GE, in this paper. GE jointly captures the sequential effect, geographical influence, temporal cyclic effect and semantic effect in a unified way by embedding the four corresponding relational graphs (POI-POI, POI-Region, POI-Time and POI-Word)into a shared low dimensional space. Then, to support the real-time recommendation, we develop a novel time-decay method to dynamically compute the user\u0026rsquo;s latest preferences based on the embedding of his/her checked-in POIs learnt in the latent space. We conduct extensive experiments to evaluate the performance of our model on two real large-scale datasets, and the experimental results show its superiority over other competitors, especially in recommending cold-start POIs. Besides, we study the contribution of each factor to improve location-based recommendation and find that both sequential effect and temporal cyclic effect play more important roles than geographical influence and semantic effect.\nKnowledge Graph Completion via Complex Tensor Factorization (Théo Trouillon et al., 2017) Théo Trouillon, C. Dance, Éric Gaussier, Johannes Welbl, S. Riedel, Guillaume Bouchard. (2017)\nKnowledge Graph Completion via Complex Tensor Factorization\nJ. Mach. Learn. Res.\nPaper Link\nInfluential Citation Count (29), SS-ID (a4dfb121275a6408d290b803baf8c9caeb23dc5b)\nABSTRACT\nIn statistical relational learning, knowledge graph completion deals with automatically understanding the structure of large knowledge graphs\u0026mdash;labeled directed graphs\u0026mdash;and predicting missing relationships\u0026mdash;labeled edges. State-of-the-art embedding models propose different trade-offs between modeling expressiveness, and time and space complexity. We reconcile both expressiveness and complexity through the use of complex-valued embeddings and explore the link between such complex-valued embeddings and unitary diagonalization. We corroborate our approach theoretically and show that all real square matrices\u0026mdash;thus all possible relation/adjacency matrices\u0026mdash;are the real part of some unitarily diagonalizable matrix. This results opens the door to a lot of other applications of square matrices factorization. Our approach based on complex embeddings is arguably simple, as it only involves a Hermitian dot product, the complex counterpart of the standard dot product between real vectors, whereas other methods resort to more and more complicated composition functions to increase their expressiveness. The proposed complex embeddings are scalable to large data sets as it remains linear in both space and time, while consistently outperforming alternative approaches on standard link prediction benchmarks.\nRelational learning via latent social dimensions (Lei Tang et al., 2009) Lei Tang, Huan Liu. (2009)\nRelational learning via latent social dimensions\nKDD\nPaper Link\nInfluential Citation Count (72), SS-ID (a505e4c2bf30cd88afe483f7541409e2ba5ab3d4)\nABSTRACT\nSocial media such as blogs, Facebook, Flickr, etc., presents data in a network format rather than classical IID distribution. To address the interdependency among data instances, relational learning has been proposed, and collective inference based on network connectivity is adopted for prediction. However, connections in social media are often multi-dimensional. An actor can connect to another actor for different reasons, e.g., alumni, colleagues, living in the same city, sharing similar interests, etc. Collective inference normally does not differentiate these connections. In this work, we propose to extract latent social dimensions based on network information, and then utilize them as features for discriminative learning. These social dimensions describe diverse affiliations of actors hidden in the network, and the discriminative learning can automatically determine which affiliations are better aligned with the class labels. Such a scheme is preferred when multiple diverse relations are associated with the same network. We conduct extensive experiments on social media data (one from a real-world blog site and the other from a popular content sharing site). Our model outperforms representative relational learning methods based on collective inference, especially when few labeled data are available. The sensitivity of this model and its connection to existing methods are also examined.\nStochastic Training of Graph Convolutional Networks with Variance Reduction (Jianfei Chen et al., 2017) Jianfei Chen, Jun Zhu, Le Song. (2017)\nStochastic Training of Graph Convolutional Networks with Variance Reduction\nICML\nPaper Link\nInfluential Citation Count (44), SS-ID (a60c69c2fae27ebbb73c87f7f2a4765556bd7f9f)\nABSTRACT\nGraph convolutional networks (GCNs) are powerful deep neural networks for graph-structured data. However, GCN computes the representation of a node recursively from its neighbors, making the receptive field size grow exponentially with the number of layers. Previous attempts on reducing the receptive field size by subsampling neighbors do not have a convergence guarantee, and their receptive field size per node is still in the order of hundreds. In this paper, we develop control variate based algorithms which allow sampling an arbitrarily small neighbor size. Furthermore, we prove new theoretical guarantee for our algorithms to converge to a local optimum of GCN. Empirical results show that our algorithms enjoy a similar convergence with the exact algorithm using only two neighbors per node. The runtime of our algorithms on a large Reddit dataset is only one seventh of previous neighbor sampling algorithms.\nJoint Node-Edge Network Embedding for Link Prediction (Ilya Makarov et al., 2018) Ilya Makarov, Olga Gerasimova, Pavel Sulimov, Ksenia Korovina, L. Zhukov. (2018)\nJoint Node-Edge Network Embedding for Link Prediction\nAIST\nPaper Link\nInfluential Citation Count (0), SS-ID (a6ef59c8c64adfb82908a31651711d7710b4d93d)\nABSTRACT\nIn this paper, we consider new formulation of graph embedding algorithm, while learning node and edge representation under common constraints. We evaluate our approach on link prediction problem for co-authorship network of HSE researchers’ publications. We compare it with existing structural network embeddings and feature-engineering models.\nDiscriminative Deep Random Walk for Network Classification (Juzheng Li et al., 2016) Juzheng Li, Jun Zhu, Bo Zhang. (2016)\nDiscriminative Deep Random Walk for Network Classification\nACL\nPaper Link\nInfluential Citation Count (2), SS-ID (a6fd225417efdbf0bb9aef2ef2046335d2d0885e)\nABSTRACT\nDeep Random Walk (DeepWalk) can learn a latent space representation for describing the topological structure of a network. However, for relational network classification, DeepWalk can be suboptimal as it lacks a mechanism to optimize the objective of the target task. In this paper, we present Discriminative Deep Random Walk (DDRW), a novel method for relational network classification. By solving a joint optimization problem, DDRW can learn the latent space representations that well capture the topological structure and meanwhile are discriminative for the network classification task. Our experimental results on several real social networks demonstrate that DDRW significantly outperforms DeepWalk on multilabel network classification tasks, while retaining the topological structure in the latent space. DDRW is stable and consistently outperforms the baseline methods by various percentages of labeled data. DDRW is also an online method that is scalable and can be naturally parallelized.\nSplineCNN: Fast Geometric Deep Learning with Continuous B-Spline Kernels (Matthias Fey et al., 2017) Matthias Fey, J. E. Lenssen, F. Weichert, H. Müller. (2017)\nSplineCNN: Fast Geometric Deep Learning with Continuous B-Spline Kernels\n2018 IEEE/CVF Conference on Computer Vision and Pattern Recognition\nPaper Link\nInfluential Citation Count (39), SS-ID (a73531abe4cafbccd5b3e949e84410a50016bd33)\nABSTRACT\nWe present Spline-based Convolutional Neural Networks (SplineCNNs), a variant of deep neural networks for irregular structured and geometric input, e.g., graphs or meshes. Our main contribution is a novel convolution operator based on B-splines, that makes the computation time independent from the kernel size due to the local support property of the B-spline basis functions. As a result, we obtain a generalization of the traditional CNN convolution operator by using continuous kernel functions parametrized by a fixed number of trainable weights. In contrast to related approaches that filter in the spectral domain, the proposed method aggregates features purely in the spatial domain. In addition, SplineCNN allows entire end-to-end training of deep architectures, using only the geometric structure as input, instead of handcrafted feature descriptors. For validation, we apply our method on tasks from the fields of image graph classification, shape correspondence and graph node classification, and show that it outperforms or pars state-of-the-art approaches while being significantly faster and having favorable properties like domain-independence. Our source code is available on GitHub1.\nGL2vec: Graph Embedding Enriched by Line Graphs with Edge Features (Hong Chen et al., 2019) Hong Chen, H. Koga. (2019)\nGL2vec: Graph Embedding Enriched by Line Graphs with Edge Features\nICONIP\nPaper Link\nInfluential Citation Count (5), SS-ID (a7df35d17d05d69e7085d1cfa288a235a8a86be1)\nABSTRACT\nRecently, several techniques to learn the embedding for a given graph dataset have been proposed. Among them, Graph2vec is significant in that it unsupervisedly learns the embedding of entire graphs which is useful for graph classification. This paper develops an algorithm which improves Graph2vec. First, we point out two limitations of Graph2vec: (1) Edge labels cannot be handled and (2) Graph2vec does not always preserve structural information enough to evaluate the structural similarity, because it bundles the node label information and the structural information in extracting subgraphs. Our algorithm overcomes these limitations by exploiting the line graphs (edge-to-vertex dual graphs) of given graphs. Specifically, it complements either the edge label information or the structural information which Graph2vec misses with the embeddings of the line graphs. Our method is named as GL2vec (Graph and Line graph to vector) because it concatenates the embedding of an original graph to that of the corresponding line graph. Experimentally, GL2vec achieves significant improvements in graph classification task over Graph2vec for many benchmark datasets.\nProSNet: integrating homology with molecular networks for protein function prediction (Sheng Wang et al., 2017) Sheng Wang, Meng Qu, Jian Peng. (2017)\nProSNet: integrating homology with molecular networks for protein function prediction\nPSB\nPaper Link\nInfluential Citation Count (0), SS-ID (a7f0d7d7ce9af0e20ab2854563d269bd2beb0cbf)\nABSTRACT\nAutomated annotation of protein function has become a critical task in the post-genomic era. Network-based approaches and homology-based approaches have been widely used and recently tested in large-scale community-wide assessment experiments. It is natural to integrate network data with homology information to further improve the predictive performance. However, integrating these two heterogeneous, high-dimensional and noisy datasets is non-trivial. In this work, we introduce a novel protein function prediction algorithm ProSNet. An integrated heterogeneous network is first built to include molecular networks of multiple species and link together homologous proteins across multiple species. Based on this integrated network, a dimensionality reduction algorithm is introduced to obtain compact low-dimensional vectors to encode proteins in the network. Finally, we develop machine learning classification algorithms that take the vectors as input and make predictions by transferring annotations both within each species and across different species. Extensive experiments on five major species demonstrate that our integration of homology with molecular networks substantially improves the predictive performance over existing approaches.\nCompression of weighted graphs (Hannu (TT) Toivonen et al., 2011) Hannu (TT) Toivonen, Fang Zhou, Aleksi Hartikainen, Atte Hinkka. (2011)\nCompression of weighted graphs\nKDD\nPaper Link\nInfluential Citation Count (14), SS-ID (a8b6b6baaa0d81ed01bb5f387b7ab14f7f234393)\nABSTRACT\nWe propose to compress weighted graphs (networks), motivated by the observation that large networks of social, biological, or other relations can be complex to handle and visualize. In the process also known as graph simplification, nodes and (unweighted) edges are grouped to supernodes and superedges, respectively, to obtain a smaller graph. We propose models and algorithms for weighted graphs. The interpretation (i.e. decompression) of a compressed, weighted graph is that a pair of original nodes is connected by an edge if their supernodes are connected by one, and that the weight of an edge is approximated to be the weight of the superedge. The compression problem now consists of choosing supernodes, superedges, and superedge weights so that the approximation error is minimized while the amount of compression is maximized. In this paper, we formulate this task as the \u0026lsquo;simple weighted graph compression problem\u0026rsquo;. We then propose a much wider class of tasks under the name of \u0026lsquo;generalized weighted graph compression problem\u0026rsquo;. The generalized task extends the optimization to preserve longer-range connectivities between nodes, not just individual edge weights. We study the properties of these problems and propose a range of algorithms to solve them, with different balances between complexity and quality of the result. We evaluate the problems and algorithms experimentally on real networks. The results indicate that weighted graphs can be compressed efficiently with relatively little compression error.\nGraph Convolutional Network with Sequential Attention for Goal-Oriented Dialogue Systems (Suman Banerjee et al., 2019) Suman Banerjee, Mitesh M. Khapra. (2019)\nGraph Convolutional Network with Sequential Attention for Goal-Oriented Dialogue Systems\nTransactions of the Association for Computational Linguistics\nPaper Link\nInfluential Citation Count (0), SS-ID (a9c895dc9d6443588ffd9d6c748215d8c48209a0)\nABSTRACT\nAbstract Domain-specific goal-oriented dialogue systems typically require modeling three types of inputs, namely, (i) the knowledge-base associated with the domain, (ii) the history of the conversation, which is a sequence of utterances, and (iii) the current utterance for which the response needs to be generated. While modeling these inputs, current state-of-the-art models such as Mem2Seq typically ignore the rich structure inherent in the knowledge graph and the sentences in the conversation context. Inspired by the recent success of structure-aware Graph Convolutional Networks (GCNs) for various NLP tasks such as machine translation, semantic role labeling, and document dating, we propose a memory-augmented GCN for goal-oriented dialogues. Our model exploits (i) the entity relation graph in a knowledge-base and (ii) the dependency graph associated with an utterance to compute richer representations for words and entities. Further, we take cognizance of the fact that in certain situations, such as when the conversation is in a code-mixed language, dependency parsers may not be available. We show that in such situations we could use the global word co-occurrence graph to enrich the representations of utterances. We experiment with four datasets: (i) the modified DSTC2 dataset, (ii) recently released code-mixed versions of DSTC2 dataset in four languages, (iii) Wizard-of-Oz style CAM676 dataset, and (iv) Wizard-of-Oz style MultiWOZ dataset. On all four datasets our method outperforms existing methods, on a wide range of evaluation metrics.\nSigned networks in social media (J. Leskovec et al., 2010) J. Leskovec, D. Huttenlocher, J. Kleinberg. (2010)\nSigned networks in social media\nCHI\nPaper Link\nInfluential Citation Count (101), SS-ID (aa3c0e570211d30b26121d5172cef27425ff71ad)\nABSTRACT\nRelations between users on social media sites often reflect a mixture of positive (friendly) and negative (antagonistic) interactions. In contrast to the bulk of research on social networks that has focused almost exclusively on positive interpretations of links between people, we study how the interplay between positive and negative relationships affects the structure of on-line social networks. We connect our analyses to theories of signed networks from social psychology. We find that the classical theory of structural balance tends to capture certain common patterns of interaction, but that it is also at odds with some of the fundamental phenomena we observe \u0026mdash; particularly related to the evolving, directed nature of these on-line networks. We then develop an alternate theory of status that better explains the observed edge signs and provides insights into the underlying social mechanisms. Our work provides one of the first large-scale evaluations of theories of signed networks using on-line datasets, as well as providing a perspective for reasoning about social media sites.\nSpherical and Hyperbolic Embeddings of Data (Richard C. Wilson et al., 2014) Richard C. Wilson, E. Hancock, E. Pekalska, R. Duin. (2014)\nSpherical and Hyperbolic Embeddings of Data\nIEEE Transactions on Pattern Analysis and Machine Intelligence\nPaper Link\nInfluential Citation Count (5), SS-ID (ab0e17513d180a68aad7680b3deea3844176cedc)\nABSTRACT\nMany computer vision and pattern recognition problems may be posed as the analysis of a set of dissimilarities between objects. For many types of data, these dissimilarities are not euclidean (i.e., they do not represent the distances between points in a euclidean space), and therefore cannot be isometrically embedded in a euclidean space. Examples include shape-dissimilarities, graph distances and mesh geodesic distances. In this paper, we provide a means of embedding such non-euclidean data onto surfaces of constant curvature. We aim to embed the data on a space whose radius of curvature is determined by the dissimilarity data. The space can be either of positive curvature (spherical) or of negative curvature (hyperbolic). We give an efficient method for solving the spherical and hyperbolic embedding problems on symmetric dissimilarity data. Our approach gives the radius of curvature and a method for approximating the objects as points on a hyperspherical manifold without optimisation. For objects which do not reside exactly on the manifold, we develop a optimisation-based procedure for approximate embedding on a hyperspherical manifold. We use the exponential map between the manifold and its local tangent space to solve the optimisation problem locally in the euclidean tangent space. This process is efficient enough to allow us to embed data sets of several thousand objects. We apply our method to a variety of data including time warping functions, shape similarities, graph similarity and gesture similarity data. In each case the embedding maintains the local structure of the data while placing the points in a metric space.\nIncorporating Syntactic and Semantic Information in Word Embeddings using Graph Convolutional Networks (Shikhar Vashishth et al., 2018) Shikhar Vashishth, Manik Bhandari, Prateek Yadav, Piyush Rai, C. Bhattacharyya, P. Talukdar. (2018)\nIncorporating Syntactic and Semantic Information in Word Embeddings using Graph Convolutional Networks\nACL\nPaper Link\nInfluential Citation Count (9), SS-ID (ab571a354f0847677862da027a69db9531eb08e8)\nABSTRACT\nWord embeddings have been widely adopted across several NLP applications. Most existing word embedding methods utilize sequential context of a word to learn its embedding. While there have been some attempts at utilizing syntactic context of a word, such methods result in an explosion of the vocabulary size. In this paper, we overcome this problem by proposing SynGCN, a flexible Graph Convolution based method for learning word embeddings. SynGCN utilizes the dependency context of a word without increasing the vocabulary size. Word embeddings learned by SynGCN outperform existing methods on various intrinsic and extrinsic tasks and provide an advantage when used with ELMo. We also propose SemGCN, an effective framework for incorporating diverse semantic knowledge for further enhancing learned word representations. We make the source code of both models available to encourage reproducible research.\nInteractive Recommender System via Knowledge Graph-enhanced Reinforcement Learning (Sijing Zhou et al., 2020) Sijing Zhou, Xinyi Dai, Haokun Chen, Weinan Zhang, Kan Ren, Ruiming Tang, Xiuqiang He, Yong Yu. (2020)\nInteractive Recommender System via Knowledge Graph-enhanced Reinforcement Learning\nSIGIR\nPaper Link\nInfluential Citation Count (5), SS-ID (ac738ab5b57c2e337da303a5e1ec0e2c81c4d963)\nABSTRACT\nInteractive recommender system (IRS) has drawn huge attention because of its flexible recommendation strategy and the consideration of optimal long-term user experiences. To deal with the dynamic user preference and optimize accumulative utilities, researchers have introduced reinforcement learning (RL) into IRS. However, RL methods share a common issue of sample efficiency, i.e., huge amount of interaction data is required to train an effective recommendation policy, which is caused by the sparse user responses and the large action space consisting of a large number of candidate items. Moreover, it is infeasible to collect much data with explorative policies in online environments, which will probably harm user experience. In this work, we investigate the potential of leveraging knowledge graph (KG) in dealing with these issues of RL methods for IRS, which provides rich side information for recommendation decision making. Instead of learning RL policies from scratch, we make use of the prior knowledge of the item correlation learned from KG to (i) guide the candidate selection for better candidate item retrieval, (ii) enrich the representation of items and user states, and (iii) propagate user preferences among the correlated items over KG to deal with the sparsity of user feedback. Comprehensive experiments have been conducted on two real-world datasets, which demonstrate the superiority of our approach with significant improvements against state-of-the-arts.\nTemporalNode2vec: Temporal Node Embedding in Temporal Networks (Mounir Haddad et al., 2019) Mounir Haddad, Cécile Bothorel, P. Lenca, Dominique Bedart. (2019)\nTemporalNode2vec: Temporal Node Embedding in Temporal Networks\nCOMPLEX NETWORKS\nPaper Link\nInfluential Citation Count (0), SS-ID (ad43d8ba1b9619211052615f24da3ecb3c8519db)\nABSTRACT\nThe goal of graph embedding is to learn a representation of graphs vertices in a latent low-dimensional space in order to encode the structural information that lies in graphs. While real-world networks evolve over time, the majority of research focuses on static networks, ignoring local and global evolution patterns. A simplistic approach consists of learning nodes embeddings independently for each time step. This can cause unstable and inefficient representations over time.\nAuthor2Vec: Learning Author Representations by Combining Content and Link Information (Ganesh Jawahar et al., 2016) Ganesh Jawahar, S. Ganguly, Manish Gupta, Vasudeva Varma, Vikram Pudi. (2016)\nAuthor2Vec: Learning Author Representations by Combining Content and Link Information\nWWW\nPaper Link\nInfluential Citation Count (3), SS-ID (aee808e9c5fb20b2dd1a51bb020112cdb908d80b)\nABSTRACT\nIn this paper, we consider the problem of learning representations for authors from bibliographic co-authorship networks. Existing methods for deep learning on graphs, such as DeepWalk, suffer from link sparsity problem as they focus on modeling the link information only. We hypothesize that capturing both the content and link information in a unified way will help mitigate the sparsity problem. To this end, we present a novel model \u0026lsquo;Author2Vec\u0026rsquo;, which learns low-dimensional author representations such that authors who write similar content and share similar network structure are closer in vector space. Such embeddings are useful in a variety of applications such as link prediction, node classification, recommendation and visualization. The author embeddings we learn are empirically shown to outperform DeepWalk by 2.35% and 0.83% for link prediction and clustering task respectively.\nGraPASA: Parametric graph embedding via siamese architecture (Yujun Chen et al., 2020) Yujun Chen, Ke Sun, Juhua Pu, Zhang Xiong, Xiangliang Zhang. (2020)\nGraPASA: Parametric graph embedding via siamese architecture\nInf. Sci.\nPaper Link\nInfluential Citation Count (0), SS-ID (af46a816ad045238c1c8cca734ec9d1f48279d8f)\nABSTRACT\nGraph representation learning or graph embedding is a classical topic in data mining. Current embedding methods are mostly non-parametric, where all the embedding points are unconstrained free points in the target space. These approaches suffer from limited scalability and an over-flexible representation. In this paper, we propose a parametric graph embedding by fusing graph topology information and node content information. The embedding points are obtained through a highly flexible non-linear transformation from node content features to the target space. This transformation is learned using the contrastive loss function of the siamese network to preserve node adjacency in the input graph. On several benchmark network datasets, the proposed GraPASA method shows a significant margin over state-of-the-art techniques on benchmark graph representation tasks.\nExplainable, Stable, and Scalable Graph Convolutional Networks for Learning Graph Representation (Ping-En Lu et al., 2020) Ping-En Lu, Cheng-Shang Chang. (2020)\nExplainable, Stable, and Scalable Graph Convolutional Networks for Learning Graph Representation\nArXiv\nPaper Link\nInfluential Citation Count (0), SS-ID (af4b880f6b30b5510cc78092dcf71d3ea52329e0)\nABSTRACT\nThe network embedding problem that maps nodes in a graph to vectors in Euclidean space can be very useful for addressing several important tasks on a graph. Recently, graph neural networks (GNNs) have been proposed for solving such a problem. However, most embedding algorithms and GNNs are difficult to interpret and do not scale well to handle millions of nodes. In this paper, we tackle the problem from a new perspective based on the equivalence of three constrained optimization problems: the network embedding problem, the trace maximization problem of the modularity matrix in a sampled graph, and the matrix factorization problem of the modularity matrix in a sampled graph. The optimal solutions to these three problems are the dominant eigenvectors of the modularity matrix. We proposed two algorithms that belong to a special class of graph convolutional networks (GCNs) for solving these problems: (i) Clustering As Feature Embedding GCN (CAFE-GCN) and (ii) sphere-GCN. Both algorithms are stable trace maximization algorithms, and they yield good approximations of dominant eigenvectors. Moreover, there are linear-time implementations for sparse graphs. In addition to solving the network embedding problem, both proposed GCNs are capable of performing dimensionality reduction. Various experiments are conducted to evaluate our proposed GCNs and show that our proposed GCNs outperform almost all the baseline methods. Moreover, CAFE-GCN could be benefited from the labeled data and have tremendous improvements in various performance metrics.\nNonlinear dimensionality reduction by locally linear embedding. (S. Roweis et al., 2000) S. Roweis, L. Saul. (2000)\nNonlinear dimensionality reduction by locally linear embedding.\nScience\nPaper Link\nInfluential Citation Count (1523), SS-ID (afcd6da7637ddeef6715109aca248da7a24b1c65)\nABSTRACT\nMany areas of science depend on exploratory data analysis and visualization. The need to analyze large amounts of multivariate data raises the fundamental problem of dimensionality reduction: how to discover compact representations of high-dimensional data. Here, we introduce locally linear embedding (LLE), an unsupervised learning algorithm that computes low-dimensional, neighborhood-preserving embeddings of high-dimensional inputs. Unlike clustering methods for local dimensionality reduction, LLE maps its inputs into a single global coordinate system of lower dimensionality, and its optimizations do not involve local minima. By exploiting the local symmetries of linear reconstructions, LLE is able to learn the global structure of nonlinear manifolds, such as those generated by images of faces or documents of text.\nExponential Family Graph Embeddings (Abdulkadir Çelikkanat et al., 2019) Abdulkadir Çelikkanat, Fragkiskos D. Malliaros. (2019)\nExponential Family Graph Embeddings\nAAAI\nPaper Link\nInfluential Citation Count (0), SS-ID (b176355c33564beb8c7864572877ee4c7dcb40c4)\nABSTRACT\nRepresenting networks in a low dimensional latent space is a crucial task with many interesting applications in graph learning problems, such as link prediction and node classification. A widely applied network representation learning paradigm is based on the combination of random walks for sampling context nodes and the traditional \\textit{Skip-Gram} model to capture center-context node relationships. In this paper, we emphasize on exponential family distributions to capture rich interaction patterns between nodes in random walk sequences. We introduce the generic \\textit{exponential family graph embedding} model, that generalizes random walk-based network representation learning techniques to exponential family conditional distributions. We study three particular instances of this model, analyzing their properties and showing their relationship to existing unsupervised learning models. Our experimental evaluation on real-world datasets demonstrates that the proposed techniques outperform well-known baseline methods in two downstream machine learning tasks.\nCoherent Comments Generation for Chinese Articles with a Graph-to-Sequence Model (Wei Li et al., 2019) Wei Li, Jingjing Xu, Yancheng He, Shengli Yan, Yunfang Wu, Xu Sun. (2019)\nCoherent Comments Generation for Chinese Articles with a Graph-to-Sequence Model\nACL\nPaper Link\nInfluential Citation Count (6), SS-ID (b2125d912941244c243a33e31b01e34467cea457)\nABSTRACT\nAutomatic article commenting is helpful in encouraging user engagement on online news platforms. However, the news documents are usually too long for models under traditional encoder-decoder frameworks, which often results in general and irrelevant comments. In this paper, we propose to generate comments with a graph-to-sequence model that models the input news as a topic interaction graph. By organizing the article into graph structure, our model can better understand the internal structure of the article and the connection between topics, which makes it better able to generate coherent and informative comments. We collect and release a large scale news-comment corpus from a popular Chinese online news platform Tencent Kuaibao. Extensive experiment results show that our model can generate much more coherent and informative comments compared with several strong baseline models.\nFinding and evaluating community structure in networks. (M. Newman et al., 2003) M. Newman, M. Girvan. (2003)\nFinding and evaluating community structure in networks.\nPhysical review. E, Statistical, nonlinear, and soft matter physics\nPaper Link\nInfluential Citation Count (1165), SS-ID (b222526a2990d9073d734e2a1830210ca14cd8bd)\nABSTRACT\nWe propose and study a set of algorithms for discovering community structure in networks-natural divisions of network nodes into densely connected subgroups. Our algorithms all share two definitive features: first, they involve iterative removal of edges from the network to split it into communities, the edges removed being identified using any one of a number of possible \u0026ldquo;betweenness\u0026rdquo; measures, and second, these measures are, crucially, recalculated after each removal. We also propose a measure for the strength of the community structure found by our algorithms, which gives us an objective metric for choosing the number of communities into which a network should be divided. We demonstrate that our algorithms are highly effective at discovering community structure in both computer-generated and real-world network data, and show how they can be used to shed light on the sometimes dauntingly complex structure of networked systems.\nTextbook Question Answering with Knowledge Graph Understanding and Unsupervised Open-set Text Comprehension (Daesik Kim et al., 2018) Daesik Kim, Seonhoon Kim, Nojun Kwak. (2018)\nTextbook Question Answering with Knowledge Graph Understanding and Unsupervised Open-set Text Comprehension\nArXiv\nPaper Link\nInfluential Citation Count (0), SS-ID (b22ce969f203fb548c42034ae7fc78cc043fdc16)\nABSTRACT\nIn this work, we introduce a novel algorithm for solving the textbook question answering (TQA) task which describes more realistic QA problems compared to other recent tasks. We mainly focus on two related issues with analysis of TQA dataset. First, it requires to comprehend long lessons to extract knowledge. To tackle this issue of extracting knowledge features from long lessons, we establish knowledge graph from texts and incorporate graph convolutional network (GCN). Second, scientific terms are not spread over the chapters and data splits in TQA dataset. To overcome this so called `out-of-domain\u0026rsquo; issue, we add novel unsupervised text learning process without any annotations before learning QA problems. The experimental results show that our model significantly outperforms prior state-of-the-art methods. Moreover, ablation studies validate that both methods of incorporating GCN for extracting knowledge from long lessons and our newly proposed unsupervised learning process are meaningful to solve this problem.\nExplicit Semantic Ranking for Academic Search via Knowledge Graph Embedding (Chenyan Xiong et al., 2017) Chenyan Xiong, Russell Power, Jamie Callan. (2017)\nExplicit Semantic Ranking for Academic Search via Knowledge Graph Embedding\nWWW\nPaper Link\nInfluential Citation Count (9), SS-ID (b30481dd5467a187b7e1a5a2dd326d97cafd95ac)\nABSTRACT\nThis paper introduces Explicit Semantic Ranking (ESR), a new ranking technique that leverages knowledge graph embedding. Analysis of the query log from our academic search engine, SemanticScholar.org, reveals that a major error source is its inability to understand the meaning of research concepts in queries. To addresses this challenge, ESR represents queries and documents in the entity space and ranks them based on their semantic connections from their knowledge graph embedding. Experiments demonstrate ESR\u0026rsquo;s ability in improving Semantic Scholar\u0026rsquo;s online production system, especially on hard queries where word-based ranking fails.\nRobust Attribute and Structure Preserving Graph Embedding (B. Hettige et al., 2020) B. Hettige, Weiqing Wang, Yuan-Fang Li, Wray L. Buntine. (2020)\nRobust Attribute and Structure Preserving Graph Embedding\nPAKDD\nPaper Link\nInfluential Citation Count (0), SS-ID (b40f3e3b7bb11949b26fc97febdc2c0d973b8021)\nABSTRACT\nGraph embedding methods are useful for a wide range of graph analysis tasks including link prediction and node classification. Most graph embedding methods learn only the topological structure of graphs. Nevertheless, it has been shown that the incorporation of node attributes is beneficial in improving the expressive power of node embeddings. However, real-world graphs are often noisy in terms of structure and/or attributes (missing and/or erroneous edges/attributes). Most existing graph embedding methods are susceptible to this noise, as they do not consider uncertainty during the modelling process. In this paper, we introduce RASE, a Robust Attribute and Structure preserving graph Embedding model. RASE is a novel graph representation learning model which effectively preserves both graph structure and node attributes through a unified loss function. To be robust, RASE uses a denoising attribute auto-encoder to deal with node attribute noise, and models uncertainty in the embedding space as Gaussians to cope with graph structure noise. We evaluate the performance of RASE through an extensive experimental study on various real-world datasets. Results demonstrate that RASE outperforms state-of-the-art embedding methods on multiple graph analysis tasks and is robust to both structure and attribute noise.\nUnsupervised Graph Representation Learning With Variable Heat Kernel (Yongjun Jing et al., 2020) Yongjun Jing, Hao Wang, Kun Shao, X. Huo, Yangyang Zhang. (2020)\nUnsupervised Graph Representation Learning With Variable Heat Kernel\nIEEE Access\nPaper Link\nInfluential Citation Count (1), SS-ID (b48fa95aa2a63466c87d176ee2caf4e5b975c085)\nABSTRACT\nGraph representation learning aims to learn a low-dimension latent representation of nodes, and the learned representation is used for downstream graph analysis tasks. However, most of the existing graph embedding models focus on how to aggregate all the neighborhood node features to encode the semantic information into the representation and neglect the global structural features of the node such as community structure and centrality. In the paper, we propose a novel unsupervised graph representation learning method (VHKRep), where a variable heat kernel is designed to better capture implicit global features via heat diffusion with the different time scale and generate the robust node representation. We conduct extensive experiment on three real-world datasets for node classification and link prediction tasks. Compared with the state-of-the-art seven models, the experimental results demonstrate the effectiveness of our proposed method on both node classification and link prediction tasks.\nCayleyNets: Graph Convolutional Neural Networks With Complex Rational Spectral Filters (R. Levie et al., 2017) R. Levie, Federico Monti, X. Bresson, M. Bronstein. (2017)\nCayleyNets: Graph Convolutional Neural Networks With Complex Rational Spectral Filters\nIEEE Transactions on Signal Processing\nPaper Link\nInfluential Citation Count (25), SS-ID (b5007972c6f5a2294f83357c73e12664dd7c85b3)\nABSTRACT\nThe rise of graph-structured data such as social networks, regulatory networks, citation graphs, and functional brain networks, in combination with resounding success of deep learning in various applications, has brought the interest in generalizing deep learning models to non-Euclidean domains. In this paper, we introduce a new spectral domain convolutional architecture for deep learning on graphs. The core ingredient of our model is a new class of parametric rational complex functions (Cayley polynomials) allowing to efficiently compute spectral filters on graphs that specialize on frequency bands of interest. Our model generates rich spectral filters that are localized in space, scales linearly with the size of the input data for sparsely connected graphs, and can handle different constructions of Laplacian operators. Extensive experimental results show the superior performance of our approach, in comparison to other spectral domain convolutional architectures, on spectral image classification, community detection, vertex classification, and matrix completion tasks.\nReinforcement Learning and Graph Embedding for Binary Truss Topology Optimization Under Stress and Displacement Constraints (K. Hayashi et al., 2020) K. Hayashi, M. Ohsaki. (2020)\nReinforcement Learning and Graph Embedding for Binary Truss Topology Optimization Under Stress and Displacement Constraints\nFrontiers in Built Environment\nPaper Link\nInfluential Citation Count (0), SS-ID (b518e6b261a4272793accb44205eccc86d041e80)\nABSTRACT\nThis paper addresses a combined method of reinforcement learning and graph embedding for binary topology optimization of trusses to minimize total structural volume under stress and displacement constraints. Although conventional deep learning methods owe their success to a convolutional neural network that is capable of capturing higher level latent information from pixels, the convolution is difficult to apply to discrete structures due to their irregular connectivity. Instead, a method based on graph embedding is proposed here to extract the features of bar members. This way, all the members have a feature vector with the same size representing their neighbor information such as connectivity and force flows from the loaded nodes to the supports. The features are used to implement reinforcement learning where an action taker called agent is trained to sequentially eliminate unnecessary members from Level-1 ground structure, where all neighboring nodes are connected by members. The trained agent is capable of finding sub-optimal solutions at a low computational cost, and it is reusable to other trusses with different geometry, topology, and boundary conditions.\nET-GRU: using multi-layer gated recurrent units to identify electron transport proteins (N. Le et al., 2019) N. Le, E. Yapp, Hui-Yuan Yeh. (2019)\nET-GRU: using multi-layer gated recurrent units to identify electron transport proteins\nBMC Bioinformatics\nPaper Link\nInfluential Citation Count (0), SS-ID (b5cc2c4a7409fee41a7ab0d920a3cb2e3e165a27)\nABSTRACT\nBackgroundElectron transport chain is a series of protein complexes embedded in the process of cellular respiration, which is an important process to transfer electrons and other macromolecules throughout the cell. It is also the major process to extract energy via redox reactions in the case of oxidation of sugars. Many studies have determined that the electron transport protein has been implicated in a variety of human diseases, i.e. diabetes, Parkinson, Alzheimer’s disease and so on. Few bioinformatics studies have been conducted to identify the electron transport proteins with high accuracy, however, their performance results require a lot of improvements. Here, we present a novel deep neural network architecture to address this problem.ResultsMost of the previous studies could not use the original position specific scoring matrix (PSSM) profiles to feed into neural networks, leading to a lack of information and the neural networks consequently could not achieve the best results. In this paper, we present a novel approach by using deep gated recurrent units (GRU) on full PSSMs to resolve this problem. Our approach can precisely predict the electron transporters with the cross-validation and independent test accuracy of 93.5 and 92.3%, respectively. Our approach demonstrates superior performance to all of the state-of-the-art predictors on electron transport proteins.ConclusionsThrough the proposed study, we provide ET-GRU, a web server for discriminating electron transport proteins in particular and other protein functions in general. Also, our achievement could promote the use of GRU in computational biology, especially in protein function prediction.\nATP: Directed Graph Embedding with Asymmetric Transitivity Preservation (Jiankai Sun et al., 2018) Jiankai Sun, Bortik Bandyopadhyay, Armin Bashizade, Jiongqian Liang, P. Sadayappan, S. Parthasarathy. (2018)\nATP: Directed Graph Embedding with Asymmetric Transitivity Preservation\nAAAI\nPaper Link\nInfluential Citation Count (4), SS-ID (b764d0070d07957d4b9621988ea3d020e9ecbe36)\nABSTRACT\nDirected graphs have been widely used in Community Question Answering services (CQAs) to model asymmetric relationships among different types of nodes in CQA graphs, e.g., question, answer, user. Asymmetric transitivity is an essential property of directed graphs, since it can play an important role in downstream graph inference and analysis. Question difficulty and user expertise follow the characteristic of asymmetric transitivity. Maintaining such properties, while reducing the graph to a lower dimensional vector embedding space, has been the focus of much recent research. In this paper, we tackle the challenge of directed graph embedding with asymmetric transitivity preservation and then leverage the proposed embedding method to solve a fundamental task in CQAs: how to appropriately route and assign newly posted questions to users with the suitable expertise and interest in CQAs. The technique incorporates graph hierarchy and reachability information naturally by relying on a nonlinear transformation that operates on the core reachability and implicit hierarchy within such graphs. Subsequently, the methodology levers a factorization-based approach to generate two embedding vectors for each node within the graph, to capture the asymmetric transitivity. Extensive experiments show that our framework consistently and significantly outperforms the state-of-the-art baselines on three diverse realworld tasks: link prediction, and question difficulty estimation and expert finding in online forums like Stack Exchange. Particularly, our framework can support inductive embedding learning for newly posted questions (unseen nodes during training), and therefore can properly route and assign these kinds of questions to experts in CQAs.\nPredicting multicellular function through multi-layer tissue networks (M. Zitnik et al., 2017) M. Zitnik, J. Leskovec. (2017)\nPredicting multicellular function through multi-layer tissue networks\nBioinform.\nPaper Link\nInfluential Citation Count (19), SS-ID (b7c4570d7d97f327e7f82fe28100172ec5e94cac)\nABSTRACT\nMotivation: Understanding functions of proteins in specific human tissues is essential for insights into disease diagnostics and therapeutics, yet prediction of tissue‐specific cellular function remains a critical challenge for biomedicine. Results: Here, we present OhmNet, a hierarchy‐aware unsupervised node feature learning approach for multi‐layer networks. We build a multi‐layer network, where each layer represents molecular interactions in a different human tissue. OhmNet then automatically learns a mapping of proteins, represented as nodes, to a neural embedding‐based low‐dimensional space of features. OhmNet encourages sharing of similar features among proteins with similar network neighborhoods and among proteins activated in similar tissues. The algorithm generalizes prior work, which generally ignores relationships between tissues, by modeling tissue organization with a rich multiscale tissue hierarchy. We use OhmNet to study multicellular function in a multi‐layer protein interaction network of 107 human tissues. In 48 tissues with known tissue‐specific cellular functions, OhmNet provides more accurate predictions of cellular function than alternative approaches, and also generates more accurate hypotheses about tissue‐specific protein actions. We show that taking into account the tissue hierarchy leads to improved predictive power. Remarkably, we also demonstrate that it is possible to leverage the tissue hierarchy in order to effectively transfer cellular functions to a functionally uncharacterized tissue. Overall, OhmNet moves from flat networks to multiscale models able to predict a range of phenotypes spanning cellular subsystems. Availability and implementation: Source code and datasets are available at http://snap.stanford.edu/ohmnet. Contact: jure@cs.stanford.edu\nSemi-supervised Learning on Graphs with Generative Adversarial Nets (Ming Ding et al., 2018) Ming Ding, Jie Tang, Jie Zhang. (2018)\nSemi-supervised Learning on Graphs with Generative Adversarial Nets\nCIKM\nPaper Link\nInfluential Citation Count (5), SS-ID (b8da4337c92acda632e8138be1b525a3aef54b85)\nABSTRACT\nWe investigate how generative adversarial nets (GANs) can help semi-supervised learning on graphs. We first provide insights on working principles of adversarial learning over graphs and then present GraphSGAN, a novel approach to semi-supervised learning on graphs. In GraphSGAN, generator and classifier networks play a novel competitive game. At equilibrium, generator generates fake samples in low-density areas between subgraphs. In order to discriminate fake samples from the real, classifier implicitly takes the density property of subgraph into consideration. An efficient adversarial learning algorithm has been developed to improve traditional normalized graph Laplacian regularization with a theoretical guarantee. Experimental results on several different genres of datasets show that the proposed GraphSGAN significantly outperforms several state-of-the-art methods. GraphSGAN can be also trained using mini-batch, thus enjoys the scalability advantage.\nAtrributed Graph Embedding Based on Multiobjective Evolutionary Algorithm for Overlapping Community Detection (Xiangyi Teng et al., 2020) Xiangyi Teng, Jing Liu. (2020)\nAtrributed Graph Embedding Based on Multiobjective Evolutionary Algorithm for Overlapping Community Detection\n2020 IEEE Congress on Evolutionary Computation (CEC)\nPaper Link\nInfluential Citation Count (0), SS-ID (b92a31918b95ae220d1b23f0ecc4f0f8cf00599f)\nABSTRACT\nGraph embedding methods aim to represent nodes in the network into a low-dimensional and continuous vector space while preserving the topological structure and varieties of relational information maximally. Nowadays the structural connections of networks and the attribute information about each node are more easily available than before. As a result, many community detection algorithms for attributed networks have been proposed. However, the majority of these methods cannot deal with the overlapping community detection problem, which is one of the most significant issues in the real-world complex network study. In addition, it is quite challenging to make full use of both structural and attribute information instead of only focusing on one part. To this end, in this paper we innovatively combine the graph embedding with multiobjective evolutionary algorithms (MOEAs) for overlapping community detection problems in attributed networks. As far as I am concerned, MOEA is first used to integrate with graph embedding methods for overlapping community detection. We term our method as MOEA-GEOV, which can automatically determine the number of communities without any prior knowledge and consider topological structure and vertex properties synchronously. In MOEA-GEOV, two objective functions concerning community structure and attribute similarity are carefully designed. Moreover, a heuristic initialization method is proposed to get a relatively good initial population. Then a novel encoding and decoding strategy is designed to efficiently represent the overlapping communities and corresponding embedded representation. In the experiments, the performance of MOEA-GEOV is validated on both single and multiple attribute real-world networks. The experimental results of community detection tasks demonstrate our method can effectively obtain overlapping community structures with practical significance.\nNormalized cuts and image segmentation (Jianbo Shi et al., 1997) Jianbo Shi, J. Malik. (1997)\nNormalized cuts and image segmentation\nProceedings of IEEE Computer Society Conference on Computer Vision and Pattern Recognition\nPaper Link\nInfluential Citation Count (1462), SS-ID (b94c7ff9532ab26c3aedbee3988ec4c7a237c173)\nABSTRACT\nWe propose a novel approach for solving the perceptual grouping problem in vision. Rather than focusing on local features and their consistencies in the image data, our approach aims at extracting the global impression of an image. We treat image segmentation as a graph partitioning problem and propose a novel global criterion, the normalized cut, for segmenting the graph. The normalized cut criterion measures both the total dissimilarity between the different groups as well as the total similarity within the groups. We show that an efficient computational technique based on a generalized eigenvalue problem can be used to optimize this criterion. We have applied this approach to segmenting static images and found results very encouraging.\nExpert Finding for Community-Based Question Answering via Ranking Metric Network Learning (Zhou Zhao et al., 2016) Zhou Zhao, Qifan Yang, Deng Cai, Xiaofei He, Yueting Zhuang. (2016)\nExpert Finding for Community-Based Question Answering via Ranking Metric Network Learning\nIJCAI\nPaper Link\nInfluential Citation Count (6), SS-ID (b98ae01668cae9c01592dab5993cf04a23f0c91a)\nABSTRACT\nExpert finding for question answering is a challenging problem in Community-based Question Answering (CQA) site, arising in many applications such as question routing and the identification of best answers. In order to provide high-quality experts, many existing approaches learn the user model mainly from their past question-answering activities in CQA sites, which suffer from the sparsity problem of CQA data. In this paper, we consider the problem of expert finding from the viewpoint of learning ranking metric embedding. We propose a novel ranking metric network learning framework for expert finding by exploiting both users\u0026rsquo; relative quality rank to given questions and their social relations. We then develop a random-walk based learning method with recurrent neural networks for ranking metric network embedding. The extensive experiments on a large-scale dataset from a real world CQA site show that our method achieves better performance than other state-of-the-art solutions to the problem.\nLink Prediction Based on Graph Embedding Method in Unweighted Networks (Chencheng Wu et al., 2020) Chencheng Wu, Yinzuo Zhou, Lulu Tan, Cong Teng. (2020)\nLink Prediction Based on Graph Embedding Method in Unweighted Networks\n2020 39th Chinese Control Conference (CCC)\nPaper Link\nInfluential Citation Count (0), SS-ID (ba3159d8791903c7fcf0b6761cacf1be5b5ac927)\nABSTRACT\nThe index of link prediction based on random walk usually has the same transition probability in the process of particle transfer to its neighbor nodes, which has strong randomness and ignores the influence of the particularity of network topology on particle transition probability. In order to resolve this problem, this paper proposes a random walk with restart index based on graph embedding (GERWR). The algorithm uses graph embedding method to randomly sample network nodes and generate node representation vectors containing potential network structure information. By calculating the similarity of node vectors, it redefines a biased transition probability. We apply it to the process of random walk and explore the influence of the particularity of network topology on the transition during the particles walk. Finally, based on biased transition, the index proposed in this paper is compared with five classical similarity indexes in unweighted networks. The results show that the prediction algorithm based on graph embedding method with biased transfer has higher accuracy than other indexes.\nBibliographic Analysis with the Citation Network Topic Model (K. W. Lim et al., 2016) K. W. Lim, Wray L. Buntine. (2016)\nBibliographic Analysis with the Citation Network Topic Model\nACML\nPaper Link\nInfluential Citation Count (2), SS-ID (bca5472054bdcfd838a416448c070f769a373df6)\nABSTRACT\nBibliographic analysis considers author’s research areas, the citation network and paper content among other things. In this paper, we combine these three in a topic model that produces a bibliographic model of authors, topics and documents using a non-parametric extension of a combination of the Poisson mixed-topic link model and the author-topic model. We propose a novel and ecient inference algorithm for the model to explore subsets of research publications from CiteSeer X . Our model demonstrates improved performance in both model tting and a clustering task compared to several baselines.\nNeuro-symbolic representation learning on biological knowledge graphs (Mona Alshahrani et al., 2016) Mona Alshahrani, Mohammed Asif Khan, Omar Maddouri, A. Kinjo, N. Queralt-Rosinach, R. Hoehndorf. (2016)\nNeuro-symbolic representation learning on biological knowledge graphs\nBioinform.\nPaper Link\nInfluential Citation Count (8), SS-ID (bdd297aff687ac360efe28338f5dec884d301221)\nABSTRACT\nMotivation : Biological data and knowledge bases increasingly rely on Semantic Web technologies and the use of knowledge graphs for data integration, retrieval and federated queries. In the past years, feature learning methods that are applicable to graph‐structured data are becoming available, but have not yet widely been applied and evaluated on structured biological knowledge. Results: We develop a novel method for feature learning on biological knowledge graphs. Our method combines symbolic methods, in particular knowledge representation using symbolic logic and automated reasoning, with neural networks to generate embeddings of nodes that encode for related information within knowledge graphs. Through the use of symbolic logic, these embeddings contain both explicit and implicit information. We apply these embeddings to the prediction of edges in the knowledge graph representing problems of function prediction, finding candidate genes of diseases, protein‐protein interactions, or drug target relations, and demonstrate performance that matches and sometimes outperforms traditional approaches based on manually crafted features. Our method can be applied to any biological knowledge graph, and will thereby open up the increasing amount of Semantic Web based knowledge bases in biology to use in machine learning and data analytics. Availability and implementation : https://github.com/bio‐ontology‐research‐group/walking‐rdf‐and‐owl Contact : robert.hoehndorf@kaust.edu.sa Supplementary information: Supplementary data are available at Bioinformatics online.\nMulti-source information fusion based heterogeneous network embedding (Bentian Li et al., 2020) Bentian Li, D. Pi, Yunxia Lin, I. A. Khan, Lin Cui. (2020)\nMulti-source information fusion based heterogeneous network embedding\nInf. Sci.\nPaper Link\nInfluential Citation Count (0), SS-ID (be7bdd550f75acfbdc435e2ca75252779ba9b871)\nABSTRACT\nHeterogeneous network embedding aims to learn a mapping between network data in original topological space and vectored data in low dimensional latent space, while encoding valuable information, such as structural and semantic information. The resulting vector representation has shown promising performance for extensive real-world applications, such as node classification and node clustering. However, most of existing methods merely focus on modeling network structural information, ignoring the rich multi-source information of different types of nodes. In this paper, we propose a novel Multi-source Information Fusion based Heterogeneous Network Embedding (MIFHNE) approach. We first capture the semantic information using the strategy of meta-graph based random walk. Subsequently, we jointly model the structural proximity, attribute information and label information in the framework of Nonnegative Matrix Factorization (NMF). Theoretical proofs and comprehensive experiments on two real-world heterogeneous network datasets demonstrate the feasibility and effectiveness of our approach.\nTemporalGAT: Attention-Based Dynamic Graph Representation Learning (A. Fathy et al., 2020) A. Fathy, Kan Li. (2020)\nTemporalGAT: Attention-Based Dynamic Graph Representation Learning\nPAKDD\nPaper Link\nInfluential Citation Count (0), SS-ID (c06fc165523554b79ce59db9a8ce113b074359a0)\nABSTRACT\nLearning representations for dynamic graphs is fundamental as it supports numerous graph analytic tasks such as dynamic link prediction, node classification, and visualization. Real-world dynamic graphs are continuously evolved where new nodes and edges are introduced or removed during graph evolution. Most existing dynamic graph representation learning methods focus on modeling dynamic graphs with fixed nodes due to the complexity of modeling dynamic graphs, and therefore, cannot efficiently learn the evolutionary patterns of real-world evolving graphs. Moreover, existing methods generally model the structural information of evolving graphs separately from temporal information. This leads to the loss of important structural and temporal information that could cause the degradation of predictive performance of the model. By employing an innovative neural network architecture based on graph attention networks and temporal convolutions, our framework jointly learns graph representations contemplating evolving graph structure and temporal patterns. We propose a deep attention model to learn low-dimensional feature representations which preserves the graph structure and features among series of graph snapshots over time. Experimental results on multiple real-world dynamic graph datasets show that, our proposed method is competitive against various state-of-the-art methods.\nmetapath2vec: Scalable Representation Learning for Heterogeneous Networks (Yuxiao Dong et al., 2017) Yuxiao Dong, N. Chawla, A. Swami. (2017)\nmetapath2vec: Scalable Representation Learning for Heterogeneous Networks\nKDD\nPaper Link\nInfluential Citation Count (164), SS-ID (c0af91371f426ff92117d2ccdadb2032bec23d2c)\nABSTRACT\nWe study the problem of representation learning in heterogeneous networks. Its unique challenges come from the existence of multiple types of nodes and links, which limit the feasibility of the conventional network embedding techniques. We develop two scalable representation learning models, namely metapath2vec and metapath2vec++. The metapath2vec model formalizes meta-path-based random walks to construct the heterogeneous neighborhood of a node and then leverages a heterogeneous skip-gram model to perform node embeddings. The metapath2vec++ model further enables the simultaneous modeling of structural and semantic correlations in heterogeneous networks. Extensive experiments show that metapath2vec and metapath2vec++ are able to not only outperform state-of-the-art embedding models in various heterogeneous network mining tasks, such as node classification, clustering, and similarity search, but also discern the structural and semantic correlations between diverse network objects.\nLarge-Scale Embedding Learning in Heterogeneous Event Data (Huan Gui et al., 2016) Huan Gui, Jialu Liu, Fangbo Tao, Meng Jiang, Brandon Norick, Jiawei Han. (2016)\nLarge-Scale Embedding Learning in Heterogeneous Event Data\n2016 IEEE 16th International Conference on Data Mining (ICDM)\nPaper Link\nInfluential Citation Count (10), SS-ID (c18c30b9b1090e752031d23d219c1007b9954229)\nABSTRACT\nHeterogeneous events, which are defined as events connecting strongly-typed objects, are ubiquitous in the real world. We propose a HyperEdge-Based Embedding (Hebe) framework for heterogeneous event data, where a hyperedge represents the interaction among a set of involving objects in an event. The Hebe framework models the proximity among objects in an event by predicting a target object given the other participating objects in the event (hyperedge). Since each hyperedge encapsulates more information on a given event, Hebe is robust to data sparseness. In addition, Hebe is scalable when the data size spirals. Extensive experiments on large-scale real-world datasets demonstrate the efficacy and robustness of Hebe.\nUnderstanding Coarsening for Embedding Large-Scale Graphs (Taha Atahan Akyildiz et al., 2020) Taha Atahan Akyildiz, Amro Alabsi Aljundi, K. Kaya. (2020)\nUnderstanding Coarsening for Embedding Large-Scale Graphs\n2020 IEEE International Conference on Big Data (Big Data)\nPaper Link\nInfluential Citation Count (0), SS-ID (c23308cf3cfc42002fcb212bcc6f5c9cd3f5d09e)\nABSTRACT\nA significant portion of the data today, e.g, social networks, web connections, etc., can be modeled by graphs. A proper analysis of graphs with Machine Learning (ML) algorithms has the potential to yield far-reaching insights into many areas of research and industry. However, the irregular structure of graph data constitutes an obstacle for running ML tasks on graphs such as link prediction, node classification, and anomaly detection. Graph embedding is a compute-intensive process of representing graphs as a set of vectors in a d-dimensional space, which in turn makes it amenable to ML tasks. Many approaches have been proposed in the literature to improve the performance of graph embedding, e.g., using distributed algorithms, accelerators, and pre-processing techniques. Graph coarsening, which can be considered a pre-processing step, is a structural approximation of a given, large graph with a smaller one. As the literature suggests, the cost of embedding significantly decreases when coarsening is employed. In this work, we thoroughly analyze the impact of the coarsening quality on the embedding performance both in terms of speed and accuracy. Our experiments with a state-of-the-art, fast graph embedding tool show that there is an interplay between the coarsening decisions taken and the embedding quality.\nGraRep: Learning Graph Representations with Global Structural Information (Shaosheng Cao et al., 2015) Shaosheng Cao, Wei Lu, Qiongkai Xu. (2015)\nGraRep: Learning Graph Representations with Global Structural Information\nCIKM\nPaper Link\nInfluential Citation Count (131), SS-ID (c2fd72cb2a77941e655b5d949d0d59b01e173c3b)\nABSTRACT\nIn this paper, we present {GraRep}, a novel model for learning vertex representations of weighted graphs. This model learns low dimensional vectors to represent vertices appearing in a graph and, unlike existing work, integrates global structural information of the graph into the learning process. We also formally analyze the connections between our work and several previous research efforts, including the DeepWalk model of Perozzi et al. as well as the skip-gram model with negative sampling of Mikolov et al. We conduct experiments on a language network, a social network as well as a citation network and show that our learned global representations can be effectively used as features in tasks such as clustering, classification and visualization. Empirical results demonstrate that our representation significantly outperforms other state-of-the-art methods in such tasks.\nPre-training of Graph Augmented Transformers for Medication Recommendation (Junyuan Shang et al., 2019) Junyuan Shang, Tengfei Ma, Cao Xiao, Jimeng Sun. (2019)\nPre-training of Graph Augmented Transformers for Medication Recommendation\nIJCAI\nPaper Link\nInfluential Citation Count (6), SS-ID (c3229debfda1b015c88404cf98f1074237d80809)\nABSTRACT\nMedication recommendation is an important healthcare application. It is commonly formulated as a temporal prediction task. Hence, most existing works only utilize longitudinal electronic health records (EHRs) from a small number of patients with multiple visits ignoring a large number of patients with a single visit (selection bias). Moreover, important hierarchical knowledge such as diagnosis hierarchy is not leveraged in the representation learning process. Despite the success of deep learning techniques in computational phenotyping, most previous approaches have two limitations: task-oriented representation and ignoring hierarchies of medical codes. To address these challenges, we propose G-BERT, a new model to combine the power of Graph Neural Networks (GNNs) and BERT (Bidirectional Encoder Representations from Transformers) for medical code representation and medication recommendation. We use GNNs to represent the internal hierarchical structures of medical codes. Then we integrate the GNN representation into a transformer-based visit encoder and pre-train it on EHR data from patients only with a single visit. The pre-trained visit encoder and representation are then fine-tuned for downstream predictive tasks on longitudinal EHRs from patients with multiple visits. G-BERT is the first to bring the language model pre-training schema into the healthcare domain and it achieved state-of-the-art performance on the medication recommendation task.\nSigned Network Embedding in Social Media (Suhang Wang et al., 2017) Suhang Wang, Jiliang Tang, C. Aggarwal, Yi Chang, Huan Liu. (2017)\nSigned Network Embedding in Social Media\nSDM\nPaper Link\nInfluential Citation Count (22), SS-ID (c34336d3bfb7a3c22caa7958779f40bb2ab70a3d)\nABSTRACT\nNetwork embedding is to learn low-dimensional vector representations for nodes of a given social network, facilitating many tasks in social network analysis such as link prediction. The vast majority of existing embedding algorithms are designed for unsigned social networks or social networks with only positive links. However, networks in social media could have both positive and negative links, and little work exists for signed social networks. From recent findings of signed network analysis, it is evident that negative links have distinct properties and added value besides positive links, which brings about both challenges and opportunities for signed network embedding. In this paper, we propose a deep learning framework SiNE for signed network embedding. The framework optimizes an objective function guided by social theories that provide a fundamental understanding of signed social networks. Experimental results on two realworld datasets of social media demonstrate the effectiveness of the proposed framework SiNE.\nEncoding Sentences with Graph Convolutional Networks for Semantic Role Labeling (Diego Marcheggiani et al., 2017) Diego Marcheggiani, Ivan Titov. (2017)\nEncoding Sentences with Graph Convolutional Networks for Semantic Role Labeling\nEMNLP\nPaper Link\nInfluential Citation Count (79), SS-ID (c3a3c163f25b9181f1fb7e71a32482a7393d2088)\nABSTRACT\nSemantic role labeling (SRL) is the task of identifying the predicate-argument structure of a sentence. It is typically regarded as an important step in the standard NLP pipeline. As the semantic representations are closely related to syntactic ones, we exploit syntactic information in our model. We propose a version of graph convolutional networks (GCNs), a recent class of neural networks operating on graphs, suited to model syntactic dependency graphs. GCNs over syntactic dependency trees are used as sentence encoders, producing latent feature representations of words in a sentence. We observe that GCN layers are complementary to LSTM ones: when we stack both GCN and LSTM layers, we obtain a substantial improvement over an already state-of-the-art LSTM SRL model, resulting in the best reported scores on the standard benchmark (CoNLL-2009) both for Chinese and English.\nCross View Link Prediction by Learning Noise-resilient Representation Consensus (Xiaokai Wei et al., 2017) Xiaokai Wei, Linchuan Xu, Bokai Cao, Philip S. Yu. (2017)\nCross View Link Prediction by Learning Noise-resilient Representation Consensus\nWWW\nPaper Link\nInfluential Citation Count (3), SS-ID (c3d62bcb84fc3a2aa9b8f4691677d7c02738f1bc)\nABSTRACT\nLink Prediction has been an important task for social and information networks. Existing approaches usually assume the completeness of network structure. However, in many real-world networks, the links and node attributes can usually be partially observable. In this paper, we study the problem of Cross View Link Prediction (CVLP) on partially observable networks, where the focus is to recommend nodes with only links to nodes with only attributes (or vice versa). We aim to bridge the information gap by learning a robust consensus for link-based and attribute-based representations so that nodes become comparable in the latent space. Also, the link-based and attribute-based representations can lend strength to each other via this consensus learning. Moreover, attribute selection is performed jointly with the representation learning to alleviate the effect of noisy high-dimensional attributes. We present two instantiations of this framework with different loss functions and develop an alternating optimization framework to solve the problem. Experimental results on four real-world datasets show the proposed algorithm outperforms the baseline methods significantly for cross-view link prediction.\nConvolutional Neural Networks on Graphs with Fast Localized Spectral Filtering (M. Defferrard et al., 2016) M. Defferrard, X. Bresson, P. Vandergheynst. (2016)\nConvolutional Neural Networks on Graphs with Fast Localized Spectral Filtering\nNIPS\nPaper Link\nInfluential Citation Count (544), SS-ID (c41eb895616e453dcba1a70c9b942c5063cc656c)\nABSTRACT\nIn this work, we are interested in generalizing convolutional neural networks (CNNs) from low-dimensional regular grids, where image, video and speech are represented, to high-dimensional irregular domains, such as social networks, brain connectomes or words\u0026rsquo; embedding, represented by graphs. We present a formulation of CNNs in the context of spectral graph theory, which provides the necessary mathematical background and efficient numerical schemes to design fast localized convolutional filters on graphs. Importantly, the proposed technique offers the same linear computational complexity and constant learning complexity as classical CNNs, while being universal to any graph structure. Experiments on MNIST and 20NEWS demonstrate the ability of this novel deep learning system to learn local, stationary, and compositional features on graphs.\nAdversarial Link Prediction in Social Networks (Kai Zhou et al., 2018) Kai Zhou, Tomasz P. Michalak, Talal Rahwan, Marcin Waniek, Y. Vorobeychik. (2018)\nAdversarial Link Prediction in Social Networks\nArXiv\nPaper Link\nInfluential Citation Count (0), SS-ID (c48bc4db8eacb97834c72b5fce3119040da011dc)\nABSTRACT\nLink prediction is one of the fundamental tools in social network analysis, used to identify relationships that are not otherwise observed. Commonly, link prediction is performed by means of a similarity metric, with the idea that a pair of similar nodes are likely to be connected. However, traditional link prediction based on similarity metrics assumes that available network data is accurate. We study the problem of adversarial link prediction, where an adversary aims to hide a target link by removing a limited subset of edges from the observed subgraph. We show that optimal attacks on local similarity metrics\u0026mdash;that is, metrics which use only the information about the node pair and their network neighbors\u0026mdash;can be found in linear time. In contrast, attacking Katz and ACT metrics which use global information about network topology is NP-Hard. We present an approximation algorithm for optimal attacks on Katz similarity, and a principled heuristic for ACT attacks. Extensive experiments demonstrate the efficacy of our methods.\nGraph Convolutional Matrix Completion (Rianne van den Berg et al., 2017) Rianne van den Berg, Thomas Kipf, M. Welling. (2017)\nGraph Convolutional Matrix Completion\nArXiv\nPaper Link\nInfluential Citation Count (121), SS-ID (c509de93b3d34ecd178f598814bd5177a0a29726)\nABSTRACT\nWe consider matrix completion for recommender systems from the point of view of link prediction on graphs. Interaction data such as movie ratings can be represented by a bipartite user-item graph with labeled edges denoting observed ratings. Building on recent progress in deep learning on graph-structured data, we propose a graph auto-encoder framework based on differentiable message passing on the bipartite interaction graph. Our model shows competitive performance on standard collaborative filtering benchmarks. In settings where complimentary feature information or structured data such as a social network is available, our framework outperforms recent state-of-the-art methods.\nCollective Classification in Network Data (P. Sen et al., 2008) P. Sen, Galileo Namata, M. Bilgic, L. Getoor, B. Gallagher, Tina Eliassi-Rad. (2008)\nCollective Classification in Network Data\nAI Mag.\nPaper Link\nInfluential Citation Count (432), SS-ID (c5f2f13778af201f486b0b3c4c8f6fcf36d4ca36)\nABSTRACT\nMany real-world applications produce networked data such as the world-wide web (hypertext documents connected via hyperlinks), social networks (for example, people connected by friendship links), communication networks (computers connected via communication links) and biological networks (for example, protein interaction networks). A recent focus in machine learning research has been to extend traditional machine learning classification techniques to classify nodes in such networks. In this article, we provide a brief introduction to this area of research and how it has progressed during the past decade. We introduce four of the most widely used inference algorithms for classifying networked data and empirically compare them on both synthetic and real-world data.\nMAGNN: Metapath Aggregated Graph Neural Network for Heterogeneous Graph Embedding (Xinyu Fu et al., 2020) Xinyu Fu, Jiani Zhang, Ziqiao Meng, Irwin King. (2020)\nMAGNN: Metapath Aggregated Graph Neural Network for Heterogeneous Graph Embedding\nWWW\nPaper Link\nInfluential Citation Count (42), SS-ID (c7fd29fdd2e0b50a571db4f607eab138e9ecb644)\nABSTRACT\nA large number of real-world graphs or networks are inherently heterogeneous, involving a diversity of node types and relation types. Heterogeneous graph embedding is to embed rich structural and semantic information of a heterogeneous graph into low-dimensional node representations. Existing models usually define multiple metapaths in a heterogeneous graph to capture the composite relations and guide neighbor selection. However, these models either omit node content features, discard intermediate nodes along the metapath, or only consider one metapath. To address these three limitations, we propose a new model named Metapath Aggregated Graph Neural Network (MAGNN) to boost the final performance. Specifically, MAGNN employs three major components, i.e., the node content transformation to encapsulate input node attributes, the intra-metapath aggregation to incorporate intermediate semantic nodes, and the inter-metapath aggregation to combine messages from multiple metapaths. Extensive experiments on three real-world heterogeneous graph datasets for node classification, node clustering, and link prediction show that MAGNN achieves more accurate prediction results than state-of-the-art baselines.\nLearning Community Embedding with Community Detection and Node Embedding on Graphs (Sandro Cavallari et al., 2017) Sandro Cavallari, V. Zheng, Hongyun Cai, K. Chang, E. Cambria. (2017)\nLearning Community Embedding with Community Detection and Node Embedding on Graphs\nCIKM\nPaper Link\nInfluential Citation Count (24), SS-ID (c8cee328b1774c2d38bea10f9fe9d081d8074307)\nABSTRACT\nIn this paper, we study an important yet largely under-explored setting of graph embedding, i.e., embedding communities instead of each individual nodes. We find that community embedding is not only useful for community-level applications such as graph visualization, but also beneficial to both community detection and node classification. To learn such embedding, our insight hinges upon a closed loop among community embedding, community detection and node embedding. On the one hand, node embedding can help improve community detection, which outputs good communities for fitting better community embedding. On the other hand, community embedding can be used to optimize the node embedding by introducing a community-aware high-order proximity. Guided by this insight, we propose a novel community embedding framework that jointly solves the three tasks together. We evaluate such a framework on multiple real-world datasets, and show that it improves graph visualization and outperforms state-of-the-art baselines in various application tasks, e.g., community detection and node classification.\nA Deep Learning Approach to Link Prediction in Dynamic Networks (Xiaoyi Li et al., 2014) Xiaoyi Li, Nan Du, Hui Li, Kang Li, Jing Gao, A. Zhang. (2014)\nA Deep Learning Approach to Link Prediction in Dynamic Networks\nSDM\nPaper Link\nInfluential Citation Count (11), SS-ID (c90dd7731b01b3b486b5a28e1ce9bec547c9cfab)\nABSTRACT\nTime varying problems usually have complex underlying structures represented as dynamic networks where entities and relationships appear and disappear over time. The problem of efficiently performing dynamic link inference is extremely challenging due to the dynamic nature in massive evolving networks especially when there exist sparse connectivities and nonlinear transitional patterns. In this paper, we propose a novel deep learning framework, i.e., Conditional Temporal Restricted Boltzmann Machine (ctRBM), which predicts links based on individual transition variance as well as influence introduced by local neighbors. The proposed model is robust to noise and have the exponential capability to capture nonlinear variance. We tackle the computational challenges by developing an efficient algorithm for learning and inference of the proposed model. To improve the efficiency of the approach, we give a faster approximated implementation based on a proposed Neighbor Influence Clustering algorithm. Extensive experiments on simulated as well as real-world dynamic networks show that the proposed method outperforms existing algorithms in link inference on dynamic networks.\nGraph summarization with bounded error (S. Navlakha et al., 2008) S. Navlakha, R. Rastogi, Nisheeth Shrivastava. (2008)\nGraph summarization with bounded error\nSIGMOD Conference\nPaper Link\nInfluential Citation Count (49), SS-ID (c948d5342f4ffe8163fc91893a100c9617a2a305)\nABSTRACT\nWe propose a highly compact two-part representation of a given graph G consisting of a graph summary and a set of corrections. The graph summary is an aggregate graph in which each node corresponds to a set of nodes in G, and each edge represents the edges between all pair of nodes in the two sets. On the other hand, the corrections portion specifies the list of edge-corrections that should be applied to the summary to recreate G. Our representations allow for both lossless and lossy graph compression with bounds on the introduced error. Further, in combination with the MDL principle, they yield highly intuitive coarse-level summaries of the input graph G. We develop algorithms to construct highly compressed graph representations with small sizes and guaranteed accuracy, and validate our approach through an extensive set of experiments with multiple real-life graph data sets. To the best of our knowledge, this is the first work to compute graph summaries using the MDL principle, and use the summaries (along with corrections) to compress graphs with bounded error.\nIn situ click chemistry generation of cyclooxygenase-2 inhibitors (A. Bhardwaj et al., 2017) A. Bhardwaj, J. Kaur, M. Wuest, F. Wuest. (2017)\nIn situ click chemistry generation of cyclooxygenase-2 inhibitors\nNature Communications\nPaper Link\nInfluential Citation Count (1), SS-ID (c9938045034626c41dd66ad1b5490bff331c1264)\nABSTRACT\nCyclooxygenase-2 isozyme is a promising anti-inflammatory drug target, and overexpression of this enzyme is also associated with several cancers and neurodegenerative diseases. The amino-acid sequence and structural similarity between inducible cyclooxygenase-2 and housekeeping cyclooxygenase-1 isoforms present a significant challenge to design selective cyclooxygenase-2 inhibitors. Herein, we describe the use of the cyclooxygenase-2 active site as a reaction vessel for the in situ generation of its own highly specific inhibitors. Multi-component competitive-binding studies confirmed that the cyclooxygenase-2 isozyme can judiciously select most appropriate chemical building blocks from a pool of chemicals to build its own highly potent inhibitor. Herein, with the use of kinetic target-guided synthesis, also termed as in situ click chemistry, we describe the discovery of two highly potent and selective cyclooxygenase-2 isozyme inhibitors. The in vivo anti-inflammatory activity of these two novel small molecules is significantly higher than that of widely used selective cyclooxygenase-2 inhibitors.Traditional inflammation and pain relief drugs target both cyclooxygenase 1 and 2 (COX-1 and COX-2), causing severe side effects. Here, the authors use in situ click chemistry to develop COX-2 specific inhibitors with high in vivo anti-inflammatory activity.\nHierarchical graph embedding in vector space by graph pyramid (S. F. Mousavi et al., 2017) S. F. Mousavi, M. Safayani, A. Mirzaei, Hoda Bahonar. (2017)\nHierarchical graph embedding in vector space by graph pyramid\nPattern Recognit.\nPaper Link\nInfluential Citation Count (5), SS-ID (c9f22dde51fb01322212708ef00a61ef580e58bd)\nABSTRACT\nLoss of information is the major challenge in graph embedding in vector space which reduces the impact of representational power of graphs in pattern recognition tasks. The objective of this article is to present a hierarchical framework which can decrease this loss in a reasonable computational time. Inspired by multi-resolution ideas in image processing, a graph pyramid is formed based on a selected graph summarization algorithm which can provide the required information for classification. All the pyramid levels or some of them are embedded into a vector through an available embedding method which constructs an informative description containing both local and global features. The experiments are conducted on graphs with numerical and categorical attributes. In the numerical case, a proposed summarization algorithm is applied while in the categorical case, k-SNAP graph summarization is applied. The results indicate that this new framework is efficient in terms of accuracy and time consumption in the context of classification problems. It is observed that this improvement is achieved regardless of selected embedding techniques.\nPrediction of drug–target interaction networks from the integration of chemical and genomic spaces (Yoshihiro Yamanishi et al., 2008) Yoshihiro Yamanishi, M. Araki, Alex Gutteridge, Wataru Honda, M. Kanehisa. (2008)\nPrediction of drug–target interaction networks from the integration of chemical and genomic spaces\nISMB\nPaper Link\nInfluential Citation Count (52), SS-ID (cb239560296d0dc0bea4ccbcc6a4eefa79b8f100)\nABSTRACT\nMotivation: The identification of interactions between drugs and target proteins is a key area in genomic drug discovery. Therefore, there is a strong incentive to develop new methods capable of detecting these potential drug–target interactions efficiently. Results: In this article, we characterize four classes of drug–target interaction networks in humans involving enzymes, ion channels, G-protein-coupled receptors (GPCRs) and nuclear receptors, and reveal significant correlations between drug structure similarity, target sequence similarity and the drug–target interaction network topology. We then develop new statistical methods to predict unknown drug–target interaction networks from chemical structure and genomic sequence information simultaneously on a large scale. The originality of the proposed method lies in the formalization of the drug–target interaction inference as a supervised learning problem for a bipartite graph, the lack of need for 3D structure information of the target proteins, and in the integration of chemical and genomic spaces into a unified space that we call ‘pharmacological space’. In the results, we demonstrate the usefulness of our proposed method for the prediction of the four classes of drug–target interaction networks. Our comprehensively predicted drug–target interaction networks enable us to suggest many potential drug–target interactions and to increase research productivity toward genomic drug discovery. Availability: Softwares are available upon request. Contact: Yoshihiro.Yamanishi@ensmp.fr Supplementary information: Datasets and all prediction results are available at http://web.kuicr.kyoto-u.ac.jp/supp/yoshi/drugtarget/.\nLink prediction for interdisciplinary collaboration via co-authorship network (Haeran Cho et al., 2018) Haeran Cho, Yi Yu. (2018)\nLink prediction for interdisciplinary collaboration via co-authorship network\nSocial Network Analysis and Mining\nPaper Link\nInfluential Citation Count (0), SS-ID (cb805fdd5a00e7a22355c4028f8fdec245831b17)\nABSTRACT\nWe analyse the Publication and Research data set of University of Bristol collected between 2008 and 2013. Using the existing co-authorship network and academic information thereof, we propose a new link prediction methodology, with the specific aim of identifying potential interdisciplinary collaboration in a university-wide collaboration network.\nAttention Models in Graphs (J. B. Lee et al., 2018) J. B. Lee, Ryan A. Rossi, Sungchul Kim, Nesreen Ahmed, Eunyee Koh. (2018)\nAttention Models in Graphs\nACM Trans. Knowl. Discov. Data\nPaper Link\nInfluential Citation Count (1), SS-ID (cc23c580b7d8063415fb6eb512053d1079b849de)\nABSTRACT\nGraph-structured data arise naturally in many different application domains. By representing data as graphs, we can capture entities (i.e., nodes) as well as their relationships (i.e., edges) with each other. Many useful insights can be derived from graph-structured data as demonstrated by an ever-growing body of work focused on graph mining. However, in the real-world, graphs can be both large—with many complex patterns—and noisy, which can pose a problem for effective graph mining. An effective way to deal with this issue is to incorporate “attention” into graph mining solutions. An attention mechanism allows a method to focus on task-relevant parts of the graph, helping it to make better decisions. In this work, we conduct a comprehensive and focused survey of the literature on the emerging field of graph attention models. We introduce three intuitive taxonomies to group existing work. These are based on problem setting (type of input and output), the type of attention mechanism used, and the task (e.g., graph classification, link prediction). We motivate our taxonomies through detailed examples and use each to survey competing approaches from a unique standpoint. Finally, we highlight several challenges in the area and discuss promising directions for future work.\nFast and Deep Graph Neural Networks (C. Gallicchio et al., 2019) C. Gallicchio, A. Micheli. (2019)\nFast and Deep Graph Neural Networks\nAAAI\nPaper Link\nInfluential Citation Count (4), SS-ID (cc56d1210f4ee7a5a351cf64eb3bbed18b48b22f)\nABSTRACT\nWe address the efficiency issue for the construction of a deep graph neural network (GNN). The approach exploits the idea of representing each input graph as a fixed point of a dynamical system (implemented through a recurrent neural network), and leverages a deep architectural organization of the recurrent units. Efficiency is gained by many aspects, including the use of small and very sparse networks, where the weights of the recurrent units are left untrained under the stability condition introduced in this work. This can be viewed as a way to study the intrinsic power of the architecture of a deep GNN, and also to provide insights for the set-up of more complex fully-trained models. Through experimental results, we show that even without training of the recurrent connections, the architecture of small deep GNN is surprisingly able to achieve or improve the state-of-the-art performance on a significant set of tasks in the field of graphs classification.\nA Survey on Network Embedding (Peng Cui et al., 2017) Peng Cui, Xiao Wang, J. Pei, Wenwu Zhu. (2017)\nA Survey on Network Embedding\nIEEE Transactions on Knowledge and Data Engineering\nPaper Link\nInfluential Citation Count (28), SS-ID (ce840188f3395815201b7da49f9bb40d24fc046a)\nABSTRACT\nNetwork embedding assigns nodes in a network to low-dimensional representations and effectively preserves the network structure. Recently, a significant amount of progresses have been made toward this emerging network analysis paradigm. In this survey, we focus on categorizing and then reviewing the current development on network embedding methods, and point out its future research directions. We first summarize the motivation of network embedding. We discuss the classical graph embedding algorithms and their relationship with network embedding. Afterwards and primarily, we provide a comprehensive overview of a large number of network embedding methods in a systematic manner, covering the structure- and property-preserving network embedding methods, the network embedding methods with side information, and the advanced information preserving network embedding methods. Moreover, several evaluation approaches for network embedding and some useful online resources, including the network data sets and softwares, are reviewed, too. Finally, we discuss the framework of exploiting these network embedding methods to build an effective system and point out some potential future directions.\nLink prediction in social networks: the state-of-the-art (Peng Wang et al., 2014) Peng Wang, Baowen Xu, Yu Wu, Xiaoyu Zhou. (2014)\nLink prediction in social networks: the state-of-the-art\nScience China Information Sciences\nPaper Link\nInfluential Citation Count (23), SS-ID (cfe701c64e4ff1d7e5b58a194b02d595b65ce872)\nABSTRACT\nIn social networks, link prediction predicts missing links in current networks and new or dissolution links in future networks, is important for mining and analyzing the evolution of social networks. In the past decade, many works have been done about the link prediction in social networks. The goal of this paper is to comprehensively review, analyze and discuss the state-of-the-art of the link prediction in social networks. A systematical category for link prediction techniques and problems is presented. Then link prediction techniques and problems are analyzed and discussed. Typical applications of link prediction are also addressed. Achievements and roadmaps of some active research groups are introduced. Finally, some future challenges of the link prediction in social networks are discussed.创新点对社交网络中的链接预测研究现状进行系统回顾、分析和讨论, 并指出未来研究挑战. 在动态社交网络中, 链接预测是挖掘和分析网络演化的一项重要任务, 其目的是预测当前未知的链接以及未来链接的变化. 过去十余年中, 在社交网络链接预测问题上已有大量研究工作. 本文旨在对该问题的研究现状和趋势进行全面回顾、分析和讨论. 提出一种分类法组织链接预测技术和问题. 详细分析和讨论了链接预测的技术、问题和应用. 介绍了该问题的活跃研究组. 分析和讨论了社交网络链接预测研究的未来挑战.\nStructural Deep Network Embedding (Daixin Wang et al., 2016) Daixin Wang, Peng Cui, Wenwu Zhu. (2016)\nStructural Deep Network Embedding\nKDD\nPaper Link\nInfluential Citation Count (223), SS-ID (d0b7c8828f0fca4dd901674e8fb5bd464a187664)\nABSTRACT\nNetwork embedding is an important method to learn low-dimensional representations of vertexes in networks, aiming to capture and preserve the network structure. Almost all the existing network embedding methods adopt shallow models. However, since the underlying network structure is complex, shallow models cannot capture the highly non-linear network structure, resulting in sub-optimal network representations. Therefore, how to find a method that is able to effectively capture the highly non-linear network structure and preserve the global and local structure is an open yet important problem. To solve this problem, in this paper we propose a Structural Deep Network Embedding method, namely SDNE. More specifically, we first propose a semi-supervised deep model, which has multiple layers of non-linear functions, thereby being able to capture the highly non-linear network structure. Then we propose to exploit the first-order and second-order proximity jointly to preserve the network structure. The second-order proximity is used by the unsupervised component to capture the global network structure. While the first-order proximity is used as the supervised information in the supervised component to preserve the local network structure. By jointly optimizing them in the semi-supervised deep model, our method can preserve both the local and global network structure and is robust to sparse networks. Empirically, we conduct the experiments on five real-world networks, including a language network, a citation network and three social networks. The results show that compared to the baselines, our method can reconstruct the original network significantly better and achieves substantial gains in three applications, i.e. multi-label classification, link prediction and visualization.\nFast Sequence-Based Embedding with Diffusion Graphs (Benedek Rozemberczki et al., 2018) Benedek Rozemberczki, R. Sarkar. (2018)\nFast Sequence-Based Embedding with Diffusion Graphs\nArXiv\nPaper Link\nInfluential Citation Count (5), SS-ID (d1764864dc0a676ff1732972e179fb2d8d4f564b)\nABSTRACT\nA graph embedding is a representation of graph vertices in a low- dimensional space, which approximately preserves properties such as distances between nodes. Vertex sequence-based embedding procedures use features extracted from linear sequences of nodes to create embeddings using a neural network. In this paper, we propose diffusion graphs as a method to rapidly generate vertex sequences for network embedding. Its computational efficiency is superior to previous methods due to simpler sequence generation, and it produces more accurate results. In experiments, we found that the performance relative to other methods improves with increasing edge density in the graph. In a community detection task, clustering nodes in the embedding space produces better results compared to other sequence-based embedding methods.\nHierarchical Graph Representation Learning with Differentiable Pooling (Rex Ying et al., 2018) Rex Ying, Jiaxuan You, Christopher Morris, Xiang Ren, William L. Hamilton, J. Leskovec. (2018)\nHierarchical Graph Representation Learning with Differentiable Pooling\nNeurIPS\nPaper Link\nInfluential Citation Count (183), SS-ID (d18b48f77eb5c517a6d2c1fa434d2952a1b0a825)\nABSTRACT\nRecently, graph neural networks (GNNs) have revolutionized the field of graph representation learning through effectively learned node embeddings, and achieved state-of-the-art results in tasks such as node classification and link prediction. However, current GNN methods are inherently flat and do not learn hierarchical representations of graphs\u0026mdash;a limitation that is especially problematic for the task of graph classification, where the goal is to predict the label associated with an entire graph. Here we propose DiffPool, a differentiable graph pooling module that can generate hierarchical representations of graphs and can be combined with various graph neural network architectures in an end-to-end fashion. DiffPool learns a differentiable soft cluster assignment for nodes at each layer of a deep GNN, mapping nodes to a set of clusters, which then form the coarsened input for the next GNN layer. Our experimental results show that combining existing GNN methods with DiffPool yields an average improvement of 5-10% accuracy on graph classification benchmarks, compared to all existing pooling approaches, achieving a new state-of-the-art on four out of five benchmark datasets.\nUsing deep neural networks and biological subwords to detect protein S-sulfenylation sites (D. Do et al., 2020) D. Do, Trang T. Le, N. Le. (2020)\nUsing deep neural networks and biological subwords to detect protein S-sulfenylation sites\nBriefings Bioinform.\nPaper Link\nInfluential Citation Count (0), SS-ID (d1e34705c7b26b40ba9bd2b1bdb2239b66da9045)\nABSTRACT\nProtein S-sulfenylation is one kind of crucial post-translational modifications (PTMs) in which the hydroxyl group covalently binds to the thiol of cysteine. Some recent studies have shown that this modification plays an important role in signaling transduction, transcriptional regulation and apoptosis. To date, the dynamic of sulfenic acids in proteins remains unclear because of its fleeting nature. Identifying S-sulfenylation sites, therefore, could be the key to decipher its mysterious structures and functions, which are important in cell biology and diseases. However, due to the lack of effective methods, scientists in this field tend to be limited in merely a handful of some wet lab techniques that are time-consuming and not cost-effective. Thus, this motivated us to develop an in silico model for detecting S-sulfenylation sites only from protein sequence information. In this study, protein sequences served as natural language sentences comprising biological subwords. The deep neural network was consequentially employed to perform classification. The performance statistics within the independent dataset including sensitivity, specificity, accuracy, Matthews correlation coefficient and area under the curve rates achieved 85.71%, 69.47%, 77.09%, 0.5554 and 0.833, respectively. Our results suggested that the proposed method (fastSulf-DNN) achieved excellent performance in predicting S-sulfenylation sites compared to other well-known tools on a benchmark dataset.\nDynamic Graph Embedding (Sujit Rokka Chhetri et al., 2020) Sujit Rokka Chhetri, Mohammad Abdullah Al Faruque. (2020)\nDynamic Graph Embedding\nPaper Link\nInfluential Citation Count (0), SS-ID (d28823f812b83ac957ac5077216766cba29d211d)\nABSTRACT\nIn Chap. 9, we presented a structural graph convolutional neural network which is capable of performing supervising learning to estimate a function between non-euclidean data and categorical data. In this chapter, we focus on non-euclidean data which are evolving over time. In the cyber-physical system, most of the non-euclidean data (such as engineering data, energy, and signal flow graph, call graph of the firmware, etc.) are always evolving. Hence, it is necessary to utilize algorithms that are capable of handling such temporally evolving non-euclidean data. In this chapter, we present a novel dynamic graph embedding algorithm to handle this issue. In the rest of the chapter, we consider temporally evolving graphs as the non-euclidean data and present an algorithm capable of capturing the pattern of time-varying links.\nModeling By Shortest Data Description* (J. Rissanen, 1978) J. Rissanen. (1978)\nModeling By Shortest Data Description*\nAutom.\nPaper Link\nInfluential Citation Count (402), SS-ID (d382b9c11e5c6a8e173fbeb442545e3be8d3e3a5)\nABSTRACT\nDifferentiating Concepts and Instances for Knowledge Graph Embedding (Xin Lv et al., 2018) Xin Lv, Lei Hou, Juan-Zi Li, Zhiyuan Liu. (2018)\nDifferentiating Concepts and Instances for Knowledge Graph Embedding\nEMNLP\nPaper Link\nInfluential Citation Count (8), SS-ID (d3c287ff061f295ddf8dc3cb02a6f39e301cae3b)\nABSTRACT\nConcepts, which represent a group of different instances sharing common properties, are essential information in knowledge representation. Most conventional knowledge embedding methods encode both entities (concepts and instances) and relations as vectors in a low dimensional semantic space equally, ignoring the difference between concepts and instances. In this paper, we propose a novel knowledge graph embedding model named TransC by differentiating concepts and instances. Specifically, TransC encodes each concept in knowledge graph as a sphere and each instance as a vector in the same semantic space. We use the relative positions to model the relations between concepts and instances (i.e.,instanceOf), and the relations between concepts and sub-concepts (i.e., subClassOf). We evaluate our model on both link prediction and triple classification tasks on the dataset based on YAGO. Experimental results show that TransC outperforms state-of-the-art methods, and captures the semantic transitivity for instanceOf and subClassOf relation. Our codes and datasets can be obtained from https://github.com/davidlvxin/TransC.\nCommunity Preserving Network Embedding (Xiao Wang et al., 2017) Xiao Wang, Peng Cui, Jing Wang, J. Pei, Wenwu Zhu, Shiqiang Yang. (2017)\nCommunity Preserving Network Embedding\nAAAI\nPaper Link\nInfluential Citation Count (52), SS-ID (d3e0d596efd9d19b93d357565a68dfa925dce2bb)\nABSTRACT\nNetwork embedding, aiming to learn the low-dimensional representations of nodes in networks, is of paramount importance in many real applications. One basic requirement of network embedding is to preserve the structure and inherent properties of the networks. While previous network embedding methods primarily preserve the microscopic structure, such as the first- and second-order proximities of nodes, the mesoscopic community structure, which is one of the most prominent feature of networks, is largely ignored. In this paper, we propose a novel Modularized Nonnegative Matrix Factorization (M-NMF) model to incorporate the community structure into network embedding. We exploit the consensus relationship between the representations of nodes and community structure, and then jointly optimize NMF based representation learning model and modularity based community detection model in a unified framework, which enables the learned representations of nodes to preserve both of the microscopic and community structures. We also provide efficient updating rules to infer the parameters of our model, together with the correctness and convergence guarantees. Extensive experimental results on a variety of real-world networks show the superior performance of the proposed method over the state-of-the-arts.\nLink Prediction Methods and Their Accuracy for Different Social Networks and Network Metrics (F. Gao et al., 2015) F. Gao, Katarzyna Musial, C. Cooper, S. Tsoka. (2015)\nLink Prediction Methods and Their Accuracy for Different Social Networks and Network Metrics\nSci. Program.\nPaper Link\nInfluential Citation Count (2), SS-ID (d47e5c2dfb5dcd58e8d0f513807e5671e4607a35)\nABSTRACT\nCurrently, we are experiencing a rapid growth of the number of social-based online systems. The availability of the vast amounts of data gathered in those systems brings new challenges that we face when trying to analyse it. One of the intensively researched topics is the prediction of social connections between users. Although a lot of effort has been made to develop new prediction approaches, the existing methods are not comprehensively analysed. In this paper we investigate the correlation between network metrics and accuracy of different prediction methods. We selected six time-stamped real-world social networks and ten most widely used link prediction methods. The results of the experiments show that the performance of some methods has a strong correlation with certain network metrics. We managed to distinguish \u0026ldquo;prediction friendly\u0026rdquo; networks, for which most of the prediction methods give good performance, as well as \u0026ldquo;prediction unfriendly\u0026rdquo; networks, for which most of the methods result in high prediction error. Correlation analysis between network metrics and prediction accuracy of prediction methods may form the basis of a metalearning system where based on network characteristics it will be able to recommend the right prediction method for a given network.\nPCA versus LDA (Aleix M. Martinez et al., 2001) Aleix M. Martinez, A. Kak. (2001)\nPCA versus LDA\nIEEE Trans. Pattern Anal. Mach. Intell.\nPaper Link\nInfluential Citation Count (241), SS-ID (d544475dc01daa0c4f9847ef72adb8878df8ce99)\nABSTRACT\nIn the context of the appearance-based paradigm for object recognition, it is generally believed that algorithms based on LDA (linear discriminant analysis) are superior to those based on PCA (principal components analysis). In this communication, we show that this is not always the case. We present our case first by using intuitively plausible arguments and, then, by showing actual results on a face database. Our overall conclusion is that when the training data set is small, PCA can outperform LDA and, also, that PCA is less sensitive to different training data sets.\nGraphSAINT: Graph Sampling Based Inductive Learning Method (Hanqing Zeng et al., 2019) Hanqing Zeng, Hongkuan Zhou, Ajitesh Srivastava, R. Kannan, V. Prasanna. (2019)\nGraphSAINT: Graph Sampling Based Inductive Learning Method\nICLR\nPaper Link\nInfluential Citation Count (85), SS-ID (d589e4018278e219733b156d44d0ba881a32195e)\nABSTRACT\nGraph Convolutional Networks (GCNs) are powerful models for learning representations of attributed this http URL scale GCNs to large graphs, state-of-the-art methods use various layer sampling techniques to alleviate the \u0026ldquo;neighbor explosion\u0026rdquo; problem during minibatch training. Here we proposeGraphSAINT, a graph sampling based inductive learning method that improves training efficiency in a fundamentally different way. By a change of perspective, GraphSAINT constructs minibatches by sampling the training graph, rather than the nodes or edges across GCN layers. Each iteration, a complete GCN is built from the properly sampled subgraph. Thus, we ensure fixed number of well-connected nodes in all layers. We further propose normalization technique to eliminate bias, and sampling algorithms for variance reduction. Importantly, we can decouple the sampling process from the forward and backward propagation of training, and extend GraphSAINT with other graph samplers and GCN variants. Comparing with strong baselines using layer sampling, GraphSAINT demonstrates superior performance in both accuracy and training time on four large graphs.\nCollective dynamics of ‘small-world’ networks (D. Watts et al., 1998) D. Watts, S. Strogatz. (1998)\nCollective dynamics of ‘small-world’ networks\nNature\nPaper Link\nInfluential Citation Count (2067), SS-ID (d61031326150ba23f90e6587c13d99188209250e)\nABSTRACT\nNetworks of coupled dynamical systems have been used to model biological oscillators, Josephson junction arrays,, excitable media, neural networks, spatial games, genetic control networks and many other self-organizing systems. Ordinarily, the connection topology is assumed to be either completely regular or completely random. But many biological, technological and social networks lie somewhere between these two extremes. Here we explore simple models of networks that can be tuned through this middle ground: regular networks ‘rewired’ to introduce increasing amounts of disorder. We find that these systems can be highly clustered, like regular lattices, yet have small characteristic path lengths, like random graphs. We call them ‘small-world’ networks, by analogy with the small-world phenomenon, (popularly known as six degrees of separation). The neural network of the worm Caenorhabditis elegans, the power grid of the western United States, and the collaboration graph of film actors are shown to be small-world networks. Models of dynamical systems with small-world coupling display enhanced signal-propagation speed, computational power, and synchronizability. In particular, infectious diseases spread more easily in small-world networks than in regular lattices.\nKnowledge Graph Completion with Adaptive Sparse Transfer Matrix (Guoliang Ji et al., 2016) Guoliang Ji, Kang Liu, Shizhu He, Jun Zhao. (2016)\nKnowledge Graph Completion with Adaptive Sparse Transfer Matrix\nAAAI\nPaper Link\nInfluential Citation Count (23), SS-ID (d6e5c0cabb07081e750d6426b649978584918216)\nABSTRACT\nWe model knowledge graphs for their completion by encoding each entity and relation into a numerical space. All previous work including Trans(E, H, R, and D) ignore the heterogeneity (some relations link many entity pairs and others do not) and the imbalance (the number of head entities and that of tail entities in a relation could be different) of knowledge graphs. In this paper, we propose a novel approach TranSparse to deal with the two issues. In TranSparse, transfer matrices are replaced by adaptive sparse matrices, whose sparse degrees are determined by the number of entities (or entity pairs) linked by relations. In experiments, we design structured and unstructured sparse patterns for transfer matrices and analyze their advantages and disadvantages. We evaluate our approach on triplet classification and link prediction tasks. Experimental results show that TranSparse outperforms Trans(E, H, R, and D) significantly, and achieves state-of-the-art performance.\nUniform Pooling for Graph Networks (Jian Qin et al., 2020) Jian Qin, Li Liu, Hui Shen, D. Hu. (2020)\nUniform Pooling for Graph Networks\nPaper Link\nInfluential Citation Count (0), SS-ID (d83c64f96d9a904280534bc3e0c5bd702aab5d94)\nABSTRACT\nThe graph convolution network has received a lot of attention because it extends the convolution to non-Euclidean domains. However, the graph pooling method is still less concerned, which can learn coarse graph embedding to facilitate graph classification. Previous pooling methods were based on assigning a score to each node and then pooling only the highest-scoring nodes, which might throw away whole neighbourhoods of nodes and therefore information. Here, we proposed a novel pooling method UGPool with a new point-of-view on selecting nodes. UGPool learns node scores based on node features and uniformly pools neighboring nodes instead of top nodes in the score-space, resulting in a uniformly coarsened graph. In multiple graph classification tasks, including the protein graphs, the biological graphs and the brain connectivity graphs, we demonstrated that UGPool outperforms other graph pooling methods while maintaining high efficiency. Moreover, we also show that UGPool can be integrated with multiple graph convolution networks to effectively improve performance compared to no pooling.\nGraph Embedding For Link Prediction Using Residual Variational Graph Autoencoders (Reyhan Kevser Keser et al., 2020) Reyhan Kevser Keser, Indrit Nallbani, Nurullah Çalik, Aydin Ayanzadeh, B. Töreyin. (2020)\nGraph Embedding For Link Prediction Using Residual Variational Graph Autoencoders\n2020 28th Signal Processing and Communications Applications Conference (SIU)\nPaper Link\nInfluential Citation Count (0), SS-ID (d94a322106c9161813360d8cfd108ec95e9fad67)\nABSTRACT\nGraphs are usually represented by high dimensional data. Hence, graph embedding is an essential task, which aims to represent a graph in a lower dimension while protecting the original graph\u0026rsquo;s properties. In this paper, we propose a novel graph embedding method called Residual Variational Graph Autoencoder (RVGAE), which boosts variational graph autoencoder\u0026rsquo;s performance utilizing residual connections. Our method\u0026rsquo;s performance is evaluated on the link prediction task. The results demonstrate that our model can achieve better results than graph convolutional neural network (GCN) and variational graph autoencoder (VGAE).\nAligning Users across Social Networks Using Network Embedding (Li Liu et al., 2016) Li Liu, W. K. Cheung, Xin Li, L. Liao. (2016)\nAligning Users across Social Networks Using Network Embedding\nIJCAI\nPaper Link\nInfluential Citation Count (36), SS-ID (da7ee47ee1ccee8080f5827c3c8ee60af90e5fa0)\nABSTRACT\nIn this paper, we adopt the representation learning approach to align users across multiple social networks where the social structures of the users are exploited. In particular, we propose to learn a network embedding with the followership/ followee-ship of each user explicitly modeled as input/output context vector representations so as to preserve the proximity of users with \u0026ldquo;similar\u0026rdquo; followers/followees in the embedded space. For the alignment, we add both known and potential anchor users across the networks to facilitate the transfer of context information across networks. We solve both the network embedding problem and the user alignment problem simultaneously under a unified optimization framework. The stochastic gradient descent and negative sampling algorithms are used to address scalability issues. Extensive experiments on real social network datasets demonstrate the effectiveness and efficiency of the proposed approach compared with several state-of-the-art methods.\nA Unified Feature Selection Framework for Graph Embedding on High Dimensional Data (Marcus Chen et al., 2015) Marcus Chen, I. Tsang, Mingkui Tan, T. Cham. (2015)\nA Unified Feature Selection Framework for Graph Embedding on High Dimensional Data\nIEEE Transactions on Knowledge and Data Engineering\nPaper Link\nInfluential Citation Count (3), SS-ID (dab795b562c7cc270c9099b925d685bea0abe82a)\nABSTRACT\nAlthough graph embedding has been a powerful tool for modeling data intrinsic structures, simply employing all features for data structure discovery may result in noise amplification. This is particularly severe for high dimensional data with small samples. To meet this challenge, this paper proposes a novel efficient framework to perform feature selection for graph embedding, in which a category of graph embedding methods is cast as a least squares regression problem. In this framework, a binary feature selector is introduced to naturally handle the feature cardinality in the least squares formulation. The resultant integral programming problem is then relaxed into a convex Quadratically Constrained Quadratic Program (QCQP) learning problem, which can be efficiently solved via a sequence of accelerated proximal gradient (APG) methods. Since each APG optimization is w.r.t. only a subset of features, the proposed method is fast and memory efficient. The proposed framework is applied to several graph embedding learning problems, including supervised, unsupervised, and semi-supervised graph embedding. Experimental results on several high dimensional data demonstrated that the proposed method outperformed the considered state-of-the-art methods.\nThe Applications of Stochastic Models in Network Embedding: A Survey (Minglong Lei et al., 2018) Minglong Lei, Yong Shi, Lingfeng Niu. (2018)\nThe Applications of Stochastic Models in Network Embedding: A Survey\n2018 IEEE/WIC/ACM International Conference on Web Intelligence (WI)\nPaper Link\nInfluential Citation Count (0), SS-ID (dbc0c4e613d2ae942694058861dd2a4aae6ff117)\nABSTRACT\nNetwork embedding is a promising topic that maps the vertices to the latent space while keeps the structural proximity in the original space. The network embedding task is difficult since the network vertices have no specific time or space orders. Models that used to extract information from images and texts with regular space or time structures can not be directly applied in network heading. The key feature of network embedding methods should be further exploited. Previous network embedding reviews mainly focus on the models and algorithms used in different methods. In this survey, we review the network embedding works in the stochastic perspective either in data side or model side. Roughly, the network embedding methods fall into three main categories: matrix based methods, random walk based methods and aggregated based methods. We focus on the applications of stochastic models in solving the challenges of network embedding in data processing and modeling following the line of the three categories.\nGlobal Vectors for Node Representations (Robin Brochier et al., 2019) Robin Brochier, Adrien Guille, Julien Velcin. (2019)\nGlobal Vectors for Node Representations\nWWW\nPaper Link\nInfluential Citation Count (1), SS-ID (dbdc3e34b5a476d9e760882b7779690b4a987d27)\nABSTRACT\nMost network embedding algorithms consist in measuring co-occur-rences of nodes via random walks then learning the embeddings using Skip-Gram with Negative Sampling. While it has proven to be a relevant choice, there are alternatives, such as GloVe, which has not been investigated yet for network embedding. Even though SGNS better handles non co-occurrence than GloVe, it has a worse time-complexity. In this paper, we propose a matrix factorization approach for network embedding, inspired by GloVe, that better handles non co-occurrence with a competitive time-complexity. We also show how to extend this model to deal with networks where nodes are documents, by simultaneously learning word, node and document representations. Quantitative evaluations show that our model achieves state-of-the-art performance, while not being so sensitive to the choice of hyper-parameters. Qualitatively speaking, we show how our model helps exploring a network of documents by generating complementary network-oriented and content-oriented keywords.\nLearning Deep Network Representations with Adversarially Regularized Autoencoders (Wenchao Yu et al., 2018) Wenchao Yu, Cheng Zheng, Wei Cheng, C. Aggarwal, Dongjin Song, Bo Zong, Haifeng Chen, Wei Wang. (2018)\nLearning Deep Network Representations with Adversarially Regularized Autoencoders\nKDD\nPaper Link\nInfluential Citation Count (6), SS-ID (dbf125bfe07856a63d4aab612c0063fc8c7b6484)\nABSTRACT\nThe problem of network representation learning, also known as network embedding, arises in many machine learning tasks assuming that there exist a small number of variabilities in the vertex representations which can capture the \u0026ldquo;semantics\u0026rdquo; of the original network structure. Most existing network embedding models, with shallow or deep architectures, learn vertex representations from the sampled vertex sequences such that the low-dimensional embeddings preserve the locality property and/or global reconstruction capability. The resultant representations, however, are difficult for model generalization due to the intrinsic sparsity of sampled sequences from the input network. As such, an ideal approach to address the problem is to generate vertex representations by learning a probability density function over the sampled sequences. However, in many cases, such a distribution in a low-dimensional manifold may not always have an analytic form. In this study, we propose to learn the network representations with adversarially regularized autoencoders (NetRA). NetRA learns smoothly regularized vertex representations that well capture the network structure through jointly considering both locality-preserving and global reconstruction constraints. The joint inference is encapsulated in a generative adversarial training process to circumvent the requirement of an explicit prior distribution, and thus obtains better generalization performance. We demonstrate empirically how well key properties of the network structure are captured and the effectiveness of NetRA on a variety of tasks, including network reconstruction, link prediction, and multi-label classification.\nDeep Learning Approaches for Link Prediction in Social Network Services (Feng Liu et al., 2013) Feng Liu, Bingquan Liu, Chengjie Sun, Ming Liu, Xiaolong Wang. (2013)\nDeep Learning Approaches for Link Prediction in Social Network Services\nICONIP\nPaper Link\nInfluential Citation Count (3), SS-ID (dc995128c156b587d9b627e89d413563cd1e05df)\nABSTRACT\nWith the fast development of online Social Network ServicesSNS, social members get large amounts of interactions which can be presented as links with values. The link prediction problem is to estimate the values of unknown links by the known links\u0026rsquo; information. In this paper, based on deep learning approaches, methods for link prediction are proposed. Firstly, an unsupervised method that can works well with little samples is introduced. Secondly, we propose a feature representation method, and the represented features perform better than original ones for link prediction. Thirdly, based on Restricted Boltzmann Machine RBM that present the joint distribution of link samples and their values, we propose a method for link prediction. By the experiments\u0026rsquo; results, our method can predict links\u0026rsquo; values with high accuracy for data from SNS websites.\nHyperbolic embedding of internet graph for distance estimation and overlay construction (Y. Shavitt et al., 2008) Y. Shavitt, Tomer Tankel. (2008)\nHyperbolic embedding of internet graph for distance estimation and overlay construction\nTNET\nPaper Link\nInfluential Citation Count (8), SS-ID (dd1d4e8acfabf225686d294660e0deb0059bdfd7)\nABSTRACT\nEstimating distances in the Internet has been studied in the recent years due to its ability to improve the performance of many applications, e.g., in the peer-to-peer realm. One scalable approach to estimate distances between nodes is to embed the nodes in some d dimensional geometric space and to use the pair distances in this space as the estimate for the real distances. Several algorithms were suggested in the past to do this in low dimensional Euclidean spaces. It was noted in recent years that the Internet structure has a highly connected core and long stretched tendrils, and that most of the routing paths between nodes in the tendrils pass through the core. Therefore, we suggest in this work, to embed the Internet distance metric in a hyperbolic space where routes are bent toward the center. We found that if the curvature, that defines the extend of the bending, is selected in the adequate range, the accuracy of Internet distance embedding can be improved. We demonstrate the strength of our hyperbolic embedding with two applications: selecting the closest server and building an application level multicast tree. For the latter, we present a distributed algorithm for building geometric multicast trees that achieve good trade-offs between delay (stretch) and load (stress). We also present a new efficient centralized embedding algorithm that enables the accurate embedding of short distances, something that have never been done before.\nLanguage Modeling with Graph Temporal Convolutional Networks (Hongyin Luo et al., 2018) Hongyin Luo, Yichen Li, Jie Fu, James R. Glass. (2018)\nLanguage Modeling with Graph Temporal Convolutional Networks\nPaper Link\nInfluential Citation Count (0), SS-ID (de23b3889d121102e463853269ec0bfa7cf4332f)\nABSTRACT\nRecently, there have been some attempts to use non-recurrent neural models for language modeling. However, a noticeable performance gap still remains. We propose a non-recurrent neural language model, dubbed graph temporal convolutional network (GTCN), that relies on graph neural network blocks and convolution operations. While the standard recurrent neural network language models encode sentences sequentially without modeling higher-level structural information, our model regards sentences as graphs and processes input words within a message propagation framework, aiming to learn better syntactic information by inferring skip-word connections. Specifically, the graph network blocks operate in parallel and learn the underlying graph structures in sentences without any additional annotation pertaining to structure knowledge. Experiments demonstrate that the model without recurrence can achieve comparable perplexity results in language modeling tasks and successfully learn syntactic information.\nSpectral Graph Wavelets for Structural Role Similarity in Networks (C. Donnat et al., 2017) C. Donnat, M. Zitnik, David Hallac, J. Leskovec. (2017)\nSpectral Graph Wavelets for Structural Role Similarity in Networks\nArXiv\nPaper Link\nInfluential Citation Count (9), SS-ID (ded841318dbc807c47608a697629fdc4fa3f01da)\nABSTRACT\nNodes residing in different parts of a graph can have similar structural roles within their local network topology. The identification of such roles provides key insight into the organization of networks and can also be used to inform machine learning on graphs. However, learning structural representations of nodes is a challenging unsupervised-learning task, which typically involves manually specifying and tailoring topological features for each node. Here we develop GRAPHWAVE, a method that represents each node’s local network neighborhood via a low-dimensional embedding by leveraging spectral graph wavelet diffusion patterns. We prove that nodes with similar local network neighborhoods will have similar GRAPHWAVE embeddings even though these nodes may reside in very different parts of the network. Our method scales linearly with the number of edges and does not require any hand-tailoring of topological features. We evaluate performance on both synthetic and real-world datasets, obtaining improvements of up to 71% over state-of-the-art baselines.\nBERT: Pre-training of Deep Bidirectional Transformers for Language Understanding (Jacob Devlin et al., 2019) Jacob Devlin, Ming-Wei Chang, Kenton Lee, Kristina Toutanova. (2019)\nBERT: Pre-training of Deep Bidirectional Transformers for Language Understanding\nNAACL\nPaper Link\nInfluential Citation Count (9863), SS-ID (df2b0e26d0599ce3e70df8a9da02e51594e0e992)\nABSTRACT\nWe introduce a new language representation model called BERT, which stands for Bidirectional Encoder Representations from Transformers. Unlike recent language representation models (Peters et al., 2018a; Radford et al., 2018), BERT is designed to pre-train deep bidirectional representations from unlabeled text by jointly conditioning on both left and right context in all layers. As a result, the pre-trained BERT model can be fine-tuned with just one additional output layer to create state-of-the-art models for a wide range of tasks, such as question answering and language inference, without substantial task-specific architecture modifications. BERT is conceptually simple and empirically powerful. It obtains new state-of-the-art results on eleven natural language processing tasks, including pushing the GLUE score to 80.5 (7.7 point absolute improvement), MultiNLI accuracy to 86.7% (4.6% absolute improvement), SQuAD v1.1 question answering Test F1 to 93.2 (1.5 point absolute improvement) and SQuAD v2.0 Test F1 to 83.1 (5.1 point absolute improvement).\nStructure preserving embedding (B. Shaw et al., 2009) B. Shaw, T. Jebara. (2009)\nStructure preserving embedding\nICML \u0026lsquo;09\nPaper Link\nInfluential Citation Count (4), SS-ID (df30fe0aeac5a530c9499598251a3854fe45ee94)\nABSTRACT\nStructure Preserving Embedding (SPE) is an algorithm for embedding graphs in Euclidean space such that the embedding is low-dimensional and preserves the global topological properties of the input graph. Topology is preserved if a connectivity algorithm, such as k-nearest neighbors, can easily recover the edges of the input graph from only the coordinates of the nodes after embedding. SPE is formulated as a semidefinite program that learns a low-rank kernel matrix constrained by a set of linear inequalities which captures the connectivity structure of the input graph. Traditional graph embedding algorithms do not preserve structure according to our definition, and thus the resulting visualizations can be misleading or less informative. SPE provides significant improvements in terms of visualization and lossless compression of graphs, outperforming popular methods such as spectral embedding and Laplacian eigen-maps. We find that many classical graphs and networks can be properly embedded using only a few dimensions. Furthermore, introducing structure preserving constraints into dimensionality reduction algorithms produces more accurate representations of high-dimensional data.\nLearning Deep Representations for Graph Clustering (Fei Tian et al., 2014) Fei Tian, Bin Gao, Qing Cui, Enhong Chen, Tie-Yan Liu. (2014)\nLearning Deep Representations for Graph Clustering\nAAAI\nPaper Link\nInfluential Citation Count (39), SS-ID (df787a974fff59f557ed1ec620fc345568aec491)\nABSTRACT\nRecently deep learning has been successfully adopted in many applications such as speech recognition and image classification. In this work, we explore the possibility of employing deep learning in graph clustering. We propose a simple method, which first learns a nonlinear embedding of the original graph by stacked autoencoder, and then runs k-means algorithm on the embedding to obtain clustering result. We show that this simple method has solid theoretical foundation, due to the similarity between autoencoder and spectral clustering in terms of what they actually optimize. Then, we demonstrate that the proposed method is more efficient and flexible than spectral clustering. First, the computational complexity of autoencoder is much lower than spectral clustering: the former can be linear to the number of nodes in a sparse graph while the latter is super quadratic due to eigenvalue decomposition. Second, when additional sparsity constraint is imposed, we can simply employ the sparse autoencoder developed in the literature of deep learning; however, it is nonstraightforward to implement a sparse spectral method. The experimental results on various graph datasets show that the proposed method significantly outperforms conventional spectral clustering, which clearly indicates the effectiveness of deep learning in graph clustering.\nsubgraph2vec: Learning Distributed Representations of Rooted Sub-graphs from Large Graphs (A. Narayanan et al., 2016) A. Narayanan, Mahinthan Chandramohan, Lihui Chen, Yang Liu, S. Saminathan. (2016)\nsubgraph2vec: Learning Distributed Representations of Rooted Sub-graphs from Large Graphs\nArXiv\nPaper Link\nInfluential Citation Count (11), SS-ID (e02f59cf876cb40233573ff78a1609f969d301cc)\nABSTRACT\nIn this paper, we present subgraph2vec, a novel approach for learning latent representations of rooted subgraphs from large graphs inspired by recent advancements in Deep Learning and Graph Kernels. These latent representations encode semantic substructure dependencies in a continuous vector space, which is easily exploited by statistical models for tasks such as graph classification, clustering, link prediction and community detection. subgraph2vec leverages on local information obtained from neighbourhoods of nodes to learn their latent representations in an unsupervised fashion. We demonstrate that subgraph vectors learnt by our approach could be used in conjunction with classifiers such as CNNs, SVMs and relational data clustering algorithms to achieve significantly superior accuracies. Also, we show that the subgraph vectors could be used for building a deep learning variant of Weisfeiler-Lehman graph kernel. Our experiments on several benchmark and large-scale real-world datasets reveal that subgraph2vec achieves significant improvements in accuracies over existing graph kernels on both supervised and unsupervised learning tasks. Specifically, on two realworld program analysis tasks, namely, code clone and malware detection, subgraph2vec outperforms state-of-the-art kernels by more than 17% and 4%, respectively.\nWhat about statistical relational learning? (CACM staff, 2015) CACM staff. (2015)\nWhat about statistical relational learning?\nCommun. ACM\nPaper Link\nInfluential Citation Count (7), SS-ID (e106966bbf727b7c705288c9a7ef8155bb8a67ab)\nABSTRACT\nletters to the editor the Halting Problem, as well as general program synthesis. I am also accused of ignoring \u0026quot; the entire field of statistical relational learning. \u0026quot; The excellent book Introduction to Statistical Relational Learning, compiled by my former student Lise Getoor and the late Ben Taskar (MIT Press, 2007), has 13 chapters on SRL languages and systems. My article referred to 10 of them. My comment that IBAL was the first probabilistic programming language (PPL) was in no way intended as a slight to Sato\u0026rsquo;s PRISM and Poole\u0026rsquo;s ICL, contributions for which I have the highest respect. My article placed these approaches, along with BLOG, within the tradition of languages for defining probability distributions over logical worlds, as did Sato and Poole. For example, the PRISM website (http://rjida.meijo-u.ac.jp/prism/) says, \u0026quot; The program defines a probability distribution over the set of possible Herbrand interpretations. \u0026quot; My article clearly distinguished this approach from the PPL tradition based on distributions over execution traces of an arbitrary programming language, due to Koller, McAllester, and Pfeffer. Perhaps this is just a matter of terminology, although it seems worthwhile to point out that execution traces need have no relational structure at all. At the time of writing, the extensive bibliography at http://probabilistic-programming.org/research/ does not include the early papers by Sato and Poole, but a broader notion of PPL might well include them. Give Me \u0026lsquo;Naked\u0026rsquo; Braces I was appalled by A. Frank Ackerman\u0026rsquo;s letter to the editor \u0026quot; Ban \u0026lsquo;Naked\u0026rsquo; Braces! \u0026quot; (Oct. 2015), which recommended programmers adopt a policy of always following the closing brace of each code block (presumably, in Algol-like languages like C and Java) with a comment intended to make it clear exactly which code block the closing brace belongs to. However, review article \u0026quot; Unifying Logic and Probability \u0026quot; (July 2015) provided an excellent summary of a number of attempts to unify these two representations, it also gave an incomplete picture of the state of the art. The entire field of statistical relational learning (SRL), which was never mentioned in the article, is devoted to learning logical probabilistic models. Although the article said little is known about com-putationally feasible algorithms for learning the structure of these models , SRL researchers have developed a wide variety of them. Likewise, contrary to the article\u0026rsquo;s statement that generic inference for logical probabi-listic models remains too slow, many efficient algorithms for this purpose …\nNeural Message Passing for Quantum Chemistry (J. Gilmer et al., 2017) J. Gilmer, S. Schoenholz, Patrick F. Riley, Oriol Vinyals, George E. Dahl. (2017)\nNeural Message Passing for Quantum Chemistry\nICML\nPaper Link\nInfluential Citation Count (440), SS-ID (e24cdf73b3e7e590c2fe5ecac9ae8aa983801367)\nABSTRACT\nSupervised learning on molecules has incredible potential to be useful in chemistry, drug discovery, and materials science. Luckily, several promising and closely related neural network models invariant to molecular symmetries have already been described in the literature. These models learn a message passing algorithm and aggregation procedure to compute a function of their entire input graph. At this point, the next step is to find a particularly effective variant of this general approach and apply it to chemical prediction benchmarks until we either solve them or reach the limits of the approach. In this paper, we reformulate existing models into a single common framework we call Message Passing Neural Networks (MPNNs) and explore additional novel variations within this framework. Using MPNNs we demonstrate state of the art results on an important molecular property prediction benchmark; these results are strong enough that we believe future work should focus on datasets with larger molecules or more accurate ground truth labels.\nStructure2vec: Deep Learning for Security Analytics over Graphs (Le Song, 2018) Le Song. (2018)\nStructure2vec: Deep Learning for Security Analytics over Graphs\nPaper Link\nInfluential Citation Count (0), SS-ID (e3dfc4fc64b2e056359a6482930c04cea6c9570a)\nABSTRACT\nAttention Guided Graph Convolutional Networks for Relation Extraction (Zhijiang Guo et al., 2019) Zhijiang Guo, Yan Zhang, Wei Lu. (2019)\nAttention Guided Graph Convolutional Networks for Relation Extraction\nACL\nPaper Link\nInfluential Citation Count (45), SS-ID (e4363d077a890c8d5c5e66b82fe69a1bbbdd5c80)\nABSTRACT\nDependency trees convey rich structural information that is proven useful for extracting relations among entities in text. However, how to effectively make use of relevant information while ignoring irrelevant information from the dependency trees remains a challenging research question. Existing approaches employing rule based hard-pruning strategies for selecting relevant partial dependency structures may not always yield optimal results. In this work, we propose Attention Guided Graph Convolutional Networks (AGGCNs), a novel model which directly takes full dependency trees as inputs. Our model can be understood as a soft-pruning approach that automatically learns how to selectively attend to the relevant sub-structures useful for the relation extraction task. Extensive results on various tasks including cross-sentence n-ary relation extraction and large-scale sentence-level relation extraction show that our model is able to better leverage the structural information of the full dependency trees, giving significantly better results than previous approaches.\nPrincipled Multilayer Network Embedding (Weiyi Liu et al., 2017) Weiyi Liu, Pin-Yu Chen, S. Yeung, T. Suzumura, Lingli Chen. (2017)\nPrincipled Multilayer Network Embedding\n2017 IEEE International Conference on Data Mining Workshops (ICDMW)\nPaper Link\nInfluential Citation Count (14), SS-ID (e445ce942f2cd572aed76160febe35973e0fc42f)\nABSTRACT\nMultilayer network analysis has become a vital tool for understanding different relationships and their interactions in a complex system, where each layer in a multilayer network depicts the topological structure of a group of nodes corresponding to a particular relationship. The interactions among different layers imply how the interplay of different relations on the topology of each layer. For a single-layer network, network embedding methods have been proposed to project the nodes in a network into a continuous vector space with a relatively small number of dimensions, where the space embeds the social representations among nodes. These algorithms have been proved to have a better performance on a variety of regular graph analysis tasks, such as link prediction, or multi-label classification. In this paper, by extending a standard graph mining into multilayer network, we have proposed three methods (\u0026ldquo;network aggregation,\u0026rdquo; \u0026ldquo;results aggregation\u0026rdquo; and \u0026ldquo;layer co-analysis\u0026rdquo;) to project a multilayer network into a continuous vector space. On one hand, without leveraging interactions among layers, \u0026ldquo;network aggregation\u0026rdquo; and \u0026ldquo;results aggregation\u0026rdquo; apply the standard network embedding method on the merged graph or each layer to find a vector space for multilayer network. On the other hand, in order to consider the influence of interactions among layers, \u0026ldquo;layer co-analysis\u0026rdquo; expands any single-layer network embedding method to a multilayer network. By introducing the link transition probability based on information distance, this method not only uses the first and second order random walk to traverse on a layer, but also has the ability to traverse between layers by leveraging interactions. From the evaluation, we have proved that comparing with regular link prediction methods, \u0026ldquo;layer co-analysis\u0026rdquo; achieved the best performance on most of the datasets, while \u0026ldquo;network aggregation\u0026rdquo; and \u0026ldquo;results aggregation\u0026rdquo; also have better performance than regular link prediction methods.\nEmbedding Networks with Edge Attributes (Palash Goyal et al., 2018) Palash Goyal, Homa Hosseinmardi, Emilio Ferrara, A. Galstyan. (2018)\nEmbedding Networks with Edge Attributes\nHT\nPaper Link\nInfluential Citation Count (0), SS-ID (e4853de6d86315073a9e9e5d8957500cd24402c1)\nABSTRACT\nPredicting links in information networks requires deep understanding and careful modeling of network structure. Network embedding, which aims to learn low-dimensional representations of nodes, has been used successfully for the task of link prediction in the past few decades. Existing methods utilize the observed edges in the network to model the interactions between nodes and learn representations which explain the behavior. In addition to the presence of edges, networks often have information which can be used to improve the embedding. For example, in author collaboration networks, the bag of words representing the abstract of co-authored paper can be used as edge attributes. In this paper, we propose a novel approach, which uses the edges and their associated labels to learn node embeddings. Our model jointly optimizes higher order node neighborhood, social roles and edge attributes reconstruction error using deep architecture which can model highly non-linear interactions. We demonstrate the efficacy of our model over existing state-of-the-art methods on two real world data sets. We observe that such attributes can improve the quality of embedding and yield better performance in link prediction.\nDeep Convolutional Networks on Graph-Structured Data (Mikael Henaff et al., 2015) Mikael Henaff, Joan Bruna, Yann LeCun. (2015)\nDeep Convolutional Networks on Graph-Structured Data\nArXiv\nPaper Link\nInfluential Citation Count (55), SS-ID (e49ff72d420c8d72e62a9353e3abc053445e59bd)\nABSTRACT\nDeep Learning\u0026rsquo;s recent successes have mostly relied on Convolutional Networks, which exploit fundamental statistical properties of images, sounds and video data: the local stationarity and multi-scale compositional structure, that allows expressing long range interactions in terms of shorter, localized interactions. However, there exist other important examples, such as text documents or bioinformatic data, that may lack some or all of these strong statistical regularities. In this paper we consider the general question of how to construct deep architectures with small learning complexity on general non-Euclidean domains, which are typically unknown and need to be estimated from the data. In particular, we develop an extension of Spectral Networks which incorporates a Graph Estimation procedure, that we test on large-scale classification problems, matching or improving over Dropout Networks with far less parameters to estimate.\nNetwork embedding in biomedical data science (Chang Su et al., 2018) Chang Su, Jie Tong, Yongjun Zhu, Peng Cui, Fei Wang. (2018)\nNetwork embedding in biomedical data science\nBriefings Bioinform.\nPaper Link\nInfluential Citation Count (2), SS-ID (e4c66275e46a66586365c851f0974a3c88baf3d7)\nABSTRACT\nOwning to the rapid development of computer technologies, an increasing number of relational data have been emerging in modern biomedical research. Many network-based learning methods have been proposed to perform analysis on such data, which provide people a deep understanding of topology and knowledge behind the biomedical networks and benefit a lot of applications for human healthcare. However, most network-based methods suffer from high computational and space cost. There remain challenges on handling high dimensionality and sparsity of the biomedical networks. The latest advances in network embedding technologies provide new effective paradigms to solve the network analysis problem. It converts network into a low-dimensional space while maximally preserves structural properties. In this way, downstream tasks such as link prediction and node classification can be done by traditional machine learning methods. In this survey, we conduct a comprehensive review of the literature on applying network embedding to advance the biomedical domain. We first briefly introduce the widely used network embedding models. After that, we carefully discuss how the network embedding approaches were performed on biomedical networks as well as how they accelerated the downstream tasks in biomedical science. Finally, we discuss challenges the existing network embedding applications in biomedical domains are faced with and suggest several promising future directions for a better improvement in human healthcare.\nEmergence of scaling in random networks (Barabási et al., 1999) Barabási, Albert. (1999)\nEmergence of scaling in random networks\nScience\nPaper Link\nInfluential Citation Count (1960), SS-ID (e50573b554cfa9ee77dcc2e298d7073a152b7199)\nABSTRACT\nSystems as diverse as genetic networks or the World Wide Web are best described as networks with complex topology. A common property of many large networks is that the vertex connectivities follow a scale-free power-law distribution. This feature was found to be a consequence of two generic mechanisms: (i) networks expand continuously by the addition of new vertices, and (ii) new vertices attach preferentially to sites that are already well connected. A model based on these two ingredients reproduces the observed stationary scale-free distributions, which indicates that the development of large networks is governed by robust self-organizing phenomena that go beyond the particulars of the individual systems.\nClique partitions, graph compression and speeding-up algorithms (T. Feder et al., 1991) T. Feder, R. Motwani. (1991)\nClique partitions, graph compression and speeding-up algorithms\nSTOC \u0026lsquo;91\nPaper Link\nInfluential Citation Count (18), SS-ID (e527be9afd581b7e2a4e5b6e6a802be7d7590373)\nABSTRACT\nWe first consider the problem of partitioning the edges of a graph ~ into bipartite cliques such that the total order of the cliques is minimized, where the order of a clique is the number of vertices in it. It is shown that the problem is NP-complete. We then prove the existence of a partition of small total order in a sufficiently dense graph and devise an efilcient algorithm to compute such a partition. It turns out that our algorithm exhibits a trade-off between the total order of the partition and the running time. Next, we define the notion of a compression of a graph ~ and use the result on graph partitioning to efficiently compute an optimal compression for graphs of a given size. An interesting application of the graph compression result arises from the fact that several graph algorithms can be adapted to work with the compressed rep~esentation of the input graph, thereby improving the bound on their running times particularly on dense graphs. This makes use of the trade-off result we obtain from our partitioning algorithm. The algorithms analyzed include those for matchings, vertex connectivity, edge connectivity and shortest paths. In each case, we improve upon the running times of the best-known algorithms for these problems.\nIndexing by Latent Semantic Analysis (S. Deerwester et al., 1990) S. Deerwester, S. Dumais, G. Furnas, T. Landauer, R. Harshman. (1990)\nIndexing by Latent Semantic Analysis\nPaper Link\nInfluential Citation Count (950), SS-ID (e5305866d701a2c102c5f81fbbf48bf6ac29f252)\nABSTRACT\nA new method for automatic indexing and retrieval is described. The approach is to take advantage of implicit higher-order structure in the association of terms with documents (“semantic structure”) in order to improve the detection of relevant documents on the basis of terms found in queries. The particular technique used is singular-value decomposition, in which a large term by document matrix is decomposed into a set of ca. 100 orthogonal factors from which the original matrix can be approximated by linear combination. Documents are represented by ca. 100 item vectors of factor weights. Queries are represented as pseudo-document vectors formed from weighted combinations of terms, and documents with supra-threshold cosine values are returned. initial tests find this completely automatic method for retrieval to be promising.\nDon\u0026#39;t Walk, Skip!: Online Learning of Multi-scale Network Embeddings (Bryan Perozzi et al., 2016) Bryan Perozzi, Vivek Kulkarni, Haochen Chen, S. Skiena. (2016)\nDon\u0026rsquo;t Walk, Skip!: Online Learning of Multi-scale Network Embeddings\nASONAM\nPaper Link\nInfluential Citation Count (11), SS-ID (e75491aba169909922c6e836a39037a5e6be426e)\nABSTRACT\nWe present WALKLETS, a novel approach for learning multiscale representations of vertices in a network. In contrast to previous works, these representations explicitly encode multi-scale vertex relationships in a way that is analytically derivable. WALKLETS generates these multiscale relationships by sub-sampling short random walks on the vertices of a graph. By \u0026lsquo;skipping\u0026rsquo; over steps in each random walk, our method generates a corpus of vertex pairs which are reachable via paths of a fixed length. This corpus can then be used to learn a series of latent representations, each of which captures successively higher order relationships from the adjacency matrix. We demonstrate the efficacy of WALKLETS\u0026rsquo;s latent representations on several multi-label network classification tasks for social networks such as BlogCatalog, DBLP, Flickr, and YouTube. Our results show that WALKLETS outperforms new methods based on neural matrix factorization. Specifically, we outperform DeepWalk by up to 10% and LINE by 58% Micro-F1 on challenging multi-label classification tasks. Finally, WALKLETS is an online algorithm, and can easily scale to graphs with millions of vertices and edges.\nA Survey of Link Prediction in Social Networks (M. Hasan et al., 2011) M. Hasan, Mohammed J. Zaki. (2011)\nA Survey of Link Prediction in Social Networks\nSocial Network Data Analytics\nPaper Link\nInfluential Citation Count (27), SS-ID (e7d30fefe1b99c21813873f976e46d03dc82b4fc)\nABSTRACT\nLink prediction is an important task for analying social networks which also has applications in other domains like, information retrieval, bioinformatics and e-commerce. There exist a variety of techniques for link prediction, ranging from feature-based classification and kernel-based method to matrix factorization and probabilistic graphical models. These methods differ from each other with respect to model complexity, prediction performance, scalability, and generalization ability. In this article, we survey some representative link prediction methods by categorizing them by the type of the models. We largely consider three types of models: first, the traditional (non-Bayesian) models which extract a set of features to train a binary classification model. Second, the probabilistic approaches which model the joint-probability among the entities in a network by Bayesian graphical models. And, finally the linear algebraic approach which computes the similarity between the nodes in a network by rank-reduced similarity matrices. We discuss various existing link prediction models that fall in these broad categories and analyze their strength and weakness. We conclude the survey with a discussion on recent developments and future research direction.\nLearning with Similarity Functions on Graphs using Matchings of Geometric Embeddings (Fredrik D. Johansson et al., 2015) Fredrik D. Johansson, Devdatt P. Dubhashi. (2015)\nLearning with Similarity Functions on Graphs using Matchings of Geometric Embeddings\nKDD\nPaper Link\nInfluential Citation Count (1), SS-ID (e8f16ec1024a6cffbb4e0d57529e9432207d4a5c)\nABSTRACT\nWe develop and apply the Balcan-Blum-Srebro (BBS) theory of classification via similarity functions (which are not necessarily kernels) to the problem of graph classification. First we place the BBS theory into the unifying framework of optimal transport theory. This also opens the way to exploit coupling methods for establishing properties required of a good similarity function as per their definition. Next, we use the approach to the problem of graph classification via geometric embeddings such as the Laplacian, pseudo-inverse Laplacian and the Lovász orthogonal labellings. We consider the similarity function given by optimal and near\u0026ndash;optimal matchings with respect to Euclidean distance of the corresponding embeddings of the graphs in high dimensions. We use optimal couplings to rigorously establish that this yields a \u0026ldquo;good\u0026rdquo; similarity measure in the BBS sense for two well known families of graphs. Further, we show that the similarity yields better classification accuracy in practice, on these families, than matchings of other well-known graph embeddings. Finally we perform an extensive empirical evaluation on benchmark data sets where we show that classifying graphs using matchings of geometric embeddings outperforms the previous state-of-the-art methods.\nDrug-Target Interaction Prediction with Graph Regularized Matrix Factorization (Ali Ezzat et al., 2017) Ali Ezzat, P. Zhao, Min Wu, Xiaoli Li, C. Kwoh. (2017)\nDrug-Target Interaction Prediction with Graph Regularized Matrix Factorization\nIEEE/ACM Transactions on Computational Biology and Bioinformatics\nPaper Link\nInfluential Citation Count (17), SS-ID (e964e8f29e79eb01063836a73dcb6c3c45565914)\nABSTRACT\nExperimental determination of drug-target interactions is expensive and time-consuming. Therefore, there is a continuous demand for more accurate predictions of interactions using computational techniques. Algorithms have been devised to infer novel interactions on a global scale where the input to these algorithms is a drug-target network (i.e., a bipartite graph where edges connect pairs of drugs and targets that are known to interact). However, these algorithms had difficulty predicting interactions involving new drugs or targets for which there are no known interactions (i.e., “orphan” nodes in the network). Since data usually lie on or near to low-dimensional non-linear manifolds, we propose two matrix factorization methods that use graph regularization in order to learn such manifolds. In addition, considering that many of the non-occurring edges in the network are actually unknown or missing cases, we developed a preprocessing step to enhance predictions in the “new drug” and “new target” cases by adding edges with intermediate interaction likelihood scores. In our cross validation experiments, our methods achieved better results than three other state-of-the-art methods in most cases. Finally, we simulated some “new drug” and “new target” cases and found that GRMF predicted the left-out interactions reasonably well.\nDynamics-Preserving Graph Embedding for Community Mining and Network Immunization (Jianan Zhong et al., 2020) Jianan Zhong, Hongjun Qiu, B. Shi. (2020)\nDynamics-Preserving Graph Embedding for Community Mining and Network Immunization\nInf.\nPaper Link\nInfluential Citation Count (0), SS-ID (ebbe61c75100df486632a9518b4c04ff5795aea9)\nABSTRACT\nIn recent years, the graph embedding approach has drawn a lot of attention in the field of network representation and analytics, the purpose of which is to automatically encode network elements into a low-dimensional vector space by preserving certain structural properties. On this basis, downstream machine learning methods can be implemented to solve static network analytic tasks, for example, node clustering based on community-preserving embeddings. However, by focusing only on structural properties, it would be difficult to characterize and manipulate various dynamics operating on the network. In the field of complex networks, epidemic spreading is one of the most typical dynamics in networks, while network immunization is one of the effective methods to suppress the epidemics. Accordingly, in this paper, we present a dynamics-preserving graph embedding method (EpiEm) to preserve the property of epidemic dynamics on networks, i.e., the infectiousness and vulnerability of network nodes. Specifically, we first generate a set of propagation sequences through simulating the Susceptible-Infectious process on a network. Then, we learn node embeddings from an influence matrix using a singular value decomposition method. Finally, we show that the node embeddings can be used to solve epidemics-related community mining and network immunization problems. The experimental results in real-world networks show that the proposed embedding method outperforms several benchmark methods with respect to both community mining and network immunization. The proposed method offers new insights into the exploration of other collective dynamics in complex networks using the graph embedding approach, such as opinion formation in social networks.\nUnsupervised feature selection for linked social media data (Jiliang Tang et al., 2012) Jiliang Tang, Huan Liu. (2012)\nUnsupervised feature selection for linked social media data\nKDD\nPaper Link\nInfluential Citation Count (17), SS-ID (ec8c47ef5797976594c7b784dcad6776743ef014)\nABSTRACT\nThe prevalent use of social media produces mountains of unlabeled, high-dimensional data. Feature selection has been shown effective in dealing with high-dimensional data for efficient data mining. Feature selection for unlabeled data remains a challenging task due to the absence of label information by which the feature relevance can be assessed. The unique characteristics of social media data further complicate the already challenging problem of unsupervised feature selection, (e.g., part of social media data is linked, which makes invalid the independent and identically distributed assumption), bringing about new challenges to traditional unsupervised feature selection algorithms. In this paper, we study the differences between social media data and traditional attribute-value data, investigate if the relations revealed in linked data can be used to help select relevant features, and propose a novel unsupervised feature selection framework, LUFS, for linked social media data. We perform experiments with real-world social media datasets to evaluate the effectiveness of the proposed framework and probe the working of its key components.\nNetwork Embedding With Completely-Imbalanced Labels (Zheng Wang et al., 2020) Zheng Wang, Xiaojun Ye, Chaokun Wang, Jian Cui, Philip S. Yu. (2020)\nNetwork Embedding With Completely-Imbalanced Labels\nIEEE Transactions on Knowledge and Data Engineering\nPaper Link\nInfluential Citation Count (2), SS-ID (ece57b93c36325d909723564044f06986e5553ff)\nABSTRACT\nNetwork embedding, aiming to project a network into a low-dimensional space, is increasingly becoming a focus of network research. Semi-supervised network embedding takes advantage of labeled data, and has shown promising performance. However, existing semi-supervised methods would get unappealing results in the completely-imbalanced label setting where some classes have no labeled nodes at all. To alleviate this, we propose two novel semi-supervised network embedding methods. The first one is a shallow method named RSDNE. Specifically, to benefit from the completely-imbalanced labels, RSDNE guarantees both intra-class similarity and inter-class dissimilarity in an approximate way. The other method is RECT which is a new class of graph neural networks. Different from RSDNE, to benefit from the completely-imbalanced labels, RECT explores the class-semantic knowledge. This enables RECT to handle networks with node features and multi-label setting. Experimental results on several real-world datasets demonstrate the superiority of the proposed methods.\nRepresentation Learning on Graphs: Methods and Applications (William L. Hamilton et al., 2017) William L. Hamilton, Rex Ying, J. Leskovec. (2017)\nRepresentation Learning on Graphs: Methods and Applications\nIEEE Data Eng. Bull.\nPaper Link\nInfluential Citation Count (140), SS-ID (ecf6c42d84351f34e1625a6a2e4cc6526da45c74)\nABSTRACT\nMachine learning on graphs is an important and ubiquitous task with applications ranging from drug design to friendship recommendation in social networks. The primary challenge in this domain is finding a way to represent, or encode, graph structure so that it can be easily exploited by machine learning models. Traditionally, machine learning approaches relied on user-defined heuristics to extract features encoding structural information about a graph (e.g., degree statistics or kernel functions). However, recent years have seen a surge in approaches that automatically learn to encode graph structure into low-dimensional embeddings, using techniques based on deep learning and nonlinear dimensionality reduction. Here we provide a conceptual review of key advancements in this area of representation learning on graphs, including matrix factorization-based methods, random-walk based algorithms, and graph neural networks. We review methods to embed individual nodes as well as approaches to embed entire (sub)graphs. In doing so, we develop a unified framework to describe these recent approaches, and we highlight a number of important applications and directions for future work.\nHARP: Hierarchical Representation Learning for Networks (Haochen Chen et al., 2017) Haochen Chen, Bryan Perozzi, Yifan Hu, S. Skiena. (2017)\nHARP: Hierarchical Representation Learning for Networks\nAAAI\nPaper Link\nInfluential Citation Count (32), SS-ID (ee9cc8e663d650ae96405ad680d6447066e6fb23)\nABSTRACT\nWe present HARP, a novel method for learning low dimensional embeddings of a graph\u0026rsquo;s nodes which preserves higher-order structural features. Our proposed method achieves this by compressing the input graph prior to embedding it, effectively avoiding troublesome embedding configurations (i.e. local minima) which can pose problems to non-convex optimization. HARP works by finding a smaller graph which approximates the global structure of its input. This simplified graph is used to learn a set of initial representations, which serve as good initializations for learning representations in the original, detailed graph. We inductively extend this idea, by decomposing a graph in a series of levels, and then embed the hierarchy of graphs from the coarsest one to the original graph. HARP is a general meta-strategy to improve all of the state-of-the-art neural algorithms for embedding graphs, including DeepWalk, LINE, and Node2vec. Indeed, we demonstrate that applying HARP\u0026rsquo;s hierarchical paradigm yields improved implementations for all three of these methods, as evaluated on both classification tasks on real-world graphs such as DBLP, BlogCatalog, CiteSeer, and Arxiv, where we achieve a performance gain over the original implementations by up to 14% Macro F1.\nExploiting Latent Social Listening Representations for Music Recommendations (Chih-Ming Chen et al., 2015) Chih-Ming Chen, Chien Po-Chuan, Lin Yu-Ching, Tsai Ming-Feng, Yang Yi-Hsuan, 陳志銘, 蔡銘峰. (2015)\nExploiting Latent Social Listening Representations for Music Recommendations\nRecSys 2015\nPaper Link\nInfluential Citation Count (1), SS-ID (effae318686b939a864a9787ffd4fa69b844b8d9)\nABSTRACT\nMusic listening can be regarded as a social activity, in which people can listen together and make friends with one other. Therefore, social relationships may imply multiple facets of the users, such as their listening behaviors and tastes. In this light, it is considered that social relationships hold abundant valuable information that can be utilized for music recommendation. However, utilizing the information for recommendation could be dicult, because such information is usually sparse. To address this issue, we propose to learn the latent social listening representations by the DeepWalk method, and then integrate the learned representations into Factorization Machines to construct better recommendation models. With the DeepWalk method, user social relationships can be transformed from the sparse and independent and identically distributed (i.i.d.) form into a dense and noni.i.d. form. In addition, the latent representations can also capture the spatial locality among users and items, therefore beneting the constructed recommendation models.\nGeometric Deep Learning on Graphs and Manifolds Using Mixture Model CNNs (Federico Monti et al., 2016) Federico Monti, D. Boscaini, Jonathan Masci, E. Rodolà, Jan Svoboda, M. Bronstein. (2016)\nGeometric Deep Learning on Graphs and Manifolds Using Mixture Model CNNs\n2017 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)\nPaper Link\nInfluential Citation Count (121), SS-ID (f09f7888aa5aeaf88a2a44aea768d9a8747e97d2)\nABSTRACT\nDeep learning has achieved a remarkable performance breakthrough in several fields, most notably in speech recognition, natural language processing, and computer vision. In particular, convolutional neural network (CNN) architectures currently produce state-of-the-art performance on a variety of image analysis tasks such as object detection and recognition. Most of deep learning research has so far focused on dealing with 1D, 2D, or 3D Euclidean-structured data such as acoustic signals, images, or videos. Recently, there has been an increasing interest in geometric deep learning, attempting to generalize deep learning methods to non-Euclidean structured data such as graphs and manifolds, with a variety of applications from the domains of network analysis, computational social science, or computer graphics. In this paper, we propose a unified framework allowing to generalize CNN architectures to non-Euclidean domains (graphs and manifolds) and learn local, stationary, and compositional task-specific features. We show that various non-Euclidean CNN methods previously proposed in the literature can be considered as particular instances of our framework. We test the proposed method on standard tasks from the realms of image-, graph-and 3D shape analysis and show that it consistently outperforms previous approaches.\nFastGCN: Fast Learning with Graph Convolutional Networks via Importance Sampling (Jing Chen et al., 2018) Jing Chen, Tengfei Ma, Cao Xiao. (2018)\nFastGCN: Fast Learning with Graph Convolutional Networks via Importance Sampling\nICLR\nPaper Link\nInfluential Citation Count (118), SS-ID (f19d3e0956d0f2daa3396fc6e9e7554a78a90710)\nABSTRACT\nThe graph convolutional networks (GCN) recently proposed by Kipf and Welling are an effective graph model for semi-supervised learning. This model, however, was originally designed to be learned with the presence of both training and test data. Moreover, the recursive neighborhood expansion across layers poses time and memory challenges for training with large, dense graphs. To relax the requirement of simultaneous availability of test data, we interpret graph convolutions as integral transforms of embedding functions under probability measures. Such an interpretation allows for the use of Monte Carlo approaches to consistently estimate the integrals, which in turn leads to a batched training scheme as we propose in this work\u0026mdash;FastGCN. Enhanced with importance sampling, FastGCN not only is efficient for training but also generalizes well for inference. We show a comprehensive set of experiments to demonstrate its effectiveness compared with GCN and related models. In particular, training is orders of magnitude more efficient while predictions remain comparably accurate.\nJoint Learning of Words and Meaning Representations for Open-Text Semantic Parsing (Antoine Bordes et al., 2012) Antoine Bordes, Xavier Glorot, J. Weston, Yoshua Bengio. (2012)\nJoint Learning of Words and Meaning Representations for Open-Text Semantic Parsing\nAISTATS\nPaper Link\nInfluential Citation Count (19), SS-ID (f2f72cfb48d15d4d2bd1e91a92e7f3ac8635d433)\nABSTRACT\nOpen-text semantic parsers are designed to interpret any statement in natural language by inferring a corresponding meaning representation (MR – a formal representation of its sense). Unfortunately, large scale systems cannot be easily machine-learned due to a lack of directly supervised data. We propose a method that learns to assign MRs to a wide range of text (using a dictionary of more than 70,000 words mapped to more than 40,000 entities) thanks to a training scheme that combines learning from knowledge bases (e.g. WordNet) with learning from raw text. The model jointly learns representations of words, entities and MRs via a multi-task training process operating on these diverse sources of data. Hence, the system ends up providing methods for knowledge acquisition and wordsense disambiguation within the context of semantic parsing in a single elegant framework. Experiments on these various tasks indicate the promise of the approach.\nLearning Combinatorial Optimization Algorithms over Graphs (Elias Boutros Khalil et al., 2017) Elias Boutros Khalil, H. Dai, Yuyu Zhang, B. Dilkina, Le Song. (2017)\nLearning Combinatorial Optimization Algorithms over Graphs\nNIPS\nPaper Link\nInfluential Citation Count (90), SS-ID (f306b1a973d9fa8c693036ca75fa8e30ad709635)\nABSTRACT\nThe design of good heuristics or approximation algorithms for NP-hard combinatorial optimization problems often requires significant specialized knowledge and trial-and-error. Can we automate this challenging, tedious process, and learn the algorithms instead? In many real-world applications, it is typically the case that the same optimization problem is solved again and again on a regular basis, maintaining the same problem structure but differing in the data. This provides an opportunity for learning heuristic algorithms that exploit the structure of such recurring problems. In this paper, we propose a unique combination of reinforcement learning and graph embedding to address this challenge. The learned greedy policy behaves like a meta-algorithm that incrementally constructs a solution, and the action is determined by the output of a graph embedding network capturing the current state of the solution. We show that our framework can be applied to a diverse range of optimization problems over graphs, and learns effective algorithms for the Minimum Vertex Cover, Maximum Cut and Traveling Salesman problems.\nGloVe: Global Vectors for Word Representation (Jeffrey Pennington et al., 2014) Jeffrey Pennington, R. Socher, Christopher D. Manning. (2014)\nGloVe: Global Vectors for Word Representation\nEMNLP\nPaper Link\nInfluential Citation Count (3451), SS-ID (f37e1b62a767a307c046404ca96bc140b3e68cb5)\nABSTRACT\nRecent methods for learning vector space representations of words have succeeded in capturing fine-grained semantic and syntactic regularities using vector arithmetic, but the origin of these regularities has remained opaque. We analyze and make explicit the model properties needed for such regularities to emerge in word vectors. The result is a new global logbilinear regression model that combines the advantages of the two major model families in the literature: global matrix factorization and local context window methods. Our model efficiently leverages statistical information by training only on the nonzero elements in a word-word cooccurrence matrix, rather than on the entire sparse matrix or on individual context windows in a large corpus. The model produces a vector space with meaningful substructure, as evidenced by its performance of 75% on a recent word analogy task. It also outperforms related models on similarity tasks and named entity recognition.\nSSNE: Status Signed Network Embedding (Chunyu Lu et al., 2019) Chunyu Lu, Pengfei Jiao, Hongtao Liu, Yaping Wang, Hongyan Xu, Wenjun Wang. (2019)\nSSNE: Status Signed Network Embedding\nPAKDD\nPaper Link\nInfluential Citation Count (0), SS-ID (f429e69863223ca62d2fa1fd667b18ddac0cb3de)\nABSTRACT\nThis work studies the problem of signed network embedding, which aims to obtain low-dimensional vectors for nodes in signed networks. Existing works mostly focus on learning representations via characterizing the social structural balance theory in signed networks. However, structural balance theory could not well satisfy some of the fundamental phenomena in real-world signed networks such as the direction of links. As a result, in this paper we integrate another theory Status Theory into signed network embedding since status theory can better explain the social mechanisms of signed networks. To be specific, we characterize the status of nodes in the semantic vector space and well design different ranking objectives for positive and negative links respectively. Besides, we utilize graph attention to assemble the information of neighborhoods. We conduct extensive experiments on three real-world datasets and the results show that our model can achieve a significant improvement compared with baselines.\nSemantic Proximity Search on Heterogeneous Graph by Proximity Embedding (Zemin Liu et al., 2017) Zemin Liu, V. Zheng, Zhou Zhao, Fanwei Zhu, K. Chang, Minghui Wu, Jing Ying. (2017)\nSemantic Proximity Search on Heterogeneous Graph by Proximity Embedding\nAAAI\nPaper Link\nInfluential Citation Count (3), SS-ID (f4ef2c9a97c183b24d08ca67f6f55b98d441e8e6)\nABSTRACT\nMany real-world networks have a rich collection of objects. The semantics of these objects allows us to capture different classes of proximities, thus enabling an important task of semantic proximity search. As the core of semantic proximity search, we have to measure the proximity on a heterogeneous graph, whose nodes are various types of objects. Most of the existing methods rely on engineering features about the graph structure between two nodes to measure their proximity. With recent development on graph embedding, we see a good chance to avoid feature engineering for semantic proximity search. There is very little work on using graph embedding for semantic proximity search. We also observe that graph embedding methods typically focus on embedding nodes, which is an “indirect” approach to learn the proximity. Thus, we introduce a new concept of proximity embedding, which directly embeds the network structure between two possibly distant nodes. We also design our proximity embedding, so as to flexibly support both symmetric and asymmetric proximities. Based on the proximity embedding, we can easily estimate the proximity score between two nodes and enable search on the graph. We evaluate our proximity embedding method on three real-world public data sets, and show it outperforms the state-of-the-art baselines. We release the code for proximity embedding.\nGeographic Routing Using Hyperbolic Space (Robert D. Kleinberg, 2007) Robert D. Kleinberg. (2007)\nGeographic Routing Using Hyperbolic Space\nIEEE INFOCOM 2007 - 26th IEEE International Conference on Computer Communications\nPaper Link\nInfluential Citation Count (56), SS-ID (f506b2ddb142d2ec539400297ba53383d958abef)\nABSTRACT\nWe propose a scalable and reliable point-to-point routing algorithm for ad hoc wireless networks and sensor-nets. Our algorithm assigns to each node of the network a virtual coordinate in the hyperbolic plane, and performs greedy geographic routing with respect to these virtual coordinates. Unlike other proposed greedy routing algorithms based on virtual coordinates, our embedding guarantees that the greedy algorithm is always successful in finding a route to the destination, if such a route exists. We describe a distributed algorithm for computing each node\u0026rsquo;s virtual coordinates in the hyperbolic plane, and for greedily routing packets to a destination point in the hyperbolic plane. (This destination may be the address of another node of the network, or it may be an address associated to a piece of content in a Distributed Hash Table. In the latter case we prove that the greedy routing strategy makes a consistent choice of the node responsible for the address, irrespective of the source address of the request.) We evaluate the resulting algorithm in terms of both path stretch and node congestion.\nEnhanced Unsupervised Graph Embedding via Hierarchical Graph Convolution Network (H. Zhang et al., 2020) H. Zhang, J. Zhou, R. Li. (2020)\nEnhanced Unsupervised Graph Embedding via Hierarchical Graph Convolution Network\nPaper Link\nInfluential Citation Count (0), SS-ID (f597a70c8708b7cda9766a403e3a2a67162d6973)\nABSTRACT\nGraph embedding aims to learn the low-dimensional representation of nodes in the network, which has been paid more and more attention in many graph-based tasks recently. Graph Convolution Network (GCN) is a typical deep semisupervised graph embedding model, which can acquire node representation from the complex network. However, GCN usually needs to use a lot of labeled data and additional expressive features in the graph embedding learning process, so the model cannot be effectively applied to undirected graphs with only network structure information. In this paper, we propose a novel unsupervised graph embedding method via hierarchical graph convolution network (HGCN). Firstly, HGCN builds the initial node embedding and pseudo-labels for the undirected graphs, and then further uses GCNs to learn the node embedding and update labels, finally combines HGCN output representation with the initial embedding to get the graph embedding. Furthermore, we improve the model to match the different undirected networks according to the number of network node label types. Comprehensive experiments demonstrate that our proposed HGCN and HGCN can significantly enhance the performance of the node classification task.\nGreedy forwarding in scale-free networks embedded in hyperbolic metric spaces (Dmitri V. Krioukov et al., 2009) Dmitri V. Krioukov, F. Papadopoulos, M. Boguñá, Amin Vahdat. (2009)\nGreedy forwarding in scale-free networks embedded in hyperbolic metric spaces\nSIGMETRICS Perform. Evaluation Rev.\nPaper Link\nInfluential Citation Count (4), SS-ID (f61005ce7db38553f2bf87be7c9fbce183b4c375)\nABSTRACT\nWe show that complex (scale-free) network topologies naturally emerge from hyperbolic metric spaces. Hyperbolic geometry facilitates maximally efficient greedy forwarding in these networks. Greedy forwarding is topology-oblivious. Nevertheless, greedy packets find their destinations with 100% probability following almost optimal shortest paths. This remarkable efficiency sustains even in highly dynamic networks. Our findings suggest that forwarding information through complex networks, such as the Internet, is possible without the overhead of existing routing protocols, and may also find practical applications in overlay networks for tasks such as application-level routing, information sharing, and data distribution.\nA Three-Way Model for Collective Learning on Multi-Relational Data (Maximilian Nickel et al., 2011) Maximilian Nickel, Volker Tresp, H. Kriegel. (2011)\nA Three-Way Model for Collective Learning on Multi-Relational Data\nICML\nPaper Link\nInfluential Citation Count (279), SS-ID (f6764d853a14b0c34df1d2283e76277aead40fde)\nABSTRACT\nRelational learning is becoming increasingly important in many areas of application. Here, we present a novel approach to relational learning based on the factorization of a three-way tensor. We show that unlike other tensor approaches, our method is able to perform collective learning via the latent components of the model and provide an efficient algorithm to compute the factorization. We substantiate our theoretical considerations regarding the collective learning capabilities of our model by the means of experiments on both a new dataset and a dataset commonly used in entity resolution. Furthermore, we show on common benchmark datasets that our approach achieves better or on-par results, if compared to current state-of-the-art relational learning solutions, while it is significantly faster to compute.\nVideo suggestion and discovery for youtube: taking random walks through the view graph (S. Baluja et al., 2008) S. Baluja, Rohan Seth, D. Sivakumar, Yushi Jing, J. Yagnik, Shankar Kumar, Deepak Ravichandran, M. Aly. (2008)\nVideo suggestion and discovery for youtube: taking random walks through the view graph\nWWW\nPaper Link\nInfluential Citation Count (34), SS-ID (f68ba8fe9fc9f7d8b7eb8c3d4a6d1046ee345e4b)\nABSTRACT\nThe rapid growth of the number of videos in YouTube provides enormous potential for users to find content of interest to them. Unfortunately, given the difficulty of searching videos, the size of the video repository also makes the discovery of new content a daunting task. In this paper, we present a novel method based upon the analysis of the entire user-video graph to provide personalized video suggestions for users. The resulting algorithm, termed Adsorption, provides a simple method to efficiently propagate preference information through a variety of graphs. We extensively test the results of the recommendations on a three month snapshot of live data from YouTube.\nNeural IR Meets Graph Embedding: A Ranking Model for Product Search (Yuan Zhang et al., 2019) Yuan Zhang, Dong Wang, Yan Zhang. (2019)\nNeural IR Meets Graph Embedding: A Ranking Model for Product Search\nWWW\nPaper Link\nInfluential Citation Count (3), SS-ID (f6c985149798760da88f871cf71148bbeca69b2a)\nABSTRACT\nRecently, neural models for information retrieval are becoming increasingly popular. They provide effective approaches for product search due to their competitive advantages in semantic matching. However, it is challenging to use graph-based features, though proved very useful in IR literature, in these neural approaches. In this paper, we leverage the recent advances in graph embedding techniques to enable neural retrieval models to exploit graph-structured data for automatic feature extraction. The proposed approach can not only help to overcome the long-tail problem of click-through data, but also incorporate external heterogeneous information to improve search results. Extensive experiments on a real-world e-commerce dataset demonstrate significant improvement achieved by our proposed approach over multiple strong baselines both as an individual retrieval model and as a feature used in learning-to-rank frameworks.\ndyngraph2vec: Capturing Network Dynamics using Dynamic Graph Representation Learning (Palash Goyal et al., 2018) Palash Goyal, Sujit Rokka Chhetri, A. Canedo. (2018)\ndyngraph2vec: Capturing Network Dynamics using Dynamic Graph Representation Learning\nKnowl. Based Syst.\nPaper Link\nInfluential Citation Count (23), SS-ID (f6e59062382fdec9b95c3abef1c27efc3b2ec1c7)\nABSTRACT\nLearning graph representations is a fundamental task aimed at capturing various properties of graphs in vector space. The most recent methods learn such representations for static networks. However, real-world networks evolve over time and have varying dynamics. Capturing such evolution is key to predicting the properties of unseen networks. To understand how the network dynamics affect the prediction performance, we propose an embedding approach which learns the structure of evolution in dynamic graphs and can predict unseen links with higher precision. Our model, dyngraph2vec, learns the temporal transitions in the network using a deep architecture composed of dense and recurrent layers. We motivate the need for capturing dynamics for the prediction on a toy dataset created using stochastic block models. We then demonstrate the efficacy of dyngraph2vec over existing state-of-the-art methods on two real-world datasets. We observe that learning dynamics can improve the quality of embedding and yield better performance in link prediction.\nHeterogeneous Network Embedding via Deep Architectures (Shiyu Chang et al., 2015) Shiyu Chang, Wei Han, Jiliang Tang, Guo-Jun Qi, C. Aggarwal, Thomas S. Huang. (2015)\nHeterogeneous Network Embedding via Deep Architectures\nKDD\nPaper Link\nInfluential Citation Count (35), SS-ID (f7172f95a3c0aa4fddfaadbce9908ce20cbf50ef)\nABSTRACT\nData embedding is used in many machine learning applications to create low-dimensional feature representations, which preserves the structure of data points in their original space. In this paper, we examine the scenario of a heterogeneous network with nodes and content of various types. Such networks are notoriously difficult to mine because of the bewildering combination of heterogeneous contents and structures. The creation of a multidimensional embedding of such data opens the door to the use of a wide variety of off-the-shelf mining techniques for multidimensional data. Despite the importance of this problem, limited efforts have been made on embedding a network of scalable, dynamic and heterogeneous data. In such cases, both the content and linkage structure provide important cues for creating a unified feature representation of the underlying network. In this paper, we design a deep embedding algorithm for networked data. A highly nonlinear multi-layered embedding function is used to capture the complex interactions between the heterogeneous data in a network. Our goal is to create a multi-resolution deep embedding function, that reflects both the local and global network structures, and makes the resulting embedding useful for a variety of data mining tasks. In particular, we demonstrate that the rich content and linkage information in a heterogeneous network can be captured by such an approach, so that similarities among cross-modal data can be measured directly in a common embedding space. Once this goal has been achieved, a wide variety of data mining problems can be solved by applying off-the-shelf algorithms designed for handling vector representations. Our experiments on real-world network datasets show the effectiveness and scalability of the proposed algorithm as compared to the state-of-the-art embedding methods.\nCollective Classification via Discriminative Matrix Factorization on Sparsely Labeled Networks (Daokun Zhang et al., 2016) Daokun Zhang, Jie Yin, Xingquan Zhu, Chengqi Zhang. (2016)\nCollective Classification via Discriminative Matrix Factorization on Sparsely Labeled Networks\nCIKM\nPaper Link\nInfluential Citation Count (1), SS-ID (f95b14cba00f995ee1c12444551d92cf43640263)\nABSTRACT\nWe address the problem of classifying sparsely labeled networks, where labeled nodes in the network are extremely scarce. Existing algorithms, such as collective classification, have been shown to be effective for jointly deriving labels of related nodes, by exploiting class label dependencies among neighboring nodes. However, when the underlying network is sparsely labeled, most nodes have too few or even no connections to labeled nodes. This makes it very difficult to leverage supervised knowledge from labeled nodes to accurately estimate label dependencies, thereby largely degrading the classification accuracy. In this paper, we propose a novel discriminative matrix factorization (DMF) based algorithm that effectively learns a latent network representation by exploiting topological paths between labeled and unlabeled nodes, in addition to nodes\u0026rsquo; content information. The main idea is to use matrix factorization to obtain a compact representation of the network that fully encodes nodes\u0026rsquo; content information and network structure, and unleash discriminative power inferred from labeled nodes to directly benefit collective classification. To achieve this, we formulate a new matrix factorization objective function that integrates network representation learning with an empirical loss minimization for classifying node labels. An efficient optimization algorithm based on conjugate gradient methods is proposed to solve the new objective function. Experimental results on real-world networks show that DMF yields superior performance gain over the state-of-the-art baselines on sparsely labeled networks.\nSelf-Grouping Multi-network Clustering (Jingchao Ni et al., 2016) Jingchao Ni, Wei Cheng, Wei Fan, X. Zhang. (2016)\nSelf-Grouping Multi-network Clustering\n2016 IEEE 16th International Conference on Data Mining (ICDM)\nPaper Link\nInfluential Citation Count (0), SS-ID (fabfba8835470ba7a33dfc25e50ef83a5be7eae0)\nABSTRACT\nJoint clustering of multiple networks has been shown to be more accurate than performing clustering on individual networks separately. Many multi-view and multi-domain network clustering methods have been developed for joint multi-network clustering. These methods typically assume there is a common clustering structure shared by all networks, and different networks can provide complementary information on this underlying clustering structure. However, this assumption is too strict to hold in many emerging real-life applications, where multiple networks have diverse data distributions. More popularly, the networks in consideration belong to different underlying groups. Only networks in the same underlying group share similar clustering structures. Better clustering performance can be achieved by considering such groups differently. As a result, an ideal method should be able to automatically detect network groups so that networks in the same group share a common clustering structure. To address this problem, we propose a novel method, ComClus, to simultaneously group and cluster multiple networks. ComClus treats node clusters as features of networks and uses them to differentiate different network groups. Network grouping and clustering are coupled and mutually enhanced during the learning process. Extensive experimental evaluation on a variety of synthetic and real datasets demonstrates the effectiveness of our method.\nTowards Data Poisoning Attack against Knowledge Graph Embedding (Hengtong Zhang et al., 2019) Hengtong Zhang, T. Zheng, Jing Gao, Chenglin Miao, Lu Su, Yaliang Li, K. Ren. (2019)\nTowards Data Poisoning Attack against Knowledge Graph Embedding\nArXiv\nPaper Link\nInfluential Citation Count (1), SS-ID (fc82a1e8b4cf04ce42e14ed6347ce81c9563cf14)\nABSTRACT\nKnowledge graph embedding (KGE) is a technique for learning continuous embeddings for entities and relations in the knowledge graph.Due to its benefit to a variety of downstream tasks such as knowledge graph completion, question answering and recommendation, KGE has gained significant attention recently. Despite its effectiveness in a benign environment, KGE\u0026rsquo; robustness to adversarial attacks is not well-studied. Existing attack methods on graph data cannot be directly applied to attack the embeddings of knowledge graph due to its heterogeneity. To fill this gap, we propose a collection of data poisoning attack strategies, which can effectively manipulate the plausibility of arbitrary targeted facts in a knowledge graph by adding or deleting facts on the graph. The effectiveness and efficiency of the proposed attack strategies are verified by extensive evaluations on two widely-used benchmarks.\nNetwork Representation Learning with Rich Text Information (Cheng Yang et al., 2015) Cheng Yang, Zhiyuan Liu, Deli Zhao, Maosong Sun, Edward Y. Chang. (2015)\nNetwork Representation Learning with Rich Text Information\nIJCAI\nPaper Link\nInfluential Citation Count (162), SS-ID (fce14c6aa64e888456256ac6796744683165a0ff)\nABSTRACT\nRepresentation learning has shown its effectiveness in many tasks such as image classification and text mining. Network representation learning aims at learning distributed vector representation for each vertex in a network, which is also increasingly recognized as an important aspect for network analysis. Most network representation learning methods investigate network structures for learning. In reality, network vertices contain rich information (such as text), which cannot be well applied with algorithmic frameworks of typical representation learning methods. By proving that DeepWalk, a state-of-the-art network representation method, is actually equivalent to matrix factorization (MF), we propose text-associated DeepWalk (TADW). TADW incorporates text features of vertices into network representation learning under the framework of matrix factorization. We evaluate our method and various baseline methods by applying them to the task of multi-class classification of vertices. The experimental results show that, our method outperforms other baselines on all three datasets, especially when networks are noisy and training ratio is small. The source code of this paper can be obtained from https://github.com/albertyang33/TADW.\nSNE: Signed Network Embedding (Shuhan Yuan et al., 2017) Shuhan Yuan, Xintao Wu, Yang Xiang. (2017)\nSNE: Signed Network Embedding\nPAKDD\nPaper Link\nInfluential Citation Count (13), SS-ID (feee6ea8961398e599577f9f793230d391985b88)\nABSTRACT\nSeveral network embedding models have been developed for unsigned networks. However, these models based on skip-gram cannot be applied to signed networks because they can only deal with one type of link. In this paper, we present our signed network embedding model called SNE. Our SNE adopts the log-bilinear model, uses node representations of all nodes along a given path, and further incorporates two signed-type vectors to capture the positive or negative relationship of each edge along the path. We conduct two experiments, node classification and link prediction, on both directed and undirected signed networks and compare with four baselines including a matrix factorization method and three state-of-the-art unsigned network embedding models. The experimental results demonstrate the effectiveness of our signed network embedding.\nCo-authorship Network Embedding and Recommending Collaborators via Network Embedding (Ilya Makarov et al., 2018) Ilya Makarov, Olga Gerasimova, Pavel Sulimov, L. Zhukov. (2018)\nCo-authorship Network Embedding and Recommending Collaborators via Network Embedding\nAIST\nPaper Link\nInfluential Citation Count (0), SS-ID (ff48f9b6be3c60101873391782d7eecf3a5a3247)\nABSTRACT\nCo-authorship networks contain invisible patterns of collaboration among researchers. The process of writing joint paper can depend of different factors, such as friendship, common interests, and policy of university. We show that, having a temporal co-authorship network, it is possible to predict future publications. We solve the problem of recommending collaborators from the point of link prediction using graph embedding, obtained from co-authorship network. We run experiments on data from HSE publications graph and compare it with relevant models.\nDynamic Heterogeneous Graph Embedding Using Hierarchical Attentions (Luwei Yang et al., 2020) Luwei Yang, Zhibo Xiao, Wen Jiang, Yi Wei, Y. Hu, Hao Wang. (2020)\nDynamic Heterogeneous Graph Embedding Using Hierarchical Attentions\nECIR\nPaper Link\nInfluential Citation Count (1), SS-ID (ffe5b25c6cf8de37823907c3aed7738ea393902e)\nABSTRACT\nGraph embedding has attracted many research interests. Existing works mainly focus on static homogeneous/heterogeneous networks or dynamic homogeneous networks. However, dynamic heterogeneous networks are more ubiquitous in reality, e.g. social network, e-commerce network, citation network, etc. There is still a lack of research on dynamic heterogeneous graph embedding. In this paper, we propose a novel dynamic heterogeneous graph embedding method using hierarchical attentions (DyHAN) that learns node embeddings leveraging both structural heterogeneity and temporal evolution. We evaluate our method on three real-world datasets. The results show that DyHAN outperforms various state-of-the-art baselines in terms of link prediction task.\nDeepWalk: online learning of social representations (Bryan Perozzi et al., 2014) Bryan Perozzi, Rami Al-Rfou, S. Skiena. (2014)\nDeepWalk: online learning of social representations\nKDD\nPaper Link\nInfluential Citation Count (1335), SS-ID (fff114cbba4f3ba900f33da574283e3de7f26c83)\nABSTRACT\nWe present DeepWalk, a novel approach for learning latent representations of vertices in a network. These latent representations encode social relations in a continuous vector space, which is easily exploited by statistical models. DeepWalk generalizes recent advancements in language modeling and unsupervised feature learning (or deep learning) from sequences of words to graphs. DeepWalk uses local information obtained from truncated random walks to learn latent representations by treating walks as the equivalent of sentences. We demonstrate DeepWalk\u0026rsquo;s latent representations on several multi-label network classification tasks for social networks such as BlogCatalog, Flickr, and YouTube. Our results show that DeepWalk outperforms challenging baselines which are allowed a global view of the network, especially in the presence of missing information. DeepWalk\u0026rsquo;s representations can provide F1 scores up to 10% higher than competing methods when labeled data is sparse. In some experiments, DeepWalk\u0026rsquo;s representations are able to outperform all baseline methods while using 60% less training data. DeepWalk is also scalable. It is an online learning algorithm which builds useful incremental results, and is trivially parallelizable. These qualities make it suitable for a broad class of real world applications such as network classification, and anomaly detection.\nMultidimensional Scaling (Kruskal J, Wish M. 1978.) Kruskal J, Wish M. (1978)\nMultidimensional Scaling New York: SAGE Publications Link-based classification (Lu \u0026amp; Getoor. 2003.) Lu Q, Getoor L. (2003)\nLink-based classification\nProceedings of the 20th InternationalConference on Machine Learning (ICML-03).New York: ACM, 496–503.\nABSTRACT A key challenge for machine learning is tackling the problem of mining richly structured data sets, where the objects are linked in some way due to either an explicit or implicit relationship that exists between the objects. Links among the objects demonstrate certain patterns, which can be helpful for many machine learning tasks and are usually hard to capture with traditional statistical models. Recently there has been a surge of interest in this area, fueled largely by interest in web and hypertext mining, but also by interest in mining social networks, bibliographic citation data, epidemiological data and other domains best described using a linked or graph structure. In this paper we propose a framework for modeling link distributions, a link-based model that supports discriminative models describing both the link distributions and the attributes of linked objects. We use a structured logistic regression model, capturing both content and links. We systematically evaluate several variants of our link-based model on a range of data sets including both web and citation collections. In all cases, the use of the link distribution improves classification accuracy.\nStatistical relational learning (Getoor L, Taskar B., 2007) Getoor L, Taskar B (2007)\nStatistical relational learning\nhttps://mitpress.mit.edu/books/introduction-statistical-relational-learning.\nABSTRACT Advanced statistical modeling and knowledge representation techniques for a newly emerging area of machine learning and probabilistic reasoning; includes introductory material, tutorials for different proposed approaches, and applications. Handling inherent uncertainty and exploiting compositional structure are fundamental to understanding and designing large-scale systems. Statistical relational learning builds on ideas from probability theory and statistics to address uncertainty while incorporating tools from logic, databases and programming languages to represent structure. In Introduction to Statistical Relational Learning, leading researchers in this emerging area of machine learning describe current formalisms, models, and algorithms that enable effective and robust reasoning about richly structured systems and data. The early chapters provide tutorials for material used in later chapters, offering introductions to representation, inference and learning in graphical models, and logic. The book then describes object-oriented approaches, including probabilistic relational models, relational Markov networks, and probabilistic entity-relationship models as well as logic-based formalisms including Bayesian logic programs, Markov logic, and stochastic logic programs. Later chapters discuss such topics as probabilistic models with unknown objects, relational dependency networks, reinforcement learning in relational domains, and information extraction. By presenting a variety of approaches, the book highlights commonalities and clarifies important differences among proposed approaches and, along the way, identifies important representational and algorithmic issues. Numerous applications are provided throughout.\n","date":"May 9, 2022","hero":"/blog-akitenkrad/posts/papers/202205/20220509110738/hero.jpg","permalink":"https://akitenkrad.github.io/blog-akitenkrad/posts/papers/202205/20220509110738/","summary":"Round-1: Overview Round-2: Model Implementation Details Round-3: Experiments Citation Makarov, I., Kiselev, D., Nikitinsky, N., \u0026amp; Subelj, L. (2021).\nSurvey on graph embeddings and their applications to machine learning problems on graphs.\nPeerJ Computer Science, 7, 1–62.\nPaper Link Abstract Dealing with relational data always required significant computational resources,domain expertise and task-dependent feature engineering to incorporate structuralinformation into a predictive model. Nowadays, a family of automated graphfeature engineering techniques has been proposed in different streams of literature.","tags":["At:Round-1","Published:2021","Survey","Graph Neural Network","Graph Embedding","Node Classification","Link Prediction","Node Clustering","Graph Visualization"],"title":"Survey on graph embeddings and their applications to machine learning problems on graphs"},{"categories":null,"contents":" Round-1: Overview Round-2: Model Implementation Details Round-3: Experiments Citation Yan, M., Xia, J., Wu, C., Bi, B., Zhao, Z., Zhang, J., Si, L., Wang, R., Wang, W., \u0026amp; Chen, H. (2019).\nA Deep Cascade Model for Multi-Document Reading Comprehension.\nProceedings of the AAAI Conference on Artificial Intelligence, 33, 7354–7361.\nhttps://doi.org/10.1609/aaai.v33i01.33017354 Abstract A fundamental trade-off between effectiveness and efficiency needs to be balanced when designing an online question answering system. Effectiveness comes from sophisticated functions such as extractive machine reading comprehension (MRC), while efficiency is obtained from improvements in preliminary retrieval components such as candidate document selection and paragraph ranking. Given the complexity of the real-world multi-document MRC scenario, it is difficult to jointly optimize both in an end-to-end system. To address this problem, we develop a novel deep cascade learning model, which progressively evolves from the documentlevel and paragraph-level ranking of candidate texts to more precise answer extraction with machine reading comprehension. Specifically, irrelevant documents and paragraphs are first filtered out with simple functions for efficiency consideration. Then we jointly train three modules on the remaining texts for better tracking the answer: the document extraction, the paragraph extraction and the answer extraction. Experiment results show that the proposed method outperforms the previous state-of-the-art methods on two large-scale multidocument benchmark datasets, i.e., TriviaQA and DuReader. In addition, our online system can stably serve typical scenarios with millions of daily requests in less than 50ms.\nWhat\u0026rsquo;s New Machine Reading Comprehension のタスクにおいて，複数のコンテキストを扱える Multi-Document Reading Comprehension Model を提案した． Document Extraction，Paragraph Extraction の2つのタスクをカスケードすることで，Answer Extraction フェーズで扱うデータ量を効率よく削減することに成功した． Question と Context を Document Extraction と Paragraph Extraction の2段階で処理することによって，Multi-Document のような Context が大量にあるタスクでもうまく機能するようなモデルを考案している（= Cascade Model） Document Extraction, Paragraph Extraction, Answer Extraction はベースのレイヤを共有しており，Joint-Leaningで学習する Figure 1 参照 TriviaQAとDuReaderデータセットで検証を実施し，既存のモデルを上回る精度を達成することを確認した． Dataset TriviaQA: A Large Scale Distantly Supervised Challenge Dataset for Reading Comprehension (Mandar Joshi et al., 2017) Mandar Joshi, Eunsol Choi, Daniel S. Weld, Luke Zettlemoyer. (2017)\nTriviaQA: A Large Scale Distantly Supervised Challenge Dataset for Reading Comprehension\nACL\nPaper Link\nInfluential Citation Count (193), SS-ID (f010affab57b5fcf1cd6be23df79d8ec98c7289c)\nABSTRACT\nWe present TriviaQA, a challenging reading comprehension dataset containing over 650K question-answer-evidence triples. TriviaQA includes 95K question-answer pairs authored by trivia enthusiasts and independently gathered evidence documents, six per question on average, that provide high quality distant supervision for answering the questions. We show that, in comparison to other recently introduced large-scale datasets, TriviaQA (1) has relatively complex, compositional questions, (2) has considerable syntactic and lexical variability between questions and corresponding answer-evidence sentences, and (3) requires more cross sentence reasoning to find answers. We also present two baseline algorithms: a feature-based classifier and a state-of-the-art neural network, that performs well on SQuAD reading comprehension. Neither approach comes close to human performance (23% and 40% vs. 80%), suggesting that TriviaQA is a challenging testbed that is worth significant future study. Data and code available at \u0026ndash; this http URL\nDuReader: a Chinese Machine Reading Comprehension Dataset from Real-world Applications (Wei He et al., 2017) Wei He, Kai Liu, Jing Liu, Yajuan Lyu, Shiqi Zhao, Xinyan Xiao, Yuan Liu, Yizhong Wang, Hua Wu, Qiaoqiao She, Xuan Liu, Tian Wu, Haifeng Wang. (2017)\nDuReader: a Chinese Machine Reading Comprehension Dataset from Real-world Applications\nQA@ACL\nPaper Link\nInfluential Citation Count (32), SS-ID (995b7affd684b910d5a1c520c3af00fd20cc39b0)\nABSTRACT\nThis paper introduces DuReader, a new large-scale, open-domain Chinese ma- chine reading comprehension (MRC) dataset, designed to address real-world MRC. DuReader has three advantages over previous MRC datasets: (1) data sources: questions and documents are based on Baidu Search and Baidu Zhidao; answers are manually generated. (2) question types: it provides rich annotations for more question types, especially yes-no and opinion questions, that leaves more opportunity for the research community. (3) scale: it contains 200K questions, 420K answers and 1M documents; it is the largest Chinese MRC dataset so far. Experiments show that human performance is well above current state-of-the-art baseline systems, leaving plenty of room for the community to make improvements. To help the community make these improvements, both DuReader and baseline systems have been posted online. We also organize a shared competition to encourage the exploration of more models. Since the release of the task, there are significant improvements over the baselines.\nModel Description Training Settings TBD\nResults References SQuAD: 100,000\u0026#43; Questions for Machine Comprehension of Text (Pranav Rajpurkar et al., 2016) Pranav Rajpurkar, Jian Zhang, Konstantin Lopyrev, Percy Liang. (2016)\nSQuAD: 100,000+ Questions for Machine Comprehension of Text\nEMNLP\nPaper Link\nInfluential Citation Count (1063), SS-ID (05dd7254b632376973f3a1b4d39485da17814df5)\nABSTRACT\nWe present the Stanford Question Answering Dataset (SQuAD), a new reading comprehension dataset consisting of 100,000+ questions posed by crowdworkers on a set of Wikipedia articles, where the answer to each question is a segment of text from the corresponding reading passage. We analyze the dataset to understand the types of reasoning required to answer the questions, leaning heavily on dependency and constituency trees. We build a strong logistic regression model, which achieves an F1 score of 51.0%, a significant improvement over a simple baseline (20%). However, human performance (86.8%) is much higher, indicating that the dataset presents a good challenge problem for future research. The dataset is freely available at this https URL\nd. (Danna Zhou et al., 2021) Danna Zhou, Shuangshuang Wang, Keli Yang, Xue Liu, Wei Liu, R. Guo, W. Liang, F. Yuan, Zewen Liu, Ting Gao, Yong-xiang Tian. (2021)\nd.\nMicrobial pathogenesis\nPaper Link\nInfluential Citation Count (3564), SS-ID (083faacdad8283a28f4bb13d76f966fd89c1c5d8)\nABSTRACT\nMulti-Passage Machine Reading Comprehension with Cross-Passage Answer Verification (Yizhong Wang et al., 2018) Yizhong Wang, Kai Liu, Jing Liu, W. He, Yajuan Lyu, Hua Wu, Sujian Li, Haifeng Wang. (2018)\nMulti-Passage Machine Reading Comprehension with Cross-Passage Answer Verification\nACL\nPaper Link\nInfluential Citation Count (14), SS-ID (0985497d1de3ffd11713e75289cc2ad55836623d)\nABSTRACT\nMachine reading comprehension (MRC) on real web data usually requires the machine to answer a question by analyzing multiple passages retrieved by search engine. Compared with MRC on a single passage, multi-passage MRC is more challenging, since we are likely to get multiple confusing answer candidates from different passages. To address this problem, we propose an end-to-end neural model that enables those answer candidates from different passages to verify each other based on their content representations. Specifically, we jointly train three modules that can predict the final answer based on three factors: the answer boundary, the answer content and the cross-passage answer verification. The experimental results show that our method outperforms the baseline by a large margin and achieves the state-of-the-art performance on the English MS-MARCO dataset and the Chinese DuReader dataset, both of which are designed for MRC in real-world settings.\nJoint Cascade Optimization Using A Product Of Boosted Classifiers (L. Lefakis et al., 2010) L. Lefakis, F. Fleuret. (2010)\nJoint Cascade Optimization Using A Product Of Boosted Classifiers\nNIPS\nPaper Link\nInfluential Citation Count (0), SS-ID (0bbbbd6e9de229467c5298a3fc85c4dffd869a80)\nABSTRACT\nThe standard strategy for efficient object detection consists of building a cascade composed of several binary classifiers. The detection process takes the form of a lazy evaluation of the conjunction of the responses of these classifiers, and concentrates the computation on difficult parts of the image which cannot be trivially rejected. We introduce a novel algorithm to construct jointly the classifiers of such a cascade, which interprets the response of a classifier as the probability of a positive prediction, and the overall response of the cascade as the probability that all the predictions are positive. From this noisy-AND model, we derive a consistent loss and a Boosting procedure to optimize that global probability on the training set. Such a joint learning allows the individual predictors to focus on a more restricted modeling problem, and improves the performance compared to a standard cascade. We demonstrate the efficiency of this approach on face and pedestrian detection with standard data-sets and comparisons with reference baselines.\nReading Wikipedia to Answer Open-Domain Questions (Danqi Chen et al., 2017) Danqi Chen, Adam Fisch, J. Weston, Antoine Bordes. (2017)\nReading Wikipedia to Answer Open-Domain Questions\nACL\nPaper Link\nInfluential Citation Count (280), SS-ID (104715e1097b7ebee436058bfd9f45540f269845)\nABSTRACT\nThis paper proposes to tackle open- domain question answering using Wikipedia as the unique knowledge source: the answer to any factoid question is a text span in a Wikipedia article. This task of machine reading at scale combines the challenges of document retrieval (finding the relevant articles) with that of machine comprehension of text (identifying the answer spans from those articles). Our approach combines a search component based on bigram hashing and TF-IDF matching with a multi-layer recurrent neural network model trained to detect answers in Wikipedia paragraphs. Our experiments on multiple existing QA datasets indicate that (1) both modules are highly competitive with respect to existing counterparts and (2) multitask learning using distant supervision on their combination is an effective complete system on this challenging task.\n‘K’ (P. Alam, 2021) P. Alam. (2021)\n‘K’\nComposites Engineering: An A–Z Guide\nPaper Link\nInfluential Citation Count (1858), SS-ID (17473bc2acf3675e73a26e27aeb2b35b04e0fce1)\nABSTRACT\nMulti-Granularity Hierarchical Attention Fusion Networks for Reading Comprehension and Question Answering (Wei Wang et al., 2018) Wei Wang, Chen Wu, Ming Yan. (2018)\nMulti-Granularity Hierarchical Attention Fusion Networks for Reading Comprehension and Question Answering\nACL\nPaper Link\nInfluential Citation Count (20), SS-ID (26b47e35fe6e4260fdf7b7cc98f279a73c277494)\nABSTRACT\nThis paper describes a novel hierarchical attention network for reading comprehension style question answering, which aims to answer questions for a given narrative paragraph. In the proposed method, attention and fusion are conducted horizontally and vertically across layers at different levels of granularity between question and paragraph. Specifically, it first encode the question and paragraph with fine-grained language embeddings, to better capture the respective representations at semantic level. Then it proposes a multi-granularity fusion approach to fully fuse information from both global and attended representations. Finally, it introduces a hierarchical attention network to focuses on the answer span progressively with multi-level soft-alignment. Extensive experiments on the large-scale SQuAD, TriviaQA dataset validate the effectiveness of the proposed method. At the time of writing the paper, our model achieves state-of-the-art on the both SQuAD and TriviaQA Wiki leaderboard as well as two adversarial SQuAD datasets.\nXGBoost: A Scalable Tree Boosting System (Tianqi Chen et al., 2016) Tianqi Chen, Carlos Guestrin. (2016)\nXGBoost: A Scalable Tree Boosting System\nKDD\nPaper Link\nInfluential Citation Count (1774), SS-ID (26bc9195c6343e4d7f434dd65b4ad67efe2be27a)\nABSTRACT\nTree boosting is a highly effective and widely used machine learning method. In this paper, we describe a scalable end-to-end tree boosting system called XGBoost, which is used widely by data scientists to achieve state-of-the-art results on many machine learning challenges. We propose a novel sparsity-aware algorithm for sparse data and weighted quantile sketch for approximate tree learning. More importantly, we provide insights on cache access patterns, data compression and sharding to build a scalable tree boosting system. By combining these insights, XGBoost scales beyond billions of examples using far fewer resources than existing systems.\nDynamic Integration of Background Knowledge in Neural NLU Systems (Dirk Weissenborn et al., 2017) Dirk Weissenborn, Tom\u0026rsquo;avs Kovcisk\u0026rsquo;y, Chris Dyer. (2017)\nDynamic Integration of Background Knowledge in Neural NLU Systems\nPaper Link\nInfluential Citation Count (5), SS-ID (2f92b10acf7c405e55c74c1043dabd9ded1b1800)\nABSTRACT\nCommon-sense or background knowledge is required to understand natural language, but in most neural natural language understanding (NLU) systems, the requisite background knowledge is indirectly acquired from static corpora. We develop a new reading architecture for the dynamic integration of explicit background knowledge in NLU models. A new task-agnostic reading module provides refined word representations to a task-specific NLU architecture by processing background knowledge in the form of free-text statements, together with the task-specific inputs. Strong performance on the tasks of document question answering (DQA) and recognizing textual entailment (RTE) demonstrate the effectiveness and flexibility of our approach. Analysis shows that our models learn to exploit knowledge selectively and in a semantically appropriate way.\nThe Goldilocks Principle: Reading Children\u0026#39;s Books with Explicit Memory Representations (Felix Hill et al., 2015) Felix Hill, Antoine Bordes, S. Chopra, J. Weston. (2015)\nThe Goldilocks Principle: Reading Children\u0026rsquo;s Books with Explicit Memory Representations\nICLR\nPaper Link\nInfluential Citation Count (102), SS-ID (35b91b365ceb016fb3e022577cec96fb9b445dc5)\nABSTRACT\nWe introduce a new test of how well language models capture meaning in children\u0026rsquo;s books. Unlike standard language modelling benchmarks, it distinguishes the task of predicting syntactic function words from that of predicting lower-frequency words, which carry greater semantic content. We compare a range of state-of-the-art models, each with a different way of encoding what has been previously read. We show that models which store explicit representations of long-term contexts outperform state-of-the-art neural language models at predicting semantic content words, although this advantage is not observed for syntactic function words. Interestingly, we find that the amount of text encoded in a single memory representation is highly influential to the performance: there is a sweet-spot, not too big and not too small, between single words and full sentences that allows the most meaningful information in a text to be effectively retained and recalled. Further, the attention over such window-based memories can be trained effectively through self-supervision. We then assess the generality of this principle by applying it to the CNN QA benchmark, which involves identifying named entities in paraphrased summaries of news articles, and achieve state-of-the-art performance.\nBidirectional Attention Flow for Machine Comprehension (Minjoon Seo et al., 2016) Minjoon Seo, Aniruddha Kembhavi, Ali Farhadi, Hannaneh Hajishirzi. (2016)\nBidirectional Attention Flow for Machine Comprehension\nICLR\nPaper Link\nInfluential Citation Count (440), SS-ID (3a7b63b50c64f4ec3358477790e84cbd6be2a0b4)\nABSTRACT\nMachine comprehension (MC), answering a query about a given context paragraph, requires modeling complex interactions between the context and the query. Recently, attention mechanisms have been successfully extended to MC. Typically these methods use attention to focus on a small portion of the context and summarize it with a fixed-size vector, couple attentions temporally, and/or often form a uni-directional attention. In this paper we introduce the Bi-Directional Attention Flow (BIDAF) network, a multi-stage hierarchical process that represents the context at different levels of granularity and uses bi-directional attention flow mechanism to obtain a query-aware context representation without early summarization. Our experimental evaluations show that our model achieves the state-of-the-art results in Stanford Question Answering Dataset (SQuAD) and CNN/DailyMail cloze test.\nSimple and Effective Multi-Paragraph Reading Comprehension (Christopher Clark et al., 2017) Christopher Clark, Matt Gardner. (2017)\nSimple and Effective Multi-Paragraph Reading Comprehension\nACL\nPaper Link\nInfluential Citation Count (48), SS-ID (3c78c6df5eb1695b6a399e346dde880af27d1016)\nABSTRACT\nWe consider the problem of adapting neural paragraph-level question answering models to the case where entire documents are given as input. Our proposed solution trains models to produce well calibrated confidence scores for their results on individual paragraphs. We sample multiple paragraphs from the documents during training, and use a shared-normalization training objective that encourages the model to produce globally correct output. We combine this method with a state-of-the-art pipeline for training models on document QA data. Experiments demonstrate strong performance on several document QA datasets. Overall, we are able to achieve a score of 71.3 F1 on the web portion of TriviaQA, a large improvement from the 56.7 F1 of the previous best system.\nS-Net: From Answer Extraction to Answer Synthesis for Machine Reading Comprehension (Chuanqi Tan et al., 2018) Chuanqi Tan, Furu Wei, Nan Yang, Bowen Du, Weifeng Lv, M. Zhou. (2018)\nS-Net: From Answer Extraction to Answer Synthesis for Machine Reading Comprehension\nAAAI\nPaper Link\nInfluential Citation Count (3), SS-ID (49f4ab44c9672f88637b7feaa182cf0b8b07a4c8)\nABSTRACT\nIn this paper, we present a novel approach to machine reading comprehension for the MS-MARCO dataset. Unlike the SQuAD dataset that aims to answer a question with exact text spans in a passage, the MS-MARCO dataset defines the task as answering a question from multiple passages and the words in the answer are not necessary in the passages. We therefore develop an extraction-then-synthesis framework to synthesize answers from extraction results. Specifically, the answer extraction model is first employed to predict the most important sub-spans from the passage as evidence, and the answer synthesis model takes the evidence as additional features along with the question and passage to further elaborate the final answers. We build the answer extraction model with state-ofthe-art neural networks for single passage reading comprehension, and propose an additional task of passage ranking to help answer extraction in multiple passages. The answer synthesis model is based on the sequence-to-sequence neural networks with extracted evidences as features. Experiments show that our extraction-then-synthesis method outperforms state-of-the-art methods.\nS-Net: From Answer Extraction to Answer Generation for Machine Reading Comprehension (Chuanqi Tan et al., 2017) Chuanqi Tan, Furu Wei, Nan Yang, Weifeng Lv, M. Zhou. (2017)\nS-Net: From Answer Extraction to Answer Generation for Machine Reading Comprehension\nAAAI 2017\nPaper Link\nInfluential Citation Count (5), SS-ID (53875e16feb74e9425e2f9da743794c850087817)\nABSTRACT\nIn this paper, we present a novel approach to machine reading comprehension for the MS-MARCO dataset. Unlike the SQuAD dataset that aims to answer a question with exact text spans in a passage, the MS-MARCO dataset defines the task as answering a question from multiple passages and the words in the answer are not necessary in the passages. We therefore develop an extraction-then-synthesis framework to synthesize answers from extraction results. Specifically, the answer extraction model is first employed to predict the most important sub-spans from the passage as evidence, and the answer synthesis model takes the evidence as additional features along with the question and passage to further elaborate the final answers. We build the answer extraction model with state-of-the-art neural networks for single passage reading comprehension, and propose an additional task of passage ranking to help answer extraction in multiple passages. The answer synthesis model is based on the sequence-to-sequence neural networks with extracted evidences as features. Experiments show that our extraction-then-synthesis method outperforms state-of-the-art methods.\nSmarnet: Teaching Machines to Read and Comprehend Like Human (Zheqian Chen et al., 2017) Zheqian Chen, Rongqin Yang, Bin Cao, Zhou Zhao, Deng Cai, Xiaofei He. (2017)\nSmarnet: Teaching Machines to Read and Comprehend Like Human\nArXiv\nPaper Link\nInfluential Citation Count (3), SS-ID (5e585d1fadffa2c25a297f988554c2e0e3373840)\nABSTRACT\nMachine Comprehension (MC) is a challenging task in Natural Language Processing field, which aims to guide the machine to comprehend a passage and answer the given question. Many existing approaches on MC task are suffering the inefficiency in some bottlenecks, such as insufficient lexical understanding, complex question-passage interaction, incorrect answer extraction and so on. In this paper, we address these problems from the viewpoint of how humans deal with reading tests in a scientific way. Specifically, we first propose a novel lexical gating mechanism to dynamically combine the words and characters representations. We then guide the machines to read in an interactive way with attention mechanism and memory network. Finally we add a checking layer to refine the answer for insurance. The extensive experiments on two popular datasets SQuAD and TriviaQA show that our method exceeds considerable performance than most state-of-the-art solutions at the time of submission.\nQ… (J. Koenderink, 2014) J. Koenderink. (2014)\nQ…\nPaper Link\nInfluential Citation Count (1046), SS-ID (61c0bc639c0bce01d348092423f34274b0388d6b)\nABSTRACT\nA cascade ranking model for efficient ranked retrieval (Lidan Wang et al., 2011) Lidan Wang, Jimmy J. Lin, Donald Metzler. (2011)\nA cascade ranking model for efficient ranked retrieval\nSIGIR\nPaper Link\nInfluential Citation Count (6), SS-ID (639c5d11e675b0287342399e2094dbe47f9e4b44)\nABSTRACT\nThere is a fundamental tradeoff between effectiveness and efficiency when designing retrieval models for large-scale document collections. Effectiveness tends to derive from sophisticated ranking functions, such as those constructed using learning to rank, while efficiency gains tend to arise from improvements in query evaluation and caching strategies. Given their inherently disjoint nature, it is difficult to jointly optimize effectiveness and efficiency in end-to-end systems. To address this problem, we formulate and develop a novel cascade ranking model, which unlike previous approaches, can simultaneously improve both top k ranked effectiveness and retrieval efficiency. The model constructs a cascade of increasingly complex ranking functions that progressively prunes and refines the set of candidate documents to minimize retrieval latency and maximize result set quality. We present a novel boosting algorithm for learning such cascades to directly optimize the tradeoff between effectiveness and efficiency. Experimental results show that our cascades are faster and return higher quality results than comparable ranking models.\nFeature-centric evaluation for efficient cascaded object detection (H. Schneiderman, 2004) H. Schneiderman. (2004)\nFeature-centric evaluation for efficient cascaded object detection\nCVPR 2004\nPaper Link\nInfluential Citation Count (5), SS-ID (7d4b63899c827125b0fa5bf77142ae8d4f52e519)\nABSTRACT\nWe describe a cascaded method for object detection. This approach uses a novel organization of the first cascade stage called \u0026ldquo;feature-centric\u0026rdquo; evaluation which re-uses feature evaluations across multiple candidate windows. We minimize the cost of this evaluation through several simplifications: (1) localized lighting normalization, (2) representation of the classifier as an additive model and (3) discrete-valued features. Such a method also incorporates a unique feature representation. The early stages in the cascade use simple fast feature evaluations and the later stages use more complex discriminative features. In particular, we propose features based on sparse coding and ordinal relationships among filter responses. This combination of cascaded feature-centric evaluation with features of increasing complexity achieves both computational efficiency and accuracy. We describe object detection experiments on ten objects including faces and automobiles. These results include 97% recognition at equal error rate on the UIUC image database for car detection.\nQANet: Combining Local Convolution with Global Self-Attention for Reading Comprehension (Adams Wei Yu et al., 2018) Adams Wei Yu, David Dohan, Minh-Thang Luong, Rui Zhao, Kai Chen, Mohammad Norouzi, Quoc V. Le. (2018)\nQANet: Combining Local Convolution with Global Self-Attention for Reading Comprehension\nICLR\nPaper Link\nInfluential Citation Count (154), SS-ID (8c1b00128e74f1cd92aede3959690615695d5101)\nABSTRACT\nCurrent end-to-end machine reading and question answering (Q\u0026amp;A) models are primarily based on recurrent neural networks (RNNs) with attention. Despite their success, these models are often slow for both training and inference due to the sequential nature of RNNs. We propose a new Q\u0026amp;A architecture called QANet, which does not require recurrent networks: Its encoder consists exclusively of convolution and self-attention, where convolution models local interactions and self-attention models global interactions. On the SQuAD dataset, our model is 3x to 13x faster in training and 4x to 9x faster in inference, while achieving equivalent accuracy to recurrent models. The speed-up gain allows us to train the model with much more data. We hence combine our model with data generated by backtranslation from a neural machine translation model. On the SQuAD dataset, our single model, trained with augmented data, achieves 84.6 F1 score on the test set, which is significantly better than the best published F1 score of 81.8.\nEvidence Aggregation for Answer Re-Ranking in Open-Domain Question Answering (Shuohang Wang et al., 2017) Shuohang Wang, Mo Yu, Jing Jiang, Wei Zhang, Xiaoxiao Guo, Shiyu Chang, Zhiguo Wang, Tim Klinger, G. Tesauro, Murray Campbell. (2017)\nEvidence Aggregation for Answer Re-Ranking in Open-Domain Question Answering\nICLR\nPaper Link\nInfluential Citation Count (29), SS-ID (8e46f7fbb96549cd1b3b0bd226f06a611126b889)\nABSTRACT\nA popular recent approach to answering open-domain questions is to first search for question-related passages and then apply reading comprehension models to extract answers. Existing methods usually extract answers from single passages independently. But some questions require a combination of evidence from across different sources to answer correctly. In this paper, we propose two models which make use of multiple passages to generate their answers. Both use an answer-reranking approach which reorders the answer candidates generated by an existing state-of-the-art QA model. We propose two methods, namely, strength-based re-ranking and coverage-based re-ranking, to make use of the aggregated evidence from different passages to better determine the answer. Our models have achieved state-of-the-art results on three public open-domain QA datasets: Quasar-T, SearchQA and the open-domain version of TriviaQA, with about 8 percentage points of improvement over the former two datasets.\n\u0026#39;J.\u0026#39; (G. G. Stokes, 1890) G. G. Stokes. (1890)\n\u0026lsquo;J.\u0026rsquo;\nPaper Link\nInfluential Citation Count (69825), SS-ID (90006064cafcb0a9ad8a30cffeb56efe7e14129b)\nABSTRACT\nhowever (for it was the literal soul of the life of the Redeemer, John xv. io), is the peculiar token of fellowship with the Redeemer. That love to God (what is meant here is not God’s love to men) is described in such a case as a perfect love (love that has been perfected), involves no difficulty, for the simple reason that the proposition is purely hypothetical. We must, of course, also take the \u0026amp;dquo;keeping\u0026amp;dquo; in all its stringency. John knows right well that the case supposed here ncver becomes full reality. \u0026amp;dquo; Hereb)’,\u0026amp;dquo; i.e. from the actual realization of love to God. \u0026amp;dquo; TIli7i 7e)e are ill Hinz \u0026amp;dquo;\nDuReader: a Chinese Machine Reading Comprehension Dataset from Real-world Applications (Wei He et al., 2017) Wei He, Kai Liu, Jing Liu, Yajuan Lyu, Shiqi Zhao, Xinyan Xiao, Yuan Liu, Yizhong Wang, Hua Wu, Qiaoqiao She, Xuan Liu, Tian Wu, Haifeng Wang. (2017)\nDuReader: a Chinese Machine Reading Comprehension Dataset from Real-world Applications\nQA@ACL\nPaper Link\nInfluential Citation Count (32), SS-ID (995b7affd684b910d5a1c520c3af00fd20cc39b0)\nABSTRACT\nThis paper introduces DuReader, a new large-scale, open-domain Chinese ma- chine reading comprehension (MRC) dataset, designed to address real-world MRC. DuReader has three advantages over previous MRC datasets: (1) data sources: questions and documents are based on Baidu Search and Baidu Zhidao; answers are manually generated. (2) question types: it provides rich annotations for more question types, especially yes-no and opinion questions, that leaves more opportunity for the research community. (3) scale: it contains 200K questions, 420K answers and 1M documents; it is the largest Chinese MRC dataset so far. Experiments show that human performance is well above current state-of-the-art baseline systems, leaving plenty of room for the community to make improvements. To help the community make these improvements, both DuReader and baseline systems have been posted online. We also organize a shared competition to encourage the exploration of more models. Since the release of the task, there are significant improvements over the baselines.\nRobust object detection via soft cascade (Lubomir D. Bourdev et al., 2005) Lubomir D. Bourdev, Jonathan Brandt. (2005)\nRobust object detection via soft cascade\n2005 IEEE Computer Society Conference on Computer Vision and Pattern Recognition (CVPR'05)\nPaper Link\nInfluential Citation Count (49), SS-ID (9a0024fbad7fcda8af1d241064f0948a8365b969)\nABSTRACT\nWe describe a method for training object detectors using a generalization of the cascade architecture, which results in a detection rate and speed comparable to that of the best published detectors while allowing for easier training and a detector with fewer features. In addition, the method allows for quickly calibrating the detector for a target detection rate, false positive rate or speed. One important advantage of our method is that it enables systematic exploration of the ROC surface, which characterizes the trade-off between accuracy and speed for a given classifier.\nMS MARCO: A Human Generated MAchine Reading COmprehension Dataset (Daniel Fernando Campos et al., 2016) Daniel Fernando Campos, Tri Nguyen, M. Rosenberg, Xia Song, Jianfeng Gao, Saurabh Tiwary, Rangan Majumder, L. Deng, Bhaskar Mitra. (2016)\nMS MARCO: A Human Generated MAchine Reading COmprehension Dataset\nCoCo@NIPS\nPaper Link\nInfluential Citation Count (188), SS-ID (a69cf45d44a9d806d2487a1ffb9eca71ee73c2ee)\nABSTRACT\nThis paper presents our recent work on the design and development of a new, large scale dataset, which we name MS MARCO, for MAchine Reading COmprehension. This new dataset is aimed to overcome a number of well-known weaknesses of previous publicly available datasets for the same task of reading comprehension and question answering. In MS MARCO, all questions are sampled from real anonymized user queries. The context passages, from which answers in the dataset are derived, are extracted from real web documents using the most advanced version of the Bing search engine. The answers to the queries are human generated. Finally, a subset of these queries has multiple answers. We aim to release one million queries and the corresponding answers in the dataset, which, to the best of our knowledge, is the most comprehensive real-world dataset of its kind in both quantity and quality. We are currently releasing 100,000 queries with their corresponding answers to inspire work in reading comprehension and question answering along with gathering feedback from the research community.\n‘H’ (P. Alam, 2021) P. Alam. (2021)\n‘H’\nComposites Engineering: An A–Z Guide\nPaper Link\nInfluential Citation Count (1958), SS-ID (a98ff4e2eb9f759f6c3be4d97852be1b2275b977)\nABSTRACT\nA Joint Many-Task Model: Growing a Neural Network for Multiple NLP Tasks (Kazuma Hashimoto et al., 2016) Kazuma Hashimoto, Caiming Xiong, Yoshimasa Tsuruoka, R. Socher. (2016)\nA Joint Many-Task Model: Growing a Neural Network for Multiple NLP Tasks\nEMNLP\nPaper Link\nInfluential Citation Count (39), SS-ID (ade0c116120b54b57a91da51235108b75c28375a)\nABSTRACT\nTransfer and multi-task learning have traditionally focused on either a single source-target pair or very few, similar tasks. Ideally, the linguistic levels of morphology, syntax and semantics would benefit each other by being trained in a single model. We introduce a joint many-task model together with a strategy for successively growing its depth to solve increasingly complex tasks. Higher layers include shortcut connections to lower-level task predictions to reflect linguistic hierarchies. We use a simple regularization term to allow for optimizing all model weights to improve one task’s loss without exhibiting catastrophic interference of the other tasks. Our single end-to-end model obtains state-of-the-art or competitive results on five different tasks from tagging, parsing, relatedness, and entailment tasks.\nGated Self-Matching Networks for Reading Comprehension and Question Answering (Wenhui Wang et al., 2017) Wenhui Wang, Nan Yang, Furu Wei, Baobao Chang, M. Zhou. (2017)\nGated Self-Matching Networks for Reading Comprehension and Question Answering\nACL\nPaper Link\nInfluential Citation Count (97), SS-ID (b798cfd967e1a9ca5e7bc995d33a907bf65d1c7f)\nABSTRACT\nIn this paper, we present the gated self-matching networks for reading comprehension style question answering, which aims to answer questions from a given passage. We first match the question and passage with gated attention-based recurrent networks to obtain the question-aware passage representation. Then we propose a self-matching attention mechanism to refine the representation by matching the passage against itself, which effectively encodes information from the whole passage. We finally employ the pointer networks to locate the positions of answers from the passages. We conduct extensive experiments on the SQuAD dataset. The single model achieves 71.3% on the evaluation metrics of exact match on the hidden test set, while the ensemble model further boosts the results to 75.9%. At the time of submission of the paper, our model holds the first place on the SQuAD leaderboard for both single and ensemble model.\n‘L’ (P. Alam, 2021) P. Alam. (2021)\n‘L’\nComposites Engineering: An A–Z Guide\nPaper Link\nInfluential Citation Count (2251), SS-ID (cbe020b715b548694bad73e49c5d72854670d6e7)\nABSTRACT\nTeaching Machines to Read and Comprehend (K. Hermann et al., 2015) K. Hermann, Tomás Kociský, Edward Grefenstette, Lasse Espeholt, Will Kay, Mustafa Suleyman, P. Blunsom. (2015)\nTeaching Machines to Read and Comprehend\nNIPS\nPaper Link\nInfluential Citation Count (387), SS-ID (d1505c6123c102e53eb19dff312cb25cea840b72)\nABSTRACT\nTeaching machines to read natural language documents remains an elusive challenge. Machine reading systems can be tested on their ability to answer questions posed on the contents of documents that they have seen, but until now large scale training and test datasets have been missing for this type of evaluation. In this work we define a new methodology that resolves this bottleneck and provides large scale supervised reading comprehension data. This allows us to develop a class of attention based deep neural networks that learn to read real documents and answer complex questions with minimal prior knowledge of language structure.\nCascade Ranking for Operational E-commerce Search (Shichen Liu et al., 2017) Shichen Liu, Fei Xiao, Wenwu Ou, Luo Si. (2017)\nCascade Ranking for Operational E-commerce Search\nKDD\nPaper Link\nInfluential Citation Count (2), SS-ID (dd2a0dd51fe7d066a142bf58d8d9a9c97bc2338e)\nABSTRACT\nIn the \u0026lsquo;Big Data\u0026rsquo; era, many real-world applications like search involve the ranking problem for a large number of items. It is important to obtain effective ranking results and at the same time obtain the results efficiently in a timely manner for providing good user experience and saving computational costs. Valuable prior research has been conducted for learning to efficiently rank like the cascade ranking (learning) model, which uses a sequence of ranking functions to progressively filter some items and rank the remaining items. However, most existing research of learning to efficiently rank in search is studied in a relatively small computing environments with simulated user queries. This paper presents novel research and thorough study of designing and deploying a Cascade model in a Large-scale Operational E-commerce Search application (CLOES), which deals with hundreds of millions of user queries per day with hundreds of servers. The challenge of the real-world application provides new insights for research: 1). Real-world search applications often involve multiple factors of preferences or constraints with respect to user experience and computational costs such as search accuracy, search latency, size of search results and total CPU cost, while most existing search solutions only address one or two factors; 2). Effectiveness of e-commerce search involves multiple types of user behaviors such as click and purchase, while most existing cascade ranking in search only models the click behavior. Based on these observations, a novel cascade ranking model is designed and deployed in an operational e-commerce search application. An extensive set of experiments demonstrate the advantage of the proposed work to address multiple factors of effectiveness, efficiency and user experience in the real-world application.\nReinforced Mnemonic Reader for Machine Comprehension (Minghao Hu et al., 2017) Minghao Hu, Yuxing Peng, Xipeng Qiu. (2017)\nReinforced Mnemonic Reader for Machine Comprehension\nPaper Link\nInfluential Citation Count (13), SS-ID (e148b1bff6a6959fa15f8bc5c5582d8a04d220f9)\nABSTRACT\nIn this paper, we introduce the Reinforced Mnemonic Reader for machine comprehension (MC) task, which aims to answer a query about a given context document. We propose several novel mechanisms that address critical problems in MC that are not adequately solved by previous works, such as enhancing the capacity of encoder, modeling long-term dependencies of contexts, refining the predicted answer span, and directly optimizing the evaluation metric. Extensive experiments on TriviaQA and Stanford Question Answering Dataset (SQuAD) show that our model achieves state-of-the-art results.\nR3: Reinforced Reader-Ranker for Open-Domain Question Answering (Shuohang Wang et al., 2017) Shuohang Wang, Mo Yu, Xiaoxiao Guo, Zhiguo Wang, Tim Klinger, Wei Zhang, Shiyu Chang, G. Tesauro, Bowen Zhou, Jing Jiang. (2017)\nR3: Reinforced Reader-Ranker for Open-Domain Question Answering\nArXiv\nPaper Link\nInfluential Citation Count (18), SS-ID (eac12391f1f7761d5eba71d345cbccbe721971c2)\nABSTRACT\nIn recent years researchers have achieved considerable success applying neural network methods to question answering (QA). These approaches have achieved state of the art results in simplified closed-domain settings such as the SQuAD (Rajpurkar et al., 2016) dataset, which provides a pre-selected passage, from which the answer to a given question may be extracted. More recently, researchers have begun to tackle open-domain QA, in which the model is given a question and access to a large corpus (e.g., wikipedia) instead of a pre-selected passage (Chen et al., 2017a). This setting is more complex as it requires large-scale search for relevant passages by an information retrieval component, combined with a reading comprehension model that \u0026ldquo;reads\u0026rdquo; the passages to generate an answer to the question. Performance in this setting lags considerably behind closed-domain performance. In this paper, we present a novel open-domain QA system called Reinforced Ranker-Reader $(R^3)$, based on two algorithmic innovations. First, we propose a new pipeline for open-domain QA with a Ranker component, which learns to rank retrieved passages in terms of likelihood of generating the ground-truth answer to a given question. Second, we propose a novel method that jointly trains the Ranker along with an answer-generation Reader model, based on reinforcement learning. We report extensive experimental results showing that our method significantly improves on the state of the art for multiple open-domain QA datasets.\n‘E’ (P. Alam, 2021) P. Alam. (2021)\n‘E’\nComposites Engineering: An A–Z Guide\nPaper Link\nInfluential Citation Count (1890), SS-ID (eef0188823e80cad31f67bbdf64dadbbadcc2726)\nABSTRACT\nTriviaQA: A Large Scale Distantly Supervised Challenge Dataset for Reading Comprehension (Mandar Joshi et al., 2017) Mandar Joshi, Eunsol Choi, Daniel S. Weld, Luke Zettlemoyer. (2017)\nTriviaQA: A Large Scale Distantly Supervised Challenge Dataset for Reading Comprehension\nACL\nPaper Link\nInfluential Citation Count (193), SS-ID (f010affab57b5fcf1cd6be23df79d8ec98c7289c)\nABSTRACT\nWe present TriviaQA, a challenging reading comprehension dataset containing over 650K question-answer-evidence triples. TriviaQA includes 95K question-answer pairs authored by trivia enthusiasts and independently gathered evidence documents, six per question on average, that provide high quality distant supervision for answering the questions. We show that, in comparison to other recently introduced large-scale datasets, TriviaQA (1) has relatively complex, compositional questions, (2) has considerable syntactic and lexical variability between questions and corresponding answer-evidence sentences, and (3) requires more cross sentence reasoning to find answers. We also present two baseline algorithms: a feature-based classifier and a state-of-the-art neural network, that performs well on SQuAD reading comprehension. Neither approach comes close to human performance (23% and 40% vs. 80%), suggesting that TriviaQA is a challenging testbed that is worth significant future study. Data and code available at \u0026ndash; this http URL\nMachine Comprehension Using Match-LSTM and Answer Pointer (Shuohang Wang et al., 2016) Shuohang Wang, Jing Jiang. (2016)\nMachine Comprehension Using Match-LSTM and Answer Pointer\nICLR\nPaper Link\nInfluential Citation Count (82), SS-ID (ff1861b71eaedba46cb679bbe2c585dbe18f9b19)\nABSTRACT\nMachine comprehension of text is an important problem in natural language processing. A recently released dataset, the Stanford Question Answering Dataset (SQuAD), offers a large number of real questions and their answers created by humans through crowdsourcing. SQuAD provides a challenging testbed for evaluating machine comprehension algorithms, partly because compared with previous datasets, in SQuAD the answers do not come from a small set of candidate answers and they have variable lengths. We propose an end-to-end neural architecture for the task. The architecture is based on match-LSTM, a model we proposed previously for textual entailment, and Pointer Net, a sequence-to-sequence model proposed by Vinyals et al.(2015) to constrain the output tokens to be from the input sequences. We propose two ways of using Pointer Net for our task. Our experiments show that both of our two models substantially outperform the best results obtained by Rajpurkar et al.(2016) using logistic regression and manually crafted features.\n","date":"May 8, 2022","hero":"/blog-akitenkrad/posts/papers/202205/20220508162318/hero.jpg","permalink":"https://akitenkrad.github.io/blog-akitenkrad/posts/papers/202205/20220508162318/","summary":"Round-1: Overview Round-2: Model Implementation Details Round-3: Experiments Citation Yan, M., Xia, J., Wu, C., Bi, B., Zhao, Z., Zhang, J., Si, L., Wang, R., Wang, W., \u0026amp; Chen, H. (2019).\nA Deep Cascade Model for Multi-Document Reading Comprehension.\nProceedings of the AAAI Conference on Artificial Intelligence, 33, 7354–7361.\nhttps://doi.org/10.1609/aaai.v33i01.33017354 Abstract A fundamental trade-off between effectiveness and efficiency needs to be balanced when designing an online question answering system. Effectiveness comes from sophisticated functions such as extractive machine reading comprehension (MRC), while efficiency is obtained from improvements in preliminary retrieval components such as candidate document selection and paragraph ranking.","tags":["At:Round-1","Published:2019","Question Answering","Extractive MRC","DS:TriviaQA","DS:DuReader","Multi-Document MRC"],"title":"A Deep Cascade Model for Multi-Document Reading Comprehension"},{"categories":null,"contents":" Round-1: Overview Round-2: Model Implementation Details Round-3: Experiments Citation Rogers, A., Kovaleva, O., \u0026amp; Rumshisky, A. (2020).\nA Primer in BERTology: What We Know About How BERT Works.\nTransactions of the Association for Computational Linguistics, 8, 842–866.\nPaper Link Abstract Transformer-based models have pushed state of the art in many areas of NLP, but our understanding of what is behind their success is still limited. This paper is the first survey of over 150 studies of the popular BERT model. We review the current state of knowledge about how BERT works, what kind of information it learns and how it is represented, common modifications to its training objectives and architecture, the overparameterization issue, and approaches to compression. We then outline directions for future research.\nModel History TBD\nWhat Knowledge Does BERT Have? Syntactic Knowledge Lin et al. (2019) Yongjie Lin, Y. Tan, R. Frank. (2019)\nOpen Sesame: Getting inside BERT’s Linguistic Knowledge\nBlackboxNLP@ACL\nPaper Link\nInfluential Citation Count (18), SS-ID (165d51a547cd920e6ac55660ad5c404dcb9562ed)\nABSTRACT\nHow and to what extent does BERT encode syntactically-sensitive hierarchical information or positionally-sensitive linear information? Recent work has shown that contextual representations like BERT perform well on tasks that require sensitivity to linguistic structure. We present here two studies which aim to provide a better understanding of the nature of BERT’s representations. The first of these focuses on the identification of structurally-defined elements using diagnostic classifiers, while the second explores BERT’s representation of subject-verb agreement and anaphor-antecedent dependencies through a quantitative assessment of self-attention vectors. In both cases, we find that BERT encodes positional information about word tokens well on its lower layers, but switches to a hierarchically-oriented encoding on higher layers. We conclude then that BERT’s representations do indeed model linguistically relevant aspects of hierarchical structure, though they do not appear to show the sharp sensitivity to hierarchical structure that is found in human processing of reflexive anaphora.\nBERTの分散表現は線形というよりは階層的である． BERTの分散表現には単語の順番に関する情報以外に文法構造の階層的な情報が含まれている可能性がある． Tenney et al. (2019) Ian Tenney, Patrick Xia, Berlin Chen, Alex Wang, Adam Poliak, R. Thomas McCoy, Najoung Kim, Benjamin Van Durme, Samuel R. Bowman, Dipanjan Das, Ellie Pavlick. (2019)\nWhat do you learn from context? Probing for sentence structure in contextualized word representations\nICLR\nPaper Link\nInfluential Citation Count (45), SS-ID (e2587eddd57bc4ba286d91b27c185083f16f40ee)\nABSTRACT\nContextualized representation models such as ELMo (Peters et al., 2018a) and BERT (Devlin et al., 2018) have recently achieved state-of-the-art results on a diverse array of downstream NLP tasks. Building on recent token-level probing work, we introduce a novel edge probing task design and construct a broad suite of sub-sentence tasks derived from the traditional structured NLP pipeline. We probe word-level contextual representations from four recent models and investigate how they encode sentence structure across a range of syntactic, semantic, local, and long-range phenomena. We find that existing models trained on language modeling and translation produce strong representations for syntactic phenomena, but only offer comparably small improvements on semantic tasks over a non-contextual baseline.\nLiu et al. (2019) Nelson F. Liu, Matt Gardner, Y. Belinkov, Matthew E. Peters, Noah A. Smith. (2019)\nLinguistic Knowledge and Transferability of Contextual Representations\nNAACL\nPaper Link\nInfluential Citation Count (108), SS-ID (f6fbb6809374ca57205bd2cf1421d4f4fa04f975)\nABSTRACT\nContextual word representations derived from large-scale neural language models are successful across a diverse set of NLP tasks, suggesting that they encode useful and transferable features of language. To shed light on the linguistic knowledge they capture, we study the representations produced by several recent pretrained contextualizers (variants of ELMo, the OpenAI transformer language model, and BERT) with a suite of sixteen diverse probing tasks. We find that linear models trained on top of frozen contextual representations are competitive with state-of-the-art task-specific models in many cases, but fail on tasks requiring fine-grained linguistic knowledge (e.g., conjunct identification). To investigate the transferability of contextual word representations, we quantify differences in the transferability of individual layers within contextualizers, especially between recurrent neural networks (RNNs) and transformers. For instance, higher layers of RNNs are more task-specific, while transformer layers do not exhibit the same monotonic trend. In addition, to better understand what makes contextual word representations transferable, we compare language model pretraining with eleven supervised pretraining tasks. For any given task, pretraining on a closely related task yields better performance than language model pretraining (which is better on average) when the pretraining dataset is fixed. However, language model pretraining on more data gives the best results.\nBERTには品詞，文法的なチャンク・格に関する情報が一部含まれている． ただし，文法階層的に遠く離れた親ノードのラベルを復元することはできなかったので，分散表現が保持しているのは単語の近辺の情報に限られる． Htut et al. (2019) Phu Mon Htut, Jason Phang, Shikha Bordia, Samuel R. Bowman. (2019)\nDo Attention Heads in BERT Track Syntactic Dependencies?\nArXiv\nPaper Link\nInfluential Citation Count (12), SS-ID (ba8215e77f35b0d947c7cec39c45df4516e93421)\nABSTRACT\nWe investigate the extent to which individual attention heads in pretrained transformer language models, such as BERT and RoBERTa, implicitly capture syntactic dependency relations. We employ two methods\u0026mdash;taking the maximum attention weight and computing the maximum spanning tree\u0026mdash;to extract implicit dependency relations from the attention weights of each layer/head, and compare them to the ground-truth Universal Dependency (UD) trees. We show that, for some UD relation types, there exist heads that can recover the dependency type significantly better than baselines on parsed English text, suggesting that some self-attention heads act as a proxy for syntactic structure. We also analyze BERT fine-tuned on two datasets\u0026mdash;the syntax-oriented CoLA and the semantics-oriented MNLI\u0026mdash;to investigate whether fine-tuning affects the patterns of their self-attention, but we do not observe substantial differences in the overall dependency relations extracted using our methods. Our results suggest that these models have some specialist attention heads that track individual dependency types, but no generalist head that performs holistic parsing significantly better than a trivial baseline, and that analyzing attention weights directly may not reveal much of the syntactic knowledge that BERT-style models are known to learn.\nJawahar et al. (2019) Ganesh Jawahar, Benoît Sagot, Djamé Seddah. (2019)\nWhat Does BERT Learn about the Structure of Language?\nACL\nPaper Link\nInfluential Citation Count (44), SS-ID (335613303ebc5eac98de757ed02a56377d99e03a)\nABSTRACT\nBERT is a recent language representation model that has surprisingly performed well in diverse language understanding benchmarks. This result indicates the possibility that BERT networks capture structural information about language. In this work, we provide novel support for this claim by performing a series of experiments to unpack the elements of English language structure learned by BERT. Our findings are fourfold. BERT’s phrasal representation captures the phrase-level information in the lower layers. The intermediate layers of BERT compose a rich hierarchy of linguistic information, starting with surface features at the bottom, syntactic features in the middle followed by semantic features at the top. BERT requires deeper layers while tracking subject-verb agreement to handle long-term dependency problem. Finally, the compositional scheme underlying BERT mimics classical, tree-like structures.\n文法構造がどのように埋め込まれるかということに関して， Attention Weights には文法的な構造は直接的には含まれていない． Htut et al. (2019)によれば，文法ツリーのルートの正解データを与えたとしても，Attention Weightsから完全な文法ツリーを構成することはできなかった． Jawahar et al. (2019)は，Attention Weightsから文法ツリーを抽出したとするが，定量的な結果は示されていない． Hewitt and Manning (2019) John Hewitt, Christopher D. Manning. (2019)\nA Structural Probe for Finding Syntax in Word Representations\nNAACL\nPaper Link\nInfluential Citation Count (30), SS-ID (455a8838cde44f288d456d01c76ede95b56dc675)\nABSTRACT\nRecent work has improved our ability to detect linguistic knowledge in word representations. However, current methods for detecting syntactic knowledge do not test whether syntax trees are represented in their entirety. In this work, we propose a structural probe, which evaluates whether syntax trees are embedded in a linear transformation of a neural network’s word representation space. The probe identifies a linear transformation under which squared L2 distance encodes the distance between words in the parse tree, and one in which squared L2 norm encodes depth in the parse tree. Using our probe, we show that such transformations exist for both ELMo and BERT but not in baselines, providing evidence that entire syntax trees are embedded implicitly in deep models’ vector geometry.\n文法の情報はBERTの トークンの分散表現 から復元することができる可能性がある． Hewitt and Manning (2019)では，PenTreebankデータセットを使用して，BERTのトークンの分散表現から文法の依存構造を復元する変換行列を学習することに成功した． Wu et al. (2020) Zhiyong Wu, Yun Chen, B. Kao, Qun Liu. (2020)\nPerturbed Masking: Parameter-free Probing for Analyzing and Interpreting BERT\nACL\nPaper Link\nInfluential Citation Count (10), SS-ID (3aaa8aaad5ef36550a6b47d6ee000f0b346a5a1f)\nABSTRACT\nBy introducing a small set of additional parameters, a probe learns to solve specific linguistic tasks (e.g., dependency parsing) in a supervised manner using feature representations (e.g., contextualized embeddings). The effectiveness of such probing tasks is taken as evidence that the pre-trained model encodes linguistic knowledge. However, this approach of evaluating a language model is undermined by the uncertainty of the amount of knowledge that is learned by the probe itself. Complementary to those works, we propose a parameter-free probing technique for analyzing pre-trained language models (e.g., BERT). Our method does not require direct supervision from the probing tasks, nor do we introduce additional parameters to the probing process. Our experiments on BERT show that syntactic trees recovered from BERT using our method are significantly better than linguistically-uninformed baselines. We further feed the empirically induced dependency structures into a downstream sentiment classification task and find its improvement compatible with or even superior to a human-designed dependency schema.\nMLM (Masked Language Model) タスクにおいて，ある単語が他の単語とどの程度関連性があるかを検証し，BERTは文法的な情報をある程度学習するが，それは正解データに近しいものとは限らないと結論づけた． Figure 1: Parameter-free probe for syntactic know-ledge: words sharing syntactic subtrees have largerimpact on each other in the MLM prediction (Wu et al.,2020).\nGoldberg (2019) Yoav Goldberg. (2019)\nAssessing BERT\u0026rsquo;s Syntactic Abilities\nArXiv\nPaper Link\nInfluential Citation Count (17), SS-ID (efeab0dcdb4c1cce5e537e57745d84774be99b9a)\nABSTRACT\nI assess the extent to which the recently introduced BERT model captures English syntactic phenomena, using (1) naturally-occurring subject-verb agreement stimuli; (2) \u0026ldquo;coloreless green ideas\u0026rdquo; subject-verb agreement stimuli, in which content words in natural sentences are randomly replaced with words sharing the same part-of-speech and inflection; and (3) manually crafted stimuli for subject-verb agreement and reflexive anaphora phenomena. The BERT model performs remarkably well on all cases.\nvan Schijndel et al. (2019) Marten van Schijndel, Aaron Mueller, Tal Linzen. (2019)\nQuantity doesn’t buy quality syntax with neural language models\nEMNLP\nPaper Link\nInfluential Citation Count (0), SS-ID (356645552f8f40adf5a99b4e3a69f47699399010)\nABSTRACT\nRecurrent neural networks can learn to predict upcoming words remarkably well on average; in syntactically complex contexts, however, they often assign unexpectedly high probabilities to ungrammatical words. We investigate to what extent these shortcomings can be mitigated by increasing the size of the network and the corpus on which it is trained. We find that gains from increasing network size are minimal beyond a certain point. Likewise, expanding the training corpus yields diminishing returns; we estimate that the training corpus would need to be unrealistically large for the models to match human performance. A comparison to GPT and BERT, Transformer-based models trained on billions of words, reveals that these models perform even more poorly than our LSTMs in some constructions. Our results make the case for more data efficient architectures.\nBERTはClozeタスクにおいて，主語-述語の関係を加味しながら学習しているが，意味のない文章や曖昧な文章に関しても一律に主語と動詞を関連づけようとしてしまう． Warstadt et al. (2019) Alex Warstadt, Yuning Cao, Ioana Grosu, Wei Peng, Hagen Blix, Yining Nie, Anna Alsop, Shikha Bordia, Haokun Liu, Alicia Parrish, Sheng-Fu Wang, Jason Phang, Anhad Mohananey, Phu Mon Htut, Paloma Jeretic, Samuel R. Bowman. (2019)\nInvestigating BERT’s Knowledge of Language: Five Analysis Methods with NPIs\nEMNLP\nPaper Link\nInfluential Citation Count (4), SS-ID (3cd331c997e90f737810aad6fcce4d993315189f)\nABSTRACT\nThough state-of-the-art sentence representation models can perform tasks requiring significant knowledge of grammar, it is an open question how best to evaluate their grammatical knowledge. We explore five experimental methods inspired by prior work evaluating pretrained sentence representation models. We use a single linguistic phenomenon, negative polarity item (NPI) licensing, as a case study for our experiments. NPIs like any are grammatical only if they appear in a licensing environment like negation (Sue doesn’t have any cats vs. *Sue has any cats). This phenomenon is challenging because of the variety of NPI licensing environments that exist. We introduce an artificially generated dataset that manipulates key features of NPI licensing for the experiments. We find that BERT has significant knowledge of these features, but its success varies widely across different experimental methods. We conclude that a variety of methods is necessary to reveal all relevant aspects of a model’s grammatical knowledge in a given domain.\nBERTは文法のscope violationsを検知するよりも，NPIs (Negative Polarity Items) の存在やNPIsに関連する単語を検知するほうが得意である． Ettinger (2019) Allyson Ettinger. (2019)\nWhat BERT Is Not: Lessons from a New Suite of Psycholinguistic Diagnostics for Language Models\nTACL\nPaper Link\nInfluential Citation Count (10), SS-ID (a0e49f65b6847437f262c59d0d399255101d0b75)\nABSTRACT\nPre-training by language modeling has become a popular and successful approach to NLP tasks, but we have yet to understand exactly what linguistic capacities these pre-training processes confer upon models. In this paper we introduce a suite of diagnostics drawn from human language experiments, which allow us to ask targeted questions about information used by language models for generating predictions in context. As a case study, we apply these diagnostics to the popular BERT model, finding that it can generally distinguish good from bad completions involving shared category or role reversal, albeit with less sensitivity than humans, and it robustly retrieves noun hypernyms, but it struggles with challenging inference and role-based event prediction— and, in particular, it shows clear insensitivity to the contextual impacts of negation.\nVulic (2020) Goran Glavas, Ivan Vulic. (2020)\nIs Supervised Syntactic Parsing Beneficial for Language Understanding Tasks? An Empirical Investigation\nEACL\nPaper Link\nInfluential Citation Count (0), SS-ID (575ac3f36e9fddeb258e2f639e26a6a7ec35160a)\nABSTRACT\nTraditional NLP has long held (supervised) syntactic parsing necessary for successful higher-level semantic language understanding (LU). The recent advent of end-to-end neural models, self-supervised via language modeling (LM), and their success on a wide range of LU tasks, however, questions this belief. In this work, we empirically investigate the usefulness of supervised parsing for semantic LU in the context of LM-pretrained transformer networks. Relying on the established fine-tuning paradigm, we first couple a pretrained transformer with a biaffine parsing head, aiming to infuse explicit syntactic knowledge from Universal Dependencies treebanks into the transformer. We then fine-tune the model for LU tasks and measure the effect of the intermediate parsing training (IPT) on downstream LU task performance. Results from both monolingual English and zero-shot language transfer experiments (with intermediate target-language parsing) show that explicit formalized syntax, injected into transformers through IPT, has very limited and inconsistent effect on downstream LU performance. Our results, coupled with our analysis of transformers’ representation spaces before and after intermediate parsing, make a significant step towards providing answers to an essential question: how (un)availing is supervised parsing for high-level semantic natural language understanding in the era of large neural models?\nBERTは「否定」を理解できず，不正な入力の検知に対しても脆弱である． 単語の語順を入れ替えたり，文章を一部削除したり守護や目的語を取り除いてもBERTの出力結果が変わらなかったため．これが意味するところは，BERTが学習している文法は不完全であるか，またはタスクが文法的な知識に依存していないかのどちらかである． タスクにおける中間段階での教師ありFine-Tuningは下流タスクの性能に大きく影響しないため，後者である可能性が高いとのこと． Semantic Knowledge Tenney et al. (2019) Ian Tenney, Patrick Xia, Berlin Chen, Alex Wang, Adam Poliak, R. Thomas McCoy, Najoung Kim, Benjamin Van Durme, Samuel R. Bowman, Dipanjan Das, Ellie Pavlick. (2019)\nWhat do you learn from context? Probing for sentence structure in contextualized word representations\nICLR\nPaper Link\nInfluential Citation Count (45), SS-ID (e2587eddd57bc4ba286d91b27c185083f16f40ee)\nABSTRACT\nContextualized representation models such as ELMo (Peters et al., 2018a) and BERT (Devlin et al., 2018) have recently achieved state-of-the-art results on a diverse array of downstream NLP tasks. Building on recent token-level probing work, we introduce a novel edge probing task design and construct a broad suite of sub-sentence tasks derived from the traditional structured NLP pipeline. We probe word-level contextual representations from four recent models and investigate how they encode sentence structure across a range of syntactic, semantic, local, and long-range phenomena. We find that existing models trained on language modeling and translation produce strong representations for syntactic phenomena, but only offer comparably small improvements on semantic tasks over a non-contextual baseline.\nClassifierを分析することで，BERTがentity type，relations，semantic roles，proto-rolesに関する情報をエンコードしていることを示した Wallace et al. (2019) Eric Wallace, Yizhong Wang, Sujian Li, Sameer Singh, Matt Gardner. (2019)\nDo NLP Models Know Numbers? Probing Numeracy in Embeddings\nEMNLP\nPaper Link\nInfluential Citation Count (18), SS-ID (0427110f0e79f41e69a8eb00a3ec8868bac26a4f)\nABSTRACT\nThe ability to understand and work with numbers (numeracy) is critical for many complex reasoning tasks. Currently, most NLP models treat numbers in text in the same way as other tokens—they embed them as distributed vectors. Is this enough to capture numeracy? We begin by investigating the numerical reasoning capabilities of a state-of-the-art question answering model on the DROP dataset. We find this model excels on questions that require numerical reasoning, i.e., it already captures numeracy. To understand how this capability emerges, we probe token embedding methods (e.g., BERT, GloVe) on synthetic list maximum, number decoding, and addition tasks. A surprising degree of numeracy is naturally present in standard embeddings. For example, GloVe and word2vec accurately encode magnitude for numbers up to 1,000. Furthermore, character-level embeddings are even more precise—ELMo captures numeracy the best for all pre-trained methods—but BERT, which uses sub-word units, is less exact.\nBERTは数字に関する分散表現が苦手である． 加算や数値のエンコード・デコードに関するタスクではBERTはあまり良い性能を発揮できなかった． BERTのTokenizerであるWordpieceでは，似た数値であってもベクトル空間上では離れた位置に写像されることがありうるため，これが原因の一部である可能性が考えられる． Balasubramanian et al. (2020) S. Balasubramanian, Naman Jain, G. Jindal, Abhijeet Awasthi, Sunita Sarawagi. (2020)\nWhat’s in a Name? Are BERT Named Entity Representations just as Good for any other Name?\nREPL4NLP\nPaper Link\nInfluential Citation Count (1), SS-ID (167f52d369b0979f27282af0f3a1a4be9c9be84b)\nABSTRACT\nWe evaluate named entity representations of BERT-based NLP models by investigating their robustness to replacements from the same typed class in the input. We highlight that on several tasks while such perturbations are natural, state of the art trained models are surprisingly brittle. The brittleness continues even with the recent entity-aware BERT models. We also try to discern the cause of this non-robustness, considering factors such as tokenization and frequency of occurrence. Then we provide a simple method that ensembles predictions from multiple replacements while jointly modeling the uncertainty of type annotations and label predictions. Experiments on three NLP tasks shows that our method enhances robustness and increases accuracy on both natural and adversarial datasets.\nBroscheit (2019) Samuel Broscheit. (2019)\nInvestigating Entity Knowledge in BERT with Simple Neural End-To-End Entity Linking\nCoNLL\nPaper Link\nInfluential Citation Count (6), SS-ID (399308fa54ade9b1362d56628132323489ce50cd)\nABSTRACT\nA typical architecture for end-to-end entity linking systems consists of three steps: mention detection, candidate generation and entity disambiguation. In this study we investigate the following questions: (a) Can all those steps be learned jointly with a model for contextualized text-representations, i.e. BERT? (b) How much entity knowledge is already contained in pretrained BERT? (c) Does additional entity knowledge improve BERT’s performance in downstream tasks? To this end we propose an extreme simplification of the entity linking setup that works surprisingly well: simply cast it as a per token classification over the entire entity vocabulary (over 700K classes in our case). We show on an entity linking benchmark that (i) this model improves the entity representations over plain BERT, (ii) that it outperforms entity linking architectures that optimize the tasks separately and (iii) that it only comes second to the current state-of-the-art that does mention detection and entity disambiguation jointly. Additionally, we investigate the usefulness of entity-aware token-representations in the text-understanding benchmark GLUE, as well as the question answering benchmarks SQUAD~V2 and SWAG and also the EN-DE WMT14 machine translation benchmark. To our surprise, we find that most of those benchmarks do not benefit from additional entity knowledge, except for a task with very small training data, the RTE task in GLUE, which improves by 2%.\nBERTは固有名詞に関する分散表現が苦手である． Balasubramanian et al. (2020) によれば，Coreference Taskにおいて名詞を置換すると，予測結果の85%が変化する．これによれば，NERタスクのF1スコアは高く出るものの，BERTは固有名詞の一般的な概念を理解しているとは言い難い． Broscheit (2019) によれば，Wikipediaのentitiy linkingにおけるBERTのfine-tuningでは，entityに関して追加情報を与えるのみで，entityに関連する情報を全て学習しているわけではない． World Knowledge Ettinger (2019) Allyson Ettinger. (2019)\nWhat BERT Is Not: Lessons from a New Suite of Psycholinguistic Diagnostics for Language Models\nTACL\nPaper Link\nInfluential Citation Count (10), SS-ID (a0e49f65b6847437f262c59d0d399255101d0b75)\nABSTRACT\nPre-training by language modeling has become a popular and successful approach to NLP tasks, but we have yet to understand exactly what linguistic capacities these pre-training processes confer upon models. In this paper we introduce a suite of diagnostics drawn from human language experiments, which allow us to ask targeted questions about information used by language models for generating predictions in context. As a case study, we apply these diagnostics to the popular BERT model, finding that it can generally distinguish good from bad completions involving shared category or role reversal, albeit with less sensitivity than humans, and it robustly retrieves noun hypernyms, but it struggles with challenging inference and role-based event prediction— and, in particular, it shows clear insensitivity to the contextual impacts of negation.\nDa and Kasai (2019) Jeff Da, Jungo Kasai. (2019)\nUnderstanding Commonsense Inference Aptitude of Deep Contextual Representations\nProceedings of the First Workshop on Commonsense Inference in Natural Language Processing\nPaper Link\nInfluential Citation Count (0), SS-ID (80dc7b0e6dbc26571672d9be57a0ae589689e410)\nABSTRACT\nPretrained deep contextual representations have advanced the state-of-the-art on various commonsense NLP tasks, but we lack a concrete understanding of the capability of these models. Thus, we investigate and challenge several aspects of BERT’s commonsense representation abilities. First, we probe BERT’s ability to classify various object attributes, demonstrating that BERT shows a strong ability in encoding various commonsense features in its embedding space, but is still deficient in many areas. Next, we show that, by augmenting BERT’s pretraining data with additional data related to the deficient attributes, we are able to improve performance on a downstream commonsense reasoning task while using a minimal amount of data. Finally, we develop a method of fine-tuning knowledge graphs embeddings alongside BERT and show the continued importance of explicit knowledge graphs.\nBERTは実用的な推論や現実のイベントなどに関する知識の扱いが不得手である． BERTは抽象的な物事や見た目，感覚的な特徴などの扱いも得意ではない． Petroni et al. (2019) Fabio Petroni, Tim Rocktäschel, Patrick Lewis, A. Bakhtin, Yuxiang Wu, Alexander H. Miller, S. Riedel. (2019)\nLanguage Models as Knowledge Bases?\nEMNLP\nPaper Link\nInfluential Citation Count (115), SS-ID (d0086b86103a620a86bc918746df0aa642e2a8a3)\nABSTRACT\nRecent progress in pretraining language models on large textual corpora led to a surge of improvements for downstream NLP tasks. Whilst learning linguistic knowledge, these models may also be storing relational knowledge present in the training data, and may be able to answer queries structured as “fill-in-the-blank” cloze statements. Language models have many advantages over structured knowledge bases: they require no schema engineering, allow practitioners to query about an open class of relations, are easy to extend to more data, and require no human supervision to train. We present an in-depth analysis of the relational knowledge already present (without fine-tuning) in a wide range of state-of-the-art pretrained language models. We find that (i) without fine-tuning, BERT contains relational knowledge competitive with traditional NLP methods that have some access to oracle knowledge, (ii) BERT also does remarkably well on open-domain question answering against a supervised baseline, and (iii) certain types of factual knowledge are learned much more readily than others by standard language model pretraining approaches. The surprisingly strong ability of these models to recall factual knowledge without any fine-tuning demonstrates their potential as unsupervised open-domain QA systems. The code to reproduce our analysis is available at https://github.com/facebookresearch/LAMA.\nRoberts et al. (2020) Adam Roberts, Colin Raffel, Noam M. Shazeer. (2020)\nHow Much Knowledge Can You Pack into the Parameters of a Language Model?\nEMNLP\nPaper Link\nInfluential Citation Count (38), SS-ID (80376bdec5f534be78ba82821f540590ebce5559)\nABSTRACT\nIt has recently been observed that neural language models trained on unstructured text can implicitly store and retrieve knowledge using natural language queries. In this short paper, we measure the practical utility of this approach by fine-tuning pre-trained models to answer questions without access to any external context or knowledge. We show that this approach scales surprisingly well with model size and outperforms models that explicitly look up knowledge on the open-domain variants of Natural Questions and WebQuestions. To facilitate reproducibility and future work, we release our code and trained models.\nDavison et al. (2019) Joshua Feldman, Joe Davison, Alexander M. Rush. (2019)\nCommonsense Knowledge Mining from Pretrained Models\nEMNLP\nPaper Link\nInfluential Citation Count (17), SS-ID (f98e135986414cccf29aec593d547c0656e4d82c)\nABSTRACT\nInferring commonsense knowledge is a key challenge in machine learning. Due to the sparsity of training data, previous work has shown that supervised methods for commonsense knowledge mining underperform when evaluated on novel data. In this work, we develop a method for generating commonsense knowledge using a large, pre-trained bidirectional language model. By transforming relational triples into masked sentences, we can use this model to rank a triple’s validity by the estimated pointwise mutual information between the two entities. Since we do not update the weights of the bidirectional model, our approach is not biased by the coverage of any one commonsense knowledge base. Though we do worse on a held-out test set than models explicitly trained on a corresponding training set, our approach outperforms these methods when mining commonsense knowledge from new sources, suggesting that our unsupervised technique generalizes better than current supervised approaches.\nBERTは関係性の抽出には長けており，シンプルなBERTモデルであってもKnowledge Baseによる手法と同等の精度を発揮することができる． Roberts et al. (2019)はT5を使ってopen-domain QAでも同様の結果が得られることを示した． Davison et al. (2020)によれば，BERTは関係性の推論に関しては汎化性能が高く，未知のデータにも良く対応できる． Forbes et al. (2019) Maxwell Forbes, Ari Holtzman, Yejin Choi. (2019)\nDo Neural Language Representations Learn Physical Commonsense?\nCogSci\nPaper Link\nInfluential Citation Count (3), SS-ID (cc02386375b1262c3a1d5525154eaea24c761d15)\nABSTRACT\nHumans understand language based on the rich background knowledge about how the physical world works, which in turn allows us to reason about the physical world through language. In addition to the properties of objects (e.g., boats require fuel) and their affordances, i.e., the actions that are applicable to them (e.g., boats can be driven), we can also reason about if-then inferences between what properties of objects imply the kind of actions that are applicable to them (e.g., that if we can drive something then it likely requires fuel). In this paper, we investigate the extent to which state-of-the-art neural language representations, trained on a vast amount of natural language text, demonstrate physical commonsense reasoning. While recent advancements of neural language models have demonstrated strong performance on various types of natural language inference tasks, our study based on a dataset of over 200k newly collected annotations suggests that neural language representations still only learn associations that are explicitly written down.\nZhou et al. (2019) Xuhui Zhou, Yue Zhang, Leyang Cui, Dandan Huang. (2019)\nEvaluating Commonsense in Pre-trained Language Models\nAAAI\nPaper Link\nInfluential Citation Count (5), SS-ID (01f2b214962997260020279bd1fd1f8f372249d4)\nABSTRACT\nContextualized representations trained over large raw text data have given remarkable improvements for NLP tasks including question answering and reading comprehension. There have been works showing that syntactic, semantic and word sense knowledge are contained in such representations, which explains why they benefit such tasks. However, relatively little work has been done investigating commonsense knowledge contained in contextualized representations, which is crucial for human question answering and reading comprehension. We study the commonsense ability of GPT, BERT, XLNet, and RoBERTa by testing them on seven challenging benchmarks, finding that language modeling and its variants are effective objectives for promoting models\u0026rsquo; commonsense ability while bi-directional context and larger training set are bonuses. We additionally find that current models do poorly on tasks require more necessary inference steps. Finally, we test the robustness of models by making dual test cases, which are correlated so that the correct prediction of one sample should lead to correct prediction of the other. Interestingly, the models show confusion on these test cases, which suggests that they learn commonsense at the surface rather than the deep level. We release a test set, named CATs publicly, for future research.\nRichardson and Sabharwal (2019) Kyle Richardson, Ashish Sabharwal. (2019)\nWhat Does My QA Model Know? Devising Controlled Probes Using Expert Knowledge\nTransactions of the Association for Computational Linguistics\nPaper Link\nInfluential Citation Count (2), SS-ID (5a9001cdccdb8b1de227a45eccc503d32d1a2464)\nABSTRACT\nAbstract Open-domain question answering (QA) involves many knowledge and reasoning challenges, but are successful QA models actually learning such knowledge when trained on benchmark QA tasks? We investigate this via several new diagnostic tasks probing whether multiple-choice QA models know definitions and taxonomic reasoning—two skills widespread in existing benchmarks and fundamental to more complex reasoning. We introduce a methodology for automatically building probe datasets from expert knowledge sources, allowing for systematic control and a comprehensive evaluation. We include ways to carefully control for artifacts that may arise during this process. Our evaluation confirms that transformer-based multiple-choice QA models are already predisposed to recognize certain types of structural linguistic knowledge. However, it also reveals a more nuanced picture: their performance notably degrades even with a slight increase in the number of “hops” in the underlying taxonomic hierarchy, and with more challenging distractor candidates. Further, existing models are far from perfect when assessed at the level of clusters of semantically connected probes, such as all hypernym questions about a single concept.\nPoerner et al. (2019) Nina Poerner, Ulli Waltinger, Hinrich Schütze. (2019)\nBERT is Not a Knowledge Base (Yet): Factual Knowledge vs. Name-Based Reasoning in Unsupervised QA\nArXiv\nPaper Link\nInfluential Citation Count (8), SS-ID (7c62ac7aedacc39ca417a48f8134e0514dc6a523)\nABSTRACT\nThe BERT language model (LM) (Devlin et al., 2019) is surprisingly good at answering cloze-style questions about relational facts. Petroni et al. (2019) take this as evidence that BERT memorizes factual knowledge during pre-training. We take issue with this interpretation and argue that the performance of BERT is partly due to reasoning about (the surface form of) entity names, e.g., guessing that a person with an Italian-sounding name speaks Italian. More specifically, we show that BERT\u0026rsquo;s precision drops dramatically when we filter certain easy-to-guess facts. As a remedy, we propose E-BERT, an extension of BERT that replaces entity mentions with symbolic entity embeddings. E-BERT outperforms both BERT and ERNIE (Zhang et al., 2019) on hard-to-guess queries. We take this as evidence that E-BERT is richer in factual knowledge, and we show two ways of ensembling BERT and E-BERT.\nBERTはWorld Knowledgeに関する因果推論を行うことはできない． BERTは関係性を推論することはできるが，その関係性の因果については感知しない．例えば，BERTは「人間が家に入る」ということと，「家が大きい」ということはそれぞれ学習できるが，「家が人間よりも大きいかどうか」ということは判断できない． BERTのWorld Knowledgeに関する成功は，現実世界のステレオタイプに依存している．例えば，BERTモデルではアメリカ人であろうとドイツ人であろうと，イタリア風な名前の持ち主はイタリア人であると判断される． Limitations Tenney et al. (2019) Ian Tenney, Dipanjan Das, Ellie Pavlick. (2019)\nBERT Rediscovers the Classical NLP Pipeline\nACL\nPaper Link\nInfluential Citation Count (59), SS-ID (97906df07855b029b7aae7c2a1c6c5e8df1d531c)\nABSTRACT\nPre-trained text encoders have rapidly advanced the state of the art on many NLP tasks. We focus on one such model, BERT, and aim to quantify where linguistic information is captured within the network. We find that the model represents the steps of the traditional NLP pipeline in an interpretable and localizable way, and that the regions responsible for each step appear in the expected sequence: POS tagging, parsing, NER, semantic roles, then coreference. Qualitative analysis reveals that the model can and often does adjust this pipeline dynamically, revising lower-level decisions on the basis of disambiguating information from higher-level representations.\nBERTモデルの深掘りによって文法的・意味的な特徴がモデルから見つからなかったということは，必ずしもBERTモデルがそれらの特徴を持っていないということを意味しているわけではない． よりよりモデルの調査方法が見つかれば，実はモデルがそれらの特徴を保持していたという事実が見つかる可能性は常にある． Warstadt et al. (2019) Alex Warstadt, Yuning Cao, Ioana Grosu, Wei Peng, Hagen Blix, Yining Nie, Anna Alsop, Shikha Bordia, Haokun Liu, Alicia Parrish, Sheng-Fu Wang, Jason Phang, Anhad Mohananey, Phu Mon Htut, Paloma Jeretic, Samuel R. Bowman. (2019)\nInvestigating BERT’s Knowledge of Language: Five Analysis Methods with NPIs\nEMNLP\nPaper Link\nInfluential Citation Count (4), SS-ID (3cd331c997e90f737810aad6fcce4d993315189f)\nABSTRACT\nThough state-of-the-art sentence representation models can perform tasks requiring significant knowledge of grammar, it is an open question how best to evaluate their grammatical knowledge. We explore five experimental methods inspired by prior work evaluating pretrained sentence representation models. We use a single linguistic phenomenon, negative polarity item (NPI) licensing, as a case study for our experiments. NPIs like any are grammatical only if they appear in a licensing environment like negation (Sue doesn’t have any cats vs. *Sue has any cats). This phenomenon is challenging because of the variety of NPI licensing environments that exist. We introduce an artificially generated dataset that manipulates key features of NPI licensing for the experiments. We find that BERT has significant knowledge of these features, but its success varies widely across different experimental methods. We conclude that a variety of methods is necessary to reveal all relevant aspects of a model’s grammatical knowledge in a given domain.\nモデルの調査方法によっては，互いを補完するような結果が出ることもあれば，全く矛盾する結果が出てくることもある． また，一口にBERTと言っても多くの亜種が開発されているので，どのモデルを優先的に調査するかによって結果が変わってくる． 一つの解決策は \u0026ldquo;BERT\u0026rdquo; モデルに注目して，BERTが何に依拠して推論を実施しているのかを明らかにすることである． Pimentel et al. (2020) Tiago Pimentel, Josef Valvoda, Rowan Hall Maudslay, Ran Zmigrod, Adina Williams, Ryan Cotterell. (2020)\nInformation-Theoretic Probing for Linguistic Structure\nACL\nPaper Link\nInfluential Citation Count (16), SS-ID (738c6d664aa6c3854e1aa894957bd595f621fc42)\nABSTRACT\nThe success of neural networks on a diverse set of NLP tasks has led researchers to question how much these networks actually “know” about natural language. Probes are a natural way of assessing this. When probing, a researcher chooses a linguistic task and trains a supervised model to predict annotations in that linguistic task from the network’s learned representations. If the probe does well, the researcher may conclude that the representations encode knowledge related to the task. A commonly held belief is that using simpler models as probes is better; the logic is that simpler models will identify linguistic structure, but not learn the task itself. We propose an information-theoretic operationalization of probing as estimating mutual information that contradicts this received wisdom: one should always select the highest performing probe one can, even if it is more complex, since it will result in a tighter estimate, and thus reveal more of the linguistic information inherent in the representation. The experimental portion of our paper focuses on empirically estimating the mutual information between a linguistic property and BERT, comparing these estimates to several baselines. We evaluate on a set of ten typologically diverse languages often underrepresented in NLP research—plus English—totalling eleven languages. Our implementation is available in https://github.com/rycolab/info-theoretic-probing.\nVoita and Titov (2020) Elena Voita, Ivan Titov. (2020)\nInformation-Theoretic Probing with Minimum Description Length\nEMNLP\nPaper Link\nInfluential Citation Count (13), SS-ID (f4b585c9a79dfce0807b445a09036ea0f9cbcdce)\nABSTRACT\nTo measure how well pretrained representations encode some linguistic property, it is common to use accuracy of a probe, i.e. a classifier trained to predict the property from the representations. Despite widespread adoption of probes, differences in their accuracy fail to adequately reflect differences in representations. For example, they do not substantially favour pretrained representations over randomly initialized ones. Analogously, their accuracy can be similar when probing for genuine linguistic labels and probing for random synthetic tasks. To see reasonable differences in accuracy with respect to these random baselines, previous work had to constrain either the amount of probe training data or its model size. Instead, we propose an alternative to the standard probes, information-theoretic probing with minimum description length (MDL). With MDL probing, training a probe to predict labels is recast as teaching it to effectively transmit the data. Therefore, the measure of interest changes from probe accuracy to the description length of labels given representations. In addition to probe quality, the description length evaluates \u0026ldquo;the amount of effort\u0026rdquo; needed to achieve the quality. This amount of effort characterizes either (i) size of a probing model, or (ii) the amount of data needed to achieve the high quality. We consider two methods for estimating MDL which can be easily implemented on top of the standard probing pipelines: variational coding and online coding. We show that these methods agree in results and are more informative and stable than the standard probes.\n今一つの方向性は，情報理論によるモデル内部の調査である． Pimentel et al. (2020)では，言語情報が与えられたときにモデルがどのような分散表現を学習するのかということに関して，相互情報量を推定するアプローチをとっている． 相互情報量アプローチでは，分散表現に含まれる情報の量よりも，情報をどの程度簡単に抽出できるか，ということに主眼が置かれた． Voita and Titov (2020)では，モデルの分散表現から情報を取り出す場合にどの程度の労力が必要なのかを定量化している． Localizing Linguistic Knowledge BERT Embeddings Mikolov et al. (2013) Tomas Mikolov, Ilya Sutskever, Kai Chen, G. Corrado, J. Dean. (2013)\nDistributed Representations of Words and Phrases and their Compositionality\nNIPS\nPaper Link\nInfluential Citation Count (3587), SS-ID (87f40e6f3022adbc1f1905e3e506abad05a9964f)\nABSTRACT\nThe recently introduced continuous Skip-gram model is an efficient method for learning high-quality distributed vector representations that capture a large number of precise syntactic and semantic word relationships. In this paper we present several extensions that improve both the quality of the vectors and the training speed. By subsampling of the frequent words we obtain significant speedup and also learn more regular word representations. We also describe a simple alternative to the hierarchical softmax called negative sampling. An inherent limitation of word representations is their indifference to word order and their inability to represent idiomatic phrases. For example, the meanings of \u0026ldquo;Canada\u0026rdquo; and \u0026ldquo;Air\u0026rdquo; cannot be easily combined to obtain \u0026ldquo;Air Canada\u0026rdquo;. Motivated by this example, we present a simple method for finding phrases in text, and show that learning good vector representations for millions of phrases is possible.\nKong et al. (2019) Lingpeng Kong, Cyprien de Masson d\u0026rsquo;Autume, Wang Ling, Lei Yu, Zihang Dai, Dani Yogatama. (2019)\nA Mutual Information Maximization Perspective of Language Representation Learning\nICLR\nPaper Link\nInfluential Citation Count (11), SS-ID (b04889922aae7f799affb2ae6508bc5f5c989567)\nABSTRACT\nWe show state-of-the-art word representation learning methods maximize an objective function that is a lower bound on the mutual information between different parts of a word sequence (i.e., a sentence). Our formulation provides an alternative perspective that unifies classical word embedding models (e.g., Skip-gram) and modern contextual embeddings (e.g., BERT, XLNet). In addition to enhancing our theoretical understanding of these methods, our derivation leads to a principled framework that can be used to construct new self-supervised tasks. We provide an example by drawing inspirations from related methods based on mutual information maximization that have been successful in computer vision, and introduce a simple self-supervised objective that maximizes the mutual information between a global sentence representation and n-grams in the sentence. Our analysis offers a holistic view of representation learning methods to transfer knowledge and translate progress across multiple domains (e.g., natural language processing, computer vision, audio processing).\nBERTにおいて，embedding とはTransformerレイヤのアウトプット（特に最終層のアウトプット）を指す． Kong et al. (2019) によれば，Word2Vec（Mikolov et al., 2013）もBERTのembeddingも相互情報量の一種であるとみなすことができるが，BERTのEmbeddingは前者と比較したときに contextualized されているという特徴がある． Akbik et al. (2019) A. Akbik, Tanja Bergmann, Roland Vollgraf. (2019)\nPooled Contextualized Embeddings for Named Entity Recognition\nNAACL\nPaper Link\nInfluential Citation Count (40), SS-ID (edfe9dd16316618e694cd087d0d418dac91eb48c)\nABSTRACT\nContextual string embeddings are a recent type of contextualized word embedding that were shown to yield state-of-the-art results when utilized in a range of sequence labeling tasks. They are based on character-level language models which treat text as distributions over characters and are capable of generating embeddings for any string of characters within any textual context. However, such purely character-based approaches struggle to produce meaningful embeddings if a rare string is used in a underspecified context. To address this drawback, we propose a method in which we dynamically aggregate contextualized embeddings of each unique string that we encounter. We then use a pooling operation to distill a ”global” word representation from all contextualized instances. We evaluate these ”pooled contextualized embeddings” on common named entity recognition (NER) tasks such as CoNLL-03 and WNUT and show that our approach significantly improves the state-of-the-art for NER. We make all code and pre-trained models available to the research community for use and reproduction.\nBommasani et al. (2020) Rishi Bommasani, Kelly Davis, Claire Cardie. (2020)\nInterpreting Pretrained Contextualized Representations via Reductions to Static Embeddings\nACL\nPaper Link\nInfluential Citation Count (17), SS-ID (d34580c522c79d5cde620331dd9ffb18643a8090)\nABSTRACT\nContextualized representations (e.g. ELMo, BERT) have become the default pretrained representations for downstream NLP applications. In some settings, this transition has rendered their static embedding predecessors (e.g. Word2Vec, GloVe) obsolete. As a side-effect, we observe that older interpretability methods for static embeddings — while more diverse and mature than those available for their dynamic counterparts — are underutilized in studying newer contextualized representations. Consequently, we introduce simple and fully general methods for converting from contextualized representations to static lookup-table embeddings which we apply to 5 popular pretrained models and 9 sets of pretrained weights. Our analysis of the resulting static embeddings notably reveals that pooling over many contexts significantly improves representational quality under intrinsic evaluation. Complementary to analyzing representational quality, we consider social biases encoded in pretrained representations with respect to gender, race/ethnicity, and religion and find that bias is encoded disparately across pretrained models and internal layers even for models with the same training data. Concerningly, we find dramatic inconsistencies between social bias estimators for word embeddings.\nMay et al. (2019) Chandler May, Alex Wang, Shikha Bordia, Samuel R. Bowman, Rachel Rudinger. (2019)\nOn Measuring Social Biases in Sentence Encoders\nNAACL\nPaper Link\nInfluential Citation Count (25), SS-ID (5e9c85235210b59a16bdd84b444a904ae271f7e7)\nABSTRACT\nThe Word Embedding Association Test shows that GloVe and word2vec word embeddings exhibit human-like implicit biases based on gender, race, and other social constructs (Caliskan et al., 2017). Meanwhile, research on learning reusable text representations has begun to explore sentence-level texts, with some sentence encoders seeing enthusiastic adoption. Accordingly, we extend the Word Embedding Association Test to measure bias in sentence encoders. We then test several sentence encoders, including state-of-the-art methods such as ELMo and BERT, for the social biases studied in prior work and two important biases that are difficult or impossible to test at the word level. We observe mixed results including suspicious patterns of sensitivity that suggest the test’s assumptions may not hold in general. We conclude by proposing directions for future work on measuring bias in sentence encoders.\nWang et al. (2020) Karthikeyan K, Zihan Wang, Stephen Mayhew, D. Roth. (2019)\nCross-Lingual Ability of Multilingual BERT: An Empirical Study\nICLR\nPaper Link\nInfluential Citation Count (7), SS-ID (3b2538f84812f434c740115c185be3e5e216c526)\nABSTRACT\nRecent work has exhibited the surprising cross-lingual abilities of multilingual BERT (M-BERT) \u0026ndash; surprising since it is trained without any cross-lingual objective and with no aligned data. In this work, we provide a comprehensive study of the contribution of different components in M-BERT to its cross-lingual ability. We study the impact of linguistic properties of the languages, the architecture of the model, and the learning objectives. The experimental study is done in the context of three typologically different languages \u0026ndash; Spanish, Hindi, and Russian \u0026ndash; and using two conceptually different NLP tasks, textual entailment and named entity recognition. Among our key conclusions is the fact that the lexical overlap between languages plays a negligible role in the cross-lingual success, while the depth of the network is an integral part of it. All our models and implementations can be found on our project page: this http URL .\ndistilled contextualized embedding は単語レベルの伝統的なタスクにおける単語の類似度といった表現と比べて，単語の意味に関して多くの情報を含んでいるということが複数の研究によって示されている． Akbik et al. (2019)，Bommasani et al. (2020)，May et al. (2019)，Wang et al. (2020)によればcontextualized representationを蒸留する手法は複数のコンテキストに渡って情報を集約するプロセスを含んでいる． Ethayarajh (2019) Kawin Ethayarajh. (2019)\nHow Contextual are Contextualized Word Representations? Comparing the Geometry of BERT, ELMo, and GPT-2 Embeddings\nEMNLP\nPaper Link\nInfluential Citation Count (29), SS-ID (9d7902e834d5d1d35179962c7a5b9d16623b0d39)\nABSTRACT\nReplacing static word embeddings with contextualized word representations has yielded significant improvements on many NLP tasks. However, just how contextual are the contextualized representations produced by models such as ELMo and BERT? Are there infinitely many context-specific representations for each word, or are words essentially assigned one of a finite number of word-sense representations? For one, we find that the contextualized representations of all words are not isotropic in any layer of the contextualizing model. While representations of the same word in different contexts still have a greater cosine similarity than those of two different words, this self-similarity is much lower in upper layers. This suggests that upper layers of contextualizing models produce more context-specific representations, much like how upper layers of LSTMs produce more task-specific representations. In all layers of ELMo, BERT, and GPT-2, on average, less than 5% of the variance in a word’s contextualized representations can be explained by a static embedding for that word, providing some justification for the success of contextualized representations.\n単語にフォーカスした分散表現をBERT内部のレイヤ間で比較した場合，後ろの方のレイヤはよりcontext-specificな情報を含むように学習されている． もし分散表現の空間が各次元に関して一様なものであるならば（directionally uniform/isotropic） BERTの分散表現においては2つのランダムな単語が思ったよりも高いコサイン類似度を示すことになる． Wiedemann et al. (2019) Gregor Wiedemann, Steffen Remus, Avi Chawla, Chris Biemann. (2019)\nDoes BERT Make Any Sense? Interpretable Word Sense Disambiguation with Contextualized Embeddings\nKONVENS\nPaper Link\nInfluential Citation Count (6), SS-ID (ba8b3d0d2b09bc2b56c6d3f153919786d9fc3075)\nABSTRACT\nContextualized word embeddings (CWE) such as provided by ELMo (Peters et al., 2018), Flair NLP (Akbik et al., 2018), or BERT (Devlin et al., 2019) are a major recent innovation in NLP. CWEs provide semantic vector representations of words depending on their respective context. Their advantage over static word embeddings has been shown for a number of tasks, such as text classification, sequence tagging, or machine translation. Since vectors of the same word type can vary depending on the respective context, they implicitly provide a model for word sense disambiguation (WSD). We introduce a simple but effective approach to WSD using a nearest neighbor classification on CWEs. We compare the performance of different CWE models for the task and can report improvements above the current state of the art for two standard WSD benchmark datasets. We further show that the pre-trained BERT model is able to place polysemic words into distinct \u0026lsquo;sense\u0026rsquo; regions of the embedding space, while ELMo and Flair NLP do not seem to possess this ability.\nSchmidt and Hofmann (2020) Florian Schmidt, T. Hofmann. (2020)\nBERT as a Teacher: Contextual Embeddings for Sequence-Level Reward\nArXiv\nPaper Link\nInfluential Citation Count (0), SS-ID (de9e7d6319b26c0d9f0da20c79403e9b9367fff4)\nABSTRACT\nMeasuring the quality of a generated sequence against a set of references is a central problem in many learning frameworks, be it to compute a score, to assign a reward, or to perform discrimination. Despite great advances in model architectures, metrics that scale independently of the number of references are still based on n-gram estimates. We show that the underlying operations, counting words and comparing counts, can be lifted to embedding words and comparing embeddings. An in-depth analysis of BERT embeddings shows empirically that contextual embeddings can be employed to capture the required dependencies while maintaining the necessary scalability through appropriate pruning and smoothing techniques. We cast unconditional generation as a reinforcement learning problem and show that our reward function indeed provides a more effective learning signal than n-gram reward in this challenging setting.\nBERTの分散表現がcontextualizedされているならば，BERTは多義語や同音異義語といったものに関してどの程度の情報を持っているのか？ BERTのcontextualized embeddingは単語の意味に応じてはっきりと別れたクラスター（distinct clusters）を形成している．これによって，BERTは語義曖昧性解消といったタスクにおいて高い精度を達成することができる． Mickus et al. (2019) Timothee Mickus, Denis Paperno, Mathieu Constant, Kees van Deemter. (2019)\nWhat do you mean, BERT? Assessing BERT as a Distributional Semantics Model\nArXiv\nPaper Link\nInfluential Citation Count (3), SS-ID (4bff291cf7fa02a0dbac767aba55d43ad8c59055)\nABSTRACT\nContextualized word embeddings, i.e. vector representations for words in context, are naturally seen as an extension of previous noncontextual distributional semantic models. In this work, we focus on BERT, a deep neural network that produces contextualized embeddings and has set the state-of-the-art in several semantic tasks, and study the semantic coherence of its embedding space. While showing a tendency towards coherence, BERT does not fully live up to the natural expectations for a semantic vector space. In particular, we find that the position of the sentence in which a word occurs, while having no meaning correlates, leaves a noticeable trace on the word embeddings and disturbs similarity relationships.\nMickus et al. (2019)によれば，BERTにおける単語の分散表現は，同じ単語であったとしても，その単語がどの文章のどの位置に出現するかに依存して変動する．変動の程度によっては，同じ単語の意味がブレることになるので，これは言語学的な観点からは望ましくない． このセクションにおける研究成果は主に単語の分散表現に着目したものであるが，BERTは文章のエンコーダとして使われるのが一般的であることに鑑みれば，単語単位の分散表現だけでなく文章単位の分散表現に関しても詳しく調査すべきである． Self-Attention Heads Attention Head にどのようなタイプが存在するか，ということについてはいくつかの研究成果がある．\nRaganato and Tiedemann (2018) Alessandro Raganato, J. Tiedemann. (2018)\nAn Analysis of Encoder Representations in Transformer-Based Machine Translation\nBlackboxNLP@EMNLP\nPaper Link\nInfluential Citation Count (10), SS-ID (94238dead40b12735d79ed63e29ead70730261a2)\nABSTRACT\nThe attention mechanism is a successful technique in modern NLP, especially in tasks like machine translation. The recently proposed network architecture of the Transformer is based entirely on attention mechanisms and achieves new state of the art results in neural machine translation, outperforming other sequence-to-sequence models. However, so far not much is known about the internal properties of the model and the representations it learns to achieve that performance. To study this question, we investigate the information that is learned by the attention mechanism in Transformer models with different translation quality. We assess the representations of the encoder by extracting dependency relations based on self-attention weights, we perform four probing tasks to study the amount of syntactic and semantic captured information and we also test attention in a transfer learning scenario. Our analysis sheds light on the relative strengths and weaknesses of the various encoder representations. We observe that specific attention heads mark syntactic dependency relations and we can also confirm that lower layers tend to learn more about syntax while higher layers tend to encode more semantics.\nClark et al. (2019) Kevin Clark, Urvashi Khandelwal, Omer Levy, Christopher D. Manning. (2019)\nWhat Does BERT Look at? An Analysis of BERT’s Attention\nBlackboxNLP@ACL\nPaper Link\nInfluential Citation Count (74), SS-ID (95a251513853c6032bdecebd4b74e15795662986)\nABSTRACT\nLarge pre-trained neural networks such as BERT have had great recent success in NLP, motivating a growing body of research investigating what aspects of language they are able to learn from unlabeled data. Most recent analysis has focused on model outputs (e.g., language model surprisal) or internal vector representations (e.g., probing classifiers). Complementary to these works, we propose methods for analyzing the attention mechanisms of pre-trained models and apply them to BERT. BERT’s attention heads exhibit patterns such as attending to delimiter tokens, specific positional offsets, or broadly attending over the whole sentence, with heads in the same layer often exhibiting similar behaviors. We further show that certain attention heads correspond well to linguistic notions of syntax and coreference. For example, we find heads that attend to the direct objects of verbs, determiners of nouns, objects of prepositions, and coreferent mentions with remarkably high accuracy. Lastly, we propose an attention-based probing classifier and use it to further demonstrate that substantial syntactic information is captured in BERT’s attention.\nKovaleva et al. (2019) Olga Kovaleva, Alexey Romanov, Anna Rogers, Anna Rumshisky. (2019)\nRevealing the Dark Secrets of BERT\nEMNLP\nPaper Link\nInfluential Citation Count (34), SS-ID (d78aed1dac6656affa4a04cbf225ced11a83d103)\nABSTRACT\nBERT-based architectures currently give state-of-the-art performance on many NLP tasks, but little is known about the exact mechanisms that contribute to its success. In the current work, we focus on the interpretation of self-attention, which is one of the fundamental underlying components of BERT. Using a subset of GLUE tasks and a set of handcrafted features-of-interest, we propose the methodology and carry out a qualitative and quantitative analysis of the information encoded by the individual BERT’s heads. Our findings suggest that there is a limited set of attention patterns that are repeated across different heads, indicating the overall model overparametrization. While different heads consistently use the same attention patterns, they have varying impact on performance across different tasks. We show that manually disabling attention in certain heads leads to a performance improvement over the regular fine-tuned BERT models.\nRaganato and Tiedemann (2018)によれば，Self-Attention Headsのタイプにはトークン自体に加えて，[CLS]，[SEP]トークンと文章の最後を表すトークンが含まれる． Clark et al. (2019)では，[CLS]，[SEP]トークン，句読点や記号などでタイプが分かれることが議論された． Kovaleva et al. (2019)はSelf-Attention Headsのタイプについて，5つのパターンがあることを示している． Heads with Linguistic Functions Htut et al. (2019) Phu Mon Htut, Jason Phang, Shikha Bordia, Samuel R. Bowman. (2019)\nDo Attention Heads in BERT Track Syntactic Dependencies?\nArXiv\nPaper Link\nInfluential Citation Count (12), SS-ID (ba8215e77f35b0d947c7cec39c45df4516e93421)\nABSTRACT\nWe investigate the extent to which individual attention heads in pretrained transformer language models, such as BERT and RoBERTa, implicitly capture syntactic dependency relations. We employ two methods\u0026mdash;taking the maximum attention weight and computing the maximum spanning tree\u0026mdash;to extract implicit dependency relations from the attention weights of each layer/head, and compare them to the ground-truth Universal Dependency (UD) trees. We show that, for some UD relation types, there exist heads that can recover the dependency type significantly better than baselines on parsed English text, suggesting that some self-attention heads act as a proxy for syntactic structure. We also analyze BERT fine-tuned on two datasets\u0026mdash;the syntax-oriented CoLA and the semantics-oriented MNLI\u0026mdash;to investigate whether fine-tuning affects the patterns of their self-attention, but we do not observe substantial differences in the overall dependency relations extracted using our methods. Our results suggest that these models have some specialist attention heads that track individual dependency types, but no generalist head that performs holistic parsing significantly better than a trivial baseline, and that analyzing attention weights directly may not reveal much of the syntactic knowledge that BERT-style models are known to learn.\nClark et al. (2019) Kevin Clark, Urvashi Khandelwal, Omer Levy, Christopher D. Manning. (2019)\nWhat Does BERT Look at? An Analysis of BERT’s Attention\nBlackboxNLP@ACL\nPaper Link\nInfluential Citation Count (74), SS-ID (95a251513853c6032bdecebd4b74e15795662986)\nABSTRACT\nLarge pre-trained neural networks such as BERT have had great recent success in NLP, motivating a growing body of research investigating what aspects of language they are able to learn from unlabeled data. Most recent analysis has focused on model outputs (e.g., language model surprisal) or internal vector representations (e.g., probing classifiers). Complementary to these works, we propose methods for analyzing the attention mechanisms of pre-trained models and apply them to BERT. BERT’s attention heads exhibit patterns such as attending to delimiter tokens, specific positional offsets, or broadly attending over the whole sentence, with heads in the same layer often exhibiting similar behaviors. We further show that certain attention heads correspond well to linguistic notions of syntax and coreference. For example, we find heads that attend to the direct objects of verbs, determiners of nouns, objects of prepositions, and coreferent mentions with remarkably high accuracy. Lastly, we propose an attention-based probing classifier and use it to further demonstrate that substantial syntactic information is captured in BERT’s attention.\nVoita et al. (2019) Elena Voita, David Talbot, F. Moiseev, Rico Sennrich, Ivan Titov. (2019)\nAnalyzing Multi-Head Self-Attention: Specialized Heads Do the Heavy Lifting, the Rest Can Be Pruned\nACL\nPaper Link\nInfluential Citation Count (49), SS-ID (07a64686ce8e43ac475a8d820a8a9f1d87989583)\nABSTRACT\nMulti-head self-attention is a key component of the Transformer, a state-of-the-art architecture for neural machine translation. In this work we evaluate the contribution made by individual attention heads to the overall performance of the model and analyze the roles played by them in the encoder. We find that the most important and confident heads play consistent and often linguistically-interpretable roles. When pruning heads using a method based on stochastic gates and a differentiable relaxation of the L0 penalty, we observe that specialized heads are last to be pruned. Our novel pruning method removes the vast majority of heads without seriously affecting performance. For example, on the English-Russian WMT dataset, pruning 38 out of 48 encoder heads results in a drop of only 0.15 BLEU.\nHoover et al. (2019) Benjamin Hoover, Hendrik Strobelt, Sebastian Gehrmann. (2019)\nexBERT: A Visual Analysis Tool to Explore Learned Representations in Transformer Models\nACL\nPaper Link\nInfluential Citation Count (4), SS-ID (327d7e55d64cb34d55bd3a3fe58233c238a312cd)\nABSTRACT\nLarge Transformer-based language models can route and reshape complex information via their multi-headed attention mechanism. Although the attention never receives explicit supervision, it can exhibit recognizable patterns following linguistic or positional information. Analyzing the learned representations and attentions is paramount to furthering our understanding of the inner workings of these models. However, analyses have to catch up with the rapid release of new models and the growing diversity of investigation techniques. To support analysis for a wide variety of models, we introduce exBERT, a tool to help humans conduct flexible, interactive investigations and formulate hypotheses for the model-internal reasoning process. exBERT provides insights into the meaning of the contextual representations and attention by matching a human-specified input to similar contexts in large annotated datasets. By aggregating the annotations of the matched contexts, exBERT can quickly replicate findings from literature and extend them to previously not analyzed models.\nZhao and Bethard (2019) Yiyun Zhao, Steven Bethard. (2020)\nHow does BERT’s attention change when you fine-tune? An analysis methodology and a case study in negation scope\nACL\nPaper Link\nInfluential Citation Count (0), SS-ID (868349fe969bc7c6b14b5f35e118a26075b7b1f2)\nABSTRACT\nLarge pretrained language models like BERT, after fine-tuning to a downstream task, have achieved high performance on a variety of NLP problems. Yet explaining their decisions is difficult despite recent work probing their internal representations. We propose a procedure and analysis methods that take a hypothesis of how a transformer-based model might encode a linguistic phenomenon, and test the validity of that hypothesis based on a comparison between knowledge-related downstream tasks with downstream control tasks, and measurement of cross-dataset consistency. We apply this methodology to test BERT and RoBERTa on a hypothesis that some attention heads will consistently attend from a word in negation scope to the negation cue. We find that after fine-tuning BERT and RoBERTa on a negation scope task, the average attention head improves its sensitivity to negation and its attention consistency across negation datasets compared to the pre-trained models. However, only the base models (not the large models) improve compared to a control task, indicating there is evidence for a shallow encoding of negation only in the base models.\nSelf-Attention Headsはそれぞれ，ある文法的な側面に特化して学習されているという可能性がある． Htut et al. (2019)及びClark et al. (2019)によれば，BERTのSelf-Attention Headsはランダムなベースラインに比べて単語の文法的な位置に対して敏感である．両研究で用いられたデータセットは別々であるが，どちらの研究でもSelf-Attention Headsは単語がobjの位置にある場合に敏感に反応すると結論づけている． Hoover et al. (2019)では，dobjなどの複雑な文法的ロールは複数のSelf-Attention Headsの組み合わせで表現されているのではないかという仮説を立てたが，今のところ十分に検証されてはいない． Htut et al. (2019)，Clark et al. (2019)は，どのSelf-Attention Headも単独では文法ツリーの完全な情報を保持していないと結論づけた． ただし，Clark et al (2019)では，共参照解析に単独で分類器として用いることができるSelf-Attention Headが見つかっている．このタスク自体はルールベースのものであるが，多分に文法的な情報を必要とするタスクである． Lin et al. (2019) Yongjie Lin, Y. Tan, R. Frank. (2019)\nOpen Sesame: Getting inside BERT’s Linguistic Knowledge\nBlackboxNLP@ACL\nPaper Link\nInfluential Citation Count (18), SS-ID (165d51a547cd920e6ac55660ad5c404dcb9562ed)\nABSTRACT\nHow and to what extent does BERT encode syntactically-sensitive hierarchical information or positionally-sensitive linear information? Recent work has shown that contextual representations like BERT perform well on tasks that require sensitivity to linguistic structure. We present here two studies which aim to provide a better understanding of the nature of BERT’s representations. The first of these focuses on the identification of structurally-defined elements using diagnostic classifiers, while the second explores BERT’s representation of subject-verb agreement and anaphor-antecedent dependencies through a quantitative assessment of self-attention vectors. In both cases, we find that BERT encodes positional information about word tokens well on its lower layers, but switches to a hierarchically-oriented encoding on higher layers. We conclude then that BERT’s representations do indeed model linguistically relevant aspects of hierarchical structure, though they do not appear to show the sharp sensitivity to hierarchical structure that is found in human processing of reflexive anaphora.\nEttinger (2019) Allyson Ettinger. (2019)\nWhat BERT Is Not: Lessons from a New Suite of Psycholinguistic Diagnostics for Language Models\nTACL\nPaper Link\nInfluential Citation Count (10), SS-ID (a0e49f65b6847437f262c59d0d399255101d0b75)\nABSTRACT\nPre-training by language modeling has become a popular and successful approach to NLP tasks, but we have yet to understand exactly what linguistic capacities these pre-training processes confer upon models. In this paper we introduce a suite of diagnostics drawn from human language experiments, which allow us to ask targeted questions about information used by language models for generating predictions in context. As a case study, we apply these diagnostics to the popular BERT model, finding that it can generally distinguish good from bad completions involving shared category or role reversal, albeit with less sensitivity than humans, and it robustly retrieves noun hypernyms, but it struggles with challenging inference and role-based event prediction— and, in particular, it shows clear insensitivity to the contextual impacts of negation.\nAttention Weights は主語-動詞の対応関係や照応の分析にはあまり役に立たない． Lin et al. (2019)によれば，BERTのSelf-Attention Headsは強く関連づけられるべき単語同士の関係を深く学習するというよりは，それぞれの単語の関係を一様に学習するというべきである．ただし，心理言語学のデータを使った実験において，一部の文法的な誤りに対しては敏感に反応したことがある． Correia et al. (2019) Gonçalo M. Correia, Vlad Niculae, André F. T. Martins. (2019)\nAdaptively Sparse Transformers\nEMNLP\nPaper Link\nInfluential Citation Count (18), SS-ID (f6390beca54411b06f3bde424fb983a451789733)\nABSTRACT\nAttention mechanisms have become ubiquitous in NLP. Recent architectures, notably the Transformer, learn powerful context-aware word representations through layered, multi-headed attention. The multiple heads learn diverse types of word relationships. However, with standard softmax attention, all attention heads are dense, assigning a non-zero weight to all context words. In this work, we introduce the adaptively sparse Transformer, wherein attention heads have flexible, context-dependent sparsity patterns. This sparsity is accomplished by replacing softmax with alpha-entmax: a differentiable generalization of softmax that allows low-scoring words to receive precisely zero weight. Moreover, we derive a method to automatically learn the alpha parameter – which controls the shape and sparsity of alpha-entmax – allowing attention heads to choose between focused or spread-out behavior. Our adaptively sparse Transformer improves interpretability and head diversity when compared to softmax Transformers on machine translation datasets. Findings of the quantitative and qualitative analysis of our approach include that heads in different layers learn different sparsity preferences and tend to be more diverse in their attention distributions than softmax Transformers. Furthermore, at no cost in accuracy, sparsity in attention heads helps to uncover different head specializations.\nBERTのSelf-Attention Headsに関して形態論的な観点からの研究はまだ実施されていない． Correia et al. (2019)では，Tarnsformerの一部のSelf-Attention HeadsがBPE（Byte-Pair Encoding）でトークン化された単語の特徴を取り込んでいるようだということが指摘されている． Clark et al. (2019) Kevin Clark, Urvashi Khandelwal, Omer Levy, Christopher D. Manning. (2019)\nWhat Does BERT Look at? An Analysis of BERT’s Attention\nBlackboxNLP@ACL\nPaper Link\nInfluential Citation Count (74), SS-ID (95a251513853c6032bdecebd4b74e15795662986)\nABSTRACT\nLarge pre-trained neural networks such as BERT have had great recent success in NLP, motivating a growing body of research investigating what aspects of language they are able to learn from unlabeled data. Most recent analysis has focused on model outputs (e.g., language model surprisal) or internal vector representations (e.g., probing classifiers). Complementary to these works, we propose methods for analyzing the attention mechanisms of pre-trained models and apply them to BERT. BERT’s attention heads exhibit patterns such as attending to delimiter tokens, specific positional offsets, or broadly attending over the whole sentence, with heads in the same layer often exhibiting similar behaviors. We further show that certain attention heads correspond well to linguistic notions of syntax and coreference. For example, we find heads that attend to the direct objects of verbs, determiners of nouns, objects of prepositions, and coreferent mentions with remarkably high accuracy. Lastly, we propose an attention-based probing classifier and use it to further demonstrate that substantial syntactic information is captured in BERT’s attention.\nJain and Wallance (2019) Sarthak Jain, Byron C. Wallace. (2019)\nAttention is not Explanation\nNAACL\nPaper Link\nInfluential Citation Count (36), SS-ID (1e83c20def5c84efa6d4a0d80aa3159f55cb9c3f)\nABSTRACT\nAttention mechanisms have seen wide adoption in neural NLP models. In addition to improving predictive performance, these are often touted as affording transparency: models equipped with attention provide a distribution over attended-to input units, and this is often presented (at least implicitly) as communicating the relative importance of inputs. However, it is unclear what relationship exists between attention weights and model outputs. In this work we perform extensive experiments across a variety of NLP tasks that aim to assess the degree to which attention weights provide meaningful “explanations” for predictions. We find that they largely do not. For example, learned attention weights are frequently uncorrelated with gradient-based measures of feature importance, and one can identify very different attention distributions that nonetheless yield equivalent predictions. Our findings show that standard attention modules do not provide meaningful explanations and should not be treated as though they do.\nSerrano and Smith (2019) Sofia Serrano, Noah A. Smith. (2019)\nIs Attention Interpretable?\nACL\nPaper Link\nInfluential Citation Count (16), SS-ID (135112c7ba1762d65f39b1a61777f26ae4dfd8ad)\nABSTRACT\nAttention mechanisms have recently boosted performance on a range of NLP tasks. Because attention layers explicitly weight input components’ representations, it is also often assumed that attention can be used to identify information that models found important (e.g., specific contextualized word tokens). We test whether that assumption holds by manipulating attention weights in already-trained text classification models and analyzing the resulting differences in their predictions. While we observe some ways in which higher attention weights correlate with greater impact on model predictions, we also find many ways in which this does not hold, i.e., where gradient-based rankings of attention weights better predict their effects than their magnitudes. We conclude that while attention noisily predicts input components’ overall importance to a model, it is by no means a fail-safe indicator.1\nWiegreffe and Pinter (2019) Sarah Wiegreffe, Yuval Pinter. (2019)\nAttention is not not Explanation\nEMNLP\nPaper Link\nInfluential Citation Count (12), SS-ID (ce177672b00ddf46e4906157a7e997ca9338b8b9)\nABSTRACT\nAttention mechanisms play a central role in NLP systems, especially within recurrent neural network (RNN) models. Recently, there has been increasing interest in whether or not the intermediate representations offered by these modules may be used to explain the reasoning for a model’s prediction, and consequently reach insights regarding the model’s decision-making process. A recent paper claims that ‘Attention is not Explanation’ (Jain and Wallace, 2019). We challenge many of the assumptions underlying this work, arguing that such a claim depends on one’s definition of explanation, and that testing it needs to take into account all elements of the model. We propose four alternative tests to determine when/whether attention can be used as explanation: a simple uniform-weights baseline; a variance calibration based on multiple random seed runs; a diagnostic framework using frozen weights from pretrained models; and an end-to-end adversarial attention training protocol. Each allows for meaningful interpretation of attention mechanisms in RNN models. We show that even when reliable adversarial distributions can be found, they don’t perform well on the simple diagnostic, indicating that prior work does not disprove the usefulness of attention mechanisms for explainability.\nBrunner et al. (2020) Gino Brunner, Yang Liu, Damian Pascual, Oliver Richter, Massimiliano Ciaramita, Roger Wattenhofer. (2019)\nOn Identifiability in Transformers\nICLR\nPaper Link\nInfluential Citation Count (13), SS-ID (9d7fbdb2e9817a6396992a1c92f75206689852d9)\nABSTRACT\nIn this paper we delve deep in the Transformer architecture by investigating two of its core components: self-attention and contextual embeddings. In particular, we study the identifiability of attention weights and token embeddings, and the aggregation of context into hidden tokens. We show that, for sequences longer than the attention head dimension, attention weights are not identifiable. We propose effective attention as a complementary tool for improving explanatory interpretations based on attention. Furthermore, we show that input tokens retain to a large degree their identity across the model. We also find evidence suggesting that identity information is mainly encoded in the angle of the embeddings and gradually decreases with depth. Finally, we demonstrate strong mixing of input information in the generation of contextual embeddings by means of a novel quantification method based on gradient attribution. Overall, we show that self-attention distributions are not directly interpretable and present tools to better understand and further investigate Transformer models.\n現在のSelf-Attention Headsへの注目度の高さは，「Attention Weightsにはある単語が別の単語に関連してどの程度重みづけられるか，ということが自動的に学習されるため，重みが持つ意味がクリアである」というアイディアによっている． この点は現在活発に議論されており，今のところAttentionレイヤが非線形の活性化関数によって重ねられているような複数レイヤのモデルにおいて，各レイヤが単独で全ての情報を保持するということはない，ということが明らかになっている． Vig (2019) Jesse Vig, Y. Belinkov. (2019)\nAnalyzing the Structure of Attention in a Transformer Language Model\nBlackboxNLP@ACL\nPaper Link\nInfluential Citation Count (8), SS-ID (a039ea239e37f53a2cb60c68e0a1967994353166)\nABSTRACT\nThe Transformer is a fully attention-based alternative to recurrent networks that has achieved state-of-the-art results across a range of NLP tasks. In this paper, we analyze the structure of attention in a Transformer language model, the GPT-2 small pretrained model. We visualize attention for individual instances and analyze the interaction between attention and syntax over a large corpus. We find that attention targets different parts of speech at different layer depths within the model, and that attention aligns with dependency relations most strongly in the middle layers. We also find that the deepest layers of the model capture the most distant relationships. Finally, we extract exemplar sentences that reveal highly specific patterns targeted by particular attention heads.\nHoover et al. (2019) Benjamin Hoover, Hendrik Strobelt, Sebastian Gehrmann. (2019)\nexBERT: A Visual Analysis Tool to Explore Learned Representations in Transformer Models\nACL\nPaper Link\nInfluential Citation Count (4), SS-ID (327d7e55d64cb34d55bd3a3fe58233c238a312cd)\nABSTRACT\nLarge Transformer-based language models can route and reshape complex information via their multi-headed attention mechanism. Although the attention never receives explicit supervision, it can exhibit recognizable patterns following linguistic or positional information. Analyzing the learned representations and attentions is paramount to furthering our understanding of the inner workings of these models. However, analyses have to catch up with the rapid release of new models and the growing diversity of investigation techniques. To support analysis for a wide variety of models, we introduce exBERT, a tool to help humans conduct flexible, interactive investigations and formulate hypotheses for the model-internal reasoning process. exBERT provides insights into the meaning of the contextual representations and attention by matching a human-specified input to similar contexts in large annotated datasets. By aggregating the annotations of the matched contexts, exBERT can quickly replicate findings from literature and extend them to previously not analyzed models.\nSelf-Attention Headsの可視化に関しても，様々なツールが開発されている． 例えば，Vig (2019)，Hoover et al. (2019)など． Attention to Special Tokens Kovaleva et al. (2019) Olga Kovaleva, Alexey Romanov, Anna Rogers, Anna Rumshisky. (2019)\nRevealing the Dark Secrets of BERT\nEMNLP\nPaper Link\nInfluential Citation Count (34), SS-ID (d78aed1dac6656affa4a04cbf225ced11a83d103)\nABSTRACT\nBERT-based architectures currently give state-of-the-art performance on many NLP tasks, but little is known about the exact mechanisms that contribute to its success. In the current work, we focus on the interpretation of self-attention, which is one of the fundamental underlying components of BERT. Using a subset of GLUE tasks and a set of handcrafted features-of-interest, we propose the methodology and carry out a qualitative and quantitative analysis of the information encoded by the individual BERT’s heads. Our findings suggest that there is a limited set of attention patterns that are repeated across different heads, indicating the overall model overparametrization. While different heads consistently use the same attention patterns, they have varying impact on performance across different tasks. We show that manually disabling attention in certain heads leads to a performance improvement over the regular fine-tuned BERT models.\n一つのモデルの中で言語情報を直接エンコードされているSelf-Attention Headsはほとんどない（少なくともGLUEでFine-tuningした場合においては）．なぜならば，Self-Attention Headsのうち heterogeneous のパターンを示したHeadは50%にも満たなかったからである． なお，多くのHeadは vertical パターンを示した． この冗長性の問題はモデルの過学習と関連しているのではないかと考えられている． Kobayashi et al. (2020) Goro Kobayashi, Tatsuki Kuribayashi, Sho Yokoi, Kentaro Inui. (2020)\nAttention Module is Not Only a Weight: Analyzing Transformers with Vector Norms\nArXiv\nPaper Link\nInfluential Citation Count (0), SS-ID (2a8e42995caaedadc9dc739d85bed2c57fc78568)\nABSTRACT\nAttention is a key component of Transformers, which have recently achieved considerable success in natural language processing. Hence, attention is being extensively studied to investigate various linguistic capabilities of Transformers, focusing on analyzing the parallels between attention weights and specific linguistic phenomena. This paper shows that attention weights alone are only one of the two factors that determine the output of attention and proposes a norm-based analysis that incorporates the second factor, the norm of the transformed input vectors. The findings of our norm-based analyses of BERT and a Transformer-based neural machine translation system include the following: (i) contrary to previous studies, BERT pays poor attention to special tokens, and (ii) reasonable word alignment can be extracted from attention mechanisms of Transformer. These findings provide insights into the inner workings of Transformers.\n入力ベクトルに対してSelf-Attention Headで重み付けしたベクトルのノルムは直感的に理解しやすいアウトプットになるが，これらのノルムはspecial tokensに対してはあまり反応しなかった． Lin et al. (2019) Yongjie Lin, Y. Tan, R. Frank. (2019)\nOpen Sesame: Getting inside BERT’s Linguistic Knowledge\nBlackboxNLP@ACL\nPaper Link\nInfluential Citation Count (18), SS-ID (165d51a547cd920e6ac55660ad5c404dcb9562ed)\nABSTRACT\nHow and to what extent does BERT encode syntactically-sensitive hierarchical information or positionally-sensitive linear information? Recent work has shown that contextual representations like BERT perform well on tasks that require sensitivity to linguistic structure. We present here two studies which aim to provide a better understanding of the nature of BERT’s representations. The first of these focuses on the identification of structurally-defined elements using diagnostic classifiers, while the second explores BERT’s representation of subject-verb agreement and anaphor-antecedent dependencies through a quantitative assessment of self-attention vectors. In both cases, we find that BERT encodes positional information about word tokens well on its lower layers, but switches to a hierarchically-oriented encoding on higher layers. We conclude then that BERT’s representations do indeed model linguistically relevant aspects of hierarchical structure, though they do not appear to show the sharp sensitivity to hierarchical structure that is found in human processing of reflexive anaphora.\nHtut et al. (2019) Phu Mon Htut, Jason Phang, Shikha Bordia, Samuel R. Bowman. (2019)\nDo Attention Heads in BERT Track Syntactic Dependencies?\nArXiv\nPaper Link\nInfluential Citation Count (12), SS-ID (ba8215e77f35b0d947c7cec39c45df4516e93421)\nABSTRACT\nWe investigate the extent to which individual attention heads in pretrained transformer language models, such as BERT and RoBERTa, implicitly capture syntactic dependency relations. We employ two methods\u0026mdash;taking the maximum attention weight and computing the maximum spanning tree\u0026mdash;to extract implicit dependency relations from the attention weights of each layer/head, and compare them to the ground-truth Universal Dependency (UD) trees. We show that, for some UD relation types, there exist heads that can recover the dependency type significantly better than baselines on parsed English text, suggesting that some self-attention heads act as a proxy for syntactic structure. We also analyze BERT fine-tuned on two datasets\u0026mdash;the syntax-oriented CoLA and the semantics-oriented MNLI\u0026mdash;to investigate whether fine-tuning affects the patterns of their self-attention, but we do not observe substantial differences in the overall dependency relations extracted using our methods. Our results suggest that these models have some specialist attention heads that track individual dependency types, but no generalist head that performs holistic parsing significantly better than a trivial baseline, and that analyzing attention weights directly may not reveal much of the syntactic knowledge that BERT-style models are known to learn.\nBERT系のモデルの実装においてよく採用される方法は，単語間のAttentionを重視し，special tokensは除外する，というものである． しかし，タスクの推論が，実はspecial tokensに強く依存するものだった場合，単語間のAttentionのみによって得られた推論結果は精度を保証されない可能性が高くなる． 実のところ，special tokensの機能については，まだあまり理解が進んでいない．[CLS]はspecial tokenのひとつかもしれないが，BERTの学習においては各Headの情報がこの[CLS]というトークンに集約されるため，このトークンにはspecial token以外の言語情報も多く含まれていると考えられる． Clark et al. (2019) Kevin Clark, Urvashi Khandelwal, Omer Levy, Christopher D. Manning. (2019)\nWhat Does BERT Look at? An Analysis of BERT’s Attention\nBlackboxNLP@ACL\nPaper Link\nInfluential Citation Count (74), SS-ID (95a251513853c6032bdecebd4b74e15795662986)\nABSTRACT\nLarge pre-trained neural networks such as BERT have had great recent success in NLP, motivating a growing body of research investigating what aspects of language they are able to learn from unlabeled data. Most recent analysis has focused on model outputs (e.g., language model surprisal) or internal vector representations (e.g., probing classifiers). Complementary to these works, we propose methods for analyzing the attention mechanisms of pre-trained models and apply them to BERT. BERT’s attention heads exhibit patterns such as attending to delimiter tokens, specific positional offsets, or broadly attending over the whole sentence, with heads in the same layer often exhibiting similar behaviors. We further show that certain attention heads correspond well to linguistic notions of syntax and coreference. For example, we find heads that attend to the direct objects of verbs, determiners of nouns, objects of prepositions, and coreferent mentions with remarkably high accuracy. Lastly, we propose an attention-based probing classifier and use it to further demonstrate that substantial syntactic information is captured in BERT’s attention.\nClark et al. (2019)はWikipediaの文章を使ってBERTがどの程度spetial tokensを重視しているが実験を実施した． 実験結果によれば，入力に近いレイヤでは[CLS]が，中間レイヤでは[SEP]が，出力に近いレイヤではピリオドとカンマに高い重みが割り当てられていることがわかった． Clark et al. (2019)では，これらのspecial tokensはある種のno-op的な機能を持っているのではないかという仮説を立てている．つまり，各ヘッドが今扱っているケースに対して適用可能かどうかを，これらのspecial tokensを使って判断しているのではないかということである． 興味深いことに，BERTは句読点（punctuation）をかなり重要視している．句読点はspecial tokensと並んで頻繁に出現するものであるため，上記と同じような扱われ方をしているのではないかと考えられている． BERT Layers BERTの最初のレイヤはトークン，セグメント，単語の位置情報のEmbeddingを入力として受け取る．\nLin et al. (2019) Yongjie Lin, Y. Tan, R. Frank. (2019)\nOpen Sesame: Getting inside BERT’s Linguistic Knowledge\nBlackboxNLP@ACL\nPaper Link\nInfluential Citation Count (18), SS-ID (165d51a547cd920e6ac55660ad5c404dcb9562ed)\nABSTRACT\nHow and to what extent does BERT encode syntactically-sensitive hierarchical information or positionally-sensitive linear information? Recent work has shown that contextual representations like BERT perform well on tasks that require sensitivity to linguistic structure. We present here two studies which aim to provide a better understanding of the nature of BERT’s representations. The first of these focuses on the identification of structurally-defined elements using diagnostic classifiers, while the second explores BERT’s representation of subject-verb agreement and anaphor-antecedent dependencies through a quantitative assessment of self-attention vectors. In both cases, we find that BERT encodes positional information about word tokens well on its lower layers, but switches to a hierarchically-oriented encoding on higher layers. We conclude then that BERT’s representations do indeed model linguistically relevant aspects of hierarchical structure, though they do not appear to show the sharp sensitivity to hierarchical structure that is found in human processing of reflexive anaphora.\n最初の方のレイヤは単語の語順に関して最も情報を保持している． Lin et al. (2019)によれば，語順に関する情報はBERT-baseモデルでは4番目のレイヤあたりで減衰し始める．それに伴って文章の階層的な構造に関する情報が増えていく．これらはトークンのインデックスや助動詞，文章の主語を予測するタスクから明らかになっている． Hewitt and Manning (2019) John Hewitt, Christopher D. Manning. (2019)\nA Structural Probe for Finding Syntax in Word Representations\nNAACL\nPaper Link\nInfluential Citation Count (30), SS-ID (455a8838cde44f288d456d01c76ede95b56dc675)\nABSTRACT\nRecent work has improved our ability to detect linguistic knowledge in word representations. However, current methods for detecting syntactic knowledge do not test whether syntax trees are represented in their entirety. In this work, we propose a structural probe, which evaluates whether syntax trees are embedded in a linear transformation of a neural network’s word representation space. The probe identifies a linear transformation under which squared L2 distance encodes the distance between words in the parse tree, and one in which squared L2 norm encodes depth in the parse tree. Using our probe, we show that such transformations exist for both ELMo and BERT but not in baselines, providing evidence that entire syntax trees are embedded implicitly in deep models’ vector geometry.\nGoldberg (2019) Yoav Goldberg. (2019)\nAssessing BERT\u0026rsquo;s Syntactic Abilities\nArXiv\nPaper Link\nInfluential Citation Count (17), SS-ID (efeab0dcdb4c1cce5e537e57745d84774be99b9a)\nABSTRACT\nI assess the extent to which the recently introduced BERT model captures English syntactic phenomena, using (1) naturally-occurring subject-verb agreement stimuli; (2) \u0026ldquo;coloreless green ideas\u0026rdquo; subject-verb agreement stimuli, in which content words in natural sentences are randomly replaced with words sharing the same part-of-speech and inflection; and (3) manually crafted stimuli for subject-verb agreement and reflexive anaphora phenomena. The BERT model performs remarkably well on all cases.\nJawahar et al. (2019) Ganesh Jawahar, Benoît Sagot, Djamé Seddah. (2019)\nWhat Does BERT Learn about the Structure of Language?\nACL\nPaper Link\nInfluential Citation Count (44), SS-ID (335613303ebc5eac98de757ed02a56377d99e03a)\nABSTRACT\nBERT is a recent language representation model that has surprisingly performed well in diverse language understanding benchmarks. This result indicates the possibility that BERT networks capture structural information about language. In this work, we provide novel support for this claim by performing a series of experiments to unpack the elements of English language structure learned by BERT. Our findings are fourfold. BERT’s phrasal representation captures the phrase-level information in the lower layers. The intermediate layers of BERT compose a rich hierarchy of linguistic information, starting with surface features at the bottom, syntactic features in the middle followed by semantic features at the top. BERT requires deeper layers while tracking subject-verb agreement to handle long-term dependency problem. Finally, the compositional scheme underlying BERT mimics classical, tree-like structures.\nLiu et al (2019) Nelson F. Liu, Matt Gardner, Y. Belinkov, Matthew E. Peters, Noah A. Smith. (2019)\nLinguistic Knowledge and Transferability of Contextual Representations\nNAACL\nPaper Link\nInfluential Citation Count (108), SS-ID (f6fbb6809374ca57205bd2cf1421d4f4fa04f975)\nABSTRACT\nContextual word representations derived from large-scale neural language models are successful across a diverse set of NLP tasks, suggesting that they encode useful and transferable features of language. To shed light on the linguistic knowledge they capture, we study the representations produced by several recent pretrained contextualizers (variants of ELMo, the OpenAI transformer language model, and BERT) with a suite of sixteen diverse probing tasks. We find that linear models trained on top of frozen contextual representations are competitive with state-of-the-art task-specific models in many cases, but fail on tasks requiring fine-grained linguistic knowledge (e.g., conjunct identification). To investigate the transferability of contextual word representations, we quantify differences in the transferability of individual layers within contextualizers, especially between recurrent neural networks (RNNs) and transformers. For instance, higher layers of RNNs are more task-specific, while transformer layers do not exhibit the same monotonic trend. In addition, to better understand what makes contextual word representations transferable, we compare language model pretraining with eleven supervised pretraining tasks. For any given task, pretraining on a closely related task yields better performance than language model pretraining (which is better on average) when the pretraining dataset is fixed. However, language model pretraining on more data gives the best results.\n文法に関する情報がBERTの中間レイヤで最も顕著に見られるということは，多くの研究が明らかにしているところである． Hewitt and Manning (2019)ではBERTの中間レイヤから文法ツリーを再構築することに最も成功した研究である（BERT-base: 6-9，BERT-large: 14-19）． Goldberg (2019)は主語と動詞の対応関係が8-9レイヤ付近で最も顕著に捉えられているということを報告している． Jawahar et al. (2019)においても同様に文法に関するタスクでモデルの中間レイヤを使用することで最も精度が高くなることがわかっている． BERTの中間層において文法的な情報が顕著に見られるという事実と関連する研究として，Liu et al. (2019)ではTransformerの中間レイヤが最も他のタスクに転用しやすいレイヤであるということが発見された． 上記の主張とは矛盾する研究もある．\nTenney et al. (2019) Ian Tenney, Dipanjan Das, Ellie Pavlick. (2019)\nBERT Rediscovers the Classical NLP Pipeline\nACL\nPaper Link\nInfluential Citation Count (59), SS-ID (97906df07855b029b7aae7c2a1c6c5e8df1d531c)\nABSTRACT\nPre-trained text encoders have rapidly advanced the state of the art on many NLP tasks. We focus on one such model, BERT, and aim to quantify where linguistic information is captured within the network. We find that the model represents the steps of the traditional NLP pipeline in an interpretable and localizable way, and that the regions responsible for each step appear in the expected sequence: POS tagging, parsing, NER, semantic roles, then coreference. Qualitative analysis reveals that the model can and often does adjust this pipeline dynamically, revising lower-level decisions on the basis of disambiguating information from higher-level representations.\nJawahar et al. (2019) Ganesh Jawahar, Benoît Sagot, Djamé Seddah. (2019)\nWhat Does BERT Learn about the Structure of Language?\nACL\nPaper Link\nInfluential Citation Count (44), SS-ID (335613303ebc5eac98de757ed02a56377d99e03a)\nABSTRACT\nBERT is a recent language representation model that has surprisingly performed well in diverse language understanding benchmarks. This result indicates the possibility that BERT networks capture structural information about language. In this work, we provide novel support for this claim by performing a series of experiments to unpack the elements of English language structure learned by BERT. Our findings are fourfold. BERT’s phrasal representation captures the phrase-level information in the lower layers. The intermediate layers of BERT compose a rich hierarchy of linguistic information, starting with surface features at the bottom, syntactic features in the middle followed by semantic features at the top. BERT requires deeper layers while tracking subject-verb agreement to handle long-term dependency problem. Finally, the compositional scheme underlying BERT mimics classical, tree-like structures.\nLiu et al (2019) Nelson F. Liu, Matt Gardner, Y. Belinkov, Matthew E. Peters, Noah A. Smith. (2019)\nLinguistic Knowledge and Transferability of Contextual Representations\nNAACL\nPaper Link\nInfluential Citation Count (108), SS-ID (f6fbb6809374ca57205bd2cf1421d4f4fa04f975)\nABSTRACT\nContextual word representations derived from large-scale neural language models are successful across a diverse set of NLP tasks, suggesting that they encode useful and transferable features of language. To shed light on the linguistic knowledge they capture, we study the representations produced by several recent pretrained contextualizers (variants of ELMo, the OpenAI transformer language model, and BERT) with a suite of sixteen diverse probing tasks. We find that linear models trained on top of frozen contextual representations are competitive with state-of-the-art task-specific models in many cases, but fail on tasks requiring fine-grained linguistic knowledge (e.g., conjunct identification). To investigate the transferability of contextual word representations, we quantify differences in the transferability of individual layers within contextualizers, especially between recurrent neural networks (RNNs) and transformers. For instance, higher layers of RNNs are more task-specific, while transformer layers do not exhibit the same monotonic trend. In addition, to better understand what makes contextual word representations transferable, we compare language model pretraining with eleven supervised pretraining tasks. For any given task, pretraining on a closely related task yields better performance than language model pretraining (which is better on average) when the pretraining dataset is fixed. However, language model pretraining on more data gives the best results.\nTenney et al. (2019)では，BERTの前半のレイヤでは基本的な文法に関する情報が保持され，後半のレイヤになるほどハイレベルな意味の特徴を捉える傾向が見られると結論づけられている． Jawahar et al. (2019)においても，モデルの最初の方のレイヤはchunkingなどの処理に，中間レイヤはパースなどの処理に有用であると報告されている． 一方，Liu et al. (2019)では，POS-taggingやchunkingなどのタスクは中間層を用いることで最も精度が良くなると報告されている． このように研究によって結論がばらついているが，これらの研究は同じデータセット，パラメータで実験されているわけではないため，単純に横並びで比較することはできない． Liu et al (2019) Nelson F. Liu, Matt Gardner, Y. Belinkov, Matthew E. Peters, Noah A. Smith. (2019)\nLinguistic Knowledge and Transferability of Contextual Representations\nNAACL\nPaper Link\nInfluential Citation Count (108), SS-ID (f6fbb6809374ca57205bd2cf1421d4f4fa04f975)\nABSTRACT\nContextual word representations derived from large-scale neural language models are successful across a diverse set of NLP tasks, suggesting that they encode useful and transferable features of language. To shed light on the linguistic knowledge they capture, we study the representations produced by several recent pretrained contextualizers (variants of ELMo, the OpenAI transformer language model, and BERT) with a suite of sixteen diverse probing tasks. We find that linear models trained on top of frozen contextual representations are competitive with state-of-the-art task-specific models in many cases, but fail on tasks requiring fine-grained linguistic knowledge (e.g., conjunct identification). To investigate the transferability of contextual word representations, we quantify differences in the transferability of individual layers within contextualizers, especially between recurrent neural networks (RNNs) and transformers. For instance, higher layers of RNNs are more task-specific, while transformer layers do not exhibit the same monotonic trend. In addition, to better understand what makes contextual word representations transferable, we compare language model pretraining with eleven supervised pretraining tasks. For any given task, pretraining on a closely related task yields better performance than language model pretraining (which is better on average) when the pretraining dataset is fixed. However, language model pretraining on more data gives the best results.\nKovaleva et al. (2019) Olga Kovaleva, Alexey Romanov, Anna Rogers, Anna Rumshisky. (2019)\nRevealing the Dark Secrets of BERT\nEMNLP\nPaper Link\nInfluential Citation Count (34), SS-ID (d78aed1dac6656affa4a04cbf225ced11a83d103)\nABSTRACT\nBERT-based architectures currently give state-of-the-art performance on many NLP tasks, but little is known about the exact mechanisms that contribute to its success. In the current work, we focus on the interpretation of self-attention, which is one of the fundamental underlying components of BERT. Using a subset of GLUE tasks and a set of handcrafted features-of-interest, we propose the methodology and carry out a qualitative and quantitative analysis of the information encoded by the individual BERT’s heads. Our findings suggest that there is a limited set of attention patterns that are repeated across different heads, indicating the overall model overparametrization. While different heads consistently use the same attention patterns, they have varying impact on performance across different tasks. We show that manually disabling attention in certain heads leads to a performance improvement over the regular fine-tuned BERT models.\nHao et al. (2019) Y. Hao, Li Dong, Furu Wei, Ke Xu. (2019)\nVisualizing and Understanding the Effectiveness of BERT\nEMNLP\nPaper Link\nInfluential Citation Count (3), SS-ID (d3cacb4806886eb2fe59c90d4b6f822c24ff1822)\nABSTRACT\nLanguage model pre-training, such as BERT, has achieved remarkable results in many NLP tasks. However, it is unclear why the pre-training-then-fine-tuning paradigm can improve performance and generalization capability across different tasks. In this paper, we propose to visualize loss landscapes and optimization trajectories of fine-tuning BERT on specific datasets. First, we find that pre-training reaches a good initial point across downstream tasks, which leads to wider optima and easier optimization compared with training from scratch. We also demonstrate that the fine-tuning procedure is robust to overfitting, even though BERT is highly over-parameterized for downstream tasks. Second, the visualization results indicate that fine-tuning BERT tends to generalize better because of the flat and wide optima, and the consistency between the training loss surface and the generalization error surface. Third, the lower layers of BERT are more invariant during fine-tuning, which suggests that the layers that are close to input learn more transferable representations of language.\nBERTの最終層は後続のタスクに特化している． これは，Liu et al. (2019)で報告されているように，モデルの中間層が最も他のタスクに転用しやすくなっているという事実とも付合する． Kovaleva et al. (2019)では，Fine-Tuningにおいてモデルの最終層のパラメータが最も大きく更新されると指摘されているが，こちらも同様に上記の事実を示唆するものである． 同様に，Hao et al. (2019)ではFine-TuningされたBERTモデルに対して低レイヤのパラメータをオリジナルのモデルで上書きしたとしてもタスクの精度に大きな影響は与えないということが報告されている． Tenney et al. (2019) Ian Tenney, Dipanjan Das, Ellie Pavlick. (2019)\nBERT Rediscovers the Classical NLP Pipeline\nACL\nPaper Link\nInfluential Citation Count (59), SS-ID (97906df07855b029b7aae7c2a1c6c5e8df1d531c)\nABSTRACT\nPre-trained text encoders have rapidly advanced the state of the art on many NLP tasks. We focus on one such model, BERT, and aim to quantify where linguistic information is captured within the network. We find that the model represents the steps of the traditional NLP pipeline in an interpretable and localizable way, and that the regions responsible for each step appear in the expected sequence: POS tagging, parsing, NER, semantic roles, then coreference. Qualitative analysis reveals that the model can and often does adjust this pipeline dynamically, revising lower-level decisions on the basis of disambiguating information from higher-level representations.\nTenney et al. (2019)によれば，文法的な情報はモデルの前半のレイヤに集約されている一方で，意味的な情報はモデルのレイヤ全体に分散しているのではないかということが指摘されている． このことは，難しいタスクがモデルの前半のレイヤではうまく回答できないのに対して，モデルの後半のレイヤを使った場合には正解する場合が多いという事実からも示唆される． では，レイヤを重ねれば重ねるほど意味的な情報が蓄積されていくのか，という疑問が生じるが，Tenney et al. (2019)ではBERT-baseとBERT-largeで最終層を使用した場合のタスクのスコアを比較した結果，予想されるほど大きな違いは出ないということがわかった． ただし，Tenney et al. (2019)は文章レベルのsemantic relationsに関する実験の結果である． Training BERT Model Arcitecture Choices Wang et al (2019) Karthikeyan K, Zihan Wang, Stephen Mayhew, D. Roth. (2019)\nCross-Lingual Ability of Multilingual BERT: An Empirical Study\nICLR\nPaper Link\nInfluential Citation Count (7), SS-ID (3b2538f84812f434c740115c185be3e5e216c526)\nABSTRACT\nRecent work has exhibited the surprising cross-lingual abilities of multilingual BERT (M-BERT) \u0026ndash; surprising since it is trained without any cross-lingual objective and with no aligned data. In this work, we provide a comprehensive study of the contribution of different components in M-BERT to its cross-lingual ability. We study the impact of linguistic properties of the languages, the architecture of the model, and the learning objectives. The experimental study is done in the context of three typologically different languages \u0026ndash; Spanish, Hindi, and Russian \u0026ndash; and using two conceptually different NLP tasks, textual entailment and named entity recognition. Among our key conclusions is the fact that the lexical overlap between languages plays a negligible role in the cross-lingual success, while the depth of the network is an integral part of it. All our models and implementations can be found on our project page: this http URL .\nVoita et al. (2019) Elena Voita, David Talbot, F. Moiseev, Rico Sennrich, Ivan Titov. (2019)\nAnalyzing Multi-Head Self-Attention: Specialized Heads Do the Heavy Lifting, the Rest Can Be Pruned\nACL\nPaper Link\nInfluential Citation Count (49), SS-ID (07a64686ce8e43ac475a8d820a8a9f1d87989583)\nABSTRACT\nMulti-head self-attention is a key component of the Transformer, a state-of-the-art architecture for neural machine translation. In this work we evaluate the contribution made by individual attention heads to the overall performance of the model and analyze the roles played by them in the encoder. We find that the most important and confident heads play consistent and often linguistically-interpretable roles. When pruning heads using a method based on stochastic gates and a differentiable relaxation of the L0 penalty, we observe that specialized heads are last to be pruned. Our novel pruning method removes the vast majority of heads without seriously affecting performance. For example, on the English-Russian WMT dataset, pruning 38 out of 48 encoder heads results in a drop of only 0.15 BLEU.\nMichel et al. (2019) Paul Michel, Omer Levy, Graham Neubig. (2019)\nAre Sixteen Heads Really Better than One?\nNeurIPS\nPaper Link\nInfluential Citation Count (49), SS-ID (b03c7ff961822183bab66b2e594415e585d3fd09)\nABSTRACT\nAttention is a powerful and ubiquitous mechanism for allowing neural models to focus on particular salient pieces of information by taking their weighted average when making predictions. In particular, multi-headed attention is a driving force behind many recent state-of-the-art NLP models such as Transformer-based MT models and BERT. These models apply multiple attention mechanisms in parallel, with each attention \u0026ldquo;head\u0026rdquo; potentially focusing on different parts of the input, which makes it possible to express sophisticated functions beyond the simple weighted average. In this paper we make the surprising observation that even if models have been trained using multiple heads, in practice, a large percentage of attention heads can be removed at test time without significantly impacting performance. In fact, some layers can even be reduced to a single head. We further examine greedy algorithms for pruning down models, and the potential speed, memory efficiency, and accuracy improvements obtainable therefrom. Finally, we analyze the results with respect to which parts of the model are more reliant on having multiple heads, and provide precursory evidence that training dynamics play a role in the gains provided by multi-head attention.\nLiu et al. (2019) Nelson F. Liu, Matt Gardner, Y. Belinkov, Matthew E. Peters, Noah A. Smith. (2019)\nLinguistic Knowledge and Transferability of Contextual Representations\nNAACL\nPaper Link\nInfluential Citation Count (108), SS-ID (f6fbb6809374ca57205bd2cf1421d4f4fa04f975)\nABSTRACT\nContextual word representations derived from large-scale neural language models are successful across a diverse set of NLP tasks, suggesting that they encode useful and transferable features of language. To shed light on the linguistic knowledge they capture, we study the representations produced by several recent pretrained contextualizers (variants of ELMo, the OpenAI transformer language model, and BERT) with a suite of sixteen diverse probing tasks. We find that linear models trained on top of frozen contextual representations are competitive with state-of-the-art task-specific models in many cases, but fail on tasks requiring fine-grained linguistic knowledge (e.g., conjunct identification). To investigate the transferability of contextual word representations, we quantify differences in the transferability of individual layers within contextualizers, especially between recurrent neural networks (RNNs) and transformers. For instance, higher layers of RNNs are more task-specific, while transformer layers do not exhibit the same monotonic trend. In addition, to better understand what makes contextual word representations transferable, we compare language model pretraining with eleven supervised pretraining tasks. For any given task, pretraining on a closely related task yields better performance than language model pretraining (which is better on average) when the pretraining dataset is fixed. However, language model pretraining on more data gives the best results.\n論文執筆時点で，BERTのアーキテクチャに関して最もシステマチックな解析を実施したのはWang et al. (2019)である．Wang et al. (2019)では，レイヤの数，Self-Attention Heads，モデルのパラメータをそれぞれ一つずつ変化させて実験を実施した．その結果，Self-Attention Headsの数はレイヤの数に比べてモデルの精度にそれほど大きな影響を与えないという結論に達した． 上記の結論は，Voita et al. (2019)，Michel et al. (2019), Liu et al. (2019)，においても支持されている． Liu et al. (2019) Nelson F. Liu, Matt Gardner, Y. Belinkov, Matthew E. Peters, Noah A. Smith. (2019)\nLinguistic Knowledge and Transferability of Contextual Representations\nNAACL\nPaper Link\nInfluential Citation Count (108), SS-ID (f6fbb6809374ca57205bd2cf1421d4f4fa04f975)\nABSTRACT\nContextual word representations derived from large-scale neural language models are successful across a diverse set of NLP tasks, suggesting that they encode useful and transferable features of language. To shed light on the linguistic knowledge they capture, we study the representations produced by several recent pretrained contextualizers (variants of ELMo, the OpenAI transformer language model, and BERT) with a suite of sixteen diverse probing tasks. We find that linear models trained on top of frozen contextual representations are competitive with state-of-the-art task-specific models in many cases, but fail on tasks requiring fine-grained linguistic knowledge (e.g., conjunct identification). To investigate the transferability of contextual word representations, we quantify differences in the transferability of individual layers within contextualizers, especially between recurrent neural networks (RNNs) and transformers. For instance, higher layers of RNNs are more task-specific, while transformer layers do not exhibit the same monotonic trend. In addition, to better understand what makes contextual word representations transferable, we compare language model pretraining with eleven supervised pretraining tasks. For any given task, pretraining on a closely related task yields better performance than language model pretraining (which is better on average) when the pretraining dataset is fixed. However, language model pretraining on more data gives the best results.\nHao et al. (2019) Y. Hao, Li Dong, Furu Wei, Ke Xu. (2019)\nVisualizing and Understanding the Effectiveness of BERT\nEMNLP\nPaper Link\nInfluential Citation Count (3), SS-ID (d3cacb4806886eb2fe59c90d4b6f822c24ff1822)\nABSTRACT\nLanguage model pre-training, such as BERT, has achieved remarkable results in many NLP tasks. However, it is unclear why the pre-training-then-fine-tuning paradigm can improve performance and generalization capability across different tasks. In this paper, we propose to visualize loss landscapes and optimization trajectories of fine-tuning BERT on specific datasets. First, we find that pre-training reaches a good initial point across downstream tasks, which leads to wider optima and easier optimization compared with training from scratch. We also demonstrate that the fine-tuning procedure is robust to overfitting, even though BERT is highly over-parameterized for downstream tasks. Second, the visualization results indicate that fine-tuning BERT tends to generalize better because of the flat and wide optima, and the consistency between the training loss surface and the generalization error surface. Third, the lower layers of BERT are more invariant during fine-tuning, which suggests that the layers that are close to input learn more transferable representations of language.\nBrunner et al. (2020) Gino Brunner, Yang Liu, Damian Pascual, Oliver Richter, Massimiliano Ciaramita, Roger Wattenhofer. (2019)\nOn Identifiability in Transformers\nICLR\nPaper Link\nInfluential Citation Count (13), SS-ID (9d7fbdb2e9817a6396992a1c92f75206689852d9)\nABSTRACT\nIn this paper we delve deep in the Transformer architecture by investigating two of its core components: self-attention and contextual embeddings. In particular, we study the identifiability of attention weights and token embeddings, and the aggregation of context into hidden tokens. We show that, for sequences longer than the attention head dimension, attention weights are not identifiable. We propose effective attention as a complementary tool for improving explanatory interpretations based on attention. Furthermore, we show that input tokens retain to a large degree their identity across the model. We also find evidence suggesting that identity information is mainly encoded in the angle of the embeddings and gradually decreases with depth. Finally, we demonstrate strong mixing of input information in the generation of contextual embeddings by means of a novel quantification method based on gradient attribution. Overall, we show that self-attention distributions are not directly interpretable and present tools to better understand and further investigate Transformer models.\nKovaleva et al. (2019) Olga Kovaleva, Alexey Romanov, Anna Rogers, Anna Rumshisky. (2019)\nRevealing the Dark Secrets of BERT\nEMNLP\nPaper Link\nInfluential Citation Count (34), SS-ID (d78aed1dac6656affa4a04cbf225ced11a83d103)\nABSTRACT\nBERT-based architectures currently give state-of-the-art performance on many NLP tasks, but little is known about the exact mechanisms that contribute to its success. In the current work, we focus on the interpretation of self-attention, which is one of the fundamental underlying components of BERT. Using a subset of GLUE tasks and a set of handcrafted features-of-interest, we propose the methodology and carry out a qualitative and quantitative analysis of the information encoded by the individual BERT’s heads. Our findings suggest that there is a limited set of attention patterns that are repeated across different heads, indicating the overall model overparametrization. While different heads consistently use the same attention patterns, they have varying impact on performance across different tasks. We show that manually disabling attention in certain heads leads to a performance improvement over the regular fine-tuned BERT models.\nSelf-Attention Headsの数とレイヤの数はそれぞれ別の機能として作用する． モデルの深さは情報の流れに作用すると考えて間違いない．最終層に近いほどタスクに特化した特徴を持ち，入力層に近ければタスクに関する特徴ではなく入力されたトークンに関する情報をより多く保持するようになる．もしこの仮説が正しければ，層が深ければ深いほどモデル全体としてはタスクに特化しない情報を多く蓄えることができるようになる． 一方で，Self-Attention Headsは基本的にいずれのHeadも同じようなパターンを学習しているものと考えらえれる．例えば，Pruningによってモデルの精度に大きな影響が出ない理由はこのあたりにありそうである． Self-Attention Headsにどの程度多様性を持たせることができるか，という点は研究に値する．今のままでは理論的には複数のレイヤで同じ情報をパラメータの重みとして保持してしまっていることになるからである． Press et al. (2020) Ofir Press, Noah A. Smith, Omer Levy. (2019)\nImproving Transformer Models by Reordering their Sublayers\nACL\nPaper Link\nInfluential Citation Count (2), SS-ID (3ff8d265f4351e4b1fdac5b586466bee0b5d6fff)\nABSTRACT\nMultilayer transformer networks consist of interleaved self-attention and feedforward sublayers. Could ordering the sublayers in a different pattern lead to better performance? We generate randomly ordered transformers and train them with the language modeling objective. We observe that some of these models are able to achieve better performance than the interleaved baseline, and that those successful variants tend to have more self-attention at the bottom and more feedforward sublayers at the top. We propose a new transformer pattern that adheres to this property, the sandwich transformer, and show that it improves perplexity on multiple word-level and character-level language modeling benchmarks, at no cost in parameters, memory, or training time. However, the sandwich reordering pattern does not guarantee performance gains across every task, as we demonstrate on machine translation models. Instead, we suggest that further exploration of task-specific sublayer reorderings is needed in order to unlock additional gains.\nBERTはSelf-AttentionとFeed-Forwardレイヤに関して対称的でバランスが取れている（is symmetric and balanced）が，これは必ずしもそうである必要はない． Press et al. (2020)によれば，Self-Attentionレイヤに関しては，最終層に近いレイヤから有益な情報が得られ，一方でFeed-Forwardレイヤに関しては入力層に近いレイヤから良い情報が得られることが多いという． Improvements to the Training Regime Pre-training BERT Fine-tuning BERT How Big Should BERT Be? Overparameterization Compression Techniques Pruning and Model Analysis Directions for Further Research References Evaluating Commonsense in Pre-trained Language Models (Xuhui Zhou et al., 2019) Xuhui Zhou, Yue Zhang, Leyang Cui, Dandan Huang. (2019)\nEvaluating Commonsense in Pre-trained Language Models\nAAAI\nPaper Link\nInfluential Citation Count (5), SS-ID (01f2b214962997260020279bd1fd1f8f372249d4)\nABSTRACT\nContextualized representations trained over large raw text data have given remarkable improvements for NLP tasks including question answering and reading comprehension. There have been works showing that syntactic, semantic and word sense knowledge are contained in such representations, which explains why they benefit such tasks. However, relatively little work has been done investigating commonsense knowledge contained in contextualized representations, which is crucial for human question answering and reading comprehension. We study the commonsense ability of GPT, BERT, XLNet, and RoBERTa by testing them on seven challenging benchmarks, finding that language modeling and its variants are effective objectives for promoting models\u0026rsquo; commonsense ability while bi-directional context and larger training set are bonuses. We additionally find that current models do poorly on tasks require more necessary inference steps. Finally, we test the robustness of models by making dual test cases, which are correlated so that the correct prediction of one sample should lead to correct prediction of the other. Interestingly, the models show confusion on these test cases, which suggests that they learn commonsense at the surface rather than the deep level. We release a test set, named CATs publicly, for future research.\nERNIE: Enhanced Representation through Knowledge Integration (Yu Sun et al., 2019) Yu Sun, Shuohuan Wang, Yukun Li, Shikun Feng, Xuyi Chen, Han Zhang, Xin Tian, Danxiang Zhu, Hao Tian, Hua Wu. (2019)\nERNIE: Enhanced Representation through Knowledge Integration\nArXiv\nPaper Link\nInfluential Citation Count (63), SS-ID (031e4e43aaffd7a479738dcea69a2d5be7957aa3)\nABSTRACT\nWe present a novel language representation model enhanced by knowledge called ERNIE (Enhanced Representation through kNowledge IntEgration). Inspired by the masking strategy of BERT, ERNIE is designed to learn language representation enhanced by knowledge masking strategies, which includes entity-level masking and phrase-level masking. Entity-level strategy masks entities which are usually composed of multiple words.Phrase-level strategy masks the whole phrase which is composed of several words standing together as a conceptual unit.Experimental results show that ERNIE outperforms other baseline methods, achieving new state-of-the-art results on five Chinese natural language processing tasks including natural language inference, semantic similarity, named entity recognition, sentiment analysis and question answering. We also demonstrate that ERNIE has more powerful knowledge inference capacity on a cloze test.\nDo NLP Models Know Numbers? Probing Numeracy in Embeddings (Eric Wallace et al., 2019) Eric Wallace, Yizhong Wang, Sujian Li, Sameer Singh, Matt Gardner. (2019)\nDo NLP Models Know Numbers? Probing Numeracy in Embeddings\nEMNLP\nPaper Link\nInfluential Citation Count (18), SS-ID (0427110f0e79f41e69a8eb00a3ec8868bac26a4f)\nABSTRACT\nThe ability to understand and work with numbers (numeracy) is critical for many complex reasoning tasks. Currently, most NLP models treat numbers in text in the same way as other tokens—they embed them as distributed vectors. Is this enough to capture numeracy? We begin by investigating the numerical reasoning capabilities of a state-of-the-art question answering model on the DROP dataset. We find this model excels on questions that require numerical reasoning, i.e., it already captures numeracy. To understand how this capability emerges, we probe token embedding methods (e.g., BERT, GloVe) on synthetic list maximum, number decoding, and addition tasks. A surprising degree of numeracy is naturally present in standard embeddings. For example, GloVe and word2vec accurately encode magnitude for numbers up to 1,000. Furthermore, character-level embeddings are even more precise—ELMo captures numeracy the best for all pre-trained methods—but BERT, which uses sub-word units, is less exact.\nEmergent linguistic structure in artificial neural networks trained by self-supervision (Christopher D. Manning et al., 2020) Christopher D. Manning, Kevin Clark, John Hewitt, Urvashi Khandelwal, Omer Levy. (2020)\nEmergent linguistic structure in artificial neural networks trained by self-supervision\nProceedings of the National Academy of Sciences\nPaper Link\nInfluential Citation Count (5), SS-ID (04ef54bd467d5e03dee7b0be601cf06d420bffa0)\nABSTRACT\nThis paper explores the knowledge of linguistic structure learned by large artificial neural networks, trained via self-supervision, whereby the model simply tries to predict a masked word in a given context. Human language communication is via sequences of words, but language understanding requires constructing rich hierarchical structures that are never observed explicitly. The mechanisms for this have been a prime mystery of human language acquisition, while engineering work has mainly proceeded by supervised learning on treebanks of sentences hand labeled for this latent structure. However, we demonstrate that modern deep contextual language models learn major aspects of this structure, without any explicit supervision. We develop methods for identifying linguistic hierarchical structure emergent in artificial neural networks and demonstrate that components in these models focus on syntactic grammatical relationships and anaphoric coreference. Indeed, we show that a linear transformation of learned embeddings in these models captures parse tree distances to a surprising degree, allowing approximate reconstruction of the sentence tree structures normally assumed by linguists. These results help explain why these models have brought such large improvements across many language-understanding tasks.\nRoBERTa: A Robustly Optimized BERT Pretraining Approach (Yinhan Liu et al., 2019) Yinhan Liu, Myle Ott, Naman Goyal, Jingfei Du, Mandar Joshi, Danqi Chen, Omer Levy, M. Lewis, Luke Zettlemoyer, Veselin Stoyanov. (2019)\nRoBERTa: A Robustly Optimized BERT Pretraining Approach\nArXiv\nPaper Link\nInfluential Citation Count (2015), SS-ID (077f8329a7b6fa3b7c877a57b81eb6c18b5f87de)\nABSTRACT\nLanguage model pretraining has led to significant performance gains but careful comparison between different approaches is challenging. Training is computationally expensive, often done on private datasets of different sizes, and, as we will show, hyperparameter choices have significant impact on the final results. We present a replication study of BERT pretraining (Devlin et al., 2019) that carefully measures the impact of many key hyperparameters and training data size. We find that BERT was significantly undertrained, and can match or exceed the performance of every model published after it. Our best model achieves state-of-the-art results on GLUE, RACE and SQuAD. These results highlight the importance of previously overlooked design choices, and raise questions about the source of recently reported improvements. We release our models and code.\nAnalyzing Multi-Head Self-Attention: Specialized Heads Do the Heavy Lifting, the Rest Can Be Pruned (Elena Voita et al., 2019) Elena Voita, David Talbot, F. Moiseev, Rico Sennrich, Ivan Titov. (2019)\nAnalyzing Multi-Head Self-Attention: Specialized Heads Do the Heavy Lifting, the Rest Can Be Pruned\nACL\nPaper Link\nInfluential Citation Count (49), SS-ID (07a64686ce8e43ac475a8d820a8a9f1d87989583)\nABSTRACT\nMulti-head self-attention is a key component of the Transformer, a state-of-the-art architecture for neural machine translation. In this work we evaluate the contribution made by individual attention heads to the overall performance of the model and analyze the roles played by them in the encoder. We find that the most important and confident heads play consistent and often linguistically-interpretable roles. When pruning heads using a method based on stochastic gates and a differentiable relaxation of the L0 penalty, we observe that specialized heads are last to be pruned. Our novel pruning method removes the vast majority of heads without seriously affecting performance. For example, on the English-Russian WMT dataset, pruning 38 out of 48 encoder heads results in a drop of only 0.15 BLEU.\nDistilling the Knowledge in a Neural Network (Geoffrey E. Hinton et al., 2015) Geoffrey E. Hinton, Oriol Vinyals, J. Dean. (2015)\nDistilling the Knowledge in a Neural Network\nArXiv\nPaper Link\nInfluential Citation Count (1210), SS-ID (0c908739fbff75f03469d13d4a1a07de3414ee19)\nABSTRACT\nA very simple way to improve the performance of almost any machine learning algorithm is to train many different models on the same data and then to average their predictions. Unfortunately, making predictions using a whole ensemble of models is cumbersome and may be too computationally expensive to allow deployment to a large number of users, especially if the individual models are large neural nets. Caruana and his collaborators have shown that it is possible to compress the knowledge in an ensemble into a single model which is much easier to deploy and we develop this approach further using a different compression technique. We achieve some surprising results on MNIST and we show that we can significantly improve the acoustic model of a heavily used commercial system by distilling the knowledge in an ensemble of models into a single model. We also introduce a new type of ensemble composed of one or more full models and many specialist models which learn to distinguish fine-grained classes that the full models confuse. Unlike a mixture of experts, these specialist models can be trained rapidly and in parallel.\nTinyBERT: Distilling BERT for Natural Language Understanding (Xiaoqi Jiao et al., 2019) Xiaoqi Jiao, Yichun Yin, Lifeng Shang, Xin Jiang, Xiao Chen, Linlin Li, F. Wang, Qun Liu. (2019)\nTinyBERT: Distilling BERT for Natural Language Understanding\nFINDINGS\nPaper Link\nInfluential Citation Count (131), SS-ID (0cbf97173391b0430140117027edcaf1a37968c7)\nABSTRACT\nLanguage model pre-training, such as BERT, has significantly improved the performances of many natural language processing tasks. However, pre-trained language models are usually computationally expensive, so it is difficult to efficiently execute them on resource-restricted devices. To accelerate inference and reduce model size while maintaining accuracy, we first propose a novel Transformer distillation method that is specially designed for knowledge distillation (KD) of the Transformer-based models. By leveraging this new KD method, the plenty of knowledge encoded in a large “teacher” BERT can be effectively transferred to a small “student” TinyBERT. Then, we introduce a new two-stage learning framework for TinyBERT, which performs Transformer distillation at both the pre-training and task-specific learning stages. This framework ensures that TinyBERT can capture the general-domain as well as the task-specific knowledge in BERT. TinyBERT4 with 4 layers is empirically effective and achieves more than 96.8% the performance of its teacher BERT-Base on GLUE benchmark, while being 7.5x smaller and 9.4x faster on inference. TinyBERT4 is also significantly better than 4-layer state-of-the-art baselines on BERT distillation, with only ~28% parameters and ~31% inference time of them. Moreover, TinyBERT6 with 6 layers performs on-par with its teacher BERT-Base.\nMPNet: Masked and Permuted Pre-training for Language Understanding (Kaitao Song et al., 2020) Kaitao Song, Xu Tan, Tao Qin, Jianfeng Lu, Tie-Yan Liu. (2020)\nMPNet: Masked and Permuted Pre-training for Language Understanding\nNeurIPS\nPaper Link\nInfluential Citation Count (16), SS-ID (0e002114cd379efaca0ec5cda6d262b5fe0be104)\nABSTRACT\nBERT adopts masked language modeling (MLM) for pre-training and is one of the most successful pre-training models. Since BERT neglects dependency among predicted tokens, XLNet introduces permuted language modeling (PLM) for pre-training to address this problem. We argue that XLNet does not leverage the full position information of a sentence and thus suffers from position discrepancy between pre-training and fine-tuning. In this paper, we propose MPNet, a novel pre-training method that inherits the advantages of BERT and XLNet and avoids their limitations. MPNet leverages the dependency among predicted tokens through permuted language modeling (vs. MLM in BERT), and takes auxiliary position information as input to make the model see a full sentence and thus reducing the position discrepancy (vs. PLM in XLNet). We pre-train MPNet on a large-scale dataset (over 160GB text corpora) and fine-tune on a variety of down-streaming tasks (GLUE, SQuAD, etc). Experimental results show that MPNet outperforms MLM and PLM by a large margin, and achieves better results on these tasks compared with previous state-of-the-art pre-trained methods (e.g., BERT, XLNet, RoBERTa) under the same model setting. We release the code and pre-trained model in GitHub\\footnote{\\url{this https URL}}.\nCan neural networks acquire a structural bias from raw linguistic data? (Alex Warstadt et al., 2020) Alex Warstadt, Samuel R. Bowman. (2020)\nCan neural networks acquire a structural bias from raw linguistic data?\nCogSci\nPaper Link\nInfluential Citation Count (3), SS-ID (0e012c2bd18236445cfbc6e3e409eb02df4691fe)\nABSTRACT\nWe evaluate whether BERT, a widely used neural network for sentence processing, acquires an inductive bias towards forming structural generalizations through pretraining on raw data. We conduct four experiments testing its preference for structural vs. linear generalizations in different structure-dependent phenomena. We find that BERT makes a structural generalization in 3 out of 4 empirical domains\u0026mdash;subject-auxiliary inversion, reflexive binding, and verb tense detection in embedded clauses\u0026mdash;but makes a linear generalization when tested on NPI licensing. We argue that these results are the strongest evidence so far from artificial learners supporting the proposition that a structural bias can be acquired from raw data. If this conclusion is correct, it is tentative evidence that some linguistic universals can be acquired by learners without innate biases. However, the precise implications for human language acquisition are unclear, as humans learn language from significantly less data than BERT.\nThe Bottom-up Evolution of Representations in the Transformer: A Study with Machine Translation and Language Modeling Objectives (Elena Voita et al., 2019) Elena Voita, Rico Sennrich, Ivan Titov. (2019)\nThe Bottom-up Evolution of Representations in the Transformer: A Study with Machine Translation and Language Modeling Objectives\nEMNLP\nPaper Link\nInfluential Citation Count (10), SS-ID (112fd54ee193237b24f2ce7fce79e399609a29c5)\nABSTRACT\nWe seek to understand how the representations of individual tokens and the structure of the learned feature space evolve between layers in deep neural networks under different learning objectives. We chose the Transformers for our analysis as they have been shown effective with various tasks, including machine translation (MT), standard left-to-right language models (LM) and masked language modeling (MLM). Previous work used black-box probing tasks to show that the representations learned by the Transformer differ significantly depending on the objective. In this work, we use canonical correlation analysis and mutual information estimators to study how information flows across Transformer layers and observe that the choice of the objective determines this process. For example, as you go from bottom to top layers, information about the past in left-to-right language models gets vanished and predictions about the future get formed. In contrast, for MLM, representations initially acquire information about the context around the token, partially forgetting the token identity and producing a more generalized token representation. The token identity then gets recreated at the top MLM layers.\nUsing Dynamic Embeddings to Improve Static Embeddings (Yile Wang et al., 2019) Yile Wang, Leyang Cui, Yue Zhang. (2019)\nUsing Dynamic Embeddings to Improve Static Embeddings\nArXiv\nPaper Link\nInfluential Citation Count (1), SS-ID (1257f59bd9b6bc3f3823125408c7b6e63db4a158)\nABSTRACT\nHow to build high-quality word embeddings is a fundamental research question in the field of natural language processing. Traditional methods such as Skip-Gram and Continuous Bag-of-Words learn {\\it static} embeddings by training lookup tables that translate words into dense vectors. Static embeddings are directly useful for solving lexical semantics tasks, and can be used as input representations for downstream problems. Recently, contextualized embeddings such as BERT have been shown more effective than static embeddings as NLP input embeddings. Such embeddings are {\\it dynamic}, calculated according to a sentential context using a network structure. One limitation of dynamic embeddings, however, is that they cannot be used without a sentence-level context. We explore the advantages of dynamic embeddings for training static embeddings, by using contextualized embeddings to facilitate training of static embedding lookup tables. Results show that the resulting embeddings outperform existing static embedding methods on various lexical semantics tasks.\nIs Attention Interpretable? (Sofia Serrano et al., 2019) Sofia Serrano, Noah A. Smith. (2019)\nIs Attention Interpretable?\nACL\nPaper Link\nInfluential Citation Count (16), SS-ID (135112c7ba1762d65f39b1a61777f26ae4dfd8ad)\nABSTRACT\nAttention mechanisms have recently boosted performance on a range of NLP tasks. Because attention layers explicitly weight input components’ representations, it is also often assumed that attention can be used to identify information that models found important (e.g., specific contextualized word tokens). We test whether that assumption holds by manipulating attention weights in already-trained text classification models and analyzing the resulting differences in their predictions. While we observe some ways in which higher attention weights correlate with greater impact on model predictions, we also find many ways in which this does not hold, i.e., where gradient-based rankings of attention weights better predict their effects than their magnitudes. We conclude that while attention noisily predicts input components’ overall importance to a model, it is by no means a fail-safe indicator.1\nOpen Sesame: Getting inside BERT’s Linguistic Knowledge (Yongjie Lin et al., 2019) Yongjie Lin, Y. Tan, R. Frank. (2019)\nOpen Sesame: Getting inside BERT’s Linguistic Knowledge\nBlackboxNLP@ACL\nPaper Link\nInfluential Citation Count (18), SS-ID (165d51a547cd920e6ac55660ad5c404dcb9562ed)\nABSTRACT\nHow and to what extent does BERT encode syntactically-sensitive hierarchical information or positionally-sensitive linear information? Recent work has shown that contextual representations like BERT perform well on tasks that require sensitivity to linguistic structure. We present here two studies which aim to provide a better understanding of the nature of BERT’s representations. The first of these focuses on the identification of structurally-defined elements using diagnostic classifiers, while the second explores BERT’s representation of subject-verb agreement and anaphor-antecedent dependencies through a quantitative assessment of self-attention vectors. In both cases, we find that BERT encodes positional information about word tokens well on its lower layers, but switches to a hierarchically-oriented encoding on higher layers. We conclude then that BERT’s representations do indeed model linguistically relevant aspects of hierarchical structure, though they do not appear to show the sharp sensitivity to hierarchical structure that is found in human processing of reflexive anaphora.\nWhat’s in a Name? Are BERT Named Entity Representations just as Good for any other Name? (S. Balasubramanian et al., 2020) S. Balasubramanian, Naman Jain, G. Jindal, Abhijeet Awasthi, Sunita Sarawagi. (2020)\nWhat’s in a Name? Are BERT Named Entity Representations just as Good for any other Name?\nREPL4NLP\nPaper Link\nInfluential Citation Count (1), SS-ID (167f52d369b0979f27282af0f3a1a4be9c9be84b)\nABSTRACT\nWe evaluate named entity representations of BERT-based NLP models by investigating their robustness to replacements from the same typed class in the input. We highlight that on several tasks while such perturbations are natural, state of the art trained models are surprisingly brittle. The brittleness continues even with the recent entity-aware BERT models. We also try to discern the cause of this non-robustness, considering factors such as tokenization and frequency of occurrence. Then we provide a simple method that ensembles predictions from multiple replacements while jointly modeling the uncertainty of type annotations and label predictions. Experiments on three NLP tasks shows that our method enhances robustness and increases accuracy on both natural and adversarial datasets.\nConditional BERT Contextual Augmentation (Xing Wu et al., 2018) Xing Wu, Shangwen Lv, Liangjun Zang, Jizhong Han, Songlin Hu. (2018)\nConditional BERT Contextual Augmentation\nICCS\nPaper Link\nInfluential Citation Count (21), SS-ID (188024469a2443f262b3cbb5c5d4a96851949d68)\nABSTRACT\nData augmentation methods are often applied to prevent overfitting and improve generalization of deep neural network models. Recently proposed contextual augmentation augments labeled sentences by randomly replacing words with more varied substitutions predicted by language model. Bidirectional Encoder Representations from Transformers (BERT) demonstrates that a deep bidirectional language model is more powerful than either an unidirectional language model or the shallow concatenation of a forward and backward model. We propose a novel data augmentation method for labeled sentences called conditional BERT contextual augmentation. We retrofit BERT to conditional BERT by introducing a new conditional masked language model (The term “conditional masked language model” appeared once in original BERT paper, which indicates context-conditional, is equivalent to term “masked language model”. In our paper, “conditional masked language model” indicates we apply extra label-conditional constraint to the “masked language model”.) task. The well trained conditional BERT can be applied to enhance contextual augmentation. Experiments on six various different text classification tasks show that our method can be easily applied to both convolutional or recurrent neural networks classifier to obtain improvement.\nUniversal Adversarial Triggers for Attacking and Analyzing NLP (Eric Wallace et al., 2019) Eric Wallace, Shi Feng, Nikhil Kandpal, Matt Gardner, Sameer Singh. (2019)\nUniversal Adversarial Triggers for Attacking and Analyzing NLP\nEMNLP\nPaper Link\nInfluential Citation Count (41), SS-ID (18a1c21f35153c45d0ef30c564bffb7d70a13ccc)\nABSTRACT\nAdversarial examples highlight model vulnerabilities and are useful for evaluation and interpretation. We define universal adversarial triggers: input-agnostic sequences of tokens that trigger a model to produce a specific prediction when concatenated to any input from a dataset. We propose a gradient-guided search over tokens which finds short trigger sequences (e.g., one word for classification and four words for language modeling) that successfully trigger the target prediction. For example, triggers cause SNLI entailment accuracy to drop from 89.94% to 0.55%, 72% of “why” questions in SQuAD to be answered “to kill american people”, and the GPT-2 language model to spew racist output even when conditioned on non-racial contexts. Furthermore, although the triggers are optimized using white-box access to a specific model, they transfer to other models for all tasks we consider. Finally, since triggers are input-agnostic, they provide an analysis of global model behavior. For instance, they confirm that SNLI models exploit dataset biases and help to diagnose heuristics learned by reading comprehension models.\nLearning and Evaluating General Linguistic Intelligence (Dani Yogatama et al., 2019) Dani Yogatama, Cyprien de Masson d\u0026rsquo;Autume, Jerome T. Connor, Tomás Kociský, Mike Chrzanowski, Lingpeng Kong, Angeliki Lazaridou, Wang Ling, Lei Yu, Chris Dyer, P. Blunsom. (2019)\nLearning and Evaluating General Linguistic Intelligence\nArXiv\nPaper Link\nInfluential Citation Count (6), SS-ID (19281b9ecdb5c07a93423a506627ab9d9b0cf039)\nABSTRACT\nWe define general linguistic intelligence as the ability to reuse previously acquired knowledge about a language\u0026rsquo;s lexicon, syntax, semantics, and pragmatic conventions to adapt to new tasks quickly. Using this definition, we analyze state-of-the-art natural language understanding models and conduct an extensive empirical investigation to evaluate them against these criteria through a series of experiments that assess the task-independence of the knowledge being acquired by the learning process. In addition to task performance, we propose a new evaluation metric based on an online encoding of the test data that quantifies how quickly an existing agent (model) learns a new task. Our results show that while the field has made impressive progress in terms of model architectures that generalize to many tasks, these models still require a lot of in-domain training examples (e.g., for fine tuning, training task-specific modules), and are prone to catastrophic forgetting. Moreover, we find that far from solving general tasks (e.g., document question answering), our models are overfitting to the quirks of particular datasets (e.g., SQuAD). We discuss missing components and conjecture on how to make progress toward general linguistic intelligence.\nGOBO: Quantizing Attention-Based NLP Models for Low Latency and Energy Efficient Inference (Ali Hadi Zadeh et al., 2020) Ali Hadi Zadeh, A. Moshovos. (2020)\nGOBO: Quantizing Attention-Based NLP Models for Low Latency and Energy Efficient Inference\n2020 53rd Annual IEEE/ACM International Symposium on Microarchitecture (MICRO)\nPaper Link\nInfluential Citation Count (4), SS-ID (1b0c8b26affd13e10ace5770e85478d60dcc368e)\nABSTRACT\nAttention-based models have demonstrated remarkable success in various natural language understanding tasks. However, efficient execution remains a challenge for these models which are memory-bound due to their massive number of parameters. We present GOBO, a model quantization technique that compresses the vast majority (typically 99.9%) of the 32-bit floating-point parameters of state-of-the-art BERT models and their variants to 3 bits while maintaining their accuracy. Unlike other quantization methods, GOBO does not require fine-tuning nor retraining to compensate for the quantization error. We present two practical hardware applications of GOBO. In the first GOBO reduces memory storage and traffic and as a result inference latency and energy consumption. This GOBO memory compression mechanism is plug-in compatible with many architectures; we demonstrate it with the TPU, Eyeriss, and an architecture using Tensor Cores-like units. Second, we present a co-designed hardware architecture that also reduces computation. Uniquely, the GOBO architecture maintains most of the weights in 3b even during computation, a property that: (i) makes the processing elements area efficient, allowing us to pack more compute power per unit area, (ii) replaces most multiply-accumulations with additions, and (iii) reduces the off-chip traffic by amplifying on-chip memory capacity.\nSegaBERT: Pre-training of Segment-aware BERT for Language Understanding (He Bai et al., 2020) He Bai, Peng Shi, Jimmy J. Lin, Luchen Tan, Kun Xiong, Wen Gao, Ming Li. (2020)\nSegaBERT: Pre-training of Segment-aware BERT for Language Understanding\nArXiv\nPaper Link\nInfluential Citation Count (2), SS-ID (1cc0b98b938b984e5da85f86c1a24099b9b4b582)\nABSTRACT\nPre-trained language models have achieved state-of-the-art results in various natural language processing tasks. Most of them are based on the Transformer architecture, which distinguishes tokens with the token position index of the input sequence. However, sentence index and paragraph index are also important to indicate the token position in a document. We hypothesize that better contextual representations can be generated from the text encoder with richer positional information. To verify this, we propose a segment-aware BERT, by replacing the token position embedding of Transformer with a combination of paragraph index, sentence index, and token index embeddings. We pre-trained the SegaBERT on the masked language modeling task in BERT but without any affiliated tasks. Experimental results show that our pre-trained model can outperform the original BERT model on various NLP tasks.\nAttention is not Explanation (Sarthak Jain et al., 2019) Sarthak Jain, Byron C. Wallace. (2019)\nAttention is not Explanation\nNAACL\nPaper Link\nInfluential Citation Count (36), SS-ID (1e83c20def5c84efa6d4a0d80aa3159f55cb9c3f)\nABSTRACT\nAttention mechanisms have seen wide adoption in neural NLP models. In addition to improving predictive performance, these are often touted as affording transparency: models equipped with attention provide a distribution over attended-to input units, and this is often presented (at least implicitly) as communicating the relative importance of inputs. However, it is unclear what relationship exists between attention weights and model outputs. In this work we perform extensive experiments across a variety of NLP tasks that aim to assess the degree to which attention weights provide meaningful “explanations” for predictions. We find that they largely do not. For example, learned attention weights are frequently uncorrelated with gradient-based measures of feature importance, and one can identify very different attention distributions that nonetheless yield equivalent predictions. Our findings show that standard attention modules do not provide meaningful explanations and should not be treated as though they do.\nHuggingFace\u0026#39;s Transformers: State-of-the-art Natural Language Processing (Thomas Wolf et al., 2019) Thomas Wolf, Lysandre Debut, Victor Sanh, Julien Chaumond, Clement Delangue, Anthony Moi, Pierric Cistac, T. Rault, Rémi Louf, Morgan Funtowicz, Jamie Brew. (2019)\nHuggingFace\u0026rsquo;s Transformers: State-of-the-art Natural Language Processing\nArXiv\nPaper Link\nInfluential Citation Count (208), SS-ID (1fa9ed2bea208511ae698a967875e943049f16b6)\nABSTRACT\nRecent progress in natural language processing has been driven by advances in both model architecture and model pretraining. Transformer architectures have facilitated building higher-capacity models and pretraining has made it possible to effectively utilize this capacity for a wide variety of tasks. \\textit{Transformers} is an open-source library with the goal of opening up these advances to the wider machine learning community. The library consists of carefully engineered state-of-the art Transformer architectures under a unified API. Backing this library is a curated collection of pretrained models made by and available for the community. \\textit{Transformers} is designed to be extensible by researchers, simple for practitioners, and fast and robust in industrial deployments. The library is available at \\url{this https URL}.\nAttention is All you Need (Ashish Vaswani et al., 2017) Ashish Vaswani, Noam M. Shazeer, Niki Parmar, Jakob Uszkoreit, Llion Jones, Aidan N. Gomez, Lukasz Kaiser, Illia Polosukhin. (2017)\nAttention is All you Need\nNIPS\nPaper Link\nInfluential Citation Count (7570), SS-ID (204e3073870fae3d05bcbc2f6a8e263d9b72e776)\nABSTRACT\nThe dominant sequence transduction models are based on complex recurrent or convolutional neural networks in an encoder-decoder configuration. The best performing models also connect the encoder and decoder through an attention mechanism. We propose a new simple network architecture, the Transformer, based solely on attention mechanisms, dispensing with recurrence and convolutions entirely. Experiments on two machine translation tasks show these models to be superior in quality while being more parallelizable and requiring significantly less time to train. Our model achieves 28.4 BLEU on the WMT 2014 English-to-German translation task, improving over the existing best results, including ensembles by over 2 BLEU. On the WMT 2014 English-to-French translation task, our model establishes a new single-model state-of-the-art BLEU score of 41.8 after training for 3.5 days on eight GPUs, a small fraction of the training costs of the best models from the literature. We show that the Transformer generalizes well to other tasks by applying it successfully to English constituency parsing both with large and limited training data.\nThe Lottery Ticket Hypothesis: Finding Sparse, Trainable Neural Networks (Jonathan Frankle et al., 2018) Jonathan Frankle, Michael Carbin. (2018)\nThe Lottery Ticket Hypothesis: Finding Sparse, Trainable Neural Networks\nICLR\nPaper Link\nInfluential Citation Count (230), SS-ID (21937ecd9d66567184b83eca3d3e09eb4e6fbd60)\nABSTRACT\nNeural network pruning techniques can reduce the parameter counts of trained networks by over 90%, decreasing storage requirements and improving computational performance of inference without compromising accuracy. However, contemporary experience is that the sparse architectures produced by pruning are difficult to train from the start, which would similarly improve training performance. We find that a standard pruning technique naturally uncovers subnetworks whose initializations made them capable of training effectively. Based on these results, we articulate the \u0026ldquo;lottery ticket hypothesis:\u0026rdquo; dense, randomly-initialized, feed-forward networks contain subnetworks (\u0026ldquo;winning tickets\u0026rdquo;) that - when trained in isolation - reach test accuracy comparable to the original network in a similar number of iterations. The winning tickets we find have won the initialization lottery: their connections have initial weights that make training particularly effective. We present an algorithm to identify winning tickets and a series of experiments that support the lottery ticket hypothesis and the importance of these fortuitous initializations. We consistently find winning tickets that are less than 10-20% of the size of several fully-connected and convolutional feed-forward architectures for MNIST and CIFAR10. Above this size, the winning tickets that we find learn faster than the original network and reach higher test accuracy.\nMixout: Effective Regularization to Finetune Large-scale Pretrained Language Models (Cheolhyoung Lee et al., 2019) Cheolhyoung Lee, Kyunghyun Cho, Wanmo Kang. (2019)\nMixout: Effective Regularization to Finetune Large-scale Pretrained Language Models\nICLR\nPaper Link\nInfluential Citation Count (12), SS-ID (222b9a7b8038120671a1610e857d3edbc7ac5550)\nABSTRACT\nIn natural language processing, it has been observed recently that generalization could be greatly improved by finetuning a large-scale language model pretrained on a large unlabeled corpus. Despite its recent success and wide adoption, finetuning a large pretrained language model on a downstream task is prone to degenerate performance when there are only a small number of training instances available. In this paper, we introduce a new regularization technique, to which we refer as \u0026ldquo;mixout\u0026rdquo;, motivated by dropout. Mixout stochastically mixes the parameters of two models. We show that our mixout technique regularizes learning to minimize the deviation from one of the two models and that the strength of regularization adapts along the optimization trajectory. We empirically evaluate the proposed mixout and its variants on finetuning a pretrained language model on downstream tasks. More specifically, we demonstrate that the stability of finetuning and the average accuracy greatly increase when we use the proposed approach to regularize finetuning of BERT on downstream tasks in GLUE.\nTrain Large, Then Compress: Rethinking Model Size for Efficient Training and Inference of Transformers (Zhuohan Li et al., 2020) Zhuohan Li, Eric Wallace, Sheng Shen, Kevin Lin, K. Keutzer, D. Klein, Joseph Gonzalez. (2020)\nTrain Large, Then Compress: Rethinking Model Size for Efficient Training and Inference of Transformers\nICML\nPaper Link\nInfluential Citation Count (6), SS-ID (2356781b8a98bf94e6fc73798c6cb65ac35e5f97)\nABSTRACT\nSince hardware resources are limited, the objective of training deep learning models is typically to maximize accuracy subject to the time and memory constraints of training and inference. We study the impact of model size in this setting, focusing on Transformer models for NLP tasks that are limited by compute: self-supervised pretraining and high-resource machine translation. We first show that even though smaller Transformer models execute faster per iteration, wider and deeper models converge in significantly fewer steps. Moreover, this acceleration in convergence typically outpaces the additional computational overhead of using larger models. Therefore, the most compute-efficient training strategy is to counterintuitively train extremely large models but stop after a small number of iterations. This leads to an apparent trade-off between the training efficiency of large Transformer models and the inference efficiency of small Transformer models. However, we show that large models are more robust to compression techniques such as quantization and pruning than small models. Consequently, one can get the best of both worlds: heavily compressed, large models achieve higher accuracy than lightly compressed, small models.\nParameter-Efficient Transfer Learning for NLP (N. Houlsby et al., 2019) N. Houlsby, A. Giurgiu, Stanislaw Jastrzebski, Bruna Morrone, Quentin de Laroussilhe, Andrea Gesmundo, Mona Attariyan, S. Gelly. (2019)\nParameter-Efficient Transfer Learning for NLP\nICML\nPaper Link\nInfluential Citation Count (112), SS-ID (29ddc1f43f28af7c846515e32cc167bc66886d0c)\nABSTRACT\nFine-tuning large pre-trained models is an effective transfer mechanism in NLP. However, in the presence of many downstream tasks, fine-tuning is parameter inefficient: an entire new model is required for every task. As an alternative, we propose transfer with adapter modules. Adapter modules yield a compact and extensible model; they add only a few trainable parameters per task, and new tasks can be added without revisiting previous ones. The parameters of the original network remain fixed, yielding a high degree of parameter sharing. To demonstrate adapter\u0026rsquo;s effectiveness, we transfer the recently proposed BERT Transformer model to 26 diverse text classification tasks, including the GLUE benchmark. Adapters attain near state-of-the-art performance, whilst adding only a few parameters per task. On GLUE, we attain within 0.4% of the performance of full fine-tuning, adding only 3.6% parameters per task. By contrast, fine-tuning trains 100% of the parameters per task.\nAttention Module is Not Only a Weight: Analyzing Transformers with Vector Norms (Goro Kobayashi et al., 2020) Goro Kobayashi, Tatsuki Kuribayashi, Sho Yokoi, Kentaro Inui. (2020)\nAttention Module is Not Only a Weight: Analyzing Transformers with Vector Norms\nArXiv\nPaper Link\nInfluential Citation Count (0), SS-ID (2a8e42995caaedadc9dc739d85bed2c57fc78568)\nABSTRACT\nAttention is a key component of Transformers, which have recently achieved considerable success in natural language processing. Hence, attention is being extensively studied to investigate various linguistic capabilities of Transformers, focusing on analyzing the parallels between attention weights and specific linguistic phenomena. This paper shows that attention weights alone are only one of the two factors that determine the output of attention and proposes a norm-based analysis that incorporates the second factor, the norm of the transformed input vectors. The findings of our norm-based analyses of BERT and a Transformer-based neural machine translation system include the following: (i) contrary to previous studies, BERT pays poor attention to special tokens, and (ii) reasonable word alignment can be extracted from attention mechanisms of Transformer. These findings provide insights into the inner workings of Transformers.\nBERT-of-Theseus: Compressing BERT by Progressive Module Replacing (Canwen Xu et al., 2020) Canwen Xu, Wangchunshu Zhou, Tao Ge, Furu Wei, Ming Zhou. (2020)\nBERT-of-Theseus: Compressing BERT by Progressive Module Replacing\nEMNLP\nPaper Link\nInfluential Citation Count (14), SS-ID (2e27f119e6fcc5477248eb0f4a6abe8d7cf4f6e7)\nABSTRACT\nIn this paper, we propose a novel model compression approach to effectively compress BERT by progressive module replacing. Our approach first divides the original BERT into several modules and builds their compact substitutes. Then, we randomly replace the original modules with their substitutes to train the compact modules to mimic the behavior of the original modules. We progressively increase the probability of replacement through the training. In this way, our approach brings a deeper level of interaction between the original and compact models. Compared to the previous knowledge distillation approaches for BERT compression, our approach does not introduce any additional loss function. Our approach outperforms existing knowledge distillation approaches on GLUE benchmark, showing a new perspective of model compression.\nSmall and Practical BERT Models for Sequence Labeling (Henry Tsai et al., 2019) Henry Tsai, Jason Riesa, Melvin Johnson, N. Arivazhagan, Xin Li, Amelia Archer. (2019)\nSmall and Practical BERT Models for Sequence Labeling\nEMNLP\nPaper Link\nInfluential Citation Count (6), SS-ID (2f9d4887d0022400fc40c774c4c78350c3bc5390)\nABSTRACT\nWe propose a practical scheme to train a single multilingual sequence labeling model that yields state of the art results and is small and fast enough to run on a single CPU. Starting from a public multilingual BERT checkpoint, our final model is 6x smaller and 27x faster, and has higher accuracy than a state-of-the-art multilingual baseline. We show that our model especially outperforms on low-resource languages, and works on codemixed input text without being explicitly trained on codemixed examples. We showcase the effectiveness of our method by reporting on part-of-speech tagging and morphological prediction on 70 treebanks and 48 languages.\nBeto, Bentz, Becas: The Surprising Cross-Lingual Effectiveness of BERT (Shijie Wu et al., 2019) Shijie Wu, Mark Dredze. (2019)\nBeto, Bentz, Becas: The Surprising Cross-Lingual Effectiveness of BERT\nEMNLP\nPaper Link\nInfluential Citation Count (28), SS-ID (2fa3f7ce620a1c7155daef6620dd6bb0e01934f3)\nABSTRACT\nPretrained contextual representation models (Peters et al., 2018; Devlin et al., 2018) have pushed forward the state-of-the-art on many NLP tasks. A new release of BERT (Devlin, 2018) includes a model simultaneously pretrained on 104 languages with impressive performance for zero-shot cross-lingual transfer on a natural language inference task. This paper explores the broader cross-lingual potential of mBERT (multilingual) as a zero shot language transfer model on 5 NLP tasks covering a total of 39 languages from various language families: NLI, document classification, NER, POS tagging, and dependency parsing. We compare mBERT with the best-published methods for zero-shot cross-lingual transfer and find mBERT competitive on each task. Additionally, we investigate the most effective strategy for utilizing mBERT in this manner, determine to what extent mBERT generalizes away from language specific features, and measure factors that influence cross-lingual transfer.\nPre-Training With Whole Word Masking for Chinese BERT (Yiming Cui et al., 2019) Yiming Cui, Wanxiang Che, Ting Liu, Bing Qin, Ziqing Yang, Shijin Wang, Guoping Hu. (2019)\nPre-Training With Whole Word Masking for Chinese BERT\nIEEE/ACM Transactions on Audio, Speech, and Language Processing\nPaper Link\nInfluential Citation Count (61), SS-ID (2ff41a463a374b138bb5a012e5a32bc4beefec20)\nABSTRACT\nBidirectional Encoder Representations from Transformers (BERT) has shown marvelous improvements across various NLP tasks, and its consecutive variants have been proposed to further improve the performance of the pre-trained language models. In this paper, we aim to first introduce the whole word masking (wwm) strategy for Chinese BERT, along with a series of Chinese pre-trained language models. Then we also propose a simple but effective model called MacBERT, which improves upon RoBERTa in several ways. Especially, we propose a new masking strategy called MLM as correction (Mac). To demonstrate the effectiveness of these models, we create a series of Chinese pre-trained language models as our baselines, including BERT, RoBERTa, ELECTRA, RBT, etc. We carried out extensive experiments on ten Chinese NLP tasks to evaluate the created Chinese pre-trained language models as well as the proposed MacBERT. Experimental results show that MacBERT could achieve state-of-the-art performances on many NLP tasks, and we also ablate details with several findings that may help future research. We open-source our pre-trained language models for further facilitating our research community.1\nWhatcha lookin\u0026#39; at? DeepLIFTing BERT\u0026#39;s Attention in Question Answering (Ekaterina Arkhangelskaia et al., 2019) Ekaterina Arkhangelskaia, Sourav Dutta. (2019)\nWhatcha lookin\u0026rsquo; at? DeepLIFTing BERT\u0026rsquo;s Attention in Question Answering\nArXiv\nPaper Link\nInfluential Citation Count (0), SS-ID (304b7c87e5c6e76ffcfdaa59fbd0656f9dab47d8)\nABSTRACT\nThere has been great success recently in tackling challenging NLP tasks by neural networks which have been pre-trained and fine-tuned on large amounts of task data. In this paper, we investigate one such model, BERT for question-answering, with the aim to analyze why it is able to achieve significantly better results than other models. We run DeepLIFT on the model predictions and test the outcomes to monitor shift in the attention values for input. We also cluster the results to analyze any possible patterns similar to human reasoning depending on the kind of input paragraph and question the model is trying to answer.\nUnderstanding Multi-Head Attention in Abstractive Summarization (Joris Baan et al., 2019) Joris Baan, Maartje ter Hoeve, M. V. D. Wees, Anne Schuth, M. de Rijke. (2019)\nUnderstanding Multi-Head Attention in Abstractive Summarization\nArXiv\nPaper Link\nInfluential Citation Count (1), SS-ID (317d2ac530e1db49229d6c442f50722db85afbb7)\nABSTRACT\nAttention mechanisms in deep learning architectures have often been used as a means of transparency and, as such, to shed light on the inner workings of the architectures. Recently, there has been a growing interest in whether or not this assumption is correct. In this paper we investigate the interpretability of multi-head attention in abstractive summarization, a sequence-to-sequence task for which attention does not have an intuitive alignment role, such as in machine translation. We first introduce three metrics to gain insight in the focus of attention heads and observe that these heads specialize towards relative positions, specific part-of-speech tags, and named entities. However, we also find that ablating and pruning these heads does not lead to a significant drop in performance, indicating redundancy. By replacing the softmax activation functions with sparsemax activation functions, we find that attention heads behave seemingly more transparent: we can ablate fewer heads and heads score higher on our interpretability metrics. However, if we apply pruning to the sparsemax model we find that we can prune even more heads, raising the question whether enforced sparsity actually improves transparency. Finally, we find that relative positions heads seem integral to summarization performance and persistently remain after pruning.\n75 Languages, 1 Model: Parsing Universal Dependencies Universally (D. Kondratyuk, 2019) D. Kondratyuk. (2019)\n75 Languages, 1 Model: Parsing Universal Dependencies Universally\nEMNLP\nPaper Link\nInfluential Citation Count (33), SS-ID (31c872514c28a172f7f0221c8596aa5bfcdb9e98)\nABSTRACT\nWe present UDify, a multilingual multi-task model capable of accurately predicting universal part-of-speech, morphological features, lemmas, and dependency trees simultaneously for all 124 Universal Dependencies treebanks across 75 languages. By leveraging a multilingual BERT self-attention model pretrained on 104 languages, we found that fine-tuning it on all datasets concatenated together with simple softmax classifiers for each UD task can meet or exceed state-of-the-art UPOS, UFeats, Lemmas, (and especially) UAS, and LAS scores, without requiring any recurrent or language-specific components. We evaluate UDify for multilingual learning, showing that low-resource languages benefit the most from cross-linguistic annotations. We also evaluate for zero-shot learning, with results suggesting that multilingual training provides strong UD predictions even for languages that neither UDify nor BERT have ever been trained on.\nexBERT: A Visual Analysis Tool to Explore Learned Representations in Transformer Models (Benjamin Hoover et al., 2019) Benjamin Hoover, Hendrik Strobelt, Sebastian Gehrmann. (2019)\nexBERT: A Visual Analysis Tool to Explore Learned Representations in Transformer Models\nACL\nPaper Link\nInfluential Citation Count (4), SS-ID (327d7e55d64cb34d55bd3a3fe58233c238a312cd)\nABSTRACT\nLarge Transformer-based language models can route and reshape complex information via their multi-headed attention mechanism. Although the attention never receives explicit supervision, it can exhibit recognizable patterns following linguistic or positional information. Analyzing the learned representations and attentions is paramount to furthering our understanding of the inner workings of these models. However, analyses have to catch up with the rapid release of new models and the growing diversity of investigation techniques. To support analysis for a wide variety of models, we introduce exBERT, a tool to help humans conduct flexible, interactive investigations and formulate hypotheses for the model-internal reasoning process. exBERT provides insights into the meaning of the contextual representations and attention by matching a human-specified input to similar contexts in large annotated datasets. By aggregating the annotations of the matched contexts, exBERT can quickly replicate findings from literature and extend them to previously not analyzed models.\nData Augmentation using Pre-trained Transformer Models (Varun Kumar et al., 2020) Varun Kumar, Ashutosh Choudhary, Eunah Cho. (2020)\nData Augmentation using Pre-trained Transformer Models\nLIFELONGNLP\nPaper Link\nInfluential Citation Count (17), SS-ID (33496cb3a5623925267528fa6b726f015e4dcda2)\nABSTRACT\nLanguage model based pre-trained models such as BERT have provided significant gains across different NLP tasks. In this paper, we study different types of transformer based pre-trained models such as auto-regressive models (GPT-2), auto-encoder models (BERT), and seq2seq models (BART) for conditional data augmentation. We show that prepending the class labels to text sequences provides a simple yet effective way to condition the pre-trained models for data augmentation. Additionally, on three classification benchmarks, pre-trained Seq2Seq model outperforms other data augmentation methods in a low-resource setting. Further, we explore how different pre-trained model based data augmentation differs in-terms of data diversity, and how well such methods preserve the class-label information.\nWhat Does BERT Learn about the Structure of Language? (Ganesh Jawahar et al., 2019) Ganesh Jawahar, Benoît Sagot, Djamé Seddah. (2019)\nWhat Does BERT Learn about the Structure of Language?\nACL\nPaper Link\nInfluential Citation Count (44), SS-ID (335613303ebc5eac98de757ed02a56377d99e03a)\nABSTRACT\nBERT is a recent language representation model that has surprisingly performed well in diverse language understanding benchmarks. This result indicates the possibility that BERT networks capture structural information about language. In this work, we provide novel support for this claim by performing a series of experiments to unpack the elements of English language structure learned by BERT. Our findings are fourfold. BERT’s phrasal representation captures the phrase-level information in the lower layers. The intermediate layers of BERT compose a rich hierarchy of linguistic information, starting with surface features at the bottom, syntactic features in the middle followed by semantic features at the top. BERT requires deeper layers while tracking subject-verb agreement to handle long-term dependency problem. Finally, the compositional scheme underlying BERT mimics classical, tree-like structures.\nBeyond Accuracy: Behavioral Testing of NLP Models with CheckList (Marco Tulio Ribeiro et al., 2020) Marco Tulio Ribeiro, Tongshuang Sherry Wu, Carlos Guestrin, Sameer Singh. (2020)\nBeyond Accuracy: Behavioral Testing of NLP Models with CheckList\nACL\nPaper Link\nInfluential Citation Count (61), SS-ID (33ec7eb2168e37e3007d1059aa96b9a63254b4da)\nABSTRACT\nAlthough measuring held-out accuracy has been the primary approach to evaluate generalization, it often overestimates the performance of NLP models, while alternative approaches for evaluating models either focus on individual tasks or on specific behaviors. Inspired by principles of behavioral testing in software engineering, we introduce CheckList, a task-agnostic methodology for testing NLP models. CheckList includes a matrix of general linguistic capabilities and test types that facilitate comprehensive test ideation, as well as a software tool to generate a large and diverse number of test cases quickly. We illustrate the utility of CheckList with tests for three tasks, identifying critical failures in both commercial and state-of-art models. In a user study, a team responsible for a commercial sentiment analysis model found new and actionable bugs in an extensively tested model. In another user study, NLP practitioners with CheckList created twice as many tests, and found almost three times as many bugs as users without it.\nQuantity doesn’t buy quality syntax with neural language models (Marten van Schijndel et al., 2019) Marten van Schijndel, Aaron Mueller, Tal Linzen. (2019)\nQuantity doesn’t buy quality syntax with neural language models\nEMNLP\nPaper Link\nInfluential Citation Count (0), SS-ID (356645552f8f40adf5a99b4e3a69f47699399010)\nABSTRACT\nRecurrent neural networks can learn to predict upcoming words remarkably well on average; in syntactically complex contexts, however, they often assign unexpectedly high probabilities to ungrammatical words. We investigate to what extent these shortcomings can be mitigated by increasing the size of the network and the corpus on which it is trained. We find that gains from increasing network size are minimal beyond a certain point. Likewise, expanding the training corpus yields diminishing returns; we estimate that the training corpus would need to be unrealistically large for the models to match human performance. A comparison to GPT and BERT, Transformer-based models trained on billions of words, reveals that these models perform even more poorly than our LSTMs in some constructions. Our results make the case for more data efficient architectures.\nWhat do you mean? (M. Jackson, 1989) M. Jackson. (1989)\nWhat do you mean?\nGeriatric nursing\nPaper Link\nInfluential Citation Count (17), SS-ID (357771514cfbbdc0ddafe1dfdf54eda3c42b325e)\nABSTRACT\nThe Lottery Ticket Hypothesis for Pre-trained BERT Networks (Tianlong Chen et al., 2020) Tianlong Chen, Jonathan Frankle, Shiyu Chang, Sijia Liu, Yang Zhang, Zhangyang Wang, Michael Carbin. (2020)\nThe Lottery Ticket Hypothesis for Pre-trained BERT Networks\nNeurIPS\nPaper Link\nInfluential Citation Count (18), SS-ID (389036b1366b64579725457993c1f63a4f3370ba)\nABSTRACT\nIn natural language processing (NLP), enormous pre-trained models like BERT have become the standard starting point for training on a range of downstream tasks, and similar trends are emerging in other areas of deep learning. In parallel, work on the lottery ticket hypothesis has shown that models for NLP and computer vision contain smaller matching subnetworks capable of training in isolation to full accuracy and transferring to other tasks. In this work, we combine these observations to assess whether such trainable, transferrable subnetworks exist in pre-trained BERT models. For a range of downstream tasks, we indeed find matching subnetworks at 40% to 90% sparsity. We find these subnetworks at (pre-trained) initialization, a deviation from prior NLP research where they emerge only after some amount of training. Subnetworks found on the masked language modeling task (the same task used to pre-train the model) transfer universally; those found on other tasks transfer in a limited fashion if at all. As large-scale pre-training becomes an increasingly central paradigm in deep learning, our results demonstrate that the main lottery ticket observations remain relevant in this context. Codes available at this https URL.\nBART: Denoising Sequence-to-Sequence Pre-training for Natural Language Generation, Translation, and Comprehension (M. Lewis et al., 2019) M. Lewis, Yinhan Liu, Naman Goyal, Marjan Ghazvininejad, Abdelrahman Mohamed, Omer Levy, Veselin Stoyanov, Luke Zettlemoyer. (2019)\nBART: Denoising Sequence-to-Sequence Pre-training for Natural Language Generation, Translation, and Comprehension\nACL\nPaper Link\nInfluential Citation Count (482), SS-ID (395de0bd3837fdf4b4b5e5f04835bcc69c279481)\nABSTRACT\nWe present BART, a denoising autoencoder for pretraining sequence-to-sequence models. BART is trained by (1) corrupting text with an arbitrary noising function, and (2) learning a model to reconstruct the original text. It uses a standard Tranformer-based neural machine translation architecture which, despite its simplicity, can be seen as generalizing BERT (due to the bidirectional encoder), GPT (with the left-to-right decoder), and other recent pretraining schemes. We evaluate a number of noising approaches, finding the best performance by both randomly shuffling the order of sentences and using a novel in-filling scheme, where spans of text are replaced with a single mask token. BART is particularly effective when fine tuned for text generation but also works well for comprehension tasks. It matches the performance of RoBERTa on GLUE and SQuAD, and achieves new state-of-the-art results on a range of abstractive dialogue, question answering, and summarization tasks, with gains of up to 3.5 ROUGE. BART also provides a 1.1 BLEU increase over a back-translation system for machine translation, with only target language pretraining. We also replicate other pretraining schemes within the BART framework, to understand their effect on end-task performance.\nInvestigating Entity Knowledge in BERT with Simple Neural End-To-End Entity Linking (Samuel Broscheit, 2019) Samuel Broscheit. (2019)\nInvestigating Entity Knowledge in BERT with Simple Neural End-To-End Entity Linking\nCoNLL\nPaper Link\nInfluential Citation Count (6), SS-ID (399308fa54ade9b1362d56628132323489ce50cd)\nABSTRACT\nA typical architecture for end-to-end entity linking systems consists of three steps: mention detection, candidate generation and entity disambiguation. In this study we investigate the following questions: (a) Can all those steps be learned jointly with a model for contextualized text-representations, i.e. BERT? (b) How much entity knowledge is already contained in pretrained BERT? (c) Does additional entity knowledge improve BERT’s performance in downstream tasks? To this end we propose an extreme simplification of the entity linking setup that works surprisingly well: simply cast it as a per token classification over the entire entity vocabulary (over 700K classes in our case). We show on an entity linking benchmark that (i) this model improves the entity representations over plain BERT, (ii) that it outperforms entity linking architectures that optimize the tasks separately and (iii) that it only comes second to the current state-of-the-art that does mention detection and entity disambiguation jointly. Additionally, we investigate the usefulness of entity-aware token-representations in the text-understanding benchmark GLUE, as well as the question answering benchmarks SQUAD~V2 and SWAG and also the EN-DE WMT14 machine translation benchmark. To our surprise, we find that most of those benchmarks do not benefit from additional entity knowledge, except for a task with very small training data, the RTE task in GLUE, which improves by 2%.\nPerturbed Masking: Parameter-free Probing for Analyzing and Interpreting BERT (Zhiyong Wu et al., 2020) Zhiyong Wu, Yun Chen, B. Kao, Qun Liu. (2020)\nPerturbed Masking: Parameter-free Probing for Analyzing and Interpreting BERT\nACL\nPaper Link\nInfluential Citation Count (10), SS-ID (3aaa8aaad5ef36550a6b47d6ee000f0b346a5a1f)\nABSTRACT\nBy introducing a small set of additional parameters, a probe learns to solve specific linguistic tasks (e.g., dependency parsing) in a supervised manner using feature representations (e.g., contextualized embeddings). The effectiveness of such probing tasks is taken as evidence that the pre-trained model encodes linguistic knowledge. However, this approach of evaluating a language model is undermined by the uncertainty of the amount of knowledge that is learned by the probe itself. Complementary to those works, we propose a parameter-free probing technique for analyzing pre-trained language models (e.g., BERT). Our method does not require direct supervision from the probing tasks, nor do we introduce additional parameters to the probing process. Our experiments on BERT show that syntactic trees recovered from BERT using our method are significantly better than linguistically-uninformed baselines. We further feed the empirically induced dependency structures into a downstream sentiment classification task and find its improvement compatible with or even superior to a human-designed dependency schema.\nCross-Lingual Ability of Multilingual BERT: An Empirical Study (Karthikeyan K et al., 2019) Karthikeyan K, Zihan Wang, Stephen Mayhew, D. Roth. (2019)\nCross-Lingual Ability of Multilingual BERT: An Empirical Study\nICLR\nPaper Link\nInfluential Citation Count (7), SS-ID (3b2538f84812f434c740115c185be3e5e216c526)\nABSTRACT\nRecent work has exhibited the surprising cross-lingual abilities of multilingual BERT (M-BERT) \u0026ndash; surprising since it is trained without any cross-lingual objective and with no aligned data. In this work, we provide a comprehensive study of the contribution of different components in M-BERT to its cross-lingual ability. We study the impact of linguistic properties of the languages, the architecture of the model, and the learning objectives. The experimental study is done in the context of three typologically different languages \u0026ndash; Spanish, Hindi, and Russian \u0026ndash; and using two conceptually different NLP tasks, textual entailment and named entity recognition. Among our key conclusions is the fact that the lexical overlap between languages plays a negligible role in the cross-lingual success, while the depth of the network is an integral part of it. All our models and implementations can be found on our project page: this http URL .\nReducing BERT Pre-Training Time from 3 Days to 76 Minutes (Yang You et al., 2019) Yang You, Jing Li, Jonathan Hseu, Xiaodan Song, J. Demmel, Cho-Jui Hsieh. (2019)\nReducing BERT Pre-Training Time from 3 Days to 76 Minutes\nArXiv\nPaper Link\nInfluential Citation Count (13), SS-ID (3c6dca9041f54583aeab60587c9e6e9272104dc1)\nABSTRACT\nLarge-batch training is key to speeding up deep neural network training in large distributed systems. However, large-batch training is difficult because it produces a generalization gap. Straightforward optimization often leads to accuracy loss on the test set. BERT \\cite{devlin2018bert} is a state-of-the-art deep learning model that builds on top of deep bidirectional transformers for language understanding. Previous large-batch training techniques do not perform well for BERT when we scale the batch size (e.g. beyond 8192). BERT pre-training also takes a long time to finish (around three days on 16 TPUv3 chips). To solve this problem, we propose the LAMB optimizer, which helps us to scale the batch size to 65536 without losing accuracy. LAMB is a general optimizer that works for both small and large batch sizes and does not need hyper-parameter tuning besides the learning rate. The baseline BERT-Large model needs 1 million iterations to finish pre-training, while LAMB with batch size 65536/32768 only needs 8599 iterations. We push the batch size to the memory limit of a TPUv3 pod and can finish BERT training in 76 minutes.\nInvestigating BERT’s Knowledge of Language: Five Analysis Methods with NPIs (Alex Warstadt et al., 2019) Alex Warstadt, Yuning Cao, Ioana Grosu, Wei Peng, Hagen Blix, Yining Nie, Anna Alsop, Shikha Bordia, Haokun Liu, Alicia Parrish, Sheng-Fu Wang, Jason Phang, Anhad Mohananey, Phu Mon Htut, Paloma Jeretic, Samuel R. Bowman. (2019)\nInvestigating BERT’s Knowledge of Language: Five Analysis Methods with NPIs\nEMNLP\nPaper Link\nInfluential Citation Count (4), SS-ID (3cd331c997e90f737810aad6fcce4d993315189f)\nABSTRACT\nThough state-of-the-art sentence representation models can perform tasks requiring significant knowledge of grammar, it is an open question how best to evaluate their grammatical knowledge. We explore five experimental methods inspired by prior work evaluating pretrained sentence representation models. We use a single linguistic phenomenon, negative polarity item (NPI) licensing, as a case study for our experiments. NPIs like any are grammatical only if they appear in a licensing environment like negation (Sue doesn’t have any cats vs. *Sue has any cats). This phenomenon is challenging because of the variety of NPI licensing environments that exist. We introduce an artificially generated dataset that manipulates key features of NPI licensing for the experiments. We find that BERT has significant knowledge of these features, but its success varies widely across different experimental methods. We conclude that a variety of methods is necessary to reveal all relevant aspects of a model’s grammatical knowledge in a given domain.\nExploring the Limits of Transfer Learning with a Unified Text-to-Text Transformer (Colin Raffel et al., 2019) Colin Raffel, Noam M. Shazeer, Adam Roberts, Katherine Lee, Sharan Narang, Michael Matena, Yanqi Zhou, Wei Li, Peter J. Liu. (2019)\nExploring the Limits of Transfer Learning with a Unified Text-to-Text Transformer\nJ. Mach. Learn. Res.\nPaper Link\nInfluential Citation Count (615), SS-ID (3cfb319689f06bf04c2e28399361f414ca32c4b3)\nABSTRACT\nTransfer learning, where a model is first pre-trained on a data-rich task before being fine-tuned on a downstream task, has emerged as a powerful technique in natural language processing (NLP). The effectiveness of transfer learning has given rise to a diversity of approaches, methodology, and practice. In this paper, we explore the landscape of transfer learning techniques for NLP by introducing a unified framework that converts every language problem into a text-to-text format. Our systematic study compares pre-training objectives, architectures, unlabeled datasets, transfer approaches, and other factors on dozens of language understanding tasks. By combining the insights from our exploration with scale and our new \u0026ldquo;Colossal Clean Crawled Corpus\u0026rdquo;, we achieve state-of-the-art results on many benchmarks covering summarization, question answering, text classification, and more. To facilitate future work on transfer learning for NLP, we release our dataset, pre-trained models, and code.\nDeepening Hidden Representations from Pre-trained Language Models for Natural Language Understanding (Jie Yang et al., 2019) Jie Yang, Hai Zhao. (2019)\nDeepening Hidden Representations from Pre-trained Language Models for Natural Language Understanding\nArXiv\nPaper Link\nInfluential Citation Count (0), SS-ID (3ee7b17cc627ac5bc99632a22ef820dc559393e6)\nABSTRACT\nTransformer-based pre-trained language models have proven to be effective for learning contextualized language representation. However, current approaches only take advantage of the output of the encoder\u0026rsquo;s final layer when fine-tuning the downstream tasks. We argue that only taking single layer\u0026rsquo;s output restricts the power of pre-trained representation. Thus we deepen the representation learned by the model by fusing the hidden representation in terms of an explicit HIdden Representation Extractor (HIRE), which automatically absorbs the complementary representation with respect to the output from the final layer. Utilizing RoBERTa as the backbone encoder, our proposed improvement over the pre-trained models is shown effective on multiple natural language understanding tasks and help our model rival with the state-of-the-art models on the GLUE benchmark.\nImproving Transformer Models by Reordering their Sublayers (Ofir Press et al., 2019) Ofir Press, Noah A. Smith, Omer Levy. (2019)\nImproving Transformer Models by Reordering their Sublayers\nACL\nPaper Link\nInfluential Citation Count (2), SS-ID (3ff8d265f4351e4b1fdac5b586466bee0b5d6fff)\nABSTRACT\nMultilayer transformer networks consist of interleaved self-attention and feedforward sublayers. Could ordering the sublayers in a different pattern lead to better performance? We generate randomly ordered transformers and train them with the language modeling objective. We observe that some of these models are able to achieve better performance than the interleaved baseline, and that those successful variants tend to have more self-attention at the bottom and more feedforward sublayers at the top. We propose a new transformer pattern that adheres to this property, the sandwich transformer, and show that it improves perplexity on multiple word-level and character-level language modeling benchmarks, at no cost in parameters, memory, or training time. However, the sandwich reordering pattern does not guarantee performance gains across every task, as we demonstrate on machine translation models. Instead, we suggest that further exploration of task-specific sublayer reorderings is needed in order to unlock additional gains.\nRight for the Wrong Reasons: Diagnosing Syntactic Heuristics in Natural Language Inference (R. Thomas McCoy et al., 2019) R. Thomas McCoy, Ellie Pavlick, Tal Linzen. (2019)\nRight for the Wrong Reasons: Diagnosing Syntactic Heuristics in Natural Language Inference\nACL\nPaper Link\nInfluential Citation Count (103), SS-ID (42ed4a9994e6121a9f325f5b901c5b3d7ce104f5)\nABSTRACT\nA machine learning system can score well on a given test set by relying on heuristics that are effective for frequent example types but break down in more challenging cases. We study this issue within natural language inference (NLI), the task of determining whether one sentence entails another. We hypothesize that statistical NLI models may adopt three fallible syntactic heuristics: the lexical overlap heuristic, the subsequence heuristic, and the constituent heuristic. To determine whether models have adopted these heuristics, we introduce a controlled evaluation set called HANS (Heuristic Analysis for NLI Systems), which contains many examples where the heuristics fail. We find that models trained on MNLI, including BERT, a state-of-the-art model, perform very poorly on HANS, suggesting that they have indeed adopted these heuristics. We conclude that there is substantial room for improvement in NLI systems, and that the HANS dataset can motivate and measure progress in this area.\nPoWER-BERT: Accelerating BERT inference for Classification Tasks (Saurabh Goyal et al., 2020) Saurabh Goyal, Anamitra R. Choudhury, Venkatesan T. Chakaravarthy, Saurabh ManishRaje, Yogish Sabharwal, Ashish Verma. (2020)\nPoWER-BERT: Accelerating BERT inference for Classification Tasks\nArXiv\nPaper Link\nInfluential Citation Count (1), SS-ID (4510d9ad22f474c30c530ae7f886ec4d42402d68)\nABSTRACT\nBERT has emerged as a popular model for natural language understanding. Given its computeintensive nature, even for inference, many recent studies have considered optimization of two important performance characteristics: model size and inference time. We consider classification tasks and propose a novel method, called PoWER-BERT, for improving the inference time for the BERT model without significant loss in the accuracy. The method works by eliminating word-vectors (intermediate vector outputs) from the encoder pipeline. We design a strategy for measuring the significance of the word-vectors based on the self-attention mechanism of the encoders which helps us identify the word-vectors to be eliminated. Experimental evaluation on the standard GLUE benchmark shows that PoWER-BERT achieves up to 4.5x reduction in inference time over BERT with \u0026lt; 1% loss in accuracy. We show that compared to the prior inference time reduction methods, PoWER-BERT offers better trade-off between accuracy and inference time. Lastly, we demonstrate that our scheme can also be used in conjunction with ALBERT (a highly compressed version of BERT) and can attain up to 6.8x factor reduction in inference time with \u0026lt; 1% loss in accuracy.\nA Structural Probe for Finding Syntax in Word Representations (John Hewitt et al., 2019) John Hewitt, Christopher D. Manning. (2019)\nA Structural Probe for Finding Syntax in Word Representations\nNAACL\nPaper Link\nInfluential Citation Count (30), SS-ID (455a8838cde44f288d456d01c76ede95b56dc675)\nABSTRACT\nRecent work has improved our ability to detect linguistic knowledge in word representations. However, current methods for detecting syntactic knowledge do not test whether syntax trees are represented in their entirety. In this work, we propose a structural probe, which evaluates whether syntax trees are embedded in a linear transformation of a neural network’s word representation space. The probe identifies a linear transformation under which squared L2 distance encodes the distance between words in the parse tree, and one in which squared L2 norm encodes depth in the parse tree. Using our probe, we show that such transformations exist for both ELMo and BERT but not in baselines, providing evidence that entire syntax trees are embedded implicitly in deep models’ vector geometry.\nWhat do you mean, BERT? Assessing BERT as a Distributional Semantics Model (Timothee Mickus et al., 2019) Timothee Mickus, Denis Paperno, Mathieu Constant, Kees van Deemter. (2019)\nWhat do you mean, BERT? Assessing BERT as a Distributional Semantics Model\nArXiv\nPaper Link\nInfluential Citation Count (3), SS-ID (4bff291cf7fa02a0dbac767aba55d43ad8c59055)\nABSTRACT\nContextualized word embeddings, i.e. vector representations for words in context, are naturally seen as an extension of previous noncontextual distributional semantic models. In this work, we focus on BERT, a deep neural network that produces contextualized embeddings and has set the state-of-the-art in several semantic tasks, and study the semantic coherence of its embedding space. While showing a tendency towards coherence, BERT does not fully live up to the natural expectations for a semantic vector space. In particular, we find that the position of the sentence in which a word occurs, while having no meaning correlates, leaves a noticeable trace on the word embeddings and disturbs similarity relationships.\nStructured Pruning of a BERT-based Question Answering Model (J. Scott McCarley et al., 2019) J. Scott McCarley, Rishav Chakravarti, Avirup Sil. (2019)\nStructured Pruning of a BERT-based Question Answering Model\nPaper Link\nInfluential Citation Count (4), SS-ID (4d8a4509753cc91832f80ec35795064e79630ef3)\nABSTRACT\nThe recent trend in industry-setting Natural Language Processing (NLP) research has been to operate large scale pretrained language models like BERT under strict computational limits. While most model compression work has focused on \u0026ldquo;distilling\u0026rdquo; a general-purpose language representation using expensive pretraining distillation, much less attention has been paid to creating smaller task-specific language representations which, arguably, are more useful in an industry setting. In this paper, we investigate compressing BERT- and RoBERTa-based question answering systems by structured pruning of parameters from the underlying trained transformer model. We find that an inexpensive combination of task-specific structured pruning and task-specific distillation, without the expense of pretraining distillation, yields highly-performing models across a range of speed/accuracy tradeoff operating points. We start from full-size models trained for SQuAD 2.0 or Natural Questions and introduce gates that allow selected parts of transformers to be individually eliminated. Specifically, we investigate (1) structured pruning to reduce the number of parameters in each transformer layer, (2) applicability to both BERT- and RoBERTa-based models, (3) applicability to both SQuAD 2.0 and Natural Questions, and (4) combining structured pruning with distillation. We find that pruning a combination of attention heads and the feed-forward layer yields a near-doubling of inference speed on SQuAD 2.0, with less than a 1.5 F1-point loss in accuracy. Furthermore, we find that a combination of distillation and structured pruning almost doubles the inference speed of RoBERTa-large based model for Natural Questions, while losing less than 0.5 F1-point on short answers.\nK-Adapter: Infusing Knowledge into Pre-Trained Models with Adapters (Ruize Wang et al., 2020) Ruize Wang, Duyu Tang, Nan Duan, Zhongyu Wei, Xuanjing Huang, Jianshu Ji, Guihong Cao, Daxin Jiang, Ming Zhou. (2020)\nK-Adapter: Infusing Knowledge into Pre-Trained Models with Adapters\nFINDINGS\nPaper Link\nInfluential Citation Count (32), SS-ID (4f03e69963b9649950ba29ae864a0de8c14f1f86)\nABSTRACT\nWe study the problem of injecting knowledge into large pre-trained models like BERT and RoBERTa. Existing methods typically update the original parameters of pre-trained models when injecting knowledge. However, when multiple kinds of knowledge are injected, they may suffer from catastrophic forgetting. To address this, we propose K-Adapter, which remains the original parameters of the pre-trained model fixed and supports continual knowledge infusion. Taking RoBERTa as the pre-trained model, K-Adapter has a neural adapter for each kind of infused knowledge, like a plug-in connected to RoBERTa. There is no information flow between different adapters, thus different adapters are efficiently trained in a distributed way. We inject two kinds of knowledge, including factual knowledge obtained from automatically aligned text-triplets on Wikipedia and Wikidata, and linguistic knowledge obtained from dependency parsing. Results on three knowledge-driven tasks (total six datasets) including relation classification, entity typing and question answering demonstrate that each adapter improves the performance, and the combination of both adapters brings further improvements. Probing experiments further indicate that K-Adapter captures richer factual and commonsense knowledge than RoBERTa.\nQ-BERT: Hessian Based Ultra Low Precision Quantization of BERT (Sheng Shen et al., 2019) Sheng Shen, Zhen Dong, Jiayu Ye, Linjian Ma, Z. Yao, A. Gholami, Michael W. Mahoney, K. Keutzer. (2019)\nQ-BERT: Hessian Based Ultra Low Precision Quantization of BERT\nAAAI\nPaper Link\nInfluential Citation Count (22), SS-ID (4fb8fd55b476909a26a8dc594e0ae98d4923ad4d)\nABSTRACT\nTransformer based architectures have become de-facto models used for a range of Natural Language Processing tasks. In particular, the BERT based models achieved significant accuracy gain for GLUE tasks, CoNLL-03 and SQuAD. However, BERT based models have a prohibitive memory footprint and latency. As a result, deploying BERT based models in resource constrained environments has become a challenging task. In this work, we perform an extensive analysis of fine-tuned BERT models using second order Hessian information, and we use our results to propose a novel method for quantizing BERT models to ultra low precision. In particular, we propose a new group-wise quantization scheme, and we use Hessian-based mix-precision method to compress the model further. We extensively test our proposed method on BERT downstream tasks of SST-2, MNLI, CoNLL-03, and SQuAD. We can achieve comparable performance to baseline with at most 2.3% performance degradation, even with ultra-low precision quantization down to 2 bits, corresponding up to 13× compression of the model parameters, and up to 4× compression of the embedding table as well as activations. Among all tasks, we observed the highest performance loss for BERT fine-tuned on SQuAD. By probing into the Hessian based analysis as well as visualization, we show that this is related to the fact that current training/fine-tuning strategy of BERT does not converge for SQuAD.\nParsing as Pretraining (David Vilares et al., 2020) David Vilares, Michalina Strzyz, Anders Søgaard, Carlos G\u0026rsquo;omez-Rodr\u0026rsquo;iguez. (2020)\nParsing as Pretraining\nAAAI\nPaper Link\nInfluential Citation Count (2), SS-ID (50be7d2858523d0e63174d974f380349fca0d666)\nABSTRACT\nRecent analyses suggest that encoders pretrained for language modeling capture certain morpho-syntactic structure. However, probing frameworks for word vectors still do not report results on standard setups such as constituent and dependency parsing. This paper addresses this problem and does full parsing (on English) relying only on pretraining architectures – and no decoding. We first cast constituent and dependency parsing as sequence tagging. We then use a single feed-forward layer to directly map word vectors to labels that encode a linearized tree. This is used to: (i) see how far we can reach on syntax modelling with just pretrained encoders, and (ii) shed some light about the syntax-sensitivity of different word vectors (by freezing the weights of the pretraining network during training). For evaluation, we use bracketing F1-score and las, and analyze in-depth differences across representations for span lengths and dependency displacements. The overall results surpass existing sequence tagging parsers on the ptb (93.5%) and end-to-end en-ewt ud (78.8%).\nReweighted Proximal Pruning for Large-Scale Language Representation (Fu-Ming Guo et al., 2019) Fu-Ming Guo, Sijia Liu, F. Mungall, Xue Lin, Yanzhi Wang. (2019)\nReweighted Proximal Pruning for Large-Scale Language Representation\nArXiv\nPaper Link\nInfluential Citation Count (3), SS-ID (540f074cb6f16563a357741837e41c44c0a38234)\nABSTRACT\nRecently, pre-trained language representation flourishes as the mainstay of the natural language understanding community, e.g., BERT. These pre-trained language representations can create state-of-the-art results on a wide range of downstream tasks. Along with continuous significant performance improvement, the size and complexity of these pre-trained neural models continue to increase rapidly. Is it possible to compress these large-scale language representation models? How will the pruned language representation affect the downstream multi-task transfer learning objectives? In this paper, we propose Reweighted Proximal Pruning (RPP), a new pruning method specifically designed for a large-scale language representation model. Through experiments on SQuAD and the GLUE benchmark suite, we show that proximal pruned BERT keeps high accuracy for both the pre-training task and the downstream multiple fine-tuning tasks at high prune ratio. RPP provides a new perspective to help us analyze what large-scale language representation might learn. Additionally, RPP makes it possible to deploy a large state-of-the-art language representation model such as BERT on a series of distinct devices (e.g., online servers, mobile phones, and edge devices).\nThe Berkeley FrameNet Project (Collin F. Baker et al., 1998) Collin F. Baker, C. Fillmore, J. Lowe. (1998)\nThe Berkeley FrameNet Project\nCOLING-ACL\nPaper Link\nInfluential Citation Count (436), SS-ID (547f23597f9ec8a93f66cedaa6fbfb73960426b1)\nABSTRACT\nFrameNet is a three-year NSF-supported project in corpus-based computational lexicography, now in its second year (NSF IRI-9618838, \u0026ldquo;Tools for Lexicon Building\u0026rdquo;). The project\u0026rsquo;s key features are (a) a commitment to corpus evidence for semantic and syntactic generalizations, and (b) the representation of the valences of its target words (mostly nouns, adjectives, and verbs) in which the semantic portion makes use of frame semantics. The resulting database will contain (a) descriptions of the semantic frames underlying the meanings of the words described, and (b) the valence representation (semantic and syntactic) of several thousand words and phrases, each accompanied by (c) a representative collection of annotated corpus attestations, which jointly exemplify the observed linkings between \u0026ldquo;frame elements\u0026rdquo; and their syntactic realizations (e.g. grammatical function, phrase type, and other syntactic traits). This report will present the project\u0026rsquo;s goals and workflow, and information about the computational tools that have been adapted or created in-house for this work.\nSesameBERT: Attention for Anywhere (Ta-Chun Su et al., 2019) Ta-Chun Su, Hsiang-Chih Cheng. (2019)\nSesameBERT: Attention for Anywhere\n2020 IEEE 7th International Conference on Data Science and Advanced Analytics (DSAA)\nPaper Link\nInfluential Citation Count (0), SS-ID (553c1048e90e84575cad9016f367cf69c52a7fd7)\nABSTRACT\nFine-tuning with pre-trained models has achieved exceptional results for many language tasks. In this study, we focused on one such self-attention network model, namely BERT, which has performed well in terms of stacking layers across diverse language-understanding benchmarks. However, in many downstream tasks, information between layers is ignored by BERT for fine-tuning. In addition, although self-attention networks are well-known for their ability to capture global dependencies, room for improvement remains in terms of emphasizing the importance of local contexts. In light of these advantages and disadvantages, this paper proposes SesameBERT, a generalized fine-tuning method that (1) enables the extraction of global information among all layers through Squeeze and Excitation and (2) enriches local information by capturing neighboring contexts via Gaussian blurring. Furthermore, we demonstrated the effectiveness of our approach in the HANS dataset, which is used to determine whether models have adopted shallow heuristics instead of learning underlying generalizations. The experiments revealed that SesameBERT outperformed BERT with respect to GLUE benchmark and the HANS evaluation set.\nAssociation for Computational Linguistics (D. Litman et al., 2001) D. Litman, J. Hirschberg, M. Swerts, Scott Miller, L. Ramshaw, R. Weischedel, Eugene Charniak, Lillian Lee. (2001)\nAssociation for Computational Linguistics\nPaper Link\nInfluential Citation Count (67), SS-ID (566eb7be43b8a2b2daff82b03711098a84859b2a)\nABSTRACT\nKEPLER: A Unified Model for Knowledge Embedding and Pre-trained Language Representation (Xiaozhi Wang et al., 2019) Xiaozhi Wang, Tianyu Gao, Zhaocheng Zhu, Zhiyuan Liu, Juan-Zi Li, Jian Tang. (2019)\nKEPLER: A Unified Model for Knowledge Embedding and Pre-trained Language Representation\nTransactions of the Association for Computational Linguistics\nPaper Link\nInfluential Citation Count (40), SS-ID (56cafbac34f2bb3f6a9828cd228ff281b810d6bb)\nABSTRACT\nAbstract Pre-trained language representation models (PLMs) cannot well capture factual knowledge from text. In contrast, knowledge embedding (KE) methods can effectively represent the relational facts in knowledge graphs (KGs) with informative entity embeddings, but conventional KE models cannot take full advantage of the abundant textual information. In this paper, we propose a unified model for Knowledge Embedding and Pre-trained LanguagERepresentation (KEPLER), which can not only better integrate factual knowledge into PLMs but also produce effective text-enhanced KE with the strong PLMs. In KEPLER, we encode textual entity descriptions with a PLM as their embeddings, and then jointly optimize the KE and language modeling objectives. Experimental results show that KEPLER achieves state-of-the-art performances on various NLP tasks, and also works remarkably well as an inductive KE model on KG link prediction. Furthermore, for pre-training and evaluating KEPLER, we construct Wikidata5M1 , a large-scale KG dataset with aligned entity descriptions, and benchmark state-of-the-art KE methods on it. It shall serve as a new KE benchmark and facilitate the research on large KG, inductive KE, and KG with text. The source code can be obtained from https://github.com/THU-KEG/KEPLER.\nSemantics-aware BERT for Language Understanding (Zhuosheng Zhang et al., 2019) Zhuosheng Zhang, Yuwei Wu, Zhao Hai, Z. Li, Shuailiang Zhang, Xi Zhou, Xiang Zhou. (2019)\nSemantics-aware BERT for Language Understanding\nAAAI\nPaper Link\nInfluential Citation Count (27), SS-ID (5744f56d3253bd7c4341d36de40a93fceaa266b3)\nABSTRACT\nThe latest work on language representations carefully integrates contextualized features into language model training, which enables a series of success especially in various machine reading comprehension and natural language inference tasks. However, the existing language representation models including ELMo, GPT and BERT only exploit plain context-sensitive features such as character or word embeddings. They rarely consider incorporating structured semantic information which can provide rich semantics for language representation. To promote natural language understanding, we propose to incorporate explicit contextual semantics from pre-trained semantic role labeling, and introduce an improved language representation model, Semantics-aware BERT (SemBERT), which is capable of explicitly absorbing contextual semantics over a BERT backbone. SemBERT keeps the convenient usability of its BERT precursor in a light fine-tuning way without substantial task-specific modifications. Compared with BERT, semantics-aware BERT is as simple in concept but more powerful. It obtains new state-of-the-art or substantially improves results on ten reading comprehension and language inference tasks.\nIs Supervised Syntactic Parsing Beneficial for Language Understanding Tasks? An Empirical Investigation (Goran Glavas et al., 2020) Goran Glavas, Ivan Vulic. (2020)\nIs Supervised Syntactic Parsing Beneficial for Language Understanding Tasks? An Empirical Investigation\nEACL\nPaper Link\nInfluential Citation Count (0), SS-ID (575ac3f36e9fddeb258e2f639e26a6a7ec35160a)\nABSTRACT\nTraditional NLP has long held (supervised) syntactic parsing necessary for successful higher-level semantic language understanding (LU). The recent advent of end-to-end neural models, self-supervised via language modeling (LM), and their success on a wide range of LU tasks, however, questions this belief. In this work, we empirically investigate the usefulness of supervised parsing for semantic LU in the context of LM-pretrained transformer networks. Relying on the established fine-tuning paradigm, we first couple a pretrained transformer with a biaffine parsing head, aiming to infuse explicit syntactic knowledge from Universal Dependencies treebanks into the transformer. We then fine-tune the model for LU tasks and measure the effect of the intermediate parsing training (IPT) on downstream LU task performance. Results from both monolingual English and zero-shot language transfer experiments (with intermediate target-language parsing) show that explicit formalized syntax, injected into transformers through IPT, has very limited and inconsistent effect on downstream LU performance. Our results, coupled with our analysis of transformers’ representation spaces before and after intermediate parsing, make a significant step towards providing answers to an essential question: how (un)availing is supervised parsing for high-level semantic natural language understanding in the era of large neural models?\nFixed Encoder Self-Attention Patterns in Transformer-Based Machine Translation (Alessandro Raganato et al., 2020) Alessandro Raganato, Yves Scherrer, J. Tiedemann. (2020)\nFixed Encoder Self-Attention Patterns in Transformer-Based Machine Translation\nFINDINGS\nPaper Link\nInfluential Citation Count (5), SS-ID (57f123c95ecf9d901be3a53291f53302740451e2)\nABSTRACT\nTransformer-based models have brought a radical change to neural machine translation. A key feature of the Transformer architecture is the so-called multi-head attention mechanism, which allows the model to focus simultaneously on different parts of the input. However, recent works have shown that most attention heads learn simple, and often redundant, positional patterns. In this paper, we propose to replace all but one attention head of each encoder layer with simple fixed – non-learnable – attentive patterns that are solely based on position and do not require any external knowledge. Our experiments with different data sizes and multiple language pairs show that fixing the attention heads on the encoder side of the Transformer at training time does not impact the translation quality and even increases BLEU scores by up to 3 points in low-resource scenarios.\nWhat does BERT Learn from Multiple-Choice Reading Comprehension Datasets? (Chenglei Si et al., 2019) Chenglei Si, Shuohang Wang, Min-Yen Kan, Jing Jiang. (2019)\nWhat does BERT Learn from Multiple-Choice Reading Comprehension Datasets?\nArXiv\nPaper Link\nInfluential Citation Count (2), SS-ID (59abe3db26b55c8837a1f2babb87350ba95ab1c0)\nABSTRACT\nMultiple-Choice Reading Comprehension (MCRC) requires the model to read the passage and question, and select the correct answer among the given options. Recent state-of-the-art models have achieved impressive performance on multiple MCRC datasets. However, such performance may not reflect the model\u0026rsquo;s true ability of language understanding and reasoning. In this work, we adopt two approaches to investigate what BERT learns from MCRC datasets: 1) an un-readable data attack, in which we add keywords to confuse BERT, leading to a significant performance drop; and 2) an un-answerable data training, in which we train BERT on partial or shuffled input. Under un-answerable data training, BERT achieves unexpectedly high performance. Based on our experiments on the 5 key MCRC datasets - RACE, MCTest, MCScript, MCScript2.0, DREAM - we observe that 1) fine-tuned BERT mainly learns how keywords lead to correct prediction, instead of learning semantic understanding and reasoning; and 2) BERT does not need correct syntactic information to solve the task; 3) there exists artifacts in these datasets such that they can be solved even without the full context.\nEfficient Training of BERT by Progressively Stacking (Linyuan Gong et al., 2019) Linyuan Gong, Di He, Zhuohan Li, Tao Qin, Liwei Wang, Tie-Yan Liu. (2019)\nEfficient Training of BERT by Progressively Stacking\nICML\nPaper Link\nInfluential Citation Count (7), SS-ID (5a3749929bf5fb8b1f98a7b2a43c3b957bcf6c88)\nABSTRACT\nUnsupervised pre-training is commonly used in natural language processing: a deep neural network trained with proper unsupervised prediction tasks are shown to be effective in many downstream tasks. Because it is easy to create a large monolingual dataset by collecting data from the Web, we can train high-capacity models. Therefore, training efficiency becomes a critical issue even when using high-performance hardware. In this paper, we explore an efficient training method for the state-of-the-art bidirectional Transformer (BERT) model. By visualizing the self-attention distributions of different layers at different positions in a well-trained BERT model, we find that in most layers, the self-attention distribution will concentrate locally around its position and the start-of-sentence token. Motivated by this, we propose the stacking algorithm to transfer knowledge from a shallow model to a deep model; then we apply stacking progressively to accelerate BERT training. Experiments showed that the models trained by our training strategy achieve similar performance to models trained from scratch, but our algorithm is much faster.\nWhat Does My QA Model Know? Devising Controlled Probes Using Expert Knowledge (Kyle Richardson et al., 2019) Kyle Richardson, Ashish Sabharwal. (2019)\nWhat Does My QA Model Know? Devising Controlled Probes Using Expert Knowledge\nTransactions of the Association for Computational Linguistics\nPaper Link\nInfluential Citation Count (2), SS-ID (5a9001cdccdb8b1de227a45eccc503d32d1a2464)\nABSTRACT\nAbstract Open-domain question answering (QA) involves many knowledge and reasoning challenges, but are successful QA models actually learning such knowledge when trained on benchmark QA tasks? We investigate this via several new diagnostic tasks probing whether multiple-choice QA models know definitions and taxonomic reasoning—two skills widespread in existing benchmarks and fundamental to more complex reasoning. We introduce a methodology for automatically building probe datasets from expert knowledge sources, allowing for systematic control and a comprehensive evaluation. We include ways to carefully control for artifacts that may arise during this process. Our evaluation confirms that transformer-based multiple-choice QA models are already predisposed to recognize certain types of structural linguistic knowledge. However, it also reveals a more nuanced picture: their performance notably degrades even with a slight increase in the number of “hops” in the underlying taxonomic hierarchy, and with more challenging distractor candidates. Further, existing models are far from perfect when assessed at the level of clusters of semantically connected probes, such as all hypernym questions about a single concept.\nHow Language-Neutral is Multilingual BERT? (Jindřich Libovický et al., 2019) Jindřich Libovický, Rudolf Rosa, Alexander M. Fraser. (2019)\nHow Language-Neutral is Multilingual BERT?\nArXiv\nPaper Link\nInfluential Citation Count (12), SS-ID (5d8beeca1a2e3263b2796e74e2f57ffb579737ee)\nABSTRACT\nMultilingual BERT (mBERT) provides sentence representations for 104 languages, which are useful for many multi-lingual tasks. Previous work probed the cross-linguality of mBERT using zero-shot transfer learning on morphological and syntactic tasks. We instead focus on the semantic properties of mBERT. We show that mBERT representations can be split into a language-specific component and a language-neutral component, and that the language-neutral component is sufficiently general in terms of modeling semantics to allow high-accuracy word-alignment and sentence retrieval but is not yet good enough for the more difficult task of MT quality estimation. Our work presents interesting challenges which must be solved to build better language-neutral representations, particularly for tasks requiring linguistic transfer of semantics.\nTransformers to Learn Hierarchical Contexts in Multiparty Dialogue for Span-based Question Answering (Changmao Li et al., 2020) Changmao Li, Jinho D. Choi. (2020)\nTransformers to Learn Hierarchical Contexts in Multiparty Dialogue for Span-based Question Answering\nACL\nPaper Link\nInfluential Citation Count (3), SS-ID (5dd520b6c92aae3fd76df5bb61014e50fab93817)\nABSTRACT\nWe introduce a novel approach to transformers that learns hierarchical representations in multiparty dialogue. First, three language modeling tasks are used to pre-train the transformers, token- and utterance-level language modeling and utterance order prediction, that learn both token and utterance embeddings for better understanding in dialogue contexts. Then, multi-task learning between the utterance prediction and the token span prediction is applied to fine-tune for span-based question answering (QA). Our approach is evaluated on the FriendsQA dataset and shows improvements of 3.8% and 1.4% over the two state-of-the-art transformer models, BERT and RoBERTa, respectively.\noLMpics-On What Language Model Pre-training Captures (Alon Talmor et al., 2019) Alon Talmor, Yanai Elazar, Yoav Goldberg, Jonathan Berant. (2019)\noLMpics-On What Language Model Pre-training Captures\nTransactions of the Association for Computational Linguistics\nPaper Link\nInfluential Citation Count (17), SS-ID (5e0cffc51e8b64a8f11326f955fa4b4f1803e3be)\nABSTRACT\nAbstract Recent success of pre-trained language models (LMs) has spurred widespread interest in the language capabilities that they possess. However, efforts to understand whether LM representations are useful for symbolic reasoning tasks have been limited and scattered. In this work, we propose eight reasoning tasks, which conceptually require operations such as comparison, conjunction, and composition. A fundamental challenge is to understand whether the performance of a LM on a task should be attributed to the pre-trained representations or to the process of fine-tuning on the task data. To address this, we propose an evaluation protocol that includes both zero-shot evaluation (no fine-tuning), as well as comparing the learning curve of a fine-tuned LM to the learning curve of multiple controls, which paints a rich picture of the LM capabilities. Our main findings are that: (a) different LMs exhibit qualitatively different reasoning abilities, e.g., RoBERTa succeeds in reasoning tasks where BERT fails completely; (b) LMs do not reason in an abstract manner and are context-dependent, e.g., while RoBERTa can compare ages, it can do so only when the ages are in the typical range of human ages; (c) On half of our reasoning tasks all models fail completely. Our findings and infrastructure can help future work on designing new datasets, models, and objective functions for pre-training.\nOn Measuring Social Biases in Sentence Encoders (Chandler May et al., 2019) Chandler May, Alex Wang, Shikha Bordia, Samuel R. Bowman, Rachel Rudinger. (2019)\nOn Measuring Social Biases in Sentence Encoders\nNAACL\nPaper Link\nInfluential Citation Count (25), SS-ID (5e9c85235210b59a16bdd84b444a904ae271f7e7)\nABSTRACT\nThe Word Embedding Association Test shows that GloVe and word2vec word embeddings exhibit human-like implicit biases based on gender, race, and other social constructs (Caliskan et al., 2017). Meanwhile, research on learning reusable text representations has begun to explore sentence-level texts, with some sentence encoders seeing enthusiastic adoption. Accordingly, we extend the Word Embedding Association Test to measure bias in sentence encoders. We then test several sentence encoders, including state-of-the-art methods such as ELMo and BERT, for the social biases studied in prior work and two important biases that are difficult or impossible to test at the word level. We observe mixed results including suspicious patterns of sensitivity that suggest the test’s assumptions may not hold in general. We conclude by proposing directions for future work on measuring bias in sentence encoders.\nERNIE: Enhanced Language Representation with Informative Entities (Zhengyan Zhang et al., 2019) Zhengyan Zhang, Xu Han, Zhiyuan Liu, Xin Jiang, Maosong Sun, Qun Liu. (2019)\nERNIE: Enhanced Language Representation with Informative Entities\nACL\nPaper Link\nInfluential Citation Count (90), SS-ID (5f994dc8cae24ca9d1ed629e517fcc652660ddde)\nABSTRACT\nNeural language representation models such as BERT pre-trained on large-scale corpora can well capture rich semantic patterns from plain text, and be fine-tuned to consistently improve the performance of various NLP tasks. However, the existing pre-trained language models rarely consider incorporating knowledge graphs (KGs), which can provide rich structured knowledge facts for better language understanding. We argue that informative entities in KGs can enhance language representation with external knowledge. In this paper, we utilize both large-scale textual corpora and KGs to train an enhanced language representation model (ERNIE), which can take full advantage of lexical, syntactic, and knowledge information simultaneously. The experimental results have demonstrated that ERNIE achieves significant improvements on various knowledge-driven tasks, and meanwhile is comparable with the state-of-the-art model BERT on other common NLP tasks. The code and datasets will be available in the future.\nMiniLM: Deep Self-Attention Distillation for Task-Agnostic Compression of Pre-Trained Transformers (Wenhui Wang et al., 2020) Wenhui Wang, Furu Wei, Li Dong, Hangbo Bao, Nan Yang, Ming Zhou. (2020)\nMiniLM: Deep Self-Attention Distillation for Task-Agnostic Compression of Pre-Trained Transformers\nNeurIPS\nPaper Link\nInfluential Citation Count (42), SS-ID (60a4a3a886338d0c8e3579d392cb32f493430255)\nABSTRACT\nPre-trained language models (e.g., BERT (Devlin et al., 2018) and its variants) have achieved remarkable success in varieties of NLP tasks. However, these models usually consist of hundreds of millions of parameters which brings challenges for fine-tuning and online serving in real-life applications due to latency and capacity constraints. In this work, we present a simple and effective approach to compress large Transformer (Vaswani et al., 2017) based pre-trained models, termed as deep self-attention distillation. The small model (student) is trained by deeply mimicking the self-attention module, which plays a vital role in Transformer networks, of the large model (teacher). Specifically, we propose distilling the self-attention module of the last Transformer layer of the teacher, which is effective and flexible for the student. Furthermore, we introduce the scaled dot-product between values in the self-attention module as the new deep self-attention knowledge, in addition to the attention distributions (i.e., the scaled dot-product of queries and keys) that have been used in existing works. Moreover, we show that introducing a teacher assistant (Mirzadeh et al., 2019) also helps the distillation of large pre-trained Transformer models. Experimental results demonstrate that our monolingual model outperforms state-of-the-art baselines in different parameter size of student models. In particular, it retains more than 99% accuracy on SQuAD 2.0 and several GLUE benchmark tasks using 50% of the Transformer parameters and computations of the teacher model. We also obtain competitive results in applying deep self-attention distillation to multilingual pre-trained models.\nSymmetric Regularization based BERT for Pair-wise Semantic Reasoning (Xingyi Cheng et al., 2019) Xingyi Cheng, Weidi Xu, Kunlong Chen, Wei Wang, Bin Bi, Ming Yan, Chen Wu, Luo Si, Wei Chu, Taifeng Wang. (2019)\nSymmetric Regularization based BERT for Pair-wise Semantic Reasoning\nSIGIR\nPaper Link\nInfluential Citation Count (1), SS-ID (63f9e2417563456f91c7e5586d43eb25c00a0c19)\nABSTRACT\nThe ability of semantic reasoning over the sentence pair is essential for many natural language understanding tasks, e.g., natural language inference and machine reading comprehension. A recent significant improvement in these tasks comes from BERT. As reported, the next sentence prediction (NSP) in BERT is of great significance for downstream problems with sentence-pair input. Despite its effectiveness, NSP still lacks the essential signal to distinguish between entailment and shallow correlation. To remedy this, we propose to augment the NSP task to a multi-class categorization task, which includes previous sentence prediction (PSP). This task encourages the model to learn the subtle semantics, thereby improves the ability of semantic understanding. Furthermore, by using a smoothing technique, the scopes of NSP and PSP are expanded into a broader range which includes close but nonsuccessive sentences. This simple method yields remarkable improvement against vanilla BERT. Our method consistently improves the performance on the NLI and MRC benchmarks by a large margin, including the challenging HANS dataset.\nDoes BERT agree? Evaluating knowledge of structure dependence through agreement relations (Geoff Bacon et al., 2019) Geoff Bacon, T. Regier. (2019)\nDoes BERT agree? Evaluating knowledge of structure dependence through agreement relations\nArXiv\nPaper Link\nInfluential Citation Count (0), SS-ID (645a96e5c474d919415850892880005e4ad3fb43)\nABSTRACT\nLearning representations that accurately model semantics is an important goal of natural language processing research. Many semantic phenomena depend on syntactic structure. Recent work examines the extent to which state-of-the-art models for pre-training representations, such as BERT, capture such structure-dependent phenomena, but is largely restricted to one phenomenon in English: number agreement between subjects and verbs. We evaluate BERT\u0026rsquo;s sensitivity to four types of structure-dependent agreement relations in a new semi-automatically curated dataset across 26 languages. We show that both the single-language and multilingual BERT models capture syntax-sensitive agreement patterns well in general, but we also highlight the specific linguistic contexts in which their performance degrades.\nUnicoder: A Universal Language Encoder by Pre-training with Multiple Cross-lingual Tasks (Haoyang Huang et al., 2019) Haoyang Huang, Yaobo Liang, Nan Duan, Ming Gong, Linjun Shou, Daxin Jiang, M. Zhou. (2019)\nUnicoder: A Universal Language Encoder by Pre-training with Multiple Cross-lingual Tasks\nEMNLP\nPaper Link\nInfluential Citation Count (17), SS-ID (65f788fb964901e3f1149a0a53317535ca85ed7d)\nABSTRACT\nWe present Unicoder, a universal language encoder that is insensitive to different languages. Given an arbitrary NLP task, a model can be trained with Unicoder using training data in one language and directly applied to inputs of the same task in other languages. Comparing to similar efforts such as Multilingual BERT and XLM , three new cross-lingual pre-training tasks are proposed, including cross-lingual word recovery, cross-lingual paraphrase classification and cross-lingual masked language model. These tasks help Unicoder learn the mappings among different languages from more perspectives. We also find that doing fine-tuning on multiple languages together can bring further improvement. Experiments are performed on two tasks: cross-lingual natural language inference (XNLI) and cross-lingual question answering (XQA), where XLM is our baseline. On XNLI, 1.8% averaged accuracy improvement (on 15 languages) is obtained. On XQA, which is a new cross-lingual dataset built by us, 5.5% averaged accuracy improvement (on French and German) is obtained.\nBERT and PALs: Projected Attention Layers for Efficient Adaptation in Multi-Task Learning (Asa Cooper Stickland et al., 2019) Asa Cooper Stickland, Iain Murray. (2019)\nBERT and PALs: Projected Attention Layers for Efficient Adaptation in Multi-Task Learning\nICML\nPaper Link\nInfluential Citation Count (13), SS-ID (660d3472d9c3733dedcf911187b234f2b65561b5)\nABSTRACT\nMulti-task learning shares information between related tasks, sometimes reducing the number of parameters required. State-of-the-art results across multiple natural language understanding tasks in the GLUE benchmark have previously used transfer from a single large task: unsupervised pre-training with BERT, where a separate BERT model was fine-tuned for each task. We explore multi-task approaches that share a single BERT model with a small number of additional task-specific parameters. Using new adaptation modules, PALs or `projected attention layers\u0026rsquo;, we match the performance of separately fine-tuned models on the GLUE benchmark with roughly 7 times fewer parameters, and obtain state-of-the-art results on the Recognizing Textual Entailment dataset.\nAnalysis Methods in Neural Language Processing: A Survey (Y. Belinkov et al., 2018) Y. Belinkov, James R. Glass. (2018)\nAnalysis Methods in Neural Language Processing: A Survey\nTACL\nPaper Link\nInfluential Citation Count (17), SS-ID (668f42a4d4094f0a66d402a16087e14269b31a1f)\nABSTRACT\nThe field of natural language processing has seen impressive progress in recent years, with neural network models replacing many of the traditional systems. A plethora of new models have been proposed, many of which are thought to be opaque compared to their feature-rich counterparts. This has led researchers to analyze, interpret, and evaluate neural networks in novel and more fine-grained ways. In this survey paper, we review analysis methods in neural language processing, categorize them according to prominent research trends, highlight existing limitations, and point to potential directions for future work.\nMovement Pruning: Adaptive Sparsity by Fine-Tuning (Victor Sanh et al., 2020) Victor Sanh, Thomas Wolf, Alexander M. Rush. (2020)\nMovement Pruning: Adaptive Sparsity by Fine-Tuning\nNeurIPS\nPaper Link\nInfluential Citation Count (20), SS-ID (66f0f35fc78bdf2af9de46093d49a428970cde2e)\nABSTRACT\nMagnitude pruning is a widely used strategy for reducing model size in pure supervised learning; however, it is less effective in the transfer learning regime that has become standard for state-of-the-art natural language processing applications. We propose the use of movement pruning, a simple, deterministic first-order weight pruning method that is more adaptive to pretrained model fine-tuning. We give mathematical foundations to the method and compare it to existing zeroth- and first-order pruning methods. Experiments show that when pruning large pretrained language models, movement pruning shows significant improvements in high-sparsity regimes. When combined with distillation, the approach achieves minimal accuracy loss with down to only 3% of the model parameters.\nProbing Natural Language Inference Models through Semantic Fragments (Kyle Richardson et al., 2019) Kyle Richardson, Hai Hu, L. Moss, Ashish Sabharwal. (2019)\nProbing Natural Language Inference Models through Semantic Fragments\nAAAI\nPaper Link\nInfluential Citation Count (12), SS-ID (681fbcd98acf20df3355eff3585994bd1f9008b7)\nABSTRACT\nDo state-of-the-art models for language understanding already have, or can they easily learn, abilities such as boolean coordination, quantification, conditionals, comparatives, and monotonicity reasoning (i.e., reasoning about word substitutions in sentential contexts)? While such phenomena are involved in natural language inference (NLI) and go beyond basic linguistic understanding, it is unclear the extent to which they are captured in existing NLI benchmarks and effectively learned by models. To investigate this, we propose the use of semantic fragments—systematically generated datasets that each target a different semantic phenomenon—for probing, and efficiently improving, such capabilities of linguistic models. This approach to creating challenge datasets allows direct control over the semantic diversity and complexity of the targeted linguistic phenomena, and results in a more precise characterization of a model\u0026rsquo;s linguistic behavior. Our experiments, using a library of 8 such semantic fragments, reveal two remarkable findings: (a) State-of-the-art models, including BERT, that are pre-trained on existing NLI benchmark datasets perform poorly on these new fragments, even though the phenomena probed here are central to the NLI task; (b) On the other hand, with only a few minutes of additional fine-tuning—with a carefully selected learning rate and a novel variation of “inoculation”—a BERT-based model can master all of these logic and monotonicity fragments while retaining its performance on established NLI benchmarks.\nLanguage Models are Few-Shot Learners (Tom B. Brown et al., 2020) Tom B. Brown, Benjamin Mann, Nick Ryder, Melanie Subbiah, J. Kaplan, Prafulla Dhariwal, Arvind Neelakantan, Pranav Shyam, Girish Sastry, Amanda Askell, Sandhini Agarwal, Ariel Herbert-Voss, Gretchen Krueger, T. Henighan, Rewon Child, A. Ramesh, Daniel M. Ziegler, Jeff Wu, Clemens Winter, Christopher Hesse, Mark Chen, Eric Sigler, Mateusz Litwin, Scott Gray, Benjamin Chess, Jack Clark, Christopher Berner, Sam McCandlish, Alec Radford, Ilya Sutskever, Dario Amodei. (2020)\nLanguage Models are Few-Shot Learners\nNeurIPS\nPaper Link\nInfluential Citation Count (428), SS-ID (6b85b63579a916f705a8e10a49bd8d849d91b1fc)\nABSTRACT\nRecent work has demonstrated substantial gains on many NLP tasks and benchmarks by pre-training on a large corpus of text followed by fine-tuning on a specific task. While typically task-agnostic in architecture, this method still requires task-specific fine-tuning datasets of thousands or tens of thousands of examples. By contrast, humans can generally perform a new language task from only a few examples or from simple instructions - something which current NLP systems still largely struggle to do. Here we show that scaling up language models greatly improves task-agnostic, few-shot performance, sometimes even reaching competitiveness with prior state-of-the-art fine-tuning approaches. Specifically, we train GPT-3, an autoregressive language model with 175 billion parameters, 10x more than any previous non-sparse language model, and test its performance in the few-shot setting. For all tasks, GPT-3 is applied without any gradient updates or fine-tuning, with tasks and few-shot demonstrations specified purely via text interaction with the model. GPT-3 achieves strong performance on many NLP datasets, including translation, question-answering, and cloze tasks, as well as several tasks that require on-the-fly reasoning or domain adaptation, such as unscrambling words, using a novel word in a sentence, or performing 3-digit arithmetic. At the same time, we also identify some datasets where GPT-3\u0026rsquo;s few-shot learning still struggles, as well as some datasets where GPT-3 faces methodological issues related to training on large web corpora. Finally, we find that GPT-3 can generate samples of news articles which human evaluators have difficulty distinguishing from articles written by humans. We discuss broader societal impacts of this finding and of GPT-3 in general.\nSpan Selection Pre-training for Question Answering (Michael R. Glass et al., 2019) Michael R. Glass, A. Gliozzo, Rishav Chakravarti, Anthony Ferritto, Lin Pan, G P Shrivatsa Bhargav, Dinesh Garg, Avirup Sil. (2019)\nSpan Selection Pre-training for Question Answering\nACL\nPaper Link\nInfluential Citation Count (2), SS-ID (6c8503803760c5c7790f72437d0f8b874334e6f0)\nABSTRACT\nBERT (Bidirectional Encoder Representations from Transformers) and related pre-trained Transformers have provided large gains across many language understanding tasks, achieving a new state-of-the-art (SOTA). BERT is pretrained on two auxiliary tasks: Masked Language Model and Next Sentence Prediction. In this paper we introduce a new pre-training task inspired by reading comprehension to better align the pre-training from memorization to understanding. Span Selection PreTraining (SSPT) poses cloze-like training instances, but rather than draw the answer from the model’s parameters, it is selected from a relevant passage. We find significant and consistent improvements over both BERT-BASE and BERT-LARGE on multiple Machine Reading Comprehension (MRC) datasets. Specifically, our proposed model has strong empirical evidence as it obtains SOTA results on Natural Questions, a new benchmark MRC dataset, outperforming BERT-LARGE by 3 F1 points on short answer prediction. We also show significant impact in HotpotQA, improving answer prediction F1 by 4 points and supporting fact prediction F1 by 1 point and outperforming the previous best system. Moreover, we show that our pre-training approach is particularly effective when training data is limited, improving the learning curve by a large amount.\nUnsupervised Cross-lingual Representation Learning at Scale (A. Conneau et al., 2019) A. Conneau, Kartikay Khandelwal, Naman Goyal, Vishrav Chaudhary, Guillaume Wenzek, Francisco Guzmán, Edouard Grave, Myle Ott, Luke Zettlemoyer, Veselin Stoyanov. (2019)\nUnsupervised Cross-lingual Representation Learning at Scale\nACL\nPaper Link\nInfluential Citation Count (527), SS-ID (6fec3e579c7cd4f13bdabbee2b6ac2e8ff5941c6)\nABSTRACT\nThis paper shows that pretraining multilingual language models at scale leads to significant performance gains for a wide range of cross-lingual transfer tasks. We train a Transformer-based masked language model on one hundred languages, using more than two terabytes of filtered CommonCrawl data. Our model, dubbed XLM-R, significantly outperforms multilingual BERT (mBERT) on a variety of cross-lingual benchmarks, including +14.6% average accuracy on XNLI, +13% average F1 score on MLQA, and +2.4% F1 score on NER. XLM-R performs particularly well on low-resource languages, improving 15.7% in XNLI accuracy for Swahili and 11.4% for Urdu over previous XLM models. We also present a detailed empirical analysis of the key factors that are required to achieve these gains, including the trade-offs between (1) positive transfer and capacity dilution and (2) the performance of high and low resource languages at scale. Finally, we show, for the first time, the possibility of multilingual modeling without sacrificing per-language performance; XLM-R is very competitive with strong monolingual models on the GLUE and XNLI benchmarks. We will make our code and models publicly available.\nInducing Syntactic Trees from BERT Representations (Rudolf Rosa et al., 2019) Rudolf Rosa, D. Mareček. (2019)\nInducing Syntactic Trees from BERT Representations\nArXiv\nPaper Link\nInfluential Citation Count (1), SS-ID (71f551f0352b91ab4725c498c68610655d3b5578)\nABSTRACT\nWe use the English model of BERT and explore how a deletion of one word in a sentence changes representations of other words. Our hypothesis is that removing a reducible word (e.g. an adjective) does not affect the representation of other words so much as removing e.g. the main verb, which makes the sentence ungrammatical and of \u0026ldquo;high surprise\u0026rdquo; for the language model. We estimate reducibilities of individual words and also of longer continuous phrases (word n-grams), study their syntax-related properties, and then also use them to induce full dependency trees.\nCompressing Large-Scale Transformer-Based Models: A Case Study on BERT (Prakhar Ganesh et al., 2020) Prakhar Ganesh, Yao Chen, Xin Lou, Mohammad Ali Khan, Y. Yang, Deming Chen, M. Winslett, Hassan Sajjad, Preslav Nakov. (2020)\nCompressing Large-Scale Transformer-Based Models: A Case Study on BERT\nTransactions of the Association for Computational Linguistics\nPaper Link\nInfluential Citation Count (5), SS-ID (738215a396f6eee1709c6b521a6199769f0ce674)\nABSTRACT\nAbstract Pre-trained Transformer-based models have achieved state-of-the-art performance for various Natural Language Processing (NLP) tasks. However, these models often have billions of parameters, and thus are too resource- hungry and computation-intensive to suit low- capability devices or applications with strict latency requirements. One potential remedy for this is model compression, which has attracted considerable research attention. Here, we summarize the research in compressing Transformers, focusing on the especially popular BERT model. In particular, we survey the state of the art in compression for BERT, we clarify the current best practices for compressing large-scale Transformer models, and we provide insights into the workings of various methods. Our categorization and analysis also shed light on promising future research directions for achieving lightweight, accurate, and generic NLP models.\nInformation-Theoretic Probing for Linguistic Structure (Tiago Pimentel et al., 2020) Tiago Pimentel, Josef Valvoda, Rowan Hall Maudslay, Ran Zmigrod, Adina Williams, Ryan Cotterell. (2020)\nInformation-Theoretic Probing for Linguistic Structure\nACL\nPaper Link\nInfluential Citation Count (16), SS-ID (738c6d664aa6c3854e1aa894957bd595f621fc42)\nABSTRACT\nThe success of neural networks on a diverse set of NLP tasks has led researchers to question how much these networks actually “know” about natural language. Probes are a natural way of assessing this. When probing, a researcher chooses a linguistic task and trains a supervised model to predict annotations in that linguistic task from the network’s learned representations. If the probe does well, the researcher may conclude that the representations encode knowledge related to the task. A commonly held belief is that using simpler models as probes is better; the logic is that simpler models will identify linguistic structure, but not learn the task itself. We propose an information-theoretic operationalization of probing as estimating mutual information that contradicts this received wisdom: one should always select the highest performing probe one can, even if it is more complex, since it will result in a tighter estimate, and thus reveal more of the linguistic information inherent in the representation. The experimental portion of our paper focuses on empirically estimating the mutual information between a linguistic property and BERT, comparing these estimates to several baselines. We evaluate on a set of ten typologically diverse languages often underrepresented in NLP research—plus English—totalling eleven languages. Our implementation is available in https://github.com/rycolab/info-theoretic-probing.\nWaLDORf: Wasteless Language-model Distillation On Reading-comprehension (J. Tian et al., 2019) J. Tian, A. Kreuzer, Pai-Hung Chen, Hans-Martin Will. (2019)\nWaLDORf: Wasteless Language-model Distillation On Reading-comprehension\nArXiv\nPaper Link\nInfluential Citation Count (0), SS-ID (73dd65e859d2566f3755c11cb12aff518202186a)\nABSTRACT\nTransformer based Very Large Language Models (VLLMs) like BERT, XLNet and RoBERTa, have recently shown tremendous performance on a large variety of Natural Language Understanding (NLU) tasks. However, due to their size, these VLLMs are extremely resource intensive and cumbersome to deploy at production time. Several recent publications have looked into various ways to distil knowledge from a transformer based VLLM (most commonly BERT-Base) into a smaller model which can run much faster at inference time. Here, we propose a novel set of techniques which together produce a task-specific hybrid convolutional and transformer model, WaLDORf, that achieves state-of-the-art inference speed while still being more accurate than previous distilled models.\nWell-Read Students Learn Better: On the Importance of Pre-training Compact Models (Iulia Turc et al., 2019) Iulia Turc, Ming-Wei Chang, Kenton Lee, Kristina Toutanova. (2019)\nWell-Read Students Learn Better: On the Importance of Pre-training Compact Models\nPaper Link\nInfluential Citation Count (37), SS-ID (7402b604f14b8b91c53ed6eed04af92c59636c97)\nABSTRACT\nRecent developments in natural language representations have been accompanied by large and expensive models that leverage vast amounts of general-domain text through self-supervised pre-training. Due to the cost of applying such models to down-stream tasks, several model compression techniques on pre-trained language representations have been proposed (Sun et al., 2019; Sanh, 2019). However, surprisingly, the simple baseline of just pre-training and fine-tuning compact models has been overlooked. In this paper, we first show that pre-training remains important in the context of smaller architectures, and fine-tuning pre-trained compact models can be competitive to more elaborate methods proposed in concurrent work. Starting with pre-trained compact models, we then explore transferring task knowledge from large fine-tuned models through standard knowledge distillation. The resulting simple, yet effective and general algorithm, Pre-trained Distillation, brings further improvements. Through extensive experiments, we more generally explore the interaction between pre-training and distillation under two variables that have been under-studied: model size and properties of unlabeled task data. One surprising observation is that they have a compound effect even when sequentially applied on the same data. To accelerate future research, we will make our 24 pre-trained miniature BERT models publicly available.\nExtreme Language Model Compression with Optimal Subwords and Shared Projections (Sanqiang Zhao et al., 2019) Sanqiang Zhao, Raghav Gupta, Yang Song, Denny Zhou. (2019)\nExtreme Language Model Compression with Optimal Subwords and Shared Projections\nArXiv\nPaper Link\nInfluential Citation Count (6), SS-ID (740e4599b0e3113ad804cee4394c7fa7c0e96ca5)\nABSTRACT\nPre-trained deep neural network language models such as ELMo, GPT, BERT and XLNet have recently achieved state-of-the-art performance on a variety of language understanding tasks. However, their size makes them impractical for a number of scenarios, especially on mobile and edge devices. In particular, the input word embedding matrix accounts for a significant proportion of the model\u0026rsquo;s memory footprint, due to the large input vocabulary and embedding dimensions. Knowledge distillation techniques have had success at compressing large neural network models, but they are ineffective at yielding student models with vocabularies different from the original teacher models. We introduce a novel knowledge distillation technique for training a student model with a significantly smaller vocabulary as well as lower embedding and hidden state dimensions. Specifically, we employ a dual-training mechanism that trains the teacher and student models simultaneously to obtain optimal word embeddings for the student vocabulary. We combine this approach with learning shared projection matrices that transfer layer-wise knowledge from the teacher model to the student model. Our method is able to compress the BERT_BASE model by more than 60x, with only a minor drop in downstream task metrics, resulting in a language model with a footprint of under 7MB. Experimental results also demonstrate higher compression efficiency and accuracy when compared with other state-of-the-art compression techniques.\nALBERT: A Lite BERT for Self-supervised Learning of Language Representations (Zhenzhong Lan et al., 2019) Zhenzhong Lan, Mingda Chen, Sebastian Goodman, Kevin Gimpel, Piyush Sharma, Radu Soricut. (2019)\nALBERT: A Lite BERT for Self-supervised Learning of Language Representations\nICLR\nPaper Link\nInfluential Citation Count (573), SS-ID (7a064df1aeada7e69e5173f7d4c8606f4470365b)\nABSTRACT\nIncreasing model size when pretraining natural language representations often results in improved performance on downstream tasks. However, at some point further model increases become harder due to GPU/TPU memory limitations and longer training times. To address these problems, we present two parameter-reduction techniques to lower memory consumption and increase the training speed of BERT. Comprehensive empirical evidence shows that our proposed methods lead to models that scale much better compared to the original BERT. We also use a self-supervised loss that focuses on modeling inter-sentence coherence, and show it consistently helps downstream tasks with multi-sentence inputs. As a result, our best model establishes new state-of-the-art results on the GLUE, RACE, and \\squad benchmarks while having fewer parameters compared to BERT-large. The code and the pretrained models are available at this https URL.\nBERT is Not a Knowledge Base (Yet): Factual Knowledge vs. Name-Based Reasoning in Unsupervised QA (Nina Poerner et al., 2019) Nina Poerner, Ulli Waltinger, Hinrich Schütze. (2019)\nBERT is Not a Knowledge Base (Yet): Factual Knowledge vs. Name-Based Reasoning in Unsupervised QA\nArXiv\nPaper Link\nInfluential Citation Count (8), SS-ID (7c62ac7aedacc39ca417a48f8134e0514dc6a523)\nABSTRACT\nThe BERT language model (LM) (Devlin et al., 2019) is surprisingly good at answering cloze-style questions about relational facts. Petroni et al. (2019) take this as evidence that BERT memorizes factual knowledge during pre-training. We take issue with this interpretation and argue that the performance of BERT is partly due to reasoning about (the surface form of) entity names, e.g., guessing that a person with an Italian-sounding name speaks Italian. More specifically, we show that BERT\u0026rsquo;s precision drops dramatically when we filter certain easy-to-guess facts. As a remedy, we propose E-BERT, an extension of BERT that replaces entity mentions with symbolic entity embeddings. E-BERT outperforms both BERT and ERNIE (Zhang et al., 2019) on hard-to-guess queries. We take this as evidence that E-BERT is richer in factual knowledge, and we show two ways of ensembling BERT and E-BERT.\nAre Pre-trained Language Models Aware of Phrases? Simple but Strong Baselines for Grammar Induction (Taeuk Kim et al., 2020) Taeuk Kim, Jihun Choi, Daniel Edmiston, Sang-goo Lee. (2020)\nAre Pre-trained Language Models Aware of Phrases? Simple but Strong Baselines for Grammar Induction\nICLR\nPaper Link\nInfluential Citation Count (7), SS-ID (7cf8510d5905bd8a63f1e098e05ab591d689e0fd)\nABSTRACT\nWith the recent success and popularity of pre-trained language models (LMs) in natural language processing, there has been a rise in efforts to understand their inner workings. In line with such interest, we propose a novel method that assists us in investigating the extent to which pre-trained LMs capture the syntactic notion of constituency. Our method provides an effective way of extracting constituency trees from the pre-trained LMs without training. In addition, we report intriguing findings in the induced trees, including the fact that pre-trained LMs outperform other approaches in correctly demarcating adverb phrases in sentences.\nHow Much Knowledge Can You Pack into the Parameters of a Language Model? (Adam Roberts et al., 2020) Adam Roberts, Colin Raffel, Noam M. Shazeer. (2020)\nHow Much Knowledge Can You Pack into the Parameters of a Language Model?\nEMNLP\nPaper Link\nInfluential Citation Count (38), SS-ID (80376bdec5f534be78ba82821f540590ebce5559)\nABSTRACT\nIt has recently been observed that neural language models trained on unstructured text can implicitly store and retrieve knowledge using natural language queries. In this short paper, we measure the practical utility of this approach by fine-tuning pre-trained models to answer questions without access to any external context or knowledge. We show that this approach scales surprisingly well with model size and outperforms models that explicitly look up knowledge on the open-domain variants of Natural Questions and WebQuestions. To facilitate reproducibility and future work, we release our code and trained models.\nHow Multilingual is Multilingual BERT? (Telmo J. P. Pires et al., 2019) Telmo J. P. Pires, Eva Schlinger, Dan Garrette. (2019)\nHow Multilingual is Multilingual BERT?\nACL\nPaper Link\nInfluential Citation Count (62), SS-ID (809cc93921e4698bde891475254ad6dfba33d03b)\nABSTRACT\nIn this paper, we show that Multilingual BERT (M-BERT), released by Devlin et al. (2018) as a single language model pre-trained from monolingual corpora in 104 languages, is surprisingly good at zero-shot cross-lingual model transfer, in which task-specific annotations in one language are used to fine-tune the model for evaluation in another language. To understand why, we present a large number of probing experiments, showing that transfer is possible even to languages in different scripts, that transfer works best between typologically similar languages, that monolingual corpora can train models for code-switching, and that the model can find translation pairs. From these results, we can conclude that M-BERT does create multilingual representations, but that these representations exhibit systematic deficiencies affecting certain language pairs.\nPatient Knowledge Distillation for BERT Model Compression (S. Sun et al., 2019) S. Sun, Yu Cheng, Zhe Gan, Jingjing Liu. (2019)\nPatient Knowledge Distillation for BERT Model Compression\nEMNLP\nPaper Link\nInfluential Citation Count (82), SS-ID (80cf2a6af4200ecfca1c18fc89de16148f1cd4bf)\nABSTRACT\nPre-trained language models such as BERT have proven to be highly effective for natural language processing (NLP) tasks. However, the high demand for computing resources in training such models hinders their application in practice. In order to alleviate this resource hunger in large-scale model training, we propose a Patient Knowledge Distillation approach to compress an original large model (teacher) into an equally-effective lightweight shallow network (student). Different from previous knowledge distillation methods, which only use the output from the last layer of the teacher network for distillation, our student model patiently learns from multiple intermediate layers of the teacher model for incremental knowledge extraction, following two strategies: (i) PKD-Last: learning from the last k layers; and (ii) PKD-Skip: learning from every k layers. These two patient distillation schemes enable the exploitation of rich information in the teacher’s hidden layers, and encourage the student model to patiently learn from and imitate the teacher through a multi-layer distillation process. Empirically, this translates into improved results on multiple NLP tasks with a significant gain in training efficiency, without sacrificing model accuracy.\nUnderstanding Commonsense Inference Aptitude of Deep Contextual Representations (Jeff Da et al., 2019) Jeff Da, Jungo Kasai. (2019)\nUnderstanding Commonsense Inference Aptitude of Deep Contextual Representations\nProceedings of the First Workshop on Commonsense Inference in Natural Language Processing\nPaper Link\nInfluential Citation Count (0), SS-ID (80dc7b0e6dbc26571672d9be57a0ae589689e410)\nABSTRACT\nERNIE 2.0: A Continual Pre-training Framework for Language Understanding (Yu Sun et al., 2019) Yu Sun, Shuohuan Wang, Yukun Li, Shikun Feng, Hao Tian, Hua Wu, Haifeng Wang. (2019)\nERNIE 2.0: A Continual Pre-training Framework for Language Understanding\nAAAI\nPaper Link\nInfluential Citation Count (63), SS-ID (80f9f109d1564cb8f82aa440a5f6f3fbe220c9ef)\nABSTRACT\nRecently pre-trained models have achieved state-of-the-art results in various language understanding tasks. Current pre-training procedures usually focus on training the model with several simple tasks to grasp the co-occurrence of words or sentences. However, besides co-occurring information, there exists other valuable lexical, syntactic and semantic information in training corpora, such as named entities, semantic closeness and discourse relations. In order to extract the lexical, syntactic and semantic information from training corpora, we propose a continual pre-training framework named ERNIE 2.0 which incrementally builds pre-training tasks and then learn pre-trained models on these constructed tasks via continual multi-task learning. Based on this framework, we construct several tasks and train the ERNIE 2.0 model to capture lexical, syntactic and semantic aspects of information in the training data. Experimental results demonstrate that ERNIE 2.0 model outperforms BERT and XLNet on 16 tasks including English tasks on GLUE benchmarks and several similar tasks in Chinese. The source codes and pre-trained models have been released at https://github.com/PaddlePaddle/ERNIE.\nFrom English To Foreign Languages: Transferring Pre-trained Language Models (Ke M. Tran, 2019) Ke M. Tran. (2019)\nFrom English To Foreign Languages: Transferring Pre-trained Language Models\nArXiv\nPaper Link\nInfluential Citation Count (2), SS-ID (8199b4c196b09d6176816e4d7db8d6f3d65e07c1)\nABSTRACT\nPre-trained models have demonstrated their effectiveness in many downstream natural language processing (NLP) tasks. The availability of multilingual pre-trained models enables zero-shot transfer of NLP tasks from high resource languages to low resource ones. However, recent research in improving pre-trained models focuses heavily on English. While it is possible to train the latest neural architectures for other languages from scratch, it is undesirable due to the required amount of compute. In this work, we tackle the problem of transferring an existing pre-trained model from English to other languages under a limited computational budget. With a single GPU, our approach can obtain a foreign BERT base model within a day and a foreign BERT large within two days. Furthermore, evaluating our models on six languages, we demonstrate that our models are better than multilingual BERT on two zero-shot tasks: natural language inference and dependency parsing.\nHow Can We Know What Language Models Know? (Zhengbao Jiang et al., 2019) Zhengbao Jiang, Frank F. Xu, J. Araki, Graham Neubig. (2019)\nHow Can We Know What Language Models Know?\nTransactions of the Association for Computational Linguistics\nPaper Link\nInfluential Citation Count (16), SS-ID (81dd3faf762ad8f084ab1d7b8fc9e77e9e160f85)\nABSTRACT\nAbstract Recent work has presented intriguing results examining the knowledge contained in language models (LMs) by having the LM fill in the blanks of prompts such as “Obama is a __ by profession”. These prompts are usually manually created, and quite possibly sub-optimal; another prompt such as “Obama worked as a __ ” may result in more accurately predicting the correct profession. Because of this, given an inappropriate prompt, we might fail to retrieve facts that the LM does know, and thus any given prompt only provides a lower bound estimate of the knowledge contained in an LM. In this paper, we attempt to more accurately estimate the knowledge contained in LMs by automatically discovering better prompts to use in this querying process. Specifically, we propose mining-based and paraphrasing-based methods to automatically generate high-quality and diverse prompts, as well as ensemble methods to combine answers from different prompts. Extensive experiments on the LAMA benchmark for extracting relational knowledge from LMs demonstrate that our methods can improve accuracy from 31.1% to 39.6%, providing a tighter lower bound on what LMs know. We have released the code and the resulting LM Prompt And Query Archive (LPAQA) at https://github.com/jzbjyb/LPAQA.\nSpanBERT: Improving Pre-training by Representing and Predicting Spans (Mandar Joshi et al., 2019) Mandar Joshi, Danqi Chen, Yinhan Liu, Daniel S. Weld, Luke Zettlemoyer, Omer Levy. (2019)\nSpanBERT: Improving Pre-training by Representing and Predicting Spans\nTACL\nPaper Link\nInfluential Citation Count (175), SS-ID (81f5810fbbab9b7203b9556f4ce3c741875407bc)\nABSTRACT\nWe present SpanBERT, a pre-training method that is designed to better represent and predict spans of text. Our approach extends BERT by (1) masking contiguous random spans, rather than random tokens, and (2) training the span boundary representations to predict the entire content of the masked span, without relying on the individual token representations within it. SpanBERT consistently outperforms BERT and our better-tuned baselines, with substantial gains on span selection tasks such as question answering and coreference resolution. In particular, with the same training data and model size as BERTlarge, our single model obtains 94.6% and 88.7% F1 on SQuAD 1.1 and 2.0 respectively. We also achieve a new state of the art on the OntoNotes coreference resolution task (79.6% F1), strong performance on the TACRED relation extraction benchmark, and even gains on GLUE.1\nIs Multilingual BERT Fluent in Language Generation? (Samuel Rönnqvist et al., 2019) Samuel Rönnqvist, Jenna Kanerva, T. Salakoski, Filip Ginter. (2019)\nIs Multilingual BERT Fluent in Language Generation?\nArXiv\nPaper Link\nInfluential Citation Count (3), SS-ID (81fbf08beb80b01abaa6ad6a07b48c3034ead8a6)\nABSTRACT\nThe multilingual BERT model is trained on 104 languages and meant to serve as a universal language model and tool for encoding sentences. We explore how well the model performs on several languages across several tasks: a diagnostic classification probing the embeddings for a particular syntactic property, a cloze task testing the language modelling ability to fill in gaps in a sentence, and a natural language generation task testing for the ability to produce coherent text fitting a given context. We find that the currently available multilingual BERT model is clearly inferior to the monolingual counterparts, and cannot in many cases serve as a substitute for a well-trained monolingual model. We find that the English and German models perform well at generation, whereas the multilingual model is lacking, in particular, for Nordic languages.\nREALM: Retrieval-Augmented Language Model Pre-Training (Kelvin Guu et al., 2020) Kelvin Guu, Kenton Lee, Z. Tung, Panupong Pasupat, Ming-Wei Chang. (2020)\nREALM: Retrieval-Augmented Language Model Pre-Training\nArXiv\nPaper Link\nInfluential Citation Count (64), SS-ID (832fff14d2ed50eb7969c4c4b976c35776548f56)\nABSTRACT\nLanguage model pre-training has been shown to capture a surprising amount of world knowledge, crucial for NLP tasks such as question answering. However, this knowledge is stored implicitly in the parameters of a neural network, requiring ever-larger networks to cover more facts. To capture knowledge in a more modular and interpretable way, we augment language model pre-training with a latent knowledge retriever, which allows the model to retrieve and attend over documents from a large corpus such as Wikipedia, used during pre-training, fine-tuning and inference. For the first time, we show how to pre-train such a knowledge retriever in an unsupervised manner, using masked language modeling as the learning signal and backpropagating through a retrieval step that considers millions of documents. We demonstrate the effectiveness of Retrieval-Augmented Language Model pre-training (REALM) by fine-tuning on the challenging task of Open-domain Question Answering (Open-QA). We compare against state-of-the-art models for both explicit and implicit knowledge storage on three popular Open-QA benchmarks, and find that we outperform all previous methods by a significant margin (4-16% absolute accuracy), while also providing qualitative benefits such as interpretability and modularity.\nHow Does BERT Answer Questions?: A Layer-Wise Analysis of Transformer Representations (Betty van Aken et al., 2019) Betty van Aken, Benjamin Winter, Alexander Löser, F. Gers. (2019)\nHow Does BERT Answer Questions?: A Layer-Wise Analysis of Transformer Representations\nCIKM\nPaper Link\nInfluential Citation Count (4), SS-ID (8380ab11c120a77cbdd2053337aa52525ec0f22e)\nABSTRACT\nBidirectional Encoder Representations from Transformers (BERT) reach state-of-the-art results in a variety of Natural Language Processing tasks. However, understanding of their internal functioning is still insufficient and unsatisfactory. In order to better understand BERT and other Transformer-based models, we present a layer-wise analysis of BERT\u0026rsquo;s hidden states. Unlike previous research, which mainly focuses on explaining Transformer models by their attention weights, we argue that hidden states contain equally valuable information. Specifically, our analysis focuses on models fine-tuned on the task of Question Answering (QA) as an example of a complex downstream task. We inspect how QA models transform token vectors in order to find the correct answer. To this end, we apply a set of general and QA-specific probing tasks that reveal the information stored in each representation layer. Our qualitative analysis of hidden state visualizations provides additional insights into BERT\u0026rsquo;s reasoning process. Our results show that the transformations within BERT go through phases that are related to traditional pipeline tasks. The system can therefore implicitly incorporate task-specific information into its token representations. Furthermore, our analysis reveals that fine-tuning has little impact on the models\u0026rsquo; semantic abilities and that prediction errors can be recognized in the vector representations of even early layers.\nUniversal Text Representation from BERT: An Empirical Study (Xiaofei Ma et al., 2019) Xiaofei Ma, Zhiguo Wang, Patrick Ng, Ramesh Nallapati, Bing Xiang. (2019)\nUniversal Text Representation from BERT: An Empirical Study\nArXiv\nPaper Link\nInfluential Citation Count (1), SS-ID (850713961a5aa20812cf952f950f09d491fae281)\nABSTRACT\nWe present a systematic investigation of layer-wise BERT activations for general-purpose text representations to understand what linguistic information they capture and how transferable they are across different tasks. Sentence-level embeddings are evaluated against two state-of-the-art models on downstream and probing tasks from SentEval, while passage-level embeddings are evaluated on four question-answering (QA) datasets under a learning-to-rank problem setting. Embeddings from the pre-trained BERT model perform poorly in semantic similarity and sentence surface information probing tasks. Fine-tuning BERT on natural language inference data greatly improves the quality of the embeddings. Combining embeddings from different BERT layers can further boost performance. BERT embeddings outperform BM25 baseline significantly on factoid QA datasets at the passage level, but fail to perform better than BM25 on non-factoid datasets. For all QA datasets, there is a gap between embedding-based method and in-domain fine-tuned BERT (we report new state-of-the-art results on two datasets), which suggests deep interactions between question and answer pairs are critical for those hard tasks.\nTo Tune or Not to Tune? Adapting Pretrained Representations to Diverse Tasks (Matthew E. Peters et al., 2019) Matthew E. Peters, Sebastian Ruder, Noah A. Smith. (2019)\nTo Tune or Not to Tune? Adapting Pretrained Representations to Diverse Tasks\nRepL4NLP@ACL\nPaper Link\nInfluential Citation Count (21), SS-ID (8659bf379ca8756755125a487c43cfe8611ce842)\nABSTRACT\nWhile most previous work has focused on different pretraining objectives and architectures for transfer learning, we ask how to best adapt the pretrained model to a given target task. We focus on the two most common forms of adaptation, feature extraction (where the pretrained weights are frozen), and directly fine-tuning the pretrained model. Our empirical results across diverse NLP tasks with two state-of-the-art models show that the relative performance of fine-tuning vs. feature extraction depends on the similarity of the pretraining and target tasks. We explore possible explanations for this finding and provide a set of adaptation guidelines for the NLP practitioner.\nHow does BERT’s attention change when you fine-tune? An analysis methodology and a case study in negation scope (Yiyun Zhao et al., 2020) Yiyun Zhao, Steven Bethard. (2020)\nHow does BERT’s attention change when you fine-tune? An analysis methodology and a case study in negation scope\nACL\nPaper Link\nInfluential Citation Count (0), SS-ID (868349fe969bc7c6b14b5f35e118a26075b7b1f2)\nABSTRACT\nLarge pretrained language models like BERT, after fine-tuning to a downstream task, have achieved high performance on a variety of NLP problems. Yet explaining their decisions is difficult despite recent work probing their internal representations. We propose a procedure and analysis methods that take a hypothesis of how a transformer-based model might encode a linguistic phenomenon, and test the validity of that hypothesis based on a comparison between knowledge-related downstream tasks with downstream control tasks, and measurement of cross-dataset consistency. We apply this methodology to test BERT and RoBERTa on a hypothesis that some attention heads will consistently attend from a word in negation scope to the negation cue. We find that after fine-tuning BERT and RoBERTa on a negation scope task, the average attention head improves its sensitivity to negation and its attention consistency across negation datasets compared to the pre-trained models. However, only the base models (not the large models) improve compared to a control task, indicating there is evidence for a shallow encoding of negation only in the base models.\nOn the Comparability of Pre-trained Language Models (M. Aßenmacher et al., 2020) M. Aßenmacher, C. Heumann. (2020)\nOn the Comparability of Pre-trained Language Models\nSwissText/KONVENS\nPaper Link\nInfluential Citation Count (0), SS-ID (86bd570007c863c147eb9c13f00fc6908f6b3fc9)\nABSTRACT\nRecent developments in unsupervised representation learning have successfully established the concept of transfer learning in NLP. Mainly three forces are driving the improvements in this area of research: More elaborated architectures are making better use of contextual information. Instead of simply plugging in static pre-trained representations, these are learned based on surrounding context in end-to-end trainable models with more intelligently designed language modelling objectives. Along with this, larger corpora are used as resources for pre-training large language models in a self-supervised fashion which are afterwards fine-tuned on supervised tasks. Advances in parallel computing as well as in cloud computing, made it possible to train these models with growing capacities in the same or even in shorter time than previously established models. These three developments agglomerate in new state-of-the-art (SOTA) results being revealed in a higher and higher frequency. It is not always obvious where these improvements originate from, as it is not possible to completely disentangle the contributions of the three driving forces. We set ourselves to providing a clear and concise overview on several large pre-trained language models, which achieved SOTA results in the last two years, with respect to their use of new architectures and resources. We want to clarify for the reader where the differences between the models are and we furthermore attempt to gain some insight into the single contributions of lexical/computational improvements as well as of architectural changes. We explicitly do not intend to quantify these contributions, but rather see our work as an overview in order to identify potential starting points for benchmark comparisons. Furthermore, we tentatively want to point at potential possibilities for improvement in the field of open-sourcing and reproducible research.\nDistributed Representations of Words and Phrases and their Compositionality (Tomas Mikolov et al., 2013) Tomas Mikolov, Ilya Sutskever, Kai Chen, G. Corrado, J. Dean. (2013)\nDistributed Representations of Words and Phrases and their Compositionality\nNIPS\nPaper Link\nInfluential Citation Count (3587), SS-ID (87f40e6f3022adbc1f1905e3e506abad05a9964f)\nABSTRACT\nThe recently introduced continuous Skip-gram model is an efficient method for learning high-quality distributed vector representations that capture a large number of precise syntactic and semantic word relationships. In this paper we present several extensions that improve both the quality of the vectors and the training speed. By subsampling of the frequent words we obtain significant speedup and also learn more regular word representations. We also describe a simple alternative to the hierarchical softmax called negative sampling. An inherent limitation of word representations is their indifference to word order and their inability to represent idiomatic phrases. For example, the meanings of \u0026ldquo;Canada\u0026rdquo; and \u0026ldquo;Air\u0026rdquo; cannot be easily combined to obtain \u0026ldquo;Air Canada\u0026rdquo;. Motivated by this example, we present a simple method for finding phrases in text, and show that learning good vector representations for millions of phrases is possible.\nHellaSwag: Can a Machine Really Finish Your Sentence? (Rowan Zellers et al., 2019) Rowan Zellers, Ari Holtzman, Yonatan Bisk, Ali Farhadi, Yejin Choi. (2019)\nHellaSwag: Can a Machine Really Finish Your Sentence?\nACL\nPaper Link\nInfluential Citation Count (35), SS-ID (8b0f27bb594b1eaaf493eaf1e2ee723a2b0a19ad)\nABSTRACT\nRecent work by Zellers et al. (2018) introduced a new task of commonsense natural language inference: given an event description such as “A woman sits at a piano,” a machine must select the most likely followup: “She sets her fingers on the keys.” With the introduction of BERT, near human-level performance was reached. Does this mean that machines can perform human level commonsense inference? In this paper, we show that commonsense inference still proves difficult for even state-of-the-art models, by presenting HellaSwag, a new challenge dataset. Though its questions are trivial for humans (\u0026gt;95% accuracy), state-of-the-art models struggle (\u0026lt;48%). We achieve this via Adversarial Filtering (AF), a data collection paradigm wherein a series of discriminators iteratively select an adversarial set of machine-generated wrong answers. AF proves to be surprisingly robust. The key insight is to scale up the length and complexity of the dataset examples towards a critical ‘Goldilocks’ zone wherein generated text is ridiculous to humans, yet often misclassified by state-of-the-art models. Our construction of HellaSwag, and its resulting difficulty, sheds light on the inner workings of deep pretrained models. More broadly, it suggests a new path forward for NLP research, in which benchmarks co-evolve with the evolving state-of-the-art in an adversarial way, so as to present ever-harder challenges.\nQuestionable Answers in Question Answering Research: Reproducibility and Variability of Published Results (M. Crane, 2018) M. Crane. (2018)\nQuestionable Answers in Question Answering Research: Reproducibility and Variability of Published Results\nTACL\nPaper Link\nInfluential Citation Count (5), SS-ID (8c0548331e02c2ead48d6c0380f9a80471ea5d80)\nABSTRACT\n“Based on theoretical reasoning it has been suggested that the reliability of findings published in the scientific literature decreases with the popularity of a research field” (Pfeiffer and Hoffmann, 2009). As we know, deep learning is very popular and the ability to reproduce results is an important part of science. There is growing concern within the deep learning community about the reproducibility of results that are presented. In this paper we present a number of controllable, yet unreported, effects that can substantially change the effectiveness of a sample model, and thusly the reproducibility of those results. Through these environmental effects we show that the commonly held belief that distribution of source code is all that is needed for reproducibility is not enough. Source code without a reproducible environment does not mean anything at all. In addition the range of results produced from these effects can be larger than the majority of incremental improvement reported.\nTransfer Fine-Tuning: A BERT Case Study (Yuki Arase et al., 2019) Yuki Arase, Junichi Tsujii. (2019)\nTransfer Fine-Tuning: A BERT Case Study\nEMNLP\nPaper Link\nInfluential Citation Count (0), SS-ID (8e00d81ff7b1656c621f64fe72fff2356bacb29f)\nABSTRACT\nA semantic equivalence assessment is defined as a task that assesses semantic equivalence in a sentence pair by binary judgment (i.e., paraphrase identification) or grading (i.e., semantic textual similarity measurement). It constitutes a set of tasks crucial for research on natural language understanding. Recently, BERT realized a breakthrough in sentence representation learning (Devlin et al., 2019), which is broadly transferable to various NLP tasks. While BERT’s performance improves by increasing its model size, the required computational power is an obstacle preventing practical applications from adopting the technology. Herein, we propose to inject phrasal paraphrase relations into BERT in order to generate suitable representations for semantic equivalence assessment instead of increasing the model size. Experiments on standard natural language understanding tasks confirm that our method effectively improves a smaller BERT model while maintaining the model size. The generated model exhibits superior performance compared to a larger BERT model on semantic equivalence assessment tasks. Furthermore, it achieves larger performance gains on tasks with limited training datasets for fine-tuning, which is a property desirable for transfer learning.\nAssessing the Benchmarking Capacity of Machine Reading Comprehension Datasets (Saku Sugawara et al., 2019) Saku Sugawara, Pontus Stenetorp, Kentaro Inui, Akiko Aizawa. (2019)\nAssessing the Benchmarking Capacity of Machine Reading Comprehension Datasets\nAAAI\nPaper Link\nInfluential Citation Count (6), SS-ID (9148f4bb8ebdcc75beaddc875d6de857bbe85ba3)\nABSTRACT\nExisting analysis work in machine reading comprehension (MRC) is largely concerned with evaluating the capabilities of systems. However, the capabilities of datasets are not assessed for benchmarking language understanding precisely. We propose a semi-automated, ablation-based methodology for this challenge; By checking whether questions can be solved even after removing features associated with a skill requisite for language understanding, we evaluate to what degree the questions do not require the skill. Experiments on 10 datasets (e.g., CoQA, SQuAD v2.0, and RACE) with a strong baseline model show that, for example, the relative scores of the baseline model provided with content words only and with shuffled sentence words in the context are on average 89.2% and 78.5% of the original scores, respectively. These results suggest that most of the questions already answered correctly by the model do not necessarily require grammatical and complex reasoning. For precise benchmarking, MRC datasets will need to take extra care in their design to ensure that questions can correctly evaluate the intended skills.\nWhen BERT Plays the Lottery, All Tickets Are Winning (Sai Prasanna et al., 2020) Sai Prasanna, Anna Rogers, Anna Rumshisky. (2020)\nWhen BERT Plays the Lottery, All Tickets Are Winning\nEMNLP\nPaper Link\nInfluential Citation Count (7), SS-ID (91ac65431b2dc46919e1673fde67671c29446812)\nABSTRACT\nMuch of the recent success in NLP is due to the large Transformer-based models such as BERT (Devlin et al, 2019). However, these models have been shown to be reducible to a smaller number of self-attention heads and layers. We consider this phenomenon from the perspective of the lottery ticket hypothesis. For fine-tuned BERT, we show that (a) it is possible to find a subnetwork of elements that achieves performance comparable with that of the full model, and (b) similarly-sized subnetworks sampled from the rest of the model perform worse. However, the \u0026ldquo;bad\u0026rdquo; subnetworks can be fine-tuned separately to achieve only slightly worse performance than the \u0026ldquo;good\u0026rdquo; ones, indicating that most weights in the pre-trained BERT are potentially useful. We also show that the \u0026ldquo;good\u0026rdquo; subnetworks vary considerably across GLUE tasks, opening up the possibilities to learn what knowledge BERT actually uses at inference time.\nWell-Read Students Learn Better: The Impact of Student Initialization on Knowledge Distillation (Iulia Turc et al., 2019) Iulia Turc, Ming-Wei Chang, Kenton Lee, Kristina Toutanova. (2019)\nWell-Read Students Learn Better: The Impact of Student Initialization on Knowledge Distillation\nArXiv\nPaper Link\nInfluential Citation Count (18), SS-ID (93ad19fbc85360043988fa9ea7932b7fdf1fa948)\nABSTRACT\nRecent developments in NLP have been accompanied by large, expensive models. Knowledge distillation is the standard method to realize these gains in applications with limited resources: a compact student is trained to recover the outputs of a powerful teacher. While most prior work investigates student architectures and transfer techniques, we focus on an often-neglected aspect\u0026mdash;student initialization. We argue that a random starting point hinders students from fully leveraging the teacher expertise, even in the presence of a large transfer set. We observe that applying language model pre-training to students unlocks their generalization potential, surprisingly even for very compact networks. We conduct experiments on 4 NLP tasks and 24 sizes of Transformer-based students; for sentiment classification on the Amazon Book Reviews dataset, pre-training boosts size reduction and TPU speed-up from 3.1x/1.25x to 31x/16x. Extensive ablation studies dissect the interaction between pre-training and distillation, revealing a compound effect even when they are applied on the same unlabeled dataset.\nGLUE: A Multi-Task Benchmark and Analysis Platform for Natural Language Understanding (Alex Wang et al., 2018) Alex Wang, Amanpreet Singh, Julian Michael, Felix Hill, Omer Levy, Samuel R. Bowman. (2018)\nGLUE: A Multi-Task Benchmark and Analysis Platform for Natural Language Understanding\nBlackboxNLP@EMNLP\nPaper Link\nInfluential Citation Count (625), SS-ID (93b8da28d006415866bf48f9a6e06b5242129195)\nABSTRACT\nHuman ability to understand language is general, flexible, and robust. In contrast, most NLU models above the word level are designed for a specific task and struggle with out-of-domain data. If we aspire to develop models with understanding beyond the detection of superficial correspondences between inputs and outputs, then it is critical to develop a unified model that can execute a range of linguistic tasks across different domains. To facilitate research in this direction, we present the General Language Understanding Evaluation (GLUE, gluebenchmark.com): a benchmark of nine diverse NLU tasks, an auxiliary dataset for probing models for understanding of specific linguistic phenomena, and an online platform for evaluating and comparing models. For some benchmark tasks, training data is plentiful, but for others it is limited or does not match the genre of the test set. GLUE thus favors models that can represent linguistic knowledge in a way that facilitates sample-efficient learning and effective knowledge-transfer across tasks. While none of the datasets in GLUE were created from scratch for the benchmark, four of them feature privately-held test data, which is used to ensure that the benchmark is used fairly. We evaluate baselines that use ELMo (Peters et al., 2018), a powerful transfer learning technique, as well as state-of-the-art sentence representation models. The best models still achieve fairly low absolute scores. Analysis with our diagnostic dataset yields similarly weak performance over all phenomena tested, with some exceptions.\nAn Analysis of Encoder Representations in Transformer-Based Machine Translation (Alessandro Raganato et al., 2018) Alessandro Raganato, J. Tiedemann. (2018)\nAn Analysis of Encoder Representations in Transformer-Based Machine Translation\nBlackboxNLP@EMNLP\nPaper Link\nInfluential Citation Count (10), SS-ID (94238dead40b12735d79ed63e29ead70730261a2)\nABSTRACT\nThe attention mechanism is a successful technique in modern NLP, especially in tasks like machine translation. The recently proposed network architecture of the Transformer is based entirely on attention mechanisms and achieves new state of the art results in neural machine translation, outperforming other sequence-to-sequence models. However, so far not much is known about the internal properties of the model and the representations it learns to achieve that performance. To study this question, we investigate the information that is learned by the attention mechanism in Transformer models with different translation quality. We assess the representations of the encoder by extracting dependency relations based on self-attention weights, we perform four probing tasks to study the amount of syntactic and semantic captured information and we also test attention in a transfer learning scenario. Our analysis sheds light on the relative strengths and weaknesses of the various encoder representations. We observe that specific attention heads mark syntactic dependency relations and we can also confirm that lower layers tend to learn more about syntax while higher layers tend to encode more semantics.\nKnowledge Distillation from Internal Representations (Gustavo Aguilar et al., 2019) Gustavo Aguilar, Yuan Ling, Y. Zhang, Benjamin Yao, Xing Fan, Edward Guo. (2019)\nKnowledge Distillation from Internal Representations\nAAAI\nPaper Link\nInfluential Citation Count (4), SS-ID (944e7b64903bde89bfea433203d5a0e774cff354)\nABSTRACT\nKnowledge distillation is typically conducted by training a small model (the student) to mimic a large and cumbersome model (the teacher). The idea is to compress the knowledge from the teacher by using its output probabilities as soft-labels to optimize the student. However, when the teacher is considerably large, there is no guarantee that the internal knowledge of the teacher will be transferred into the student; even if the student closely matches the soft-labels, its internal representations may be considerably different. This internal mismatch can undermine the generalization capabilities originally intended to be transferred from the teacher to the student. In this paper, we propose to distill the internal representations of a large model such as BERT into a simplified version of it. We formulate two ways to distill such representations and various algorithms to conduct the distillation. We experiment with datasets from the GLUE benchmark and consistently show that adding knowledge distillation from internal representations is a more powerful method than only using soft-label distillation.\nPoWER-BERT: Accelerating BERT Inference via Progressive Word-vector Elimination (Saurabh Goyal et al., 2020) Saurabh Goyal, Anamitra R. Choudhury, S. Raje, Venkatesan T. Chakaravarthy, Yogish Sabharwal, Ashish Verma. (2020)\nPoWER-BERT: Accelerating BERT Inference via Progressive Word-vector Elimination\nICML\nPaper Link\nInfluential Citation Count (13), SS-ID (94f94e8892261d0377159379ca5a166ceae19a14)\nABSTRACT\nWe develop a novel method, called PoWER-BERT, for improving the inference time of the popular BERT model, while maintaining the accuracy. It works by: a) exploiting redundancy pertaining to word-vectors (intermediate encoder outputs) and eliminating the redundant vectors. b) determining which word-vectors to eliminate by developing a strategy for measuring their significance, based on the self-attention mechanism. c) learning how many word-vectors to eliminate by augmenting the BERT model and the loss function. Experiments on the standard GLUE benchmark shows that PoWER-BERT achieves up to 4.5x reduction in inference time over BERT with \u0026lt;1% loss in accuracy. We show that PoWER-BERT offers significantly better trade-off between accuracy and inference time compared to prior methods. We demonstrate that our method attains up to 6.8x reduction in inference time with \u0026lt;1% loss in accuracy when applied over ALBERT, a highly compressed version of BERT. The code for PoWER-BERT is publicly available at this https URL.\nWhat Does BERT Look at? An Analysis of BERT’s Attention (Kevin Clark et al., 2019) Kevin Clark, Urvashi Khandelwal, Omer Levy, Christopher D. Manning. (2019)\nWhat Does BERT Look at? An Analysis of BERT’s Attention\nBlackboxNLP@ACL\nPaper Link\nInfluential Citation Count (74), SS-ID (95a251513853c6032bdecebd4b74e15795662986)\nABSTRACT\nLarge pre-trained neural networks such as BERT have had great recent success in NLP, motivating a growing body of research investigating what aspects of language they are able to learn from unlabeled data. Most recent analysis has focused on model outputs (e.g., language model surprisal) or internal vector representations (e.g., probing classifiers). Complementary to these works, we propose methods for analyzing the attention mechanisms of pre-trained models and apply them to BERT. BERT’s attention heads exhibit patterns such as attending to delimiter tokens, specific positional offsets, or broadly attending over the whole sentence, with heads in the same layer often exhibiting similar behaviors. We further show that certain attention heads correspond well to linguistic notions of syntax and coreference. For example, we find heads that attend to the direct objects of verbs, determiners of nouns, objects of prepositions, and coreferent mentions with remarkably high accuracy. Lastly, we propose an attention-based probing classifier and use it to further demonstrate that substantial syntactic information is captured in BERT’s attention.\nBERT Rediscovers the Classical NLP Pipeline (Ian Tenney et al., 2019) Ian Tenney, Dipanjan Das, Ellie Pavlick. (2019)\nBERT Rediscovers the Classical NLP Pipeline\nACL\nPaper Link\nInfluential Citation Count (59), SS-ID (97906df07855b029b7aae7c2a1c6c5e8df1d531c)\nABSTRACT\nPre-trained text encoders have rapidly advanced the state of the art on many NLP tasks. We focus on one such model, BERT, and aim to quantify where linguistic information is captured within the network. We find that the model represents the steps of the traditional NLP pipeline in an interpretable and localizable way, and that the regions responsible for each step appear in the expected sequence: POS tagging, parsing, NER, semantic roles, then coreference. Qualitative analysis reveals that the model can and often does adjust this pipeline dynamically, revising lower-level decisions on the basis of disambiguating information from higher-level representations.\nContextual and Non-Contextual Word Embeddings: an in-depth Linguistic Investigation (Alessio Miaschi et al., 2020) Alessio Miaschi, F. Dell’Orletta. (2020)\nContextual and Non-Contextual Word Embeddings: an in-depth Linguistic Investigation\nREPL4NLP\nPaper Link\nInfluential Citation Count (0), SS-ID (9b1933038680b13c06b60dfe810e96a3a0ef9d37)\nABSTRACT\nIn this paper we present a comparison between the linguistic knowledge encoded in the internal representations of a contextual Language Model (BERT) and a contextual-independent one (Word2vec). We use a wide set of probing tasks, each of which corresponds to a distinct sentence-level feature extracted from different levels of linguistic annotation. We show that, although BERT is capable of understanding the full context of each word in an input sequence, the implicit knowledge encoded in its aggregated sentence representations is still comparable to that of a contextual-independent model. We also find that BERT is able to encode sentence-level properties even within single-word embeddings, obtaining comparable or even superior results than those obtained with sentence representations.\nA Cross-Task Analysis of Text Span Representations (Shubham Toshniwal et al., 2020) Shubham Toshniwal, Haoyue Shi, Bowen Shi, Lingyu Gao, Karen Livescu, Kevin Gimpel. (2020)\nA Cross-Task Analysis of Text Span Representations\nREPL4NLP\nPaper Link\nInfluential Citation Count (0), SS-ID (9b2b96adf4ec05b086037222a893fa778f83a985)\nABSTRACT\nMany natural language processing (NLP) tasks involve reasoning with textual spans, including question answering, entity recognition, and coreference resolution. While extensive research has focused on functional architectures for representing words and sentences, there is less work on representing arbitrary spans of text within sentences. In this paper, we conduct a comprehensive empirical evaluation of six span representation methods using eight pretrained language representation models across six tasks, including two tasks that we introduce. We find that, although some simple span representations are fairly reliable across tasks, in general the optimal span representation varies by task, and can also vary within different facets of individual tasks. We also find that the choice of span representation has a bigger impact with a fixed pretrained encoder than with a fine-tuned encoder.\nHow Contextual are Contextualized Word Representations? Comparing the Geometry of BERT, ELMo, and GPT-2 Embeddings (Kawin Ethayarajh, 2019) Kawin Ethayarajh. (2019)\nHow Contextual are Contextualized Word Representations? Comparing the Geometry of BERT, ELMo, and GPT-2 Embeddings\nEMNLP\nPaper Link\nInfluential Citation Count (29), SS-ID (9d7902e834d5d1d35179962c7a5b9d16623b0d39)\nABSTRACT\nReplacing static word embeddings with contextualized word representations has yielded significant improvements on many NLP tasks. However, just how contextual are the contextualized representations produced by models such as ELMo and BERT? Are there infinitely many context-specific representations for each word, or are words essentially assigned one of a finite number of word-sense representations? For one, we find that the contextualized representations of all words are not isotropic in any layer of the contextualizing model. While representations of the same word in different contexts still have a greater cosine similarity than those of two different words, this self-similarity is much lower in upper layers. This suggests that upper layers of contextualizing models produce more context-specific representations, much like how upper layers of LSTMs produce more task-specific representations. In all layers of ELMo, BERT, and GPT-2, on average, less than 5% of the variance in a word’s contextualized representations can be explained by a static embedding for that word, providing some justification for the success of contextualized representations.\nOn Identifiability in Transformers (Gino Brunner et al., 2019) Gino Brunner, Yang Liu, Damian Pascual, Oliver Richter, Massimiliano Ciaramita, Roger Wattenhofer. (2019)\nOn Identifiability in Transformers\nICLR\nPaper Link\nInfluential Citation Count (13), SS-ID (9d7fbdb2e9817a6396992a1c92f75206689852d9)\nABSTRACT\nIn this paper we delve deep in the Transformer architecture by investigating two of its core components: self-attention and contextual embeddings. In particular, we study the identifiability of attention weights and token embeddings, and the aggregation of context into hidden tokens. We show that, for sequences longer than the attention head dimension, attention weights are not identifiable. We propose effective attention as a complementary tool for improving explanatory interpretations based on attention. Furthermore, we show that input tokens retain to a large degree their identity across the model. We also find evidence suggesting that identity information is mainly encoded in the angle of the embeddings and gradually decreases with depth. Finally, we demonstrate strong mixing of input information in the generation of contextual embeddings by means of a novel quantification method based on gradient attribution. Overall, we show that self-attention distributions are not directly interpretable and present tools to better understand and further investigate Transformer models.\nProducts of Random Latent Variable Grammars (Slav Petrov, 2010) Slav Petrov. (2010)\nProducts of Random Latent Variable Grammars\nNAACL\nPaper Link\nInfluential Citation Count (10), SS-ID (9dccaf6ea0fa19772cf8067295b16df3eb7b4dda)\nABSTRACT\nWe show that the automatically induced latent variable grammars of Petrov et al. (2006) vary widely in their underlying representations, depending on their EM initialization point. We use this to our advantage, combining multiple automatically learned grammars into an unweighted product model, which gives significantly improved performance over state-of-the-art individual grammars. In our model, the probability of a constituent is estimated as a product of posteriors obtained from multiple grammars that differ only in the random seed used for initialization, without any learning or tuning of combination weights. Despite its simplicity, a product of eight automatically learned grammars improves parsing accuracy from 90.2% to 91.8% on English, and from 80.3% to 84.5% on German.\nIntermediate-Task Transfer Learning with Pretrained Language Models: When and Why Does It Work? (Yada Pruksachatkun et al., 2020) Yada Pruksachatkun, Jason Phang, Haokun Liu, Phu Mon Htut, Xiaoyi Zhang, Richard Yuanzhe Pang, Clara Vania, Katharina Kann, Samuel R. Bowman. (2020)\nIntermediate-Task Transfer Learning with Pretrained Language Models: When and Why Does It Work?\nACL\nPaper Link\nInfluential Citation Count (7), SS-ID (9e594ae4ae9c38b6495810a8872f513ae19be29c)\nABSTRACT\nWhile pretrained models such as BERT have shown large gains across natural language understanding tasks, their performance can be improved by further training the model on a data-rich intermediate task, before fine-tuning it on a target task. However, it is still poorly understood when and why intermediate-task training is beneficial for a given target task. To investigate this, we perform a large-scale study on the pretrained RoBERTa model with 110 intermediate-target task combinations. We further evaluate all trained models with 25 probing tasks meant to reveal the specific skills that drive transfer. We observe that intermediate tasks requiring high-level inference and reasoning abilities tend to work best. We also observe that target task performance is strongly correlated with higher-level abilities such as coreference resolution. However, we fail to observe more granular correlations between probing and target task performance, highlighting the need for further work on broad-coverage probing benchmarks. We also observe evidence that the forgetting of knowledge learned during pretraining may limit our analysis, highlighting the need for further work on transfer learning methods in these settings.\nOn the Cross-lingual Transferability of Monolingual Representations (Mikel Artetxe et al., 2019) Mikel Artetxe, Sebastian Ruder, Dani Yogatama. (2019)\nOn the Cross-lingual Transferability of Monolingual Representations\nACL\nPaper Link\nInfluential Citation Count (68), SS-ID (9e9d919c1de684ca42c8b581ec62c7aa685f431e)\nABSTRACT\nState-of-the-art unsupervised multilingual models (e.g., multilingual BERT) have been shown to generalize in a zero-shot cross-lingual setting. This generalization ability has been attributed to the use of a shared subword vocabulary and joint training across multiple languages giving rise to deep multilingual abstractions. We evaluate this hypothesis by designing an alternative approach that transfers a monolingual model to new languages at the lexical level. More concretely, we first train a transformer-based masked language model on one language, and transfer it to a new language by learning a new embedding matrix with the same masked language modeling objective, freezing parameters of all other layers. This approach does not rely on a shared vocabulary or joint training. However, we show that it is competitive with multilingual BERT on standard cross-lingual classification benchmarks and on a new Cross-lingual Question Answering Dataset (XQuAD). Our results contradict common beliefs of the basis of the generalization ability of multilingual models and suggest that deep monolingual models learn some abstractions that generalize across languages. We also release XQuAD as a more comprehensive cross-lingual benchmark, which comprises 240 paragraphs and 1190 question-answer pairs from SQuAD v1.1 translated into ten languages by professional translators.\nBERT is Not an Interlingua and the Bias of Tokenization (Jasdeep Singh et al., 2019) Jasdeep Singh, Bryan McCann, R. Socher, Caiming Xiong. (2019)\nBERT is Not an Interlingua and the Bias of Tokenization\nEMNLP\nPaper Link\nInfluential Citation Count (8), SS-ID (9eb4cd1a4b4717c97c47e3dc4563a75779ae9390)\nABSTRACT\nMultilingual transfer learning can benefit both high- and low-resource languages, but the source of these improvements is not well understood. Cananical Correlation Analysis (CCA) of the internal representations of a pre- trained, multilingual BERT model reveals that the model partitions representations for each language rather than using a common, shared, interlingual space. This effect is magnified at deeper layers, suggesting that the model does not progressively abstract semantic con- tent while disregarding languages. Hierarchical clustering based on the CCA similarity scores between languages reveals a tree structure that mirrors the phylogenetic trees hand- designed by linguists. The subword tokenization employed by BERT provides a stronger bias towards such structure than character- and word-level tokenizations. We release a subset of the XNLI dataset translated into an additional 14 languages at https://www.github.com/salesforce/xnli_extension to assist further research into multilingual representations.\nCloze-driven Pretraining of Self-attention Networks (Alexei Baevski et al., 2019) Alexei Baevski, Sergey Edunov, Yinhan Liu, Luke Zettlemoyer, Michael Auli. (2019)\nCloze-driven Pretraining of Self-attention Networks\nEMNLP\nPaper Link\nInfluential Citation Count (14), SS-ID (9f1c5777a193b2c3bb2b25e248a156348e5ba56d)\nABSTRACT\nWe present a new approach for pretraining a bi-directional transformer model that provides significant performance gains across a variety of language understanding problems. Our model solves a cloze-style word reconstruction task, where each word is ablated and must be predicted given the rest of the text. Experiments demonstrate large performance gains on GLUE and new state of the art results on NER as well as constituency parsing benchmarks, consistent with BERT. We also present a detailed analysis of a number of factors that contribute to effective pretraining, including data domain and size, model capacity, and variations on the cloze objective.\nBERTRAM: Improved Word Embeddings Have Big Impact on Contextualized Model Performance (Timo Schick et al., 2019) Timo Schick, Hinrich Schütze. (2019)\nBERTRAM: Improved Word Embeddings Have Big Impact on Contextualized Model Performance\nACL\nPaper Link\nInfluential Citation Count (3), SS-ID (9f4c37f154946e141a67ae2816c70b19241b3224)\nABSTRACT\nPretraining deep language models has led to large performance gains in NLP. Despite this success, Schick and Schütze (2020) recently showed that these models struggle to understand rare words. For static word embeddings, this problem has been addressed by separately learning representations for rare words. In this work, we transfer this idea to pretrained language models: We introduce BERTRAM, a powerful architecture based on BERT that is capable of inferring high-quality embeddings for rare words that are suitable as input representations for deep language models. This is achieved by enabling the surface form and contexts of a word to interact with each other in a deep architecture. Integrating BERTRAM into BERT leads to large performance increases due to improved representations of rare and medium frequency words on both a rare word probing task and three downstream tasks.\nAnalyzing the Structure of Attention in a Transformer Language Model (Jesse Vig et al., 2019) Jesse Vig, Y. Belinkov. (2019)\nAnalyzing the Structure of Attention in a Transformer Language Model\nBlackboxNLP@ACL\nPaper Link\nInfluential Citation Count (8), SS-ID (a039ea239e37f53a2cb60c68e0a1967994353166)\nABSTRACT\nThe Transformer is a fully attention-based alternative to recurrent networks that has achieved state-of-the-art results across a range of NLP tasks. In this paper, we analyze the structure of attention in a Transformer language model, the GPT-2 small pretrained model. We visualize attention for individual instances and analyze the interaction between attention and syntax over a large corpus. We find that attention targets different parts of speech at different layer depths within the model, and that attention aligns with dependency relations most strongly in the middle layers. We also find that the deepest layers of the model capture the most distant relationships. Finally, we extract exemplar sentences that reveal highly specific patterns targeted by particular attention heads.\nDistilling Task-Specific Knowledge from BERT into Simple Neural Networks (Raphael Tang et al., 2019) Raphael Tang, Yao Lu, Linqing Liu, Lili Mou, Olga Vechtomova, Jimmy J. Lin. (2019)\nDistilling Task-Specific Knowledge from BERT into Simple Neural Networks\nArXiv\nPaper Link\nInfluential Citation Count (26), SS-ID (a08293b2c9c5bcddb023cc7eb3354d4d86bfae89)\nABSTRACT\nIn the natural language processing literature, neural networks are becoming increasingly deeper and complex. The recent poster child of this trend is the deep language representation model, which includes BERT, ELMo, and GPT. These developments have led to the conviction that previous-generation, shallower neural networks for language understanding are obsolete. In this paper, however, we demonstrate that rudimentary, lightweight neural networks can still be made competitive without architecture changes, external training data, or additional input features. We propose to distill knowledge from BERT, a state-of-the-art language representation model, into a single-layer BiLSTM, as well as its siamese counterpart for sentence-pair tasks. Across multiple datasets in paraphrasing, natural language inference, and sentiment classification, we achieve comparable results with ELMo, while using roughly 100 times fewer parameters and 15 times less inference time.\nWhat BERT Is Not: Lessons from a New Suite of Psycholinguistic Diagnostics for Language Models (Allyson Ettinger, 2019) Allyson Ettinger. (2019)\nWhat BERT Is Not: Lessons from a New Suite of Psycholinguistic Diagnostics for Language Models\nTACL\nPaper Link\nInfluential Citation Count (10), SS-ID (a0e49f65b6847437f262c59d0d399255101d0b75)\nABSTRACT\nPre-training by language modeling has become a popular and successful approach to NLP tasks, but we have yet to understand exactly what linguistic capacities these pre-training processes confer upon models. In this paper we introduce a suite of diagnostics drawn from human language experiments, which allow us to ask targeted questions about information used by language models for generating predictions in context. As a case study, we apply these diagnostics to the popular BERT model, finding that it can generally distinguish good from bad completions involving shared category or role reversal, albeit with less sensitivity than humans, and it robustly retrieves noun hypernyms, but it struggles with challenging inference and role-based event prediction— and, in particular, it shows clear insensitivity to the contextual impacts of negation.\nA Matter of Framing: The Impact of Linguistic Formalism on Probing Results (Ilia Kuznetsov et al., 2020) Ilia Kuznetsov, Iryna Gurevych. (2020)\nA Matter of Framing: The Impact of Linguistic Formalism on Probing Results\nEMNLP\nPaper Link\nInfluential Citation Count (0), SS-ID (a160dbe78b0546679ec8a3140b3cf4614e3cc485)\nABSTRACT\nDeep pre-trained contextualized encoders like BERT (Delvin et al., 2019) demonstrate remarkable performance on a range of downstream tasks. A recent line of research in probing investigates the linguistic knowledge implicitly learned by these models during pre-training. While most work in probing operates on the task level, linguistic tasks are rarely uniform and can be represented in a variety of formalisms. Any linguistics-based probing study thereby inevitably commits to the formalism used to annotate the underlying data. Can the choice of formalism affect probing results? To investigate, we conduct an in-depth cross-formalism layer probing study in role semantics. We find linguistically meaningful differences in the encoding of semantic role- and proto-role information by BERT depending on the formalism and demonstrate that layer probing can detect subtle differences between the implementations of the same linguistic formalism. Our results suggest that linguistic formalism is an important dimension in probing studies, along with the commonly used cross-task and cross-lingual experimental settings.\nAll-but-the-Top: Simple and Effective Postprocessing for Word Representations (Jiaqi Mu et al., 2017) Jiaqi Mu, S. Bhat, P. Viswanath. (2017)\nAll-but-the-Top: Simple and Effective Postprocessing for Word Representations\nICLR\nPaper Link\nInfluential Citation Count (30), SS-ID (a2d407962bb1f5fcd209114f5687d4c11bf9dfad)\nABSTRACT\nReal-valued word representations have transformed NLP applications; popular examples are word2vec and GloVe, recognized for their ability to capture linguistic regularities. In this paper, we demonstrate a {\\em very simple}, and yet counter-intuitive, postprocessing technique \u0026ndash; eliminate the common mean vector and a few top dominating directions from the word vectors \u0026ndash; that renders off-the-shelf representations {\\em even stronger}. The postprocessing is empirically validated on a variety of lexical-level intrinsic tasks (word similarity, concept categorization, word analogy) and sentence-level tasks (semantic textural similarity and { text classification}) on multiple datasets and with a variety of representation methods and hyperparameter choices in multiple languages; in each case, the processed representations are consistently better than the original ones.\nPERL: Pivot-based Domain Adaptation for Pre-trained Deep Contextualized Embedding Models (Eyal Ben-David et al., 2020) Eyal Ben-David, Carmel Rabinovitz, Roi Reichart. (2020)\nPERL: Pivot-based Domain Adaptation for Pre-trained Deep Contextualized Embedding Models\nTransactions of the Association for Computational Linguistics\nPaper Link\nInfluential Citation Count (4), SS-ID (a33b09d1a41db92ca14185a28f9163056ca2a115)\nABSTRACT\nAbstract Pivot-based neural representation models have led to significant progress in domain adaptation for NLP. However, previous research following this approach utilize only labeled data from the source domain and unlabeled data from the source and target domains, but neglect to incorporate massive unlabeled corpora that are not necessarily drawn from these domains. To alleviate this, we propose PERL: A representation learning model that extends contextualized word embedding models such as BERT (Devlin et al., 2019) with pivot-based fine-tuning. PERL outperforms strong baselines across 22 sentiment classification domain adaptation setups, improves in-domain model performance, yields effective reduced-size models, and increases model stability.1\nDistilBERT, a distilled version of BERT: smaller, faster, cheaper and lighter (Victor Sanh et al., 2019) Victor Sanh, Lysandre Debut, Julien Chaumond, Thomas Wolf. (2019)\nDistilBERT, a distilled version of BERT: smaller, faster, cheaper and lighter\nArXiv\nPaper Link\nInfluential Citation Count (417), SS-ID (a54b56af24bb4873ed0163b77df63b92bd018ddc)\nABSTRACT\nAs Transfer Learning from large-scale pre-trained models becomes more prevalent in Natural Language Processing (NLP), operating these large models in on-the-edge and/or under constrained computational training or inference budgets remains challenging. In this work, we propose a method to pre-train a smaller general-purpose language representation model, called DistilBERT, which can then be fine-tuned with good performances on a wide range of tasks like its larger counterparts. While most prior work investigated the use of distillation for building task-specific models, we leverage knowledge distillation during the pre-training phase and show that it is possible to reduce the size of a BERT model by 40%, while retaining 97% of its language understanding capabilities and being 60% faster. To leverage the inductive biases learned by larger models during pre-training, we introduce a triple loss combining language modeling, distillation and cosine-distance losses. Our smaller, faster and lighter model is cheaper to pre-train and we demonstrate its capabilities for on-device computations in a proof-of-concept experiment and a comparative on-device study.\nTaBERT: Pretraining for Joint Understanding of Textual and Tabular Data (Pengcheng Yin et al., 2020) Pengcheng Yin, Graham Neubig, Wen-tau Yih, Sebastian Riedel. (2020)\nTaBERT: Pretraining for Joint Understanding of Textual and Tabular Data\nACL\nPaper Link\nInfluential Citation Count (30), SS-ID (a5b1d1cab073cb746a990b37d42dc7b67763f881)\nABSTRACT\nRecent years have witnessed the burgeoning of pretrained language models (LMs) for text-based natural language (NL) understanding tasks. Such models are typically trained on free-form NL text, hence may not be suitable for tasks like semantic parsing over structured data, which require reasoning over both free-form NL questions and structured tabular data (e.g., database tables). In this paper we present TaBERT, a pretrained LM that jointly learns representations for NL sentences and (semi-)structured tables. TaBERT is trained on a large corpus of 26 million tables and their English contexts. In experiments, neural semantic parsers using TaBERT as feature representation layers achieve new best results on the challenging weakly-supervised semantic parsing benchmark WikiTableQuestions, while performing competitively on the text-to-SQL dataset Spider.\nGetting Closer to AI Complete Question Answering: A Set of Prerequisite Real Tasks (Anna Rogers et al., 2020) Anna Rogers, Olga Kovaleva, Matthew Downey, Anna Rumshisky. (2020)\nGetting Closer to AI Complete Question Answering: A Set of Prerequisite Real Tasks\nAAAI\nPaper Link\nInfluential Citation Count (7), SS-ID (a87f0bac2ed58e8a79d33d0c1cf81c6407cd645f)\nABSTRACT\nThe recent explosion in question answering research produced a wealth of both factoid reading comprehension (RC) and commonsense reasoning datasets. Combining them presents a different kind of task: deciding not simply whether information is present in the text, but also whether a confident guess could be made for the missing information. We present QuAIL, the first RC dataset to combine text-based, world knowledge and unanswerable questions, and to provide question type annotation that would enable diagnostics of the reasoning strategies by a given QA system. QuAIL contains 15K multi-choice questions for 800 texts in 4 domains. Crucially, it offers both general and text-specific questions, unlikely to be found in pretraining data. We show that QuAIL poses substantial challenges to the current state-of-the-art systems, with a 30% drop in accuracy compared to the most similar existing dataset.\nSMART: Robust and Efficient Fine-Tuning for Pre-trained Natural Language Models through Principled Regularized Optimization (Haoming Jiang et al., 2019) Haoming Jiang, Pengcheng He, Weizhu Chen, Xiaodong Liu, Jianfeng Gao, T. Zhao. (2019)\nSMART: Robust and Efficient Fine-Tuning for Pre-trained Natural Language Models through Principled Regularized Optimization\nACL\nPaper Link\nInfluential Citation Count (24), SS-ID (ab70853cd5912c470f6ff95e95481980f0a2a41b)\nABSTRACT\nTransfer learning has fundamentally changed the landscape of natural language processing (NLP). Many state-of-the-art models are first pre-trained on a large text corpus and then fine-tuned on downstream tasks. However, due to limited data resources from downstream tasks and the extremely high complexity of pre-trained models, aggressive fine-tuning often causes the fine-tuned model to overfit the training data of downstream tasks and fail to generalize to unseen data. To address such an issue in a principled manner, we propose a new learning framework for robust and efficient fine-tuning for pre-trained models to attain better generalization performance. The proposed framework contains two important ingredients: 1. Smoothness-inducing regularization, which effectively manages the complexity of the model; 2. Bregman proximal point optimization, which is an instance of trust-region methods and can prevent aggressive updating. Our experiments show that the proposed framework achieves new state-of-the-art performance on a number of NLP tasks including GLUE, SNLI, SciTail and ANLI. Moreover, it also outperforms the state-of-the-art T5 model, which is the largest pre-trained model containing 11 billion parameters, on GLUE.\nThieves on Sesame Street! Model Extraction of BERT-based APIs (Kalpesh Krishna et al., 2019) Kalpesh Krishna, Gaurav Singh Tomar, Ankur P. Parikh, Nicolas Papernot, Mohit Iyyer. (2019)\nThieves on Sesame Street! Model Extraction of BERT-based APIs\nICLR\nPaper Link\nInfluential Citation Count (15), SS-ID (ac713aebdcc06f15f8ea61e1140bb360341fdf27)\nABSTRACT\nWe study the problem of model extraction in natural language processing, in which an adversary with only query access to a victim model attempts to reconstruct a local copy of that model. Assuming that both the adversary and victim model fine-tune a large pretrained language model such as BERT (Devlin et al. 2019), we show that the adversary does not need any real training data to successfully mount the attack. In fact, the attacker need not even use grammatical or semantically meaningful queries: we show that random sequences of words coupled with task-specific heuristics form effective queries for model extraction on a diverse set of NLP tasks, including natural language inference and question answering. Our work thus highlights an exploit only made feasible by the shift towards transfer learning methods within the NLP community: for a query budget of a few hundred dollars, an attacker can extract a model that performs only slightly worse than the victim model. Finally, we study two defense strategies against model extraction\u0026mdash;membership classification and API watermarking\u0026mdash;which while successful against naive adversaries, are ineffective against more sophisticated ones.\nIs BERT Really Robust? A Strong Baseline for Natural Language Attack on Text Classification and Entailment (Di Jin et al., 2019) Di Jin, Zhijing Jin, Joey Tianyi Zhou, Peter Szolovits. (2019)\nIs BERT Really Robust? A Strong Baseline for Natural Language Attack on Text Classification and Entailment\nAAAI\nPaper Link\nInfluential Citation Count (68), SS-ID (ae04f3d011511ad8ed7ffdf9fcfb7f11e6899ca2)\nABSTRACT\nMachine learning algorithms are often vulnerable to adversarial examples that have imperceptible alterations from the original counterparts but can fool the state-of-the-art models. It is helpful to evaluate or even improve the robustness of these models by exposing the maliciously crafted adversarial examples. In this paper, we present TextFooler, a simple but strong baseline to generate adversarial text. By applying it to two fundamental natural language tasks, text classification and textual entailment, we successfully attacked three target models, including the powerful pre-trained BERT, and the widely used convolutional and recurrent neural networks. We demonstrate three advantages of this framework: (1) effective—it outperforms previous attacks by success rate and perturbation rate, (2) utility-preserving—it preserves semantic content, grammaticality, and correct types classified by humans, and (3) efficient—it generates adversarial text with computational complexity linear to the text length.1\nAre Sixteen Heads Really Better than One? (Paul Michel et al., 2019) Paul Michel, Omer Levy, Graham Neubig. (2019)\nAre Sixteen Heads Really Better than One?\nNeurIPS\nPaper Link\nInfluential Citation Count (49), SS-ID (b03c7ff961822183bab66b2e594415e585d3fd09)\nABSTRACT\nAttention is a powerful and ubiquitous mechanism for allowing neural models to focus on particular salient pieces of information by taking their weighted average when making predictions. In particular, multi-headed attention is a driving force behind many recent state-of-the-art NLP models such as Transformer-based MT models and BERT. These models apply multiple attention mechanisms in parallel, with each attention \u0026ldquo;head\u0026rdquo; potentially focusing on different parts of the input, which makes it possible to express sophisticated functions beyond the simple weighted average. In this paper we make the surprising observation that even if models have been trained using multiple heads, in practice, a large percentage of attention heads can be removed at test time without significantly impacting performance. In fact, some layers can even be reduced to a single head. We further examine greedy algorithms for pruning down models, and the potential speed, memory efficiency, and accuracy improvements obtainable therefrom. Finally, we analyze the results with respect to which parts of the model are more reliant on having multiple heads, and provide precursory evidence that training dynamics play a role in the gains provided by multi-head attention.\nA Mutual Information Maximization Perspective of Language Representation Learning (Lingpeng Kong et al., 2019) Lingpeng Kong, Cyprien de Masson d\u0026rsquo;Autume, Wang Ling, Lei Yu, Zihang Dai, Dani Yogatama. (2019)\nA Mutual Information Maximization Perspective of Language Representation Learning\nICLR\nPaper Link\nInfluential Citation Count (11), SS-ID (b04889922aae7f799affb2ae6508bc5f5c989567)\nABSTRACT\nWe show state-of-the-art word representation learning methods maximize an objective function that is a lower bound on the mutual information between different parts of a word sequence (i.e., a sentence). Our formulation provides an alternative perspective that unifies classical word embedding models (e.g., Skip-gram) and modern contextual embeddings (e.g., BERT, XLNet). In addition to enhancing our theoretical understanding of these methods, our derivation leads to a principled framework that can be used to construct new self-supervised tasks. We provide an example by drawing inspirations from related methods based on mutual information maximization that have been successful in computer vision, and introduce a simple self-supervised objective that maximizes the mutual information between a global sentence representation and n-grams in the sentence. Our analysis offers a holistic view of representation learning methods to transfer knowledge and translate progress across multiple domains (e.g., natural language processing, computer vision, audio processing).\nSentence Encoders on STILTs: Supplementary Training on Intermediate Labeled-data Tasks (Jason Phang et al., 2018) Jason Phang, Thibault Févry, Samuel R. Bowman. (2018)\nSentence Encoders on STILTs: Supplementary Training on Intermediate Labeled-data Tasks\nArXiv\nPaper Link\nInfluential Citation Count (38), SS-ID (b47381e04739ea3f392ba6c8faaf64105493c196)\nABSTRACT\nPretraining sentence encoders with language modeling and related unsupervised tasks has recently been shown to be very effective for language understanding tasks. By supplementing language model-style pretraining with further training on data-rich supervised tasks, such as natural language inference, we obtain additional performance improvements on the GLUE benchmark. Applying supplementary training on BERT (Devlin et al., 2018), we attain a GLUE score of 81.8\u0026mdash;the state of the art (as of 02/24/2019) and a 1.4 point improvement over BERT. We also observe reduced variance across random restarts in this setting. Our approach yields similar improvements when applied to ELMo (Peters et al., 2018a) and Radford et al. (2018)\u0026rsquo;s model. In addition, the benefits of supplementary training are particularly pronounced in data-constrained regimes, as we show in experiments with artificially limited training data.\nDo Attention Heads in BERT Track Syntactic Dependencies? (Phu Mon Htut et al., 2019) Phu Mon Htut, Jason Phang, Shikha Bordia, Samuel R. Bowman. (2019)\nDo Attention Heads in BERT Track Syntactic Dependencies?\nArXiv\nPaper Link\nInfluential Citation Count (12), SS-ID (ba8215e77f35b0d947c7cec39c45df4516e93421)\nABSTRACT\nWe investigate the extent to which individual attention heads in pretrained transformer language models, such as BERT and RoBERTa, implicitly capture syntactic dependency relations. We employ two methods\u0026mdash;taking the maximum attention weight and computing the maximum spanning tree\u0026mdash;to extract implicit dependency relations from the attention weights of each layer/head, and compare them to the ground-truth Universal Dependency (UD) trees. We show that, for some UD relation types, there exist heads that can recover the dependency type significantly better than baselines on parsed English text, suggesting that some self-attention heads act as a proxy for syntactic structure. We also analyze BERT fine-tuned on two datasets\u0026mdash;the syntax-oriented CoLA and the semantics-oriented MNLI\u0026mdash;to investigate whether fine-tuning affects the patterns of their self-attention, but we do not observe substantial differences in the overall dependency relations extracted using our methods. Our results suggest that these models have some specialist attention heads that track individual dependency types, but no generalist head that performs holistic parsing significantly better than a trivial baseline, and that analyzing attention weights directly may not reveal much of the syntactic knowledge that BERT-style models are known to learn.\nDoes BERT Make Any Sense? Interpretable Word Sense Disambiguation with Contextualized Embeddings (Gregor Wiedemann et al., 2019) Gregor Wiedemann, Steffen Remus, Avi Chawla, Chris Biemann. (2019)\nDoes BERT Make Any Sense? Interpretable Word Sense Disambiguation with Contextualized Embeddings\nKONVENS\nPaper Link\nInfluential Citation Count (6), SS-ID (ba8b3d0d2b09bc2b56c6d3f153919786d9fc3075)\nABSTRACT\nContextualized word embeddings (CWE) such as provided by ELMo (Peters et al., 2018), Flair NLP (Akbik et al., 2018), or BERT (Devlin et al., 2019) are a major recent innovation in NLP. CWEs provide semantic vector representations of words depending on their respective context. Their advantage over static word embeddings has been shown for a number of tasks, such as text classification, sequence tagging, or machine translation. Since vectors of the same word type can vary depending on the respective context, they implicitly provide a model for word sense disambiguation (WSD). We introduce a simple but effective approach to WSD using a nearest neighbor classification on CWEs. We compare the performance of different CWE models for the task and can report improvements above the current state of the art for two standard WSD benchmark datasets. We further show that the pre-trained BERT model is able to place polysemic words into distinct \u0026lsquo;sense\u0026rsquo; regions of the embedding space, while ELMo and Flair NLP do not seem to possess this ability.\nFine-Tuning Pretrained Language Models: Weight Initializations, Data Orders, and Early Stopping (Jesse Dodge et al., 2020) Jesse Dodge, Gabriel Ilharco, Roy Schwartz, Ali Farhadi, Hannaneh Hajishirzi, Noah A. Smith. (2020)\nFine-Tuning Pretrained Language Models: Weight Initializations, Data Orders, and Early Stopping\nArXiv\nPaper Link\nInfluential Citation Count (17), SS-ID (baf60d13c98916b77b09bc525ede1cd610ed1db5)\nABSTRACT\nFine-tuning pretrained contextual word embedding models to supervised downstream tasks has become commonplace in natural language processing. This process, however, is often brittle: even with the same hyperparameter values, distinct random seeds can lead to substantially different results. To better understand this phenomenon, we experiment with four datasets from the GLUE benchmark, fine-tuning BERT hundreds of times on each while varying only the random seeds. We find substantial performance increases compared to previously reported results, and we quantify how the performance of the best-found model varies as a function of the number of fine-tuning trials. Further, we examine two factors influenced by the choice of random seed: weight initialization and training data order. We find that both contribute comparably to the variance of out-of-sample performance, and that some weight initializations perform well across all tasks explored. On small datasets, we observe that many fine-tuning trials diverge part of the way through training, and we offer best practices for practitioners to stop training less promising runs early. We publicly release all of our experimental data, including training and validation scores for 2,100 trials, to encourage further analysis of training dynamics during fine-tuning.\nImproving BERT Fine-tuning with Embedding Normalization (Wenxuan Zhou et al., 2019) Wenxuan Zhou, Junyi Du, Xiang Ren. (2019)\nImproving BERT Fine-tuning with Embedding Normalization\nArXiv\nPaper Link\nInfluential Citation Count (0), SS-ID (bb6e205f56f064ae76703b40147422483c438ef6)\nABSTRACT\nLarge pre-trained sentence encoders like BERT start a new chapter in natural language processing. A common practice to apply pre-trained BERT to sequence classification tasks (e.g., classification of sentences or sentence pairs) is by feeding the embedding of [CLS] token (in the last layer) to a task-specific classification layer, and then fine tune the model parameters of BERT and classifier jointly. In this paper, we conduct systematic analysis over several sequence classification datasets to examine the embedding values of [CLS] token before the fine tuning phase, and present the biased embedding distribution issue\u0026mdash;i.e., embedding values of [CLS] concentrate on a few dimensions and are non-zero centered. Such biased embedding brings challenge to the optimization process during fine-tuning as gradients of [CLS] embedding may explode and result in degraded model performance. We further propose several simple yet effective normalization methods to modify the [CLS] embedding during the fine-tuning. Compared with the previous practice, neural classification model with the normalized embedding shows improvements on several text classification tasks, demonstrates the effectiveness of our method.\nLarge Batch Optimization for Deep Learning: Training BERT in 76 minutes (Yang You et al., 2019) Yang You, Jing Li, Sashank J. Reddi, Jonathan Hseu, Sanjiv Kumar, Srinadh Bhojanapalli, Xiaodan Song, J. Demmel, K. Keutzer, Cho-Jui Hsieh. (2019)\nLarge Batch Optimization for Deep Learning: Training BERT in 76 minutes\nICLR\nPaper Link\nInfluential Citation Count (53), SS-ID (bc789aef715498e79a74f857fa090ece9e383bf1)\nABSTRACT\nTraining large deep neural networks on massive datasets is computationally very challenging. There has been recent surge in interest in using large batch stochastic optimization methods to tackle this issue. The most prominent algorithm in this line of research is LARS, which by employing layerwise adaptive learning rates trains ResNet on ImageNet in a few minutes. However, LARS performs poorly for attention models like BERT, indicating that its performance gains are not consistent across tasks. In this paper, we first study a principled layerwise adaptation strategy to accelerate training of deep neural networks using large mini-batches. Using this strategy, we develop a new layerwise adaptive large batch optimization technique called LAMB; we then provide convergence analysis of LAMB as well as LARS, showing convergence to a stationary point in general nonconvex settings. Our empirical results demonstrate the superior performance of LAMB across various tasks such as BERT and ResNet-50 training with very little hyperparameter tuning. In particular, for BERT training, our optimizer enables use of very large batch sizes of 32868 without any degradation of performance. By increasing the batch size to the memory limit of a TPUv3 Pod, BERT training time can be reduced from 3 days to just 76 minutes (Table 1). The LAMB implementation is available at this https URL\nVisualizing Attention in Transformer-Based Language Representation Models (Jesse Vig, 2019) Jesse Vig. (2019)\nVisualizing Attention in Transformer-Based Language Representation Models\nArXiv\nPaper Link\nInfluential Citation Count (5), SS-ID (beb051c652f02c2d5829d783fbc4f3acce99bc3c)\nABSTRACT\nWe present an open-source tool for visualizing multi-head self-attention in Transformer-based language representation models. The tool extends earlier work by visualizing attention at three levels of granularity: the attention-head level, the model level, and the neuron level. We describe how each of these views can help to interpret the model, and we demonstrate the tool on the BERT model and the OpenAI GPT-2 model. We also present three use cases for analyzing GPT-2: detecting model bias, identifying recurring patterns, and linking neurons to model behavior.\nSyntax-Infused Transformer and BERT models for Machine Translation and Natural Language Understanding (Dhanasekar Sundararaman et al., 2019) Dhanasekar Sundararaman, Vivek Subramanian, Guoyin Wang, Shijing Si, Dinghan Shen, Dong Wang, L. Carin. (2019)\nSyntax-Infused Transformer and BERT models for Machine Translation and Natural Language Understanding\nArXiv\nPaper Link\nInfluential Citation Count (1), SS-ID (beb91a773677872fc21f08722bdcc737bf5917b5)\nABSTRACT\nAttention-based models have shown significant improvement over traditional algorithms in several NLP tasks. The Transformer, for instance, is an illustrative example that generates abstract representations of tokens inputted to an encoder based on their relationships to all tokens in a sequence. Recent studies have shown that although such models are capable of learning syntactic features purely by seeing examples, explicitly feeding this information to deep learning models can significantly enhance their performance. Leveraging syntactic information like part of speech (POS) may be particularly beneficial in limited training data settings for complex models such as the Transformer. We show that the syntax-infused Transformer with multiple features achieves an improvement of 0.7 BLEU when trained on the full WMT 14 English to German translation dataset and a maximum improvement of 1.99 BLEU points when trained on a fraction of the dataset. In addition, we find that the incorporation of syntax into BERT fine-tuning outperforms baseline on a number of downstream tasks from the GLUE benchmark.\nKnowledge Enhanced Contextual Word Representations (Matthew E. Peters et al., 2019) Matthew E. Peters, Mark Neumann, IV RobertL.Logan, Roy Schwartz, V. Joshi, Sameer Singh, Noah A. Smith. (2019)\nKnowledge Enhanced Contextual Word Representations\nEMNLP\nPaper Link\nInfluential Citation Count (61), SS-ID (bfeb827d06c1a3583b5cc6d25241203a81f6af09)\nABSTRACT\nContextual word representations, typically trained on unstructured, unlabeled text, do not contain any explicit grounding to real world entities and are often unable to remember facts about those entities. We propose a general method to embed multiple knowledge bases (KBs) into large scale models, and thereby enhance their representations with structured, human-curated knowledge. For each KB, we first use an integrated entity linker to retrieve relevant entity embeddings, then update contextual word representations via a form of word-to-entity attention. In contrast to previous approaches, the entity linkers and self-supervised language modeling objective are jointly trained end-to-end in a multitask setting that combines a small amount of entity linking supervision with a large amount of raw text. After integrating WordNet and a subset of Wikipedia into BERT, the knowledge enhanced BERT (KnowBert) demonstrates improved perplexity, ability to recall facts as measured in a probing task and downstream performance on relationship extraction, entity typing, and word sense disambiguation. KnowBert’s runtime is comparable to BERT’s and it scales to large KBs.\nTANDA: Transfer and Adapt Pre-Trained Transformer Models for Answer Sentence Selection (Siddhant Garg et al., 2019) Siddhant Garg, Thuy Vu, Alessandro Moschitti. (2019)\nTANDA: Transfer and Adapt Pre-Trained Transformer Models for Answer Sentence Selection\nAAAI\nPaper Link\nInfluential Citation Count (12), SS-ID (c12e6c65e1de5d3993c5b65d0e234ae1f60c85ae)\nABSTRACT\nWe propose TandA, an effective technique for fine-tuning pre-trained Transformer models for natural language tasks. Specifically, we first transfer a pre-trained model into a model for a general task by fine-tuning it with a large and high-quality dataset. We then perform a second fine-tuning step to adapt the transferred model to the target domain. We demonstrate the benefits of our approach for answer sentence selection, which is a well-known inference task in Question Answering. We built a large scale dataset to enable the transfer step, exploiting the Natural Questions dataset. Our approach establishes the state of the art on two well-known benchmarks, WikiQA and TREC-QA, achieving the impressive MAP scores of 92% and 94.3%, respectively, which largely outperform the the highest scores of 83.4% and 87.5% of previous work. We empirically show that TandA generates more stable and robust models reducing the effort required for selecting optimal hyper-parameters. Additionally, we show that the transfer step of TandA makes the adaptation step more robust to noise. This enables a more effective use of noisy datasets for fine-tuning. Finally, we also confirm the positive impact of TandA in an industrial setting, using domain specific datasets subject to different types of noise.\nWhen Bert Forgets How To POS: Amnesic Probing of Linguistic Properties and MLM Predictions (Yanai Elazar et al., 2020) Yanai Elazar, Shauli Ravfogel, Alon Jacovi, Yoav Goldberg. (2020)\nWhen Bert Forgets How To POS: Amnesic Probing of Linguistic Properties and MLM Predictions\nArXiv\nPaper Link\nInfluential Citation Count (1), SS-ID (c8b00d4706fc8979a9c5f410addccbcfe1c0d894)\nABSTRACT\nA growing body of work makes use of probing in order to investigate the working of neural models, often considered black boxes. Recently, an ongoing debate emerged surrounding the limitations of the probing paradigm. In this work, we point out the inability to infer behavioral conclusions from probing results, and offer an alternative method which is focused on how the information is being used, rather than on what information is encoded. Our method, Amnesic Probing, follows the intuition that the utility of a property for a given task can be assessed by measuring the influence of a causal intervention which removes it from the representation. Equipped with this new analysis tool, we can now ask questions that were not possible before, e.g. is part-of-speech information important for word prediction? We perform a series of analyses on BERT to answer these types of questions. Our findings demonstrate that conventional probing performance is not correlated to task importance, and we call for increased scrutiny of claims that draw behavioral or causal conclusions from probing results.\nOn the use of BERT for Neural Machine Translation (S. Clinchant et al., 2019) S. Clinchant, K. Jung, Vassilina Nikoulina. (2019)\nOn the use of BERT for Neural Machine Translation\nEMNLP\nPaper Link\nInfluential Citation Count (9), SS-ID (c93b2d64fce8737506757bbce51e17b533f9285b)\nABSTRACT\nExploiting large pretrained models for various NMT tasks have gained a lot of visibility recently. In this work we study how BERT pretrained models could be exploited for supervised Neural Machine Translation. We compare various ways to integrate pretrained BERT model with NMT model and study the impact of the monolingual data used for BERT training on the final translation quality. We use WMT-14 English-German, IWSLT15 English-German and IWSLT14 English-Russian datasets for these experiments. In addition to standard task test set evaluation, we perform evaluation on out-of-domain test sets and noise injected test sets, in order to assess how BERT pretrained representations affect model robustness.\nDo Neural Language Representations Learn Physical Commonsense? (Maxwell Forbes et al., 2019) Maxwell Forbes, Ari Holtzman, Yejin Choi. (2019)\nDo Neural Language Representations Learn Physical Commonsense?\nCogSci\nPaper Link\nInfluential Citation Count (3), SS-ID (cc02386375b1262c3a1d5525154eaea24c761d15)\nABSTRACT\nHumans understand language based on the rich background knowledge about how the physical world works, which in turn allows us to reason about the physical world through language. In addition to the properties of objects (e.g., boats require fuel) and their affordances, i.e., the actions that are applicable to them (e.g., boats can be driven), we can also reason about if-then inferences between what properties of objects imply the kind of actions that are applicable to them (e.g., that if we can drive something then it likely requires fuel). In this paper, we investigate the extent to which state-of-the-art neural language representations, trained on a vast amount of natural language text, demonstrate physical commonsense reasoning. While recent advancements of neural language models have demonstrated strong performance on various types of natural language inference tasks, our study based on a dataset of over 200k newly collected annotations suggests that neural language representations still only learn associations that are explicitly written down.\nQ8BERT: Quantized 8Bit BERT (Ofir Zafrir et al., 2019) Ofir Zafrir, Guy Boudoukh, Peter Izsak, Moshe Wasserblat. (2019)\nQ8BERT: Quantized 8Bit BERT\n2019 Fifth Workshop on Energy Efficient Machine Learning and Cognitive Computing - NeurIPS Edition (EMC2-NIPS)\nPaper Link\nInfluential Citation Count (17), SS-ID (ce106590145e89ea4b621c99665862967ccf5dac)\nABSTRACT\nRecently, pre-trained Transformer [1] based language models such as BERT [2] and GPT [3], have shown great improvement in many Natural Language Processing (NLP) tasks. However, these models contain a large amount of parameters. The emergence of even larger and more accurate models such as GPT2 [4] and Megatron11https://github.com/NVIDIA/Megatron-LM, suggest a trend of large pre-trained Transformer models. However, using these large models in production environments is a complex task requiring a large amount of compute, memory and power resources. In this work we show how to perform quantization-aware training during the fine-tuning phase of BERT in order to compress BERT by 4x with minimal accuracy loss. Furthermore, the produced quantized model can accelerate inference speed if it is optimized for 8bit Integer supporting hardware.\nAttention is not not Explanation (Sarah Wiegreffe et al., 2019) Sarah Wiegreffe, Yuval Pinter. (2019)\nAttention is not not Explanation\nEMNLP\nPaper Link\nInfluential Citation Count (12), SS-ID (ce177672b00ddf46e4906157a7e997ca9338b8b9)\nABSTRACT\nAttention mechanisms play a central role in NLP systems, especially within recurrent neural network (RNN) models. Recently, there has been increasing interest in whether or not the intermediate representations offered by these modules may be used to explain the reasoning for a model’s prediction, and consequently reach insights regarding the model’s decision-making process. A recent paper claims that ‘Attention is not Explanation’ (Jain and Wallace, 2019). We challenge many of the assumptions underlying this work, arguing that such a claim depends on one’s definition of explanation, and that testing it needs to take into account all elements of the model. We propose four alternative tests to determine when/whether attention can be used as explanation: a simple uniform-weights baseline; a variance calibration based on multiple random seed runs; a diagnostic framework using frozen weights from pretrained models; and an end-to-end adversarial attention training protocol. Each allows for meaningful interpretation of attention mechanisms in RNN models. We show that even when reliable adversarial distributions can be found, they don’t perform well on the simple diagnostic, indicating that prior work does not disprove the usefulness of attention mechanisms for explainability.\nLanguage Models as Knowledge Bases? (Fabio Petroni et al., 2019) Fabio Petroni, Tim Rocktäschel, Patrick Lewis, A. Bakhtin, Yuxiang Wu, Alexander H. Miller, S. Riedel. (2019)\nLanguage Models as Knowledge Bases?\nEMNLP\nPaper Link\nInfluential Citation Count (115), SS-ID (d0086b86103a620a86bc918746df0aa642e2a8a3)\nABSTRACT\nRecent progress in pretraining language models on large textual corpora led to a surge of improvements for downstream NLP tasks. Whilst learning linguistic knowledge, these models may also be storing relational knowledge present in the training data, and may be able to answer queries structured as “fill-in-the-blank” cloze statements. Language models have many advantages over structured knowledge bases: they require no schema engineering, allow practitioners to query about an open class of relations, are easy to extend to more data, and require no human supervision to train. We present an in-depth analysis of the relational knowledge already present (without fine-tuning) in a wide range of state-of-the-art pretrained language models. We find that (i) without fine-tuning, BERT contains relational knowledge competitive with traditional NLP methods that have some access to oracle knowledge, (ii) BERT also does remarkably well on open-domain question answering against a supervised baseline, and (iii) certain types of factual knowledge are learned much more readily than others by standard language model pretraining approaches. The surprisingly strong ability of these models to recall factual knowledge without any fine-tuning demonstrates their potential as unsupervised open-domain QA systems. The code to reproduce our analysis is available at https://github.com/facebookresearch/LAMA.\nFreeLB: Enhanced Adversarial Training for Natural Language Understanding (Chen Zhu et al., 2019) Chen Zhu, Yu Cheng, Zhe Gan, S. Sun, T. Goldstein, Jingjing Liu. (2019)\nFreeLB: Enhanced Adversarial Training for Natural Language Understanding\nICLR\nPaper Link\nInfluential Citation Count (34), SS-ID (d01fa0311e8e15b8b874b376123530c815f52852)\nABSTRACT\nAdversarial training, which minimizes the maximal risk for label-preserving input perturbations, has proved to be effective for improving the generalization of language models. In this work, we propose a novel adversarial training algorithm, FreeLB, that promotes higher invariance in the embedding space, by adding adversarial perturbations to word embeddings and minimizing the resultant adversarial risk inside different regions around input samples. To validate the effectiveness of the proposed approach, we apply it to Transformer-based models for natural language understanding and commonsense reasoning tasks. Experiments on the GLUE benchmark show that when applied only to the finetuning stage, it is able to improve the overall test scores of BERT-base model from 78.3 to 79.4, and RoBERTa-large model from 88.5 to 88.8. In addition, the proposed approach achieves state-of-the-art single-model test accuracies of 85.44% and 67.75% on ARC-Easy and ARC-Challenge. Experiments on CommonsenseQA benchmark further demonstrate that FreeLB can be generalized and boost the performance of RoBERTa-large model on other tasks as well. Code is available at \\url{this https URL .\nFreeLB: Enhanced Adversarial Training for Language Understanding (Chen Zhu et al., 2019) Chen Zhu, Yu Cheng, Zhe Gan, S. Sun, T. Goldstein, Jingjing Liu. (2019)\nFreeLB: Enhanced Adversarial Training for Language Understanding\nICLR 2020\nPaper Link\nInfluential Citation Count (16), SS-ID (d2038ced371e45aee3651c7a595c4566f4826b9f)\nABSTRACT\nAdversarial training, which minimizes the maximal risk for label-preserving input perturbations, has proved to be effective for improving the generalization of language models. In this work, we propose a novel adversarial training algorithm - FreeLB, that promotes higher robustness and invariance in the embedding space, by adding adversarial perturbations to word embeddings and minimizing the resultant adversarial risk inside different regions around input samples. To validate the effectiveness of the proposed approach, we apply it to Transformer-based models for natural language understanding and commonsense reasoning tasks. Experiments on the GLUE benchmark show that when applied only to the finetuning stage, it is able to improve the overall test scores of BERT-based model from 78.3 to 79.4, and RoBERTa-large model from 88.5 to 88.8. In addition, the proposed approach achieves state-of-the-art test accuracies of 85.39% and 67.32% on ARC-Easy and ARC-Challenge. Experiments on CommonsenseQA benchmark further demonstrate that FreeLB can be generalized and boost the performance of RoBERTa-large model on other tasks as well.\nInterpreting Pretrained Contextualized Representations via Reductions to Static Embeddings (Rishi Bommasani et al., 2020) Rishi Bommasani, Kelly Davis, Claire Cardie. (2020)\nInterpreting Pretrained Contextualized Representations via Reductions to Static Embeddings\nACL\nPaper Link\nInfluential Citation Count (17), SS-ID (d34580c522c79d5cde620331dd9ffb18643a8090)\nABSTRACT\nContextualized representations (e.g. ELMo, BERT) have become the default pretrained representations for downstream NLP applications. In some settings, this transition has rendered their static embedding predecessors (e.g. Word2Vec, GloVe) obsolete. As a side-effect, we observe that older interpretability methods for static embeddings — while more diverse and mature than those available for their dynamic counterparts — are underutilized in studying newer contextualized representations. Consequently, we introduce simple and fully general methods for converting from contextualized representations to static lookup-table embeddings which we apply to 5 popular pretrained models and 9 sets of pretrained weights. Our analysis of the resulting static embeddings notably reveals that pooling over many contexts significantly improves representational quality under intrinsic evaluation. Complementary to analyzing representational quality, we consider social biases encoded in pretrained representations with respect to gender, race/ethnicity, and religion and find that bias is encoded disparately across pretrained models and internal layers even for models with the same training data. Concerningly, we find dramatic inconsistencies between social bias estimators for word embeddings.\nVisualizing and Understanding the Effectiveness of BERT (Y. Hao et al., 2019) Y. Hao, Li Dong, Furu Wei, Ke Xu. (2019)\nVisualizing and Understanding the Effectiveness of BERT\nEMNLP\nPaper Link\nInfluential Citation Count (3), SS-ID (d3cacb4806886eb2fe59c90d4b6f822c24ff1822)\nABSTRACT\nLanguage model pre-training, such as BERT, has achieved remarkable results in many NLP tasks. However, it is unclear why the pre-training-then-fine-tuning paradigm can improve performance and generalization capability across different tasks. In this paper, we propose to visualize loss landscapes and optimization trajectories of fine-tuning BERT on specific datasets. First, we find that pre-training reaches a good initial point across downstream tasks, which leads to wider optima and easier optimization compared with training from scratch. We also demonstrate that the fine-tuning procedure is robust to overfitting, even though BERT is highly over-parameterized for downstream tasks. Second, the visualization results indicate that fine-tuning BERT tends to generalize better because of the flat and wide optima, and the consistency between the training loss surface and the generalization error surface. Third, the lower layers of BERT are more invariant during fine-tuning, which suggests that the layers that are close to input learn more transferable representations of language.\nRNNs Implicitly Implement Tensor Product Representations (R. Thomas McCoy et al., 2018) R. Thomas McCoy, Tal Linzen, Ewan Dunbar, P. Smolensky. (2018)\nRNNs Implicitly Implement Tensor Product Representations\nICLR\nPaper Link\nInfluential Citation Count (2), SS-ID (d3ded34ff3378aadaa9a7c10e51cef6d04391a86)\nABSTRACT\nRecurrent neural networks (RNNs) can learn continuous vector representations of symbolic structures such as sequences and sentences; these representations often exhibit linear regularities (analogies). Such regularities motivate our hypothesis that RNNs that show such regularities implicitly compile symbolic structures into tensor product representations (TPRs; Smolensky, 1990), which additively combine tensor products of vectors representing roles (e.g., sequence positions) and vectors representing fillers (e.g., particular words). To test this hypothesis, we introduce Tensor Product Decomposition Networks (TPDNs), which use TPRs to approximate existing vector representations. We demonstrate using synthetic data that TPDNs can successfully approximate linear and tree-based RNN autoencoder representations, suggesting that these representations exhibit interpretable compositional structure; we explore the settings that lead RNNs to induce such structure-sensitive representations. By contrast, further TPDN experiments show that the representations of four models trained to encode naturally-occurring sentences can be largely approximated with a bag of words, with only marginal improvements from more sophisticated structures. We conclude that TPDNs provide a powerful method for interpreting vector representations, and that standard RNNs can induce compositional sequence representations that are remarkably well approximated by TPRs; at the same time, existing training tasks for sentence representation learning may not be sufficient for inducing robust structural representations.\nStructBERT: Incorporating Language Structures into Pre-training for Deep Language Understanding (Wei Wang et al., 2019) Wei Wang, Bin Bi, Ming Yan, Chen Wu, Zuyi Bao, Liwei Peng, Luo Si. (2019)\nStructBERT: Incorporating Language Structures into Pre-training for Deep Language Understanding\nICLR\nPaper Link\nInfluential Citation Count (21), SS-ID (d56c1fc337fb07ec004dc846f80582c327af717c)\nABSTRACT\nRecently, the pre-trained language model, BERT (and its robustly optimized version RoBERTa), has attracted a lot of attention in natural language understanding (NLU), and achieved state-of-the-art accuracy in various NLU tasks, such as sentiment classification, natural language inference, semantic textual similarity and question answering. Inspired by the linearization exploration work of Elman [8], we extend BERT to a new model, StructBERT, by incorporating language structures into pre-training. Specifically, we pre-train StructBERT with two auxiliary tasks to make the most of the sequential order of words and sentences, which leverage language structures at the word and sentence levels, respectively. As a result, the new model is adapted to different levels of language understanding required by downstream tasks. The StructBERT with structural pre-training gives surprisingly good empirical results on a variety of downstream tasks, including pushing the state-of-the-art on the GLUE benchmark to 89.0 (outperforming all published models), the F1 score on SQuAD v1.1 question answering to 93.0, the accuracy on SNLI to 91.7.\nMultilingual Alignment of Contextual Word Representations (Steven Cao et al., 2020) Steven Cao, Nikita Kitaev, D. Klein. (2020)\nMultilingual Alignment of Contextual Word Representations\nICLR\nPaper Link\nInfluential Citation Count (17), SS-ID (d592007d1c106fe1217604eb35664c7a5f07cb32)\nABSTRACT\nWe propose procedures for evaluating and strengthening contextual embedding alignment and show that they are useful in analyzing and improving multilingual BERT. In particular, after our proposed alignment procedure, BERT exhibits significantly improved zero-shot performance on XNLI compared to the base model, remarkably matching pseudo-fully-supervised translate-train models for Bulgarian and Greek. Further, to measure the degree of alignment, we introduce a contextual version of word retrieval and show that it correlates well with downstream zero-shot transfer. Using this word retrieval task, we also analyze BERT and find that it exhibits systematic deficiencies, e.g. worse alignment for open-class parts-of-speech and word pairs written in different scripts, that are corrected by the alignment procedure. These results support contextual alignment as a useful concept for understanding large multilingual pre-trained models.\nEnergy and Policy Considerations for Deep Learning in NLP (Emma Strubell et al., 2019) Emma Strubell, Ananya Ganesh, A. McCallum. (2019)\nEnergy and Policy Considerations for Deep Learning in NLP\nACL\nPaper Link\nInfluential Citation Count (64), SS-ID (d6a083dad7114f3a39adc65c09bfbb6cf3fee9ea)\nABSTRACT\nRecent progress in hardware and methodology for training neural networks has ushered in a new generation of large networks trained on abundant data. These models have obtained notable gains in accuracy across many NLP tasks. However, these accuracy improvements depend on the availability of exceptionally large computational resources that necessitate similarly substantial energy consumption. As a result these models are costly to train and develop, both financially, due to the cost of hardware and electricity or cloud compute time, and environmentally, due to the carbon footprint required to fuel modern tensor processing hardware. In this paper we bring this issue to the attention of NLP researchers by quantifying the approximate financial and environmental costs of training a variety of recently successful neural network models for NLP. Based on these findings, we propose actionable recommendations to reduce costs and improve equity in NLP research and practice.\nRevealing the Dark Secrets of BERT (Olga Kovaleva et al., 2019) Olga Kovaleva, Alexey Romanov, Anna Rogers, Anna Rumshisky. (2019)\nRevealing the Dark Secrets of BERT\nEMNLP\nPaper Link\nInfluential Citation Count (34), SS-ID (d78aed1dac6656affa4a04cbf225ced11a83d103)\nABSTRACT\nBERT-based architectures currently give state-of-the-art performance on many NLP tasks, but little is known about the exact mechanisms that contribute to its success. In the current work, we focus on the interpretation of self-attention, which is one of the fundamental underlying components of BERT. Using a subset of GLUE tasks and a set of handcrafted features-of-interest, we propose the methodology and carry out a qualitative and quantitative analysis of the information encoded by the individual BERT’s heads. Our findings suggest that there is a limited set of attention patterns that are repeated across different heads, indicating the overall model overparametrization. While different heads consistently use the same attention patterns, they have varying impact on performance across different tasks. We show that manually disabling attention in certain heads leads to a performance improvement over the regular fine-tuned BERT models.\nDoes BERT Solve Commonsense Task via Commonsense Knowledge? (Leyang Cui et al., 2020) Leyang Cui, Sijie Cheng, Yu Wu, Yue Zhang. (2020)\nDoes BERT Solve Commonsense Task via Commonsense Knowledge?\nArXiv\nPaper Link\nInfluential Citation Count (1), SS-ID (d8ea988072efb115ee8c85e159c1fa4a816360b5)\nABSTRACT\nThe success of pre-trained contextualized language models such as BERT motivates a line of work that investigates linguistic knowledge inside such models in order to explain the huge improvement in downstream tasks. While previous work shows syntactic, semantic and word sense knowledge in BERT, little work has been done on investigating how BERT solves CommonsenseQA tasks. In particular, it is an interesting research question whether BERT relies on shallow syntactic patterns or deeper commonsense knowledge for disambiguation. We propose two attention-based methods to analyze commonsense knowledge inside BERT, and the contribution of such knowledge for the model prediction. We find that attention heads successfully capture the structured commonsense knowledge encoded in ConceptNet, which helps BERT solve commonsense tasks directly. Fine-tuning further makes BERT learn to use the commonsense knowledge on higher layers.\nCompressing BERT: Studying the Effects of Weight Pruning on Transfer Learning (Mitchell A. Gordon et al., 2020) Mitchell A. Gordon, Kevin Duh, Nicholas Andrews. (2020)\nCompressing BERT: Studying the Effects of Weight Pruning on Transfer Learning\nREPL4NLP\nPaper Link\nInfluential Citation Count (8), SS-ID (d9b824dbecbe3a1f0b1489f9e4521a532a63818d)\nABSTRACT\nPre-trained universal feature extractors, such as BERT for natural language processing and VGG for computer vision, have become effective methods for improving deep learning models without requiring more labeled data. While effective, feature extractors like BERT may be prohibitively large for some deployment scenarios. We explore weight pruning for BERT and ask: how does compression during pre-training affect transfer learning? We find that pruning affects transfer learning in three broad regimes. Low levels of pruning (30-40%) do not affect pre-training loss or transfer to downstream tasks at all. Medium levels of pruning increase the pre-training loss and prevent useful pre-training information from being transferred to downstream tasks. High levels of pruning additionally prevent models from fitting downstream datasets, leading to further degradation. Finally, we observe that fine-tuning BERT on a specific task does not improve its prunability. We conclude that BERT can be pruned once during pre-training rather than separately for each task without affecting performance.\nGoogle\u0026#39;s Neural Machine Translation System: Bridging the Gap between Human and Machine Translation (Yonghui Wu et al., 2016) Yonghui Wu, M. Schuster, Z. Chen, Quoc V. Le, Mohammad Norouzi, Wolfgang Macherey, M. Krikun, Yuan Cao, Qin Gao, Klaus Macherey, J. Klingner, Apurva Shah, Melvin Johnson, Xiaobing Liu, Lukasz Kaiser, Stephan Gouws, Y. Kato, Taku Kudo, H. Kazawa, K. Stevens, George Kurian, Nishant Patil, Wei Wang, C. Young, Jason R. Smith, Jason Riesa, Alex Rudnick, Oriol Vinyals, G. Corrado, Macduff Hughes, J. Dean. (2016)\nGoogle\u0026rsquo;s Neural Machine Translation System: Bridging the Gap between Human and Machine Translation\nArXiv\nPaper Link\nInfluential Citation Count (345), SS-ID (dbde7dfa6cae81df8ac19ef500c42db96c3d1edd)\nABSTRACT\nNeural Machine Translation (NMT) is an end-to-end learning approach for automated translation, with the potential to overcome many of the weaknesses of conventional phrase-based translation systems. Unfortunately, NMT systems are known to be computationally expensive both in training and in translation inference. Also, most NMT systems have difficulty with rare words. These issues have hindered NMT\u0026rsquo;s use in practical deployments and services, where both accuracy and speed are essential. In this work, we present GNMT, Google\u0026rsquo;s Neural Machine Translation system, which attempts to address many of these issues. Our model consists of a deep LSTM network with 8 encoder and 8 decoder layers using attention and residual connections. To improve parallelism and therefore decrease training time, our attention mechanism connects the bottom layer of the decoder to the top layer of the encoder. To accelerate the final translation speed, we employ low-precision arithmetic during inference computations. To improve handling of rare words, we divide words into a limited set of common sub-word units (\u0026ldquo;wordpieces\u0026rdquo;) for both input and output. This method provides a good balance between the flexibility of \u0026ldquo;character\u0026rdquo;-delimited models and the efficiency of \u0026ldquo;word\u0026rdquo;-delimited models, naturally handles translation of rare words, and ultimately improves the overall accuracy of the system. Our beam search technique employs a length-normalization procedure and uses a coverage penalty, which encourages generation of an output sentence that is most likely to cover all the words in the source sentence. On the WMT'14 English-to-French and English-to-German benchmarks, GNMT achieves competitive results to state-of-the-art. Using a human side-by-side evaluation on a set of isolated simple sentences, it reduces translation errors by an average of 60% compared to Google\u0026rsquo;s phrase-based production system.\nBERT as a Teacher: Contextual Embeddings for Sequence-Level Reward (Florian Schmidt et al., 2020) Florian Schmidt, T. Hofmann. (2020)\nBERT as a Teacher: Contextual Embeddings for Sequence-Level Reward\nArXiv\nPaper Link\nInfluential Citation Count (0), SS-ID (de9e7d6319b26c0d9f0da20c79403e9b9367fff4)\nABSTRACT\nMeasuring the quality of a generated sequence against a set of references is a central problem in many learning frameworks, be it to compute a score, to assign a reward, or to perform discrimination. Despite great advances in model architectures, metrics that scale independently of the number of references are still based on n-gram estimates. We show that the underlying operations, counting words and comparing counts, can be lifted to embedding words and comparing embeddings. An in-depth analysis of BERT embeddings shows empirically that contextual embeddings can be employed to capture the required dependencies while maintaining the necessary scalability through appropriate pruning and smoothing techniques. We cast unconditional generation as a reinforcement learning problem and show that our reward function indeed provides a more effective learning signal than n-gram reward in this challenging setting.\nBERT: Pre-training of Deep Bidirectional Transformers for Language Understanding (Jacob Devlin et al., 2019) Jacob Devlin, Ming-Wei Chang, Kenton Lee, Kristina Toutanova. (2019)\nBERT: Pre-training of Deep Bidirectional Transformers for Language Understanding\nNAACL\nPaper Link\nInfluential Citation Count (9863), SS-ID (df2b0e26d0599ce3e70df8a9da02e51594e0e992)\nABSTRACT\nWe introduce a new language representation model called BERT, which stands for Bidirectional Encoder Representations from Transformers. Unlike recent language representation models (Peters et al., 2018a; Radford et al., 2018), BERT is designed to pre-train deep bidirectional representations from unlabeled text by jointly conditioning on both left and right context in all layers. As a result, the pre-trained BERT model can be fine-tuned with just one additional output layer to create state-of-the-art models for a wide range of tasks, such as question answering and language inference, without substantial task-specific architecture modifications. BERT is conceptually simple and empirically powerful. It obtains new state-of-the-art results on eleven natural language processing tasks, including pushing the GLUE score to 80.5 (7.7 point absolute improvement), MultiNLI accuracy to 86.7% (4.6% absolute improvement), SQuAD v1.1 question answering Test F1 to 93.2 (1.5 point absolute improvement) and SQuAD v2.0 Test F1 to 83.1 (5.1 point absolute improvement).\nConstructions at Work: The Nature of Generalization in Language (A. Goldberg, 2006) A. Goldberg. (2006)\nConstructions at Work: The Nature of Generalization in Language\nPaper Link\nInfluential Citation Count (229), SS-ID (dfc79017e52efb270155ce8b93337467804cb697)\nABSTRACT\nPart One: Constructions 1. Overview 2. Surface Generalizations 3. Item Specific Knowledge and Generalizations Part Two: Learning Generalizations 4. How Generalizations are Learned 5. How Generalizations are Constrained 6. Why Generalizations are Learned Part Three: Explaining Generalizations 7. Island Constraints and Scope 8. Grammatical Categorization: Subject Auxiliary Inversion 9. Cross-linguistic Generalizations in Argument Realization 10. Variations on a Constructionist Theme 11. Conclusion References Index\nXLNet: Generalized Autoregressive Pretraining for Language Understanding (Zhilin Yang et al., 2019) Zhilin Yang, Zihang Dai, Yiming Yang, J. Carbonell, R. Salakhutdinov, Quoc V. Le. (2019)\nXLNet: Generalized Autoregressive Pretraining for Language Understanding\nNeurIPS\nPaper Link\nInfluential Citation Count (631), SS-ID (e0c6abdbdecf04ffac65c440da77fb9d66bb474c)\nABSTRACT\nWith the capability of modeling bidirectional contexts, denoising autoencoding based pretraining like BERT achieves better performance than pretraining approaches based on autoregressive language modeling. However, relying on corrupting the input with masks, BERT neglects dependency between the masked positions and suffers from a pretrain-finetune discrepancy. In light of these pros and cons, we propose XLNet, a generalized autoregressive pretraining method that (1) enables learning bidirectional contexts by maximizing the expected likelihood over all permutations of the factorization order and (2) overcomes the limitations of BERT thanks to its autoregressive formulation. Furthermore, XLNet integrates ideas from Transformer-XL, the state-of-the-art autoregressive model, into pretraining. Empirically, under comparable experiment settings, XLNet outperforms BERT on 20 tasks, often by a large margin, including question answering, natural language inference, sentiment analysis, and document ranking.\nWhat do you learn from context? Probing for sentence structure in contextualized word representations (Ian Tenney et al., 2019) Ian Tenney, Patrick Xia, Berlin Chen, Alex Wang, Adam Poliak, R. Thomas McCoy, Najoung Kim, Benjamin Van Durme, Samuel R. Bowman, Dipanjan Das, Ellie Pavlick. (2019)\nWhat do you learn from context? Probing for sentence structure in contextualized word representations\nICLR\nPaper Link\nInfluential Citation Count (45), SS-ID (e2587eddd57bc4ba286d91b27c185083f16f40ee)\nABSTRACT\nContextualized representation models such as ELMo (Peters et al., 2018a) and BERT (Devlin et al., 2018) have recently achieved state-of-the-art results on a diverse array of downstream NLP tasks. Building on recent token-level probing work, we introduce a novel edge probing task design and construct a broad suite of sub-sentence tasks derived from the traditional structured NLP pipeline. We probe word-level contextual representations from four recent models and investigate how they encode sentence structure across a range of syntactic, semantic, local, and long-range phenomena. We find that existing models trained on language modeling and translation produce strong representations for syntactic phenomena, but only offer comparably small improvements on semantic tasks over a non-contextual baseline.\nCross-lingual Language Model Pretraining (Guillaume Lample et al., 2019) Guillaume Lample, A. Conneau. (2019)\nCross-lingual Language Model Pretraining\nNeurIPS\nPaper Link\nInfluential Citation Count (345), SS-ID (ec4eba83f6b3266d9ae7cabb2b2cb1518f727edc)\nABSTRACT\nRecent studies have demonstrated the efficiency of generative pretraining for English natural language understanding. In this work, we extend this approach to multiple languages and show the effectiveness of cross-lingual pretraining. We propose two methods to learn cross-lingual language models (XLMs): one unsupervised that only relies on monolingual data, and one supervised that leverages parallel data with a new cross-lingual language model objective. We obtain state-of-the-art results on cross-lingual classification, unsupervised and supervised machine translation. On XNLI, our approach pushes the state of the art by an absolute gain of 4.9% accuracy. On unsupervised machine translation, we obtain 34.3 BLEU on WMT’16 German-English, improving the previous state of the art by more than 9 BLEU. On supervised machine translation, we obtain a new state of the art of 38.5 BLEU on WMT’16 Romanian-English, outperforming the previous best approach by more than 4 BLEU. Our code and pretrained models will be made publicly available.\nPooled Contextualized Embeddings for Named Entity Recognition (A. Akbik et al., 2019) A. Akbik, Tanja Bergmann, Roland Vollgraf. (2019)\nPooled Contextualized Embeddings for Named Entity Recognition\nNAACL\nPaper Link\nInfluential Citation Count (40), SS-ID (edfe9dd16316618e694cd087d0d418dac91eb48c)\nABSTRACT\nContextual string embeddings are a recent type of contextualized word embedding that were shown to yield state-of-the-art results when utilized in a range of sequence labeling tasks. They are based on character-level language models which treat text as distributions over characters and are capable of generating embeddings for any string of characters within any textual context. However, such purely character-based approaches struggle to produce meaningful embeddings if a rare string is used in a underspecified context. To address this drawback, we propose a method in which we dynamically aggregate contextualized embeddings of each unique string that we encounter. We then use a pooling operation to distill a ”global” word representation from all contextualized instances. We evaluate these ”pooled contextualized embeddings” on common named entity recognition (NER) tasks such as CoNLL-03 and WNUT and show that our approach significantly improves the state-of-the-art for NER. We make all code and pre-trained models available to the research community for use and reproduction.\nDocument Classification by Word Embeddings of BERT (Hirotaka Tanaka et al., 2019) Hirotaka Tanaka, Hiroyuki Shinnou, Rui Cao, Jing Bai, Wen Ma. (2019)\nDocument Classification by Word Embeddings of BERT\nPACLING\nPaper Link\nInfluential Citation Count (0), SS-ID (ef1041ff14c02dc9e35317916561b904d7ef8433)\nABSTRACT\nBidirectional Encoder Representations from Transformers (BERT) is a pre-training model that uses the encoder component of a bidirectional transformer and converts an input sentence or input sentence pair into word enbeddings. The performance of various natural language processing systems has been greatly improved by BERT. However, for a real task, it is necessary to consider how BERT is used based on the type of task. The standerd method for document classification by BERT is to treat the word embedding of special token [CLS] as a feature vector of the document, and to fine-tune the entire model of the classifier, including a pre-training model. However, after normalizing each the feature vector consisting of the mean vector of word embeddings outputted by BERT for the document, and the feature vectors according to the bag-of-words model, we create a vector concatenating them. Our proposed method involves using the concatenated vector as the feature vector of the document.\nPay Less Attention with Lightweight and Dynamic Convolutions (Felix Wu et al., 2019) Felix Wu, Angela Fan, Alexei Baevski, Yann Dauphin, Michael Auli. (2019)\nPay Less Attention with Lightweight and Dynamic Convolutions\nICLR\nPaper Link\nInfluential Citation Count (65), SS-ID (ef523bb9437178c50d1b1e3e3ca5fb230ab37e3f)\nABSTRACT\nSelf-attention is a useful mechanism to build generative models for language and images. It determines the importance of context elements by comparing each element to the current time step. In this paper, we show that a very lightweight convolution can perform competitively to the best reported self-attention results. Next, we introduce dynamic convolutions which are simpler and more efficient than self-attention. We predict separate convolution kernels based solely on the current time-step in order to determine the importance of context elements. The number of operations required by this approach scales linearly in the input length, whereas self-attention is quadratic. Experiments on large-scale machine translation, language modeling and abstractive summarization show that dynamic convolutions improve over strong self-attention models. On the WMT'14 English-German test set dynamic convolutions achieve a new state of the art of 29.7 BLEU.\nAssessing BERT\u0026#39;s Syntactic Abilities (Yoav Goldberg, 2019) Yoav Goldberg. (2019)\nAssessing BERT\u0026rsquo;s Syntactic Abilities\nArXiv\nPaper Link\nInfluential Citation Count (17), SS-ID (efeab0dcdb4c1cce5e537e57745d84774be99b9a)\nABSTRACT\nI assess the extent to which the recently introduced BERT model captures English syntactic phenomena, using (1) naturally-occurring subject-verb agreement stimuli; (2) \u0026ldquo;coloreless green ideas\u0026rdquo; subject-verb agreement stimuli, in which content words in natural sentences are randomly replaced with words sharing the same part-of-speech and inflection; and (3) manually crafted stimuli for subject-verb agreement and reflexive anaphora phenomena. The BERT model performs remarkably well on all cases.\nFurther Boosting BERT-based Models by Duplicating Existing Layers: Some Intriguing Phenomena inside BERT (Wei-Tsung Kao et al., 2020) Wei-Tsung Kao, Tsung-Han Wu, Po-Han Chi, Chun-Cheng Hsieh, Hung-yi Lee. (2020)\nFurther Boosting BERT-based Models by Duplicating Existing Layers: Some Intriguing Phenomena inside BERT\nArXiv\nPaper Link\nInfluential Citation Count (1), SS-ID (f18fa3728868af6c44bb1dc3e913925abc37b5c1)\nABSTRACT\nAlthough Bidirectional Encoder Representations from Transformers (BERT) have achieved tremendous success in many natural language processing (NLP) tasks, it remains a black box, so much previous work has tried to lift the veil of BERT and understand the functionality of each layer. In this paper, we found that removing or duplicating most layers in BERT would not change their outputs. This fact remains true across a wide variety of BERT-based models. Based on this observation, we propose a quite simple method to boost the performance of BERT. By duplicating some layers in the BERT-based models to make it deeper (no extra training required in this step), they obtain better performance in the down-stream tasks after fine-tuning.\nGloVe: Global Vectors for Word Representation (Jeffrey Pennington et al., 2014) Jeffrey Pennington, R. Socher, Christopher D. Manning. (2014)\nGloVe: Global Vectors for Word Representation\nEMNLP\nPaper Link\nInfluential Citation Count (3451), SS-ID (f37e1b62a767a307c046404ca96bc140b3e68cb5)\nABSTRACT\nRecent methods for learning vector space representations of words have succeeded in capturing fine-grained semantic and syntactic regularities using vector arithmetic, but the origin of these regularities has remained opaque. We analyze and make explicit the model properties needed for such regularities to emerge in word vectors. The result is a new global logbilinear regression model that combines the advantages of the two major model families in the literature: global matrix factorization and local context window methods. Our model efficiently leverages statistical information by training only on the nonzero elements in a word-word cooccurrence matrix, rather than on the entire sparse matrix or on individual context windows in a large corpus. The model produces a vector space with meaningful substructure, as evidenced by its performance of 75% on a recent word analogy task. It also outperforms related models on similarity tasks and named entity recognition.\nProbing Neural Network Comprehension of Natural Language Arguments (Timothy Niven et al., 2019) Timothy Niven, Hung-Yu Kao. (2019)\nProbing Neural Network Comprehension of Natural Language Arguments\nACL\nPaper Link\nInfluential Citation Count (12), SS-ID (f3b89e9a2b8ce1b6058e6984c3556bc2dded0938)\nABSTRACT\nWe are surprised to find that BERT’s peak performance of 77% on the Argument Reasoning Comprehension Task reaches just three points below the average untrained human baseline. However, we show that this result is entirely accounted for by exploitation of spurious statistical cues in the dataset. We analyze the nature of these cues and demonstrate that a range of models all exploit them. This analysis informs the construction of an adversarial dataset on which all models achieve random accuracy. Our adversarial dataset provides a more robust assessment of argument comprehension and should be adopted as the standard in future work.\nReducing Transformer Depth on Demand with Structured Dropout (Angela Fan et al., 2019) Angela Fan, Edouard Grave, Armand Joulin. (2019)\nReducing Transformer Depth on Demand with Structured Dropout\nICLR\nPaper Link\nInfluential Citation Count (47), SS-ID (f4a8480cffa491020bdbb8c4c4e7a7e923b1c2c1)\nABSTRACT\nOverparameterized transformer networks have obtained state of the art results in various natural language processing tasks, such as machine translation, language modeling, and question answering. These models contain hundreds of millions of parameters, necessitating a large amount of computation and making them prone to overfitting. In this work, we explore LayerDrop, a form of structured dropout, which has a regularization effect during training and allows for efficient pruning at inference time. In particular, we show that it is possible to select sub-networks of any depth from one large network without having to finetune them and with limited impact on performance. We demonstrate the effectiveness of our approach by improving the state of the art on machine translation, language modeling, summarization, question answering, and language understanding benchmarks. Moreover, we show that our approach leads to small BERT-like models of higher quality compared to training from scratch or using distillation.\nInformation-Theoretic Probing with Minimum Description Length (Elena Voita et al., 2020) Elena Voita, Ivan Titov. (2020)\nInformation-Theoretic Probing with Minimum Description Length\nEMNLP\nPaper Link\nInfluential Citation Count (13), SS-ID (f4b585c9a79dfce0807b445a09036ea0f9cbcdce)\nABSTRACT\nTo measure how well pretrained representations encode some linguistic property, it is common to use accuracy of a probe, i.e. a classifier trained to predict the property from the representations. Despite widespread adoption of probes, differences in their accuracy fail to adequately reflect differences in representations. For example, they do not substantially favour pretrained representations over randomly initialized ones. Analogously, their accuracy can be similar when probing for genuine linguistic labels and probing for random synthetic tasks. To see reasonable differences in accuracy with respect to these random baselines, previous work had to constrain either the amount of probe training data or its model size. Instead, we propose an alternative to the standard probes, information-theoretic probing with minimum description length (MDL). With MDL probing, training a probe to predict labels is recast as teaching it to effectively transmit the data. Therefore, the measure of interest changes from probe accuracy to the description length of labels given representations. In addition to probe quality, the description length evaluates \u0026ldquo;the amount of effort\u0026rdquo; needed to achieve the quality. This amount of effort characterizes either (i) size of a probing model, or (ii) the amount of data needed to achieve the high quality. We consider two methods for estimating MDL which can be easily implemented on top of the standard probing pipelines: variational coding and online coding. We show that these methods agree in results and are more informative and stable than the standard probes.\nAdaptively Sparse Transformers (Gonçalo M. Correia et al., 2019) Gonçalo M. Correia, Vlad Niculae, André F. T. Martins. (2019)\nAdaptively Sparse Transformers\nEMNLP\nPaper Link\nInfluential Citation Count (18), SS-ID (f6390beca54411b06f3bde424fb983a451789733)\nABSTRACT\nAttention mechanisms have become ubiquitous in NLP. Recent architectures, notably the Transformer, learn powerful context-aware word representations through layered, multi-headed attention. The multiple heads learn diverse types of word relationships. However, with standard softmax attention, all attention heads are dense, assigning a non-zero weight to all context words. In this work, we introduce the adaptively sparse Transformer, wherein attention heads have flexible, context-dependent sparsity patterns. This sparsity is accomplished by replacing softmax with alpha-entmax: a differentiable generalization of softmax that allows low-scoring words to receive precisely zero weight. Moreover, we derive a method to automatically learn the alpha parameter – which controls the shape and sparsity of alpha-entmax – allowing attention heads to choose between focused or spread-out behavior. Our adaptively sparse Transformer improves interpretability and head diversity when compared to softmax Transformers on machine translation datasets. Findings of the quantitative and qualitative analysis of our approach include that heads in different layers learn different sparsity preferences and tend to be more diverse in their attention distributions than softmax Transformers. Furthermore, at no cost in accuracy, sparsity in attention heads helps to uncover different head specializations.\nUniLMv2: Pseudo-Masked Language Models for Unified Language Model Pre-Training (Hangbo Bao et al., 2020) Hangbo Bao, Li Dong, Furu Wei, Wenhui Wang, Nan Yang, Xiaodong Liu, Yu Wang, Songhao Piao, Jianfeng Gao, Ming Zhou, H. Hon. (2020)\nUniLMv2: Pseudo-Masked Language Models for Unified Language Model Pre-Training\nICML\nPaper Link\nInfluential Citation Count (23), SS-ID (f64e1d6bc13aae99aab5449fc9ae742a9ba7761e)\nABSTRACT\nWe propose to pre-train a unified language model for both autoencoding and partially autoregressive language modeling tasks using a novel training procedure, referred to as a pseudo-masked language model (PMLM). Given an input text with masked tokens, we rely on conventional masks to learn inter-relations between corrupted tokens and context via autoencoding, and pseudo masks to learn intra-relations between masked spans via partially autoregressive modeling. With well-designed position embeddings and self-attention masks, the context encodings are reused to avoid redundant computation. Moreover, conventional masks used for autoencoding provide global masking information, so that all the position embeddings are accessible in partially autoregressive language modeling. In addition, the two tasks pre-train a unified language model as a bidirectional encoder and a sequence-to-sequence decoder, respectively. Our experiments show that the unified language models pre-trained using PMLM achieve new state-of-the-art results on a wide range of natural language understanding and generation tasks across several widely used benchmarks.\nInducing Relational Knowledge from BERT (Zied Bouraoui et al., 2019) Zied Bouraoui, José Camacho-Collados, S. Schockaert. (2019)\nInducing Relational Knowledge from BERT\nAAAI\nPaper Link\nInfluential Citation Count (10), SS-ID (f67fcbb1aec92ae293998ddfd904f61a31bef334)\nABSTRACT\nOne of the most remarkable properties of word embeddings is the fact that they capture certain types of semantic and syntactic relationships. Recently, pre-trained language models such as BERT have achieved groundbreaking results across a wide range of Natural Language Processing tasks. However, it is unclear to what extent such models capture relational knowledge beyond what is already captured by standard word embeddings. To explore this question, we propose a methodology for distilling relational knowledge from a pre-trained language model. Starting from a few seed instances of a given relation, we first use a large text corpus to find sentences that are likely to express this relation. We then use a subset of these extracted sentences as templates. Finally, we fine-tune a language model to predict whether a given word pair is likely to be an instance of some relation, when given an instantiated template for that relation as input.\nLinguistic Knowledge and Transferability of Contextual Representations (Nelson F. Liu et al., 2019) Nelson F. Liu, Matt Gardner, Y. Belinkov, Matthew E. Peters, Noah A. Smith. (2019)\nLinguistic Knowledge and Transferability of Contextual Representations\nNAACL\nPaper Link\nInfluential Citation Count (108), SS-ID (f6fbb6809374ca57205bd2cf1421d4f4fa04f975)\nABSTRACT\nContextual word representations derived from large-scale neural language models are successful across a diverse set of NLP tasks, suggesting that they encode useful and transferable features of language. To shed light on the linguistic knowledge they capture, we study the representations produced by several recent pretrained contextualizers (variants of ELMo, the OpenAI transformer language model, and BERT) with a suite of sixteen diverse probing tasks. We find that linear models trained on top of frozen contextual representations are competitive with state-of-the-art task-specific models in many cases, but fail on tasks requiring fine-grained linguistic knowledge (e.g., conjunct identification). To investigate the transferability of contextual word representations, we quantify differences in the transferability of individual layers within contextualizers, especially between recurrent neural networks (RNNs) and transformers. For instance, higher layers of RNNs are more task-specific, while transformer layers do not exhibit the same monotonic trend. In addition, to better understand what makes contextual word representations transferable, we compare language model pretraining with eleven supervised pretraining tasks. For any given task, pretraining on a closely related task yields better performance than language model pretraining (which is better on average) when the pretraining dataset is fixed. However, language model pretraining on more data gives the best results.\nCommonsense Knowledge Mining from Pretrained Models (Joshua Feldman et al., 2019) Joshua Feldman, Joe Davison, Alexander M. Rush. (2019)\nCommonsense Knowledge Mining from Pretrained Models\nEMNLP\nPaper Link\nInfluential Citation Count (17), SS-ID (f98e135986414cccf29aec593d547c0656e4d82c)\nABSTRACT\nInferring commonsense knowledge is a key challenge in machine learning. Due to the sparsity of training data, previous work has shown that supervised methods for commonsense knowledge mining underperform when evaluated on novel data. In this work, we develop a method for generating commonsense knowledge using a large, pre-trained bidirectional language model. By transforming relational triples into masked sentences, we can use this model to rank a triple’s validity by the estimated pointwise mutual information between the two entities. Since we do not update the weights of the bidirectional model, our approach is not biased by the coverage of any one commonsense knowledge base. Though we do worse on a held-out test set than models explicitly trained on a corresponding training set, our approach outperforms these methods when mining commonsense knowledge from new sources, suggesting that our unsupervised technique generalizes better than current supervised approaches.\nGreen AI (Roy Schwartz et al., 2019) Roy Schwartz, Jesse Dodge, Noah Smith, Oren Etzioni. (2019)\nGreen AI\nCommun. ACM\nPaper Link\nInfluential Citation Count (17), SS-ID (fb73b93de3734a996829caf31e4310e0054e9c6b)\nABSTRACT\nCreating efficiency in AI research will decrease its carbon footprint and increase its inclusivity as deep learning study should not require the deepest pockets.\n","date":"May 6, 2022","hero":"/blog-akitenkrad/posts/papers/202205/20220506021208/hero.jpg","permalink":"https://akitenkrad.github.io/blog-akitenkrad/posts/papers/202205/20220506021208/","summary":"Round-1: Overview Round-2: Model Implementation Details Round-3: Experiments Citation Rogers, A., Kovaleva, O., \u0026amp; Rumshisky, A. (2020).\nA Primer in BERTology: What We Know About How BERT Works.\nTransactions of the Association for Computational Linguistics, 8, 842–866.\nPaper Link Abstract Transformer-based models have pushed state of the art in many areas of NLP, but our understanding of what is behind their success is still limited. This paper is the first survey of over 150 studies of the popular BERT model.","tags":["At:Round-1","published:2020","Survey","BERT","BERTology"],"title":"A Primer in BERTology: What We Know About How BERT Works"},{"categories":null,"contents":" Round-1: Overview Round-2: Model Implementation Details Round-3: Experiments Citation Karpukhin, V., Oğuz, B., Min, S., Lewis, P., Wu, L., Edunov, S., Chen, D., \u0026amp; Yih, W. (2020).\nDense Passage Retrieval for Open-Domain Question Answering.\nPaper Link Abstract Open-domain question answering relies on efficient passage retrieval to select candidate contexts, where traditional sparse vector space models, such as TF-IDF or BM25, are the de facto method. In this work, we show that retrieval can be practically implemented using dense representations alone, where embeddings are learned from a small number of questions and passages by a simple dual-encoder framework. When evaluated on a wide range of open-domain QA datasets, our dense retriever outperforms a strong Lucene-BM25 system largely by 9%-19% absolute in terms of top-20 passage retrieval accuracy, and helps our end-to-end QA system establish new state-of-the-art on multiple open-domain QA benchmarks.\nWhat\u0026rsquo;s New QAタスクにおいて，追加で事前学習せずにDense Embeddingを学習する方法（Deep Passage Retriever）を提案 QuestionとPassageを別々にEmbeddingするDual Encoderモデルにおいて，効率的な学習方法を採用 Deep Passage Retrieverで，既存手法（TF-IDF，BM25）を上回る精度を達成 上記の観点を複数のQAデータセットで検証 Dataset Natural Questions Kwiatkowski, T. et al. (2019).\nNatural Questions: A Benchmark for Question Answering Research.\nTransactions of the Association for Computational Linguistics, 7, 453–466.\nhttps://doi.org/10.1162/TACL_A_00276 TriviaQA Joshi, M., Choi, E., Weld, D. S., \u0026amp; Zettlemoyer, L. (2017).\nTriviaQA: A Large Scale Distantly Supervised Challenge Dataset for Reading Comprehension.\nhttps://doi.org/10.48550/arxiv.1705.03551 WebQuestions Berant, J., Chou, A. K., Frostig, R., \u0026amp; Liang, P. (2013).\nSemantic Parsing on Freebase from Question-Answer Pairs.\nEMNLP. Curated-TREC Baudiš, P., \u0026amp; Šedivý, J. (2015).\nModeling of the question answering task in the YodaQA system.\nLecture Notes in Computer Science (Including Subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics), 9283, 222–228.\nhttps://doi.org/10.1007/978-3-319-24027-5_20 SQuAD v1.1 Rajpurkar, P., Zhang, J., Lopyrev, K., \u0026amp; Liang, P. (2016).\nSQuAD: 100,000+ Questions for Machine Comprehension of Text.\nEMNLP 2016 - Conference on Empirical Methods in Natural Language Processing, Proceedings, 2383–2392.\nhttps://doi.org/10.18653/V1/D16-1264 Dataset Summary\nDataset Train(original) Train(for DPR) Dev Test Natural Questions 79,168 58,880 8,757 3,610 TriviaQA 78,785 60,413 8,837 11,313 WebQuestions 3,417 2,474 361 2,032 CuratedTREC 1,353 1,125 133 694 SQuAD 78,713 70,096 8,886 10,570 Model Description TBD\nTraining Settings Results SQuADを除いて，DPRは軒並みBM25よりも良い精度を出している SQuADでは，アノテーターはPassageを見た後にQuestionを記載する手順になっているため，PassageとQuestionが非常に似たものになり，計算上，BM25で精度が高くなりやすいと考えられる SQuADではWikipediaの記事中から500件強を収集して構築されたもので，学習データにかなりバイアスがあると考えられる References Scaling question answering to the web (Cody C. T. Kwok et al., 2001) Cody C. T. Kwok, Oren Etzioni, Daniel S. Weld. (2001)\nScaling question answering to the web\nTOIS\nPaper Link\nInfluential Citation Count (22), SS-ID (016e9cc85c658c6a69710b4c617609ad2a5d3a74)\nABSTRACT\nThe wealth of information on the web makes it an attractive resource for seeking quick answers to simple, factual questions such as \u0026amp;quote;who was the first American in space?\u0026amp;quote; or \u0026amp;quote;what is the second tallest mountain in the world?\u0026amp;quote; Yet today\u0026rsquo;s most advanced web search services (e.g., Google and AskJeeves) make it surprisingly tedious to locate answers to such questions. In this paper, we extend question-answering techniques, first studied in the information retrieval literature, to the web and experimentally evaluate their performance.First we introduce Mulder, which we believe to be the first general-purpose, fully-automated question-answering system available on the web. Second, we describe Mulder\u0026rsquo;s architecture, which relies on multiple search-engine queries, natural-language parsing, and a novel voting procedure to yield reliable answers coupled with high recall. Finally, we compare Mulder\u0026rsquo;s performance to that of Google and AskJeeves on questions drawn from the TREC-8 question answering track. We find that Mulder\u0026rsquo;s recall is more than a factor of three higher than that of AskJeeves. In addition, we find that Google requires 6.6 times as much user effort to achieve the same level of recall as Mulder.\nSQuAD: 100,000\u0026#43; Questions for Machine Comprehension of Text (Pranav Rajpurkar et al., 2016) Pranav Rajpurkar, Jian Zhang, Konstantin Lopyrev, Percy Liang. (2016)\nSQuAD: 100,000+ Questions for Machine Comprehension of Text\nEMNLP\nPaper Link\nInfluential Citation Count (1063), SS-ID (05dd7254b632376973f3a1b4d39485da17814df5)\nABSTRACT\nWe present the Stanford Question Answering Dataset (SQuAD), a new reading comprehension dataset consisting of 100,000+ questions posed by crowdworkers on a set of Wikipedia articles, where the answer to each question is a segment of text from the corresponding reading passage. We analyze the dataset to understand the types of reasoning required to answer the questions, leaning heavily on dependency and constituency trees. We build a strong logistic regression model, which achieves an F1 score of 51.0%, a significant improvement over a simple baseline (20%). However, human performance (86.8%) is much higher, indicating that the dataset presents a good challenge problem for future research. The dataset is freely available at this https URL\nMulti-passage BERT: A Globally Normalized BERT Model for Open-domain Question Answering (Zhiguo Wang et al., 2019) Zhiguo Wang, Patrick Ng, Xiaofei Ma, Ramesh Nallapati, Bing Xiang. (2019)\nMulti-passage BERT: A Globally Normalized BERT Model for Open-domain Question Answering\nEMNLP\nPaper Link\nInfluential Citation Count (16), SS-ID (0cf535110808d33fdf4db3ffa1621dea16e29c0d)\nABSTRACT\nBERT model has been successfully applied to open-domain QA tasks. However, previous work trains BERT by viewing passages corresponding to the same question as independent training instances, which may cause incomparable scores for answers from different passages. To tackle this issue, we propose a multi-passage BERT model to globally normalize answer scores across all passages of the same question, and this change enables our QA model find better answers by utilizing more passages. In addition, we find that splitting articles into passages with the length of 100 words by sliding window improves performance by 4%. By leveraging a passage ranker to select high-quality passages, multi-passage BERT gains additional 2%. Experiments on four standard benchmarks showed that our multi-passage BERT outperforms all state-of-the-art models on all benchmarks. In particular, on the OpenSQuAD dataset, our model gains 21.4% EM and 21.5% F1 over all non-BERT models, and 5.8% EM and 6.5% F1 over BERT-based models.\nReading Wikipedia to Answer Open-Domain Questions (Danqi Chen et al., 2017) Danqi Chen, Adam Fisch, J. Weston, Antoine Bordes. (2017)\nReading Wikipedia to Answer Open-Domain Questions\nACL\nPaper Link\nInfluential Citation Count (280), SS-ID (104715e1097b7ebee436058bfd9f45540f269845)\nABSTRACT\nThis paper proposes to tackle open- domain question answering using Wikipedia as the unique knowledge source: the answer to any factoid question is a text span in a Wikipedia article. This task of machine reading at scale combines the challenges of document retrieval (finding the relevant articles) with that of machine comprehension of text (identifying the answer spans from those articles). Our approach combines a search component based on bigram hashing and TF-IDF matching with a multi-layer recurrent neural network model trained to detect answers in Wikipedia paragraphs. Our experiments on multiple existing QA datasets indicate that (1) both modules are highly competitive with respect to existing counterparts and (2) multitask learning using distant supervision on their combination is an effective complete system on this challenging task.\nPerformance Issues and Error Analysis in an Open-Domain Question Answering System (D. Moldovan et al., 2002) D. Moldovan, Marius Pasca, S. Harabagiu, M. Surdeanu. (2002)\nPerformance Issues and Error Analysis in an Open-Domain Question Answering System\nACL\nPaper Link\nInfluential Citation Count (12), SS-ID (1503e5c5adb0a3063d09b0f398f724d7dd26a979)\nABSTRACT\nThis paper presents an in-depth analysis of a state-of-the-art Question Answering system. Several scenarios are examined: (1) the performance of each module in a serial baseline system, (2) the impact of feedbacks and the insertion of a logic prover, and (3) the impact of various lexical resources. The main conclusion is that the overall performance depends on the depth of natural language processing resources and the tools used for answer finding.\nKnowledge Guided Text Retrieval and Reading for Open Domain Question Answering (Sewon Min et al., 2019) Sewon Min, Danqi Chen, Luke Zettlemoyer, Hannaneh Hajishirzi. (2019)\nKnowledge Guided Text Retrieval and Reading for Open Domain Question Answering\nArXiv\nPaper Link\nInfluential Citation Count (4), SS-ID (1715aa36ccc851310308630d4db61dcecf49a50d)\nABSTRACT\nWe introduce an approach for open-domain question answering (QA) that retrieves and reads a passage graph, where vertices are passages of text and edges represent relationships that are derived from an external knowledge base or co-occurrence in the same article. Our goals are to boost coverage by using knowledge-guided retrieval to find more relevant passages than text-matching methods, and to improve accuracy by allowing for better knowledge-guided fusion of information across related passages. Our graph retrieval method expands a set of seed keyword-retrieved passages by traversing the graph structure of the knowledge base. Our reader extends a BERT-based architecture and updates passage representations by propagating information from related passages and their relations, instead of reading each passage in isolation. Experiments on three open-domain QA datasets, WebQuestions, Natural Questions and TriviaQA, show improved performance over non-graph baselines by 2-11% absolute. Our approach also matches or exceeds the state-of-the-art in every case, without using an expensive end-to-end training regime.\nNatural Questions: A Benchmark for Question Answering Research (T. Kwiatkowski et al., 2019) T. Kwiatkowski, Jennimaria Palomaki, Olivia Redfield, Michael Collins, Ankur P. Parikh, Chris Alberti, D. Epstein, Illia Polosukhin, Jacob Devlin, Kenton Lee, Kristina Toutanova, Llion Jones, Matthew Kelcey, Ming-Wei Chang, Andrew M. Dai, Jakob Uszkoreit, Quoc V. Le, Slav Petrov. (2019)\nNatural Questions: A Benchmark for Question Answering Research\nTACL\nPaper Link\nInfluential Citation Count (121), SS-ID (17dbd7b72029181327732e4d11b52a08ed4630d0)\nABSTRACT\nWe present the Natural Questions corpus, a question answering data set. Questions consist of real anonymized, aggregated queries issued to the Google search engine. An annotator is presented with a question along with a Wikipedia page from the top 5 search results, and annotates a long answer (typically a paragraph) and a short answer (one or more entities) if present on the page, or marks null if no long/short answer is present. The public release consists of 307,373 training examples with single annotations; 7,830 examples with 5-way annotations for development data; and a further 7,842 examples with 5-way annotated sequestered as test data. We present experiments validating quality of the data. We also describe analysis of 25-way annotations on 302 examples, giving insights into human variability on the annotation task. We introduce robust metrics for the purposes of evaluating question answering systems; demonstrate high human upper bounds on these metrics; and establish baseline results using competitive methods drawn from related literature.\nLearning and Inference via Maximum Inner Product Search (Stephen Mussmann et al., 2016) Stephen Mussmann, S. Ermon. (2016)\nLearning and Inference via Maximum Inner Product Search\nICML\nPaper Link\nInfluential Citation Count (2), SS-ID (2040c5de2344b9b14f1bbfff372f708639cca739)\nABSTRACT\nA large class of commonly used probabilistic models known as log-linear models are defined up to a normalization constant. Typical learning algorithms for such models require solving a sequence of probabilistic inference queries. These inferences are typically intractable, and are a major bottleneck for learning models with large output spaces. In this paper, we provide a new approach for amortizing the cost of a sequence of related inference queries, such as the ones arising during learning. Our technique relies on a surprising connection with algorithms developed in the past two decades for similarity search in large data bases. Our approach achieves improved running times with provable approximation guarantees. We show that it performs well both on synthetic data and neural language models with large output spaces.\nIndexing by Latent Semantic Analysis (S. Deerwester et al., 1990) S. Deerwester, S. Dumais, T. Landauer, G. Furnas, R. Harshman. (1990)\nIndexing by Latent Semantic Analysis\nJ. Am. Soc. Inf. Sci.\nPaper Link\nInfluential Citation Count (770), SS-ID (20a80a7356859daa4170fb4da6b87b84adbb547f)\nABSTRACT\nA new method for automatic indexing and retrieval is described. The approach is to take advantage of implicit higher-order structure in the association of terms with documents (“semantic structure”) in order to improve the detection of relevant documents on the basis of terms found in queries. The particular technique used is singular-value decomposition, in which a large term by document matrix is decomposed into a set of ca. 100 orthogonal factors from which the original matrix can be approximated by linear combination. Documents are represented by ca. 100 item vectors of factor weights. Queries are represented as pseudo-document vectors formed from weighted combinations of terms, and documents with supra-threshold cosine values are returned. initial tests find this completely automatic method for retrieval to be promising.\nBillion-Scale Similarity Search with GPUs (Jeff Johnson et al., 2017) Jeff Johnson, M. Douze, H. Jégou. (2017)\nBillion-Scale Similarity Search with GPUs\nIEEE Transactions on Big Data\nPaper Link\nInfluential Citation Count (166), SS-ID (2cbb8de53759e75411bc528518947a3094fbce3a)\nABSTRACT\nSimilarity search finds application in database systems handling complex data such as images or videos, which are typically represented by high-dimensional features and require specific indexing structures. This paper tackles the problem of better utilizing GPUs for this task. While GPUs excel at data parallel tasks such as distance computation, prior approaches in this domain are bottlenecked by algorithms that expose less parallelism, such as $k$mml:mathmml:mik\u0026lt;/mml:mi\u0026gt;\u0026lt;/mml:math\u0026gt;-min selection, or make poor use of the memory hierarchy. We propose a novel design for $k$mml:mathmml:mik\u0026lt;/mml:mi\u0026gt;\u0026lt;/mml:math\u0026gt;-selection. We apply it in different similarity search scenarios, by optimizing brute-force, approximate and compressed-domain search based on product quantization. In all these setups, we outperform the state of the art by large margins. Our implementation operates at up to 55 percent of theoretical peak performance, enabling a nearest neighbor implementation that is 8.5 × faster than prior GPU state of the art. It enables the construction of a high accuracy $k$mml:mathmml:mik\u0026lt;/mml:mi\u0026gt;\u0026lt;/mml:math\u0026gt;-NN graph on 95 million images from the Yfcc100M dataset in 35 minutes, and of a graph connecting 1 billion vectors in less than 12 hours on 4 Maxwell Titan X GPUs. We have open-sourced our approach for the sake of comparison and reproducibility.\nEnd-to-End Open-Domain Question Answering with BERTserini (Wei Yang et al., 2019) Wei Yang, Yuqing Xie, Aileen Lin, Xingyu Li, Luchen Tan, Kun Xiong, Ming Li, Jimmy J. Lin. (2019)\nEnd-to-End Open-Domain Question Answering with BERTserini\nNAACL\nPaper Link\nInfluential Citation Count (45), SS-ID (2fe7dba5a58aee5156594b4d78634ecd6c7dcabd)\nABSTRACT\nWe demonstrate an end-to-end question answering system that integrates BERT with the open-source Anserini information retrieval toolkit. In contrast to most question answering and reading comprehension models today, which operate over small amounts of input text, our system integrates best practices from IR with a BERT-based reader to identify answers from a large corpus of Wikipedia articles in an end-to-end fashion. We report large improvements over previous results on a standard benchmark test collection, showing that fine-tuning pretrained BERT with SQuAD is sufficient to achieve high accuracy in identifying answer spans.\nA Discrete Hard EM Approach for Weakly Supervised Question Answering (Sewon Min et al., 2019) Sewon Min, Danqi Chen, Hannaneh Hajishirzi, Luke Zettlemoyer. (2019)\nA Discrete Hard EM Approach for Weakly Supervised Question Answering\nEMNLP\nPaper Link\nInfluential Citation Count (19), SS-ID (30eff53e981695c7296d258b8dc44b4c7b482a0c)\nABSTRACT\nMany question answering (QA) tasks only provide weak supervision for how the answer should be computed. For example, TriviaQA answers are entities that can be mentioned multiple times in supporting documents, while DROP answers can be computed by deriving many different equations from numbers in the reference text. In this paper, we show it is possible to convert such tasks into discrete latent variable learning problems with a precomputed, task-specific set of possible solutions (e.g. different mentions or equations) that contains one correct option. We then develop a hard EM learning scheme that computes gradients relative to the most likely solution at each update. Despite its simplicity, we show that this approach significantly outperforms previous methods on six QA tasks, including absolute gains of 2–10%, and achieves the state-of-the-art on five of them. Using hard updates instead of maximizing marginal likelihood is key to these results as it encourages the model to find the one correct answer, which we show through detailed qualitative analysis.\nPoly-encoders: Architectures and Pre-training Strategies for Fast and Accurate Multi-sentence Scoring (Samuel Humeau et al., 2020) Samuel Humeau, Kurt Shuster, Marie-Anne Lachaux, J. Weston. (2020)\nPoly-encoders: Architectures and Pre-training Strategies for Fast and Accurate Multi-sentence Scoring\nICLR\nPaper Link\nInfluential Citation Count (28), SS-ID (3511facfa0230b8c3ba5b72d9c11bc58f6ed6ecc)\nABSTRACT\nThe use of deep pre-trained transformers has led to remarkable progress in a number of applications (Devlin et al., 2018). For tasks that make pairwise comparisons between sequences, matching a given input with a corresponding label, two approaches are common: Cross-encoders performing full self-attention over the pair and Bi-encoders encoding the pair separately. The former often performs better, but is too slow for practical use. In this work, we develop a new transformer architecture, the Poly-encoder, that learns global rather than token level self-attention features. We perform a detailed comparison of all three approaches, including what pre-training and fine-tuning strategies work best. We show our models achieve state-of-the-art results on four tasks; that Poly-encoders are faster than Cross-encoders and more accurate than Bi-encoders; and that the best results are obtained by pre-training on large datasets similar to the downstream tasks.\nBART: Denoising Sequence-to-Sequence Pre-training for Natural Language Generation, Translation, and Comprehension (M. Lewis et al., 2019) M. Lewis, Yinhan Liu, Naman Goyal, Marjan Ghazvininejad, Abdelrahman Mohamed, Omer Levy, Veselin Stoyanov, Luke Zettlemoyer. (2019)\nBART: Denoising Sequence-to-Sequence Pre-training for Natural Language Generation, Translation, and Comprehension\nACL\nPaper Link\nInfluential Citation Count (482), SS-ID (395de0bd3837fdf4b4b5e5f04835bcc69c279481)\nABSTRACT\nWe present BART, a denoising autoencoder for pretraining sequence-to-sequence models. BART is trained by (1) corrupting text with an arbitrary noising function, and (2) learning a model to reconstruct the original text. It uses a standard Tranformer-based neural machine translation architecture which, despite its simplicity, can be seen as generalizing BERT (due to the bidirectional encoder), GPT (with the left-to-right decoder), and other recent pretraining schemes. We evaluate a number of noising approaches, finding the best performance by both randomly shuffling the order of sentences and using a novel in-filling scheme, where spans of text are replaced with a single mask token. BART is particularly effective when fine tuned for text generation but also works well for comprehension tasks. It matches the performance of RoBERTa on GLUE and SQuAD, and achieves new state-of-the-art results on a range of abstractive dialogue, question answering, and summarization tasks, with gains of up to 3.5 ROUGE. BART also provides a 1.1 BLEU increase over a back-translation system for machine translation, with only target language pretraining. We also replicate other pretraining schemes within the BART framework, to understand their effect on end-task performance.\nExploring the Limits of Transfer Learning with a Unified Text-to-Text Transformer (Colin Raffel et al., 2019) Colin Raffel, Noam M. Shazeer, Adam Roberts, Katherine Lee, Sharan Narang, Michael Matena, Yanqi Zhou, Wei Li, Peter J. Liu. (2019)\nExploring the Limits of Transfer Learning with a Unified Text-to-Text Transformer\nJ. Mach. Learn. Res.\nPaper Link\nInfluential Citation Count (615), SS-ID (3cfb319689f06bf04c2e28399361f414ca32c4b3)\nABSTRACT\nTransfer learning, where a model is first pre-trained on a data-rich task before being fine-tuned on a downstream task, has emerged as a powerful technique in natural language processing (NLP). The effectiveness of transfer learning has given rise to a diversity of approaches, methodology, and practice. In this paper, we explore the landscape of transfer learning techniques for NLP by introducing a unified framework that converts every language problem into a text-to-text format. Our systematic study compares pre-training objectives, architectures, unlabeled datasets, transfer approaches, and other factors on dozens of language understanding tasks. By combining the insights from our exploration with scale and our new \u0026ldquo;Colossal Clean Crawled Corpus\u0026rdquo;, we achieve state-of-the-art results on many benchmarks covering summarization, question answering, text classification, and more. To facilitate future work on transfer learning for NLP, we release our dataset, pre-trained models, and code.\nEfficient Natural Language Response Suggestion for Smart Reply (Matthew Henderson et al., 2017) Matthew Henderson, Rami Al-Rfou, B. Strope, Yun-Hsuan Sung, László Lukács, Ruiqi Guo, Sanjiv Kumar, Balint Miklos, R. Kurzweil. (2017)\nEfficient Natural Language Response Suggestion for Smart Reply\nArXiv\nPaper Link\nInfluential Citation Count (13), SS-ID (435553998fbef790b5bed3491a8f634d9ec5cfa2)\nABSTRACT\nThis paper presents a computationally efficient machine-learned method for natural language response suggestion. Feed-forward neural networks using n-gram embedding features encode messages into vectors which are optimized to give message-response pairs a high dot-product value. An optimized search finds response suggestions. The method is evaluated in a large-scale commercial e-mail application, Inbox by Gmail. Compared to a sequence-to-sequence approach, the new system achieves the same quality at a small fraction of the computational requirements and latency.\nProgressively Pretrained Dense Corpus Index for Open-Domain Question Answering (Wenhan Xiong et al., 2020) Wenhan Xiong, Hong Wang, W. Wang. (2020)\nProgressively Pretrained Dense Corpus Index for Open-Domain Question Answering\nEACL\nPaper Link\nInfluential Citation Count (1), SS-ID (469d92f195aebfa09e9b411ad92b3c879bcd1eba)\nABSTRACT\nCommonly used information retrieval methods such as TF-IDF in open-domain question answering (QA) systems are insufficient to capture deep semantic matching that goes beyond lexical overlaps. Some recent studies consider the retrieval process as maximum inner product search (MIPS) using dense question and paragraph representations, achieving promising results on several information-seeking QA datasets. However, the pretraining of the dense vector representations is highly resource-demanding, e.g., requires a very large batch size and lots of training steps. In this work, we propose a sample-efficient method to pretrain the paragraph encoder. First, instead of using heuristically created pseudo question-paragraph pairs for pretraining, we use an existing pretrained sequence-to-sequence model to build a strong question generator that creates high-quality pretraining data. Second, we propose a simple progressive pretraining algorithm to ensure the existence of effective negative samples in each batch. Across three open-domain QA datasets, our method consistently outperforms a strong dense retrieval baseline that uses 6 times more computation for training. On two of the datasets, our method achieves more than 4-point absolute improvement in terms of answer exact match.\nThe Probabilistic Relevance Framework: BM25 and Beyond (S. Robertson et al., 2009) S. Robertson, H. Zaragoza. (2009)\nThe Probabilistic Relevance Framework: BM25 and Beyond\nFound. Trends Inf. Retr.\nPaper Link\nInfluential Citation Count (278), SS-ID (47ced790a563344efae66588b5fb7fe6cca29ed3)\nABSTRACT\nThe Probabilistic Relevance Framework (PRF) is a formal framework for document retrieval, grounded in work done in the 1970—1980s, which led to the development of one of the most successful text-retrieval algorithms, BM25. In recent years, research in the PRF has yielded new retrieval models capable of taking into account document meta-data (especially structure and link-graph information). Again, this has led to one of the most successful Web-search and corporate-search algorithms, BM25F. This work presents the PRF from a conceptual point of view, describing the probabilistic modelling assumptions behind the framework and the different ranking algorithms that result from its application: the binary independence model, relevance feedback models, BM25 and BM25F. It also discusses the relation between the PRF and other statistical models for IR, and covers some related topics, such as the use of non-textual features, and parameter optimisation for models with free parameters.\nRevealing the Importance of Semantic Retrieval for Machine Reading at Scale (Yixin Nie et al., 2019) Yixin Nie, Songhe Wang, Mohit Bansal. (2019)\nRevealing the Importance of Semantic Retrieval for Machine Reading at Scale\nEMNLP\nPaper Link\nInfluential Citation Count (20), SS-ID (4bf61dab8ad195e87b6f0496ec7bada5d37c476f)\nABSTRACT\nMachine Reading at Scale (MRS) is a challenging task in which a system is given an input query and is asked to produce a precise output by “reading” information from a large knowledge base. The task has gained popularity with its natural combination of information retrieval (IR) and machine comprehension (MC). Advancements in representation learning have led to separated progress in both IR and MC; however, very few studies have examined the relationship and combined design of retrieval and comprehension at different levels of granularity, for development of MRS systems. In this work, we give general guidelines on system design for MRS by proposing a simple yet effective pipeline system with special consideration on hierarchical semantic retrieval at both paragraph and sentence level, and their potential effects on the downstream task. The system is evaluated on both fact verification and open-domain multihop QA, achieving state-of-the-art results on the leaderboard test sets of both FEVER and HOTPOTQA. To further demonstrate the importance of semantic retrieval, we present ablation and analysis studies to quantify the contribution of neural retrieval modules at both paragraph-level and sentence-level, and illustrate that intermediate semantic retrieval modules are vital for not only effectively filtering upstream information and thus saving downstream computation, but also for shaping upstream data distribution and providing better data for downstream modeling.\nRetrieval-Augmented Generation for Knowledge-Intensive NLP Tasks (Patrick Lewis et al., 2020) Patrick Lewis, Ethan Perez, Aleksandara Piktus, Fabio Petroni, Vladimir Karpukhin, Naman Goyal, Heinrich Kuttler, M. Lewis, Wen-tau Yih, Tim Rocktäschel, Sebastian Riedel, Douwe Kiela. (2020)\nRetrieval-Augmented Generation for Knowledge-Intensive NLP Tasks\nNeurIPS\nPaper Link\nInfluential Citation Count (53), SS-ID (58ed1fbaabe027345f7bb3a6312d41c5aac63e22)\nABSTRACT\nLarge pre-trained language models have been shown to store factual knowledge in their parameters, and achieve state-of-the-art results when fine-tuned on downstream NLP tasks. However, their ability to access and precisely manipulate knowledge is still limited, and hence on knowledge-intensive tasks, their performance lags behind task-specific architectures. Additionally, providing provenance for their decisions and updating their world knowledge remain open research problems. Pre-trained models with a differentiable access mechanism to explicit non-parametric memory can overcome this issue, but have so far been only investigated for extractive downstream tasks. We explore a general-purpose fine-tuning recipe for retrieval-augmented generation (RAG) \u0026ndash; models which combine pre-trained parametric and non-parametric memory for language generation. We introduce RAG models where the parametric memory is a pre-trained seq2seq model and the non-parametric memory is a dense vector index of Wikipedia, accessed with a pre-trained neural retriever. We compare two RAG formulations, one which conditions on the same retrieved passages across the whole generated sequence, the other can use different passages per token. We fine-tune and evaluate our models on a wide range of knowledge-intensive NLP tasks and set the state-of-the-art on three open domain QA tasks, outperforming parametric seq2seq models and task-specific retrieve-and-extract architectures. For language generation tasks, we find that RAG models generate more specific, diverse and factual language than a state-of-the-art parametric-only seq2seq baseline.\nColBERT: Efficient and Effective Passage Search via Contextualized Late Interaction over BERT (O. Khattab et al., 2020) O. Khattab, M. Zaharia. (2020)\nColBERT: Efficient and Effective Passage Search via Contextualized Late Interaction over BERT\nSIGIR\nPaper Link\nInfluential Citation Count (52), SS-ID (60b8ad6177230ad5402af409a6edb5af441baeb4)\nABSTRACT\nRecent progress in Natural Language Understanding (NLU) is driving fast-paced advances in Information Retrieval (IR), largely owed to fine-tuning deep language models (LMs) for document ranking. While remarkably effective, the ranking models based on these LMs increase computational cost by orders of magnitude over prior approaches, particularly as they must feed each query-document pair through a massive neural network to compute a single relevance score. To tackle this, we present ColBERT, a novel ranking model that adapts deep LMs (in particular, BERT) for efficient retrieval. ColBERT introduces a late interaction architecture that independently encodes the query and the document using BERT and then employs a cheap yet powerful interaction step that models their fine-grained similarity. By delaying and yet retaining this fine-granular interaction, ColBERT can leverage the expressiveness of deep LMs while simultaneously gaining the ability to pre-compute document representations offline, considerably speeding up query processing. Crucially, ColBERT\u0026rsquo;s pruning-friendly interaction mechanism enables leveraging vector-similarity indexes for end-to-end retrieval directly from millions of documents. We extensively evaluate ColBERT using two recent passage search datasets. Results show that ColBERT\u0026rsquo;s effectiveness is competitive with existing BERT-based models (and outperforms every non-BERT baseline), while executing two orders-of-magnitude faster and requiring up to four orders-of-magnitude fewer FLOPs per query.\nLearning to rank using gradient descent (C. Burges et al., 2005) C. Burges, Tal Shaked, Erin Renshaw, Ari Lazier, Matt Deeds, Nicole Hamilton, Greg Hullender. (2005)\nLearning to rank using gradient descent\nICML\nPaper Link\nInfluential Citation Count (290), SS-ID (63aaf12163fe9735dfe9a69114937c4fa34f303a)\nABSTRACT\nWe investigate using gradient descent methods for learning ranking functions; we propose a simple probabilistic cost function, and we introduce RankNet, an implementation of these ideas using a neural network to model the underlying ranking function. We present test results on toy data and on data from a commercial internet search engine.\nThe TREC-8 Question Answering Track Report (E. Voorhees, 1999) E. Voorhees. (1999)\nThe TREC-8 Question Answering Track Report\nTREC\nPaper Link\nInfluential Citation Count (157), SS-ID (646d4888871aca2a25111eb2520e4c47e253b014)\nABSTRACT\nThe TREC-8 Question Answering track was the first large-scale evaluation of domain-independent question answering systems. This paper summarizes the results of the track by giving a brief overview of the different approaches taken to solve the problem. The most accurate systems found a correct response for more than 2/3 of the questions. Relatively simple bag-of-words approaches were adequate for finding answers when responses could be as long as a paragraph (250 bytes), but more sophisticated processing was necessary for more direct responses (50 bytes).\nThe TREC-8 Question Answering track was an initial e\u000bort to bring the bene\u000cts of large-scale evaluation to bear on a question answering (QA) task. The goal in the QA task is to retrieve small snippets of text that contain the actual answer to a question rather than the document lists traditionally returned by text retrieval systems. The assumption is that users would usually prefer to be given the answer rather than and the answer themselves in a document.\nThis paper summarizes the retrieval results of the track; a companion paper (\\The TREC-8 Question Answering Track Evaluation\u0026quot;) gives details about how the evaluation was implemented. By necessity, a track report can give only an overview of the different approaches used in the track. Readers are urged to consult the participants\u0026rsquo; papers elsewhere in the Proceedings for details regarding a particular approach.\nLearning to Retrieve Reasoning Paths over Wikipedia Graph for Question Answering (Akari Asai et al., 2019) Akari Asai, Kazuma Hashimoto, Hannaneh Hajishirzi, R. Socher, Caiming Xiong. (2019)\nLearning to Retrieve Reasoning Paths over Wikipedia Graph for Question Answering\nICLR\nPaper Link\nInfluential Citation Count (26), SS-ID (6580bf92ca01a403ac58f6764dc1dd7a771579d0)\nABSTRACT\nAnswering questions that require multi-hop reasoning at web-scale necessitates retrieving multiple evidence documents, one of which often has little lexical or semantic relationship to the question. This paper introduces a new graph-based recurrent retrieval approach that learns to retrieve reasoning paths over the Wikipedia graph to answer multi-hop open-domain questions. Our retriever model trains a recurrent neural network that learns to sequentially retrieve evidence paragraphs in the reasoning path by conditioning on the previously retrieved documents. Our reader model ranks the reasoning paths and extracts the answer span included in the best reasoning path. Experimental results show state-of-the-art results in three open-domain QA datasets, showcasing the effectiveness and robustness of our method. Notably, our method achieves significant improvement in HotpotQA, outperforming the previous best model by more than 14 points.\nLearning Dense Representations for Entity Retrieval (D. Gillick et al., 2019) D. Gillick, Sayali Kulkarni, L. Lansing, A. Presta, Jason Baldridge, Eugene Ie, Diego Garcia-Olano. (2019)\nLearning Dense Representations for Entity Retrieval\nCoNLL\nPaper Link\nInfluential Citation Count (10), SS-ID (6b5cb3b85fb247256b264c2732916cf129015a92)\nABSTRACT\nWe show that it is feasible to perform entity linking by training a dual encoder (two-tower) model that encodes mentions and entities in the same dense vector space, where candidate entities are retrieved by approximate nearest neighbor search. Unlike prior work, this setup does not rely on an alias table followed by a re-ranker, and is thus the first fully learned entity retrieval model. We show that our dual encoder, trained using only anchor-text links in Wikipedia, outperforms discrete alias table and BM25 baselines, and is competitive with the best comparable results on the standard TACKBP-2010 dataset. In addition, it can retrieve candidates extremely fast, and generalizes well to a new dataset derived from Wikinews. On the modeling side, we demonstrate the dramatic value of an unsupervised negative mining algorithm for this task.\nAsymmetric LSH (ALSH) for Sublinear Time Maximum Inner Product Search (MIPS) (Anshumali Shrivastava et al., 2014) Anshumali Shrivastava, Ping Li. (2014)\nAsymmetric LSH (ALSH) for Sublinear Time Maximum Inner Product Search (MIPS)\nNIPS\nPaper Link\nInfluential Citation Count (44), SS-ID (6dbffa57b3c6c5645cf701b9b444984a4b61bb57)\nABSTRACT\nWe present the first provably sublinear time algorithm for approximate \\emph{Maximum Inner Product Search} (MIPS). Our proposal is also the first hashing algorithm for searching with (un-normalized) inner product as the underlying similarity measure. Finding hashing schemes for MIPS was considered hard. We formally show that the existing Locality Sensitive Hashing (LSH) framework is insufficient for solving MIPS, and then we extend the existing LSH framework to allow asymmetric hashing schemes. Our proposal is based on an interesting mathematical phenomenon in which inner products, after independent asymmetric transformations, can be converted into the problem of approximate near neighbor search. This key observation makes efficient sublinear hashing scheme for MIPS possible. In the extended asymmetric LSH (ALSH) framework, we provide an explicit construction of provably fast hashing scheme for MIPS. The proposed construction and the extended LSH framework could be of independent theoretical interest. Our proposed algorithm is simple and easy to implement. We evaluate the method, for retrieving inner products, in the collaborative filtering task of item recommendations on Netflix and Movielens datasets.\nBreak It Down: A Question Understanding Benchmark (Tomer Wolfson et al., 2020) Tomer Wolfson, Mor Geva, Ankit Gupta, Matt Gardner, Yoav Goldberg, Daniel Deutch, Jonathan Berant. (2020)\nBreak It Down: A Question Understanding Benchmark\nTACL\nPaper Link\nInfluential Citation Count (10), SS-ID (71c908529b12ef6ee8d735127a63d48b1fc5c43c)\nABSTRACT\nUnderstanding natural language questions entails the ability to break down a question into the requisite steps for computing its answer. In this work, we introduce a Question Decomposition Meaning Representation (QDMR) for questions. QDMR constitutes the ordered list of steps, expressed through natural language, that are necessary for answering a question. We develop a crowdsourcing pipeline, showing that quality QDMRs can be annotated at scale, and release the Break dataset, containing over 83K pairs of questions and their QDMRs. We demonstrate the utility of QDMR by showing that (a) it can be used to improve open-domain question answering on the HotpotQA dataset, (b) it can be deterministically converted to a pseudo-SQL formal language, which can alleviate annotation in semantic parsing applications. Last, we use Break to train a sequence-to-sequence model with copying that parses questions into QDMR structures, and show that it substantially outperforms several natural baselines.\nModeling of the Question Answering Task in the YodaQA System (P. Baudis et al., 2015) P. Baudis, J. Sedivý. (2015)\nModeling of the Question Answering Task in the YodaQA System\nCLEF\nPaper Link\nInfluential Citation Count (17), SS-ID (7e5955481e9d197cc1cd1b64a90fbd245b88c886)\nABSTRACT\nWe briefly survey the current state of art in the field of Question Answering and present the YodaQA system, an open source framework for this task and a baseline pipeline with reasonable performance. We take a holistic approach, reviewing and aiming to integrate many different question answering task definitions and approaches concerning classes of knowledge bases, question representation and answer generation. To ease performance comparisons of general-purpose QA systems, we also propose an effort in building a new reference QA testing corpus which is a curated and extended version of the TREC corpus.\nHow Much Knowledge Can You Pack into the Parameters of a Language Model? (Adam Roberts et al., 2020) Adam Roberts, Colin Raffel, Noam M. Shazeer. (2020)\nHow Much Knowledge Can You Pack into the Parameters of a Language Model?\nEMNLP\nPaper Link\nInfluential Citation Count (38), SS-ID (80376bdec5f534be78ba82821f540590ebce5559)\nABSTRACT\nIt has recently been observed that neural language models trained on unstructured text can implicitly store and retrieve knowledge using natural language queries. In this short paper, we measure the practical utility of this approach by fine-tuning pre-trained models to answer questions without access to any external context or knowledge. We show that this approach scales surprisingly well with model size and outperforms models that explicitly look up knowledge on the open-domain variants of Natural Questions and WebQuestions. To facilitate reproducibility and future work, we release our code and trained models.\nREALM: Retrieval-Augmented Language Model Pre-Training (Kelvin Guu et al., 2020) Kelvin Guu, Kenton Lee, Z. Tung, Panupong Pasupat, Ming-Wei Chang. (2020)\nREALM: Retrieval-Augmented Language Model Pre-Training\nArXiv\nPaper Link\nInfluential Citation Count (64), SS-ID (832fff14d2ed50eb7969c4c4b976c35776548f56)\nABSTRACT\nLanguage model pre-training has been shown to capture a surprising amount of world knowledge, crucial for NLP tasks such as question answering. However, this knowledge is stored implicitly in the parameters of a neural network, requiring ever-larger networks to cover more facts. To capture knowledge in a more modular and interpretable way, we augment language model pre-training with a latent knowledge retriever, which allows the model to retrieve and attend over documents from a large corpus such as Wikipedia, used during pre-training, fine-tuning and inference. For the first time, we show how to pre-train such a knowledge retriever in an unsupervised manner, using masked language modeling as the learning signal and backpropagating through a retrieval step that considers millions of documents. We demonstrate the effectiveness of Retrieval-Augmented Language Model pre-training (REALM) by fine-tuning on the challenging task of Open-domain Question Answering (Open-QA). We compare against state-of-the-art models for both explicit and implicit knowledge storage on three popular Open-QA benchmarks, and find that we outperform all previous methods by a significant margin (4-16% absolute accuracy), while also providing qualitative benefits such as interpretability and modularity.\nPassage Re-ranking with BERT (Rodrigo Nogueira et al., 2019) Rodrigo Nogueira, Kyunghyun Cho. (2019)\nPassage Re-ranking with BERT\nArXiv\nPaper Link\nInfluential Citation Count (89), SS-ID (85e07116316e686bf787114ba10ca60f4ea7c5b2)\nABSTRACT\nRecently, neural models pretrained on a language modeling task, such as ELMo (Peters et al., 2017), OpenAI GPT (Radford et al., 2018), and BERT (Devlin et al., 2018), have achieved impressive results on various natural language processing tasks such as question-answering and natural language inference. In this paper, we describe a simple re-implementation of BERT for query-based passage re-ranking. Our system is the state of the art on the TREC-CAR dataset and the top entry in the leaderboard of the MS MARCO passage retrieval task, outperforming the previous state of the art by 27% (relative) in MRR@10. The code to reproduce our results is available at this https URL\nMetric Learning: A Survey (B. Kulis, 2013) B. Kulis. (2013)\nMetric Learning: A Survey\nFound. Trends Mach. Learn.\nPaper Link\nInfluential Citation Count (33), SS-ID (8916521f7d4c97befa30b06e17a7a39cda274552)\nABSTRACT\nThe metric learning problem is concerned with learning a distance function tuned to a particular task, and has been shown to be useful when used in conjunction with nearest-neighbor methods and other techniques that rely on distances or similarities. Metric Learning: A Review presents an overview of existing research in this topic, including recent progress on scaling to high-dimensional feature spaces and to data sets with an extremely large number of data points. It presents as unified a framework as possible under which existing research on metric learning can be cast. The monograph starts out by focusing on linear metric learning approaches, and mainly concentrates on the class of Mahalanobis distance learning methods. It then discusses nonlinear metric learning approaches, focusing on the connections between the non-linear and linear approaches. Finally, it discusses extensions of metric learning, as well as applications to a variety of problems in computer vision, text analysis, program analysis, and multimedia. Metric Learning: A Review is an ideal reference for anyone interested in the metric learning problem. It synthesizes much of the recent work in the area and it is hoped that it will inspire new algorithms and applications.\nIntroduction to (H. Hung et al., 2015) H. Hung, G. Toderici. (2015)\nIntroduction to\nACM Trans. Multim. Comput. Commun. Appl.\nPaper Link\nInfluential Citation Count (1), SS-ID (969dfac1f7f3f500b3976cec07ff1cc7d1a391cd)\nABSTRACT\nThis special issue continues the tradition of inviting the best papers from ACM Multimedia to extend their work to a journal article. In 2015, the conference was held in Orlando, FL, USA. A number of new areas were introduced this year. The two articles presented in this special issue came from the Deep Learning for Multimedia area and the Emotional and Social Signals in Multimedia area. As usual, a rigorous review process was carried out followed by an intense two-day colocated technical program committee meeting. Selecting the final set of best-paper candidates was a very intense process for all concerned, sparking a lot of debate about how important it is to have best paper candidates that are multimodal and take a fresh perspective on new topics. The following best paper extensions underwent a rigorous review procedure to ensure that the work was sufficiently extended compared to their respective conference paper versions. We thank the anonymous reviewers who helped to ensure the quality of these two extended papers. The first article, “Emotion Recognition During Speech Using Dynamics of Multiple Regions of Face” by Yelin Kim and Emily Mower-Provost, addresses the challenging task of performing automated facial emotion recognition when someone is speaking simultaneously. In this article, the authors exploit the context of the speech to disambiguate facial behavior that is caused by speech production from true expressions of facial emotion. They investigate an unsupervised method of segmenting the facial movements due to speech, demonstrating an improvement in facial-emotion recognition performance on the IEMOCAP and SAVEE datasets. Importantly, they describe the correspondence of their experimental findings in relation to existing emotion perception studies. This work is particularly valuable in the development of more naturalistic human-centered and emotionally aware multimedia interfaces. The second article, “Correspondence Autoencoders for Cross-Modal Retrieval” by Fangxiang Feng, Xiaojie Wang, and Ruifan Li, tackles the task of cross-modal retrieval by using correspondence autoencoder which connects the text and image modality. This enables users to issue text queries and have images retrieved using their shared representations. The authors present three distinct architectures for achieving this. A correspondence cross-modal autoencoder reconstructs its input, which may consist of text phrases or images, while using a shared bottleneck layer (with the text and image belonging to the same entity). In the second variant, the full-modal architecture, both inputs must be reconstructed given a single modality. The final deep architecture employs restricted Boltzmann machines. Experimental results show that the described architectures improve upon previously published literature in this domain on the Wikipedia, Pascal, and NUS-WIDE-10k datasets. Moreover, the authors\nSignature Verification Using A \u0026#39;Siamese\u0026#39; Time Delay Neural Network (J. Bromley et al., 1993) J. Bromley, James W. Bentz, L. Bottou, I. Guyon, Yann LeCun, C. Moore, Eduard Säckinger, Roopak Shah. (1993)\nSignature Verification Using A \u0026lsquo;Siamese\u0026rsquo; Time Delay Neural Network\nInt. J. Pattern Recognit. Artif. Intell.\nPaper Link\nInfluential Citation Count (153), SS-ID (997dc5d9a058753f034422afe7bd0cc0b8ad808b)\nABSTRACT\nThis paper describes an algorithm for verification of signatures written on a pen-input tablet. The algorithm is based on a novel, artificial neural network, called a \u0026ldquo;Siamese\u0026rdquo; neural network. This network consists of two identical sub-networks joined at their outputs. During training the two sub-networks extract features from two signatures, while the joining neuron measures the distance between the two feature vectors. Verification consists of comparing an extracted feature vector with a stored feature vector for the signer. Signatures closer to this stored representation than a chosen threshold are accepted, all other signatures are rejected as forgeries.\nAn Analysis of the AskMSR Question-Answering System (E. Brill et al., 2002) E. Brill, S. Dumais, Michele Banko. (2002)\nAn Analysis of the AskMSR Question-Answering System\nEMNLP\nPaper Link\nInfluential Citation Count (18), SS-ID (9c99620d7511c83a402ff3b4b3a2348a669e61e3)\nABSTRACT\nWe describe the architecture of the AskMSR question answering system and systematically evaluate contributions of different system components to accuracy. The system differs from most question answering systems in its dependency on data redundancy rather than sophisticated linguistic analyses of either questions or candidate answers. Because a wrong answer is often worse than no answer, we also explore strategies for predicting when the question answering system is likely to give an incorrect answer.\nLatent Retrieval for Weakly Supervised Open Domain Question Answering (Kenton Lee et al., 2019) Kenton Lee, Ming-Wei Chang, Kristina Toutanova. (2019)\nLatent Retrieval for Weakly Supervised Open Domain Question Answering\nACL\nPaper Link\nInfluential Citation Count (100), SS-ID (a81874b4a651a740fffbfc47ef96515e8c7f782f)\nABSTRACT\nRecent work on open domain question answering (QA) assumes strong supervision of the supporting evidence and/or assumes a blackbox information retrieval (IR) system to retrieve evidence candidates. We argue that both are suboptimal, since gold evidence is not always available, and QA is fundamentally different from IR. We show for the first time that it is possible to jointly learn the retriever and reader from question-answer string pairs and without any IR system. In this setting, evidence retrieval from all of Wikipedia is treated as a latent variable. Since this is impractical to learn from scratch, we pre-train the retriever with an Inverse Cloze Task. We evaluate on open versions of five QA datasets. On datasets where the questioner already knows the answer, a traditional IR system such as BM25 is sufficient. On datasets where a user is genuinely seeking an answer, we show that learned retrieval is crucial, outperforming BM25 by up to 19 points in exact match.\nSemantic Parsing on Freebase from Question-Answer Pairs (Jonathan Berant et al., 2013) Jonathan Berant, A. Chou, Roy Frostig, Percy Liang. (2013)\nSemantic Parsing on Freebase from Question-Answer Pairs\nEMNLP\nPaper Link\nInfluential Citation Count (222), SS-ID (b29447ba499507a259ae9d8f685d60cc1597d7d3)\nABSTRACT\nIn this paper, we train a semantic parser that scales up to Freebase. Instead of relying on annotated logical forms, which is especially expensive to obtain at large scale, we learn from question-answer pairs. The main challenge in this setting is narrowing down the huge number of possible logical predicates for a given question. We tackle this problem in two ways: First, we build a coarse mapping from phrases to predicates using a knowledge base and a large text corpus. Second, we use a bridging operation to generate additional predicates based on neighboring predicates. On the dataset of Cai and Yates (2013), despite not having annotated logical forms, our system outperforms their state-of-the-art parser. Additionally, we collected a more realistic and challenging dataset of question-answer pairs and improves over a natural baseline.\nReal-Time Open-Domain Question Answering with Dense-Sparse Phrase Index (Minjoon Seo et al., 2019) Minjoon Seo, Jinhyuk Lee, T. Kwiatkowski, Ankur P. Parikh, Ali Farhadi, Hannaneh Hajishirzi. (2019)\nReal-Time Open-Domain Question Answering with Dense-Sparse Phrase Index\nACL\nPaper Link\nInfluential Citation Count (12), SS-ID (b29db655a18e7417e1188ba392a06b6314f0cb87)\nABSTRACT\nExisting open-domain question answering (QA) models are not suitable for real-time usage because they need to process several long documents on-demand for every input query, which is computationally prohibitive. In this paper, we introduce query-agnostic indexable representations of document phrases that can drastically speed up open-domain QA. In particular, our dense-sparse phrase encoding effectively captures syntactic, semantic, and lexical information of the phrases and eliminates the pipeline filtering of context documents. Leveraging strategies for optimizing training and inference time, our model can be trained and deployed even in a single 4-GPU server. Moreover, by representing phrases as pointers to their start and end tokens, our model indexes phrases in the entire English Wikipedia (up to 60 billion phrases) using under 2TB. Our experiments on SQuAD-Open show that our model is on par with or more accurate than previous models with 6000x reduced computational cost, which translates into at least 68x faster end-to-end inference benchmark on CPUs. Code and demo are available at nlp.cs.washington.edu/denspi\nDenoising Distantly Supervised Open-Domain Question Answering (Yankai Lin et al., 2018) Yankai Lin, Haozhe Ji, Zhiyuan Liu, Maosong Sun. (2018)\nDenoising Distantly Supervised Open-Domain Question Answering\nACL\nPaper Link\nInfluential Citation Count (21), SS-ID (ba1382a0574baa0345fd727f259bc86797fe1381)\nABSTRACT\nDistantly supervised open-domain question answering (DS-QA) aims to find answers in collections of unlabeled text. Existing DS-QA models usually retrieve related paragraphs from a large-scale corpus and apply reading comprehension technique to extract answers from the most relevant paragraph. They ignore the rich information contained in other paragraphs. Moreover, distant supervision data inevitably accompanies with the wrong labeling problem, and these noisy data will substantially degrade the performance of DS-QA. To address these issues, we propose a novel DS-QA model which employs a paragraph selector to filter out those noisy paragraphs and a paragraph reader to extract the correct answer from those denoised paragraphs. Experimental results on real-world datasets show that our model can capture useful information from noisy data and achieve significant improvements on DS-QA as compared to all baselines.\nReal-time Inference in Multi-sentence Tasks with Deep Pretrained Transformers (Samuel Humeau et al., 2019) Samuel Humeau, Kurt Shuster, Marie-Anne Lachaux, J. Weston. (2019)\nReal-time Inference in Multi-sentence Tasks with Deep Pretrained Transformers\nArXiv\nPaper Link\nInfluential Citation Count (2), SS-ID (bb2afd8172469fef7276e9789b306e085ed6e650)\nABSTRACT\nThe use of deep pretrained bidirectional transformers has led to remarkable progress in learning multi-sentence representations for downstream language understanding tasks (Devlin et al., 2018). For tasks that make pairwise comparisons, e.g. matching a given context with a corresponding response, two approaches have permeated the literature. A Cross-encoder performs full self-attention over the pair; a Bi-encoder performs self-attention for each sequence separately, and the final representation is a function of the pair. While Cross-encoders nearly always outperform Bi-encoders on various tasks, both in our work and others\u0026rsquo; (Urbanek et al., 2019), they are orders of magnitude slower, which hampers their ability to perform real-time inference. In this work, we develop a new architecture, the Poly-encoder, that is designed to approach the performance of the Cross-encoder while maintaining reasonable computation time. Additionally, we explore two pretraining schemes with different datasets to determine how these affect the performance on our chosen dialogue tasks: ConvAI2 and DSTC7 Track 1. We show that our models achieve state-of-the-art results on both tasks; that the Poly-encoder is a suitable replacement for Bi-encoders and Cross-encoders; and that even better results can be obtained by pretraining on a large dialogue dataset.\nLeveraging Passage Retrieval with Generative Models for Open Domain Question Answering (Gautier Izacard et al., 2020) Gautier Izacard, Edouard Grave. (2020)\nLeveraging Passage Retrieval with Generative Models for Open Domain Question Answering\nEACL\nPaper Link\nInfluential Citation Count (44), SS-ID (bde0c85ed3d61de2a8874ddad70497b3d68bc8ad)\nABSTRACT\nGenerative models for open domain question answering have proven to be competitive, without resorting to external knowledge. While promising, this approach requires to use models with billions of parameters, which are expensive to train and query. In this paper, we investigate how much these models can benefit from retrieving text passages, potentially containing evidence. We obtain state-of-the-art results on the Natural Questions and TriviaQA open benchmarks. Interestingly, we observe that the performance of this method significantly improves when increasing the number of retrieved passages. This is evidence that sequence-to-sequence models offers a flexible framework to efficiently aggregate and combine evidence from multiple passages.\nIntroduction to \u0026#39;This is Watson\u0026#39; (D. Ferrucci, 2012) D. Ferrucci. (2012)\nIntroduction to \u0026lsquo;This is Watson\u0026rsquo;\nIBM J. Res. Dev.\nPaper Link\nInfluential Citation Count (36), SS-ID (bde2d81eaf6086e664af87c04241d4ce4e1bd01b)\nABSTRACT\nIn 2007, IBM Research took on the grand challenge of building a computer system that could compete with champions at the game of Jeopardy!™. In 2011, the open-domain question-answering (QA) system, dubbed Watson, beat the two highest ranked players in a nationally televised two-game Jeopardy! match. This paper provides a brief history of the events and ideas that positioned our team to take on the Jeopardy! challenge, build Watson, IBM Watson™, and ultimately triumph. It describes both the nature of the QA challenge represented by Jeopardy! and our overarching technical approach. The main body of this paper provides a narrative of the DeepQA processing pipeline to introduce the articles in this special issue and put them in context of the overall system. Finally, this paper summarizes our main results, describing how the system, as a holistic combination of many diverse algorithmic techniques, performed at champion levels, and it briefly discusses the team\u0026rsquo;s future research plans.\nInformation science as \u0026#39;Little Science\u0026#39;:The implications of a bibliometric analysis of theJournal of the American Society for Information Science (W. Koehler, 2001) W. Koehler. (2001)\nInformation science as \u0026lsquo;Little Science\u0026rsquo;:The implications of a bibliometric analysis of theJournal of the American Society for Information Science\nScientometrics\nPaper Link\nInfluential Citation Count (20), SS-ID (c69317340f1684cd27af2cccdc5f3285402f8d7e)\nABSTRACT\nThis paper considers the status of information science as science through an exploration ofone of the leading journals in the field – the Journal of the American Society for InformationScience (JASIS) from its initial publication as American Documentation (AD) in 1950 through theclosing issue of its Silver Anniversary year in December 1999. It is a bibliometric examination ofAD/JASIS articles. Based on our analysis of articles published in AD and JASIS from 1950 to1999, we find that there has been a slow but perhaps inevitable shift based first on the single nonfundedresearcher and author to a much wider research and publishing participation amongauthors, regions, corporate authors, and countries. This suggests not only cross-fertilization ofideas, but also more complex research questions. A small trend toward greater external fundingfurther reinforces this hypothesis. Information may no longer be \u0026ldquo;little\u0026rdquo; science, but it is also not\u0026quot;big\u0026quot; science.\nApproximate Nearest Neighbor Negative Contrastive Learning for Dense Text Retrieval (Lee Xiong et al., 2020) Lee Xiong, Chenyan Xiong, Ye Li, Kwok-Fung Tang, Jialin Liu, Paul Bennett, Junaid Ahmed, Arnold Overwijk. (2020)\nApproximate Nearest Neighbor Negative Contrastive Learning for Dense Text Retrieval\nICLR\nPaper Link\nInfluential Citation Count (70), SS-ID (c9b8593db099869fe7254aa1fa53f3c9073b0176)\nABSTRACT\nConducting text retrieval in a dense learned representation space has many intriguing advantages over sparse retrieval. Yet the effectiveness of dense retrieval (DR) often requires combination with sparse retrieval. In this paper, we identify that the main bottleneck is in the training mechanisms, where the negative instances used in training are not representative of the irrelevant documents in testing. This paper presents Approximate nearest neighbor Negative Contrastive Estimation (ANCE), a training mechanism that constructs negatives from an Approximate Nearest Neighbor (ANN) index of the corpus, which is parallelly updated with the learning process to select more realistic negative training instances. This fundamentally resolves the discrepancy between the data distribution used in the training and testing of DR. In our experiments, ANCE boosts the BERT-Siamese DR model to outperform all competitive dense and sparse retrieval baselines. It nearly matches the accuracy of sparse-retrieval-and-BERT-reranking using dot-product in the ANCE-learned representation space and provides almost 100x speed-up.\nLearning a similarity metric discriminatively, with application to face verification (S. Chopra et al., 2005) S. Chopra, R. Hadsell, Yann LeCun. (2005)\nLearning a similarity metric discriminatively, with application to face verification\n2005 IEEE Computer Society Conference on Computer Vision and Pattern Recognition (CVPR'05)\nPaper Link\nInfluential Citation Count (178), SS-ID (cfaae9b6857b834043606df3342d8dc97524aa9d)\nABSTRACT\nWe present a method for training a similarity metric from data. The method can be used for recognition or verification applications where the number of categories is very large and not known during training, and where the number of training samples for a single category is very small. The idea is to learn a function that maps input patterns into a target space such that the L/sub 1/ norm in the target space approximates the \u0026ldquo;semantic\u0026rdquo; distance in the input space. The method is applied to a face verification task. The learning process minimizes a discriminative loss function that drives the similarity metric to be small for pairs of faces from the same person, and large for pairs from different persons. The mapping from raw to the target space is a convolutional network whose architecture is designed for robustness to geometric distortions. The system is tested on the Purdue/AR face database which has a very high degree of variability in the pose, lighting, expression, position, and artificial occlusions such as dark glasses and obscuring scarves.\nLearning Discriminative Projections for Text Similarity Measures (Wen-tau Yih et al., 2011) Wen-tau Yih, Kristina Toutanova, John C. Platt, Christopher Meek. (2011)\nLearning Discriminative Projections for Text Similarity Measures\nCoNLL\nPaper Link\nInfluential Citation Count (16), SS-ID (d5b034176d6021bc965fca9aa02f17864d1ccf67)\nABSTRACT\nTraditional text similarity measures consider each term similar only to itself and do not model semantic relatedness of terms. We propose a novel discriminative training method that projects the raw term vectors into a common, low-dimensional vector space. Our approach operates by finding the optimal matrix to minimize the loss of the pre-selected similarity function (e.g., cosine) of the projected vectors, and is able to efficiently handle a large number of training examples in the high-dimensional space. Evaluated on two very different tasks, cross-lingual document retrieval and ad relevance measure, our method not only outperforms existing state-of-the-art approaches, but also achieves high accuracy at low dimensions and is thus more efficient.\nMaximum inner-product search using cone trees (P. Ram et al., 2012) P. Ram, Alexander G. Gray. (2012)\nMaximum inner-product search using cone trees\nKDD\nPaper Link\nInfluential Citation Count (13), SS-ID (dcd2755f4e7b5ed96571ec6a741b172a217cabe2)\nABSTRACT\nThe problem of efficiently finding the best match for a query in a given set with respect to the Euclidean distance or the cosine similarity has been extensively studied. However, the closely related problem of efficiently finding the best match with respect to the inner-product has never been explored in the general setting to the best of our knowledge. In this paper we consider this problem and contrast it with the previous problems considered. First, we propose a general branch-and-bound algorithm based on a (single) tree data structure. Subsequently, we present a dual-tree algorithm for the case where there are multiple queries. Our proposed branch-and-bound algorithms are based on novel inner-product bounds. Finally we present a new data structure, the cone tree, for increasing the efficiency of the dual-tree algorithm. We evaluate our proposed algorithms on a variety of data sets from various applications, and exhibit up to five orders of magnitude improvement in query time over the naive search technique in some cases.\nBERT: Pre-training of Deep Bidirectional Transformers for Language Understanding (Jacob Devlin et al., 2019) Jacob Devlin, Ming-Wei Chang, Kenton Lee, Kristina Toutanova. (2019)\nBERT: Pre-training of Deep Bidirectional Transformers for Language Understanding\nNAACL\nPaper Link\nInfluential Citation Count (9863), SS-ID (df2b0e26d0599ce3e70df8a9da02e51594e0e992)\nABSTRACT\nWe introduce a new language representation model called BERT, which stands for Bidirectional Encoder Representations from Transformers. Unlike recent language representation models (Peters et al., 2018a; Radford et al., 2018), BERT is designed to pre-train deep bidirectional representations from unlabeled text by jointly conditioning on both left and right context in all layers. As a result, the pre-trained BERT model can be fine-tuned with just one additional output layer to create state-of-the-art models for a wide range of tasks, such as question answering and language inference, without substantial task-specific architecture modifications. BERT is conceptually simple and empirically powerful. It obtains new state-of-the-art results on eleven natural language processing tasks, including pushing the GLUE score to 80.5 (7.7 point absolute improvement), MultiNLI accuracy to 86.7% (4.6% absolute improvement), SQuAD v1.1 question answering Test F1 to 93.2 (1.5 point absolute improvement) and SQuAD v2.0 Test F1 to 83.1 (5.1 point absolute improvement).\nQuantization based Fast Inner Product Search (Ruiqi Guo et al., 2015) Ruiqi Guo, Sanjiv Kumar, K. Choromanski, David Simcha. (2015)\nQuantization based Fast Inner Product Search\nAISTATS\nPaper Link\nInfluential Citation Count (6), SS-ID (e15fdad9f7d160e11e9a313bd80ebe99952eff08)\nABSTRACT\nWe propose a quantization based approach for fast approximate Maximum Inner Product Search (MIPS). Each database vector is quantized in multiple subspaces via a set of codebooks, learned directly by minimizing the inner product quantization error. Then, the inner product of a query to a database vector is approximated as the sum of inner products with the subspace quantizers. Different from recently proposed LSH approaches to MIPS, the database vectors and queries do not need to be augmented in a higher dimensional feature space. We also provide a theoretical analysis of the proposed approach, consisting of the concentration results under mild assumptions. Furthermore, if a small sample of example queries is given at the training time, we propose a modified codebook learning procedure which further improves the accuracy. Experimental results on a variety of datasets including those arising from deep neural networks show that the proposed approach significantly outperforms the existing state-of-the-art.\nMulti-step Retriever-Reader Interaction for Scalable Open-domain Question Answering (R. Das et al., 2019) R. Das, S. Dhuliawala, M. Zaheer, A. McCallum. (2019)\nMulti-step Retriever-Reader Interaction for Scalable Open-domain Question Answering\nICLR\nPaper Link\nInfluential Citation Count (13), SS-ID (e7512b84e923372ae410d7614e71224d573ed2ef)\nABSTRACT\nThis paper introduces a new framework for open-domain question answering in which the retriever and the reader iteratively interact with each other. The framework is agnostic to the architecture of the machine reading model, only requiring access to the token-level hidden representations of the reader. The retriever uses fast nearest neighbor search to scale to corpora containing millions of paragraphs. A gated recurrent unit updates the query at each step conditioned on the state of the reader and the reformulated query is used to re-rank the paragraphs by the retriever. We conduct analysis and show that iterative interaction helps in retrieving informative paragraphs from the corpus. Finally, we show that our multi-step-reasoning framework brings consistent improvement when applied to two widely used reader architectures DrQA and BiDAF on various large open-domain datasets \u0026mdash; TriviaQA-unfiltered, QuasarT, SearchQA, and SQuAD-Open.\nTriviaQA: A Large Scale Distantly Supervised Challenge Dataset for Reading Comprehension (Mandar Joshi et al., 2017) Mandar Joshi, Eunsol Choi, Daniel S. Weld, Luke Zettlemoyer. (2017)\nTriviaQA: A Large Scale Distantly Supervised Challenge Dataset for Reading Comprehension\nACL\nPaper Link\nInfluential Citation Count (193), SS-ID (f010affab57b5fcf1cd6be23df79d8ec98c7289c)\nABSTRACT\nWe present TriviaQA, a challenging reading comprehension dataset containing over 650K question-answer-evidence triples. TriviaQA includes 95K question-answer pairs authored by trivia enthusiasts and independently gathered evidence documents, six per question on average, that provide high quality distant supervision for answering the questions. We show that, in comparison to other recently introduced large-scale datasets, TriviaQA (1) has relatively complex, compositional questions, (2) has considerable syntactic and lexical variability between questions and corresponding answer-evidence sentences, and (3) requires more cross sentence reasoning to find answers. We also present two baseline algorithms: a feature-based classifier and a state-of-the-art neural network, that performs well on SQuAD reading comprehension. Neither approach comes close to human performance (23% and 40% vs. 80%), suggesting that TriviaQA is a challenging testbed that is worth significant future study. Data and code available at \u0026ndash; this http URL\nData Augmentation for BERT Fine-Tuning in Open-Domain Question Answering (Wei Yang et al., 2019) Wei Yang, Yuqing Xie, Luchen Tan, Kun Xiong, Ming Li, Jimmy J. Lin. (2019)\nData Augmentation for BERT Fine-Tuning in Open-Domain Question Answering\nArXiv\nPaper Link\nInfluential Citation Count (6), SS-ID (f5eaf727b80240a13e9f631211c9ecec7e3b9feb)\nABSTRACT\nRecently, a simple combination of passage retrieval using off-the-shelf IR techniques and a BERT reader was found to be very effective for question answering directly on Wikipedia, yielding a large improvement over the previous state of the art on a standard benchmark dataset. In this paper, we present a data augmentation technique using distant supervision that exploits positive as well as negative examples. We apply a stage-wise approach to fine tuning BERT on multiple datasets, starting with data that is \u0026ldquo;furthest\u0026rdquo; from the test data and ending with the \u0026ldquo;closest\u0026rdquo;. Experimental results show large gains in effectiveness over previous approaches on English QA datasets, and we establish new baselines on two recent Chinese QA datasets.\nR3: Reinforced Ranker-Reader for Open-Domain Question Answering (Shuohang Wang et al., 2018) Shuohang Wang, Mo Yu, Xiaoxiao Guo, Zhiguo Wang, Tim Klinger, Wei Zhang, Shiyu Chang, G. Tesauro, Bowen Zhou, Jing Jiang. (2018)\nR3: Reinforced Ranker-Reader for Open-Domain Question Answering\nAAAI\nPaper Link\nInfluential Citation Count (33), SS-ID (f7df82c5417b9ec7582def05b79ca080a07c4f3b)\nABSTRACT\nIn recent years researchers have achieved considerable success applying neural network methods to question answering (QA). These approaches have achieved state of the art results in simplified closed-domain settings such as the SQuAD (Rajpurkar et al. 2016) dataset, which provides a preselected passage, from which the answer to a given question may be extracted. More recently, researchers have begun to tackle open-domain QA, in which the model is given a question and access to a large corpus (e.g., wikipedia) instead of a pre-selected passage (Chen et al. 2017a). This setting is more complex as it requires large-scale search for relevant passages by an information retrieval component, combined with a reading comprehension model that “reads” the passages to generate an answer to the question. Performance in this setting lags well behind closed-domain performance. In this paper, we present a novel open-domain QA system called Reinforced Ranker-Reader (R), based on two algorithmic innovations. First, we propose a new pipeline for open-domain QA with a Ranker component, which learns to rank retrieved passages in terms of likelihood of extracting the ground-truth answer to a given question. Second, we propose a novel method that jointly trains the Ranker along with an answer-extraction Reader model, based on reinforcement learning. We report extensive experimental results showing that our method significantly improves on the state of the art for multiple open-domain QA datasets. 2\nLearning deep structured semantic models for web search using clickthrough data (Po-Sen Huang et al., 2013) Po-Sen Huang, Xiaodong He, Jianfeng Gao, L. Deng, A. Acero, Larry Heck. (2013)\nLearning deep structured semantic models for web search using clickthrough data\nCIKM\nPaper Link\nInfluential Citation Count (243), SS-ID (fdb813d8b927bdd21ae1858cafa6c34b66a36268)\nABSTRACT\nLatent semantic models, such as LSA, intend to map a query to its relevant documents at the semantic level where keyword-based matching often fails. In this study we strive to develop a series of new latent semantic models with a deep structure that project queries and documents into a common low-dimensional space where the relevance of a document given a query is readily computed as the distance between them. The proposed deep structured semantic models are discriminatively trained by maximizing the conditional likelihood of the clicked documents given a query using the clickthrough data. To make our models applicable to large-scale Web search applications, we also use a technique called word hashing, which is shown to effectively scale up our semantic models to handle large vocabularies which are common in such tasks. The new models are evaluated on a Web document ranking task using a real-world data set. Results show that our best model significantly outperforms other latent semantic models, which were considered state-of-the-art in the performance prior to the work presented in this paper.\n","date":"May 5, 2022","hero":"/blog-akitenkrad/posts/papers/202205/20220505222900/hero.jpg","permalink":"https://akitenkrad.github.io/blog-akitenkrad/posts/papers/202205/20220505222900/","summary":"Round-1: Overview Round-2: Model Implementation Details Round-3: Experiments Citation Karpukhin, V., Oğuz, B., Min, S., Lewis, P., Wu, L., Edunov, S., Chen, D., \u0026amp; Yih, W. (2020).\nDense Passage Retrieval for Open-Domain Question Answering.\nPaper Link Abstract Open-domain question answering relies on efficient passage retrieval to select candidate contexts, where traditional sparse vector space models, such as TF-IDF or BM25, are the de facto method. In this work, we show that retrieval can be practically implemented using dense representations alone, where embeddings are learned from a small number of questions and passages by a simple dual-encoder framework.","tags":["At:Round-1","Published:2020","Question Answering","Dual Encoder","BERT","Extractive MRC","DS:SQuAD","DS:Natural Questions","DS:TriviaQA","DS:WebQuestions","DS:TREC"],"title":"Dense Passage Retrieval for Open-Domain Question Answering"},{"categories":null,"contents":" Round-1: Overview Round-2: Model Implementation Details Round-3: Experiments Citation He, P., Liu, X., Gao, J., \u0026amp; Chen, W. (2020).\nDeBERTa: Decoding-enhanced BERT with Disentangled Attention.\nPaper Link Abstract Recent progress in pre-trained neural language models has significantly improved the performance of many natural language processing (NLP) tasks. In this paper we propose a new model architecture DeBERTa (Decoding-enhanced BERT with disentangled attention) that improves the BERT and RoBERTa models using two novel techniques. The first is the disentangled attention mechanism, where each word is represented using two vectors that encode its content and position, respectively, and the attention weights among words are computed using disentangled matrices on their contents and relative positions, respectively. Second, an enhanced mask decoder is used to incorporate absolute positions in the decoding layer to predict the masked tokens in model pre-training. In addition, a new virtual adversarial training method is used for fine-tuning to improve models\u0026rsquo; generalization. We show that these techniques significantly improve the efficiency of model pre-training and the performance of both natural language understanding (NLU) and natural langauge generation (NLG) downstream tasks. Compared to RoBERTa-Large, a DeBERTa model trained on half of the training data performs consistently better on a wide range of NLP tasks, achieving improvements on MNLI by +0.9% (90.2% vs. 91.1%), on SQuAD v2.0 by +2.3% (88.4% vs. 90.7%) and RACE by +3.6% (83.2% vs. 86.8%). Notably, we scale up DeBERTa by training a larger version that consists of 48 Transform layers with 1.5 billion parameters. The significant performance boost makes the single DeBERTa model surpass the human performance on the SuperGLUE benchmark (Wang et al., 2019a) for the first time in terms of macro-average score (89.9 versus 89.8), and the ensemble DeBERTa model sits atop the SuperGLUE leaderboard as of January 6, 2021, out performing the human baseline by a decent margin (90.3 versus 89.8).\nWhat\u0026rsquo;s New 2つの新しいテクニックを使ってBERTとRoBERTaを精度改善 Disentangled Attention トークンの分散表現は，その内容だけではなく文書内での相対的な位置にも依存している テキストの内容とトークンの相対的な位置情報をそれぞれベクトル化し，組み合わせて分散表現を構成 Attention Weightは2つのベクトルの共起行列（disentangled matrices）によって計算される Enhanced Mask Decoder 事前学習のデコーダで絶対的な位置情報を加味してマスクされたトークンを予測する Disentangled Attentionでも相対的な位置情報を利用しているが，予測時には絶対的な位置情報も重要となる 学習には新しいVirtual Adversarial Training (Miyato et al., 2017; Jiang et al., 2020) の学習方法 Scale-invariant-Fine-Tuning (SiFT) を提案 GitHub https://github.com/microsoft/DeBERTa Dataset GLUE Alex Wang, Amanpreet Singh, Julian Michael, Felix Hill, Omer Levy, Samuel R. Bowman. (2018)\nGLUE: A Multi-Task Benchmark and Analysis Platform for Natural Language Understanding\nBlackboxNLP@EMNLP\nhttps://www.semanticscholar.org/paper/93b8da28d006415866bf48f9a6e06b5242129195 SuperGLUE Alex Wang, Yada Pruksachatkun, Nikita Nangia, Amanpreet Singh, Julian Michael, Felix Hill, Omer Levy, Samuel R. Bowman. (2019)\nSuperGLUE: A Stickier Benchmark for General-Purpose Language Understanding Systems\nNeurIPS\nhttps://www.semanticscholar.org/paper/d9f6ada77448664b71128bb19df15765336974a6 SQuAD v1.1 Rajpurkar, P., Zhang, J., Lopyrev, K., \u0026amp; Liang, P. (2016).\nSQuAD: 100,000+ Questions for Machine Comprehension of Text.\nEMNLP 2016 - Conference on Empirical Methods in Natural Language Processing, Proceedings, 2383–2392.\nhttps://doi.org/10.18653/V1/D16-1264 RACE Guokun Lai, Qizhe Xie, Hanxiao Liu, Yiming Yang, E. Hovy. (2017)\nRACE: Large-scale ReAding Comprehension Dataset From Examinations\nEMNLP\nhttps://www.semanticscholar.org/paper/636a79420d838eabe4af7fb25d6437de45ab64e8 ReCoRD Sheng Zhang, Xiaodong Liu, Jingjing Liu, Jianfeng Gao, Kevin Duh, Benjamin Van Durme. (2018)\nReCoRD: Bridging the Gap between Human and Machine Commonsense Reading Comprehension\nArXiv\nhttps://www.semanticscholar.org/paper/a5b66ee341cb990f7f70a124b5fab3316d3b7e27 SWAG Rowan Zellers, Yonatan Bisk, Roy Schwartz, Yejin Choi. (2018)\nSWAG: A Large-Scale Adversarial Dataset for Grounded Commonsense Inference\nEMNLP\nhttps://www.semanticscholar.org/paper/af5c4b80fbf847f69a202ba5a780a3dd18c1a027 MultiNLI Adina Williams, Nikita Nangia, Samuel R. Bowman. (2017)\nA Broad-Coverage Challenge Corpus for Sentence Understanding through Inference\nNAACL\nPaper Link CoNLL-2003 Sang, E. F. T. K., \u0026amp; de Meulder, F. (2003).\nIntroduction to the CoNLL-2003 Shared Task: Language-Independent Named Entity Recognition.\nPaper Link Model Description TBD\nTraining Settings 学習データ Wikipedia (English Wikipedia dump) BookCorpus Zhu et al. (2015) Yukun Zhu, Ryan Kiros, R. Zemel, R. Salakhutdinov, R. Urtasun, A. Torralba, S. Fidler. (2015)\nAligning Books and Movies: Towards Story-Like Visual Explanations by Watching Movies and Reading Books\n2015 IEEE International Conference on Computer Vision (ICCV)\nPaper Link OPENWEBTEXT Gokaslan \u0026amp; Cohen (2019) Aaron Gokaslan and Vanya Cohen. (2019)\nOpenwebtext corpus.\nDataset Link STORIES Trinh et al. (2018) Trieu H. Trinh, Quoc V. Le. (2018)\nA Simple Method for Commonsense Reasoning\nArXiv\nPaper Link モデルごとの学習データ使用状況 Results Comparison results on the GLUE dev set RoBERTaやXLNet，ELECTRAなどの事前学習モデルは160GBの学習データを必要としたが，DeBERTaは78GBだけで学習が可能 ほぼ全てのタスクにおいて，DeBERTaが他のモデルよりも良い精度を達成している Results on NLP Datasets References ERNIE: Enhanced Representation through Knowledge Integration (Yu Sun et al., 2019) Yu Sun, Shuohuan Wang, Yukun Li, Shikun Feng, Xuyi Chen, Han Zhang, Xin Tian, Danxiang Zhu, Hao Tian, Hua Wu. (2019)\nERNIE: Enhanced Representation through Knowledge Integration\nArXiv\nPaper Link\nInfluential Citation Count (63), SS-ID (031e4e43aaffd7a479738dcea69a2d5be7957aa3)\nABSTRACT\nWe present a novel language representation model enhanced by knowledge called ERNIE (Enhanced Representation through kNowledge IntEgration). Inspired by the masking strategy of BERT, ERNIE is designed to learn language representation enhanced by knowledge masking strategies, which includes entity-level masking and phrase-level masking. Entity-level strategy masks entities which are usually composed of multiple words.Phrase-level strategy masks the whole phrase which is composed of several words standing together as a conceptual unit.Experimental results show that ERNIE outperforms other baseline methods, achieving new state-of-the-art results on five Chinese natural language processing tasks including natural language inference, semantic similarity, named entity recognition, sentiment analysis and question answering. We also demonstrate that ERNIE has more powerful knowledge inference capacity on a cloze test.\nReformer: The Efficient Transformer (Nikita Kitaev et al., 2020) Nikita Kitaev, Lukasz Kaiser, Anselm Levskaya. (2020)\nReformer: The Efficient Transformer\nICLR\nPaper Link\nInfluential Citation Count (103), SS-ID (055fd6a9f7293269f1b22c1470e63bd02d8d9500)\nABSTRACT\nLarge Transformer models routinely achieve state-of-the-art results on a number of tasks but training these models can be prohibitively costly, especially on long sequences. We introduce two techniques to improve the efficiency of Transformers. For one, we replace dot-product attention by one that uses locality-sensitive hashing, changing its complexity from O($L^2$) to O($L\\log L$), where $L$ is the length of the sequence. Furthermore, we use reversible residual layers instead of the standard residuals, which allows storing activations only once in the training process instead of $N$ times, where $N$ is the number of layers. The resulting model, the Reformer, performs on par with Transformer models while being much more memory-efficient and much faster on long sequences.\nSQuAD: 100,000\u0026#43; Questions for Machine Comprehension of Text (Pranav Rajpurkar et al., 2016) Pranav Rajpurkar, Jian Zhang, Konstantin Lopyrev, Percy Liang. (2016)\nSQuAD: 100,000+ Questions for Machine Comprehension of Text\nEMNLP\nPaper Link\nInfluential Citation Count (1063), SS-ID (05dd7254b632376973f3a1b4d39485da17814df5)\nABSTRACT\nWe present the Stanford Question Answering Dataset (SQuAD), a new reading comprehension dataset consisting of 100,000+ questions posed by crowdworkers on a set of Wikipedia articles, where the answer to each question is a segment of text from the corresponding reading passage. We analyze the dataset to understand the types of reasoning required to answer the questions, leaning heavily on dependency and constituency trees. We build a strong logistic regression model, which achieves an F1 score of 51.0%, a significant improvement over a simple baseline (20%). However, human performance (86.8%) is much higher, indicating that the dataset presents a good challenge problem for future research. The dataset is freely available at this https URL\nRoBERTa: A Robustly Optimized BERT Pretraining Approach (Yinhan Liu et al., 2019) Yinhan Liu, Myle Ott, Naman Goyal, Jingfei Du, Mandar Joshi, Danqi Chen, Omer Levy, M. Lewis, Luke Zettlemoyer, Veselin Stoyanov. (2019)\nRoBERTa: A Robustly Optimized BERT Pretraining Approach\nArXiv\nPaper Link\nInfluential Citation Count (2015), SS-ID (077f8329a7b6fa3b7c877a57b81eb6c18b5f87de)\nABSTRACT\nLanguage model pretraining has led to significant performance gains but careful comparison between different approaches is challenging. Training is computationally expensive, often done on private datasets of different sizes, and, as we will show, hyperparameter choices have significant impact on the final results. We present a replication study of BERT pretraining (Devlin et al., 2019) that carefully measures the impact of many key hyperparameters and training data size. We find that BERT was significantly undertrained, and can match or exceed the performance of every model published after it. Our best model achieves state-of-the-art results on GLUE, RACE and SQuAD. These results highlight the importance of previously overlooked design choices, and raise questions about the source of recently reported improvements. We release our models and code.\nAligning Books and Movies: Towards Story-Like Visual Explanations by Watching Movies and Reading Books (Yukun Zhu et al., 2015) Yukun Zhu, Ryan Kiros, R. Zemel, R. Salakhutdinov, R. Urtasun, A. Torralba, S. Fidler. (2015)\nAligning Books and Movies: Towards Story-Like Visual Explanations by Watching Movies and Reading Books\n2015 IEEE International Conference on Computer Vision (ICCV)\nPaper Link\nInfluential Citation Count (167), SS-ID (0e6824e137847be0599bb0032e37042ed2ef5045)\nABSTRACT\nBooks are a rich source of both fine-grained information, how a character, an object or a scene looks like, as well as high-level semantics, what someone is thinking, feeling and how these states evolve through a story. This paper aims to align books to their movie releases in order to provide rich descriptive explanations for visual content that go semantically far beyond the captions available in the current datasets. To align movies and books we propose a neural sentence embedding that is trained in an unsupervised way from a large corpus of books, as well as a video-text neural embedding for computing similarities between movie clips and sentences in the book. We propose a context-aware CNN to combine information from multiple sources. We demonstrate good quantitative performance for movie/book alignment and show several qualitative examples that showcase the diversity of tasks our model can be used for.\nThe Seventh PASCAL Recognizing Textual Entailment Challenge (L. Bentivogli et al., 2011) L. Bentivogli, Peter Clark, Ido Dagan, Danilo Giampiccolo. (2011)\nThe Seventh PASCAL Recognizing Textual Entailment Challenge\nTAC\nPaper Link\nInfluential Citation Count (16), SS-ID (0f8468de03ee9f12d693237bec87916311bf1c24)\nABSTRACT\nThis paper presents the Seventh Recognizing Textual Entailment (RTE-7) challenge. This year’s challenge replicated the exercise proposed in RTE-6, consisting of a Main Task, in which Textual Entailment is performed on a real corpus in the Update Summarization scenario; a Main subtask aimed at detecting novel information; and a KBP Validation Task, in which RTE systems had to validate the output of systems participating in the KBP Slot Filling Task. Thirteen teams participated in the Main Task (submitting 33 runs) and 5 in the Novelty Detection Subtask (submitting 13 runs). The KBP Validation Task was undertaken by 2 participants which submitted 5 runs. The ablation test experiment, introduced in RTE-5 to evaluate the impact of knowledge resources used by the systems participating in the Main Task and extended also to tools in RTE-6, was also repeated in RTE-7.\nThe Winograd Schema Challenge (H. Levesque et al., 2011) H. Levesque, E. Davis, L. Morgenstern. (2011)\nThe Winograd Schema Challenge\nKR\nPaper Link\nInfluential Citation Count (146), SS-ID (128cb6b891aee1b5df099acb48e2efecfcff689f)\nABSTRACT\nIn this paper, we present an alternative to the Turing Test that has some conceptual and practical advantages. Like the original, it involves responding to typed English sentences, and English-speaking adults will have no difficulty with it. Unlike the original, the subject is not required to engage in a conversation and fool an interrogator into believing she is dealing with a person. Moreover, the test is arranged in such a way that having full access to a large corpus of English text might not help much. Finally, the interrogator or a third party will be able to decide unambiguously after a few minutes whether or not a subject has passed the test.\nThe Second PASCAL Recognising Textual Entailment Challenge (Roy Bar-Haim et al., 2006) Roy Bar-Haim, Ido Dagan, Bill Dolan, L. Ferro, Danilo Giampiccolo, B. Magnini. (2006)\nThe Second PASCAL Recognising Textual Entailment Challenge\nPaper Link\nInfluential Citation Count (49), SS-ID (136326377c122560768db674e35f5bcd6de3bc40)\nABSTRACT\nThis paper describes the Second PASCAL Recognising Textual Entailment Challenge (RTE-2). 1 We describe the RTE2 dataset and overview the submissions for the challenge. One of the main goals for this year’s dataset was to provide more “realistic” text-hypothesis examples, based mostly on outputs of actual systems. The 23 submissions for the challenge present diverse approaches and research directions, and the best results achieved this year are considerably higher than last year’s state of the art.\nCOCO-LM: Correcting and Contrasting Text Sequences for Language Model Pretraining (Yu Meng et al., 2021) Yu Meng, Chenyan Xiong, Payal Bajaj, Saurabh Tiwary, Paul Bennett, Jiawei Han, Xia Song. (2021)\nCOCO-LM: Correcting and Contrasting Text Sequences for Language Model Pretraining\nNeurIPS\nPaper Link\nInfluential Citation Count (7), SS-ID (19537be34dbadbcaa4fffcf028a8ada5095b1b5c)\nABSTRACT\nWe present a self-supervised learning framework, COCO-LM, that pretrains Language Models by COrrecting and COntrasting corrupted text sequences. Following ELECTRA-style pretraining, COCO-LM employs an auxiliary language model to corrupt text sequences, upon which it constructs two new tasks for pretraining the main model. The first token-level task, Corrective Language Modeling, is to detect and correct tokens replaced by the auxiliary model, in order to better capture token-level semantics. The second sequence-level task, Sequence Contrastive Learning, is to align text sequences originated from the same source input while ensuring uniformity in the representation space. Experiments on GLUE and SQuAD demonstrate that COCO-LM not only outperforms recent state-of-the-art pretrained models in accuracy, but also improves pretraining efficiency. It achieves the MNLI accuracy of ELECTRA with 50% of its pretraining GPU hours. With the same pretraining steps of standard base/large-sized models, COCO-LM outperforms the previous best models by 1+ GLUE average points.\nUnified Language Model Pre-training for Natural Language Understanding and Generation (Li Dong et al., 2019) Li Dong, Nan Yang, Wenhui Wang, Furu Wei, Xiaodong Liu, Yu Wang, Jianfeng Gao, M. Zhou, H. Hon. (2019)\nUnified Language Model Pre-training for Natural Language Understanding and Generation\nNeurIPS\nPaper Link\nInfluential Citation Count (106), SS-ID (1c71771c701aadfd72c5866170a9f5d71464bb88)\nABSTRACT\nThis paper presents a new Unified pre-trained Language Model (UniLM) that can be fine-tuned for both natural language understanding and generation tasks. The model is pre-trained using three types of language modeling tasks: unidirectional, bidirectional, and sequence-to-sequence prediction. The unified modeling is achieved by employing a shared Transformer network and utilizing specific self-attention masks to control what context the prediction conditions on. UniLM compares favorably with BERT on the GLUE benchmark, and the SQuAD 2.0 and CoQA question answering tasks. Moreover, UniLM achieves new state-of-the-art results on five natural language generation datasets, including improving the CNN/DailyMail abstractive summarization ROUGE-L to 40.51 (2.04 absolute improvement), the Gigaword abstractive summarization ROUGE-L to 35.75 (0.86 absolute improvement), the CoQA generative question answering F1 score to 82.5 (37.1 absolute improvement), the SQuAD question generation BLEU-4 to 22.12 (3.75 absolute improvement), and the DSTC7 document-grounded dialog response generation NIST-4 to 2.67 (human performance is 2.65). The code and pre-trained models are available at this https URL.\nAttention is All you Need (Ashish Vaswani et al., 2017) Ashish Vaswani, Noam M. Shazeer, Niki Parmar, Jakob Uszkoreit, Llion Jones, Aidan N. Gomez, Lukasz Kaiser, Illia Polosukhin. (2017)\nAttention is All you Need\nNIPS\nPaper Link\nInfluential Citation Count (7570), SS-ID (204e3073870fae3d05bcbc2f6a8e263d9b72e776)\nABSTRACT\nThe dominant sequence transduction models are based on complex recurrent or convolutional neural networks in an encoder-decoder configuration. The best performing models also connect the encoder and decoder through an attention mechanism. We propose a new simple network architecture, the Transformer, based solely on attention mechanisms, dispensing with recurrence and convolutions entirely. Experiments on two machine translation tasks show these models to be superior in quality while being more parallelizable and requiring significantly less time to train. Our model achieves 28.4 BLEU on the WMT 2014 English-to-German translation task, improving over the existing best results, including ensembles by over 2 BLEU. On the WMT 2014 English-to-French translation task, our model establishes a new single-model state-of-the-art BLEU score of 41.8 after training for 3.5 days on eight GPUs, a small fraction of the training costs of the best models from the literature. We show that the Transformer generalizes well to other tasks by applying it successfully to English constituency parsing both with large and limited training data.\nNatural- to formal-language generation using Tensor Product Representations (Kezhen Chen et al., 2019) Kezhen Chen, Qiuyuan Huang, H. Palangi, P. Smolensky, Kenneth D. Forbus, Jianfeng Gao. (2019)\nNatural- to formal-language generation using Tensor Product Representations\nArXiv\nPaper Link\nInfluential Citation Count (0), SS-ID (219e09984a2a71f54dbd86c15d31c7b0f53e1837)\nABSTRACT\nGenerating formal-language represented by relational tuples, such as Lisp programs or mathematical expressions, from a natural-language input is an extremely challenging task because it requires to explicitly capture discrete symbolic structural information from the input to generate the output. Most state-of-the-art neural sequence models do not explicitly capture such structure information, and thus do not perform well on these tasks. In this paper, we propose a new encoder-decoder model based on Tensor Product Representations (TPRs) for Natural- to Formal-language generation, called TP-N2F. The encoder of TP-N2F employs TPR \u0026lsquo;binding\u0026rsquo; to encode natural-language symbolic structure in vector space and the decoder uses TPR \u0026lsquo;unbinding\u0026rsquo; to generate a sequence of relational tuples, each consisting of a relation (or operation) and a number of arguments, in symbolic space. TP-N2F considerably outperforms LSTM-based Seq2Seq models, creating a new state of the art results on two benchmarks: the MathQA dataset for math problem solving, and the AlgoList dataset for program synthesis. Ablation studies show that improvements are mainly attributed to the use of TPRs in both the encoder and decoder to explicitly capture relational structure information for symbolic reasoning.\nGenerating Long Sequences with Sparse Transformers (Rewon Child et al., 2019) Rewon Child, Scott Gray, Alec Radford, Ilya Sutskever. (2019)\nGenerating Long Sequences with Sparse Transformers\nArXiv\nPaper Link\nInfluential Citation Count (79), SS-ID (21da617a0f79aabf94272107184606cefe90ab75)\nABSTRACT\nTransformers are powerful sequence models, but require time and memory that grows quadratically with the sequence length. In this paper we introduce sparse factorizations of the attention matrix which reduce this to $O(n \\sqrt{n})$. We also introduce a) a variation on architecture and initialization to train deeper networks, b) the recomputation of attention matrices to save memory, and c) fast attention kernels for training. We call networks with these changes Sparse Transformers, and show they can model sequences tens of thousands of timesteps long using hundreds of layers. We use the same architecture to model images, audio, and text from raw bytes, setting a new state of the art for density modeling of Enwik8, CIFAR-10, and ImageNet-64. We generate unconditional samples that demonstrate global coherence and great diversity, and show it is possible in principle to use self-attention to model sequences of length one million or more.\nAdversarial Training for Large Neural Language Models (Xiaodong Liu et al., 2020) Xiaodong Liu, Hao Cheng, Pengcheng He, Weizhu Chen, Yu Wang, Hoifung Poon, Jianfeng Gao. (2020)\nAdversarial Training for Large Neural Language Models\nArXiv\nPaper Link\nInfluential Citation Count (9), SS-ID (2ffcf8352223c95ae8cef4daaec995525ecc926b)\nABSTRACT\nGeneralization and robustness are both key desiderata for designing machine learning methods. Adversarial training can enhance robustness, but past work often finds it hurts generalization. In natural language processing (NLP), pre-training large neural language models such as BERT have demonstrated impressive gain in generalization for a variety of tasks, with further improvement from adversarial fine-tuning. However, these models are still vulnerable to adversarial attacks. In this paper, we show that adversarial pre-training can improve both generalization and robustness. We propose a general algorithm ALUM (Adversarial training for large neural LangUage Models), which regularizes the training objective by applying perturbations in the embedding space that maximizes the adversarial loss. We present the first comprehensive study of adversarial training in all stages, including pre-training from scratch, continual pre-training on a well-trained model, and task-specific fine-tuning. ALUM obtains substantial gains over BERT on a wide range of NLP tasks, in both regular and adversarial scenarios. Even for models that have been well trained on extremely large text corpora, such as RoBERTa, ALUM can still produce significant gains from continual pre-training, whereas conventional non-adversarial methods can not. ALUM can be further combined with task-specific fine-tuning to attain additional gains. The ALUM code is publicly available at this https URL.\nExploring the Limits of Transfer Learning with a Unified Text-to-Text Transformer (Colin Raffel et al., 2019) Colin Raffel, Noam M. Shazeer, Adam Roberts, Katherine Lee, Sharan Narang, Michael Matena, Yanqi Zhou, Wei Li, Peter J. Liu. (2019)\nExploring the Limits of Transfer Learning with a Unified Text-to-Text Transformer\nJ. Mach. Learn. Res.\nPaper Link\nInfluential Citation Count (615), SS-ID (3cfb319689f06bf04c2e28399361f414ca32c4b3)\nABSTRACT\nTransfer learning, where a model is first pre-trained on a data-rich task before being fine-tuned on a downstream task, has emerged as a powerful technique in natural language processing (NLP). The effectiveness of transfer learning has given rise to a diversity of approaches, methodology, and practice. In this paper, we explore the landscape of transfer learning techniques for NLP by introducing a unified framework that converts every language problem into a text-to-text format. Our systematic study compares pre-training objectives, architectures, unlabeled datasets, transfer approaches, and other factors on dozens of language understanding tasks. By combining the insights from our exploration with scale and our new \u0026ldquo;Colossal Clean Crawled Corpus\u0026rdquo;, we achieve state-of-the-art results on many benchmarks covering summarization, question answering, text classification, and more. To facilitate future work on transfer learning for NLP, we release our dataset, pre-trained models, and code.\nSwitch Transformers: Scaling to Trillion Parameter Models with Simple and Efficient Sparsity (W. Fedus et al., 2021) W. Fedus, Barret Zoph, Noam M. Shazeer. (2021)\nSwitch Transformers: Scaling to Trillion Parameter Models with Simple and Efficient Sparsity\nArXiv\nPaper Link\nInfluential Citation Count (69), SS-ID (3fd0f34117cf9395130e08c3f02ac2dadcca7206)\nABSTRACT\nIn deep learning, models typically reuse the same parameters for all inputs. Mixture of Experts (MoE) models defy this and instead select diﬀerent parameters for each incoming example. The result is a sparsely-activated model—with an outrageous number of parameters—but a constant computational cost. However, despite several notable successes of MoE, widespread adoption has been hindered by complexity, communication costs, and training instability. We address these with the introduction of the Switch Transformer. We simplify the MoE routing algorithm and design intuitive improved models with reduced communication and computational costs. Our proposed training techniques mitigate the instabilities, and we show large sparse models may be trained, for the ﬁrst time, with lower precision (bﬂoat16) formats. We design models based oﬀ T5-Base and T5-Large (Raﬀel et al., 2019) to obtain up to 7x increases in pre-training speed with the same computational resources. These improvements extend into multilingual settings where we measure gains over the mT5-Base version across all 101 languages. Finally, we advance the current scale of language models by pre-training up to trillion parameter models on the “Colossal Clean Crawled Corpus”, and achieve a 4x speedup over the T5-XXL model. 1 fourth axis: increase the parameter count while keeping the ﬂoating point operations (FLOPs) per example constant. Our hypothesis is that the parameter count, independent of total computation performed, is a separately important axis on which to scale. We achieve this by designing a sparsely activated model that eﬃciently uses hardware designed for dense matrix multiplications such as GPUs and TPUs. Our work here focuses on TPU architectures, but these class of models may be similarly trained on GPU clusters. In our distributed training setup, our sparsely activated layers split unique weights on diﬀerent devices. Therefore, the weights of the model increase with the number of devices, all while maintaining a manageable memory and computational footprint on each device.\nFixing Weight Decay Regularization in Adam (I. Loshchilov et al., 2017) I. Loshchilov, F. Hutter. (2017)\nFixing Weight Decay Regularization in Adam\nArXiv\nPaper Link\nInfluential Citation Count (93), SS-ID (45dfef0cc1ed96558c1c650432ce39d6a1050b6a)\nABSTRACT\nWe note that common implementations of adaptive gradient algorithms, such as Adam, limit the potential benefit of weight decay regularization, because the weights do not decay multiplicatively (as would be expected for standard weight decay) but by an additive constant factor. We propose a simple way to resolve this issue by decoupling weight decay and the optimization steps taken w.r.t. the loss function. We provide empirical evidence that our proposed modification (i) decouples the optimal choice of weight decay factor from the setting of the learning rate for both standard SGD and Adam, and (ii) substantially improves Adam\u0026rsquo;s generalization performance, allowing it to compete with SGD with momentum on image classification datasets (on which it was previously typically outperformed by the latter). We also demonstrate that longer optimization runs require smaller weight decay values for optimal results and introduce a normalized variant of weight decay to reduce this dependence. Finally, we propose a version of Adam with warm restarts (AdamWR) that has strong anytime performance while achieving state-of-the-art results on CIFAR-10 and ImageNet32x32. Our source code will become available after the review process.\nAutomatically Constructing a Corpus of Sentential Paraphrases (W. Dolan et al., 2005) W. Dolan, Chris Brockett. (2005)\nAutomatically Constructing a Corpus of Sentential Paraphrases\nIJCNLP\nPaper Link\nInfluential Citation Count (132), SS-ID (475354f10798f110d34792b6d88f31d6d5cb099e)\nABSTRACT\nAn obstacle to research in automatic paraphrase identification and generation is the lack of large-scale, publiclyavailable labeled corpora of sentential paraphrases. This paper describes the creation of the recently-released Microsoft Research Paraphrase Corpus, which contains 5801 sentence pairs, each hand-labeled with a binary judgment as to whether the pair constitutes a paraphrase. The corpus was created using heuristic extraction techniques in conjunction with an SVM-based classifier to select likely sentence-level paraphrases from a large corpus of topicclustered news data. These pairs were then submitted to human judges, who confirmed that 67% were in fact semantically equivalent. In addition to describing the corpus itself, we explore a number of issues that arose in defining guidelines for the human raters.\nVirtual Adversarial Training: A Regularization Method for Supervised and Semi-Supervised Learning (Takeru Miyato et al., 2017) Takeru Miyato, S. Maeda, Masanori Koyama, S. Ishii. (2017)\nVirtual Adversarial Training: A Regularization Method for Supervised and Semi-Supervised Learning\nIEEE Transactions on Pattern Analysis and Machine Intelligence\nPaper Link\nInfluential Citation Count (281), SS-ID (4b1c6f6521da545892f3f5dc39461584d4a27ec0)\nABSTRACT\nWe propose a new regularization method based on virtual adversarial loss: a new measure of local smoothness of the conditional label distribution given input. Virtual adversarial loss is defined as the robustness of the conditional label distribution around each input data point against local perturbation. Unlike adversarial training, our method defines the adversarial direction without label information and is hence applicable to semi-supervised learning. Because the directions in which we smooth the model are only “virtually” adversarial, we call our method virtual adversarial training (VAT). The computational cost of VAT is relatively low. For neural networks, the approximated gradient of virtual adversarial loss can be computed with no more than two pairs of forward- and back-propagations. In our experiments, we applied VAT to supervised and semi-supervised learning tasks on multiple benchmark datasets. With a simple enhancement of the algorithm based on the entropy minimization principle, our VAT achieves state-of-the-art performance for semi-supervised learning tasks on SVHN and CIFAR-10.\nKnow What You Don’t Know: Unanswerable Questions for SQuAD (Pranav Rajpurkar et al., 2018) Pranav Rajpurkar, Robin Jia, Percy Liang. (2018)\nKnow What You Don’t Know: Unanswerable Questions for SQuAD\nACL\nPaper Link\nInfluential Citation Count (339), SS-ID (4d1c856275744c0284312a3a50efb6ca9dc4cd4c)\nABSTRACT\nExtractive reading comprehension systems can often locate the correct answer to a question in a context document, but they also tend to make unreliable guesses on questions for which the correct answer is not stated in the context. Existing datasets either focus exclusively on answerable questions, or use automatically generated unanswerable questions that are easy to identify. To address these weaknesses, we present SQuADRUn, a new dataset that combines the existing Stanford Question Answering Dataset (SQuAD) with over 50,000 unanswerable questions written adversarially by crowdworkers to look similar to answerable ones. To do well on SQuADRUn, systems must not only answer questions when possible, but also determine when no answer is supported by the paragraph and abstain from answering. SQuADRUn is a challenging natural language understanding task for existing models: a strong neural system that gets 86% F1 on SQuAD achieves only 66% F1 on SQuADRUn. We release SQuADRUn to the community as the successor to SQuAD.\nExploiting Structured Knowledge in Text via Graph-Guided Representation Learning (Tao Shen et al., 2020) Tao Shen, Yi Mao, Pengcheng He, Guodong Long, Adam Trischler, Weizhu Chen. (2020)\nExploiting Structured Knowledge in Text via Graph-Guided Representation Learning\nEMNLP\nPaper Link\nInfluential Citation Count (2), SS-ID (4f42a0782f8b25fff62214e70bc43ce88f914c19)\nABSTRACT\nIn this work, we aim at equipping pre-trained language models with structured knowledge. We present two self-supervised tasks learning over raw text with the guidance from knowledge graphs. Building upon entity-level masked language models, our first contribution is an entity masking scheme that exploits relational knowledge underlying the text. This is fulfilled by using a linked knowledge graph to select informative entities and then masking their mentions. In addition we use knowledge graphs to obtain distractors for the masked entities, and propose a novel distractor-suppressed ranking objective which is optimized jointly with masked language model. In contrast to existing paradigms, our approach uses knowledge graphs implicitly, only during pre-training, to inject language models with structured knowledge via learning from raw text. It is more efficient than retrieval-based methods that perform entity linking and integration during finetuning and inference, and generalizes more effectively than the methods that directly learn from concatenated graph triples. Experiments show that our proposed model achieves improved performance on five benchmark datasets, including question answering and knowledge base completion tasks.\nOn the Variance of the Adaptive Learning Rate and Beyond (Liyuan Liu et al., 2019) Liyuan Liu, Haoming Jiang, Pengcheng He, Weizhu Chen, Xiaodong Liu, Jianfeng Gao, Jiawei Han. (2019)\nOn the Variance of the Adaptive Learning Rate and Beyond\nICLR\nPaper Link\nInfluential Citation Count (139), SS-ID (5759a53418ae3fe74ce96c531617914e7656e45e)\nABSTRACT\nThe learning rate warmup heuristic achieves remarkable success in stabilizing training, accelerating convergence and improving generalization for adaptive stochastic optimization algorithms like RMSprop and Adam. Here, we study its mechanism in details. Pursuing the theory behind warmup, we identify a problem of the adaptive learning rate (i.e., it has problematically large variance in the early stage), suggest warmup works as a variance reduction technique, and provide both empirical and theoretical evidence to verify our hypothesis. We further propose RAdam, a new variant of Adam, by introducing a term to rectify the variance of the adaptive learning rate. Extensive experimental results on image classification, language modeling, and neural machine translation verify our intuition and demonstrate the effectiveness and robustness of our proposed method. All implementations are available at: this https URL.\nA Broad-Coverage Challenge Corpus for Sentence Understanding through Inference (Adina Williams et al., 2017) Adina Williams, Nikita Nangia, Samuel R. Bowman. (2017)\nA Broad-Coverage Challenge Corpus for Sentence Understanding through Inference\nNAACL\nPaper Link\nInfluential Citation Count (438), SS-ID (5ded2b8c64491b4a67f6d39ce473d4b9347a672e)\nABSTRACT\nThis paper introduces the Multi-Genre Natural Language Inference (MultiNLI) corpus, a dataset designed for use in the development and evaluation of machine learning models for sentence understanding. At 433k examples, this resource is one of the largest corpora available for natural language inference (a.k.a. recognizing textual entailment), improving upon available resources in both its coverage and difficulty. MultiNLI accomplishes this by offering data from ten distinct genres of written and spoken English, making it possible to evaluate systems on nearly the full complexity of the language, while supplying an explicit setting for evaluating cross-genre domain adaptation. In addition, an evaluation using existing machine learning models designed for the Stanford NLI corpus shows that it represents a substantially more difficult task than does that corpus, despite the two showing similar levels of inter-annotator agreement.\nRACE: Large-scale ReAding Comprehension Dataset From Examinations (Guokun Lai et al., 2017) Guokun Lai, Qizhe Xie, Hanxiao Liu, Yiming Yang, E. Hovy. (2017)\nRACE: Large-scale ReAding Comprehension Dataset From Examinations\nEMNLP\nPaper Link\nInfluential Citation Count (179), SS-ID (636a79420d838eabe4af7fb25d6437de45ab64e8)\nABSTRACT\nWe present RACE, a new dataset for benchmark evaluation of methods in the reading comprehension task. Collected from the English exams for middle and high school Chinese students in the age range between 12 to 18, RACE consists of near 28,000 passages and near 100,000 questions generated by human experts (English instructors), and covers a variety of topics which are carefully designed for evaluating the students’ ability in understanding and reasoning. In particular, the proportion of questions that requires reasoning is much larger in RACE than that in other benchmark datasets for reading comprehension, and there is a significant gap between the performance of the state-of-the-art models (43%) and the ceiling human performance (95%). We hope this new dataset can serve as a valuable resource for research and evaluation in machine comprehension. The dataset is freely available at http://www.cs.cmu.edu/~glai1/data/race/ and the code is available at https://github.com/qizhex/RACE_AR_baselines.\nMulti-Task Deep Neural Networks for Natural Language Understanding (Xiaodong Liu et al., 2019) Xiaodong Liu, Pengcheng He, Weizhu Chen, Jianfeng Gao. (2019)\nMulti-Task Deep Neural Networks for Natural Language Understanding\nACL\nPaper Link\nInfluential Citation Count (168), SS-ID (658721bc13b0fa97366d38c05a96bf0a9f4bb0ac)\nABSTRACT\nIn this paper, we present a Multi-Task Deep Neural Network (MT-DNN) for learning representations across multiple natural language understanding (NLU) tasks. MT-DNN not only leverages large amounts of cross-task data, but also benefits from a regularization effect that leads to more general representations to help adapt to new tasks and domains. MT-DNN extends the model proposed in Liu et al. (2015) by incorporating a pre-trained bidirectional transformer language model, known as BERT (Devlin et al., 2018). MT-DNN obtains new state-of-the-art results on ten NLU tasks, including SNLI, SciTail, and eight out of nine GLUE tasks, pushing the GLUE benchmark to 82.7% (2.2% absolute improvement) as of February 25, 2019 on the latest GLUE test set. We also demonstrate using the SNLI and SciTail datasets that the representations learned by MT-DNN allow domain adaptation with substantially fewer in-domain labels than the pre-trained BERT representations. Our code and pre-trained models will be made publicly available.\nX-SQL: reinforce schema representation with context (Pengcheng He et al., 2019) Pengcheng He, Yi Mao, K. Chakrabarti, Weizhu Chen. (2019)\nX-SQL: reinforce schema representation with context\nArXiv\nPaper Link\nInfluential Citation Count (11), SS-ID (658d6885db65a82d6b2eff926f5c4017bf99c9da)\nABSTRACT\nIn this work, we present X-SQL, a new network architecture for the problem of parsing natural language to SQL query. X-SQL proposes to enhance the structural schema representation with the contextual output from BERT-style pre-training model, and together with type information to learn a new schema representation for down-stream tasks. We evaluated X-SQL on the WikiSQL dataset and show its new state-of-the-art performance.\nRecursive Deep Models for Semantic Compositionality Over a Sentiment Treebank (R. Socher et al., 2013) R. Socher, Alex Perelygin, Jean Wu, Jason Chuang, Christopher D. Manning, A. Ng, Christopher Potts. (2013)\nRecursive Deep Models for Semantic Compositionality Over a Sentiment Treebank\nEMNLP\nPaper Link\nInfluential Citation Count (861), SS-ID (687bac2d3320083eb4530bf18bb8f8f721477600)\nABSTRACT\nSemantic word spaces have been very useful but cannot express the meaning of longer phrases in a principled way. Further progress towards understanding compositionality in tasks such as sentiment detection requires richer supervised training and evaluation resources and more powerful models of composition. To remedy this, we introduce a Sentiment Treebank. It includes fine grained sentiment labels for 215,154 phrases in the parse trees of 11,855 sentences and presents new challenges for sentiment compositionality. To address them, we introduce the Recursive Neural Tensor Network. When trained on the new treebank, this model outperforms all previous methods on several metrics. It pushes the state of the art in single sentence positive/negative classification from 80% up to 85.4%. The accuracy of predicting fine-grained sentiment labels for all phrases reaches 80.7%, an improvement of 9.7% over bag of features baselines. Lastly, it is the only model that can accurately capture the effects of negation and its scope at various tree levels for both positive and negative phrases.\nLanguage Models are Few-Shot Learners (Tom B. Brown et al., 2020) Tom B. Brown, Benjamin Mann, Nick Ryder, Melanie Subbiah, J. Kaplan, Prafulla Dhariwal, Arvind Neelakantan, Pranav Shyam, Girish Sastry, Amanda Askell, Sandhini Agarwal, Ariel Herbert-Voss, Gretchen Krueger, T. Henighan, Rewon Child, A. Ramesh, Daniel M. Ziegler, Jeff Wu, Clemens Winter, Christopher Hesse, Mark Chen, Eric Sigler, Mateusz Litwin, Scott Gray, Benjamin Chess, Jack Clark, Christopher Berner, Sam McCandlish, Alec Radford, Ilya Sutskever, Dario Amodei. (2020)\nLanguage Models are Few-Shot Learners\nNeurIPS\nPaper Link\nInfluential Citation Count (428), SS-ID (6b85b63579a916f705a8e10a49bd8d849d91b1fc)\nABSTRACT\nRecent work has demonstrated substantial gains on many NLP tasks and benchmarks by pre-training on a large corpus of text followed by fine-tuning on a specific task. While typically task-agnostic in architecture, this method still requires task-specific fine-tuning datasets of thousands or tens of thousands of examples. By contrast, humans can generally perform a new language task from only a few examples or from simple instructions - something which current NLP systems still largely struggle to do. Here we show that scaling up language models greatly improves task-agnostic, few-shot performance, sometimes even reaching competitiveness with prior state-of-the-art fine-tuning approaches. Specifically, we train GPT-3, an autoregressive language model with 175 billion parameters, 10x more than any previous non-sparse language model, and test its performance in the few-shot setting. For all tasks, GPT-3 is applied without any gradient updates or fine-tuning, with tasks and few-shot demonstrations specified purely via text interaction with the model. GPT-3 achieves strong performance on many NLP datasets, including translation, question-answering, and cloze tasks, as well as several tasks that require on-the-fly reasoning or domain adaptation, such as unscrambling words, using a novel word in a sentence, or performing 3-digit arithmetic. At the same time, we also identify some datasets where GPT-3\u0026rsquo;s few-shot learning still struggles, as well as some datasets where GPT-3 faces methodological issues related to training on large web corpora. Finally, we find that GPT-3 can generate samples of news articles which human evaluators have difficulty distinguishing from articles written by humans. We discuss broader societal impacts of this finding and of GPT-3 in general.\nLongformer: The Long-Document Transformer (Iz Beltagy et al., 2020) Iz Beltagy, Matthew E. Peters, Arman Cohan. (2020)\nLongformer: The Long-Document Transformer\nArXiv\nPaper Link\nInfluential Citation Count (195), SS-ID (71b6394ad5654f5cd0fba763768ba4e523f7bbca)\nABSTRACT\nTransformer-based models are unable to process long sequences due to their self-attention operation, which scales quadratically with the sequence length. To address this limitation, we introduce the Longformer with an attention mechanism that scales linearly with sequence length, making it easy to process documents of thousands of tokens or longer. Longformer\u0026rsquo;s attention mechanism is a drop-in replacement for the standard self-attention and combines a local windowed attention with a task motivated global attention. Following prior work on long-sequence transformers, we evaluate Longformer on character-level language modeling and achieve state-of-the-art results on text8 and enwik8. In contrast to most prior work, we also pretrain Longformer and finetune it on a variety of downstream tasks. Our pretrained Longformer consistently outperforms RoBERTa on long document tasks and sets new state-of-the-art results on WikiHop and TriviaQA. We finally introduce the Longformer-Encoder-Decoder (LED), a Longformer variant for supporting long document generative sequence-to-sequence tasks, and demonstrate its effectiveness on the arXiv summarization dataset.\nELECTRA: Pre-training Text Encoders as Discriminators Rather Than Generators (Kevin Clark et al., 2020) Kevin Clark, Minh-Thang Luong, Quoc V. Le, Christopher D. Manning. (2020)\nELECTRA: Pre-training Text Encoders as Discriminators Rather Than Generators\nICLR\nPaper Link\nInfluential Citation Count (284), SS-ID (756810258e3419af76aff38c895c20343b0602d0)\nABSTRACT\nWhile masked language modeling (MLM) pre-training methods such as BERT produce excellent results on downstream NLP tasks, they require large amounts of compute to be effective. These approaches corrupt the input by replacing some tokens with [MASK] and then train a model to reconstruct the original tokens. As an alternative, we propose a more sample-efficient pre-training task called replaced token detection. Instead of masking the input, our approach corrupts it by replacing some input tokens with plausible alternatives sampled from a small generator network. Then, instead of training a model that predicts the original identities of the corrupted tokens, we train a discriminative model that predicts whether each token in the corrupted input was replaced by a generator sample or not. Thorough experiments demonstrate this new pre-training task is more efficient than MLM because the model learns from all input tokens rather than just the small subset that was masked out. As a result, the contextual representations learned by our approach substantially outperform the ones learned by methods such as BERT and XLNet given the same model size, data, and compute. The gains are particularly strong for small models; for example, we train a model on one GPU for 4 days that outperforms GPT (trained using 30x more compute) on the GLUE natural language understanding benchmark. Our approach also works well at scale, where we match the performance of RoBERTa, the current state-of-the-art pre-trained transformer, while using less than 1/4 of the compute.\nALBERT: A Lite BERT for Self-supervised Learning of Language Representations (Zhenzhong Lan et al., 2019) Zhenzhong Lan, Mingda Chen, Sebastian Goodman, Kevin Gimpel, Piyush Sharma, Radu Soricut. (2019)\nALBERT: A Lite BERT for Self-supervised Learning of Language Representations\nICLR\nPaper Link\nInfluential Citation Count (573), SS-ID (7a064df1aeada7e69e5173f7d4c8606f4470365b)\nABSTRACT\nIncreasing model size when pretraining natural language representations often results in improved performance on downstream tasks. However, at some point further model increases become harder due to GPU/TPU memory limitations and longer training times. To address these problems, we present two parameter-reduction techniques to lower memory consumption and increase the training speed of BERT. Comprehensive empirical evidence shows that our proposed methods lead to models that scale much better compared to the original BERT. We also use a self-supervised loss that focuses on modeling inter-sentence coherence, and show it consistently helps downstream tasks with multi-sentence inputs. As a result, our best model establishes new state-of-the-art results on the GLUE, RACE, and \\squad benchmarks while having fewer parameters compared to BERT-large. The code and the pretrained models are available at this https URL.\nSpanBERT: Improving Pre-training by Representing and Predicting Spans (Mandar Joshi et al., 2019) Mandar Joshi, Danqi Chen, Yinhan Liu, Daniel S. Weld, Luke Zettlemoyer, Omer Levy. (2019)\nSpanBERT: Improving Pre-training by Representing and Predicting Spans\nTACL\nPaper Link\nInfluential Citation Count (175), SS-ID (81f5810fbbab9b7203b9556f4ce3c741875407bc)\nABSTRACT\nWe present SpanBERT, a pre-training method that is designed to better represent and predict spans of text. Our approach extends BERT by (1) masking contiguous random spans, rather than random tokens, and (2) training the span boundary representations to predict the entire content of the masked span, without relying on the individual token representations within it. SpanBERT consistently outperforms BERT and our better-tuned baselines, with substantial gains on span selection tasks such as question answering and coreference resolution. In particular, with the same training data and model size as BERTlarge, our single model obtains 94.6% and 88.7% F1 on SQuAD 1.1 and 2.0 respectively. We also achieve a new state of the art on the OntoNotes coreference resolution task (79.6% F1), strong performance on the TACRED relation extraction benchmark, and even gains on GLUE.1\nMegatron-LM: Training Multi-Billion Parameter Language Models Using Model Parallelism (M. Shoeybi et al., 2019) M. Shoeybi, M. Patwary, Raul Puri, P. LeGresley, J. Casper, Bryan Catanzaro. (2019)\nMegatron-LM: Training Multi-Billion Parameter Language Models Using Model Parallelism\nArXiv\nPaper Link\nInfluential Citation Count (70), SS-ID (8323c591e119eb09b28b29fd6c7bc76bd889df7a)\nABSTRACT\nRecent work in language modeling demonstrates that training large transformer models advances the state of the art in Natural Language Processing applications. However, very large models can be quite difficult to train due to memory constraints. In this work, we present our techniques for training very large transformer models and implement a simple, efficient intra-layer model parallel approach that enables training transformer models with billions of parameters. Our approach does not require a new compiler or library changes, is orthogonal and complimentary to pipeline model parallelism, and can be fully implemented with the insertion of a few communication operations in native PyTorch. We illustrate this approach by converging transformer based models up to 8.3 billion parameters using 512 GPUs. We sustain 15.1 PetaFLOPs across the entire application with 76% scaling efficiency when compared to a strong single GPU baseline that sustains 39 TeraFLOPs, which is 30% of peak FLOPs. To demonstrate that large language models can further advance the state of the art (SOTA), we train an 8.3 billion parameter transformer language model similar to GPT-2 and a 3.9 billion parameter model similar to BERT. We show that careful attention to the placement of layer normalization in BERT-like models is critical to achieving increased performance as the model size grows. Using the GPT-2 model we achieve SOTA results on the WikiText103 (10.8 compared to SOTA perplexity of 15.8) and LAMBADA (66.5% compared to SOTA accuracy of 63.2%) datasets. Our BERT model achieves SOTA results on the RACE dataset (90.9% compared to SOTA accuracy of 89.4%).\nGLUE: A Multi-Task Benchmark and Analysis Platform for Natural Language Understanding (Alex Wang et al., 2018) Alex Wang, Amanpreet Singh, Julian Michael, Felix Hill, Omer Levy, Samuel R. Bowman. (2018)\nGLUE: A Multi-Task Benchmark and Analysis Platform for Natural Language Understanding\nBlackboxNLP@EMNLP\nPaper Link\nInfluential Citation Count (625), SS-ID (93b8da28d006415866bf48f9a6e06b5242129195)\nABSTRACT\nHuman ability to understand language is general, flexible, and robust. In contrast, most NLU models above the word level are designed for a specific task and struggle with out-of-domain data. If we aspire to develop models with understanding beyond the detection of superficial correspondences between inputs and outputs, then it is critical to develop a unified model that can execute a range of linguistic tasks across different domains. To facilitate research in this direction, we present the General Language Understanding Evaluation (GLUE, gluebenchmark.com): a benchmark of nine diverse NLU tasks, an auxiliary dataset for probing models for understanding of specific linguistic phenomena, and an online platform for evaluating and comparing models. For some benchmark tasks, training data is plentiful, but for others it is limited or does not match the genre of the test set. GLUE thus favors models that can represent linguistic knowledge in a way that facilitates sample-efficient learning and effective knowledge-transfer across tasks. While none of the datasets in GLUE were created from scratch for the benchmark, four of them feature privately-held test data, which is used to ensure that the benchmark is used fairly. We evaluate baselines that use ELMo (Peters et al., 2018), a powerful transfer learning technique, as well as state-of-the-art sentence representation models. The best models still achieve fairly low absolute scores. Analysis with our diagnostic dataset yields similarly weak performance over all phenomena tested, with some exceptions.\nLanguage Models are Unsupervised Multitask Learners (Alec Radford et al., 2019) Alec Radford, Jeff Wu, Rewon Child, D. Luan, Dario Amodei, Ilya Sutskever. (2019)\nLanguage Models are Unsupervised Multitask Learners\nPaper Link\nInfluential Citation Count (1306), SS-ID (9405cc0d6169988371b2755e573cc28650d14dfe)\nABSTRACT\nNatural language processing tasks, such as question answering, machine translation, reading comprehension, and summarization, are typically approached with supervised learning on taskspecific datasets. We demonstrate that language models begin to learn these tasks without any explicit supervision when trained on a new dataset of millions of webpages called WebText. When conditioned on a document plus questions, the answers generated by the language model reach 55 F1 on the CoQA dataset matching or exceeding the performance of 3 out of 4 baseline systems without using the 127,000+ training examples. The capacity of the language model is essential to the success of zero-shot task transfer and increasing it improves performance in a log-linear fashion across tasks. Our largest model, GPT-2, is a 1.5B parameter Transformer that achieves state of the art results on 7 out of 8 tested language modeling datasets in a zero-shot setting but still underfits WebText. Samples from the model reflect these improvements and contain coherent paragraphs of text. These findings suggest a promising path towards building language processing systems which learn to perform tasks from their naturally occurring demonstrations.\nTensor Product Variable Binding and the Representation of Symbolic Structures in Connectionist Systems (Geoffrey E. Hinton, 1991) Geoffrey E. Hinton. (1991)\nTensor Product Variable Binding and the Representation of Symbolic Structures in Connectionist Systems\nPaper Link\nInfluential Citation Count (52), SS-ID (9438172bfbb74a6a4ea4242b180d4335bb1f18b7)\nABSTRACT\nThis chapter contains sections titled: 1. Introduction, 2. Connectionist Representation and Tensor Product Binding: Definition and Examples, 3. Tensor Product Representation: Properties, 4. Conclusion\nLooking Beyond the Surface: A Challenge Set for Reading Comprehension over Multiple Sentences (Daniel Khashabi et al., 2018) Daniel Khashabi, Snigdha Chaturvedi, Michael Roth, Shyam Upadhyay, D. Roth. (2018)\nLooking Beyond the Surface: A Challenge Set for Reading Comprehension over Multiple Sentences\nNAACL\nPaper Link\nInfluential Citation Count (46), SS-ID (99ad0533f84c110da2d0713d5798e6e14080b159)\nABSTRACT\nWe present a reading comprehension challenge in which questions can only be answered by taking into account information from multiple sentences. We solicit and verify questions and answers for this challenge through a 4-step crowdsourcing experiment. Our challenge dataset contains 6,500+ questions for 1000+ paragraphs across 7 different domains (elementary school science, news, travel guides, fiction stories, etc) bringing in linguistic diversity to the texts and to the questions wordings. On a subset of our dataset, we found human solvers to achieve an F1-score of 88.1%. We analyze a range of baselines, including a recent state-of-art reading comprehension system, and demonstrate the difficulty of this challenge, despite a high human performance. The dataset is the first to study multi-sentence inference at scale, with an open-ended set of question types that requires reasoning skills.\nSemEval-2017 Task 1: Semantic Textual Similarity Multilingual and Crosslingual Focused Evaluation (Daniel Matthew Cer et al., 2017) Daniel Matthew Cer, Mona T. Diab, Eneko Agirre, I. Lopez-Gazpio, Lucia Specia. (2017)\nSemEval-2017 Task 1: Semantic Textual Similarity Multilingual and Crosslingual Focused Evaluation\nSemEval@ACL\nPaper Link\nInfluential Citation Count (157), SS-ID (a23fa96e7217ba0e9405d9e1fe3cdedd57b6e096)\nABSTRACT\nSemantic Textual Similarity (STS) measures the meaning similarity of sentences. Applications include machine translation (MT), summarization, generation, question answering (QA), short answer grading, semantic search, dialog and conversational systems. The STS shared task is a venue for assessing the current state-of-the-art. The 2017 task focuses on multilingual and cross-lingual pairs with one sub-track exploring MT quality estimation (MTQE) data. The task obtained strong participation from 31 teams, with 17 participating in all language tracks. We summarize performance and review a selection of well performing methods. Analysis highlights common errors, providing insight into the limitations of existing models. To support ongoing work on semantic representations, the STS Benchmark is introduced as a new shared training and evaluation set carefully selected from the corpus of English STS shared task data (2012-2017).\nReCoRD: Bridging the Gap between Human and Machine Commonsense Reading Comprehension (Sheng Zhang et al., 2018) Sheng Zhang, Xiaodong Liu, Jingjing Liu, Jianfeng Gao, Kevin Duh, Benjamin Van Durme. (2018)\nReCoRD: Bridging the Gap between Human and Machine Commonsense Reading Comprehension\nArXiv\nPaper Link\nInfluential Citation Count (28), SS-ID (a5b66ee341cb990f7f70a124b5fab3316d3b7e27)\nABSTRACT\nWe present a large-scale dataset, ReCoRD, for machine reading comprehension requiring commonsense reasoning. Experiments on this dataset demonstrate that the performance of state-of-the-art MRC systems fall far behind human performance. ReCoRD represents a challenge for future research to bridge the gap between human and machine commonsense reading comprehension. ReCoRD is available at this http URL\nAdam: A Method for Stochastic Optimization (Diederik P. Kingma et al., 2014) Diederik P. Kingma, Jimmy Ba. (2014)\nAdam: A Method for Stochastic Optimization\nICLR\nPaper Link\nInfluential Citation Count (14607), SS-ID (a6cb366736791bcccc5c8639de5a8f9636bf87e8)\nABSTRACT\nWe introduce Adam, an algorithm for first-order gradient-based optimization of stochastic objective functions, based on adaptive estimates of lower-order moments. The method is straightforward to implement, is computationally efficient, has little memory requirements, is invariant to diagonal rescaling of the gradients, and is well suited for problems that are large in terms of data and/or parameters. The method is also appropriate for non-stationary objectives and problems with very noisy and/or sparse gradients. The hyper-parameters have intuitive interpretations and typically require little tuning. Some connections to related algorithms, on which Adam was inspired, are discussed. We also analyze the theoretical convergence properties of the algorithm and provide a regret bound on the convergence rate that is comparable to the best known results under the online convex optimization framework. Empirical results demonstrate that Adam works well in practice and compares favorably to other stochastic optimization methods. Finally, we discuss AdaMax, a variant of Adam based on the infinity norm.\nWiC: the Word-in-Context Dataset for Evaluating Context-Sensitive Meaning Representations (Mohammad Taher Pilehvar et al., 2018) Mohammad Taher Pilehvar, José Camacho-Collados. (2018)\nWiC: the Word-in-Context Dataset for Evaluating Context-Sensitive Meaning Representations\nNAACL\nPaper Link\nInfluential Citation Count (7), SS-ID (a925f818f787e142c5f6bcb7bbd7ede2deb34860)\nABSTRACT\nBy design, word embeddings are unable to model the dynamic nature of words’ semantics, i.e., the property of words to correspond to potentially different meanings. To address this limitation, dozens of specialized meaning representation techniques such as sense or contextualized embeddings have been proposed. However, despite the popularity of research on this topic, very few evaluation benchmarks exist that specifically focus on the dynamic semantics of words. In this paper we show that existing models have surpassed the performance ceiling of the standard evaluation dataset for the purpose, i.e., Stanford Contextual Word Similarity, and highlight its shortcomings. To address the lack of a suitable benchmark, we put forward a large-scale Word in Context dataset, called WiC, based on annotations curated by experts, for generic evaluation of context-sensitive representations. WiC is released in https://pilehvar.github.io/wic/.\nSMART: Robust and Efficient Fine-Tuning for Pre-trained Natural Language Models through Principled Regularized Optimization (Haoming Jiang et al., 2019) Haoming Jiang, Pengcheng He, Weizhu Chen, Xiaodong Liu, Jianfeng Gao, T. Zhao. (2019)\nSMART: Robust and Efficient Fine-Tuning for Pre-trained Natural Language Models through Principled Regularized Optimization\nACL\nPaper Link\nInfluential Citation Count (24), SS-ID (ab70853cd5912c470f6ff95e95481980f0a2a41b)\nABSTRACT\nTransfer learning has fundamentally changed the landscape of natural language processing (NLP). Many state-of-the-art models are first pre-trained on a large text corpus and then fine-tuned on downstream tasks. However, due to limited data resources from downstream tasks and the extremely high complexity of pre-trained models, aggressive fine-tuning often causes the fine-tuned model to overfit the training data of downstream tasks and fail to generalize to unseen data. To address such an issue in a principled manner, we propose a new learning framework for robust and efficient fine-tuning for pre-trained models to attain better generalization performance. The proposed framework contains two important ingredients: 1. Smoothness-inducing regularization, which effectively manages the complexity of the model; 2. Bregman proximal point optimization, which is an instance of trust-region methods and can prevent aggressive updating. Our experiments show that the proposed framework achieves new state-of-the-art performance on a number of NLP tasks including GLUE, SNLI, SciTail and ANLI. Moreover, it also outperforms the state-of-the-art T5 model, which is the largest pre-trained model containing 11 billion parameters, on GLUE.\nDeep Learning Based Text Classification: A Comprehensive Review (Shervin Minaee et al., 2021) Shervin Minaee, E. Cambria, Jianfeng Gao. (2021)\nDeep Learning Based Text Classification: A Comprehensive Review\nPaper Link\nInfluential Citation Count (9), SS-ID (adc61e21eafecfbf6ebecc570f9f913659a2bfb2)\nABSTRACT\nDeep learning basedmodels have surpassed classical machine learning based approaches in various text classification tasks, including sentiment analysis, news categorization, question answering, and natural language inference. In this paper, we provide a comprehensive review of more than 150 deep learning based models for text classification developed in recent years, and discuss their technical contributions, similarities, and strengths. We also provide a summary of more than 40 popular datasets widely used for text classification. Finally, we provide a quantitative analysis of the performance of different deep learning models on popular benchmarks, and discuss future research directions. Additional\nSWAG: A Large-Scale Adversarial Dataset for Grounded Commonsense Inference (Rowan Zellers et al., 2018) Rowan Zellers, Yonatan Bisk, Roy Schwartz, Yejin Choi. (2018)\nSWAG: A Large-Scale Adversarial Dataset for Grounded Commonsense Inference\nEMNLP\nPaper Link\nInfluential Citation Count (78), SS-ID (af5c4b80fbf847f69a202ba5a780a3dd18c1a027)\nABSTRACT\nGiven a partial description like “she opened the hood of the car,” humans can reason about the situation and anticipate what might come next (”then, she examined the engine”). In this paper, we introduce the task of grounded commonsense inference, unifying natural language inference and commonsense reasoning. We present SWAG, a new dataset with 113k multiple choice questions about a rich spectrum of grounded situations. To address the recurring challenges of the annotation artifacts and human biases found in many existing datasets, we propose Adversarial Filtering (AF), a novel procedure that constructs a de-biased dataset by iteratively training an ensemble of stylistic classifiers, and using them to filter the data. To account for the aggressive adversarial filtering, we use state-of-the-art language models to massively oversample a diverse set of potential counterfactuals. Empirical results demonstrate that while humans can solve the resulting inference problems with high accuracy (88%), various competitive models struggle on our task. We provide comprehensive analysis that indicates significant opportunities for future research.\nThe Third PASCAL Recognizing Textual Entailment Challenge (Danilo Giampiccolo et al., 2007) Danilo Giampiccolo, B. Magnini, Ido Dagan, W. Dolan. (2007)\nThe Third PASCAL Recognizing Textual Entailment Challenge\nACL-PASCAL@ACL\nPaper Link\nInfluential Citation Count (62), SS-ID (b2815bc4c9e4260227cd7ca0c9d68d41c4c2f58b)\nABSTRACT\nTransformer-XL: Attentive Language Models beyond a Fixed-Length Context (Zihang Dai et al., 2019) Zihang Dai, Zhilin Yang, Yiming Yang, J. Carbonell, Quoc V. Le, R. Salakhutdinov. (2019)\nTransformer-XL: Attentive Language Models beyond a Fixed-Length Context\nACL\nPaper Link\nInfluential Citation Count (237), SS-ID (c4744a7c2bb298e4a52289a1e085c71cc3d37bc6)\nABSTRACT\nTransformers have a potential of learning longer-term dependency, but are limited by a fixed-length context in the setting of language modeling. We propose a novel neural architecture Transformer-XL that enables learning dependency beyond a fixed length without disrupting temporal coherence. It consists of a segment-level recurrence mechanism and a novel positional encoding scheme. Our method not only enables capturing longer-term dependency, but also resolves the context fragmentation problem. As a result, Transformer-XL learns dependency that is 80% longer than RNNs and 450% longer than vanilla Transformers, achieves better performance on both short and long sequences, and is up to 1,800+ times faster than vanilla Transformers during evaluation. Notably, we improve the state-of-the-art results of bpc/perplexity to 0.99 on enwiki8, 1.08 on text8, 18.3 on WikiText-103, 21.8 on One Billion Word, and 54.5 on Penn Treebank (without finetuning). When trained only on WikiText-103, Transformer-XL manages to generate reasonably coherent, novel text articles with thousands of tokens. Our code, pretrained models, and hyperparameters are available in both Tensorflow and PyTorch.\nSelf-Attention with Relative Position Representations (Peter Shaw et al., 2018) Peter Shaw, Jakob Uszkoreit, Ashish Vaswani. (2018)\nSelf-Attention with Relative Position Representations\nNAACL\nPaper Link\nInfluential Citation Count (134), SS-ID (c8efcc854d97dfc2a42b83316a2109f9d166e43f)\nABSTRACT\nRelying entirely on an attention mechanism, the Transformer introduced by Vaswani et al. (2017) achieves state-of-the-art results for machine translation. In contrast to recurrent and convolutional neural networks, it does not explicitly model relative or absolute position information in its structure. Instead, it requires adding representations of absolute positions to its inputs. In this work we present an alternative approach, extending the self-attention mechanism to efficiently consider representations of the relative positions, or distances between sequence elements. On the WMT 2014 English-to-German and English-to-French translation tasks, this approach yields improvements of 1.3 BLEU and 0.3 BLEU over absolute position representations, respectively. Notably, we observe that combining relative and absolute position representations yields no further improvement in translation quality. We describe an efficient implementation of our method and cast it as an instance of relation-aware self-attention mechanisms that can generalize to arbitrary graph-labeled inputs.\nNeural Network Acceptability Judgments (Alex Warstadt et al., 2018) Alex Warstadt, Amanpreet Singh, Samuel R. Bowman. (2018)\nNeural Network Acceptability Judgments\nTransactions of the Association for Computational Linguistics\nPaper Link\nInfluential Citation Count (89), SS-ID (cb0f3ee1e98faf92429d601cdcd76c69c1e484eb)\nABSTRACT\nAbstract This paper investigates the ability of artificial neural networks to judge the grammatical acceptability of a sentence, with the goal of testing their linguistic competence. We introduce the Corpus of Linguistic Acceptability (CoLA), a set of 10,657 English sentences labeled as grammatical or ungrammatical from published linguistics literature. As baselines, we train several recurrent neural network models on acceptability classification, and find that our models outperform unsupervised models by Lau et al. (2016) on CoLA. Error-analysis on specific grammatical phenomena reveals that both Lau et al.’s models and ours learn systematic generalizations like subject-verb-object order. However, all models we test perform far below human level on a wide range of grammatical constructions.\nStructBERT: Incorporating Language Structures into Pre-training for Deep Language Understanding (Wei Wang et al., 2019) Wei Wang, Bin Bi, Ming Yan, Chen Wu, Zuyi Bao, Liwei Peng, Luo Si. (2019)\nStructBERT: Incorporating Language Structures into Pre-training for Deep Language Understanding\nICLR\nPaper Link\nInfluential Citation Count (21), SS-ID (d56c1fc337fb07ec004dc846f80582c327af717c)\nABSTRACT\nRecently, the pre-trained language model, BERT (and its robustly optimized version RoBERTa), has attracted a lot of attention in natural language understanding (NLU), and achieved state-of-the-art accuracy in various NLU tasks, such as sentiment classification, natural language inference, semantic textual similarity and question answering. Inspired by the linearization exploration work of Elman [8], we extend BERT to a new model, StructBERT, by incorporating language structures into pre-training. Specifically, we pre-train StructBERT with two auxiliary tasks to make the most of the sequential order of words and sentences, which leverage language structures at the word and sentence levels, respectively. As a result, the new model is adapted to different levels of language understanding required by downstream tasks. The StructBERT with structural pre-training gives surprisingly good empirical results on a variety of downstream tasks, including pushing the state-of-the-art on the GLUE benchmark to 89.0 (outperforming all published models), the F1 score on SQuAD v1.1 question answering to 93.0, the accuracy on SNLI to 91.7.\nA Simple Method for Commonsense Reasoning (Trieu H. Trinh et al., 2018) Trieu H. Trinh, Quoc V. Le. (2018)\nA Simple Method for Commonsense Reasoning\nArXiv\nPaper Link\nInfluential Citation Count (16), SS-ID (d7b6753a2d4a2b286c396854063bde3a91b75535)\nABSTRACT\nCommonsense reasoning is a long-standing challenge for deep learning. For example, it is difficult to use neural networks to tackle the Winograd Schema dataset (Levesque et al., 2011). In this paper, we present a simple method for commonsense reasoning with neural networks, using unsupervised learning. Key to our method is the use of language models, trained on a massive amount of unlabled data, to score multiple choice questions posed by commonsense reasoning tests. On both Pronoun Disambiguation and Winograd Schema challenges, our models outperform previous state-of-the-art methods by a large margin, without using expensive annotated knowledge bases or hand-engineered features. We train an array of large RNN language models that operate at word or character level on LM-1-Billion, CommonCrawl, SQuAD, Gutenberg Books, and a customized corpus for this task and show that diversity of training data plays an important role in test performance. Further analysis also shows that our system successfully discovers important features of the context that decide the correct answer, indicating a good grasp of commonsense knowledge.\nEnhancing the Transformer with Explicit Relational Encoding for Math Problem Solving (Imanol Schlag et al., 2019) Imanol Schlag, P. Smolensky, Roland Fernandez, N. Jojic, J. Schmidhuber, Jianfeng Gao. (2019)\nEnhancing the Transformer with Explicit Relational Encoding for Math Problem Solving\nArXiv\nPaper Link\nInfluential Citation Count (1), SS-ID (d88f31a0091eee02c5a2aa2013914818cdef114e)\nABSTRACT\nWe incorporate Tensor-Product Representations within the Transformer in order to better support the explicit representation of relation structure. Our Tensor-Product Transformer (TP-Transformer) sets a new state of the art on the recently-introduced Mathematics Dataset containing 56 categories of free-form math word-problems. The essential component of the model is a novel attention mechanism, called TP-Attention, which explicitly encodes the relations between each Transformer cell and the other cells from which values have been retrieved by attention. TP-Attention goes beyond linear combination of retrieved values, strengthening representation-building and resolving ambiguities introduced by multiple layers of standard attention. The TP-Transformer\u0026rsquo;s attention maps give better insights into how it is capable of solving the Mathematics Dataset\u0026rsquo;s challenging problems. Pretrained models and code will be made available after publication.\nSuperGLUE: A Stickier Benchmark for General-Purpose Language Understanding Systems (Alex Wang et al., 2019) Alex Wang, Yada Pruksachatkun, Nikita Nangia, Amanpreet Singh, Julian Michael, Felix Hill, Omer Levy, Samuel R. Bowman. (2019)\nSuperGLUE: A Stickier Benchmark for General-Purpose Language Understanding Systems\nNeurIPS\nPaper Link\nInfluential Citation Count (137), SS-ID (d9f6ada77448664b71128bb19df15765336974a6)\nABSTRACT\nIn the last year, new models and methods for pretraining and transfer learning have driven striking performance improvements across a range of language understanding tasks. The GLUE benchmark, introduced a little over one year ago, offers a single-number metric that summarizes progress on a diverse set of such tasks, but performance on the benchmark has recently surpassed the level of non-expert humans, suggesting limited headroom for further research. In this paper we present SuperGLUE, a new benchmark styled after GLUE with a new set of more difficult language understanding tasks, a software toolkit, and a public leaderboard. SuperGLUE is available at this http URL.\nThe Sixth PASCAL Recognizing Textual Entailment Challenge (L. Bentivogli et al., 2009) L. Bentivogli, Peter Clark, Ido Dagan, Danilo Giampiccolo. (2009)\nThe Sixth PASCAL Recognizing Textual Entailment Challenge\nTAC\nPaper Link\nInfluential Citation Count (80), SS-ID (db8885a0037fe47d973ade79d696586453710233)\nABSTRACT\nThis paper presents the Sixth Recognizing Textual Entailment (RTE-6) challenge. This year a major innovation was introduced, as the traditional Main Task was replaced by a new task, similar to the RTE-5 Search Pilot, in which Textual Entailment is performed on a real corpus in the Update Summarization scenario. A subtask was also proposed, aimed at detecting novel information. To continue the effort of testing RTE in NLP applications, a KBP Validation Pilot Task was set up, in which RTE systems had to validate the output of systems participating in the KBP Slot Filling Task. Eighteen teams participated in the Main Task (48 submitted runs) and 9 in the Novelty Detection Subtask (22 submitted runs). As for the Pilot, 10 runs were submitted by 3 participants. Finally, the exploratory effort started in RTE-5 to perform resource evaluation through ablation tests was not only reiterated in RTE-6, but also extended to tools.\nThe PASCAL Recognising Textual Entailment Challenge (Ido Dagan et al., 2007) Ido Dagan, Oren Glickman, B. Magnini. (2007)\nThe PASCAL Recognising Textual Entailment Challenge\nMLCW\nPaper Link\nInfluential Citation Count (229), SS-ID (de794d50713ea5f91a7c9da3d72041e2f5ef8452)\nABSTRACT\nThis paper presents the Third PASCAL Recognising Textual Entailment Challenge (RTE-3), providing an overview of the dataset creating methodology and the submitted systems. In creating this year\u0026rsquo;s dataset, a number of longer texts were introduced to make the challenge more oriented to realistic scenarios. Additionally, a pool of resources was offered so that the participants could share common tools. A pilot task was also set up, aimed at differentiating unknown entailments from identified contradictions and providing justifications for overall system decisions. 26 participants submitted 44 runs, using different approaches and generally presenting new entailment models and achieving higher scores than in the previous challenges.\nBERT: Pre-training of Deep Bidirectional Transformers for Language Understanding (Jacob Devlin et al., 2019) Jacob Devlin, Ming-Wei Chang, Kenton Lee, Kristina Toutanova. (2019)\nBERT: Pre-training of Deep Bidirectional Transformers for Language Understanding\nNAACL\nPaper Link\nInfluential Citation Count (9863), SS-ID (df2b0e26d0599ce3e70df8a9da02e51594e0e992)\nABSTRACT\nWe introduce a new language representation model called BERT, which stands for Bidirectional Encoder Representations from Transformers. Unlike recent language representation models (Peters et al., 2018a; Radford et al., 2018), BERT is designed to pre-train deep bidirectional representations from unlabeled text by jointly conditioning on both left and right context in all layers. As a result, the pre-trained BERT model can be fine-tuned with just one additional output layer to create state-of-the-art models for a wide range of tasks, such as question answering and language inference, without substantial task-specific architecture modifications. BERT is conceptually simple and empirically powerful. It obtains new state-of-the-art results on eleven natural language processing tasks, including pushing the GLUE score to 80.5 (7.7 point absolute improvement), MultiNLI accuracy to 86.7% (4.6% absolute improvement), SQuAD v1.1 question answering Test F1 to 93.2 (1.5 point absolute improvement) and SQuAD v2.0 Test F1 to 83.1 (5.1 point absolute improvement).\nXLNet: Generalized Autoregressive Pretraining for Language Understanding (Zhilin Yang et al., 2019) Zhilin Yang, Zihang Dai, Yiming Yang, J. Carbonell, R. Salakhutdinov, Quoc V. Le. (2019)\nXLNet: Generalized Autoregressive Pretraining for Language Understanding\nNeurIPS\nPaper Link\nInfluential Citation Count (631), SS-ID (e0c6abdbdecf04ffac65c440da77fb9d66bb474c)\nABSTRACT\nWith the capability of modeling bidirectional contexts, denoising autoencoding based pretraining like BERT achieves better performance than pretraining approaches based on autoregressive language modeling. However, relying on corrupting the input with masks, BERT neglects dependency between the masked positions and suffers from a pretrain-finetune discrepancy. In light of these pros and cons, we propose XLNet, a generalized autoregressive pretraining method that (1) enables learning bidirectional contexts by maximizing the expected likelihood over all permutations of the factorization order and (2) overcomes the limitations of BERT thanks to its autoregressive formulation. Furthermore, XLNet integrates ideas from Transformer-XL, the state-of-the-art autoregressive model, into pretraining. Empirically, under comparable experiment settings, XLNet outperforms BERT on 20 tasks, often by a large margin, including question answering, natural language inference, sentiment analysis, and document ranking.\nSmall-Bench NLP: Benchmark for small single GPU trained models in Natural Language Processing (Kamal Raj Kanakarajan et al., 2021) Kamal Raj Kanakarajan, Bhuvana Kundumani, Malaikannan Sankarasubbu. (2021)\nSmall-Bench NLP: Benchmark for small single GPU trained models in Natural Language Processing\nArXiv\nPaper Link\nInfluential Citation Count (0), SS-ID (e762d09783b4cf1fd9907b48b3477eb355dd8690)\nABSTRACT\nRecent progress in the Natural Language Processing domain has given us several State-ofthe-Art (SOTA) pretrained models which can be finetuned for specific tasks. These large models with billions of parameters trained on numerous GPUs/TPUs over weeks are leading in the benchmark leaderboards. In this paper, we discuss the need for a benchmark for cost and time effective smaller models trained on a single GPU. This will enable researchers with resource constraints experiment with novel and innovative ideas on tokenization, pretraining tasks, architecture, fine tuning methods etc. We set up Small-Bench NLP, a benchmark for small efficient neural language models trained on a single GPU. Small-Bench NLP benchmark comprises of eight NLP tasks on the publicly available GLUE datasets and a leaderboard to track the progress of the community. Our ELECTRA-DeBERTa (15M parameters) small model architecture achieves an average score of 81.53 which is comparable to that of BERT-Base’s 82.20 (110M parameters). Our models, code and leaderboard are available at https://github.com/small\nPointer Sentinel Mixture Models (Stephen Merity et al., 2016) Stephen Merity, Caiming Xiong, James Bradbury, R. Socher. (2016)\nPointer Sentinel Mixture Models\nICLR\nPaper Link\nInfluential Citation Count (218), SS-ID (efbd381493bb9636f489b965a2034d529cd56bcd)\nABSTRACT\nRecent neural network sequence models with softmax classifiers have achieved their best language modeling performance only with very large hidden states and large vocabularies. Even then they struggle to predict rare or unseen words even if the context makes the prediction unambiguous. We introduce the pointer sentinel mixture architecture for neural sequence models which has the ability to either reproduce a word from the recent context or produce a word from a standard softmax classifier. Our pointer sentinel-LSTM model achieves state of the art language modeling performance on the Penn Treebank (70.9 perplexity) while using far fewer parameters than a standard softmax LSTM. In order to evaluate how well language models can exploit longer contexts and deal with more realistic vocabularies and larger corpora we also introduce the freely available WikiText corpus.\nA Hybrid Neural Network Model for Commonsense Reasoning (Pengcheng He et al., 2019) Pengcheng He, Xiaodong Liu, Weizhu Chen, Jianfeng Gao. (2019)\nA Hybrid Neural Network Model for Commonsense Reasoning\nEMNLP\nPaper Link\nInfluential Citation Count (3), SS-ID (f5e3990ab9a67f824ef2c28114e2b158d653edca)\nABSTRACT\nThis paper proposes a hybrid neural network(HNN) model for commonsense reasoning. An HNN consists of two component models, a masked language model and a semantic similarity model, which share a BERTbased contextual encoder but use different model-specific input and output layers. HNN obtains new state-of-the-art results on three classic commonsense reasoning tasks, pushing the WNLI benchmark to 89%, the Winograd Schema Challenge (WSC) benchmark to 75.1%, and the PDP60 benchmark to 90.0%. An ablation study shows that language models and semantic similarity models are complementary approaches to commonsense reasoning, and HNN effectively combines the strengths of both. The code and pre-trained models will be publicly available at https: //github.com/namisan/mt-dnn.\nSemEval-2012 Task 7: Choice of Plausible Alternatives: An Evaluation of Commonsense Causal Reasoning (A. Gordon et al., 2011) A. Gordon, Zornitsa Kozareva, Melissa Roemmele. (2011)\nSemEval-2012 Task 7: Choice of Plausible Alternatives: An Evaluation of Commonsense Causal Reasoning\n*SEMEVAL\nPaper Link\nInfluential Citation Count (56), SS-ID (fb0b11046474b8f1c810f947f313c7c7229a988f)\nABSTRACT\nSemEval-2012 Task 7 presented a deceptively simple challenge: given an English sentence as a premise, select the sentence amongst two alternatives that more plausibly has a causal relation to the premise. In this paper, we describe the development of this task and its motivation. We describe the two systems that competed in this task as part of SemEval-2012, and compare their results to those achieved in previously published research. We discuss the characteristics that make this task so difficult, and offer our thoughts on how progress can be made in the future.\nMusic Transformer: Generating Music with Long-Term Structure (Cheng-Zhi Anna Huang et al., 2019) Cheng-Zhi Anna Huang, Ashish Vaswani, Jakob Uszkoreit, Ian Simon, Curtis Hawthorne, Noam M. Shazeer, Andrew M. Dai, M. Hoffman, Monica Dinculescu, D. Eck. (2019)\nMusic Transformer: Generating Music with Long-Term Structure\nICLR\nPaper Link\nInfluential Citation Count (35), SS-ID (fb507ada871d1e8c29e376dbf7b7879689aa89f9)\nABSTRACT\nMusic relies heavily on repetition to build structure and meaning. Self-reference occurs on multiple timescales, from motifs to phrases to reusing of entire sections of music, such as in pieces with ABA structure. The Transformer (Vaswani et al., 2017), a sequence model based on self-attention, has achieved compelling results in many generation tasks that require maintaining long-range coherence. This suggests that self-attention might also be well-suited to modeling music. In musical composition and performance, however, relative timing is critically important. Existing approaches for representing relative positional information in the Transformer modulate attention based on pairwise distance (Shaw et al., 2018). This is impractical for long sequences such as musical compositions since their memory complexity for intermediate relative information is quadratic in the sequence length. We propose an algorithm that reduces their intermediate memory requirement to linear in the sequence length. This enables us to demonstrate that a Transformer with our modified relative attention mechanism can generate minutelong compositions (thousands of steps, four times the length modeled in Oore et al. (2018)) with compelling structure, generate continuations that coherently elaborate on a given motif, and in a seq2seq setup generate accompaniments conditioned on melodies1. We evaluate the Transformer with our relative attention mechanism on two datasets, JSB Chorales and Piano-e-Competition, and obtain state-of-the-art results on the latter.\n","date":"May 3, 2022","hero":"/blog-akitenkrad/posts/papers/202205/20220503010000/hero.jpg","permalink":"https://akitenkrad.github.io/blog-akitenkrad/posts/papers/202205/20220503010000/","summary":"Round-1: Overview Round-2: Model Implementation Details Round-3: Experiments Citation He, P., Liu, X., Gao, J., \u0026amp; Chen, W. (2020).\nDeBERTa: Decoding-enhanced BERT with Disentangled Attention.\nPaper Link Abstract Recent progress in pre-trained neural language models has significantly improved the performance of many natural language processing (NLP) tasks. In this paper we propose a new model architecture DeBERTa (Decoding-enhanced BERT with disentangled attention) that improves the BERT and RoBERTa models using two novel techniques.","tags":["At:Round-1","Published:2020","BERT","Attention","Disentangled Attention","Virtual Adversarial Training","DS:GLUE","DS:SuperGLUE","DS:SQuAD","DS:RACE","DS:ReCoRD","DS:SWAG","DS:MultiNLI","DS:CoNLL"],"title":"DeBERTa: Decoding-Enhanced BERT with Disentangled Attention"},{"categories":null,"contents":"This is a sample post intended to test the followings:\nA different post author. Table of contents. Markdown content rendering. Math rendering. Emoji rendering. Markdown Syntax Rendering Headings The following HTML \u0026lt;h1\u0026gt;—\u0026lt;h6\u0026gt; elements represent six levels of section headings. \u0026lt;h1\u0026gt; is the highest section level while \u0026lt;h6\u0026gt; is the lowest.\nH1 H2 H3 H4 H5 H6 Paragraph Xerum, quo qui aut unt expliquam qui dolut labo. Aque venitatiusda cum, voluptionse latur sitiae dolessi aut parist aut dollo enim qui voluptate ma dolestendit peritin re plis aut quas inctum laceat est volestemque commosa as cus endigna tectur, offic to cor sequas etum rerum idem sintibus eiur? Quianimin porecus evelectur, cum que nis nust voloribus ratem aut omnimi, sitatur? Quiatem. Nam, omnis sum am facea corem alique molestrunt et eos evelece arcillit ut aut eos eos nus, sin conecerem erum fuga. Ri oditatquam, ad quibus unda veliamenimin cusam et facea ipsamus es exerum sitate dolores editium rerore eost, temped molorro ratiae volorro te reribus dolorer sperchicium faceata tiustia prat.\nItatur? Quiatae cullecum rem ent aut odis in re eossequodi nonsequ idebis ne sapicia is sinveli squiatum, core et que aut hariosam ex eat.\nBlockquotes The blockquote element represents content that is quoted from another source, optionally with a citation which must be within a footer or cite element, and optionally with in-line changes such as annotations and abbreviations.\nBlockquote without attribution Tiam, ad mint andaepu dandae nostion secatur sequo quae. Note that you can use Markdown syntax within a blockquote.\nBlockquote with attribution Don\u0026rsquo;t communicate by sharing memory, share memory by communicating.\n— Rob Pike1\nTables Tables aren\u0026rsquo;t part of the core Markdown spec, but Hugo supports supports them out-of-the-box.\n| Name | Age | | ----- | --- | | Bob | 27 | | Alice | 23 | Name Age Bob 27 Alice 23 Inline Markdown within tables | Inline\u0026amp;nbsp;\u0026amp;nbsp;\u0026amp;nbsp; | Markdown\u0026amp;nbsp;\u0026amp;nbsp;\u0026amp;nbsp; | In\u0026amp;nbsp;\u0026amp;nbsp;\u0026amp;nbsp; | Table | | ------------------------ | -------------------------- | ----------------------------------- | ------ | | *italics* | **bold** | ~~strikethrough~~\u0026amp;nbsp;\u0026amp;nbsp;\u0026amp;nbsp; | `code` | Inline Markdown In Table italics bold strikethrough code Code Blocks Code block with backticks html \u0026lt;!DOCTYPE html\u0026gt; \u0026lt;html lang=\u0026#34;en\u0026#34;\u0026gt; \u0026lt;head\u0026gt; \u0026lt;meta charset=\u0026#34;UTF-8\u0026#34;\u0026gt; \u0026lt;title\u0026gt;Example HTML5 Document\u0026lt;/title\u0026gt; \u0026lt;/head\u0026gt; \u0026lt;body\u0026gt; \u0026lt;p\u0026gt;Test\u0026lt;/p\u0026gt; \u0026lt;/body\u0026gt; \u0026lt;/html\u0026gt; Code block indented with four spaces \u0026lt;!DOCTYPE html\u0026gt; \u0026lt;html lang=\u0026quot;en\u0026quot;\u0026gt; \u0026lt;head\u0026gt; \u0026lt;meta charset=\u0026quot;UTF-8\u0026quot;\u0026gt; \u0026lt;title\u0026gt;Example HTML5 Document\u0026lt;/title\u0026gt; \u0026lt;/head\u0026gt; \u0026lt;body\u0026gt; \u0026lt;p\u0026gt;Test\u0026lt;/p\u0026gt; \u0026lt;/body\u0026gt; \u0026lt;/html\u0026gt; Code block with Hugo\u0026rsquo;s internal highlight shortcode \u0026lt;!DOCTYPE html\u0026gt; \u0026lt;html lang=\u0026#34;en\u0026#34;\u0026gt; \u0026lt;head\u0026gt; \u0026lt;meta charset=\u0026#34;UTF-8\u0026#34;\u0026gt; \u0026lt;title\u0026gt;Example HTML5 Document\u0026lt;/title\u0026gt; \u0026lt;/head\u0026gt; \u0026lt;body\u0026gt; \u0026lt;p\u0026gt;Test\u0026lt;/p\u0026gt; \u0026lt;/body\u0026gt; \u0026lt;/html\u0026gt; List Types Ordered List First item Second item Third item Unordered List List item Another item And another item Nested list Fruit Apple Orange Banana Dairy Milk Cheese Other Elements — abbr, sub, sup, kbd, mark GIF is a bitmap image format.\nH2O\nXn + Yn = Zn\nPress CTRL+ALT+Delete to end the session.\nMost salamanders are nocturnal, and hunt for insects, worms, and other small creatures.\nMath Rendering Block math: $$ \\varphi = 1+\\frac{1} {1+\\frac{1} {1+\\frac{1} {1+\\cdots} } } $$\nEmoji Rendering 🙈 🙈 🙉 🙉 🙊 🙊\nExtended List {{ \u0026lt; fa-arrow-right-list \u0026gt; }} First --- Second --- Third {{ \u0026lt; /fa-arrow-right-list \u0026gt; }} First Second Third The above quote is excerpted from Rob Pike\u0026rsquo;s talk during Gopherfest, November 18, 2015.\u0026#160;\u0026#x21a9;\u0026#xfe0e;\n","date":"May 3, 2022","hero":"/blog-akitenkrad/posts/markdown/hero.jpg","permalink":"https://akitenkrad.github.io/blog-akitenkrad/posts/markdown/","summary":"This is a sample post intended to test the followings:\nA different post author. Table of contents. Markdown content rendering. Math rendering. Emoji rendering. Markdown Syntax Rendering Headings The following HTML \u0026lt;h1\u0026gt;—\u0026lt;h6\u0026gt; elements represent six levels of section headings. \u0026lt;h1\u0026gt; is the highest section level while \u0026lt;h6\u0026gt; is the lowest.\nH1 H2 H3 H4 H5 H6 Paragraph Xerum, quo qui aut unt expliquam qui dolut labo. Aque venitatiusda cum, voluptionse latur sitiae dolessi aut parist aut dollo enim qui voluptate ma dolestendit peritin re plis aut quas inctum laceat est volestemque commosa as cus endigna tectur, offic to cor sequas etum rerum idem sintibus eiur?","tags":["Markdown Syntax"],"title":"Markdown Syntax Guide"},{"categories":null,"contents":"This file exists solely to respond to /search URL with the related search layout template.\nNo content shown here is rendered, all content is based in the template layouts/page/search.html\nSetting a very low sitemap priority will tell search engines this is not important content.\nThis implementation uses Fusejs, jquery and mark.js\nInitial setup Search depends on additional output content type of JSON in config.toml ``` [outputs] home = [\u0026ldquo;HTML\u0026rdquo;, \u0026ldquo;JSON\u0026rdquo;] ```\nSearching additional fileds To search additional fields defined in front matter, you must add it in 2 places.\nEdit layouts/_default/index.JSON This exposes the values in /index.json i.e. add category ``` \u0026hellip; \u0026ldquo;contents\u0026rdquo;:{{ .Content | plainify | jsonify }} {{ if .Params.tags }}, \u0026ldquo;tags\u0026rdquo;:{{ .Params.tags | jsonify }}{{end}}, \u0026ldquo;categories\u0026rdquo; : {{ .Params.categories | jsonify }}, \u0026hellip; ```\nEdit fuse.js options to Search static/js/search.js ``` keys: [ \u0026ldquo;title\u0026rdquo;, \u0026ldquo;contents\u0026rdquo;, \u0026ldquo;tags\u0026rdquo;, \u0026ldquo;categories\u0026rdquo; ] ```\n","date":"January 1, 0001","hero":null,"permalink":"https://akitenkrad.github.io/blog-akitenkrad/search/","summary":"This file exists solely to respond to /search URL with the related search layout template.\nNo content shown here is rendered, all content is based in the template layouts/page/search.html\nSetting a very low sitemap priority will tell search engines this is not important content.\nThis implementation uses Fusejs, jquery and mark.js\nInitial setup Search depends on additional output content type of JSON in config.toml ``` [outputs] home = [\u0026ldquo;HTML\u0026rdquo;, \u0026ldquo;JSON\u0026rdquo;] ```","tags":null,"title":"Search Results"}]