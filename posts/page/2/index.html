<!doctype html><html><head><title>Post</title><meta charset=utf-8><meta name=viewport content="width=device-width,initial-scale=1"><meta http-equiv=x-ua-compatible content="ie=edge"><link rel=stylesheet href=https://akitenkrad.github.io/blog-akitenkrad/css/bootstrap.min.css><link rel=stylesheet href=https://akitenkrad.github.io/blog-akitenkrad/css/layouts/main.css><link rel=stylesheet href=https://akitenkrad.github.io/blog-akitenkrad/css/navigators/navbar.css><link rel=stylesheet href=https://akitenkrad.github.io/blog-akitenkrad/css/plyr.css><link rel=stylesheet href=https://akitenkrad.github.io/blog-akitenkrad/css/flag-icon.min.css><link rel=stylesheet href="https://fonts.googleapis.com/css2?family=Muli:wght@300;400;500;600"><link rel=stylesheet href=https://akitenkrad.github.io/blog-akitenkrad/fontawesome/css/all.min.css><link rel=icon type=image/png href=https://akitenkrad.github.io/blog-akitenkrad/images/favicons/favicon-96x96_huf1ee13f0caf27d1547f91fb46207d708_13005_42x0_resize_box_3.png><meta property="og:title" content="Post"><meta property="og:description" content><meta property="og:type" content="website"><meta property="og:url" content="https://akitenkrad.github.io/blog-akitenkrad/posts/"><link rel=stylesheet href=https://akitenkrad.github.io/blog-akitenkrad/css/layouts/list.css><link rel=stylesheet href=https://akitenkrad.github.io/blog-akitenkrad/css/navigators/sidebar.css><link rel=stylesheet href=https://akitenkrad.github.io/blog-akitenkrad/css/style.css><script async src="https://www.googletagmanager.com/gtag/js?id=G-1MYYZQG0WE"></script>
<script>var doNotTrack=!1;if(!doNotTrack){window.dataLayer=window.dataLayer||[];function gtag(){dataLayer.push(arguments)}gtag("js",new Date),gtag("config","G-1MYYZQG0WE",{anonymize_ip:!1})}</script></head><body data-spy=scroll data-target=#TableOfContents data-offset=80><div class="container-fluid bg-dimmed wrapper"><nav class="navbar navbar-expand-xl top-navbar final-navbar shadow"><div class=container><button class="navbar-toggler navbar-light" id=sidebar-toggler type=button onclick=toggleSidebar()>
<span class=navbar-toggler-icon></span></button>
<a class=navbar-brand href=/blog-akitenkrad><img src=/blog-akitenkrad/images/avatar_hu2673d53b0ac78c90b0a5a617874cdcc4_128349_42x0_resize_box_3.png alt=Logo>
Akitenkrad's Blog</a>
<button class="navbar-toggler navbar-light" id=toc-toggler type=button onclick=toggleTOC()>
<span class=navbar-toggler-icon></span></button><div class="collapse navbar-collapse lang-selector" id=top-nav-items><ul class="navbar-nav ml-auto"><li class=nav-item><a class=nav-link href=/blog-akitenkrad#home>Home</a></li><li class=nav-item><a class=nav-link href=/blog-akitenkrad#about>About</a></li><li class=nav-item><a class=nav-link href=/blog-akitenkrad#recent-posts>Recent Posts</a></li><li class=nav-item><a class=nav-link id=blog-link href=https://akitenkrad.github.io/blog-akitenkrad/posts>Posts</a></li><li class=nav-item><a class=nav-link id=tag-link href=https://akitenkrad.github.io/blog-akitenkrad/tags>Tags</a></li></ul></div></div><img src=/blog-akitenkrad/images/avatar_hu2673d53b0ac78c90b0a5a617874cdcc4_128349_42x0_resize_box_3.png class=d-none id=main-logo alt=Logo>
<img src=/blog-akitenkrad/images/avatar_hu2673d53b0ac78c90b0a5a617874cdcc4_128349_42x0_resize_box_3.png class=d-none id=inverted-logo alt="Inverted Logo"></nav><section class=sidebar-section id=sidebar-section><div class=sidebar-holder><div class=sidebar id=sidebar><form class=mx-auto method=get action=/blog-akitenkrad/search><input type=text name=keyword placeholder=Search data-search id=search-box></form><div class=sidebar-tree><ul class=tree id=tree><li id=list-heading><a href=/blog-akitenkrad/posts data-filter=all>Posts</a></li><div class=subtree><li><i class="fas fa-plus-circle"></i><a href=/blog-akitenkrad/posts/conference/>Conference</a><ul><li><a href=/blog-akitenkrad/posts/conference/acl/ title="Annual Meeting of the Association for Computational Linguistics">Annual Meeting of the Association for Computational Linguistics</a></li></ul></li><li><i class="fas fa-plus-circle"></i><a href=/blog-akitenkrad/posts/papers/>Papers</a><ul><li><i class="fas fa-plus-circle"></i><a href=/blog-akitenkrad/posts/papers/202205/>2022.05</a><ul><li><a href=/blog-akitenkrad/posts/papers/202205/20220503010000/ title=2022.05.03>2022.05.03</a></li><li><a href=/blog-akitenkrad/posts/papers/202205/20220505222900/ title=2022.05.05>2022.05.05</a></li><li><a href=/blog-akitenkrad/posts/papers/202205/20220506021208/ title=2022.05.06>2022.05.06</a></li><li><a href=/blog-akitenkrad/posts/papers/202205/20220508162318/ title=2022.05.08>2022.05.08</a></li><li><a href=/blog-akitenkrad/posts/papers/202205/20220509110738/ title=2022.05.09>2022.05.09</a></li><li><a href=/blog-akitenkrad/posts/papers/202205/20220511010217/ title=2022.05.11>2022.05.11</a></li><li><a href=/blog-akitenkrad/posts/papers/202205/20220514151839/ title=2022.05.14>2022.05.14</a></li><li><a href=/blog-akitenkrad/posts/papers/202205/20220518224923/ title=2022.05.18>2022.05.18</a></li><li><a href=/blog-akitenkrad/posts/papers/202205/20220520124748/ title=2022.05.20>2022.05.20</a></li><li><a href=/blog-akitenkrad/posts/papers/202205/20220523223206/ title=2022.05.23>2022.05.23</a></li><li><a href=/blog-akitenkrad/posts/papers/202205/20220525115521/ title=2022.05.25>2022.05.25</a></li><li><a href=/blog-akitenkrad/posts/papers/202205/20220529131339/ title=2022.05.29>2022.05.29</a></li><li><a href=/blog-akitenkrad/posts/papers/202205/20220530102936/ title=2022.05.30>2022.05.30</a></li></ul></li><li><i class="fas fa-plus-circle"></i><a href=/blog-akitenkrad/posts/papers/202206/>2022.06</a><ul><li><a href=/blog-akitenkrad/posts/papers/202206/20220602171700/ title=2022.06.02>2022.06.02</a></li><li><a href=/blog-akitenkrad/posts/papers/202206/20220608085622/ title=2022.06.08>2022.06.08</a></li><li><a href=/blog-akitenkrad/posts/papers/202206/20220612105422/ title=2022.06.12>2022.06.12</a></li><li><a href=/blog-akitenkrad/posts/papers/202206/20220618223844/ title=2022.06.18>2022.06.18</a></li></ul></li><li><i class="fas fa-plus-circle"></i><a href=/blog-akitenkrad/posts/papers/202207/>2022.07</a><ul><li><a href=/blog-akitenkrad/posts/papers/202207/20220726163444/ title=2022.07.25>2022.07.25</a></li><li><a href=/blog-akitenkrad/posts/papers/202207/20220727145036/ title=2022.07.27>2022.07.27</a></li></ul></li><li><i class="fas fa-plus-circle"></i><a href=/blog-akitenkrad/posts/papers/202208/>2022.08</a><ul><li><a href=/blog-akitenkrad/posts/papers/202208/20220802103319/ title=2022.08.02>2022.08.02</a></li></ul></li></ul></li><li><i class="fas fa-plus-circle"></i><a href=/blog-akitenkrad/posts/graphs/>Graphs</a><ul><li><i class="fas fa-plus-circle"></i><a href=/blog-akitenkrad/posts/graphs/202208/>2022.08</a><ul><li><a href=/blog-akitenkrad/posts/graphs/202208/20220822092748/ title=1ヶ月当たりの実労働時間の推移>1ヶ月当たりの実労働時間の推移</a></li><li><a href=/blog-akitenkrad/posts/graphs/202208/20220813115200/ title=コンビニエンスストアの店舗数の推移>コンビニエンスストアの店舗数の推移</a></li><li><a href=/blog-akitenkrad/posts/graphs/202208/20220821113322/ title=地域別1世帯当たり1ヶ月間の支出額の推移>地域別1世帯当たり1ヶ月間の支出額の推移</a></li><li><a href=/blog-akitenkrad/posts/graphs/202208/20220815131016/ title="年齢別大学院入学者数 (2021)">年齢別大学院入学者数 (2021)</a></li><li><a href=/blog-akitenkrad/posts/graphs/202208/20220818122628/ title=情報サービス業における企業特殊的人的資本（名目）の推移>情報サービス業における企業特殊的人的資本（名目）の推移</a></li><li><a href=/blog-akitenkrad/posts/graphs/202208/20220814175022/ title=東京23区の乗用車保有台数>東京23区の乗用車保有台数</a></li><li><a href=/blog-akitenkrad/posts/graphs/202208/20220817121117/ title="業種別企業特殊的人的資本 (2018)">業種別企業特殊的人的資本 (2018)</a></li><li><a href=/blog-akitenkrad/posts/graphs/202208/20220823104100/ title=睡眠時間の推移>睡眠時間の推移</a></li><li><a href=/blog-akitenkrad/posts/graphs/202208/20220820225528/ title=都道府県別国公立別学校数・学生数>都道府県別国公立別学校数・学生数</a></li><li><a href=/blog-akitenkrad/posts/graphs/202208/20220816120845/ title="都道府県別消費者物価指数/教育（全国平均=100）">都道府県別消費者物価指数/教育（全国平均=100）</a></li><li><a href=/blog-akitenkrad/posts/graphs/202208/20220812173814/ title=金沢市の夏の月平均気温の遷移>金沢市の夏の月平均気温の遷移</a></li></ul></li></ul></li><li><a href=/blog-akitenkrad/posts/latex/ title="Latex Mathematics Syntax Guide">Latex Mathematics Syntax Guide</a></li><li><a href=/blog-akitenkrad/posts/markdown/ title="Markdown Sample">Markdown Sample</a></li></div></ul></div></div></div></section><section class=content-section id=content-section><div class="content container-fluid" id=content><div class="container-fluid post-card-holder" id=post-card-holder><div class=post-card><a href=https://akitenkrad.github.io/blog-akitenkrad/posts/papers/202207/20220727145036/ class=post-card-link><div class=card><div class=card-head><img class=card-img-top src=/blog-akitenkrad/posts/papers/202207/20220727145036/hero.png alt="Hero Image"></div><div class=card-body><h5 class=card-title>Dynamic Heterogeneous Graph Embedding Using Hierarchical Attentions</h5><p class="card-text post-summary">Round-1: Overview Round-2: Model Implementation Details Round-3: Experiments Citation Yang, L., Xiao, Z., Jiang, W., Wei, Y., Hu, Y., & Wang, H. (2020).
Dynamic heterogeneous graph embedding using hierarchical attentions.
Lecture Notes in Computer Science (Including Subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics), 12036 LNCS.
https://doi.org/10.1007/978-3-030-45442-5_53 Abstract Graph embedding has attracted many research interests. Existing works mainly focus on static homogeneous/heterogeneous networks or dynamic homogeneous networks.</p></div><div class=card-footer><span class=float-left>July 27, 2022</span>
<a href=https://akitenkrad.github.io/blog-akitenkrad/posts/papers/202207/20220727145036/ class="float-right btn btn-outline-info btn-sm">Read</a></div></div></a></div><div class=post-card><a href=https://akitenkrad.github.io/blog-akitenkrad/posts/papers/202207/20220726163444/ class=post-card-link><div class=card><div class=card-head><img class=card-img-top src=/blog-akitenkrad/posts/papers/202207/20220726163444/hero.png alt="Hero Image"></div><div class=card-body><h5 class=card-title>Dynamic Network Embedding Survey</h5><p class="card-text post-summary">Round-1: Overview Round-2: Model Implementation Details Round-3: Experiments Citation Xue, G., Zhong, M., Li, J., Chen, J., Zhai, C., & Kong, R. (2022)
Dynamic network embedding survey
Neurocomputing, 472, 212–223. https://doi.org/10.1016/J.NEUCOM.2021.03.138 Abstract Since many real world networks are evolving over time, such as social networks and user-item networks, there are increasing research efforts on dynamic network embedding in recent years. They learn node representations from a sequence of evolving graphs but not only the latest network, for preserving both structural and temporal information from the dynamic networks.</p></div><div class=card-footer><span class=float-left>July 26, 2022</span>
<a href=https://akitenkrad.github.io/blog-akitenkrad/posts/papers/202207/20220726163444/ class="float-right btn btn-outline-info btn-sm">Read</a></div></div></a></div><div class=post-card><a href=https://akitenkrad.github.io/blog-akitenkrad/posts/papers/202206/20220618223844/ class=post-card-link><div class=card><div class=card-head><img class=card-img-top src=/blog-akitenkrad/posts/papers/202206/20220618223844/hero.jpg alt="Hero Image"></div><div class=card-body><h5 class=card-title>High-order Proximity Preserved Embedding for Dynamic Networks</h5><p class="card-text post-summary">Round-1: Overview Round-2: Model Implementation Details Round-3: Experiments Citation Zhu, D., Cui, P., Zhang, Z., Pei, J., & Zhu, W. (2018).
High-Order Proximity Preserved Embedding for Dynamic Networks.
IEEE Transactions on Knowledge and Data Engineering, 30(11), 2134–2144.
https://doi.org/10.1109/TKDE.2018.2822283 Abstract Network embedding, aiming to embed a network into a low dimensional vector space while preserving the inherent structural properties of the network, has attracted considerable attention. However, most existing embedding methods focus on the static network while neglecting the evolving characteristic of real-world networks.</p></div><div class=card-footer><span class=float-left>June 18, 2022</span>
<a href=https://akitenkrad.github.io/blog-akitenkrad/posts/papers/202206/20220618223844/ class="float-right btn btn-outline-info btn-sm">Read</a></div></div></a></div><div class=post-card><a href=https://akitenkrad.github.io/blog-akitenkrad/posts/papers/202206/20220612105422/ class=post-card-link><div class=card><div class=card-head><img class=card-img-top src=/blog-akitenkrad/posts/papers/202206/20220612105422/hero.png alt="Hero Image"></div><div class=card-body><h5 class=card-title>Attributed Network Embedding for Learning in a Dynamic Environment</h5><p class="card-text post-summary">Round-1: Overview Round-2: Model Implementation Details Round-3: Experiments Citation Jundong Li, Harsh Dani, Xia Hu, Jiliang Tang, Yi Chang, and Huan Liu. 2017.
Attributed Network Embedding for Learning in a Dynamic Environment.
In Proceedings of the 2017 ACM on Conference on Information and Knowledge Management (CIKM &lsquo;17). Association for Computing Machinery, New York, NY, USA, 387–396.
https://doi.org/10.1145/3132847.3132919 Abstract Network embedding leverages the node proximity manifested to learn a low-dimensional node vector representation for each node in the network.</p></div><div class=card-footer><span class=float-left>June 12, 2022</span>
<a href=https://akitenkrad.github.io/blog-akitenkrad/posts/papers/202206/20220612105422/ class="float-right btn btn-outline-info btn-sm">Read</a></div></div></a></div><div class=post-card><a href=https://akitenkrad.github.io/blog-akitenkrad/posts/papers/202206/20220608085622/ class=post-card-link><div class=card><div class=card-head><img class=card-img-top src=/blog-akitenkrad/posts/papers/202206/20220608085622/hero.png alt="Hero Image"></div><div class=card-body><h5 class=card-title>CodeBERT: A Pre-Trained Model for Programming and Natural Languages</h5><p class="card-text post-summary">Round-1: Overview Round-2: Model Implementation Details Round-3: Experiments Citation Feng, Z., Guo, D., Tang, D., Duan, N., Feng, X., Gong, M., Shou, L., Qin, B., Liu, T., Jiang, D., & Zhou, M. (2020).
CodeBERT: A Pre-Trained Model for Programming and Natural Languages.
Findings of the Association for Computational Linguistics Findings of ACL: EMNLP 2020, 1536–1547.
https://doi.org/10.18653/V1/2020.FINDINGS-EMNLP.139 Abstract We present CodeBERT, a bimodal pre-trained model for programming language (PL) and natural language (NL).</p></div><div class=card-footer><span class=float-left>June 8, 2022</span>
<a href=https://akitenkrad.github.io/blog-akitenkrad/posts/papers/202206/20220608085622/ class="float-right btn btn-outline-info btn-sm">Read</a></div></div></a></div><div class=post-card><a href=https://akitenkrad.github.io/blog-akitenkrad/posts/latex/ class=post-card-link><div class=card><div class=card-head><img class=card-img-top src=/blog-akitenkrad/posts/latex/hero.jpg alt="Hero Image"></div><div class=card-body><h5 class=card-title>Latex Mathematics Syntax Guide</h5><p class="card-text post-summary">等号 コマンド 出力 コマンド 出力 コマンド 出力 コマンド 出力 = $=$ \neq $\neq$ \sim $\sim$ \simeq $\simeq$ \approx $\approx$ \fallingdotseq $\fallingdotseq$ \risingdotseq $\risingdotseq$ \equiv $\equiv$ 不等号 コマンド 出力 コマンド 出力 コマンド 出力 コマンド 出力 > $>$ &lt; $&lt;$ \geq $\geq$ \geqq $\geqq$ \leq $\leq$ \leqq $\leqq$ \gg $\gg$ \ll $\ll$ 演算子 コマンド 出力 コマンド 出力 コマンド 出力 コマンド 出力 + $+$ - $-$ \times $\times$ \div $\div$ \pm $\pm$ \mp $\mp$ \oplus $\oplus$ \ominus $\ominus$ \oslash $\oslash$ \circ $\circ$ \cdot $\cdot$ \bullet $\bullet$ \ltimes $\ltimes$ \rtimes $\rtimes$ 集合 コマンド 出力 コマンド 出力 コマンド 出力 コマンド 出力 \in $\in$ \ni $\ni$ \notin $\notin$ \subset $\subset$ \supset $\supset$ \subseteq $\subseteq$ \supseteq $\supseteq$ \nsubseteq $\nsubseteq$ \cap $\cap$ \cup $\cup$ \emptyset $\emptyset$ \infty $\infty$ 括弧 コマンド 出力 コマンド 出力 コマンド 出力 コマンド 出力 () $()$ {}, \lbrace \rbrace $\lbrace \rbrace$ [], \lbrack \rbrack $\lbrack \rbrack$ \lanble \ranble $\langle \rangle$ ||, \lvert \rvert $\lvert \rvert$ \|\|, \lVert \rVert $\lVert \rVert$ \lfloor \rfloor $\lfloor \rfloor$ \lceil \rceil $\lceil \rceil $ \ulcorner \urcorner $\ulcorner \urcorner$ \llcorner \lrcorner $\llcorner \lrcorner$ 修飾 コマンド 出力 コマンド 出力 コマンド 出力 コマンド 出力 A^T $A^T$ A^\mathrm{T} $A^\mathrm{T}$ A^\mathsf{T} $A^\mathsf{T}$ A^\intercal $A^\intercal$ A^\top $A^\top$ x^{\prime} $x^{\prime}$ x^{\backprime} $x^{\backprime}$ \hat{x} $\hat{x}$ \check{x} $\check{x}$ \grave{x} $\grave{x}$ \acute{x} $\acute{x}$ \breve{x} $\breve{x}$ \bar{x} $\bar{x}$ \tilde{x} $\tilde{x}$ \dot{x} $\dot{x}$ \ddot{x} $\ddot{x}$ \dddot{x} $\dddot{x}$ \vec{x} $\vec{x}$ \overrightarrow{x} $\overrightarrow{x}$ \widehat{x} $\widehat{x}$ \boldsymbol{x} $\boldsymbol{x}$ \overline{数式} $\overline{数式}$ \underline{数式} $\underline{数式}$ \overbrace{数式} $\overbrace{数式}$ \overbrace{数式}^{説明} $\overbrace{数式}^{説明}$ \underbrace{数式} $\underbrace{数式}$ \underbrace{数式}_{説明} $\underbrace{数式}_{説明}$ 矢印 コマンド 出力 コマンド 出力 コマンド 出力 コマンド 出力 \leftarrow, \gets $\gets$ \rightarrow, \to $\to$ \longleftarrow $\longleftarrow$ \longrightarrow $\longrightarrow$ \Leftarrow $\Leftarrow$ \Rightarrow $\Rightarrow$ \Longleftarrow $\Longleftarrow$ \Longrightarrow $\Longrightarrow$ \leftrightarrow $\leftrightarrow$ \longleftrightarrow $\longleftrightarrow$ \Leftrightarrow $\Leftrightarrow$ \Longleftrightarrow, \iff $ \Longleftrightarrow$ \nearrow $\nearrow$ \swarrow $\swarrow$ \searrow $\searrow$ \nwarrow $\nwarrow$ \uparrow $\uparrow$ \downarrow $\downarrow$ \Uparrow $\Uparrow$ \Downarrow $\Downarrow$ \updownarrow $\updownarrow$ \Updownarrow $\Updownarrow$ \mapsto $\mapsto$ \longmapsto $\longmapsto$ \hookleftarrow $\hookleftarrow$ \hookrightarrow $\hookrightarrow$ \twoheadleftarrow $\twoheadleftarrow$ \twoheadrightarrow $\twoheadrightarrow$ \circlearrowleft $\circlearrowleft$ \circlearrowright $\circlearrowright$ \curvearrowleft $\curvearrowleft$ \curvearrowright $\curvearrowright$ \leftharpoonup $\leftharpoonup$ \rightharpoonup $\rightharpoonup$ \leftharpoondown $\leftharpoondown$ \rightharpoondown $\rightharpoondown$ \leftrightharpoons $\leftrightharpoons$ \rightleftharpoons $\rightleftharpoons$ \upharpoonleft $\upharpoonleft$ \upharpoonright $\upharpoonright$ \downharpoonleft $\downharpoonleft$ \downharpoonright $\downharpoonright$ \leftarrowtail $\leftarrowtail$ \rightarrowtail $\rightarrowtail$ \Lsh $\Lsh$ \Rsh $\Rsh$ \leftrightsquigarrow $\leftrightsquigarrow$ \rightsquigarrow $\rightsquigarrow$ \looparrowleft $\looparrowleft$ \looparrowright $\looparrowright$ \Lleftarrow $\Lleftarrow$ \Rrightarrow $\Rrightarrow$ \nleftarrow $\nleftarrow$ \nrightarrow $\nrightarrow$ \nLeftarrow $\nLeftarrow$ \nRightarrow $\nRightarrow$ \nleftrightarrow $\nleftrightarrow$ \nLeftrightarrow $\nLeftrightarrow$ \xleftarrow{a} $\xleftarrow{a}$ \xrightarrow{a} $\xrightarrow{a}$ \xleftarrow[b]{} $\xleftarrow[b]{}$ \xrightarrow[b]{} $\xrightarrow[b]{}$ \xleftarrow[b]{a} $\xleftarrow[b]{a}$ \xrightarrow[b]{a} $\xrightarrow[b]{a}$ \overset{\mathrm{def}}{\iff} $\overset{\mathrm{def}}{\iff}$</p></div><div class=card-footer><span class=float-left>June 3, 2022</span>
<a href=https://akitenkrad.github.io/blog-akitenkrad/posts/latex/ class="float-right btn btn-outline-info btn-sm">Read</a></div></div></a></div><div class=post-card><a href=https://akitenkrad.github.io/blog-akitenkrad/posts/papers/202206/20220602171700/ class=post-card-link><div class=card><div class=card-head><img class=card-img-top src=/blog-akitenkrad/posts/papers/202206/20220602171700/hero.jpg alt="Hero Image"></div><div class=card-body><h5 class=card-title>S-Net: From Answer Extraction to Answer Generation for Machine Reading Comprehension</h5><p class="card-text post-summary">Round-1: Overview Round-2: Model Implementation Details Round-3: Experiments Citation Chuanqi Tan, Furu Wei, Nan Yang, Bowen Du,Weifeng Lv, and Ming Zhou. 2018.
S-Net: Fromanswer extraction to answer synthesis for machinereading comprehension.
InAssociation for the Ad-vancement of Artificial Intelligence (AAAI), pages5940–5947. Abstract In this paper, we present a novel approach to machine reading comprehension forthe MS-MARCO dataset. Unlike the SQuAD dataset that aims to answer a ques-tion with exact text spans in a passage, the MS-MARCO dataset defines the taskas answering a question from multiple passages and the words in the answer arenot necessary in the passages.</p></div><div class=card-footer><span class=float-left>June 2, 2022</span>
<a href=https://akitenkrad.github.io/blog-akitenkrad/posts/papers/202206/20220602171700/ class="float-right btn btn-outline-info btn-sm">Read</a></div></div></a></div><div class=post-card><a href=https://akitenkrad.github.io/blog-akitenkrad/posts/papers/202205/20220530102936/ class=post-card-link><div class=card><div class=card-head><img class=card-img-top src=/blog-akitenkrad/posts/papers/202205/20220530102936/hero.jpg alt="Hero Image"></div><div class=card-body><h5 class=card-title>Neural Machine Translation of Rare Words with Subword Units</h5><p class="card-text post-summary">Round-1: Overview Round-2: Model Implementation Details Round-3: Experiments Citation Sennrich, R., Haddow, B., & Birch, A. (2015).
Neural Machine Translation of Rare Words with Subword Units.
https://doi.org/10.48550/arxiv.1508.07909 Abstract Neural machine translation (NMT) models typically operate with a fixed vocabulary, but translation is an open-vocabulary problem. Previous work addresses the translation of out-of-vocabulary words by backing off to a dictionary. In this paper, we introduce a simpler and more effective approach, making the NMT model capable of open-vocabulary translation by encoding rare and unknown words as sequences of subword units.</p></div><div class=card-footer><span class=float-left>May 30, 2022</span>
<a href=https://akitenkrad.github.io/blog-akitenkrad/posts/papers/202205/20220530102936/ class="float-right btn btn-outline-info btn-sm">Read</a></div></div></a></div><div class=post-card><a href=https://akitenkrad.github.io/blog-akitenkrad/posts/papers/202205/20220529131339/ class=post-card-link><div class=card><div class=card-head><img class=card-img-top src=/blog-akitenkrad/posts/papers/202205/20220529131339/hero.jpg alt="Hero Image"></div><div class=card-body><h5 class=card-title>Attention Is All You Need</h5><p class="card-text post-summary">Round-1: Overview Round-2: Model Implementation Details Round-3: Experiments Citation Vaswani, A., Shazeer, N., Parmar, N., Uszkoreit, J., Jones, L., Gomez, A. N., Kaiser, Ł., & Polosukhin, I. (2017).
Attention is all you need.
Advances in Neural Information Processing Systems, 2017-Decem, 5999–6009.
http://arxiv.org/abs/1706.03762 Abstract The dominant sequence transduction models are based on complex recurrent or convolutional neural networks in an encoder-decoder configuration. The best performing models also connect the encoder and decoder through an attention mechanism.</p></div><div class=card-footer><span class=float-left>May 29, 2022</span>
<a href=https://akitenkrad.github.io/blog-akitenkrad/posts/papers/202205/20220529131339/ class="float-right btn btn-outline-info btn-sm">Read</a></div></div></a></div><div class=post-card><a href=https://akitenkrad.github.io/blog-akitenkrad/posts/papers/202205/20220525115521/ class=post-card-link><div class=card><div class=card-head><img class=card-img-top src=/blog-akitenkrad/posts/papers/202205/20220525115521/hero.png alt="Hero Image"></div><div class=card-body><h5 class=card-title>Improving Language Understanding by Generative Pre-Training</h5><p class="card-text post-summary">Round-1: Overview Round-2: Model Implementation Details Round-3: Experiments Citation Abstract Background & Wat&rsquo;s New Dataset Model Description Training Settings Results References Semi-Supervised Text Classification Using EM (O. Chapelle et al., 2006) O. Chapelle, Bernhard SchÃ¶lkopf, A. Zien. (2006)
Semi-Supervised Text Classification Using EM
Paper Link
Influential Citation Count (2), SS-ID (03bafef700d35112a9926dd1b2be91a4aa6984a4)
ABSTRACT
This chapter contains sections titled: Introduction, A Generative Model for Text, Experimental Results with Basic EM, Using a More Expressive Generative Model, Overcoming the Challenges of Local Maxima, Conclusions and Summary</p></div><div class=card-footer><span class=float-left>May 25, 2022</span>
<a href=https://akitenkrad.github.io/blog-akitenkrad/posts/papers/202205/20220525115521/ class="float-right btn btn-outline-info btn-sm">Read</a></div></div></a></div><div class=post-card><a href=https://akitenkrad.github.io/blog-akitenkrad/posts/papers/202205/20220523223206/ class=post-card-link><div class=card><div class=card-head><img class=card-img-top src=/blog-akitenkrad/posts/papers/202205/20220523223206/hero.jpg alt="Hero Image"></div><div class=card-body><h5 class=card-title>RoBERTa: A Robustly Optimized BERT Pretraining Approach</h5><p class="card-text post-summary">Round-1: Overview Round-2: Model Implementation Details Round-3: Experiments Citation Liu, Y., Ott, M., Goyal, N., Du, J., Joshi, M., Chen, D., Levy, O., Lewis, M., Zettlemoyer, L., & Stoyanov, V. (2019).
RoBERTa: A Robustly Optimized BERT Pretraining Approach.
https://doi.org/10.48550/arxiv.1907.11692 Abstract Language model pretraining has led to significant performance gains but careful comparison between different approaches is challenging. Training is computationally expensive, often done on private datasets of different sizes, and, as we will show, hyperparameter choices have significant impact on the final results.</p></div><div class=card-footer><span class=float-left>May 23, 2022</span>
<a href=https://akitenkrad.github.io/blog-akitenkrad/posts/papers/202205/20220523223206/ class="float-right btn btn-outline-info btn-sm">Read</a></div></div></a></div><div class=post-card><a href=https://akitenkrad.github.io/blog-akitenkrad/posts/papers/202205/20220520124748/ class=post-card-link><div class=card><div class=card-head><img class=card-img-top src=/blog-akitenkrad/posts/papers/202205/20220520124748/hero.jpg alt="Hero Image"></div><div class=card-body><h5 class=card-title>Semi-Supervised Classification with Graph Convolutional Networks</h5><p class="card-text post-summary">Round-1: Overview Round-2: Model Implementation Details Round-3: Experiments Citation Kipf, T. N., & Welling, M. (2016).
Semi-Supervised Classification with Graph Convolutional Networks.
Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition. (2019)
https://doi.org/10.48550/arxiv.1609.02907 Abstract We present a scalable approach for semi-supervised learning on graph-structured data that is based on an efficient variant of convolutional neural networks which operate directly on graphs. We motivate the choice of our convolutional architecture via a localized first-order approximation of spectral graph convolutions.</p></div><div class=card-footer><span class=float-left>May 20, 2022</span>
<a href=https://akitenkrad.github.io/blog-akitenkrad/posts/papers/202205/20220520124748/ class="float-right btn btn-outline-info btn-sm">Read</a></div></div></a></div></div><div class=paginator><ul class="pagination pagination-default"><li class=page-item><a href=/blog-akitenkrad/posts/ aria-label=First class=page-link role=button><span aria-hidden=true>&#171;&#171;</span></a></li><li class=page-item><a href=/blog-akitenkrad/posts/ aria-label=Previous class=page-link role=button><span aria-hidden=true>&#171;</span></a></li><li class=page-item><a href=/blog-akitenkrad/posts/ aria-label="Page 1" class=page-link role=button>1</a></li><li class="page-item active"><a aria-current=page aria-label="Page 2" class=page-link role=button>2</a></li><li class=page-item><a href=/blog-akitenkrad/posts/page/3/ aria-label="Page 3" class=page-link role=button>3</a></li><li class=page-item><a href=/blog-akitenkrad/posts/page/3/ aria-label=Next class=page-link role=button><span aria-hidden=true>&#187;</span></a></li><li class=page-item><a href=/blog-akitenkrad/posts/page/3/ aria-label=Last class=page-link role=button><span aria-hidden=true>&#187;&#187;</span></a></li></ul></div></div></section></div><footer id=footer class="container-fluid text-center align-content-center footer pb-2"><div class="container pt-5"><div class="row text-left"><div class="col-md-4 col-sm-12"><h5>Navigation</h5><ul><li class=nav-item><a class=smooth-scroll href=https://akitenkrad.github.io/blog-akitenkrad/#about>About</a></li><li class=nav-item><a class=smooth-scroll href=https://akitenkrad.github.io/blog-akitenkrad/#recent-posts>Recent Posts</a></li></ul></div><div class="col-md-4 col-sm-12"><h5>Contact me:</h5><ul><li><a href=mailto:contact.to.akitenkrad@gmail.com target=_blank rel=noopener><span><i class="fas fa-envelope"></i></span> <span>contact.to.akitenkrad@gmail.com</span></a></li></ul></div></div></div><hr><div class=container><div class="row text-left"><div class=col-md-4><a id=theme href=https://github.com/hossainemruz/toha target=_blank rel=noopener><img src=/blog-akitenkrad/images/theme-logo_hu8376fd15465fef26ffe66b6bcf0ca686_13669_32x0_resize_box_3.png alt="Toha Theme Logo">
Toha</a></div><div class="col-md-4 text-center">© 2020 Akitenkrad.</div><div class="col-md-4 text-right"><a id=hugo href=https://gohugo.io/ target=_blank rel=noopener>Powered by
<img src=/blog-akitenkrad/images/hugo-logo.svg alt="Hugo Logo" height=18></a></div></div></div><script src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.4/MathJax.js?config=TeX-AMS-MML_HTMLorMML"></script>
<script type=text/x-mathjax-config>
      MathJax.Hub.Config({
        tex2jax: {
          inlineMath: [['$','$']]
        }
      });
      </script></footer><script type=text/javascript src=https://akitenkrad.github.io/blog-akitenkrad/js/jquery-3.4.1.min.js></script>
<script type=text/javascript src=https://akitenkrad.github.io/blog-akitenkrad/js/popper.min.js></script>
<script type=text/javascript src=https://akitenkrad.github.io/blog-akitenkrad/js/bootstrap.min.js></script>
<script type=text/javascript src=https://akitenkrad.github.io/blog-akitenkrad/js/navbar.js></script>
<script type=text/javascript src=https://akitenkrad.github.io/blog-akitenkrad/js/plyr.js></script>
<script type=text/javascript src=https://akitenkrad.github.io/blog-akitenkrad/js/main.js></script>
<script src=https://akitenkrad.github.io/blog-akitenkrad/js/list.js></script></body></html>