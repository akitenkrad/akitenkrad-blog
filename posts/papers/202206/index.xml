<?xml version="1.0" encoding="utf-8" standalone="yes"?><rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom"><channel><title>2022.06 on Akitenkrad's Blog</title><link>https://akitenkrad.github.io/blog-akitenkrad/posts/papers/202206/</link><description>Recent content in 2022.06 on Akitenkrad's Blog</description><generator>Hugo -- gohugo.io</generator><language>ja-jp</language><lastBuildDate>Wed, 08 Jun 2022 00:00:00 +0000</lastBuildDate><atom:link href="https://akitenkrad.github.io/blog-akitenkrad/posts/papers/202206/index.xml" rel="self" type="application/rss+xml"/><item><title>CodeBERT: A Pre-Trained Model for Programming and Natural Languages</title><link>https://akitenkrad.github.io/blog-akitenkrad/posts/papers/202206/20220608085622/</link><pubDate>Wed, 08 Jun 2022 00:00:00 +0000</pubDate><guid>https://akitenkrad.github.io/blog-akitenkrad/posts/papers/202206/20220608085622/</guid><description>Round-1: Overview Round-2: Model Implementation Details Round-3: Experiments Citation Feng, Z., Guo, D., Tang, D., Duan, N., Feng, X., Gong, M., Shou, L., Qin, B., Liu, T., Jiang, D., &amp;amp; Zhou, M. (2020).
CodeBERT: A Pre-Trained Model for Programming and Natural Languages.
Findings of the Association for Computational Linguistics Findings of ACL: EMNLP 2020, 1536–1547.
https://doi.org/10.18653/V1/2020.FINDINGS-EMNLP.139 Abstract We present CodeBERT, a bimodal pre-trained model for programming language (PL) and natural language (NL).</description></item><item><title>S-Net: From Answer Extraction to Answer Generation for Machine Reading Comprehension</title><link>https://akitenkrad.github.io/blog-akitenkrad/posts/papers/202206/20220602171700/</link><pubDate>Thu, 02 Jun 2022 00:00:00 +0000</pubDate><guid>https://akitenkrad.github.io/blog-akitenkrad/posts/papers/202206/20220602171700/</guid><description>Round-1: Overview Round-2: Model Implementation Details Round-3: Experiments Citation Chuanqi Tan, Furu Wei, Nan Yang, Bowen Du,Weifeng Lv, and Ming Zhou. 2018.
S-Net: Fromanswer extraction to answer synthesis for machinereading comprehension.
InAssociation for the Ad-vancement of Artificial Intelligence (AAAI), pages5940–5947. Abstract In this paper, we present a novel approach to machine reading comprehension forthe MS-MARCO dataset. Unlike the SQuAD dataset that aims to answer a ques-tion with exact text spans in a passage, the MS-MARCO dataset defines the taskas answering a question from multiple passages and the words in the answer arenot necessary in the passages.</description></item></channel></rss>