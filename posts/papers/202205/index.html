<!doctype html><html><head><title>2022.05</title><meta charset=utf-8><meta name=viewport content="width=device-width,initial-scale=1"><meta http-equiv=x-ua-compatible content="ie=edge"><link rel=stylesheet href=https://akitenkrad.github.io/blog-akitenkrad/css/bootstrap.min.css><link rel=stylesheet href=https://akitenkrad.github.io/blog-akitenkrad/css/layouts/main.css><link rel=stylesheet href=https://akitenkrad.github.io/blog-akitenkrad/css/navigators/navbar.css><link rel=stylesheet href=https://akitenkrad.github.io/blog-akitenkrad/css/plyr.css><link rel=stylesheet href=https://akitenkrad.github.io/blog-akitenkrad/css/flag-icon.min.css><link rel=stylesheet href="https://fonts.googleapis.com/css2?family=Muli:wght@300;400;500;600"><link rel=stylesheet href=https://akitenkrad.github.io/blog-akitenkrad/fontawesome/css/all.min.css><link rel=icon type=image/png href=https://akitenkrad.github.io/blog-akitenkrad/images/favicons/favicon-96x96_huf1ee13f0caf27d1547f91fb46207d708_13005_42x0_resize_box_3.png><meta property="og:title" content="2022.05"><meta property="og:description" content><meta property="og:type" content="website"><meta property="og:url" content="https://akitenkrad.github.io/blog-akitenkrad/posts/papers/202205/"><link rel=stylesheet href=https://akitenkrad.github.io/blog-akitenkrad/css/layouts/list.css><link rel=stylesheet href=https://akitenkrad.github.io/blog-akitenkrad/css/navigators/sidebar.css><link rel=stylesheet href=https://akitenkrad.github.io/blog-akitenkrad/css/style.css><script async src="https://www.googletagmanager.com/gtag/js?id=G-1MYYZQG0WE"></script>
<script>var doNotTrack=!1;if(!doNotTrack){window.dataLayer=window.dataLayer||[];function gtag(){dataLayer.push(arguments)}gtag("js",new Date),gtag("config","G-1MYYZQG0WE",{anonymize_ip:!1})}</script></head><body data-spy=scroll data-target=#TableOfContents data-offset=80><div class="container-fluid bg-dimmed wrapper"><nav class="navbar navbar-expand-xl top-navbar final-navbar shadow"><div class=container><button class="navbar-toggler navbar-light" id=sidebar-toggler type=button onclick=toggleSidebar()>
<span class=navbar-toggler-icon></span></button>
<a class=navbar-brand href=/blog-akitenkrad><img src=/blog-akitenkrad/images/avatar_hu2673d53b0ac78c90b0a5a617874cdcc4_128349_42x0_resize_box_3.png alt=Logo>
Akitenkrad's Blog</a>
<button class="navbar-toggler navbar-light" id=toc-toggler type=button onclick=toggleTOC()>
<span class=navbar-toggler-icon></span></button><div class="collapse navbar-collapse lang-selector" id=top-nav-items><ul class="navbar-nav ml-auto"></ul></div></div><img src=/blog-akitenkrad/images/avatar_hu2673d53b0ac78c90b0a5a617874cdcc4_128349_42x0_resize_box_3.png class=d-none id=main-logo alt=Logo>
<img src=/blog-akitenkrad/images/avatar_hu2673d53b0ac78c90b0a5a617874cdcc4_128349_42x0_resize_box_3.png class=d-none id=inverted-logo alt="Inverted Logo"></nav><section class=sidebar-section id=sidebar-section><div class=sidebar-holder><div class=sidebar id=sidebar><form class=mx-auto method=get action=/blog-akitenkrad/search><input type=text name=keyword placeholder=Search data-search id=search-box></form><div class=sidebar-tree><ul class=tree id=tree><li id=list-heading><a href=/blog-akitenkrad/posts data-filter=all>Posts</a></li><div class=subtree><li><i class="fas fa-minus-circle"></i><a class=active href=/blog-akitenkrad/posts/papers/>Papers</a><ul class=active><li><i class="fas fa-minus-circle"></i><a class=active href=/blog-akitenkrad/posts/papers/202205/>2022.05</a><ul class=active><li><a href=/blog-akitenkrad/posts/papers/202205/20220503010000/ title=2022.05.03>2022.05.03</a></li><li><a href=/blog-akitenkrad/posts/papers/202205/20220505222900/ title=2022.05.05>2022.05.05</a></li><li><a href=/blog-akitenkrad/posts/papers/202205/20220506021208/ title=2022.05.06>2022.05.06</a></li><li><a href=/blog-akitenkrad/posts/papers/202205/20220508162318/ title=2022.05.08>2022.05.08</a></li><li><a href=/blog-akitenkrad/posts/papers/202205/20220509110738/ title=2022.05.09>2022.05.09</a></li><li><a href=/blog-akitenkrad/posts/papers/202205/20220511010217/ title=2022.05.11>2022.05.11</a></li><li><a href=/blog-akitenkrad/posts/papers/202205/20220514151839/ title=2022.05.14>2022.05.14</a></li><li><a href=/blog-akitenkrad/posts/papers/202205/20220518224923/ title=2022.05.18>2022.05.18</a></li><li><a href=/blog-akitenkrad/posts/papers/202205/20220520124748/ title=2022.05.20>2022.05.20</a></li><li><a href=/blog-akitenkrad/posts/papers/202205/20220523223206/ title=2022.05.23>2022.05.23</a></li><li><a href=/blog-akitenkrad/posts/papers/202205/20220525115521/ title=2022.05.25>2022.05.25</a></li><li><a href=/blog-akitenkrad/posts/papers/202205/20220529131339/ title=2022.05.29>2022.05.29</a></li><li><a href=/blog-akitenkrad/posts/papers/202205/20220530102936/ title=2022.05.30>2022.05.30</a></li></ul></li><li><a href=/blog-akitenkrad/posts/papers/202206/ title=2022.06>2022.06</a></li><li><i class="fas fa-plus-circle"></i><a href=/blog-akitenkrad/posts/papers/202207/>2022.07</a><ul><li><a href=/blog-akitenkrad/posts/papers/202207/20220726163444/ title=2022.07.25>2022.07.25</a></li><li><a href=/blog-akitenkrad/posts/papers/202207/20220727145036/ title=2022.07.27>2022.07.27</a></li></ul></li></ul></li><li><a href=/blog-akitenkrad/posts/latex/ title="Latex Mathematics Syntax Guide">Latex Mathematics Syntax Guide</a></li><li><a href=/blog-akitenkrad/posts/markdown/ title="Markdown Sample">Markdown Sample</a></li></div></ul></div></div></div></section><section class=content-section id=content-section><div class="content container-fluid" id=content><div class="container-fluid post-card-holder" id=post-card-holder><div class=post-card><a href=https://akitenkrad.github.io/blog-akitenkrad/posts/papers/202205/20220530102936/ class=post-card-link><div class=card><div class=card-head><img class=card-img-top src=/blog-akitenkrad/posts/papers/202205/20220530102936/hero.jpg alt="Hero Image"></div><div class=card-body><h5 class=card-title>Neural Machine Translation of Rare Words with Subword Units</h5><p class="card-text post-summary">Round-1: Overview Round-2: Model Implementation Details Round-3: Experiments Citation Sennrich, R., Haddow, B., & Birch, A. (2015).
Neural Machine Translation of Rare Words with Subword Units.
https://doi.org/10.48550/arxiv.1508.07909 Abstract Neural machine translation (NMT) models typically operate with a fixed vocabulary, but translation is an open-vocabulary problem. Previous work addresses the translation of out-of-vocabulary words by backing off to a dictionary. In this paper, we introduce a simpler and more effective approach, making the NMT model capable of open-vocabulary translation by encoding rare and unknown words as sequences of subword units.</p></div><div class=card-footer><span class=float-left>May 30, 2022</span>
<a href=https://akitenkrad.github.io/blog-akitenkrad/posts/papers/202205/20220530102936/ class="float-right btn btn-outline-info btn-sm">Read</a></div></div></a></div><div class=post-card><a href=https://akitenkrad.github.io/blog-akitenkrad/posts/papers/202205/20220529131339/ class=post-card-link><div class=card><div class=card-head><img class=card-img-top src=/blog-akitenkrad/posts/papers/202205/20220529131339/hero.jpg alt="Hero Image"></div><div class=card-body><h5 class=card-title>Attention Is All You Need</h5><p class="card-text post-summary">Round-1: Overview Round-2: Model Implementation Details Round-3: Experiments Citation Vaswani, A., Shazeer, N., Parmar, N., Uszkoreit, J., Jones, L., Gomez, A. N., Kaiser, Ł., & Polosukhin, I. (2017).
Attention is all you need.
Advances in Neural Information Processing Systems, 2017-Decem, 5999–6009.
http://arxiv.org/abs/1706.03762 Abstract The dominant sequence transduction models are based on complex recurrent or convolutional neural networks in an encoder-decoder configuration. The best performing models also connect the encoder and decoder through an attention mechanism.</p></div><div class=card-footer><span class=float-left>May 29, 2022</span>
<a href=https://akitenkrad.github.io/blog-akitenkrad/posts/papers/202205/20220529131339/ class="float-right btn btn-outline-info btn-sm">Read</a></div></div></a></div><div class=post-card><a href=https://akitenkrad.github.io/blog-akitenkrad/posts/papers/202205/20220525115521/ class=post-card-link><div class=card><div class=card-head><img class=card-img-top src=/blog-akitenkrad/posts/papers/202205/20220525115521/hero.png alt="Hero Image"></div><div class=card-body><h5 class=card-title>Improving Language Understanding by Generative Pre-Training</h5><p class="card-text post-summary">Round-1: Overview Round-2: Model Implementation Details Round-3: Experiments Citation Abstract What&rsquo;s New Dataset Model Description Training Settings Results References Semi-Supervised Text Classification Using EM (O. Chapelle et al., 2006) O. Chapelle, Bernhard SchÃ¶lkopf, A. Zien. (2006)
Semi-Supervised Text Classification Using EM
Paper Link
Influential Citation Count (2), SS-ID (03bafef700d35112a9926dd1b2be91a4aa6984a4)
ABSTRACT
This chapter contains sections titled: Introduction, A Generative Model for Text, Experimental Results with Basic EM, Using a More Expressive Generative Model, Overcoming the Challenges of Local Maxima, Conclusions and Summary</p></div><div class=card-footer><span class=float-left>May 25, 2022</span>
<a href=https://akitenkrad.github.io/blog-akitenkrad/posts/papers/202205/20220525115521/ class="float-right btn btn-outline-info btn-sm">Read</a></div></div></a></div><div class=post-card><a href=https://akitenkrad.github.io/blog-akitenkrad/posts/papers/202205/20220523223206/ class=post-card-link><div class=card><div class=card-head><img class=card-img-top src=/blog-akitenkrad/posts/papers/202205/20220523223206/hero.jpg alt="Hero Image"></div><div class=card-body><h5 class=card-title>RoBERTa: A Robustly Optimized BERT Pretraining Approach</h5><p class="card-text post-summary">Round-1: Overview Round-2: Model Implementation Details Round-3: Experiments Citation Liu, Y., Ott, M., Goyal, N., Du, J., Joshi, M., Chen, D., Levy, O., Lewis, M., Zettlemoyer, L., & Stoyanov, V. (2019).
RoBERTa: A Robustly Optimized BERT Pretraining Approach.
https://doi.org/10.48550/arxiv.1907.11692 Abstract Language model pretraining has led to significant performance gains but careful comparison between different approaches is challenging. Training is computationally expensive, often done on private datasets of different sizes, and, as we will show, hyperparameter choices have significant impact on the final results.</p></div><div class=card-footer><span class=float-left>May 23, 2022</span>
<a href=https://akitenkrad.github.io/blog-akitenkrad/posts/papers/202205/20220523223206/ class="float-right btn btn-outline-info btn-sm">Read</a></div></div></a></div><div class=post-card><a href=https://akitenkrad.github.io/blog-akitenkrad/posts/papers/202205/20220520124748/ class=post-card-link><div class=card><div class=card-head><img class=card-img-top src=/blog-akitenkrad/posts/papers/202205/20220520124748/hero.jpg alt="Hero Image"></div><div class=card-body><h5 class=card-title>Semi-Supervised Classification with Graph Convolutional Networks</h5><p class="card-text post-summary">Round-1: Overview Round-2: Model Implementation Details Round-3: Experiments Citation Kipf, T. N., & Welling, M. (2016).
Semi-Supervised Classification with Graph Convolutional Networks.
Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition. (2019)
https://doi.org/10.48550/arxiv.1609.02907 Abstract We present a scalable approach for semi-supervised learning on graph-structured data that is based on an efficient variant of convolutional neural networks which operate directly on graphs. We motivate the choice of our convolutional architecture via a localized first-order approximation of spectral graph convolutions.</p></div><div class=card-footer><span class=float-left>May 20, 2022</span>
<a href=https://akitenkrad.github.io/blog-akitenkrad/posts/papers/202205/20220520124748/ class="float-right btn btn-outline-info btn-sm">Read</a></div></div></a></div><div class=post-card><a href=https://akitenkrad.github.io/blog-akitenkrad/posts/papers/202205/20220518224923/ class=post-card-link><div class=card><div class=card-head><img class=card-img-top src=/blog-akitenkrad/posts/papers/202205/20220518224923/hero.png alt="Hero Image"></div><div class=card-body><h5 class=card-title>A Context-Aware Citation Recommendation Model with BERT and Graph Convolutional Networks</h5><p class="card-text post-summary">Round-1: Overview Round-2: Model Implementation Details Round-3: Experiments Citation Jeong, C., Jang, S., Shin, H., Park, E., & Choi, S. (2019).
A Context-Aware Citation Recommendation Model with BERT and Graph Convolutional Networks.
https://doi.org/10.48550/arxiv.1903.06464 Abstract With the tremendous growth in the number of scientific papers being published, searching for references while writing a scientific paper is a time-consuming process. A technique that could add a reference citation at the appropriate place in a sentence will be beneficial.</p></div><div class=card-footer><span class=float-left>May 18, 2022</span>
<a href=https://akitenkrad.github.io/blog-akitenkrad/posts/papers/202205/20220518224923/ class="float-right btn btn-outline-info btn-sm">Read</a></div></div></a></div><div class=post-card><a href=https://akitenkrad.github.io/blog-akitenkrad/posts/papers/202205/20220514151839/ class=post-card-link><div class=card><div class=card-head><img class=card-img-top src=/blog-akitenkrad/posts/papers/202205/20220514151839/hero.jpg alt="Hero Image"></div><div class=card-body><h5 class=card-title>UnitedQA: A Hybrid Approach for Open Domain Question Answering</h5><p class="card-text post-summary">Round-1: Overview Round-2: Model Implementation Details Round-3: Experiments Citation Cheng, H., Shen, Y., Liu, X., He, P., Chen, W., & Gao, J. (2021).
UnitedQA: A Hybrid Approach for Open Domain Question Answering.
https://doi.org/10.48550/arxiv.2101.00178 Abstract To date, most of recent work under the retrieval-reader framework for open-domain QA focuses on either extractive or generative reader exclusively. In this paper, we study a hybrid approach for leveraging the strengths of both models.</p></div><div class=card-footer><span class=float-left>May 14, 2022</span>
<a href=https://akitenkrad.github.io/blog-akitenkrad/posts/papers/202205/20220514151839/ class="float-right btn btn-outline-info btn-sm">Read</a></div></div></a></div><div class=post-card><a href=https://akitenkrad.github.io/blog-akitenkrad/posts/papers/202205/20220511010217/ class=post-card-link><div class=card><div class=card-head><img class=card-img-top src=/blog-akitenkrad/posts/papers/202205/20220511010217/hero.jpg alt="Hero Image"></div><div class=card-body><h5 class=card-title>Multi-Style Generative Reading Comprehension</h5><p class="card-text post-summary">Round-1: Overview Round-2: Model Implementation Details Round-3: Experiments Citation Nishida, K., Saito, I., Nishida, K., Shinoda, K., Otsuka, A., Asano, H., & Tomita, J. (2020).
Multi-style Generative Reading Comprehension.
ACL 2019 - 57th Annual Meeting of the Association for Computational Linguistics, Proceedings of the Conference, 2273–2284.
https://doi.org/10.18653/v1/p19-1220 Abstract This study tackles generative reading comprehension (RC), which consists of answering questions based on textual evidence and natural language generation (NLG). We proposea multi-style abstractive summarization model for question answering, called Masque.</p></div><div class=card-footer><span class=float-left>May 11, 2022</span>
<a href=https://akitenkrad.github.io/blog-akitenkrad/posts/papers/202205/20220511010217/ class="float-right btn btn-outline-info btn-sm">Read</a></div></div></a></div><div class=post-card><a href=https://akitenkrad.github.io/blog-akitenkrad/posts/papers/202205/20220509110738/ class=post-card-link><div class=card><div class=card-head><img class=card-img-top src=/blog-akitenkrad/posts/papers/202205/20220509110738/hero.jpg alt="Hero Image"></div><div class=card-body><h5 class=card-title>Survey on graph embeddings and their applications to machine learning problems on graphs</h5><p class="card-text post-summary">Round-1: Overview Round-2: Model Implementation Details Round-3: Experiments Citation Makarov, I., Kiselev, D., Nikitinsky, N., & Subelj, L. (2021).
Survey on graph embeddings and their applications to machine learning problems on graphs.
PeerJ Computer Science, 7, 1–62.
Paper Link Abstract Dealing with relational data always required significant computational resources,domain expertise and task-dependent feature engineering to incorporate structuralinformation into a predictive model. Nowadays, a family of automated graphfeature engineering techniques has been proposed in different streams of literature.</p></div><div class=card-footer><span class=float-left>May 9, 2022</span>
<a href=https://akitenkrad.github.io/blog-akitenkrad/posts/papers/202205/20220509110738/ class="float-right btn btn-outline-info btn-sm">Read</a></div></div></a></div><div class=post-card><a href=https://akitenkrad.github.io/blog-akitenkrad/posts/papers/202205/20220508162318/ class=post-card-link><div class=card><div class=card-head><img class=card-img-top src=/blog-akitenkrad/posts/papers/202205/20220508162318/hero.jpg alt="Hero Image"></div><div class=card-body><h5 class=card-title>A Deep Cascade Model for Multi-Document Reading Comprehension</h5><p class="card-text post-summary">Round-1: Overview Round-2: Model Implementation Details Round-3: Experiments Citation Yan, M., Xia, J., Wu, C., Bi, B., Zhao, Z., Zhang, J., Si, L., Wang, R., Wang, W., & Chen, H. (2019).
A Deep Cascade Model for Multi-Document Reading Comprehension.
Proceedings of the AAAI Conference on Artificial Intelligence, 33, 7354–7361.
https://doi.org/10.1609/aaai.v33i01.33017354 Abstract A fundamental trade-off between effectiveness and efficiency needs to be balanced when designing an online question answering system. Effectiveness comes from sophisticated functions such as extractive machine reading comprehension (MRC), while efficiency is obtained from improvements in preliminary retrieval components such as candidate document selection and paragraph ranking.</p></div><div class=card-footer><span class=float-left>May 8, 2022</span>
<a href=https://akitenkrad.github.io/blog-akitenkrad/posts/papers/202205/20220508162318/ class="float-right btn btn-outline-info btn-sm">Read</a></div></div></a></div><div class=post-card><a href=https://akitenkrad.github.io/blog-akitenkrad/posts/papers/202205/20220506021208/ class=post-card-link><div class=card><div class=card-head><img class=card-img-top src=/blog-akitenkrad/posts/papers/202205/20220506021208/hero.jpg alt="Hero Image"></div><div class=card-body><h5 class=card-title>A Primer in BERTology: What We Know About How BERT Works</h5><p class="card-text post-summary">Round-1: Overview Round-2: Model Implementation Details Round-3: Experiments Citation Rogers, A., Kovaleva, O., & Rumshisky, A. (2020).
A Primer in BERTology: What We Know About How BERT Works.
Transactions of the Association for Computational Linguistics, 8, 842–866.
Paper Link Abstract Transformer-based models have pushed state of the art in many areas of NLP, but our understanding of what is behind their success is still limited. This paper is the first survey of over 150 studies of the popular BERT model.</p></div><div class=card-footer><span class=float-left>May 6, 2022</span>
<a href=https://akitenkrad.github.io/blog-akitenkrad/posts/papers/202205/20220506021208/ class="float-right btn btn-outline-info btn-sm">Read</a></div></div></a></div><div class=post-card><a href=https://akitenkrad.github.io/blog-akitenkrad/posts/papers/202205/20220505222900/ class=post-card-link><div class=card><div class=card-head><img class=card-img-top src=/blog-akitenkrad/posts/papers/202205/20220505222900/hero.jpg alt="Hero Image"></div><div class=card-body><h5 class=card-title>Dense Passage Retrieval for Open-Domain Question Answering</h5><p class="card-text post-summary">Round-1: Overview Round-2: Model Implementation Details Round-3: Experiments Citation Karpukhin, V., Oğuz, B., Min, S., Lewis, P., Wu, L., Edunov, S., Chen, D., & Yih, W. (2020).
Dense Passage Retrieval for Open-Domain Question Answering.
Paper Link Abstract Open-domain question answering relies on efficient passage retrieval to select candidate contexts, where traditional sparse vector space models, such as TF-IDF or BM25, are the de facto method. In this work, we show that retrieval can be practically implemented using dense representations alone, where embeddings are learned from a small number of questions and passages by a simple dual-encoder framework.</p></div><div class=card-footer><span class=float-left>May 5, 2022</span>
<a href=https://akitenkrad.github.io/blog-akitenkrad/posts/papers/202205/20220505222900/ class="float-right btn btn-outline-info btn-sm">Read</a></div></div></a></div></div><div class=paginator><ul class="pagination pagination-default"><li class="page-item disabled"><a aria-disabled=true aria-label=First class=page-link role=button tabindex=-1><span aria-hidden=true>&#171;&#171;</span></a></li><li class="page-item disabled"><a aria-disabled=true aria-label=Previous class=page-link role=button tabindex=-1><span aria-hidden=true>&#171;</span></a></li><li class="page-item active"><a aria-current=page aria-label="Page 1" class=page-link role=button>1</a></li><li class=page-item><a href=/blog-akitenkrad/posts/papers/202205/page/2/ aria-label="Page 2" class=page-link role=button>2</a></li><li class=page-item><a href=/blog-akitenkrad/posts/papers/202205/page/2/ aria-label=Next class=page-link role=button><span aria-hidden=true>&#187;</span></a></li><li class=page-item><a href=/blog-akitenkrad/posts/papers/202205/page/2/ aria-label=Last class=page-link role=button><span aria-hidden=true>&#187;&#187;</span></a></li></ul></div></div></section></div><footer id=footer class="container-fluid text-center align-content-center footer pb-2"><div class="container pt-5"><div class="row text-left"><div class="col-md-4 col-sm-12"><h5>Navigation</h5><ul><li class=nav-item><a class=smooth-scroll href=https://akitenkrad.github.io/blog-akitenkrad/#about>About</a></li><li class=nav-item><a class=smooth-scroll href=https://akitenkrad.github.io/blog-akitenkrad/#recent-posts>Recent Posts</a></li></ul></div><div class="col-md-4 col-sm-12"><h5>Contact me:</h5><ul><li><a href=mailto:contact.to.akitenkrad@gmail.com target=_blank rel=noopener><span><i class="fas fa-envelope"></i></span> <span>contact.to.akitenkrad@gmail.com</span></a></li></ul></div></div></div><hr><div class=container><div class="row text-left"><div class=col-md-4><a id=theme href=https://github.com/hossainemruz/toha target=_blank rel=noopener><img src=/blog-akitenkrad/images/theme-logo_hu8376fd15465fef26ffe66b6bcf0ca686_13669_32x0_resize_box_3.png alt="Toha Theme Logo">
Toha</a></div><div class="col-md-4 text-center">© 2020 Akitenkrad.</div><div class="col-md-4 text-right"><a id=hugo href=https://gohugo.io/ target=_blank rel=noopener>Powered by
<img src=/blog-akitenkrad/images/hugo-logo.svg alt="Hugo Logo" height=18></a></div></div></div><script src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.4/MathJax.js?config=TeX-AMS-MML_HTMLorMML"></script>
<script type=text/x-mathjax-config>
      MathJax.Hub.Config({
        tex2jax: {
          inlineMath: [['$','$']]
        }
      });
      </script></footer><script type=text/javascript src=https://akitenkrad.github.io/blog-akitenkrad/js/jquery-3.4.1.min.js></script>
<script type=text/javascript src=https://akitenkrad.github.io/blog-akitenkrad/js/popper.min.js></script>
<script type=text/javascript src=https://akitenkrad.github.io/blog-akitenkrad/js/bootstrap.min.js></script>
<script type=text/javascript src=https://akitenkrad.github.io/blog-akitenkrad/js/navbar.js></script>
<script type=text/javascript src=https://akitenkrad.github.io/blog-akitenkrad/js/plyr.js></script>
<script type=text/javascript src=https://akitenkrad.github.io/blog-akitenkrad/js/main.js></script>
<script src=https://akitenkrad.github.io/blog-akitenkrad/js/list.js></script></body></html>